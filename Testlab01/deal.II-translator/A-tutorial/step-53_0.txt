[0.x.0]*
 [2.x.0] 
* This tutorial depends on  [2.x.1] .
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13]
*  [2.x.2] 
* [1.x.14]
*  [2.x.3]  This program elaborates on concepts of geometry and the classes thatimplement it. These classes are grouped into the documentation module on  [2.x.4]  "Manifold description for triangulations". See there for additionalinformation.
*  [2.x.5]  This tutorial is also available as a Jupyter Python notebook that  uses the deal.II python interface. The notebook is available in the  same directory as the original C++ program. Rendered notebook can also  be viewed on the [1.x.15].
* 

* [1.x.16][1.x.17][1.x.18]
* 

* Partial differential equations for realistic problems are often posed ondomains with complicated geometries. To provide just a few examples, considerthese cases:
* 
*  - Among the two arguably most important industrial applications for the finite  element method, aerodynamics and more generally fluid dynamics is  one. Computer simulations today are used in the design of every airplane,  car, train and ship. The domain in which the partial differential equation  is posed is, in these cases, the air surrounding the plane with its wings,  flaps and engines; the air surrounding the car with its wheel, wheel wells,  mirrors and, in the case of race cars, all sorts of aerodynamic equipment;  the air surrounding the train with its wheels and gaps between cars. In the  case of ships, the domain is the water surrounding the ship with its rudders  and propellers.
* 
*  - The other of the two big applications of the finite element method is  structural engineering in which the domains are bridges, airplane nacelles  and wings, and other solid bodies of often complicated shapes.
* 
*  - Finite element modeling is also often used to describe the generation and  propagation of earthquake waves. In these cases, one needs to accurately  represent the geometry of faults in the Earth crust. Since faults intersect,  dip at angles, and are often not completely straight, domains are frequently  very complex.One could cite many more examples of complicated geometries in which one wantsto pose and solve a partial differential equation. What this shows is that the"real" world is much more complicated than what we have shown in almost all ofthe tutorial programs preceding this one.
* This program is therefore devoted to showing how one deals with complexgeometries using a concrete application. In particular, what it shows is howwe make a mesh fit the domain we want to solve on. On the other hand, what theprogram does not show is how to create a coarse for a domain. The process toarrive at a coarse mesh is called "mesh generation" and there are a number ofhigh-quality programs that do this much better than we could everimplement. However, deal.II does have the ability to read in meshes in manyformats generated by mesh generators and then make them fit a given shape,either by deforming a mesh or refining it a number of times until it fits. Thedeal.II Frequently Asked Questions page referenced from http://www.dealii.org/provides resources to mesh generators.
* 

* [1.x.19][1.x.20]
* 

* Let us assume that you have a complex domain and that you already have acoarse mesh that somehow represents the general features of the domain. Thenthere are two situations in which it is necessary to describe to a deal.IIprogram the details of your geometry:
* 
*  - Mesh refinement: Whenever a cell is refined, it is necessary to introduce  new vertices in the Triangulation. In the simplest case, one assumes that  the objects that make up the Triangulation are straight line segments, a  bi-linear surface or a tri-linear volume. The next vertex is then simply put  into the middle of the old ones. However, for curved boundaries or if we  want to solve a PDE on a curved, lower-dimensional manifold embedded in a  higher-dimensional space, this is insufficient since it will not respect the  actual geometry. We will therefore have to tell Triangulation where to put  new points.
* 
*  - Integration: When using higher order finite element methods, it is often  necessary to compute integrals using curved approximations of the boundary,  i.e., describe each edge or face of cells as curves, instead of straight  line segments or bilinear patches. The same is, of course, true when  integrating boundary terms (e.g., inhomogeneous Neumann boundary  conditions). For the purpose of integration, the various Mapping classes  then provide the transformation from the reference cell to the actual cell.
* In both cases, we need a way to provide information about the geometry of thedomain at the level of an individual cell, its faces and edges. This is wherethe Manifold class comes into play. Manifold is an abstract base class thatonly defines an interface by which the Triangulation and Mapping classes canquery geometric information about the domain. Conceptually, Manifold sees theworld in a way not dissimilar to how the mathematical subdiscipline geometrysees it: a domain is essentially just a collection of points that is somehowequipped with the notion of a distance between points so that we can obtain apoint "in the middle" of some other points.
* deal.II provides a number of classes that implement the interface provided byManifold for a variety of common geometries. On the other hand, in thisprogram we will consider only a very common and much simpler case, namely thesituation where (a part of) the domain we want to solve on can be described bytransforming a much simpler domain (we will call this the "reference domain").In the language of mathematics, this meansthat the (part of the) domain is a [1.x.21]. Charts aredescribed by a smooth function that maps from the simpler domain to the chart(the "push-forward" function) and its inverse (the "pull-back" function). Ifthe domain as a whole is not a chart (e.g., the surface of a sphere), then itcan often be described as a collection of charts (e.g., the northernhemisphere and the southern hemisphere are each charts) and the domain can thenbe describe by an [1.x.22].
* If a domain can be decomposed into an atlas, all we need to do is provide thepull-back and push-forward functions for each of the charts. In deal.II, thismeans providing a class derived from ChartManifold, and this is precisely whatwe will do in this program.
* 

* [1.x.23][1.x.24]
* 

* To illustrate how one describes geometries using charts in deal.II, we willconsider a case that originates in an application of the [1.x.25], using adata set provided by D. Sarah Stamps. In the concrete application, we wereinterested in describing flow in the Earth mantle under the [1.x.26], azone where two continental plates drift apart. Not to beat around the bush,the geometry we want to describe looks like this:
*  [2.x.6] 
* In particular, though you cannot see this here, the top surface is notjust colored by the elevation but is, in fact, deformed to follow thecorrect topography.While the actual application is not relevant here, the geometry is. The domainwe are interested in is a part of the Earth that ranges from the surface to adepth of 500km, from 26 to 35 degrees East of the Greenwich meridian, and from5 degrees North of the equator to 10 degrees South.
* This description of the geometry suggests to start with a box [2.x.7]  (measured in degrees,degrees, and meters) and to provide a map  [2.x.8]  sothat  [2.x.9]  where  [2.x.10]  is the domain weseek.  [2.x.11]  is then a chart,  [2.x.12]  the pull-back operator, and [2.x.13]  the push-forward operator. If we need a point  [2.x.14]  that is the"average" of other points  [2.x.15] , the ChartManifold class then firstapplies the pull-back to obtain  [2.x.16] , averages these to apoint  [2.x.17]  and then computes  [2.x.18] .
* Our goal here is therefore to implement a class that describes  [2.x.19]  and [2.x.20] . If Earth was a sphere, then this would not be difficult: if wedenote by  [2.x.21]  the points of  [2.x.22]  (i.e.,longitude counted eastward, latitude counted northward, and elevation relativeto zero depth), then[1.x.27]provides coordinates in a Cartesian coordinate system, where  [2.x.23]  is the radiusof the sphere. However, the Earth is not a sphere:
*  [2.x.24]  [2.x.25]  It is flattened at the poles and larger at the equator: the semi-major axis  is approximately 22km longer than the semi-minor axis. We will account for  this using the [1.x.28]  reference standard for the Earth shape. The formula used in WGS 84 to obtain  a position in Cartesian coordinates from longitude, latitude, and elevation  is[1.x.29]  where  [2.x.26] , and radius and  ellipticity are given by  [2.x.27] . In this formula,  we assume that the arguments to sines and cosines are evaluated in degree, not  radians (though we will have to change this assumption in the code).
*  [2.x.28]  It has topography in the form of mountains and valleys. We will account for  this using real topography data (see below for a description of where  this data comes from). Using this data set, we can look up elevations on a  latitude-longitude mesh laid over the surface of the Earth. Starting with  the box  [2.x.29] , we will therefore  first stretch it in vertical direction before handing it off to the WGS 84  function: if  [2.x.30]  is the height at longitude  [2.x.31]   and latitude  [2.x.32] , then we define[1.x.30]  Using this function, the top surface of the box  [2.x.33]  is displaced to the  correct topography, the bottom surface remains where it was, and points in  between are linearly interpolated. [2.x.34] 
* Using these two functions, we can then define the entire push-forward function [2.x.35]  as[1.x.31]In addition, we will have to define the inverse of this function, thepull-back operation, which we can write as[1.x.32]We can obtain one of the components of this function by inverting the formula above:[1.x.33]Computing  [2.x.36]  is also possible though a lot moreawkward. We won't show the formula here but instead only provide the implementationin the program.
* 

* [1.x.34][1.x.35]
* 

* There are a number of issues we need to address in the program. At the largest scale,we need to write a class that implements the interface of ChartManifold. This involvesa function  [2.x.37]  that takes a pointin the reference domain  [2.x.38]  and transform it into real space using the function [2.x.39]  outlined above, and its inverse function  [2.x.40] implementing  [2.x.41] . We will do so in the  [2.x.42]  class belowthat looks, in essence, like this:
* [1.x.36]
* 
* The transformations above have two parts: the WGS 84 transformations and the topographytransformation. Consequently, the  [2.x.43]  class will haveadditional (non-virtual) member functions [2.x.44]  and [2.x.45]  that implement these two pieces, andcorresponding pull back functions.
* The WGS 84 transformation functions are not particularly interesting (even though theformulas they implement are impressive). The more interesting part is the topographytransformation. Recall that for this, we needed to evaluate the elevation function [2.x.46] . There is of course no formula for this: Earth is what it is,the best one can do is look up the altitude from some table. This is, in fact what wewill do.
* The data we use was originally created by the  [1.x.37], was downloaded from the US Geologic Survey(USGS) and processed by D. Sarah Stamps who also wrote the initial version ofthe WGS 84 transformation functions. The topography data so processed isstored in a file  [2.x.47]  that, when unpackedlooks like this:
* [1.x.38]
* The data is formatted as  [2.x.48]  where the first twocolumns are provided in degrees North of the equator and degrees East of the Greenwichmeridian. The final column is given in meters above the WGS 84 zero elevation.
* In the transformation functions, we need to evaluate  [2.x.49]  for a givenlongitude  [2.x.50]  and latitude  [2.x.51] . In general, this data point will not beavailable and we will have to interpolate between adjacent data points. Writing such aninterpolation routine is not particularly difficult, but it is a bit tedious and errorprone. Fortunately, we can somehow shoehorn this data set into an existing class: [2.x.52]  . Unfortunately, the class does not fit the billquite exactly and so we need to work around it a bit. The problem comes from the waywe initialize this class: in its simplest form, it takes a stream of values that itassumes form an equispaced mesh in the  [2.x.53]  plane (or, here, the  [2.x.54]  plane).Which is what they do here, sort of: they are ordered latitude first, longitude second;and more awkwardly, the first column starts at the largest values and counts down,rather than the usual other way around.
* Now, while tutorial programs are meant to illustrate how to code with deal.II, they donot necessarily have to satisfy the same quality standards as one would have to dowith production codes. In a production code, we would write a function that reads thedata and (i) automatically determines the extents of the first and second column,(ii) automatically determines the number of data points in each direction, (iii) doesthe interpolation regardless of the order in which data is arranged, if necessaryby switching the order between reading and presenting it to the [2.x.55]  class.
* On the other hand, tutorial programs are best if they are short and demonstrate keypoints rather than dwell on unimportant aspects and, thereby, obscure what we reallywant to show. Consequently, we will allow ourselves a bit of leeway:
* 
*  - since this program is intended solely for a particular geometry around the area  of the East-African rift and since this is precisely the area described by the data  file, we will hardcode in the program that there are   [2.x.56]  pieces of data;
* 
*  - we will hardcode the boundaries of the data   [2.x.57] ;
* 
*  - we will lie to the  [2.x.58]  class: the class will  only see the data in the last column of this data file, and we will pretend that  the data is arranged in a way that there are 1139 data points in the first  coordinate direction that are arranged in [1.x.39] order but in an  interval  [2.x.59]  (not the negated bounds). Then,  when we need to look something up for a latitude  [2.x.60] , we can ask the  interpolating table class for a value at  [2.x.61] . With this little  trick, we can avoid having to switch around the order of data as read from  file.
* All of this then calls for a class that essentially looks like this:
* [1.x.40]
* 
* Note how the  [2.x.62]  function negates the latitude. It also switchesfrom the format  [2.x.63]  that we use everywhere else to the latitude-longitudeformat used in the table. Finally, it takes its arguments in radians as that is whatwe do everywhere else in the program, but then converts them to the degree-basedsystem used for table lookup. As you will see in the implementation below, the functionhas a few more (static) member functions that we will call in the initializationof the  [2.x.64]  member variable: the class type of this variablehas a constructor that allows us to set everything right at construction time,rather than having to fill data later on, but this constructor takes a number ofobjects that can't be constructed in-place (at least not in C++98). Consequently,the construction of each of the objects we want to pass in the initialization happensin a number of static member functions.
* Having discussed the general outline of how we want to implement things, let us goto the program and show how it is done in practice.
* 

*  [1.x.41] [1.x.42]
*  Let us start with the include files we need here. Obviously, we need the ones that describe the triangulation ( [2.x.65] ), and that allow us to create and output triangulations ( [2.x.66]  and  [2.x.67] ). Furthermore, we need the header file that declares the Manifold and ChartManifold classes that we will need to describe the geometry ( [2.x.68] ). We will then also need the  [2.x.69]  function from the last of the following header files; the purpose for this function will become discussed at the point where we use it.
* 

* 
* [1.x.43]
* 
*  The remainder of the include files relate to reading the topography data. As explained in the introduction, we will read it from a file and then use the  [2.x.70]  class that is declared in the first of the following header files. Because the data is large, the file we read from is stored as gzip compressed data and we make use of some BOOST-provided functionality to read directly from gzipped data.
* 

* 
* [1.x.44]
* 
*  The final part of the top matter is to open a namespace into which to put everything, and then to import the dealii namespace into it.
* 

* 
* [1.x.45]
* 
*   [1.x.46]  [1.x.47]   
*   The first significant part of this program is the class that describes the topography  [2.x.71]  as a function of longitude and latitude. As discussed in the introduction, we will make our life a bit easier here by not writing the class in the most general way possible but by only writing it for the particular purpose we are interested in here: interpolating data obtained from one very specific data file that contains information about a particular area of the world for which we know the extents.   
*   The general layout of the class has been discussed already above. Following is its declaration, including three static member functions that we will need in initializing the  [2.x.72]  member variable.
* 

* 
* [1.x.48]
* 
*  Let us move to the implementation of the class. The interesting parts of the class are the constructor and the  [2.x.73]  function. The former initializes the  [2.x.74]  member variable and we will use the constructor that requires us to pass in the end points of the 2-dimensional data set we want to interpolate (which are here given by the intervals  [2.x.75] , using the trick of switching end points discussed in the introduction, and  [2.x.76] , both given in degrees), the number of intervals into which the data is split (379 in latitude direction and 219 in longitude direction, for a total of  [2.x.77]  data points), and a Table object that contains the data. The data then of course has size  [2.x.78]  and we initialize it by providing an iterator to the first of the 83,600 elements of a  [2.x.79]  object returned by the  [2.x.80]  function below. Note that all of the member functions we call here are static because (i) they do not access any member variables of the class, and (ii) because they are called at a time when the object is not initialized fully anyway.
* 

* 
* [1.x.49]
* 
*  The only other function of greater interest is the  [2.x.81]  function. It returns a temporary vector that contains all 83,600 data points describing the altitude and is read from the file  [2.x.82] . Because the file is compressed by gzip, we cannot just read it through an object of type  [2.x.83]  but there are convenient methods in the BOOST library (see http://www.boost.org) that allows us to read from compressed files without first having to uncompress it on disk. The result is, basically, just another input stream that, for all practical purposes, looks just like the ones we always use.   
*   When reading the data, we read the three columns but throw ignore the first two. The datum in the last column is appended to an array that we the return and that will be copied into the table from which  [2.x.84]  is initialized. Since the BOOST.iostreams library does not provide a very useful exception when the input file does not exist, is not readable, or does not contain the correct number of data lines, we catch all exceptions it may produce and create our own one. To this end, in the  [2.x.85]  clause, we let the program run into an  [2.x.86]  statement. Since the condition is always false, this always triggers an exception. In other words, this is equivalent to writing  [2.x.87]  but it also fills certain fields in the exception object that will later be printed on the screen identifying the function, file and line where the exception happened.
* 

* 
* [1.x.50]
* 
*  create a stream where we read from gzipped data
* 

* 
* [1.x.51]
* 
*   [1.x.52]  [1.x.53]   
*   The following class is then the main one of this program. Its structure has been described in much detail in the introduction and does not need much introduction any more.
* 

* 
* [1.x.54]
* 
*  The implementation, as well, is pretty straightforward if you have read the introduction. In particular, both of the pull back and push forward functions are just concatenations of the respective functions of the WGS 84 and topography mappings:
* 

* 
* [1.x.55]
* 
*  The next function is required by the interface of the Manifold base class, and allows cloning the AfricaGeometry class. Notice that, while the function returns a  [2.x.88]  we internally create a `unique_ptr<AfricaGeometry>`. In other words, the library requires a pointer-to-base-class, which we provide by creating a pointer-to-derived-class.
* 

* 
* [1.x.56]
* 
*  The following two functions then define the forward and inverse transformations that correspond to the WGS 84 reference shape of Earth. The forward transform follows the formula shown in the introduction. The inverse transform is significantly more complicated and is, at the very least, not intuitive. It also suffers from the fact that it returns an angle that at the end of the function we need to clip back into the interval  [2.x.89]  if it should have escaped from there.
* 

* 
* [1.x.57]
* 
*  In contrast, the topography transformations follow exactly the description in the introduction. There is not consequently not much to add:
* 

* 
* [1.x.58]
* 
*   [1.x.59]  [1.x.60]   
*   Having so described the properties of the geometry, not it is time to deal with the mesh used to discretize it. To this end, we create objects for the geometry and triangulation, and then proceed to create a  [2.x.90]  rectangular mesh that corresponds to the reference domain  [2.x.91] . We choose this number of subdivisions because it leads to cells that are roughly like cubes instead of stretched in one direction or another.   
*   Of course, we are not actually interested in meshing the reference domain. We are interested in meshing the real domain. Consequently, we will use the  [2.x.92]  function that simply moves every point of a triangulation according to a given transformation. The transformation function it wants is a function that takes as its single argument a point in the reference domain and returns the corresponding location in the domain that we want to map to. This is, of course, exactly the push forward function of the geometry we use. We wrap it by a lambda function to obtain the kind of function object required for the transformation.
* 

* 
* [1.x.61]
* 
*  The next step is to explain to the triangulation to use our geometry object whenever a new point is needed upon refining the mesh. We do this by telling the triangulation to use our geometry for everything that has manifold indicator zero, and then proceed to mark all cells and their bounding faces and edges with manifold indicator zero. This ensures that the triangulation consults our geometry object every time a new vertex is needed. Since manifold indicators are inherited from mother to children, this also happens after several recursive refinement steps.
* 

* 
* [1.x.62]
* 
*  The last step is to refine the mesh beyond its initial  [2.x.93]  coarse mesh. We could just refine globally a number of times, but since for the purpose of this tutorial program we're really only interested in what is happening close to the surface, we just refine 6 times all of the cells that have a face at a boundary with indicator 5. Looking this up in the documentation of the  [2.x.94]  function we have used above reveals that boundary indicator 5 corresponds to the top surface of the domain (and this is what the last  [2.x.95]  argument in the call to  [2.x.96]  above meant: to "color" the boundaries by assigning each boundary a unique boundary indicator).
* 

* 
* [1.x.63]
* 
*  Having done this all, we can now output the mesh into a file of its own:
* 

* 
* [1.x.64]
* 
*   [1.x.65]  [1.x.66]
* 

* 
*  Finally, the main function, which follows the same scheme used in all tutorial programs starting with  [2.x.97] . There isn't much to do here, only to call the single  [2.x.98]  function.
* 

* 
* [1.x.67]
* [1.x.68][1.x.69]
* 

* Running the program produces a mesh file  [2.x.99]  that we canvisualize with any of the usual visualization programs that can read the VTUfile format. If one just looks at the mesh itself, it is actually very difficultto see anything that doesn't just look like a perfectly round piece of asphere (though if one modified the program so that it does produce a sphere andlooked at them at the same time, the difference between the overall sphere andWGS 84 shape is quite apparent). Apparently, Earth is actually quite a flat place.Of course we already know this from satellite pictures.However, we can tease out something more bycoloring cells by their volume. This both produces slight variations in huealong the top surface and something for the visualization programs to applytheir shading algorithms to (because the top surfaces of the cells are now nolonger just tangential to a sphere but tilted):
*  [2.x.100] 
* Yet, at least as far as visualizations are concerned, this is still not tooimpressive. Rather, let us visualize things in a way so that we show theactual elevation along the top surface. In other words, we want a picture likethis, with an incredible amount of detail:
*  [2.x.101] 
* A zoom-in of this picture shows the vertical displacement quite clearly (here,looking from the West-Northwest over the rift valley, the triple peaksof[1.x.70],[1.x.71], and[1.x.72]in the[1.x.73],[1.x.74]and toward the great flatness of[1.x.75]):
*  [2.x.102] 
* 

* These image were produced with three small modifications: [2.x.103]    [2.x.104]  An additional seventh mesh refinement towards the top surface for the  first of these two pictures, and a total of nine for the second. In the  second image, the horizontal mesh size is approximately 1.5km, and just  under 1km in vertical direction. (The picture was also created using a  more resolved data set; however, it is too big to distribute as part of  the tutorial.)
*    [2.x.105]  The addition of the following function that, given a point   [2.x.106]  computes the elevation by converting the point to  reference WGS 84 coordinates and only keeping the depth variable (the  function is, consequently, a simplified version of the   [2.x.107]  function):
* [1.x.76]
* 
*    [2.x.108] Adding the following piece to the bottom of the  [2.x.109]  function:
* [1.x.77]
*  [2.x.110] This last piece of code first creates a  [2.x.111]  finite element space on the mesh.It then (ab)uses  [2.x.112]  to evaluate theelevation function for every node at the top boundary (the one with boundaryindicator 5). We here wrap the call to  [2.x.113]  with theScalarFunctionFromFunctionObject class to make a regular C++ function looklike an object of a class derived from the Function class that we wantto use in  [2.x.114]  Having so gotten a listof degrees of freedom located at the top boundary and corresponding elevationvalues, we just go down this list and set these elevations in the [2.x.115]  vector (leaving all interior degrees of freedom attheir original zero value). This vector is then output using DataOut asusual and can be visualized as shown above.
* 

* [1.x.78][1.x.79]
* 

* If you zoomed in on the mesh shown above and looked closely enough, you wouldfind that at hanging nodes, the two small edges connecting to the hangingnodes are not in exactly the same location as the large edge of theneighboring cell. This can be shown more clearly by using a different surfacedescription in which we enlarge the vertical topography to enhance the effect(courtesy of Alexander Grayver):
*  [2.x.116] 
* So what is happening here? Partly, this is only a result of visualization, butthere is an underlying real cause as well:
*  [2.x.117]    [2.x.118] When you visualize a mesh using any of the common visualization  programs, what they really show you is just a set of edges that are plotted  as straight lines in three-dimensional space. This is so because almost all  data file formats for visualizing data only describe hexahedral cells as a  collection of eight vertices in 3d space, and do not allow to any more  complicated descriptions. (This is the main reason why   [2.x.119]  takes an argument that can be set to something  larger than one.) These linear edges may be the edges of the cell you do  actual computations on, or they may not, depending on what kind of mapping  you use when you do your integrations using FEValues. By default, of course,  FEValues uses a linear mapping (i.e., an object of class MappingQ1) and in  that case a 3d cell is indeed described exclusively by its 8 vertices and  the volume it fills is a trilinear interpolation between these points,  resulting in linear edges. But, you could also have used tri-quadratic,  tri-cubic, or even higher order mappings and in these cases the volume of  each cell will be bounded by quadratic, cubic or higher order polynomial  curves. Yet, you only get to see these with linear edges in the  visualization program because, as mentioned, file formats do not allow to  describe the real geometry of cells.
*    [2.x.120] That said, let us for simplicity assume that you are indeed using a  trilinear mapping, then the image shown above is a faithful representation  of the cells on which you form your integrals. In this case, indeed the  small cells at a hanging nodes do not, in general, snugly fit against the  large cell but leave a gap or may intersect the larger cell. Why is this?  Because when the triangulation needs a new vertex on an edge it wants to  refine, it asks the manifold description where this new vertex is supposed  to be, and the manifold description duly returns such a point by (in the  case of a geometry derived from ChartManifold) pulling the adjacent points  of the line back to the reference domain, averaging their locations, and  pushing forward this new location to the real domain. But this new location  is not usually along a straight line (in real space) between the adjacent  vertices and consequently the two small straight lines forming the refined  edge do not lie exactly on the one large straight line forming the unrefined  side of the hanging node. [2.x.121] 
* The situation is slightly more complicated if you use a higher order mappingusing the MappingQ class, but not fundamentally different. Let's take aquadratic mapping for the moment (nothing fundamental changes with even higherorder mappings). Then you need to imagine each edge of the cells you integrateon as a quadratic curve despite the fact that you will never actually see itplotted that way by a visualization program. But imagine it that way for asecond. So which quadratic curve does MappingQ take? It is the quadratic curvethat goes through the two vertices at the end of the edge as well as a pointin the middle that it queries from the manifold. In the case of the long edgeon the unrefined side, that's of course exactly the location of the hangingnode, so the quadratic curve describing the long edge does go through thehanging node, unlike in the case of the linear mapping. But the two smalledges are also quadratic curves; for example, the left small edge will gothrough the left vertex of the long edge and the hanging node, plus a point itqueries halfway in between from the manifold. Because, as before, the pointthe manifold returns halfway along the left small edge is rarely exactly onthe quadratic curve describing the long edge, the quadratic short edge willtypically not coincide with the left half of the quadratic long edge, and thesame is true for the right short edge. In other words, again, the geometriesof the large cell and its smaller neighbors at hanging nodes do not touchsnuggly.
* This all begs two questions: first, does it matter, and second, could this befixed. Let us discuss these in the following:
*  [2.x.122]    [2.x.123] Does it matter? It is almost certainly true that this depends on the  equation you are solving. For example, it is known that solving the Euler  equations of gas dynamics on complex geometries requires highly accurate  boundary descriptions to ensure convergence of quantities that are measure  the flow close to the boundary. On the other hand, equations with elliptic  components (e.g., the Laplace or Stokes equations) are typically rather  forgiving of these issues: one does quadrature anyway to approximate  integrals, and further approximating the geometry may not do as much harm as  one could fear given that the volume of the overlaps or gaps at every  hanging node is only  [2.x.124]  even with a linear mapping and  [2.x.125]  for a mapping of degree  [2.x.126] . (You can see this by considering  that in 2d the gap/overlap is a triangle with base  [2.x.127]  and height  [2.x.128] ; in 3d, it is a pyramid-like structure with base area  [2.x.129]  and  height  [2.x.130] . Similar considerations apply for higher order mappings  where the height of the gaps/overlaps is  [2.x.131] .) In other words,  if you use a linear mapping with linear elements, the error in the volume  you integrate over is already at the same level as the integration error  using the usual Gauss quadrature. Of course, for higher order elements one  would have to choose matching mapping objects.
*   Another point of view on why it is probably not worth worrying too much  about the issue is that there is certainly no narrative in the community of  numerical analysts that these issues are a major concern one needs to watch  out for when using complex geometries. If it does not seem to be discussed  often among practitioners, if ever at all, then it is at least not something  people have identified as a common problem.
*   This issue is not dissimilar to having hanging nodes at curved boundaries  where the geometry description of the boundary typically pulls a hanging  node onto the boundary whereas the large edge remains straight, making the  adjacent small and large cells not match each other. Although this behavior  existed in deal.II since its beginning, 15 years before manifold  descriptions became available, it did not ever come up in mailing list  discussions or conversations with colleagues.
*    [2.x.132] Could it be fixed? In principle, yes, but it's a complicated  issue. Let's assume for the moment that we would only ever use the MappingQ1  class, i.e., linear mappings. In that case, whenever the triangulation class  requires a new vertex along an edge that would become a hanging node, it  would just take the mean value of the adjacent vertices [1.x.80], i.e., without asking the manifold description. This way, the  point lies on the long straight edge and the two short straight edges would  match the one long edge. Only when all adjacent cells have been refined and  the point is no longer a hanging node would we replace its coordinates by  coordinates we get by a manifold. This may be awkward to implement, but it  would certainly be possible.
*   The more complicated issue arises because people may want to use a higher  order MappingQ object. In that case, the Triangulation class may freely  choose the location of the hanging node (because the quadratic curve for the  long edge can be chosen in such a way that it goes through the hanging node)  but the MappingQ class, when determining the location of mid-edge points  must make sure that if the edge is one half of a long edge of a neighboring  coarser cell, then the midpoint cannot be obtained from the manifold but  must be chosen along the long quadratic edge. For cubic (and all other odd)  mappings, the matter is again a bit complicated because one typically  arranges the cubic edge to go through points 1/3 and 2/3 along the edge, and  thus necessarily through the hanging node, but this could probably be worked  out. In any case, even then, there are two problems with this:
* 

* 
* 

* 
* 
*  - When refining the triangulation, the Triangulation class can not know what    mapping will be used. In fact it is not uncommon for a triangulation to be    used differently in different contexts within the same program. If the    mapping used determines whether we can freely choose a point or not, how,    then, should the triangulation locate new vertices?
* 

* 
* 

* 
* 
*  - Mappings are purely local constructs: they only work on a cell in    isolation, and this is one of the important features of the finite element    method. Having to ask whether one of the vertices of an edge is a hanging    node requires querying the neighborhood of a cell; furthermore, such a    query does not just involve the 6 face neighbors of a cell in 3d, but may    require traversing a possibly very large number of other cells that    connect to an edge. Even if it can be done, one still needs to do    different things depending on how the neighborhood looks like, producing    code that is likely very complex, hard to maintain, and possibly slow.
*   Consequently, at least for the moment, none of these ideas are  implemented. This leads to the undesirable consequence of discontinuous  geometries, but, as discussed above, the effects of this do not appear to  pose problem in actual practice.
*  [2.x.133] 
* 

* [1.x.81][1.x.82] [2.x.134] 
* [0.x.1]