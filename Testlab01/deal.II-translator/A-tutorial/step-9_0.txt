[0.x.0]*
 [2.x.0] 
* This tutorial depends on  [2.x.1] .
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18]
* [1.x.19][1.x.20][1.x.21]
* 

* 
* In this example, our aims are the following: [2.x.2]    [2.x.3] solve the advection equation  [2.x.4] ;   [2.x.5] show how we can use multiple threads to get results quicker if we have a    multi-processor machine;   [2.x.6] develop a simple refinement criterion. [2.x.7] While the second aim is difficult to describe in general terms withoutreference to the code, we will discuss the other two aims in thefollowing. The use of multiple threads will then be detailed at therelevant places within the program. We will, however, follow thegeneral discussion of the WorkStream approach detailed in the [2.x.8]  "Parallel computing with multiple processors accessing shared memory"documentation module.
* 

* [1.x.22][1.x.23]
* 

* In the present example program, we want to numerically approximate thesolution of the advection equation[1.x.24]where  [2.x.9]  is a vector field that describes the advection direction andspeed (which may be dependent on the space variables if [2.x.10] ),  [2.x.11]  is a sourcefunction, and  [2.x.12]  is the solution. The physical process that thisequation describes is that of a given flow field  [2.x.13] , with whichanother substance is transported, the density or concentration ofwhich is given by  [2.x.14] . The equation does not contain diffusion of thissecond species within its carrier substance, but there are sourceterms.
* It is obvious that at the inflow, the above equation needs to beaugmented by boundary conditions:[1.x.25]where  [2.x.15]  describes the inflow portion of the boundary and isformally defined by[1.x.26]and  [2.x.16]  being the outward normal to the domain at point [2.x.17] . This definition is quite intuitive, sinceas  [2.x.18]  points outward, the scalar product with  [2.x.19]  can onlybe negative if the transport direction  [2.x.20]  points inward, i.e. atthe inflow boundary. The mathematical theory states that we must notpose any boundary condition on the outflow part of the boundary.
* Unfortunately, the equation stated above cannot be solved in a stable way usingthe standard finite element method. The problem is thatsolutions to this equation possess insufficient regularityperpendicular to the transport direction: while they are smooth alongthe streamlines defined by the "wind field" [2.x.21] , they may be discontinuous perpendicular to thisdirection. This is easy to understand: what the equation  [2.x.22]  means is in essence that the [1.x.27]. But the equation has no implicationsfor the derivatives in the perpendicular direction, and consequentlyif  [2.x.23]  is discontinuous at a point on the inflow boundary, then thisdiscontinuity will simply be transported along the streamline of thewind field that starts at this boundary point.These discontinuities lead to numerical instabilities thatmake a stable solution by a standard continuous finite element discretizationimpossible.
* A standard approach to address this difficulty is the  [2.x.24] "streamline-upwindPetrov-Galerkin" [2.x.25]  (SUPG) method, sometimes also called thestreamline diffusion method. A good explanation of the method can befound in  [2.x.26]  . Formally, this method replaces the stepin which we derive the the weak form of the differential equation fromthe strong form: Instead of multiplying the equation by a testfunction  [2.x.27]  and integrating over the domain, we instead multiplyby  [2.x.28] , where  [2.x.29]  is aparameter that is chosen in the range of the (local) mesh width  [2.x.30] ;good results are usually obtained by setting  [2.x.31] .(Why this is called "streamline diffusion" will be explained below;for the moment, let us simply take for granted that this is how wederive a stable discrete formulation.)The value for  [2.x.32]  here is small enoughthat we do not introduce excessive diffusion, but large enough that theresulting problem is well-posed.
* Using the test functions as defined above, an initial weak form of theproblem would ask for finding a function  [2.x.33]  so that for all testfunctions  [2.x.34]  we have[1.x.28]However, we would like to include inflow boundary conditions  [2.x.35] weakly into this problem, and this can be done by requiring that inaddition to the equation above we also have[1.x.29]for all test functions  [2.x.36]  that live on the boundary and that arefrom a suitable test space. It turns out that a suitable space of testfunctions happens to be  [2.x.37]  times the traces ofthe functions  [2.x.38]  in the test space we already use for thedifferential equation in the domain. Thus, we require that for alltest functions  [2.x.39]  we have[1.x.30]Without attempting a justification (see again the literature on the finiteelement method in general, and the streamline diffusion method inparticular), we can combine the equations for the differentialequation and the boundary values in the followingweak formulation ofour stabilized problem: find a discrete function  [2.x.40]  such thatfor all discrete test functions  [2.x.41]  there holds[1.x.31]
* 

* One would think that this leads to a system matrixto be inverted of the form[1.x.32]with basis functions  [2.x.42] .  However, this is apitfall that happens to every numerical analyst at least once(including the author): we have here expanded the solution [2.x.43] , but if we do so, we will have to solve theproblem[1.x.33]where  [2.x.44]  is the vector of expansion coefficients, i.e., we have tosolve the transpose problem of what we might have expected naively.
* This is a point we made in the introduction of  [2.x.45] . There, we argued thatto avoid this very kind of problem, one should get in the habit of alwaysmultiplying with test functions [1.x.34] instead of from the rightto obtain the correct matrix right away. In order to obtain the formof the linear system that we need, it is therefore best to rewrite the weakformulation to[1.x.35]and then to obtain[1.x.36]as system matrix. We will assemble this matrix in the program.
* 

* [1.x.37][1.x.38]
* 

* Looking at the bilinear form mentioned above, we see that the discretesolution has to satisfy an equation of which the left hand side inweak form has a domain term of the kind[1.x.39]or if we split this up, the form[1.x.40]If we wanted to see what strong form of the equation that wouldcorrespond to, we need to integrate the second term. This yields thefollowing formulation, where for simplicity we'll ignore boundaryterms for now:[1.x.41]Let us assume for a moment that the wind field  [2.x.46]  isdivergence-free, i.e., that  [2.x.47] . Then applyingthe product rule to the derivative of the term in square brackets onthe right and using the divergence-freeness will give us the following:[1.x.42]That means that the strong form of the equation would be of the sort[1.x.43]What is important to recognize now is that  [2.x.48]  is the [2.x.49] derivative in direction  [2.x.50]  [2.x.51] . So, if we denote this by [2.x.52]  (in the same way aswe often write  [2.x.53]  forthe derivative in normal direction at the boundary), then the strongform of the equation is[1.x.44]In other words, the unusual choice of test function is equivalent tothe addition of term to the strong form that corresponds to a secondorder (i.e., diffusion) differential operator in the direction of the windfield  [2.x.54] , i.e., in "streamline direction". A fuller account wouldalso have to explore the effect of the test function on boundaryvalues and why it is necessary to also use the same test function forthe right hand side, but the discussion above might make clear wherethe name "streamline diffusion" for the method originates from.
* 

* [1.x.45][1.x.46]
* 

* A "Galerkin method" is one where one obtains the weak formulation bymultiplying the equation by a test function  [2.x.55]  (and then integratingover  [2.x.56] ) where the functions  [2.x.57]  are from the same space as thesolution  [2.x.58]  (though possibly with different boundary values). Butthis is not strictly necessary: One could also imagine choosing thetest functions from a different set of functions, as long as thatdifferent set has "as many dimensions" as the original set offunctions so that we end up with as many independent equations asthere are degrees of freedom (where all of this needs to beappropriately defined in the infinite-dimensional case). Methods thatmake use of this possibility (i.e., choose the set of test functionsdifferently than the set of solutions) are called "Petrov-Galerkin"methods. In the current case, the test functions all have the form [2.x.59]  where  [2.x.60]  is from the set of solutions.
* 

* [1.x.47][1.x.48]
* 

* [Upwind methods](https://en.wikipedia.org/wiki/Upwind_scheme) have along history in the derivation of stabilized schemes for advectionequations. Generally, the idea is that instead of looking at afunction "here", we look at it a small distance further "upstream" or "upwind",i.e., where the information "here" originally came from. This mightsuggest not considering  [2.x.61] , butsomething like  [2.x.62] . Or, equivalently uponintegration, we could evaluate  [2.x.63]  and instead consider  [2.x.64] a bit downstream:  [2.x.65] . This would be cumbersomefor a variety of reasons: First, we would have to define what  [2.x.66] should be if  [2.x.67]  happens to be outside [2.x.68] ; second, computing integrals numerically would be much moreawkward since we no longer evaluate  [2.x.69]  and  [2.x.70]  at the same quadraturepoints. But since we assume that  [2.x.71]  is small, we can do a Taylorexpansion:[1.x.49]This form for the test function should by now look familiar.
* 

* [1.x.50][1.x.51]
* 

* As the resulting matrix is no longer symmetric positive definite, we cannotuse the usual Conjugate Gradient method (implemented in theSolverCG class) to solve the system. Instead, we use the GMRES (GeneralizedMinimum RESidual) method (implemented in SolverGMRES) that is suitablefor problems of the kind we have here.
* 

* [1.x.52][1.x.53]
* 

* For the problem which we will solve in this tutorial program, we usethe following domain and functions (in  [2.x.72]  space dimensions):[1.x.54]
* For  [2.x.73] , we extend  [2.x.74]  and  [2.x.75]  by simply duplicatingthe last of the components shown above one more time.
* With all of this, the following comments are in order: [2.x.76]  [2.x.77]  The advection field  [2.x.78]  transports the solution roughly indiagonal direction from lower left to upper right, but with a wigglestructure superimposed. [2.x.79]  The right hand side adds to the field generated by the inflowboundary conditions a blob in the lower left corner, which is thentransported along. [2.x.80]  The inflow boundary conditions impose a weighted sinusoidalstructure that is transported along with the flow field. Since [2.x.81]  on the boundary, the weighting term never gets very large. [2.x.82] 
* 

* [1.x.55][1.x.56]
* 

* In all previous examples with adaptive refinement, we have used anerror estimator first developed by Kelly et al., which assigns to eachcell  [2.x.83]  the following indicator:[1.x.57]where  [2.x.84]  denotes the jump of the normal derivativesacross a face  [2.x.85]  of the cell  [2.x.86] . It can beshown that this error indicator uses a discrete analogue of the secondderivatives, weighted by a power of the cell size that is adjusted tothe linear elements assumed to be in use here:[1.x.58]which itself is related to the error size in the energy norm.
* The problem with this error indicator in the present case is that itassumes that the exact solution possesses second derivatives. This isalready questionable for solutions to Laplace's problem in some cases,although there most problems allow solutions in  [2.x.87] . If solutionsare only in  [2.x.88] , then the second derivatives would be singular insome parts (of lower dimension) of the domain and the error indicatorswould not reduce there under mesh refinement. Thus, the algorithmwould continuously refine the cells around these parts, i.e. wouldrefine into points or lines (in 2d).
* However, for the present case, solutions are usually not even in  [2.x.89] (and this missing regularity is not the exceptional case as forLaplace's equation), so the error indicator described above is notreally applicable. We will thus develop an indicator that is based ona discrete approximation of the gradient. Although the gradient oftendoes not exist, this is the only criterion available to us, at leastas long as we use continuous elements as in the presentexample. To start with, we note that given two cells  [2.x.90] ,  [2.x.91]  ofwhich the centers are connected by the vector  [2.x.92] , we canapproximate the directional derivative of a function  [2.x.93]  as follows:[1.x.59]where  [2.x.94]  and  [2.x.95]  denote  [2.x.96]  evaluated at the centers of therespective cells. We now multiply the above approximation by [2.x.97]  and sum over all neighbors  [2.x.98]  of  [2.x.99] :[1.x.60]If the vectors  [2.x.100]  connecting  [2.x.101]  with its neighbors spanthe whole space (i.e. roughly:  [2.x.102]  has neighbors in all directions),then the term in parentheses in the left hand side expression forms aregular matrix, which we can invert to obtain an approximation of thegradient of  [2.x.103]  on  [2.x.104] :[1.x.61]We will denote the approximation on the right hand side by [2.x.105] , and we will use the following quantity as refinementcriterion:[1.x.62]which is inspired by the following (not rigorous) argument:[1.x.63]
* 
* 

*  [1.x.64] [1.x.65]
*  Just as in previous examples, we have to include several files of which the meaning has already been discussed:
* 

* 
* [1.x.66]
* 
*  The following two files provide classes and information for multithreaded programs. In the first one, the classes and functions are declared which we need to do assembly in parallel (i.e. the  [2.x.106]  namespace). The second file has a class MultithreadInfo which can be used to query the number of processors in your system, which is often useful when deciding how many threads to start in parallel.
* 

* 
* [1.x.67]
* 
*  The next new include file declares a base class  [2.x.107]  not unlike the  [2.x.108]  class, but with the difference that  [2.x.109]  returns a Tensor instead of a scalar.
* 

* 
* [1.x.68]
* 
*  This is C++, as we want to write some output to disk:
* 

* 
* [1.x.69]
* 
*  The last step is as in previous programs:
* 

* 
* [1.x.70]
* 
*   [1.x.71]  [1.x.72]
* 

* 
*  Next we declare a class that describes the advection field. This, of course, is a vector field with as many components as there are space dimensions. One could now use a class derived from the  [2.x.110]  base class, as we have done for boundary values and coefficients in previous examples, but there is another possibility in the library, namely a base class that describes tensor valued functions. This is more convenient than overriding  [2.x.111]  with a method that knows about multiple function components: at the end of the day we need a Tensor, so we may as well just use a class that returns a Tensor.
* 

* 
* [1.x.73]
* 
*  In previous examples, we have used assertions that throw exceptions in several places. However, we have never seen how such exceptions are declared. This can be done as follows:
* 

* 
* [1.x.74]
* 
*  The syntax may look a little strange, but is reasonable. The format is basically as follows: use the name of one of the macros  [2.x.112]  denotes the number of additional parameters which the exception object shall take. In this case, as we want to throw the exception when the sizes of two vectors differ, we need two arguments, so we use  [2.x.113] . The first parameter then describes the name of the exception, while the following declare the data types of the parameters. The last argument is a sequence of output directives that will be piped into the  [2.x.114]  object, thus the strange format with the leading  [2.x.115]  operator and the like. Note that we can access the parameters which are passed to the exception upon construction (i.e. within the  [2.x.116]  call) by using the names  [2.x.117] , where  [2.x.118]  is the number of arguments as defined by the use of the respective macro  [2.x.119] .     
*   To learn how the preprocessor expands this macro into actual code, please refer to the documentation of the exception classes. In brief, this macro call declares and defines a class  [2.x.120]  inheriting from ExceptionBase which implements all necessary error output functions.
* 

* 
* [1.x.75]
* 
*  The following two functions implement the interface described above. The first simply implements the function as described in the introduction, while the second uses the same trick to avoid calling a virtual function as has already been introduced in the previous example program. Note the check for the right sizes of the arguments in the second function, which should always be present in such functions; it is our experience that many if not most programming errors result from incorrectly initialized arrays, incompatible parameters to functions and the like; using assertion as in this case can eliminate many of these problems.
* 

* 
* [1.x.76]
* 
*  Besides the advection field, we need two functions describing the source terms ( [2.x.121] ) and the boundary values. As described in the introduction, the source is a constant function in the vicinity of a source point, which we denote by the constant static variable  [2.x.122] . We set the values of this center using the same template tricks as we have shown in the  [2.x.123]  example program. The rest is simple and has been shown previously.
* 

* 
* [1.x.77]
* 
*  The only new thing here is that we check for the value of the  [2.x.124]  parameter. As this is a scalar function, it is obvious that it only makes sense if the desired component has the index zero, so we assert that this is indeed the case.  [2.x.125]  is a global predefined exception (probably the one most often used, we therefore made it global instead of local to some class), that takes three parameters: the index that is outside the allowed range, the first element of the valid range and the one past the last (i.e. again the half-open interval so often used in the C++ standard library):
* 

* 
* [1.x.78]
* 
*  Finally for the boundary values, which is just another class derived from the  [2.x.126]  base class:
* 

* 
* [1.x.79]
* 
*   [1.x.80]  [1.x.81]
* 

* 
*  Here comes the main class of this program. It is very much like the main classes of previous examples, so we again only comment on the differences.
* 

* 
* [1.x.82]
* 
*  The next set of functions will be used to assemble the matrix. However, unlike in the previous examples, the  [2.x.127]  function will not do the work itself, but rather will delegate the actual assembly to helper functions  [2.x.128]  and  [2.x.129] . The rationale is that matrix assembly can be parallelized quite well, as the computation of the local contributions on each cell is entirely independent of other cells, and we only have to synchronize when we add the contribution of a cell to the global matrix.     
*   The strategy for parallelization we choose here is one of the possibilities mentioned in detail in the  [2.x.130]  module in the documentation. Specifically, we will use the WorkStream approach discussed there. Since there is so much documentation in this module, we will not repeat the rationale for the design choices here (for example, if you read through the module mentioned above, you will understand what the purpose of the  [2.x.131]  and  [2.x.132]  structures is). Rather, we will only discuss the specific implementation.     
*   If you read the page mentioned above, you will find that in order to parallelize assembly, we need two data structures
* 
*  -  one that corresponds to data that we need during local integration ("scratch data", i.e., things we only need as temporary storage), and one that carries information from the local integration to the function that then adds the local contributions to the corresponding elements of the global matrix. The former of these typically contains the FEValues and FEFaceValues objects, whereas the latter has the local matrix, local right hand side, and information about which degrees of freedom live on the cell for which we are assembling a local contribution. With this information, the following should be relatively self-explanatory:
* 

* 
* [1.x.83]
* 
*  FEValues and FEFaceValues are expensive objects to set up, so we include them in the scratch object so that as much data is reused between cells as possible.
* 

* 
* [1.x.84]
* 
*  We also store a few vectors that we will populate with values on each cell. Setting these objects up is, in the usual case, cheap; however, they require memory allocations, which can be expensive in multithreaded applications. Hence we keep them here so that computations on a cell do not require new allocations.
* 

* 
* [1.x.85]
* 
*  Finally, we need objects that describe the problem's data:
* 

* 
* [1.x.86]
* 
*  The following functions again are the same as they were in previous examples, as are the subsequent variables:
* 

* 
* [1.x.87]
* 
*   [1.x.88]  [1.x.89]
* 

* 
*  Now, finally, here comes the class that will compute the difference approximation of the gradient on each cell and weighs that with a power of the mesh size, as described in the introduction. This class is a simple version of the  [2.x.133]  class in the library, that uses similar techniques to obtain finite difference approximations of the gradient of a finite element field, or of higher derivatives.   
*   The class has one public static function  [2.x.134]  that is called to compute a vector of error indicators, and a few private functions that do the actual work on all active cells. As in other parts of the library, we follow an informal convention to use vectors of floats for error indicators rather than the common vectors of doubles, as the additional accuracy is not necessary for estimated values.   
*   In addition to these two functions, the class declares two exceptions which are raised when a cell has no neighbors in each of the space directions (in which case the matrix described in the introduction would be singular and can't be inverted), while the other one is used in the more common case of invalid parameters to a function, namely a vector of wrong size.   
*   Two other comments: first, the class has no non-static member functions or variables, so this is not really a class, but rather serves the purpose of a  [2.x.135]  in C++. The reason that we chose a class over a namespace is that this way we can declare functions that are private. This can be done with namespaces as well, if one declares some functions in header files in the namespace and implements these and other functions in the implementation file. The functions not declared in the header file are still in the namespace but are not callable from outside. However, as we have only one file here, it is not possible to hide functions in the present case.   
*   The second comment is that the dimension template parameter is attached to the function rather than to the class itself. This way, you don't have to specify the template parameter yourself as in most other cases, but the compiler can figure its value out itself from the dimension of the DoFHandler object that one passes as first argument.   
*   Before jumping into the fray with the implementation, let us also comment on the parallelization strategy. We have already introduced the necessary framework for using the WorkStream concept in the declaration of the main class of this program above. We will use it again here. In the current context, this means that we have to define  [2.x.136]   [2.x.137] classes for scratch and copy objects, [2.x.138]   [2.x.139] a function that does the local computation on one cell, and [2.x.140]   [2.x.141] a function that copies the local result into a global object. [2.x.142]   [2.x.143]  Given this general framework, we will, however, deviate from it a bit. In particular, WorkStream was generally invented for cases where each local computation on a cell [1.x.90] to a global object
* 
*  -  for example, when assembling linear systems where we add local contributions into a global matrix and right hand side. WorkStream is designed to handle the potential conflict of multiple threads trying to do this addition at the same time, and consequently has to provide for some way to ensure that only one thread gets to do this at a time. Here, however, the situation is slightly different: we compute contributions from every cell individually, but then all we need to do is put them into an element of an output vector that is unique to each cell. Consequently, there is no risk that the write operations from two cells might conflict, and the elaborate machinery of WorkStream to avoid conflicting writes is not necessary. Consequently, what we will do is this: We still need a scratch object that holds, for example, the FEValues object. However, we only create a fake, empty copy data structure. Likewise, we do need the function that computes local contributions, but since it can already put the result into its final location, we do not need a copy-local-to-global function and will instead give the  [2.x.144]  function an empty function object
* 
*  -  the equivalent to a NULL function pointer.
* 

* 
* [1.x.91]
* 
*   [1.x.92]  [1.x.93]
* 

* 
*  
*   Now for the implementation of the main class. Constructor, destructor and the function  [2.x.145]  follow the same pattern that was used previously, so we need not comment on these three function:
* 

* 
* [1.x.94]
* 
*  In the following function, the matrix and right hand side are assembled. As stated in the documentation of the main class above, it does not do this itself, but rather delegates to the function following next, utilizing the WorkStream concept discussed in  [2.x.146]  .   
*   If you have looked through the  [2.x.147]  module, you will have seen that assembling in parallel does not take an incredible amount of extra code as long as you diligently describe what the scratch and copy data objects are, and if you define suitable functions for the local assembly and the copy operation from local contributions to global objects. This done, the following will do all the heavy lifting to get these operations done on multiple threads on as many cores as you have in your system:
* 

* 
* [1.x.95]
* 
*  As already mentioned above, we need to have scratch objects for the parallel computation of local contributions. These objects contain FEValues and FEFaceValues objects (as well as some arrays), and so we will need to have constructors and copy constructors that allow us to create them. For the cell terms we need the values and gradients of the shape functions, the quadrature points in order to determine the source density and the advection field at a given point, and the weights of the quadrature points times the determinant of the Jacobian at these points. In contrast, for the boundary integrals, we don't need the gradients, but rather the normal vectors to the cells. This determines which update flags we will have to pass to the constructors of the members of the class:
* 

* 
* [1.x.96]
* 
*  Now, this is the function that does the actual work. It is not very different from the  [2.x.148]  functions of previous example programs, so we will again only comment on the differences. The mathematical stuff closely follows what we have said in the introduction.   
*   There are a number of points worth mentioning here, though. The first one is that we have moved the FEValues and FEFaceValues objects into the ScratchData object. We have done so because the alternative would have been to simply create one every time we get into this function
* 
*  -  i.e., on every cell. It now turns out that the FEValues classes were written with the explicit goal of moving everything that remains the same from cell to cell into the construction of the object, and only do as little work as possible in  [2.x.149]  whenever we move to a new cell. What this means is that it would be very expensive to create a new object of this kind in this function as we would have to do it for every cell
* 
*  -  exactly the thing we wanted to avoid with the FEValues class. Instead, what we do is create it only once (or a small number of times) in the scratch objects and then re-use it as often as we can.   
*   This begs the question of whether there are other objects we create in this function whose creation is expensive compared to its use. Indeed, at the top of the function, we declare all sorts of objects. The  [2.x.150] ,  [2.x.151]  do not cost much to create, so there is no harm here. However, allocating memory in creating the  [2.x.152]  and similar variables below typically costs a significant amount of time, compared to just accessing the (temporary) values we store in them. Consequently, these would be candidates for moving into the  [2.x.153]  class. We will leave this as an exercise.
* 

* 
* [1.x.97]
* 
*  We define some abbreviations to avoid unnecessarily long lines:
* 

* 
* [1.x.98]
* 
*  We declare cell matrix and cell right hand side...
* 

* 
* [1.x.99]
* 
*  ... an array to hold the global indices of the degrees of freedom of the cell on which we are presently working...
* 

* 
* [1.x.100]
* 
*  ... then initialize the  [2.x.154]  object...
* 

* 
* [1.x.101]
* 
*  ... obtain the values of right hand side and advection directions at the quadrature points...
* 

* 
* [1.x.102]
* 
*  ... set the value of the streamline diffusion parameter as described in the introduction...
* 

* 
* [1.x.103]
* 
*  ... and assemble the local contributions to the system matrix and right hand side as also discussed above:
* 

* 
* [1.x.104]
* 
*  Alias the AssemblyScratchData object to keep the lines from getting too long:
* 

* 
* [1.x.105]
* 
*  Besides the cell terms which we have built up now, the bilinear form of the present problem also contains terms on the boundary of the domain. Therefore, we have to check whether any of the faces of this cell are on the boundary of the domain, and if so assemble the contributions of this face as well. Of course, the bilinear form only contains contributions from the  [2.x.155]  part of the boundary, but to find out whether a certain part of a face of the present cell is part of the inflow boundary, we have to have information on the exact location of the quadrature points and on the direction of flow at this point; we obtain this information using the FEFaceValues object and only decide within the main loop whether a quadrature point is on the inflow boundary.
* 

* 
* [1.x.106]
* 
*  Ok, this face of the present cell is on the boundary of the domain. Just as for the usual FEValues object which we have used in previous examples and also above, we have to reinitialize the FEFaceValues object for the present face:
* 

* 
* [1.x.107]
* 
*  For the quadrature points at hand, we ask for the values of the inflow function and for the direction of flow:
* 

* 
* [1.x.108]
* 
*  Now loop over all quadrature points and see whether this face is on the inflow or outflow part of the boundary. The normal vector points out of the cell: since the face is at the boundary, the normal vector points out of the domain, so if the advection direction points into the domain, its scalar product with the normal vector must be negative (to see why this is true, consider the scalar product definition that uses a cosine):
* 

* 
* [1.x.109]
* 
*  If the face is part of the inflow boundary, then compute the contributions of this face to the global matrix and right hand side, using the values obtained from the FEFaceValues object and the formulae discussed in the introduction:
* 

* 
* [1.x.110]
* 
*  The final piece of information the copy routine needs is the global indices of the degrees of freedom on this cell, so we end by writing them to the local array:
* 

* 
* [1.x.111]
* 
*  The second function we needed to write was the one that copies the local contributions the previous function computed (and put into the AssemblyCopyData object) into the global matrix and right hand side vector objects. This is essentially what we always had as the last block of code when assembling something on every cell. The following should therefore be pretty obvious:
* 

* 
* [1.x.112]
* 
*  Here comes the linear solver routine. As the system is no longer symmetric positive definite as in all the previous examples, we cannot use the Conjugate Gradient method anymore. Rather, we use a solver that is more general and does not rely on any special properties of the matrix: the GMRES method. GMRES, like the conjugate gradient method, requires a decent preconditioner: we use a Jacobi preconditioner here, which works well enough for this problem.
* 

* 
* [1.x.113]
* 
*  The following function refines the grid according to the quantity described in the introduction. The respective computations are made in the class  [2.x.156] .
* 

* 
* [1.x.114]
* 
*  This function is similar to the one in step 6, but since we use a higher degree finite element we save the solution in a different way. Visualization programs like VisIt and Paraview typically only understand data that is associated with nodes: they cannot plot fifth-degree basis functions, which results in a very inaccurate picture of the solution we computed. To get around this we save multiple  [2.x.157] patches [2.x.158]  per cell: in 2D we save 64 bilinear `cells' to the VTU file for each cell, and in 3D we save 512. The end result is that the visualization program will use a piecewise linear interpolation of the cubic basis functions: this captures the solution detail and, with most screen resolutions, looks smooth. We save the grid in a separate step with no extra patches so that we have a visual representation of the cell faces.   
*   Version 9.1 of deal.II gained the ability to write higher degree polynomials (i.e., write piecewise bicubic visualization data for our piecewise bicubic solution) VTK and VTU output: however, not all recent versions of ParaView and VisIt (as of 2018) can read this format, so we use the older, more general (but less efficient) approach here.
* 

* 
* [1.x.115]
* 
*  VTU output can be expensive, both to compute and to write to disk. Here we ask ZLib, a compression library, to compress the data in a way that maximizes throughput.
* 

* 
* [1.x.116]
* 
*  ... as is the main loop (setup
* 
*  -  solve
* 
*  -  refine), aside from the number of cycles and the initial grid:
* 

* 
* [1.x.117]
* 
*   [1.x.118]  [1.x.119]
* 

* 
*  Now for the implementation of the  [2.x.159]  class. Let us start by defining constructors for the  [2.x.160]  class used by the  [2.x.161]  function:
* 

* 
* [1.x.120]
* 
*  We allocate a vector to hold iterators to all active neighbors of a cell. We reserve the maximal number of active neighbors in order to avoid later reallocations. Note how this maximal number of active neighbors is computed here.
* 

* 
* [1.x.121]
* 
*  Next comes the implementation of the  [2.x.162]  class. The first function does not much except for delegating work to the other function, but there is a bit of setup at the top.   
*   Before starting with the work, we check that the vector into which the results are written has the right size. Programming mistakes in which one forgets to size arguments correctly at the calling site are quite common. Because the resulting damage from not catching such errors is often subtle (e.g., corruption of data somewhere in memory, or non-reproducible results), it is well worth the effort to check for such things.
* 

* 
* [1.x.122]
* 
*  Here comes the function that estimates the local error by computing the finite difference approximation of the gradient. The function first computes the list of active neighbors of the present cell and then computes the quantities described in the introduction for each of the neighbors. The reason for this order is that it is not a one-liner to find a given neighbor with locally refined meshes. In principle, an optimized implementation would find neighbors and the quantities depending on them in one step, rather than first building a list of neighbors and in a second step their contributions but we will gladly leave this as an exercise. As discussed before, the worker function passed to  [2.x.163]  works on "scratch" objects that keep all temporary objects. This way, we do not need to create and initialize objects that are expensive to initialize within the function that does the work every time it is called for a given cell. Such an argument is passed as the second argument. The third argument would be a "copy-data" object (see  [2.x.164]  for more information) but we do not actually use any of these here. Since  [2.x.165]  insists on passing three arguments, we declare this function with three arguments, but simply ignore the last one.   
*   (This is unsatisfactory from an aesthetic perspective. It can be avoided by using an anonymous (lambda) function. If you allow, let us here show how. First, assume that we had declared this function to only take two arguments by omitting the unused last one. Now,  [2.x.166]  still wants to call this function with three arguments, so we need to find a way to "forget" the third argument in the call. Simply passing  [2.x.167]  the pointer to the function as we do above will not do this
* 
*  -  the compiler will complain that a function declared to have two arguments is called with three arguments. However, we can do this by passing the following as the third argument to  [2.x.168]   [2.x.169]  This is not much better than the solution implemented below: either the routine itself must take three arguments or it must be wrapped by something that takes three arguments. We don't use this since adding the unused argument at the beginning is simpler.   
*   Now for the details:
* 

* 
* [1.x.124]
* 
*  We need space for the tensor  [2.x.170] , which is the sum of outer products of the y-vectors.
* 

* 
* [1.x.125]
* 
*  First initialize the  [2.x.171]  object, as well as the  [2.x.172]  tensor:
* 

* 
* [1.x.126]
* 
*  Now, before we go on, we first compute a list of all active neighbors of the present cell. We do so by first looping over all faces and see whether the neighbor there is active, which would be the case if it is on the same level as the present cell or one level coarser (note that a neighbor can only be once coarser than the present cell, as we only allow a maximal difference of one refinement over a face in deal.II). Alternatively, the neighbor could be on the same level and be further refined; then we have to find which of its children are next to the present cell and select these (note that if a child of a neighbor of an active cell that is next to this active cell, needs necessarily be active itself, due to the one-refinement rule cited above).     
*   Things are slightly different in one space dimension, as there the one-refinement rule does not exist: neighboring active cells may differ in as many refinement levels as they like. In this case, the computation becomes a little more difficult, but we will explain this below.     
*   Before starting the loop over all neighbors of the present cell, we have to clear the array storing the iterators to the active neighbors, of course.
* 

* 
* [1.x.127]
* 
*  First define an abbreviation for the iterator to the face and the neighbor
* 

* 
* [1.x.128]
* 
*  Then check whether the neighbor is active. If it is, then it is on the same level or one level coarser (if we are not in 1D), and we are interested in it in any case.
* 

* 
* [1.x.129]
* 
*  If the neighbor is not active, then check its children.
* 

* 
* [1.x.130]
* 
*  To find the child of the neighbor which bounds to the present cell, successively go to its right child if we are left of the present cell (n==0), or go to the left child if we are on the right (n==1), until we find an active cell.
* 

* 
* [1.x.131]
* 
*  As this used some non-trivial geometrical intuition, we might want to check whether we did it right, i.e., check whether the neighbor of the cell we found is indeed the cell we are presently working on. Checks like this are often useful and have frequently uncovered errors both in algorithms like the line above (where it is simple to involuntarily exchange  [2.x.173]  or the like) and in the library (the assumptions underlying the algorithm above could either be wrong, wrongly documented, or are violated due to an error in the library). One could in principle remove such checks after the program works for some time, but it might be a good things to leave it in anyway to check for changes in the library or in the algorithm above.                   
*   Note that if this check fails, then this is certainly an error that is irrecoverable and probably qualifies as an internal error. We therefore use a predefined exception class to throw here.
* 

* 
* [1.x.132]
* 
*  If the check succeeded, we push the active neighbor we just found to the stack we keep:
* 

* 
* [1.x.133]
* 
*  If we are not in 1d, we collect all neighbor children `behind' the subfaces of the current face and move on:
* 

* 
* [1.x.134]
* 
*  OK, now that we have all the neighbors, lets start the computation on each of them. First we do some preliminaries: find out about the center of the present cell and the solution at this point. The latter is obtained as a vector of function values at the quadrature points, of which there are only one, of course. Likewise, the position of the center is the position of the first (and only) quadrature point in real space.
* 

* 
* [1.x.135]
* 
*  Now loop over all active neighbors and collect the data we need.
* 

* 
* [1.x.136]
* 
*  Then get the center of the neighbor cell and the value of the finite element function at that point. Note that for this information we have to reinitialize the  [2.x.174]  object for the neighbor cell.
* 

* 
* [1.x.137]
* 
*  Compute the vector  [2.x.175]  connecting the centers of the two cells. Note that as opposed to the introduction, we denote by  [2.x.176]  the normalized difference vector, as this is the quantity used everywhere in the computations.
* 

* 
* [1.x.138]
* 
*  Then add up the contribution of this cell to the Y matrix...
* 

* 
* [1.x.139]
* 
*  ... and update the sum of difference quotients:
* 

* 
* [1.x.140]
* 
*  If now, after collecting all the information from the neighbors, we can determine an approximation of the gradient for the present cell, then we need to have passed over vectors  [2.x.177]  which span the whole space, otherwise we would not have all components of the gradient. This is indicated by the invertibility of the matrix.     
*   If the matrix is not invertible, then the present cell had an insufficient number of active neighbors. In contrast to all previous cases (where we raised exceptions) this is, however, not a programming error: it is a runtime error that can happen in optimized mode even if it ran well in debug mode, so it is reasonable to try to catch this error also in optimized mode. For this case, there is the  [2.x.178]  macro: it checks the condition like the  [2.x.179]  macro, but not only in debug mode; it then outputs an error message, but instead of aborting the program as in the case of the  [2.x.180]  macro, the exception is thrown using the  [2.x.181]  command of C++. This way, one has the possibility to catch this error and take reasonable counter actions. One such measure would be to refine the grid globally, as the case of insufficient directions can not occur if every cell of the initial grid has been refined at least once.
* 

* 
* [1.x.141]
* 
*  If, on the other hand, the matrix is invertible, then invert it, multiply the other quantity with it, and compute the estimated error using this quantity and the correct powers of the mesh width:
* 

* 
* [1.x.142]
* 
*  The last part of this function is the one where we write into the element of the output vector what we have just computed. The address of this vector has been stored in the scratch data object, and all we have to do is know how to get at the correct element inside this vector
* 
*  -  but we can ask the cell we're on the how-manyth active cell it is for this:
* 

* 
* [1.x.143]
* 
*   [1.x.144]  [1.x.145]
* 

* 
*  The  [2.x.182]  function is similar to the previous examples. The primary difference is that we use MultithreadInfo to set the maximum number of threads (see the documentation module  [2.x.183]  "Parallel computing with multiple processors accessing shared memory" for more information). The number of threads used is the minimum of the environment variable DEAL_II_NUM_THREADS and the parameter of  [2.x.184] . If no value is given to  [2.x.185] , the default value from the Intel Threading Building Blocks (TBB) library is used. If the call to  [2.x.186]  is omitted, the number of threads will be chosen by TBB independently of DEAL_II_NUM_THREADS.
* 

* 
* [1.x.146]
* [1.x.147][1.x.148]
* 

* 
* The results of this program are not particularly spectacular. Theyconsist of the console output, some grid files, and the solution oneach of these grids. First for the console output:
* [1.x.149]
* 
* Quite a number of cells are used on the finest level to resolve the features ofthe solution. Here are the fourth and tenth grids: [2.x.187] and the fourth and tenth solutions: [2.x.188] and both the grid and solution zoomed in: [2.x.189] 
* The solution is created by that part that is transported along the wigglyadvection field from the left and lower boundaries to the top right, and thepart that is created by the source in the lower left corner, and the results ofwhich are also transported along. The grid shown above is well-adapted toresolve these features. The comparison between plots shows that, even though weare using a high-order approximation, we still need adaptive mesh refinement tofully resolve the wiggles.
* 

* [1.x.150][1.x.151] [2.x.190] 
* [0.x.1]