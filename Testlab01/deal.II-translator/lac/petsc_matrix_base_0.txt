[0.x.0]*
     This class acts as an iterator walking over the elements of PETSc     matrices. Since PETSc offers a uniform interface for all types of     matrices, this iterator can be used to access both sparse and full     matrices.         Note that PETSc does not give any guarantees as to the order of     elements within each row. Note also that accessing the elements of a     full matrix surprisingly only shows the nonzero elements of the matrix,     not all elements.        
*  [2.x.0]     
* [0.x.1]*
       Accessor class for iterators      
* [0.x.2]*
         Declare type for container size.        
* [0.x.3]*
         Constructor. Since we use accessors only for read access, a const         matrix pointer is sufficient.        
* [0.x.4]*
         Row number of the element represented by this object.        
* [0.x.5]*
         Index in row of the element represented by this object.        
* [0.x.6]*
         Column number of the element represented by this object.        
* [0.x.7]*
         Value of this matrix entry.        
* [0.x.8]*
         Exception        
* [0.x.9]*
         Exception        
* [0.x.10]*
         The matrix accessed.        
* [0.x.11]*
         Current row number.        
* [0.x.12]*
         Current index in row.        
* [0.x.13]*
         Cache where we store the column indices of the present row. This is         necessary, since PETSc makes access to the elements of its matrices         rather hard, and it is much more efficient to copy all column         entries of a row once when we enter it than repeatedly asking PETSc         for individual ones. This also makes some sense since it is likely         that we will access them sequentially anyway.                 In order to make copying of iterators/accessor of acceptable         performance, we keep a shared pointer to these entries so that more         than one accessor can access this data if necessary.        
* [0.x.14]*
         Similar cache for the values of this row.        
* [0.x.15]*
         Discard the old row caches (they may still be used by other         accessors) and generate new ones for the row pointed to presently         by this accessor.        
* [0.x.16]*
       Declare type for container size.      
* [0.x.17]*
       Constructor. Create an iterator into the matrix  [2.x.1]  for the       given row and the index within it.      
* [0.x.18]*
       Prefix increment.      
* [0.x.19]*
       Postfix increment.      
* [0.x.20]*
       Dereferencing operator.      
* [0.x.21]*
       Dereferencing operator.      
* [0.x.22]*
       Comparison. True, if both iterators point to the same matrix       position.      
* [0.x.23]*
       Inverse of <tt>==</tt>.      
* [0.x.24]*
       Comparison operator. Result is true if either the first row number is       smaller or if the row numbers are equal and the first index is       smaller.      
* [0.x.25]*
       Exception      
* [0.x.26]*
       Store an object of the accessor class.      
* [0.x.27]*
   Base class for all matrix classes that are implemented on top of the   PETSc matrix types. Since in PETSc all matrix types (i.e. sequential and   parallel, sparse, blocked, etc.)  are built by filling the contents of an   abstract object that is only referenced through a pointer of a type that   is independent of the actual matrix type, we can implement almost all   functionality of matrices in this base class. Derived classes will then   only have to provide the functionality to create one or the other kind of   matrix.     The interface of this class is modeled after the existing SparseMatrix   class in deal.II. It has almost the same member functions, and is often   exchangeable. However, since PETSc only supports a single scalar type   (either double, float, or a complex data type), it is not templated, and   only works with whatever your PETSc installation has defined the data   type PetscScalar to.     Note that PETSc only guarantees that operations do what you expect if the   functions  [2.x.2]  and  [2.x.3]  have been called   after matrix assembly. Therefore, you need to call    [2.x.4]  before you actually use the matrix. This also   calls  [2.x.5]  that compresses the storage format for sparse   matrices by discarding unused elements. PETSc allows to continue with   assembling the matrix after calls to these functions, but since there are   no more free entries available after that any more, it is better to only   call  [2.x.6]  once at the end of the assembly stage and   before the matrix is actively used.    
*  [2.x.7]   
*  [2.x.8]   
* [0.x.28]*
     Declare an alias for the iterator class.    
* [0.x.29]*
     Declare type for container size.    
* [0.x.30]*
     Declare an alias in analogy to all the other container classes.    
* [0.x.31]*
     Default constructor.    
* [0.x.32]*
     Copy constructor. It is deleted as copying this base class     without knowing the concrete kind of matrix stored may both     miss important details and be expensive if the matrix is large.    
* [0.x.33]*
     Copy operator. It is deleted as copying this base class     without knowing the concrete kind of matrix stored may both     miss important details and be expensive if the matrix is large.    
* [0.x.34]*
     Destructor. Made virtual so that one can use pointers to this class.    
* [0.x.35]*
     This operator assigns a scalar to a matrix. Since this does usually not     make much sense (should we set all matrix entries to this value? Only     the nonzero entries of the sparsity pattern?), this operation is only     allowed if the actual value to be assigned is zero. This operator only     exists to allow for the obvious notation <tt>matrix=0</tt>, which sets     all elements of the matrix to zero, but keeps the sparsity pattern     previously used.    
* [0.x.36]*
     Release all memory and return to a state just like after having called     the default constructor.    
* [0.x.37]*
     Set the element ([1.x.0]) to  [2.x.9]          If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds a new entry to the matrix if     it didn't exist before, very much in contrast to the SparseMatrix class     which throws an error if the entry does not exist. If <tt>value</tt> is     not a finite number an exception is thrown.    
* [0.x.38]*
     Set all elements given in a FullMatrix<double> into the sparse matrix     locations given by <tt>indices</tt>. In other words, this function     writes the elements in <tt>full_matrix</tt> into the calling matrix,     using the local-to-global indexing specified by <tt>indices</tt> for     both the rows and the columns of the matrix. This function assumes a     quadratic sparse matrix and a quadratic full_matrix, the usual     situation in FE calculations.         If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds some new entries to the matrix     if they didn't exist before, very much in contrast to the SparseMatrix     class which throws an error if the entry does not exist.         The optional parameter <tt>elide_zero_values</tt> can be used to     specify whether zero values should be inserted anyway or they should be     filtered away. The default value is <tt>false</tt>, i.e., even zero     values are inserted/replaced.    
* [0.x.39]*
     Same function as before, but now including the possibility to use     rectangular full_matrices and different local-to-global indexing on     rows and columns, respectively.    
* [0.x.40]*
     Set several elements in the specified row of the matrix with column     indices as given by <tt>col_indices</tt> to the respective value.         If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds some new entries to the matrix     if they didn't exist before, very much in contrast to the SparseMatrix     class which throws an error if the entry does not exist.         The optional parameter <tt>elide_zero_values</tt> can be used to     specify whether zero values should be inserted anyway or they should be     filtered away. The default value is <tt>false</tt>, i.e., even zero     values are inserted/replaced.    
* [0.x.41]*
     Set several elements to values given by <tt>values</tt> in a given row     in columns given by col_indices into the sparse matrix.         If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds some new entries to the matrix     if they didn't exist before, very much in contrast to the SparseMatrix     class which throws an error if the entry does not exist.         The optional parameter <tt>elide_zero_values</tt> can be used to     specify whether zero values should be inserted anyway or they should be     filtered away. The default value is <tt>false</tt>, i.e., even zero     values are inserted/replaced.    
* [0.x.42]*
     Add  [2.x.10]  to the element ([1.x.1]).         If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds a new entry to the matrix if     it didn't exist before, very much in contrast to the SparseMatrix class     which throws an error if the entry does not exist. If <tt>value</tt> is     not a finite number an exception is thrown.    
* [0.x.43]*
     Add all elements given in a FullMatrix<double> into sparse matrix     locations given by <tt>indices</tt>. In other words, this function adds     the elements in <tt>full_matrix</tt> to the respective entries in     calling matrix, using the local-to-global indexing specified by     <tt>indices</tt> for both the rows and the columns of the matrix. This     function assumes a quadratic sparse matrix and a quadratic full_matrix,     the usual situation in FE calculations.         If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds some new entries to the matrix     if they didn't exist before, very much in contrast to the SparseMatrix     class which throws an error if the entry does not exist.         The optional parameter <tt>elide_zero_values</tt> can be used to     specify whether zero values should be added anyway or these should be     filtered away and only non-zero data is added. The default value is     <tt>true</tt>, i.e., zero values won't be added into the matrix.    
* [0.x.44]*
     Same function as before, but now including the possibility to use     rectangular full_matrices and different local-to-global indexing on     rows and columns, respectively.    
* [0.x.45]*
     Set several elements in the specified row of the matrix with column     indices as given by <tt>col_indices</tt> to the respective value.         If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds some new entries to the matrix     if they didn't exist before, very much in contrast to the SparseMatrix     class which throws an error if the entry does not exist.         The optional parameter <tt>elide_zero_values</tt> can be used to     specify whether zero values should be added anyway or these should be     filtered away and only non-zero data is added. The default value is     <tt>true</tt>, i.e., zero values won't be added into the matrix.    
* [0.x.46]*
     Add an array of values given by <tt>values</tt> in the given global     matrix row at columns specified by col_indices in the sparse matrix.         If the present object (from a derived class of this one) happens to be     a sparse matrix, then this function adds some new entries to the matrix     if they didn't exist before, very much in contrast to the SparseMatrix     class which throws an error if the entry does not exist.         The optional parameter <tt>elide_zero_values</tt> can be used to     specify whether zero values should be added anyway or these should be     filtered away and only non-zero data is added. The default value is     <tt>true</tt>, i.e., zero values won't be added into the matrix.    
* [0.x.47]*
     Remove all elements from this <tt>row</tt> by setting them to zero. The     function does not modify the number of allocated nonzero entries, it     only sets some entries to zero. It may drop them from the sparsity     pattern, though (but retains the allocated memory in case new entries     are again added later).         This operation is used in eliminating constraints (e.g. due to hanging     nodes) and makes sure that we can write this modification to the matrix     without having to read entries (such as the locations of non-zero     elements) from it
* 
*  -  without this operation, removing constraints on     parallel matrices is a rather complicated procedure.         The second parameter can be used to set the diagonal entry of this row     to a value different from zero. The default is to set it to zero.    
* [0.x.48]*
     Same as clear_row(), except that it works on a number of rows at once.         The second parameter can be used to set the diagonal entries of all     cleared rows to something different from zero. Note that all of these     diagonal entries get the same value
* 
*  -  if you want different values for     the diagonal entries, you have to set them by hand.    
* [0.x.49]*
     PETSc matrices store their own sparsity patterns. So, in analogy to our     own SparsityPattern class, this function compresses the sparsity     pattern and allows the resulting matrix to be used in all other     operations where before only assembly functions were allowed. This     function must therefore be called once you have assembled the matrix.         See      [2.x.11]  "Compressing distributed objects"     for more information.    
* [0.x.50]*
     Return the value of the entry ([1.x.2]).  This may be an expensive     operation and you should always take care where to call this function.     In contrast to the respective function in the  [2.x.12]  class, we     don't throw an exception if the respective entry doesn't exist in the     sparsity pattern of this class, since PETSc does not transmit this     information.         This function is therefore exactly equivalent to the <tt>el()</tt>     function.    
* [0.x.51]*
     Return the value of the matrix entry ([1.x.3]). If this entry does     not exist in the sparsity pattern, then zero is returned. While this     may be convenient in some cases, note that it is simple to write     algorithms that are slow compared to an optimal solution, since the     sparsity of the matrix is not used.    
* [0.x.52]*
     Return the main diagonal element in the [1.x.4]th row. This function     throws an error if the matrix is not quadratic.         Since we do not have direct access to the underlying data structure,     this function is no faster than the elementwise access using the el()     function. However, we provide this function for compatibility with the     SparseMatrix class.    
* [0.x.53]*
     Return the number of rows in this matrix.    
* [0.x.54]*
     Return the number of columns in this matrix.    
* [0.x.55]*
     Return the local dimension of the matrix, i.e. the number of rows     stored on the present MPI process. For sequential matrices, this number     is the same as m(), but for parallel matrices it may be smaller.         To figure out which elements exactly are stored locally, use     local_range().    
* [0.x.56]*
     Return a pair of indices indicating which rows of this matrix are     stored locally. The first number is the index of the first row stored,     the second the index of the one past the last one that is stored     locally. If this is a sequential matrix, then the result will be the     pair (0,m()), otherwise it will be a pair (i,i+n), where     <tt>n=local_size()</tt>.    
* [0.x.57]*
     Return whether  [2.x.13]  is in the local range or not, see also     local_range().    
* [0.x.58]*
     Return a reference to the MPI communicator object in use with this     matrix. This function has to be implemented in derived classes.    
* [0.x.59]*
     Return the number of nonzero elements of this matrix. Actually, it     returns the number of entries in the sparsity pattern; if any of the     entries should happen to be zero, it is counted anyway.    
* [0.x.60]*
     Number of entries in a specific row.    
* [0.x.61]*
     Return the l1-norm of the matrix, that is  [2.x.14] , (max. sum of columns). This is the natural     matrix norm that is compatible to the l1-norm for vectors, i.e.      [2.x.15] . (cf. Haemmerlin-Hoffmann: Numerische     Mathematik)    
* [0.x.62]*
     Return the linfty-norm of the matrix, that is  [2.x.16] , (max. sum of rows). This is the natural     matrix norm that is compatible to the linfty-norm of vectors, i.e.      [2.x.17] . (cf. Haemmerlin-Hoffmann:     Numerische Mathematik)    
* [0.x.63]*
     Return the frobenius norm of the matrix, i.e. the square root of the     sum of squares of all entries in the matrix.    
* [0.x.64]*
     Return the square of the norm of the vector  [2.x.18]  with respect to the     norm induced by this matrix, i.e.  [2.x.19] . This is useful,     e.g. in the finite element context, where the  [2.x.20]  norm of a function     equals the matrix norm with respect to the mass matrix of the vector     representing the nodal values of the finite element function.         Obviously, the matrix needs to be quadratic for this operation.         The implementation of this function is not as efficient as the one in     the  [2.x.21]  class used in deal.II (i.e. the original one, not the     PETSc wrapper class) since PETSc doesn't support this operation and     needs a temporary vector.         Note that if the current object represents a parallel distributed     matrix (of type  [2.x.22]  then the given     vector has to be a distributed vector as well. Conversely, if the     matrix is not distributed, then neither may the vector be.    
* [0.x.65]*
     Compute the matrix scalar product  [2.x.23] .         The implementation of this function is not as efficient as the one in     the  [2.x.24]  class used in deal.II (i.e. the original one, not the     PETSc wrapper class) since PETSc doesn't support this operation and     needs a temporary vector.         Note that if the current object represents a parallel distributed     matrix (of type  [2.x.25]  then both vectors     have to be distributed vectors as well. Conversely, if the matrix is     not distributed, then neither of the vectors may be.    
* [0.x.66]*
     Return the trace of the matrix, i.e. the sum of all diagonal entries in     the matrix.    
* [0.x.67]*
     Multiply the entire matrix by a fixed factor.    
* [0.x.68]*
     Divide the entire matrix by a fixed factor.    
* [0.x.69]*
     Add the matrix  [2.x.26]  scaled by the factor  [2.x.27]  to the current     matrix.    
* [0.x.70]*
     Matrix-vector multiplication: let [1.x.5] with [1.x.6]     being this matrix.         Source and destination must not be the same vector.         Note that if the current object represents a parallel distributed     matrix (of type  [2.x.28]  then both vectors     have to be distributed vectors as well. Conversely, if the matrix is     not distributed, then neither of the vectors may be.    
* [0.x.71]*
     Matrix-vector multiplication: let [1.x.7] with     [1.x.8] being this matrix. This function does the same as vmult() but     takes the transposed matrix.         Source and destination must not be the same vector.         Note that if the current object represents a parallel distributed     matrix (of type  [2.x.29]  then both vectors     have to be distributed vectors as well. Conversely, if the matrix is     not distributed, then neither of the vectors may be.    
* [0.x.72]*
     Adding Matrix-vector multiplication. Add [1.x.9] on [1.x.10]     with [1.x.11] being this matrix.         Source and destination must not be the same vector.         Note that if the current object represents a parallel distributed     matrix (of type  [2.x.30]  then both vectors     have to be distributed vectors as well. Conversely, if the matrix is     not distributed, then neither of the vectors may be.    
* [0.x.73]*
     Adding Matrix-vector multiplication. Add [1.x.12] to     [1.x.13] with [1.x.14] being this matrix. This function does the same     as vmult_add() but takes the transposed matrix.         Source and destination must not be the same vector.         Note that if the current object represents a parallel distributed     matrix (of type  [2.x.31]  then both vectors     have to be distributed vectors as well. Conversely, if the matrix is     not distributed, then neither of the vectors may be.    
* [0.x.74]*
     Compute the residual of an equation [1.x.15], where the residual is     defined to be [1.x.16]. Write the residual into  [2.x.32]  The     [1.x.17] norm of the residual vector is returned.         Source [1.x.18] and destination [1.x.19] must not be the same vector.         Note that if the current object represents a parallel distributed     matrix (of type  [2.x.33]  then all vectors     have to be distributed vectors as well. Conversely, if the matrix is     not distributed, then neither of the vectors may be.    
* [0.x.75]*
     Iterator starting at the first entry. This can only be called on a     processor owning the entire matrix. In all other cases refer to the     version of begin() taking a row number as an argument.    
* [0.x.76]*
     Final iterator. This can only be called on a processor owning the entire     matrix. In all other cases refer to the version of end() taking a row     number as an argument.    
* [0.x.77]*
     Iterator starting at the first entry of row  [2.x.34]          Note that if the given row is empty, i.e. does not contain any nonzero     entries, then the iterator returned by this function equals     <tt>end(r)</tt>. Note also that the iterator may not be dereferenceable     in that case.    
* [0.x.78]*
     Final iterator of row <tt>r</tt>. It points to the first element past     the end of line  [2.x.35]  or past the end of the entire sparsity pattern.         Note that the end iterator is not necessarily dereferenceable. This is     in particular the case if it is the end iterator for the last row of a     matrix.    
* [0.x.79]*
     Conversion operator to gain access to the underlying PETSc type. If you     do this, you cut this class off some information it may need, so this     conversion operator should only be used if you know what you do. In     particular, it should only be used for read-only operations into the     matrix.    
* [0.x.80]*
     Return a reference to the underlying PETSc type. It can be used to     modify the underlying data, so use it only when you know what you     are doing.    
* [0.x.81]*
     Make an in-place transpose of a matrix.    
* [0.x.82]*
     Test whether a matrix is symmetric.  Default tolerance is      [2.x.36] -bit machine precision.    
* [0.x.83]*
     Test whether a matrix is Hermitian, i.e. it is the complex conjugate of     its transpose. Default tolerance is  [2.x.37] -bit machine     precision.    
* [0.x.84]*
     Print the PETSc matrix object values using PETSc internal matrix viewer     function <tt>MatView</tt>. The default format prints the non- zero     matrix elements. For other valid view formats, consult     http://www.mcs.anl.gov/petsc/petsc-current/docs/manualpages/Mat/MatView.html    
* [0.x.85]*
     Print the elements of a matrix to the given output stream.          [2.x.38]  out The output stream to which to write.      [2.x.39]  alternative_output This argument is ignored. It exists for     compatibility with similar functions in other matrix classes.    
* [0.x.86]*
     Return the number bytes consumed by this matrix on this CPU.    
* [0.x.87]*
     Exception    
* [0.x.88]*
     Exception.    
* [0.x.89]*
     A generic matrix object in PETSc. The actual type, a sparse matrix, is     set in the constructor.    
* [0.x.90]*
     Store whether the last action was a write or add operation.    
* [0.x.91]*
     Ensure that the add/set mode that is required for actions following     this call is compatible with the current mode. Should be called from     all internal functions accessing matrix elements.    
* [0.x.92]*
     Internal function that checks that there are no pending insert/add     operations. Throws an exception otherwise. Useful before calling any     PETSc internal functions modifying the matrix.    
* [0.x.93]*
     For some matrix storage formats, in particular for the PETSc     distributed blockmatrices, set and add operations on individual     elements can not be freely mixed. Rather, one has to synchronize     operations when one wants to switch from setting elements to adding to     elements. BlockMatrixBase automatically synchronizes the access by     calling this helper function for each block. This function ensures that     the matrix is in a state that allows adding elements; if it previously     already was in this state, the function does nothing.    
* [0.x.94]*
     Same as prepare_add() but prepare the matrix for setting elements if     the representation of elements in this class requires such an     operation.    
* [0.x.95]*
     Base function to perform the matrix-matrix multiplication  [2.x.40] ,     or, if a vector  [2.x.41]  whose size is compatible with B is given,      [2.x.42] , where  [2.x.43]  defines a     diagonal matrix with the vector entries.         This function assumes that the calling matrix  [2.x.44]  and  [2.x.45]      have compatible sizes. The size of  [2.x.46]  will be set within this     function.         The content as well as the sparsity pattern of the matrix  [2.x.47]  will be     reset by this function, so make sure that the sparsity pattern is not     used somewhere else in your program. This is an expensive operation, so     think twice before you use this function.    
* [0.x.96]*
     Base function to perform the matrix-matrix multiplication with     the transpose of <tt>this</tt>, i.e.,  [2.x.48] , or,     if an optional vector  [2.x.49]  whose size is compatible with  [2.x.50]  is given,      [2.x.51] , where  [2.x.52]  defines a     diagonal matrix with the vector entries.         This function assumes that the calling matrix  [2.x.53]  and  [2.x.54]      have compatible sizes. The size of  [2.x.55]  will be set within this     function.         The content as well as the sparsity pattern of the matrix  [2.x.56]  will be     changed by this function, so make sure that the sparsity pattern is not     used somewhere else in your program. This is an expensive operation, so     think twice before you use this function.    
* [0.x.97]*
     An internal array of integer values that is used to store the column     indices when adding/inserting local data into the (large) sparse     matrix.         This variable does not store any "state" of the matrix     object. Rather, it is only used as a temporary buffer by some     of the member functions of this class. As with all  [2.x.57]      member variables, the use of this variable is not thread-safe     unless guarded by a mutex. However, since PETSc matrix     operations are not thread-safe anyway, there is no need to     attempt to make things thread-safe, and so there is no mutex     associated with this variable.    
* [0.x.98]*
     An internal array of double values that is used to store the column     indices when adding/inserting local data into the (large) sparse     matrix.         The same comment as for the  [2.x.58]  variable above     applies.    
* [0.x.99]