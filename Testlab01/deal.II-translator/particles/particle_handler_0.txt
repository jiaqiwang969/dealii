[0.x.0]*
   This class manages the storage and handling of particles. It provides   the data structures necessary to store particles efficiently, accessor   functions to iterate over particles and find particles, and algorithms   to distribute particles in parallel domains. Note that the class   is designed in a similar way as the triangulation class. In particular,   we call particles in the domain of the local process local particles,   and particles that belong to neighbor processes and live in the ghost cells   around the locally owned domain "ghost particles".     This class is used in  [2.x.0] .    
*  [2.x.1]   
* [0.x.1]*
     A type that can be used to iterate over all particles in the domain.    
* [0.x.2]*
     A type that represents a range of particles.    
* [0.x.3]*
     Default constructor.    
* [0.x.4]*
     Constructor that initializes the particle handler with     a given triangulation and mapping. Since particles are stored in     respect to their surrounding cells this information is necessary to     correctly organize the particle collection.     This constructor is equivalent to calling the default constructor and     the initialize function.    
* [0.x.5]*
     Destructor.    
* [0.x.6]*
     Initialize the particle handler. This function does not clear the     internal data structures, it just sets the triangulation and the     mapping to be used.    
* [0.x.7]*
     Copy the state of particle handler  [2.x.2]  into the     current object. This will copy     all particles and properties and leave this object     as an identical copy of  [2.x.3]  Existing     particles in this object are deleted. Be aware that this     does not copy functions that are connected to the signals of      [2.x.4]  nor does it connect the current object's member     functions to triangulation signals, which must be done by the caller     if necessary, that is if the  [2.x.5]  had     connected functions.         This function is expensive as it has to duplicate all data     in  [2.x.6]  and insert it into this object,     which may be a significant amount of data. However, it can     be useful to save the state of a particle     collection at a certain point in time and reset this     state later under certain conditions, for example if     a timestep has to be undone and repeated.    
* [0.x.8]*
     Clear all particle related data.    
* [0.x.9]*
     Only clear particle data, but keep cache information about number     of particles. This is useful during reorganization of particle data     between processes.    
* [0.x.10]*
     Update all internally cached numbers. Note that all functions that     modify internal data structures and act on multiple particles will     call this function automatically (e.g. insert_particles), while     functions that act on single particles will not call this function     (e.g. insert_particle). This is done because the update is     expensive compared to single operations.    
* [0.x.11]*
     Return an iterator to the first particle.    
* [0.x.12]*
     Return an iterator to the first particle.    
* [0.x.13]*
     Return an iterator past the end of the particles.    
* [0.x.14]*
     Return an iterator past the end of the particles.    
* [0.x.15]*
     Return an iterator to the first ghost particle.    
* [0.x.16]*
     Return an iterator to the first ghost particle.    
* [0.x.17]*
     Return an iterator past the end of the ghost particles.    
* [0.x.18]*
     Return an iterator past the end of the ghost particles.    
* [0.x.19]*
     Return the number of particles that live on the given cell.        
*  [2.x.7]  While this function is used in  [2.x.8] , it is not an efficient       function to use if the number of particles is large. That is because       to find the particles that are located in one cell costs        [2.x.9]  where  [2.x.10]  is the number of overall particles. Since       you will likely do this for every cell, and assuming that the number       of particles and the number of cells are roughly proportional,       you end up with an  [2.x.11]  algorithm. A better approach       is to use the fact that internally, particles are arranged in the       order of the active cells they are in. In other words, if you iterate       over all particles, you will encounter them in the same order as       you walk over the active cells. You can exploit this by keeping an       iterator to the first particle of the first cell, and when you move       to the next cell, you increment the particle iterator as well until       you find a particle located on that next cell. Counting how many       steps this took will then give you the number you are looking for,       at a cost of  [2.x.12]  when accumulated over all cells.       This is the approach used in  [2.x.13] , for example. The approach is       also detailed in the "Possibilities for extensions section"       of  [2.x.14] .    
* [0.x.20]*
     Return a pair of particle iterators that mark the begin and end of     the particles in a particular cell. The last iterator is the first     particle that is no longer in the cell.         The number of elements in the returned range equals what the     n_particles_in_cell() function returns.        
*  [2.x.15]  While this function is used in  [2.x.16] , it is not an efficient       function to use if the number of particles is large. That is because       to find the particles that are located in one cell costs        [2.x.17]  where  [2.x.18]  is the number of overall particles. Since       you will likely do this for every cell, and assuming that the number       of particles and the number of cells are roughly proportional,       you end up with an  [2.x.19]  algorithm. A better approach       is to use the fact that internally, particles are arranged in the       order of the active cells they are in. In other words, if you iterate       over all particles, you will encounter them in the same order as       you walk over the active cells. You can exploit this by keeping an       iterator to the first particle of the first cell, and when you move       to the next cell, you increment the particle iterator as well until       you find a particle located on that next cell. This is the approach       used in  [2.x.20] , for example, and has an overall cost of        [2.x.21]  when accumulated over all cells. The approach is       also detailed in the "Possibilities for extensions section"       of  [2.x.22] .    
* [0.x.21]*
     Return a pair of particle iterators that mark the begin and end of     the particles in a particular cell. The last iterator is the first     particle that is no longer in the cell.         The number of elements in the returned range equals what the     n_particles_in_cell() function returns.        
*  [2.x.23]  While this function is used in  [2.x.24] , it is not an efficient       function to use if the number of particles is large. That is because       to find the particles that are located in one cell costs        [2.x.25]  where  [2.x.26]  is the number of overall particles. Since       you will likely do this for every cell, and assuming that the number       of particles and the number of cells are roughly proportional,       you end up with an  [2.x.27]  algorithm. A better approach       is to use the fact that internally, particles are arranged in the       order of the active cells they are in. In other words, if you iterate       over all particles, you will encounter them in the same order as       you walk over the active cells. You can exploit this by keeping an       iterator to the first particle of the first cell, and when you move       to the next cell, you increment the particle iterator as well until       you find a particle located on that next cell. This is the approach       used in  [2.x.28] , for example, and has an overall cost of        [2.x.29]  when accumulated over all cells. The approach is       also detailed in the "Possibilities for extensions section"       of  [2.x.30] .    
* [0.x.22]*
     Remove a particle pointed to by the iterator.    
* [0.x.23]*
     Insert a particle into the collection of particles. Return an iterator     to the new position of the particle. This function involves a copy of     the particle and its properties. Note that this function is of  [2.x.31]  complexity for  [2.x.32]  particles.    
* [0.x.24]*
     Insert a number of particles into the collection of particles.     This function involves a copy of the particles and their properties.     Note that this function is of O(n_existing_particles + n_particles)     complexity.    
* [0.x.25]*
     Create and insert a number of particles into the collection of particles.     This function takes a list of positions and creates a set of particles     at these positions, which are then added to the local particle     collection. Note that this function currently uses      [2.x.33]  which assumes all positions are     within the local part of the triangulation. If one of them is not in the     local domain this function will throw an exception.    
* [0.x.26]*
     Create and insert a number of particles into the collection of particles.     This function takes a list of positions and creates a set of particles     at these positions, which are then distributed and added to the local     particle collection of a processor. Note that this function uses      [2.x.34]  Consequently, it can     require intense communications between the processors. This function     is used in  [2.x.35] .         This function figures out what mpi process owns the points that do not     fall within the locally owned part of the triangulation, it sends     to that process the points passed to this function on this process,     and receives the points that fall within the locally owned cells of     the triangulation from whoever received them as input.         In order to keep track of what mpi process received what points, a map     from mpi process to IndexSet is returned by the function. This IndexSet     contains the local indices of the points that were passed to this     function on the calling mpi process, and that falls within the part of     triangulation owned by this mpi process.         The ids of the resulting particles are assigned from the optional     argument  [2.x.36]  If the vector of  [2.x.37]  is empty, then the ids are     computed automatically from the get_next_free_particle_index() onward.     For example, if the method get_next_free_particle_index() returns n0,     calling this function with two MPI processes each adding n1 and n2     particles will result in the n1 particles added by process zero having     ids equal to `[n0,n0+n1)`, and the n2 particles added by process one     having ids `[n0+n1, n0+n1+n2)`.          [2.x.38]  positions A vector of points that do not need to be on the     local processor, but have to be in the triangulation that is associated     with this ParticleHandler object.          [2.x.39]  global_bounding_boxes A vector of vectors of bounding boxes.     The bounding boxes `global_bboxes[rk]` describe which part of the mesh is     locally owned by the mpi process with rank `rk`. The local description     can be obtained from  [2.x.40]      and the global one can be obtained by passing the local ones to      [2.x.41]           [2.x.42]  properties (Optional) A vector of vector of properties     associated with each local point. The size of the vector should be either     zero (no properties will be transferred nor attached to the generated     particles) or it should be a vector of `positions.size()` vectors of size     `n_properties_per_particle()`. Notice that this function call will     transfer the properties from the local mpi process to the final mpi     process that will own each of the particles, and it may therefore be     communication intensive.          [2.x.43]  ids (Optional) A vector of ids to associate to each particle.     If the vector is empty, the ids are assigned as a continuous range     from the first available index, as documented above. If the vector is not     empty, then its size must match the size of the  [2.x.44]  vector.          [2.x.45]  A map from owner to IndexSet, that contains the local indices     of the points that were passed to this function on the calling mpi     process, and that falls within the part of triangulation owned by this     mpi process.    
* [0.x.27]*
     Insert a number of particles into the collection of particles. This     function takes a list of particles for which we don't know the associated     cell iterator, and distributes them to the correct local particle     collection of a processor, by unpacking the locations, figuring out where     to send the particles by calling      [2.x.46]  and sending the     particles to the corresponding process.         In order to keep track of what mpi process received what particles, a map     from mpi process to IndexSet is returned by the function. This IndexSet     contains the local indices of the particles that were passed to this     function on the calling mpi process, and that falls within the part of     the triangulation owned by this mpi process.          [2.x.47]  particles A vector of particles that do not need to be on the     local processor.          [2.x.48]  global_bounding_boxes A vector of vectors of bounding boxes.     The bounding boxes `global_bboxes[rk]` describe which part of the mesh is     locally owned by the mpi process with rank `rk`. The local description     can be obtained from  [2.x.49]      and the global one can be obtained by passing the local ones to      [2.x.50]           [2.x.51]  A map from owner to IndexSet, that contains the local indices     of the points that were passed to this function on the calling mpi     process, and that falls within the part of triangulation owned by this     mpi process.    
* [0.x.28]*
     Set the position of the particles by using the values contained in the     vector  [2.x.52]           [2.x.53]  VectorType Any of the parallel distributed vectors supported by     the library.         The vector  [2.x.54]  should have read access to the indices     created by extracting the locally relevant ids with     locally_owned_particle_ids(), and taking its tensor     product with the index set representing the range `[0, spacedim)`, i.e.:    
* [1.x.0]
*          The position of the particle with global index `id` is read from     spacedim consecutive entries starting from     `input_vector[id*spacedim]`.         Notice that it is not necessary that the  [2.x.55]  those     indices, however it has to have read access to them (i.e., it can be a     distributed vector with ghost entries).         If the argument  [2.x.56]  is set to false, then the new     position taken from the values contained in      [2.x.57]  replacing the previously stored particle position.     By default, the particles are displaced by the amount contained in the      [2.x.58]  i.e., the contents of the vector are considered    offsets* that are added to the previous position.         After setting the new position, this function calls internally the method     sort_particles_into_subdomains_and_cells(). You should     make sure you satisfy the requirements of that function.          [2.x.59]  input_vector A parallel distributed vector containing     the displacement to apply to each particle, or their new absolute     position.          [2.x.60]  displace_particles Control if the  [2.x.61]  should     be interpreted as a displacement vector, or a vector of absolute     positions.    
* [0.x.29]*
     Set the position of the particles within the particle handler using a     vector of points. The new set of point defined by the     vector has to be sufficiently close to the original one to ensure that     the sort_particles_into_subdomains_and_cells() function manages to find     the new cells in which the particles belong.         Points are numbered in the same way they are traversed locally by the     ParticleHandler. A typical way to use this method, is to first call the     get_particle_positions() function, and then modify the resulting vector.          [2.x.62]  [in] new_positions A vector of points of dimension     particle_handler.n_locally_owned_particles()          [2.x.63]  [in] displace_particles When true, this function adds the value     of the vector of points to the     current position of the particle, thus displacing them by the     amount given by the function. When false, the position of the     particle is replaced by the value in the vector.    
* [0.x.30]*
     Set the position of the particles within the particle handler using a     function with spacedim components. The new set of point defined by the     function has to be sufficiently close to the original one to ensure that     the sort_particles_into_subdomains_and_cells algorithm manages to find     the new cells in which the particles belong.         The function is evaluated at the current location of the particles.          [2.x.64]  [in] function A function that has n_components==spacedim that     describes either the displacement or the new position of the particles as     a function of the current location of the particle.          [2.x.65]  [in] displace_particles When true, this function adds the results     of the function to the current position of the particle, thus displacing     them by the amount given by the function. When false, the position of the     particle is replaced by the value of the function.    
* [0.x.31]*
     Read the position of the particles and store them into the distributed     vector  [2.x.66]  By default the      [2.x.67]  is overwritten by this operation, but you can add to     its entries by setting  [2.x.68]  to `true`.          [2.x.69]  VectorType Any of the parallel distributed vectors supported by     the library.         This is the reverse operation of the set_particle_positions() function.     The position of the particle with global index `id` is written to     spacedim consecutive entries starting from     `output_vector[id*spacedim]`.         Notice that, if you use a distributed vector type, it is not necessary     for the  [2.x.70]  to own the entries corresponding to the indices     that will be written. However you should keep in mind that this requires     a global communication to distribute the entries above to their     respective owners.          [2.x.71]  out] output_vector A parallel distributed vector containing     the positions of the particles, or updated with the positions of the     particles.          [2.x.72]  add_to_output_vector Control if the function should set the     entries of the  [2.x.73]  or if should add to them.    
* [0.x.32]*
     Gather the position of the particles within the particle handler in     a vector of points. The order of the points is the same on would obtain     by iterating over all (local) particles, and querying their locations.          [2.x.74]  [in,out] positions A vector preallocated at size     `particle_handler.n_locally_owned_articles` and whose points will become     the positions of the locally owned particles          [2.x.75]  [in] add_to_output_vector When true, the value of the point of     the particles is added to the positions vector. When false,     the value of the points in the positions vector are replaced by the     position of the particles.    
* [0.x.33]*
     This function allows to register three additional functions that are     called every time a particle is transferred to another process     (i.e. during sorting into cells, during ghost particle transfer, or     during serialization of all particles).          [2.x.76]  size_callback A function that is called when serializing     particle data. The function gets no arguments and is expected to     return the size of the additional data that is serialized per     particle. Note that this currently implies the data size has to be     the same for every particle.      [2.x.77]  store_callback A function that is called once per particle     when serializing particle data. Arguments to the function are a     particle iterator that identifies the current particle and a void     pointer that points to a data block of size size_callback() in which     the function can store additional data. The function is expected to     return a void pointer pointing to a position right after its data     block.      [2.x.78]  load_callback A function that is called once per particle     when deserializing particle data. Arguments to the function are a     particle iterator that identifies the current particle and a void     pointer that points to a data block of size size_callback() in which     additional data was stored by the store_callback function. The     function is expected to return a void pointer pointing to a position     right after its data block.    
* [0.x.34]*
     Return the total number of particles that were managed by this class     the last time the update_cached_numbers() function was called.     The actual number of particles may have changed since then if     particles have been added or removed.          [2.x.79]  Total number of particles in simulation.    
* [0.x.35]*
     Return the maximum number of particles per cell the last     time the update_cached_numbers() function was called.          [2.x.80]  Maximum number of particles in one cell in simulation.    
* [0.x.36]*
     Return the number of particles in the local part of the     triangulation.    
* [0.x.37]*
     Return the next free particle index in the global set     of particles the last     time the update_cached_numbers() function was called.    
* [0.x.38]*
     Extract an IndexSet with global dimensions equal to     get_next_free_particle_index(), containing the locally owned     particle indices.         This function can be used to construct distributed vectors and matrices     to manipulate particles using linear algebra operations.         Notice that it is the user's responsibility to guarantee that particle     indices are unique, and no check is performed to verify that this is the     case, nor that the union of all IndexSet objects on each mpi process is     complete.          [2.x.81]  An IndexSet of size get_next_free_particle_index(), containing     n_locally_owned_particle() indices.          [2.x.82]  Use locally_owned_particle_ids() instead.    
* [0.x.39]*
     Extract an IndexSet with global dimensions equal to     get_next_free_particle_index(), containing the locally owned     particle indices.         This function can be used to construct distributed vectors and matrices     to manipulate particles using linear algebra operations.         Notice that it is the user's responsibility to guarantee that particle     indices are unique, and no check is performed to verify that this is the     case, nor that the union of all IndexSet objects on each mpi process is     complete.          [2.x.83]  An IndexSet of size get_next_free_particle_index(), containing     n_locally_owned_particle() indices.    
* [0.x.40]*
     Return the number of properties each particle has.    
* [0.x.41]*
     Return a reference to the property pool that owns all particle     properties, and organizes them physically.    
* [0.x.42]*
     Find and update the cells containing each particle for all locally owned     particles. If particles moved out of the local subdomain     they will be sent to their new process and inserted there.     After this function call every particle is either on its current     process and in its current cell, or deleted (if it could not find     its new process or cell).         The user may attach a function to the signal      [2.x.84]  The signal is     triggered whenever a particle is deleted, and the connected functions     are called passing an iterator to the particle in question, and its last     known cell association.    
* [0.x.43]*
     Exchange all particles that live in cells that are ghost cells to     other processes. Clears and re-populates the ghost_neighbors     member variable.    
* [0.x.44]*
     Update all particles that live in cells that are ghost cells to     other processes. In this context, update means to update the     location and the properties of the ghost particles assuming that     the ghost particles have not changed cells. Consequently, this will     not update the reference location of the particles.    
* [0.x.45]*
     Callback function that should be called before every refinement     and when writing checkpoints. This function is used to     register store_particles() with the triangulation. This function     is used in  [2.x.85] .    
* [0.x.46]*
     Callback function that should be called after every refinement     and after resuming from a checkpoint.  This function is used to     register load_particles() with the triangulation. This function     is used in  [2.x.86] .    
* [0.x.47]*
     Serialize the contents of this class using the [BOOST serialization     library](https://www.boost.org/doc/libs/1_74_0/libs/serialization/doc/index.html).    
* [0.x.48]*
     A structure that has  [2.x.87]  objects for a number of actions that a     particle handler can do to itself. How signals can be used in     applications is explained in the "Getting notice when a triangulation     changes" section in the Triangulation class with more information and     examples. In short these signals allow the particle handler to notify     applications about certain events inside the particle handler, e.g. when     a particle is lost.         For documentation on signals, see     http://www.boost.org/doc/libs/release/libs/signals2 .    
* [0.x.49]*
       This signal is triggered whenever the        [2.x.88]  function       encounters a particle that can not be associated with a cell. This can       happen if the particle leaves the domain of the triangulation, or if it       leaves the locally known domain in a parallel triangulation (including       the ghost cells for a  [2.x.89]              The connected function receives an iterator to the particle in       question, and its last known cell association.             This signal is used in  [2.x.90] .      
* [0.x.50]*
     Signals for the events that a particle handler can notify the     calling application about.    
* [0.x.51]*
     Address of the triangulation to work on.    
* [0.x.52]*
     Address of the mapping to work on.    
* [0.x.53]*
     This object owns and organizes the memory for all particle     properties. Since particles reference the property pool, the     latter has to be destroyedafter* the particles are destroyed.     This is achieved by making sure the `property_pool` member variable     precedes the declaration of the `particles` and `ghost_particles`     members.    
* [0.x.54]*
     Set of particles currently living in the local domain, organized by     the level/index of the cell they are in.    
* [0.x.55]*
     Set of particles that currently live in the ghost cells of the local     domain, organized by the level/index of the cell they are in. These     particles are equivalent to the ghost entries in distributed vectors.    
* [0.x.56]*
     This variable stores how many particles are stored globally. It is     calculated by update_cached_numbers().    
* [0.x.57]*
     The maximum number of particles per cell in the global domain. This     variable is important to store and load particle data during     repartition and serialization of the solution. Note that the     variable is only updated when it is needed, e.g. after particle     movement, before/after mesh refinement, before creating a     checkpoint and after resuming from a checkpoint.    
* [0.x.58]*
     This variable stores the next free particle index that is available     globally in case new particles need to be generated.    
* [0.x.59]*
     A function that can be registered by calling     register_additional_store_load_functions. It is called when serializing     particle data. The function gets no arguments and is expected to     return the size of the additional data that is serialized per     particle. Note that this currently implies the data size has to be     the same for every particle, but it does not have to be the same for     every serialization process (e.g. a serialization during particle     movement might include temporary data, while a serialization after     movement was finished does not need to transfer this data).    
* [0.x.60]*
     A function that can be registered by calling     register_additional_store_load_functions. It is called once per     particle when serializing particle data. Arguments to the function     are a particle iterator that identifies the current particle and a void     pointer that points to a data block of size size_callback() in which     the function can store additional data. The function is expected to     return a void pointer pointing to a position right after its data     block.    
* [0.x.61]*
     A function that is called once per particle     when deserializing particle data. Arguments to the function are a     particle iterator that identifies the current particle and a void     pointer that points to a data block of size size_callback() from     which the function can load additional data. This block was filled     by the store_callback function during serialization. This function     is expected to return a void pointer pointing to a position right     after its data block.    
* [0.x.62]*
     This variable is set by the register_store_callback_function()     function and used by the register_load_callback_function() function     to check where the particle data was registered in the corresponding     triangulation object.    
* [0.x.63]*
     The  [2.x.91]  is used to store the information about the     vertex_to_cells set and the vertex_to_cell_centers vectors to prevent     recomputing them every time we sort_into_subdomain_and_cells().     This cache is automatically updated when the triangulation has     changed. This cache is stored within a unique pointer because the     particle handler has a constructor that enables it to be constructed     without a triangulation. The cache does not have such a constructor.    
* [0.x.64]*
     Transfer particles that have crossed subdomain boundaries to other     processors.     All received particles and their new cells will be appended to the      [2.x.92]  vector.          [2.x.93]  [in] particles_to_send All particles that should be sent and     their new subdomain_ids are in this map.          [2.x.94]  [in,out] received_particles Vector that stores all received     particles. Note that it is not required nor checked that the list     is empty, received particles are simply attached to the end of     the vector.          [2.x.95]  [in] new_cells_for_particles Optional vector of cell     iterators with the same structure as  [2.x.96]  If this     parameter is given it should contain the cell iterator for every     particle to be send in which the particle belongs. This parameter     is necessary if the cell information of the particle iterator is     outdated (e.g. after particle movement).          [2.x.97]  [in] enable_cache Optional bool that enables updating     the ghost particles without rebuilding them from scratch by     building a cache of type GhostParticlePartitioner, which     stores the necessary information to update the ghost particles.     Once this cache is built, the ghost particles can be updated     by a call to send_recv_particles_properties_and_location().    
* [0.x.65]*
     Transfer particles position and properties assuming that     the particles have not changed cells. This routine uses the     GhostParticlePartitioner as a caching structure to update the particles.     It inherently assumes that particles cannot have changed cell.     All updated particles will be appended to the      [2.x.98]  container.          [2.x.99]  [in] particles_to_send All particles for which information     should be sent and their new subdomain_ids are in this map.          [2.x.100]  [in,out] received_particles A map with all received     particles. Note that it is not required nor checked that the container     is empty, received particles are simply inserted into     the map.        
* [0.x.66]*
     Cache structure used to store the elements which are required to     exchange the particle information (location and properties) across     processors in order to update the ghost particles. This structure     is only used to update the ghost particles.    
* [0.x.67]*
     Called by listener functions from Triangulation for every cell     before a refinement step. All particles have to be attached to their     cell to be sent around to the new processes.    
* [0.x.68]*
     Called by listener functions after a refinement step. The local map     of particles has to be read from the triangulation user_pointer.    
* [0.x.69]