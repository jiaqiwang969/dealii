[0.x.0]*
 A namespace for the implementation of thread management in deal.II. Most of the content of this namespace is discussed in detail in one of the reports linked to from the documentation page of deal.II.
* 

* 
*  [2.x.0] 

* 
* [0.x.1]*
   A class implementing a [1.x.0].   Mutexes are used to lock data structures to ensure that only a   single thread of execution can access them at the same time.     This class is a thin wrapper around  [2.x.1]  The only difference   is that this class is copyable when  [2.x.2]  is not.  Indeed, when   copied, the receiving object does not copy any state from the object   being copied, i.e. an entirely new mutex is created. These semantics   are consistent with the common use case if a mutex is used as a member   variable to lock the other member variables of a class: in that case,   the mutex of the copied-to object should only guard the members of the   copied-to object, not the members of both the copied-to and   copied-from object. Since at the time when the class is copied, the   destination's member variable is not used yet, its corresponding mutex   should also remain in its original state.  
* [0.x.2]*
     Default constructor.    
* [0.x.3]*
     Copy constructor. As discussed in this class's documentation, no state     is copied from the object given as argument.    
* [0.x.4]*
     Copy operators. As discussed in this class's documentation, no state     is copied from the object given as argument.    
* [0.x.5]*
   Split the range  [2.x.3]    subintervals of equal size. The last interval will be a little bit   larger, if the number of elements in the whole range is not exactly   divisible by  [2.x.4] . The type of the iterators has to   fulfill the requirements of a forward iterator, i.e.    [2.x.5]  must be available, and of course it must be   assignable.     A list of subintervals is returned as a vector of pairs of iterators,   where each pair denotes the range  [2.x.6] .    
*  [2.x.7]   
* [0.x.6]*
   Split the interval  [2.x.8]  into subintervals of (almost)   equal size. This function works mostly as the one before, with the   difference that instead of iterators, now values are taken that define   the whole interval.    
*  [2.x.9]   
* [0.x.7]*
    [2.x.10]  internal  
* [0.x.8]*
   A namespace in which helper functions and the like for the threading   subsystem are implemented. The members of this namespace are not meant   for public use.  
* [0.x.9]*
      [2.x.11]          If in a sub-thread an exception is thrown, it is not propagated to the     main thread. Therefore, the exception handler that is provided by the     applications main function or some of its other parts will not be able     to catch these exceptions. Therefore, we have to provide an exception     handler in the top function of each sub-thread that at least catches     the exception and prints some information, rather than letting the     operating system to just kill the program without a message. In each of     the functions we use as entry points to new threads, we therefore     install a try-catch block, and if an exception of type      [2.x.12]  is caught, it passes over control to this     function, which will then provide some output.    
* [0.x.10]*
      [2.x.13]          Same as above, but the type of the exception is not derived from      [2.x.14] , so there is little way to provide     something more useful.    
* [0.x.11]*
    [2.x.15]   
* [0.x.12]*
      [2.x.16]          Given an arbitrary type RT, store an element of it and grant     access to it through functions get() and set(). There are     specializations for reference types (which need to be stored as     pointers to the object being referenced), and for type void.         This function is not dissimilar to the  [2.x.17]      combination of classes. The difference is that a  [2.x.18]      can only be read once via  [2.x.19]  (presumably this     design is due to the fact that  [2.x.20]  can throw     an exception previously stored in the  [2.x.21]  On     the other hand, this class makes the result available for     as many times as desired. It also doesn't store any exceptions     (though they will be forwarded by the classes using the current     class).    
* [0.x.13]*
      [2.x.22]          Given an arbitrary type RT, store an element of it and grant access to     it through functions get() and set(). This is the specialization for     reference types: since references cannot be set after construction time,     we store a pointer instead, which holds the address of the object being     referenced.         This function is not dissimilar to the  [2.x.23]      combination of classes. The difference is that a  [2.x.24]      can only be read once via  [2.x.25]  (presumably this     design is due to the fact that  [2.x.26]  can throw     an exception previously stored in the  [2.x.27]  On     the other hand, this class makes the result available for     as many times as desired. It also doesn't store any exceptions     (though they will be forwarded by the classes using the current     class).    
* [0.x.14]*
      [2.x.28]          Given an arbitrary type RT, store an element of it and grant access to     it through functions get() and set(). This is the specialization for     type void: there is obviously nothing to store, so no function set(),     and a function get() that returns void.         This function is not dissimilar to the  [2.x.29]      combination of classes. The difference is that a  [2.x.30]      can only be read once via  [2.x.31]  (presumably this     design is due to the fact that  [2.x.32]  can throw     an exception previously stored in the  [2.x.33]  On     the other hand, this class makes the result available for     as many times as desired. It also doesn't store any exceptions     (though they will be forwarded by the classes using the current     class).    
* [0.x.15]*
     A class that represents threads. For each thread, we create exactly one     of these objects
* 
*  -  exactly one because it carries the returned value     of the function called on the thread.         While we have only one of these objects per thread, several      [2.x.34]  objects may refer to this descriptor. If all Thread     objects go out of scope the ThreadDescriptor will detach from the     thread before being destroyed.    
* [0.x.16]*
       An object that represents the thread started.      
* [0.x.17]*
       An object that will hold the value returned by the function called on       the thread.             The return value is stored in a shared_ptr because we might abandon       the ThreadDescriptor.  This makes sure the object stays alive       until the thread exits.      
* [0.x.18]*
       An atomic  bool variable that is initially false, is set to true       when a new thread is started, and is set back to false once join()       has been called.             We use this variable to make sure we can call join() twice on the       same thread. For some reason, the C++ standard library throws a        [2.x.35]  exception if one tries to call  [2.x.36]        twice (and in fact, before the second call,  [2.x.37]        returns false) but this is a somewhat desirable thing to do because       one doesn't have to keep track whether join() has been called before.       Using this variable, whenever we have called join() before, the       variable is set to true and we can skip over calling        [2.x.38]  a second time. Access to this variable is guarded       by the following mutex.            
*  [2.x.39]  Historically, we did not need the mutex for this variable:       threads can only be joined from the thread that created it       originally. Consequently, everything that happens in a function that       does not create threads (such as the join() function below) looks       atomic to the outside world. Since we clear and test thread_is_active       in the same function as we call  [2.x.40]  these actions are       atomic and need no mutex. Of course, two threads may call join() on       the same thread object at the same time, but this action is undefined       anyway since they can not both join the same thread. That said, more       recent C++ standards do not appear to have the requirement any more       that the only thread that can call join() is the one that created the       thread. Neither does `pthread_join` appear to have this requirement any       more.  Consequently, we can in fact join from different threads and       we test this in base/thread_validity_07.            
*  [2.x.41]  The reason why we need to use a  [2.x.42]  is       discussed in detail in the documentation of        [2.x.43]       
* [0.x.19]*
       Mutex guarding access to the previous variable.      
* [0.x.20]*
       Default constructor.      
* [0.x.21]*
       Start the thread and let it put its return value into the ret_val       object.      
* [0.x.22]*
       Wait for the thread to end.      
* [0.x.23]*
       The function that runs on the thread.      
* [0.x.24]*
   An object that represents a spawned thread. This object can be freely   copied around in user space, and all instances will represent the same   thread and can require to wait for its termination and access its return   value.     Threads can be abandoned, i.e. if you just call  [2.x.44]  but   don't care about the returned object, or if you assign the return    [2.x.45]  object to an object that subsequently goes out of scope,   then the thread previously created will still continue to do work. You   will simply not be able to access its return value any more, and it may   also happen that your program terminates before the thread has finished   its work.     The default value of the template argument is  [2.x.46] , so if   the function you are calling on a new thread has no return value, you can   omit the template argument.    
*  [2.x.47]       [2.x.48]  Use  [2.x.49]  or  [2.x.50]  instead.    
*  [2.x.51]  Since this class is used in ThreadGroup, its constructors, rather   than the class itself, are deprecated to allow compilation with
* 

* 
* 

* 
* 

* 
* 
*  - error=deprecated-declarations.  
* [0.x.25]*
     Construct a thread object with a function object.    
* [0.x.26]*
     Default constructor. You can't do much with a thread object constructed     this way, except for assigning it a thread object that holds data     created by the new_thread() functions.    
* [0.x.27]*
     Copy constructor.    
* [0.x.28]*
     Join the thread represented by this object, i.e. wait for it to finish.     If you have used the default constructor of this class and have not     assigned a thread object to it, then this function is a no-op.    
* [0.x.29]*
     Get the return value of the function of the thread. Since it     is only available once the thread finishes, this function     internally also calls join(). You can call this function     multiple times as long as the object refers to the same task,     and expect to get the same return value every time. (With the     exception of the case where the returned object has been moved;     see below.)        
*  [2.x.52]  The function returns a [1.x.1] to     the returned object, instead of the returned object. This     allows writing code such as    
* [1.x.2]
*      You will rarely have a need to write such code. On the other hand,     the function needs to return a writable (non- [2.x.53]  reference to     support code such as this:    
* [1.x.3]
*      Here, it is necessary to  [2.x.54]  the returned object (namely,     the  [2.x.55]  object) because      [2.x.56]  objects can not be copied. In other words,     to get the pointer out of the object returned from the thread, it needs     to be moved, and in order to be moved, the current function needs to     return a writable (non- [2.x.57]  reference.    
* [0.x.30]*
     Return true if this object has had a thread associated with it, either     by using the non-default constructor or by assignment.    
* [0.x.31]*
     Check for equality of thread objects. Since objects of this class store     an implicit pointer to an object that exists exactly once for each     thread, the check is simply to compare these pointers.    
* [0.x.32]*
     Shared pointer to the object representing the thread, and abstracting     operating system functions to work on it. This also makes sure that the     object lives as long as there is at least one subscriber to it.    
* [0.x.33]*
     A general template that returns  [2.x.58]  if t is of reference     type, and t otherwise.         The case that t is of reference type is handled in a partial     specialization declared below.    
* [0.x.34]*
     A general template that returns  [2.x.59]  if t is of reference     type, and t otherwise.         The case that t is of reference type is handled in this partial     specialization.    
* [0.x.35]*
   Overload of the new_thread function for objects that can be converted to    [2.x.60]  ()>, i.e. anything that can be called like a   function object without arguments and returning an object of type RT (or   void).    
*  [2.x.61]   
* [0.x.36]*
   Overload of the new_thread() function for objects that can be called like a   function object without arguments. In particular, this function allows   calling  [2.x.62]  with either objects that result from using    [2.x.63]  or using lambda functions. For example, this function is called   when writing code such as  
* [1.x.4]
*    Here, we run the sequence of functions    [2.x.64]  on   a separate thread, by making the lambda function declared here the   function to execute on the thread. The lambda function then returns   42 (which is a bit pointless here, but it could of course be some   computed number), and this is going to be the returned value you   can later retrieve via  [2.x.65]  once the   thread (i.e., the body of the lambda function) has completed.    
*  [2.x.66]  Every lambda function (or whatever else it is you pass to     the new_thread() function here, for example the result of a      [2.x.67]  expression) has a return type and consequently     returns an object of this type. This type can be inferred     using the C++11  [2.x.68]  statement used in the     declaration of this function, and it is then used as the template     argument of the  [2.x.69]  object returned by the current function.     In the example above, because the lambda function returns 42     (which in C++ has data type  [2.x.70] ), the inferred     type is  [2.x.71]  and the task object will have type      [2.x.72] . In other words, it is not [1.x.5]     to explicitly specify in user code what that return type     of the lambda or  [2.x.73]  expression will be, though it is     possible to explicitly do so by (entirely equivalently) writing    
* [1.x.6]
*     
*  [2.x.74]  In practice, the lambda functions you will pass to     new_thread() will of course typically be more complicated.     In particular, they will likely [1.x.7] variables     from the surrounding context and use them within the lambda.     See   https://en.wikipedia.org/wiki/Anonymous_function#C.2B.2B_.28since_C.2B.2B11.29     for more on how lambda functions work.    
*  [2.x.75]  If you pass a lambda function as an argument to the     current function that captures a variable [1.x.8],     or if you use a  [2.x.76]  that binds a function argument to     a reference variable using  [2.x.77]  or  [2.x.78]  then     obviously you can only do this if the variables you reference     or capture have a lifetime that extends at least until the time     where the thread finishes.    
*  [2.x.79]   
* [0.x.37]*
   Overload of the new_thread function for non-member or static member   functions.    
*  [2.x.80]   
* [0.x.38]*
   Overload of the non-const new_thread function for member functions.    
*  [2.x.81]   
* [0.x.39]*
   Overload of the new_thread function for const member functions.    
*  [2.x.82]   
* [0.x.40]*
   A container for thread objects. Allows to add new thread objects and wait   for them all together. The thread objects need to have the same return   value for the called function.    
*  [2.x.83]       [2.x.84]  Use TaskGroup instead.  
* [0.x.41]*
     Add another thread object to the collection.    
* [0.x.42]*
     Wait for all threads in the collection to finish. It is not a problem     if some of them have already been waited for, i.e. you may call this     function more than once, and you can also add new thread objects     between subsequent calls to this function if you want.    
* [0.x.43]*
     List of thread objects.    
* [0.x.44]*
     Set the value of a  [2.x.85]  object by evaluating the action.    
* [0.x.45]*
     Set the value of a  [2.x.86]  object by evaluating the     action. This function is a specialization of the previous one     for the case where the return type is `void`. Consequently, we     can't set a value. But we do evaluate the function object and     call  [2.x.87]  without argument.    
* [0.x.46]*
   This class describes a task object, i.e., what one obtains by calling    [2.x.88]  The idea is that  [2.x.89]  allows one to run   a function whenever the C++ run-time system finds it convenient
* 
*  -    typically, when there is an idle processor available. This can be used to   run things in the background when there is no immediate need for the   result, or if there are other things that could well be done in parallel.   Whenever the result of that background task is needed, one can call either   join() to just wait for the task to finish, or return_value() to obtain the   value that was returned by the function that was run on that background   task.     This class is conceptually similar to the    [2.x.90]  class that   is returned by    [2.x.91]  (which is   itself similar to what  [2.x.92]  does). The principal conceptual   difference is that one can only call  [2.x.93]  once, whereas one   can call  [2.x.94]  as many times as desired. It is,   thus, comparable to the    [2.x.95]    class. However,  [2.x.96]  can not be used for types that can not   be copied
* 
*  -  a particular restriction for  [2.x.97]  for example.    
*  [2.x.98]   
* [0.x.47]*
     Construct a task object, given a function object to execute on     the task, and then schedule this function for     execution. However, when  [2.x.99]  returns     1, i.e., if the deal.II runtime system has been configured to     only use one thread, then just execute the given function     object.          [2.x.100]  Using this constructor automatically makes the task object     joinable().    
* [0.x.48]*
     Default constructor. You can't do much with a task object constructed     this way, except for assigning it a task object that holds data created     by the  [2.x.101]  functions.          [2.x.102]  Using this constructor leaves the object in an unjoinable state,     i.e., joinable() will return false.    
* [0.x.49]*
     Join the task represented by this object, i.e. wait for it to finish.         A task can be joined multiple times (while the first join() operation     may block until the task has completed running, all successive attempts     to join will return immediately).         If the operation that was executed on the task with which this     object was initialized throws an exception instead of returning     regularly, then calling the current join() function will first     wait for that task to finish, and then in turn throw the     exception that the task operation had thrown originally. This     allows for the propagation of exceptions from tasks executed on     a separate thread to the calling thread.         (This behavior differs from that of      [2.x.103]      where the  [2.x.104]  function only waits for     completion of the operation, whereas the exception is     propagated only once one calls  [2.x.105]  However,     this is awkward when putting `void` functions onto separate     tasks because these do not actually return anything;     consequently, it is more natural to call  [2.x.106]      for such tasks than the  [2.x.107]  function since the     latter does not, actually, return anything that could be     gotten.)          [2.x.108]  You can't call this function if you have used the default     constructor of this class and have not assigned a task object to it. In     other words, the function joinable() must return true.    
* [0.x.50]*
     Return whether the current object can be joined. You can join a task     object once a task (typically created with  [2.x.109]  has     actually been assigned to it. On the other hand, the function returns     false if the object has been default constructed.         A task can be joined multiple times (while the first join() operation     may block until the task has completed running, all successive attempts     to join will return immediately). Consequently, if this function     returns true, it will continue to return true until the task object it     reports on is assigned to from another object.    
* [0.x.51]*
     Get the return value of the function of the task. Since it is     only available once the thread finishes, this function     internally also calls join(). You can call this function     multiple times as long as the object refers to the same task,     and expect to get the same return value every time. (With the     exception of the case where the returned object has been moved;     see below.)        
*  [2.x.110]  The function returns a [1.x.9] to     the returned object, instead of the returned object. This     allows writing code such as    
* [1.x.10]
*      You will rarely have a need to write such code. On the other hand,     the function needs to return a writable (non- [2.x.111]  reference to     support code such as this:    
* [1.x.11]
*      Here, it is necessary to  [2.x.112]  the returned object (namely,     the  [2.x.113]  object) because      [2.x.114]  objects can not be copied. In other words,     to get the pointer out of the object returned from the task, it needs     to be moved, and in order to be moved, the current function needs to     return a writable (non- [2.x.115]  reference.         This function internally calls the join() member function. As a     consequence, and as explained there, if the packaged task     throws an exception that is then re-thrown by the join()     function and consequently also the current function if you have     not previously called join().          [2.x.116]  You can't call this function if you have used the default     constructor of this class and have not assigned a task object to it. In     other words, the function joinable() must return true.    
* [0.x.52]*
      [2.x.117]  Exceptions      [2.x.118]     
* [0.x.53]*
     Exception    
* [0.x.54]*
     A data structure that holds a  [2.x.119]  into which the task deposits     its return value. Since one can only call  [2.x.120]  once,     we do so in the get() member function and then move the returned object     into the `returned_object` member variable from where we can read it     multiple times and from where it can also be moved away if it is not     copyable.    
* [0.x.55]*
       Constructor. Initializes an  [2.x.121]  object and assumes       that the task so set has not finished yet.      
* [0.x.56]*
       Wait for the  [2.x.122]  object to be ready, i.e., for the       time when the  [2.x.123]  receives its value. If this has       already happened, this function can follow a fast path.      
* [0.x.57]*
       A mutex used to synchronize access to the data structures of this       class.      
* [0.x.58]*
       The promise associated with the task that is represented by the current       class.      
* [0.x.59]*
       A boolean indicating whether the task in question has finished.            
*  [2.x.124]  We are using a  [2.x.125]  here because we have       to make sure that concurrent reads and stores between threads are       properly synchronized, and that sequential reads on a given thread       are not reordered or optimized away. A  [2.x.126]  [1] achieves       this because (if not otherwise annotated) reads and stores to the       boolean are subject to the  [2.x.127]  memory       ordering [2]. This ensures that Schmidt's double checking does       indeed work. For additional information (and a potentially more       efficient implementation) see [3].             [1] https://en.cppreference.com/w/cpp/atomic/atomic       [2] https://en.cppreference.com/w/cpp/atomic/memory_order       [3]       https://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/      
* [0.x.60]*
       The place where the returned value is moved to once the  [2.x.128]        has delivered.      
* [0.x.61]*
     A pointer to a descriptor of the object that described the task     and its return value.    
* [0.x.62]*
   Overload of the new_task function for objects that can be converted to    [2.x.129]  ()>, i.e. anything that can be called like a   function object without arguments and returning an object of type RT (or   void).    
*  [2.x.130]  When  [2.x.131]  returns 1, i.e., if the     deal.II runtime system has been configured to only use one     thread, then this function just executes the given function     object immediately and stores the return value in the Task     object returned by this function.    
*  [2.x.132]   [2.x.133]  is, in essence, equivalent to calling      [2.x.134]  ...)` in that it runs the given task     in the background. See https://en.cppreference.com/w/cpp/thread/async     for more information.    
*  [2.x.135]   
* [0.x.63]*
   Overload of the new_task function for objects that can be called like a   function object without arguments. In particular, this function allows   calling  [2.x.136]  with either objects that result from using    [2.x.137]  or using lambda functions. For example, this function is called   when writing code such as  
* [1.x.12]
*    Here, we schedule the call to the sequence of functions    [2.x.138]  on   a separate task, by making the lambda function declared here the   function to execute on the task. The lambda function then returns   42 (which is a bit pointless here, but it could of course be some   computed number), and this is going to be the returned value you   can later retrieve via  [2.x.139]  once the   task (i.e., the body of the lambda function) has completed.    
*  [2.x.140]  When  [2.x.141]  returns 1, i.e., if the     deal.II runtime system has been configured to only use one     thread, then this function just executes the given function     object immediately and stores the return value in the Task     object returned by this function.    
*  [2.x.142]  Every lambda function (or whatever else it is you pass to     the new_task() function here, for example the result of a      [2.x.143]  expression) has a return type and consequently     returns an object of this type. This type can be inferred     using the C++11  [2.x.144]  statement used in the     declaration of this function, and it is then used as the template     argument of the  [2.x.145]  object returned by the current function.     In the example above, because the lambda function returns 42     (which in C++ has data type  [2.x.146] ), the inferred     type is  [2.x.147]  and the task object will have type      [2.x.148] . In other words, it is not [1.x.13]     to explicitly specify in user code what that return type     of the lambda or  [2.x.149]  expression will be, though it is     possible to explicitly do so by (entirely equivalently) writing    
* [1.x.14]
*     
*  [2.x.150]  In practice, the lambda functions you will pass to     new_task() will of course typically be more complicated.     In particular, they will likely [1.x.15] variables     from the surrounding context and use them within the lambda.     See   https://en.wikipedia.org/wiki/Anonymous_function#C.2B.2B_.28since_C.2B.2B11.29     for more on how lambda functions work.    
*  [2.x.151]  If you pass a lambda function as an argument to the     current function that captures a variable [1.x.16],     or if you use a  [2.x.152]  that binds a function argument to     a reference variable using  [2.x.153]  or  [2.x.154]  then     obviously you can only do this if the variables you reference     or capture have a lifetime that extends at least until the time     where the task finishes.    
*  [2.x.155]   [2.x.156]  is, in essence, equivalent to calling      [2.x.157]  ...)` in that it runs the given task     in the background. See https://en.cppreference.com/w/cpp/thread/async     for more information.    
*  [2.x.158]   
* [0.x.64]*
   Overload of the new_task function for non-member or static member   functions. See the other functions of same name for more information.    
*  [2.x.159]   
* [0.x.65]*
   Overload of the non-const new_task function. See the other functions of   same name for more information.    
*  [2.x.160]   
* [0.x.66]*
   Overload of the new_task function. See the other functions of same name for   more information.    
*  [2.x.161]   
* [0.x.67]*
   A container for task objects. Allows to add new task objects and wait for   them all together. The task objects need to have the same return value   for the called function.     Note that the call to join_all() must be executed on the same thread as   the calls that add subtasks. Otherwise, there might be a deadlock. In   other words, a Task object should never passed on to another task for   calling the join() method.    
*  [2.x.162]   
* [0.x.68]*
     Add another task object to the collection.    
* [0.x.69]*
     Return how many tasks have been put into this group. This     function does not distinguish how many of these tasks have     already run and have finished, are still waiting to be     scheduled to a CPU resource, or are currently running. Tasks     that have been joined already are also still counted.    
* [0.x.70]*
     Wait for all tasks in the collection to finish. It is not a problem if     some of them have already been waited for, i.e. you may call this     function more than once, and you can also add new task objects between     subsequent calls to this function if you want.    
* [0.x.71]*
     List of task objects.    
* [0.x.72]*
  [2.x.163] 

* 
* [0.x.73]