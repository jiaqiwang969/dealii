[0.x.0]*
 A namespace whose main template function supports running multiple threads each of which operates on a subset of the given range of objects. The class uses the Intel Threading Building Blocks (TBB) to load balance the individual subranges onto the available threads. For a lengthy discussion of the rationale of this class, see the  [2.x.0]  "Parallel computing with multiple processors" module. It is used in the tutorial first in  [2.x.1] , and again in  [2.x.2] ,  [2.x.3] ,  [2.x.4]  and others.
*  The class is built on the following premise: One frequently has some work that needs to be done on a sequence of objects; a prototypical example is assembling cell contributions to a system matrix or right hand side. In many such examples, part of the work can be done entirely independently and in parallel, possibly using several processor cores on a machine with shared memory. However, some other part of this work may need to be synchronized and be done in order. In the example of assembling a matrix, the computation of local contributions can be done entirely in parallel, but copying the local contributions into the global matrix requires some care: First, several threads can't write at the same time, but need to synchronize writing using a mutex; secondly, we want the order in which local contributions are added to the global matrix to be always the same because floating point addition is not commutative and adding local contributions to the global matrix in different orders leads to subtly different results that can affect the number of iterations for iterative solvers as well as the round-off error in the solution in random ways. Consequently, we want to ensure that only one thread at a time writes into the global matrix, and that results are copied in a stable and reproducible order.
*  This class implements a framework for this work model. It works with a stream of objects given by an iterator range, runs a worker function in parallel on all of these objects and then passes each object to a postprocessor function that runs sequentially and gets objects in exactly the order in which they appear in the input iterator range. None of the synchronization work is exposed to the user of this class.
*  Internally, the range given to the run() function of this class is split into a sequence of "items", which are then distributed according to some %internal algorithm onto the number of available threads. An item is an element of the range of iterators on which we are to operate; for example, for the purpose of assembling matrices or evaluating error indicators, an item could be a cell. The TBB library determines how many threads are created (typically as many as there are processor cores), but the number of items that may be active at any given time is specified by the argument to the constructor. It should be bigger or equal to the number of processor cores
* 
*  - the default is four times the number of cores on the current system.
*  Items are created upon request by the TBB whenever one of the worker threads is idle or is expected to become idle. It is then handed off to a worker function, typically a member function of a main class. These worker functions are run in parallel on a number of threads, and there is no guarantee that they are asked to work on items in any particular order, in particular not necessarily in the order in which items are generated from the iterator range.
*  Typically, worker functions need additional data, for example FEValues objects, input data vectors, etc, some of which can not be shared among threads. To this end, the run() function takes another template argument, ScratchData, which designates a type objects of which are stored with each item and which threads can use as private data without having to share them with other threads. The run() function takes an additional argument with an object of type ScratchData that is going to be copied for the arguments passed to each of the worker functions.
*  In addition, worker functions store their results in objects of template type CopyData. These are then handed off to a separate function, called copier, that may use the stored results to transfer them into permanent storage. For example, it may copy the results of local contributions to a matrix computed by a worker function into the global matrix. In contrast to the worker function, however, only one instance of the copier is run at any given time; it can therefore safely copy local contributions into the global matrix without the need to lock the global object using a mutex or similar means. Furthermore, it is guaranteed that the copier is run with CopyData objects in the same order in which their associated items were created; consequently, even if worker threads may compute results in unspecified order, the copier always receives the results in exactly the same order as the items were created.
*  Once an item is processed by the copier, it is deleted and the ScratchData and CopyData objects that were used in its computation are considered unused and may be re-used for the next invocation of the worker function, on this or another thread. However, the WorkStream functions make no attempt to reset these objects to any kind of pristine state
* 
*  -  a worker should assume that the CopyData object it gets handed has prior content and clear it first in whatever manner seems appropriate, before putting content into it that can later be processed again by the copier.
*  The member variables in ScratchData and CopyData can be accessed independently of other concurrent uses of copies of these data structures. Therefore, it is perfectly fine to resize auxiliary data structures associated with ScratchData and CopyData to different lengths on each cell. For example, a vector holding densities at each quadrature point which is used with  [2.x.5]  to assemble the local matrix could be resized to the corresponding number of quadrature points of the current cell in DoFHandlers with hp-capabilities. Similarly, local stiffness matrix in CopyData can be resized in accordance with the number of local DoFs on the current cell.
* 

* 
*  [2.x.6]  For integration over cells and faces, it is often useful to use methods more specific to the task than the current function (which doesn't care whether the iterators are over cells, vector elements, or any other kind of range). An implementation of an interface specifically suited to integration is the  [2.x.7]  function.
* 

* 
*  [2.x.8]  The functions in this namespace only really work in parallel when multithread mode was selected during deal.II configuration. Otherwise they simply work on each item sequentially.
* 

* 
*  [2.x.9] 

* 
* [0.x.1]*
   The nested namespaces contain various implementations of the workstream   algorithms.  
* [0.x.2]*
     A namespace for the implementation of details of the WorkStream pattern     and function. This namespace holds classes that deal with the second     implementation described in the paper by Turcksin, Kronbichler and     Bangerth (see      [2.x.10] ).     Here, no coloring is provided, so copying is done sequentially using a     TBB filter.         Even though this implementation is slower than the third implementation     discussed in that paper, we need to keep it around for two reasons: (i)     a user may not give us a graph coloring, (ii) we want to use this     implementation for colors that are just too small.    
* [0.x.3]*
       A class that creates a sequence of items from a range of iterators.      
* [0.x.4]*
         A data type that we use to identify items to be worked on. This is         the structure that is passed around between the different parts of         the WorkStream implementation to identify what needs to be done by         the various stages of the pipeline.        
* [0.x.5]*
           A structure that contains a pointer to a scratch data object           along with a flag that indicates whether this object is currently           in use.          
* [0.x.6]*
             Default constructor.            
* [0.x.7]*
           Typedef to a list of scratch data objects. The rationale for this           list is provided in the variables that use these lists.          
* [0.x.8]*
           A list of iterators that need to be worked on. Only the first           n_items are relevant.          
* [0.x.9]*
           The CopyData objects that the Worker part of the pipeline fills           for each work item. Again, only the first n_items elements are           what we care about.          
* [0.x.10]*
           Number of items identified by the work_items array that the           Worker and Copier pipeline stage need to work on. The maximum           value of this variable will be chunk_size.          
* [0.x.11]*
           Pointer to a thread local variable identifying the scratch data           objects this thread will use. The initial implementation of this           class using thread local variables provided only a single scratch           object per thread. This doesn't work, because the worker           functions may start tasks itself and then call            [2.x.11]  or a similar function, which the           TBB scheduler may use to run something else on the current thread
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 
*  -  for example another instance of the worker function.           Consequently, there would be two instances of the worker function           that use the same scratch object if we only provided a single           scratch object per thread. The solution is to provide a list of           scratch objects for each thread, together with a flag indicating           whether this scratch object is currently used. If a thread needs           a scratch object, it walks this list until it finds an unused           object, or, if there is none, creates one itself. Note that we           need not use synchronization primitives for this process since           the lists are thread-local and we are guaranteed that only a           single thread accesses them as long as we have no yield point in           between the accesses to the list.                     The pointers to scratch objects stored in each of these lists           must be so that they are deleted on all threads when the thread           local object is destroyed. This is achieved by using unique_ptr.                     Note that when a worker needs to create a scratch object, it           allocates it using sample_scratch_data to copy from. This has the           advantage of a first-touch initialization, i.e., the memory for           the scratch data object is allocated and initialized by the same           thread that will later use it.          
* [0.x.12]*
           Pointer to a sample scratch data object, to be used to initialize           the scratch data objects created for each individual thread.          
* [0.x.13]*
           Flag is true if the buffer is used and false if the buffer can be           used.          
* [0.x.14]*
           Default constructor. Initialize everything that doesn't have a           default constructor itself.          
* [0.x.15]*
         Constructor. Take an iterator range, the size of a buffer that can         hold items, and the sample additional data object that will be         passed to each worker and copier function invocation.        
* [0.x.16]*
         Create an item and return a pointer to it.        
* [0.x.17]*
         The interval of iterators still to be worked on. This range will         shrink over time.        
* [0.x.18]*
         A buffer that will store items.        
* [0.x.19]*
         Pointer to a thread local variable identifying the scratch data         objects this thread will use. The initial implementation of this         class using thread local variables provided only a single scratch         object per thread. This doesn't work, because the worker functions         may start tasks itself and then call  [2.x.12]          or a similar function, which the TBB scheduler may use to run         something else on the current thread
* 
*  -  for example another         instance of the worker function. Consequently, there would be two         instances of the worker function that use the same scratch object         if we only provided a single scratch object per thread. The         solution is to provide a list of scratch objects for each thread,         together with a flag indicating whether this scratch object is         currently used. If a thread needs a scratch object, it walks this         list until it finds an unused object, or, if there is none, creates         one itself. Note that we need not use synchronization primitives         for this process since the lists are thread-local and we are         guaranteed that only a single thread accesses them as long as we         have no yield point in between the accesses to the list.                 The pointers to scratch objects stored in each of these lists must         be so that they are deleted on all threads when the thread local         object is destroyed. This is achieved by using unique_ptr.                 Note that when a worker needs to create a scratch object, it         allocates it using sample_scratch_data to copy from. This has the         advantage of a first-touch initialization, i.e., the memory for the         scratch data object is allocated and initialized by the same thread         that will later use it.        
* [0.x.20]*
         A reference to a sample scratch data that will be used to         initialize the thread-local pointers to a scratch data object each         of the worker tasks uses.        
* [0.x.21]*
         Number of elements of the iterator range that each thread should         work on sequentially; a large number makes sure that each thread         gets a significant amount of work before the next task switch         happens, whereas a small number is better for load balancing.        
* [0.x.22]*
       A class that manages calling the worker function on a number of       parallel threads. Note that it is, in the TBB notation, a filter that       can run in parallel.      
* [0.x.23]*
         Constructor. Takes a reference to the object on which we will         operate as well as a pointer to the function that will do the         assembly.        
* [0.x.24]*
         Work on an item.        
* [0.x.25]*
         Pointer to the function that does the assembling on the sequence of         cells.        
* [0.x.26]*
         This flag is true if the copier stage exist. If it does not, the         worker has to free the buffer. Otherwise the copier will do it.        
* [0.x.27]*
       A class that manages calling the copier function. Note that it is, in       the TBB notation, a filter that runs sequentially, ensuring that all       items are copied in the same order in which they are created.      
* [0.x.28]*
         Constructor. Takes a reference to the object on which we will         operate as well as a pointer to the function that will do the         copying from the additional data object to the global matrix or         similar.        
* [0.x.29]*
         Work on a single item.        
* [0.x.30]*
         Pointer to the function that does the copying of data.        
* [0.x.31]*
     A reference implementation without using multithreading to be used if we     don't have multithreading support or if the user requests to run things     sequentially. This is more efficient than using TBB or taskflow if we     only have a single thread.    
* [0.x.32]*
       Sequential version without colors.      
* [0.x.33]*
       Sequential version with colors      
* [0.x.34]*
     A namespace for the implementation of details of the WorkStream pattern     and function. This namespace holds classes that deal with the third     implementation described in the paper by Turcksin, Kronbichler and     Bangerth (see      [2.x.13] ).    
* [0.x.35]*
       A structure that contains a pointer to scratch and copy data objects       along with a flag that indicates whether this object is currently in       use.      
* [0.x.36]*
         Default constructor.        
* [0.x.37]*
       A class that manages calling the worker and copier functions. Unlike       the other implementations, parallel_for is used instead of a       pipeline.      
* [0.x.38]*
         Constructor.        
* [0.x.39]*
         The function that calls the worker and the copier functions on a         range of items denoted by the two arguments.        
* [0.x.40]*
         Typedef to a list of scratch data objects. The rationale for this         list is provided in the variables that use these lists.        
* [0.x.41]*
         Pointer to the function that does the assembling on the sequence of         cells.        
* [0.x.42]*
         Pointer to the function that does the copying from local         contribution to global object.        
* [0.x.43]*
         References to sample scratch and copy data for when we need them.        
* [0.x.44]*
       The colored run function using TBB.      
* [0.x.45]*
   This is one of two main functions of the WorkStream concept, doing work   as described in the introduction to this namespace. It corresponds to   implementation 3 of the paper by Turcksin, Kronbichler and Bangerth, see    [2.x.14] .   As such, it takes not a range of iterators described by a begin and end   iterator, but a "colored" graph of iterators where each color represents   cells for which writing the cell contributions into the global object   does not conflict (in other words, these cells are not neighbors). Each   "color" is represented by  [2.x.15]  of cells. The first argument to   this function, a set of sets of cells (which are represent as a vector of   vectors, for efficiency), is typically constructed by calling    [2.x.16]  See there for more information.     This function that can be used for worker and copier objects that are   either pointers to non-member functions or objects that allow to be   called with an operator(), for example objects created by lambda functions   or  [2.x.17]      The two data types <tt>ScratchData</tt> and <tt>CopyData</tt> need to   have a working copy constructor. <tt>ScratchData</tt> is only used in the   <tt>worker</tt> function, while <tt>CopyData</tt> is the object passed   from the <tt>worker</tt> to the <tt>copier</tt>.     The  [2.x.18]  argument indicates the number of items that can be   live at any given time. Each item consists of  [2.x.19]  elements of   the input stream that will be worked on by the worker and copier   functions one after the other on the same thread.    
*  [2.x.20]  If your data objects are large, or their constructors are   expensive, it is helpful to keep in mind that <tt>queue_length</tt>   copies of the <tt>ScratchData</tt> object and   <tt>queue_length*chunk_size</tt> copies of the <tt>CopyData</tt> object   are generated.    
*  [2.x.21]  In case the copier does not do anything, pass    [2.x.22]  CopyData &)>()` as  [2.x.23]  to make sure   a more efficient algorithm is used internally. It is important, however,   to recognize that the empty function object created above isnot*
   the same as a lambda function with an empty body,   `[](const CopyData &) {}`
* 
*  -  from the perspective of this function,   there is no way to recognize whether a lambda function provided as   a copier does something or does not do something in its body,   and so it needs to be copied. On the other hand, a default-constructed    [2.x.24]  objectcan* be recognized, and is then used to select   a more efficient algorithm.  
* [0.x.46]*
   This is one of two main functions of the WorkStream concept, doing work   as described in the introduction to this namespace. It corresponds to   implementation 2 of the paper by Turcksin, Kronbichler and Bangerth (see    [2.x.25] ).     This function that can be used for worker and copier objects that are   either pointers to non-member functions or objects that allow to be   called with an operator(), for example lambda functions   or objects created by  [2.x.26]  If the copier is an empty function, it is   ignored in the pipeline. (However, a lambda function with an empty body is  not* equivalent to an empty  [2.x.27]  object and will, consequently,   not be ignored.     The argument passed as  [2.x.28]  must be convertible to the same type as  [2.x.29]    begin, but doesn't have to be of the same type itself. This allows to   write code like <code>WorkStream().run(dof_handler.begin_active(),   dof_handler.end(), ...</code> where the first is of type    [2.x.30]  whereas the second is of type    [2.x.31]      The two data types <tt>ScratchData</tt> and <tt>CopyData</tt> need to   have a working copy constructor. <tt>ScratchData</tt> is only used in the   <tt>worker</tt> function, while <tt>CopyData</tt> is the object passed   from the <tt>worker</tt> to the <tt>copier</tt>.     The  [2.x.32]  argument indicates the number of items that can be   live at any given time. Each item consists of  [2.x.33]  elements of   the input stream that will be worked on by the worker and copier   functions one after the other on the same thread.    
*  [2.x.34]  If your data objects are large, or their constructors are   expensive, it is helpful to keep in mind that <tt>queue_length</tt>   copies of the <tt>ScratchData</tt> object and   <tt>queue_length*chunk_size</tt> copies of the <tt>CopyData</tt> object   are generated.    
*  [2.x.35]  In case the copier does not do anything, pass    [2.x.36]  CopyData &)>()` as  [2.x.37]  to make sure   a more efficient algorithm is used internally. It is important, however,   to recognize that the empty function object created above isnot*
   the same as a lambda function with an empty body,   `[](const CopyData &) {}`
* 
*  -  from the perspective of this function,   there is no way to recognize whether a lambda function provided as   a copier does something or does not do something in its body,   and so it needs to be copied. On the other hand, a default-constructed    [2.x.38]  objectcan* be recognized, and is then used to select   a more efficient algorithm.  
* [0.x.47]*
   Same as the function above, but for iterator ranges and C-style arrays.   A class that fulfills the requirements of an iterator range defines the   functions  [2.x.39]  and  [2.x.40]    both of which return iterators to elements that form the bounds of the   range.  
* [0.x.48]*
   Same as the function above, but for deal.II's IteratorRange.  
* [0.x.49]*
   This is a variant of one of the two main functions of the WorkStream   concept, doing work as described in the introduction to this namespace.   It corresponds to implementation 2 of the paper by Turcksin, Kronbichler   and Bangerth (see    [2.x.41] ).     This is the function that can be used for worker and copier functions   that are member functions of a class. If the copier is an empty function,   it is ignored in the pipeline.     The argument passed as  [2.x.42]  must be convertible to the same type as  [2.x.43]    begin, but doesn't have to be of the same type itself. This allows to   write code like <code>WorkStream().run(dof_handler.begin_active(),   dof_handler.end(), ...</code> where the first is of type    [2.x.44]  whereas the second is of type    [2.x.45]      The  [2.x.46]  argument indicates the number of items that can be   live at any given time. Each item consists of  [2.x.47]  elements of   the input stream that will be worked on by the worker and copier   functions one after the other on the same thread.    
*  [2.x.48]  If your data objects are large, or their constructors are   expensive, it is helpful to keep in mind that <tt>queue_length</tt>   copies of the <tt>ScratchData</tt> object and   <tt>queue_length*chunk_size</tt> copies of the <tt>CopyData</tt> object   are generated.    
*  [2.x.49]  In case the copier does not do anything, pass    [2.x.50]  CopyData &)>()` as  [2.x.51]  to make sure   a more efficient algorithm is used internally. It is important, however,   to recognize that the empty function object created above isnot*
   the same as a lambda function with an empty body,   `[](const CopyData &) {}`
* 
*  -  from the perspective of this function,   there is no way to recognize whether a lambda function provided as   a copier does something or does not do something in its body,   and so it needs to be copied. On the other hand, a default-constructed    [2.x.52]  objectcan* be recognized, and is then used to select   a more efficient algorithm.  
* [0.x.50]*
   Same as the function above, but for iterator ranges and C-style arrays.   A class that fulfills the requirements of an iterator range defines the   functions  [2.x.53]  and  [2.x.54]    both of which return iterators to elements that form the bounds of the   range.  
* [0.x.51]*
   Same as the function above, but for deal.II's IteratorRange.  
* [0.x.52]