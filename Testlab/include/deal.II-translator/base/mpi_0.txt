include/deal.II-translator/base/mpi_0.txt
[0.x.0]*
 帮助性宏，用于从一些MPI_*的指针参数中移除const。
 函数的指针参数中删除const。
* 这是需要的，因为像MPI_Allgather()这样的函数的输入参数在OpenMPI 1.6.5中没有标记为const。如果使用MPI 3或更新的版本，这个宏是一个NOOP，而我们在其他情况下做以下工作。
* 1.从[2.x.0]的类型中移除 2.从结果类型中移除const 3.添加到结果类型中 4.将给定的表达式[2.x.1]const_cast到这个新类型中。

* 
* [0.x.1]*
   给出元素总数[2.x.2]，为整个[2.x.3]的元素创建一个均匀分布的1:1分区，本地大小将等于[2.x.4]除以分区的数量，再加上余下的部分在第一个进程中分配。每个进程将存储一个连续的索引子集，进程p+1上的索引集从比进程p上存储的最后一个索引大的索引开始。例如，一个[2.x.5]为11的3个进程将产生索引集{ [0,4), [4,8), [8,11)] }，这个函数将返回[2.x.6] 的索引集。 
* [0.x.2]*
   一个命名空间，用于抽象使用消息传递接口（MPI）的某些操作，或者在deal.II被配置为完全不使用MPI的情况下提供后备操作的实用函数。   
* [2.x.7]   
* [0.x.3]*
     返回给定的[2.x.8]"communicator "对象中存在的MPI进程的数量。如果这是一个顺序作业（即，程序根本没有使用MPI，或者使用了MPI但只启动了一个MPI进程），那么通信器必然只涉及一个进程，函数返回1。   
* [0.x.4]*
     返回[2.x.9]"当前MPI进程在给定的[2.x.10]"通信器 "所描述的进程空间中的等级。    这将是每个进程的唯一值，介于0和（小于）所有进程的数量（由get_n_mpi_processes()给出）之间。   
* [0.x.5]*
     返回一个行列向量（在[2.x.11]指定的进程子集的[2.x.12]内）。    
* [0.x.6]*
     考虑一个非结构化的通信模式，MPI宇宙中的每个进程都想向其他进程的一个子集发送一些数据。要做到这一点，其他处理器需要知道从谁那里期待消息。这个函数可以计算这个信息。         [2.x.13] mpi_comm 一个[2.x.14] "通信器"，描述要相互通信的处理器。         [2.x.15] destinations 当前进程想要发送信息的处理器列表。这个列表不需要以任何方式进行排序。如果它包含重复的条目，那就意味着有多条信息是要发给某个目的地的。         [2.x.16] 已表示要向当前处理器发送东西的处理器的列表。由此产生的列表没有被排序。    如果处理器在其目的地列表中多次输入同一个目的地，它可能包含重复的条目。   
* [0.x.7]*
     compute_point_to_point_communication_pattern()的简化版本（为了提高效率），它只计算MPI宇宙中期待通信的进程数。         [2.x.17] mpi_comm 一个[2.x.18]"通信器"，描述要相互通信的处理器。         [2.x.19] destinations 当前进程想要发送信息的处理器的列表。这个列表不需要以任何方式进行排序。如果它包含重复的条目，那就意味着有多条信息是要发给某个目的地的。         [2.x.20]想要向当前处理器发送东西的处理器的数量。   
* [0.x.8]*
     给定一个[2.x.21]"通信器"，生成一个新的通信器，该通信器包含相同的处理器集合，但有一个不同的、唯一的标识。        这个功能可以用来确保不同的对象，如分布式矩阵，都有唯一的通信器，它们可以在上面进行交互而不互相干扰。        当不再需要时，这里创建的通信器需要用free_communicator()来销毁。        这个函数等同于调用 [2.x.22] 。   
* [0.x.9]*
     释放给定的[2.x.23]"通信器"[2.x.24]，该通信器是使用diplicate_communicator()复制的。        参数是通过引用传递的，并且将被无效化并设置为MPI空手柄。这个函数等同于调用 [2.x.25] 。   
* [0.x.10]*
     帮助类，用于自动复制和释放MPI [2.x.26] "communicator"。        这个类使用diplicate_communicator()复制构造函数中给出的通信器，并在这个对象被销毁时通过调用free_communicator()自动释放它。你可以使用operator*来访问被包裹的通信器。        这个类的存在是为了轻松地允许复制通信器，而不必担心使用后何时以及如何释放它。   
* [0.x.11]*
       创建一个给定的[2.x.27]的复制品。      
* [0.x.12]*
       不允许制作副本。     
* [0.x.13]*
       解构器会自动释放通讯器。     
* [0.x.14]*
       访问存储的通信器。     
* [0.x.15]*
       不允许对这个类进行赋值。     
* [0.x.16]*
       当然的通讯器。     
* [0.x.17]*
     这个类代表一个mutex，在使用MPI的并行计算中为一组处理器守卫一个关键部分。        lock()命令会等待，直到通信器中的所有MPI等级都使用unlock()释放了之前的锁。        一个典型的用法是使用锁防护来守护一个关键部分。   
* [1.x.0]
* 这里，关键代码将在所有处理器上完成，然后才能再次获得mutex（例如通过第二次执行上面的块。关键代码块通常涉及MPI通信，如果没有锁，会产生不正确的结果。例如，如果代码包含具有MPI_ANY_SOURCE的非阻塞接收，数据包在迭代之间可能会被混淆。        请注意，在调用同一关键区域之间，mutex需要是同一个实例。虽然不是必须的，但这可以通过使实例静态化来实现（就像上面的例子）。该变量也可以是一个全局变量，或执行函数所属对象的成员变量。   
* [0.x.18]*
       这个辅助类为CollectiveMutex提供了一个范围内的锁。            详见CollectiveMutex的类文档。     
* [0.x.19]*
         构造函数。阻塞直到它能获得锁。       
* [0.x.20]*
         销毁器。释放锁。       
* [0.x.21]*
         对mutex的引用。       
* [0.x.22]*
         通信器。       
* [0.x.23]*
       该类的构造函数。     
* [0.x.24]*
       销毁mutex。假设当前没有持有锁。     
* [0.x.25]*
       获取mutex，如果有必要，等待我们可以这样做。            这是一个集体调用，需要由通信器中的所有处理器来执行。     
* [0.x.26]*
       释放锁。            这是一个集体调用，需要由通信器中的所有处理器来执行。     
* [0.x.27]*
       保持跟踪，如果我们现在有这个锁。     
* [0.x.28]*
       追踪非阻塞屏障的请求。     
* [0.x.29]*
     如果[2.x.28]是一个内部通信器，这个函数返回一个新的通信器[2.x.29]，其通信组由[2.x.30]参数定义。该函数只对实际想要创建通信器的进程组进行集合，即在[2.x.31]参数中被命名的进程。如果一个给定进程的多个线程同时执行create_group()操作，用户必须通过提供不同的[2.x.32]或[2.x.33]参数来区分这些操作。        这个函数是在MPI-3.0标准中引入的。如果可用，则使用所提供的MPI实现中的相应函数。    否则，该实现遵循以下出版物中描述的实现。   
* [1.x.1]
*     
* [0.x.30]*
     考虑到本地拥有的元素数量[2.x.34]，在整个MPI通信器中创建一个1:1的元素分区[2.x.35]，元素的总大小是整个MPI通信器中[2.x.36]的总和。 每个进程将存储连续的索引子集，进程p+1上的索引集从比进程p上存储的最后一个索引大的一个索引开始。   
* [0.x.31]*
     给定元素总数 [2.x.37] 在MPI通信器上创建一个均匀分布的1:1的元素分区 [2.x.38] 使用 [2.x.39] 来确定分区数量和处理器ID，以调用上述 [2.x.40] 函数。   
* [0.x.32]*
     计算整个MPI通信器[2.x.41]的平均值和标准偏差，提供的数值为一个范围`[begin,end)`。    平均值计算为[2.x.42]，其中[2.x.43]是所有处理器上的`begin'和`end'迭代器所指向的元素（即，每个处理器的`[begin,end]范围指向整体元素数量的一个子集）。标准偏差的计算方法是[2.x.44] ，这被称为无偏的样本方差。         [2.x.45] Number指定了存储均值的类型。    标准偏差被存储为相应的实数类型。    例如，这允许从整数输入值计算统计数据。   
* [0.x.33]*
     返回所有处理器上的数值之和 [2.x.46] 这个函数是在[2.x.47]"通信器 "中给出的所有处理器上的集体。    如果deal.II没有被配置为使用MPI，这个函数只是返回 [2.x.48] 这个函数对应于 [2.x.49] 函数，即所有处理器都收到这个操作的结果。       
* [2.x.50] 有时，并非所有处理器都需要一个结果，在这种情况下，人们会调用[2.x.51]函数而不是[2.x.52]函数。后者的费用最多是前者的两倍，所以如果你关心性能，可能值得调查一下你的算法是否确实到处需要结果。       
* [2.x.53] 这个函数只对某些模板参数实现 [2.x.54] 。   
* [0.x.34]*
     和前面的函数一样，但是对T类型的数组的元素进行求和。换句话说，结果数组的第i个元素是每个处理器的输入数组的第i个条目之和。T和U必须衰减到相同的类型，例如，它们的区别只是其中一个有const类型限定符，另一个没有。        输入和输出数组可以是相同的。   
* [0.x.35]*
     和前面的函数一样，但是要对ArrayView参数指定的数组元素进行求和。    换句话说，结果数组的第i个元素是每个处理器的输入数组的第i个条目之和。        输入和输出数组可以是相同的。   
* [0.x.36]*
     对一个对称张量的条目进行MPI求和。         [2.x.55] SymmetricTensor    
* [0.x.37]*
     对一个张量的条目进行MPI求和。         [2.x.56] 张量    
* [0.x.38]*
     对稀疏矩阵的条目进行MPI求和。       
* [2.x.57] [2.x.58] 和 [2.x.59] 应该具有相同的稀疏模式，而且对所有MPI进程都应该是相同的。         [2.x.60] 稀疏矩阵    
* [0.x.39]*
     返回所有处理器上的最大值 [2.x.61] 这个函数是在[2.x.62] "通信器 "中给出的所有处理器上的集合。    如果deal.II没有被配置为使用MPI，这个函数只是返回[2.x.63]的值，这个函数对应于[2.x.64]函数，即所有处理器都收到这个操作的结果。       
* [2.x.65] 有时，并非所有处理器都需要一个结果，在这种情况下，人们会调用[2.x.66]函数而不是[2.x.67]函数。后者的费用最多是前者的两倍，所以如果你关心性能，可能值得调查一下你的算法是否确实到处需要结果。       
* [2.x.68] 这个函数只对某些模板参数实现 [2.x.69] 。   
* [0.x.40]*
     和前面的函数一样，但是在一个T类型的数组的元素上取最大值。换句话说，结果数组的第i个元素是每个处理器的输入数组的第i个条目的最大值。T和U必须衰减到相同的类型，例如，它们的区别只是其中一个有const类型限定符，另一个没有。        输入和输出向量可以是相同的。   
* [0.x.41]*
     和前面的函数一样，但在ArrayView参数指定的数组元素上取最大值。    换句话说，结果数组的第i个元素是每个处理器的输入数组的第i个条目上的最大值。        输入和输出数组可以是相同的。   
* [0.x.42]*
     返回所有处理器上的最小值 [2.x.70] 这个函数是在[2.x.71]"通信器 "中给出的所有处理器上的集合。    如果deal.II没有被配置为使用MPI，这个函数只是返回 [2.x.72] 这个函数对应于 [2.x.73] 函数，即所有处理器都收到这个操作的结果。       
* [2.x.74] 有时，并非所有处理器都需要一个结果，在这种情况下，人们会调用[2.x.75]函数而不是[2.x.76]函数。后者的费用最多是前者的两倍，所以如果你关心性能，可能值得调查一下你的算法是否确实到处需要结果。       
* [2.x.77] 这个函数只对某些模板参数实现 [2.x.78] 。   
* [0.x.43]*
     和前面的函数一样，但在一个T类型的数组的元素上取最小值。换句话说，结果数组的第i个元素是每个处理器的输入数组的第i个条目的最小值。T和U必须衰减到相同的类型，例如，它们的区别只是其中一个有const类型限定符，另一个没有。        输入和输出数组可以是相同的。   
* [0.x.44]*
     和前面的函数一样，但是在ArrayView参数指定的数组元素中取最小值。    换句话说，结果数组的第i个元素是每个处理器的输入数组的第i个条目上的最小值。        输入和输出数组可以是相同的。   
* [0.x.45]*
     在数值为[2.x.79]的所有处理器上执行[1.x.2]的操作。 [1.x.3]操作符`||`如果任一或所有操作数为`真'，则返回布尔值`真'，否则返回`假`。如果提供的值[2.x.80]在其相关的数据类型`T`中对应于`0`，它将被解释为`false`，否则为`true`。数据类型`T`必须是`integral`类型，即`bool`、`char`、`short`、`int`、`long`，或它们的任何变化。        这个函数是在[2.x.81]"通信器 "中给出的所有处理器上的集体。    如果deal.II没有被配置为使用MPI，这个函数只是返回[2.x.82]的值，这个函数对应于[2.x.83]函数，即所有处理器都收到这个操作的结果。       
* [2.x.84] 有时，并非所有处理器都需要一个结果，在这种情况下，人们会调用[2.x.85]函数而不是[2.x.86]函数。后者的费用最多是前者的两倍，所以如果你关心性能，可能值得调查一下你的算法是否确实到处需要结果。   
* [0.x.46]*
     和前面的函数一样，但是对数组中的每个元素执行[1.x.4]操作。换句话说，结果数组的第i个元素是对每个处理器的输入数组的第i个条目应用[1.x.5]操作的结果。T和U必须衰减到相同的类型，例如，它们只是因其中一个有const类型限定符而另一个没有而不同。        输入和输出数组可以是相同的。       
* [2.x.87] 根据你的标准库，这个函数可能无法与数据类型`bool`的[2.x.88]的特殊化一起工作。在这种情况下，请使用一个不同的容器或数据类型。   
* [0.x.47]*
     和前面的函数一样，但是对ArrayView参数指定的数组中的每个元素执行[1.x.6]操作。    换句话说，结果数组的第i个元素是对每个处理器的输入数组的第i个条目应用[1.x.7]操作的结果。        输入和输出数组可以是相同的。   
* [0.x.48]*
     一个数据结构用于存储min_max_avg()函数的结果。    该结构存储由参与[2.x.89]"MPI通信器 "的每个处理器贡献的一个值的最小值、最大值和平均值。    该结构还存储持有最小值和最大值的处理器的索引（或者更准确地说，是[2.x.90]"MPI等级"），以及所有数值的总和。       
* [2.x.91] 这个结构没有构造函数，因为MPI要求它是一个POD类型。   
* [0.x.49]*
       参与调用min_max_avg()的处理器贡献的所有值的总和。     
* [0.x.50]*
       参与调用min_max_avg()的处理器贡献的所有数值的最小值。     
* [0.x.51]*
       参与调用min_max_avg()的处理器贡献的所有数值的最大值。     
* [0.x.52]*
       持有最小值的处理器的等级之一（即[2.x.92]"MPI通信器 "中的[2.x.93]"MPI等级"）。     
* [0.x.53]*
       持有最大值的处理器的等级之一（即[2.x.94]"MPI通信器 "内的 "MPI等级"）。     
* [0.x.54]*
       参与调用min_max_avg()的处理器所贡献数值的平均值。     
* [0.x.55]*
     在给定的MPI [2.x.96] "communicator" [2.x.97] 的集体操作中，返回总和、平均值、最小值、最大值、最小和最大值的处理器ID，并将返回结果。该结果在所有机器上都可用。       
* [2.x.99] 有时，并非所有处理器都需要结果，在这种情况下，人们会调用[2.x.100]函数而不是[2.x.101]函数。后者最多只有两倍的费用，所以如果你关心性能，可能值得调查一下你的算法是否确实到处需要结果。   
* [0.x.56]*
     与上述相同，但在给定的MPI [2.x.102] "communicator" [2.x.103]上对向量的每个条目返回总和、平均数、最小值、最大值、最小和最大值的进程ID作为集体操作。       
* [2.x.104] 该函数执行一次缩减扫频。         [2.x.105] 输入向量的大小在所有进程中必须是相同的。   
* [0.x.57]*
     和上面一样，但是在给定的MPI [2.x.106] "communicator" [2.x.107] 上对ArrayView的每个条目返回sum, average, minimum, maximum, process id of minimum and maximum作为一个集体操作。       
* [2.x.108] 该函数执行一次缩减扫频。         [2.x.109] 输入ArrayView的大小在所有进程中必须是相同的，并且输入和输出ArrayVew必须有相同的大小。   
* [0.x.58]*
     一个用于在程序开始时初始化MPI系统并在程序结束时再次关闭的类。它还允许你控制每个MPI进程中使用的线程数量。        如果deal.II配置了PETSc，PETSc将在开始时通过`PetscInitialize`初始化（该类的构造函数），在结束时通过`PetscFinalize`去初始化（即在该类的析构函数中）。这对SLEPc来说也是如此。        如果deal.II配置了p4est，该库也将在开始时被初始化，并在结束时被解除初始化（通过调用sc_init(), p4est_init(), 和sc_finalize()）。        如果一个程序使用MPI，通常只需在 [2.x.110] 的开头创建一个这种类型的对象。然后，这个类的构造函数带着给定的参数运行[2.x.111]，同时初始化上面提到的其他库。在程序结束时，编译器将调用这个对象的析构器，反过来调用[2.x.112]来关闭MPI系统。        这个类在[2.x.113]、[2.x.114]、[2.x.115]、[2.x.116]和其他一些地方使用。       
* [2.x.117] 该类通过`MPI_COMM_WORLD`通信器执行MPI子系统以及上面列出的依赖库的初始化。这意味着你必须在[1.x.8]MPI进程上创建一个MPI_InitFinalize对象，无论你是否打算在特定的处理器上使用deal.II。在大多数使用情况下，人们当然希望使用基本相同的程序在所有MPI进程上工作，因此这不是一个问题。但是如果你计划只在MPI进程的一个子集上运行基于deal.II的工作，使用@ ref GlossMPICommunicator "MPI communicator"，它是`MPI_COMM_WORLD`的一个子集（例如，在客户-服务器设置中，只有一个子集的进程负责有限元通信，其余进程做其他事情），那么你仍然需要在程序开始时在所有MPI进程中创建这个对象，因为它在初始化时使用`MPI_COMM_WORLD`。   
* [0.x.59]*
       初始化MPI（如果deal.II被配置为使用它，则初始化PETSc），并将deal.II使用的线程数（通过底层的线程构件库）设置为给定参数。             [2.x.118] argc 对传递给main的'argc'参数的引用。这个参数用于初始化MPI（可能还有PETSc），因为它们从命令行读取参数。       [2.x.119] argv 对传递给main的'argv'参数的引用。       [2.x.120] max_num_threads 这个MPI进程应该利用的最大线程数。如果这个参数被设置为[2.x.121]（默认值），那么线程的数量将以如下方式自动确定：在这个MPI进程上运行的线程数量是以你的节点上所有的核心都被使用的方式设置的。换句话说，如果你在每个节点上启动了一个MPI进程，设置这个参数就相当于把它设置为这个MPI进程所运行的节点上的核心数。如果你在每个节点上启动的MPI进程与每个节点上的核数一样多，那么这就相当于将1作为参数传递。另一方面，例如，如果你在每个16核节点上启动4个MPI进程，那么这个选项将为每个节点启动4个工作线程。如果你在一个8核节点上启动3个进程，那么它们将分别启动3、3和2个线程。           
* [2.x.122] 这个函数用[2.x.124]或者按照上面的讨论，用等于分配给这个MPI进程的核数的线程数调用[2.x.123]。然而，[2.x.125]反过来也评估了环境变量DEAL_II_NUM_THREADS。最后，工作线程只能在当前MPI进程可以访问的核上创建；一些MPI实现将每个进程可以访问的核数量限制在一个或一个子集上，以确保更好的缓存行为。因此，真正被创建的线程数将是这里传递的参数、环境变量（如果设置了）和线程可访问的核心数的最小值。           
* [2.x.126] [2.x.127]只有在创建任何线程之前调用它才能发挥作用。因此，对它的调用最安全的地方是在 [2.x.128] 的开头。      因此，这延伸到了当前的类：创建这种类型的对象的最佳位置也是在 [2.x.129] 的顶部或接近顶部。     
* [0.x.60]*
       解构器。在该类拥有MPI进程的情况下调用<tt>MPI_Finalize()</tt>。     
* [0.x.61]*
       注册一个MPI_Request的引用，在调用`MPI_Finalize'之前，我们需要对其调用`MPI_Wait'。            当MPI_Finalize被调用时，该对象[2.x.130]需要存在，这意味着该请求通常是静态分配的。否则，你需要在请求超出范围之前调用unregister_request()。注意，一个请求已经被等待（并因此被重置为MPI_REQUEST_NULL）是可以接受的。            在同一个实例中多次调用这个函数是可以接受的（就像下面的例子中所做的）。            通常情况下，这个函数被CollectiveMutex使用，而不是直接使用，但它也可以像这样直接使用。     
* [1.x.9]
*       
* [0.x.62]*
       取消先前使用register_request()添加的请求的注册。     
* [0.x.63]*
       一个具有[2.x.131]对象的结构，用于注册MPI init或finalize之后的回调运行。            关于信号的文档，见http://www.boost.org/doc/libs/release/libs/signals2 。     
* [0.x.64]*
         在我们用[2.x.132]初始化MPI上下文后立即触发的信号。       
* [0.x.65]*
         一个在我们用 [2.x.133] 关闭MPI上下文之前触发的信号。它可用于在调用 [2.x.134] 之前取消静态分配的MPI资源，这些资源需要被取消分配。       
* [0.x.66]*
       在最终确定之前对MPI_Wait的请求      
* [0.x.67]*
     返回(i)deal.II是否已被编译为支持MPI（例如用[2.x.135]编译），如果是，是否(ii)[2.x.136]已被调用（例如使用[2.x.137]类）。换句话说，该结果表明当前作业是否在MPI下运行。       
* [2.x.138]该函数没有考虑到一个MPI作业是否实际运行在一个以上的处理器上，或者实际上是一个恰好在MPI下运行的单节点作业。   
* [0.x.68]*
     发起一个某某通信，并在处理器之间交换任意对象（类T应该是可序列化的，使用[2.x.139]。         [2.x.140] comm MPI通信器。         [2.x.141] objects_to_send 从意在接收数据的进程的等级（无符号int）和要发送的对象的映射（类型`T`必须是可序列化的，这个函数才能正常工作）。如果这个映射包含一个键值等于当前进程等级的条目（即一个向进程发送数据给自己的指令），那么这个数据项就被简单地复制到返回的对象中。         [2.x.142]从发送数据的进程的等级（无符号int）和收到的对象的映射。   
* [0.x.69]*
     经典MPI_Allgather函数的泛化，它接受任意的数据类型T，只要[2.x.143]接受T作为参数。         [2.x.144] comm MPI通信器。     [2.x.145] object_to_send 一个要发送给所有其他进程的对象 [2.x.146] 一个对象的向量，其大小等于MPI通信器中的进程数。每个条目包含从处理器收到的对象，在通信器中具有相应的等级。   
* [0.x.70]*
     经典MPI_Gather函数的泛化，它接受任意的数据类型T，只要[2.x.147]接受T作为参数。         [2.x.148] comm MPI通信器。     [2.x.149] object_to_send 一个要发送给根进程的对象 [2.x.150] root_process 进程，它接收来自所有进程的对象。默认情况下，等级为0的进程是根进程。         [2.x.151] [2.x.152] 接收一个对象的向量，其大小等于MPI通信器中的进程数。每个条目包含从通信器中具有相应等级的处理器接收的对象。所有其他进程收到一个空的向量。   
* [0.x.71]*
     从进程[2.x.154]发送一个对象[2.x.153]到所有其他进程。        经典的`MPI_Bcast`函数的泛化，接受任意的数据类型`T`，只要[2.x.155]（它反过来使用[2.x.156]，详见[2.x.157]）接受`T`作为参数。         [2.x.158] comm MPI通信器。     [2.x.159] object_to_send 一个要发送给所有进程的对象。     [2.x.160] root_process 向所有进程发送对象的进程。默认情况下，等级为0的进程是根进程。         [2.x.161] 在根进程上，返回一份 [2.x.162] 在其他每个进程上，返回一份由 [2.x.163] 发送的对象的副本。    
* [0.x.72]*
     一个通过用户指定的二进制操作[2.x.165]在[2.x.166]上结合所有进程的值[2.x.164]的函数，因此，这个函数类似于MPI_Reduce（和[2.x.167]然而，一方面由于用户指定的二进制操作，它对内置类型较慢，但另一方面，可以处理一般对象类型，包括存储可变数量数据的对象。        与all_reduce相反，结果将只在单一等级上可用。在所有其他进程中，返回值是未定义的。   
* [0.x.73]*
     一个通过用户指定的二进制操作[2.x.169]将所有进程的值[2.x.168]结合起来并将结果分配给所有进程的函数。因此，这个函数类似于MPI_Allreduce（如果它是由一个全局还原和一个广播步骤实现的），但由于用户指定的二进制操作，也可以处理一般的对象类型，包括那些存储可变数量的数据的对象。   
* [0.x.74]*
     给定一个分割的索引集空间，根据分割的索引集，计算第二个索引集的每个元素的自有MPI进程等级。这个函数的一个自然用法是为每个鬼魂的自由度计算拥有该索引的进程的MPI等级。        人们可能会想："但是我们知道一个鬼魂自由度属于哪个等级，基于它所在单元的子域ID"。但是这种启发式方法对于不同子域ID的幽灵单元之间的接口上的DoF，或者幽灵单元和人工单元之间的接口上的DoF是失败的。此外，这个函数可以实现完全抽象的信息交换，而不需要借助于网格中的邻居。        传给这个函数的第一个参数，[2.x.170]必须在所有进程之间唯一地划分一个索引空间。    否则，对这个参数没有任何限制。特别是，没有必要将索引空间划分为连续的子集。此外，对第二个索引集[2.x.171]没有任何限制，只要其大小与第一个索引集相符。它可以在每个进程上任意独立选择。在第二个索引集也包含本地拥有的索引的情况下，这些索引将被正确处理，并为这些条目返回本进程的等级。       
* [2.x.172] 这是一个集体操作：给定通信器内的所有进程都必须调用这个函数。由于这个函数不使用MPI_Alltoall或MPI_Allgather，而是使用非阻塞的点对点通信来代替，并且只使用一个非阻塞的屏障，所以它大大减少了内存消耗。这个函数适合于具有>100k MPI行列的大规模模拟。         [2.x.173] owned_indices 指数集，包含本进程本地拥有的指数。     [2.x.174] indices_to_look_up 包含用户对拥有的进程的等级感兴趣的指数的索引集。     [2.x.175] comm MPI通信器。         [2.x.176] 包含索引集中每个条目的MPI进程等级的列表 [2.x.177] 顺序与ElementIterator中的顺序相吻合。   
* [0.x.75]*
     计算MPI通信器中所有进程的输入向量[2.x.178]的联合[2.x.179] 。        
* [2.x.180] 这是一个集体操作。其结果将在所有进程中可用。   
* [0.x.76]*
     与上述相同，但对[2.x.181]而言。    
* [0.x.77]

