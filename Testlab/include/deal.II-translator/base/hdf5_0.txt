include/deal.II-translator/base/hdf5_0.txt
[0.x.0]*
 包含deal.II的HDF5接口的命名空间。
* [层次数据格式（HDF）]（https://www.hdfgroup.org/）是一种跨平台和高I/O性能的格式，旨在存储大量的数据。它支持串行和MPI I/O访问。这组类提供了一个与[HDF5库](https://www.hdfgroup.org/downloads/hdf5/)的接口。
* 教程[2.x.0]展示了如何使用deal.II的HDF5接口。
* # 组、数据集和属性 一个HDF5文件被组织在[组](https://bitbucket.hdfgroup.org/pages/HDFFV/hdf5doc/master/browse/html/UG/HDF5_Users_Guide-Responsive%20HTML5/HDF5_Users_Guide/Groups/HDF5_Groups.htm)和[数据集](https://bitbucket.hdfgroup.org/pages/HDFFV/hdf5doc/master/browse/html/UG/HDF5_Users_Guide-Responsive%20HTML5/HDF5_Users_Guide/Datasets/HDF5_Datasets.htm)中。组可以包含数据集和其他组。数据集是由数据元素的集合组成的对象。数据集等同于张量和矩阵。此外，属性可以被附加到根文件、组或数据集。一个[HDF5属性]（https://bitbucket.hdfgroup.org/pages/HDFFV/hdf5doc/master/browse/html/UG/HDF5_Users_Guide-Responsive%20HTML5/HDF5_Users_Guide/Attributes/HDF5_Attributes.htm）是一个小型的元数据。方法[2.x.1]和[2.x.2]可以用来获取和设置属性。
* 一个例子显示如下

* 
* [1.x.0]
* 
* # MPI I/O 一个HDF5文件可以用串行（一个单一进程）或MPI支持（几个进程访问同一个HDF5文件）来打开/创建。 [2.x.3] [2.x.4] &, const FileAccessMode）为串行操作打开/创建一个HDF5文件。 [2.x.5] [2.x.6] &, const FileAccessMode, const MPI_Comm &) 使用MPI并行地创建或打开一个HDF5文件。修改文件结构的HDF5调用总是集体进行的，而数据集中的原始数据的写入和读取可以独立进行，也可以集体进行。[集体访问通常更快](https://www.hdfgroup.org/2015/08/parallel-io-with-hdf5/)，因为它允许MPI进行优化。在deal.II的HDF5接口中，为了最大限度地提高性能，所有的调用都被设置为集体调用。这意味着所有的MPI进程都必须对每一次调用做出贡献，即使他们没有数据需要写入。MPI HDF5要求deal.II和HDF5已经被编译为MPI支持。
* ## 写一个并行的hyperslab Hyperslab是数据集的一部分。一个hyperslab可以是一个数据集中连续的点的集合，也可以是一个数据集中有规律的点或块的模式。Hyperslabs等同于python numpy和h5py [slices](http://docs.h5py.org/en/latest/high/dataset.html#reading-writing-data)。参见HDF5用户指南中的[1.x.1]部分。也可参见[1.x.2]。
* 下面的例子显示了如何编写一个简单的矩形超文本。偏移量定义了原始数据集中超文本的原点。超文本的尺寸是`hyperslab_dimensions = {2, 5}`。注意，每个进程可以写一个不同尺寸的超文本。如果一个进程根本不写任何数据，该进程应该调用函数[2.x.7]，因为该操作是集体的*，所有MPI进程都必须为该调用作出贡献，即使它们没有数据可写。

* 
* [1.x.3]
* 
* 函数[2.x.8] Container &,const [2.x.9] &, const [2.x.10] &)用于写简单的超板，函数[2.x.11] Container &,const [2.x.12] &, const [2.x.13] &, const [2.x.14] &, const [2.x.15] &, const [2.x.16] &)用于写复杂超板。
* ##并行写入无序数据 下面的例子显示了如何写入一个选择的数据。请注意，每个进程可以写入不同数量的数据。如果一个进程根本不写任何数据，该进程应该调用函数[2.x.17]，因为该操作是collective*，所有的MPI进程都必须为该调用作出贡献，即使他们没有数据可写。一个更详细的例子可以在[2.x.18]中找到。

* 
* [1.x.4]
* 
* ## 查询HDF5在最后一次并行I/O调用中使用的I/O模式 在deal.II的HDF5 C++接口中，默认的访问模式是集体访问，这通常会更快，因为它允许MPI做更多的优化。在某些情况下，比如有类型转换时，HDF5库可以决定做独立的I/O而不是集体I/O，即使用户要求集体I/O。参见下面的[文章]（https://www.hdfgroup.org/2015/08/parallel-io-with-hdf5/）。在需要最大性能的情况下，确保所有的MPI读/写操作都是集体的，这很重要。HDF5库提供了API例程，可以在读/写I/O操作之后使用，以查询I/O模式。如果[2.x.19]为True，那么在每次读/写操作之后，deal.II的HDF5接口都会调用例程[H5Pget_mpio_actual_io_mode()](https://support.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-GetMpioActualIoMode)和[H5Pget_mpio_no_collective_cause()](https://support.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-GetMpioNoCollectiveCause) 。结果存储在 [2.x.20] [2.x.21] 和 [2.x.22] 我们建议只在调试模式下查询I/O模式，因为它需要调用额外的HDF5程序。
* 以下代码可用于查询I/O方式。

* 
* [1.x.5]
* 
* 如果写操作是集体的，那么输出应该是

* 
* [1.x.6]
* 参见[2.x.23] [2.x.24] 和 [2.x.25] 所有可能的返回代码。
* # HDF5数据集和hyperslabs的等级 deal.II的HDF5接口可以用来向任何特定等级的数据集和hyperslabs写入/读取数据。`FullMatrix`只能用于向等级为2的数据集和超文本写入/读取数据。另一方面，[2.x.26]和`Vector`可以用来向等级为1、2、3和更高的数据集和hyperslab写/读数据，数据是按照C和C++矩阵中常用的[row-major order]（https://en.wikipedia.org/wiki/Row-_and_column-major_order）组织的。我们可以用[2.x.27]重写上一节的代码 

* 
* [1.x.7]
* 前面的代码写出了以下的超简约矩阵

* 
* [1.x.8]
* 
* # 数据类型 属性数据类型可以是float, `double`, [2.x.28] [2.x.29] `int`, `unsigned int`, `bool`和 [2.x.30] [2.x.31] 和 [2.x.32] 可以使用所有这些数据类型。
* 数据集数据类型可以是`float`，`double`， [2.x.33] [2.x.34] `int`和`unsigned int`。 [2.x.35] [2.x.36] [2.x.37]等可以与所有这些数据类型一起使用。注意，数据集数据类型不能是`bool'，原因是不能假设[2.x.38]以连续的方式存储元素。
* 

* ## 复数和HDF5 在HDF5文件中没有正式的HDF5格式来存储[2.x.39]数字。但是事实上*的标准是将[2.x.40]数字存储在一个复合类型中，其中`r`对应实部，`i`对应虚部。在这个接口中，我们定义了两个复合类型，一个用于[2.x.41]，对应于`(double,double)`，另一个用于[2.x.42]，对应于`（float,float）`。这两种类型分别对应于python/numpy/h5py的类型：`complex128`和`complex64`。这意味着本接口生成的文件将被python/numpy/h5py正确读取，同时本接口能够读取python/numpy/h5py生成的文件。
* # 与python脚本交换数据 HDF5格式可以用来与python脚本交换数据。字符串被存储为HDF5可变长度的UTF-8字符串，复数，如上所述，被存储为HDF5复合数据类型，与[h5py](https://www.h5py.org/)和[numpy](http://www.numpy.org/)兼容。
* 下面的python脚本写了一个deal.II模拟的参数。~~~~~~~~~~~~~{.py} h5_file = h5py.File('simulation.hdf5','w') data = h5_file.create_group('data') data.attrs['nb_frequency_points'] = 50 # int data.attrs['rho'] = 2300.5 # double data.attrs['save_vtk_files'] = True # bool data.attrs['simulation_type'] = 'elastic_equation' # utf8 string ~~~~~~~~~~~~~
* 用MPI HDF5进行C++ deal.II仿真。

* 
* [1.x.9]
* 
* 用python读取模拟结果。~~~~~~~~~~~~~{.py} h5_file = h5py.File('simulation.hdf5','r+') data = h5_file['data'] displacement = data['displacement'] # complex128 dtype active_cells = data.attrs['deges_of_freedom']) ~~~~~~~~~~~~~
* # HDF5和线程安全 默认情况下，HDF5不是线程安全的。HDF5库可以被配置为线程安全的，参见[HDF5文档](https://support.hdfgroup.org/HDF5/faq/threadsafe.html)。线程安全的HDF5版本将API序列化，但不提供任何级别的并发性。为了实现HDF5的高并行性能，我们建议将HDF5与MPI一起使用。

* 
* [0.x.1]*
   HDF5对象的基类。 
* [0.x.2]*
     构造函数。 [2.x.43] 是HDF5对象的名称。如果[2.x.44]为True，则使用MPI I/O。   
* [0.x.3]*
     读取一个属性。 [2.x.45] 可以是`float`, `double`, [2.x.46] [2.x.47] `int`, `unsigned int`, `bool` 或 [2.x.48] 注意 [2.x.49] 的编码是UTF8，以便与python3兼容。        数据类型转换在读或写时进行，是自动的。参见HDF5用户指南中的[1.x.10]部分。   
* [0.x.4]*
     写入一个属性。 [2.x.50] 可以是`float`, `double`, [2.x.51] [2.x.52] `int`, `unsigned int`, `bool` 或 [2.x.53] 注意，为了与python3兼容，[2.x.54] 的编码为UTF8。        数据类型转换在读或写时进行，是自动的。参见HDF5用户指南中的[1.x.11]部分。   
* [0.x.5]*
     返回对象的#名称。在文件的情况下，#name对应的是文件名。在Group和DataSet的情况下，#name对应于HDF5文件中的对象名称。   
* [0.x.6]*
     HDF5Oject的名称。在文件的情况下，[2.x.55]对应于文件名。在Group和DataSet的情况下，[2.x.56]对应于HDF5文件中的对象名称。   
* [0.x.7]*
     文件、组和数据集对象的HDF5标识符。[2.x.57] 指针允许对象被复制。例如，程序的几个部分可以共享和访问同一个组；当所有访问该组的函数关闭时，该组的HDF5资源将被自动释放。   
* [0.x.8]*
     如果为真则使用并行HDF5，如果为假则使用串行HDF5。   
* [0.x.9]*
   这个类实现了一个HDF5数据集。 
* [0.x.10]*
     打开数据集。这是一个内部构造函数。应该使用函数[2.x.58]来打开一个数据集。   
* [0.x.11]*
     创建数据集。这是一个内部构造函数。应该使用函数[2.x.59]来创建一个数据集。   
* [0.x.12]*
     读取数据集的所有数据。        数据类型转换在读取操作时进行，是自动的。参见HDF5用户指南中的[1.x.12]部分。        容器 "可以是[2.x.60] [2.x.61] [2.x.62] [2.x.63] [2.x.64] [2.x.65] int>`、`Vector<float>`、`Vector<double>`、[2.x.66] [2.x.67] `FullMatrix<float>`、`FullMatrix<double>`、[2.x.68] 或[2.x.69]     
* [0.x.13]*
     读取数据集的一个子集的数据。        数据类型转换在读取操作时进行，并且是自动的。参见HDF5用户指南中的[1.x.13]部分。        选定的元素可以是分散的，在数据集中采取任何形状。    例如，在一个等级为4的数据集的情况下，选择3个点将由一个3乘4的数组来描述。请注意，索引是基于零的。要选择(1,1,1,1)、(14,6,12,18)和(8,22,30,22)这几个点，点选择阵列将如下。       
* [1.x.14]
* [1.x.15] 数据类型转换在读操作时进行，是自动的。参见HDF5用户指南中的[1.x.16]部分。   
* [0.x.14]*
     从数据集中读取一个超文本。参数总结如下。
* 

* 
* 

* 
 

 
 

 
 

 
 

 
* 
* - [2.x.70] 超级板块的起始位置。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.71] 沿着每个维度要选择的元素数量。        当读取一个超文本时，HDF5也允许提供 "stride "和 "block "参数（参见[HDF5文档](https://support.hdfgroup.org/HDF5/doc1.8/RM/RM_H5S.html#Dataspace-SelectHyperslab)）。    这些参数不会被当前函数使用，而是被设置为 "nullptr"。然而，这些参数可以在函数read_hyperslab(const [2.x.72] &, const [2.x.73] &, const [2.x.74] &, const [2.x.75] &, const [2.x.76] &) 中使用。        参见HDF5用户指南中的[1.x.17]部分。也可以参见[1.x.18]。        数据类型转换是在读或写的时候进行的，是自动的。参见HDF5用户指南中的[1.x.19]部分。        容器 "可以是[2.x.77] [2.x.78] [2.x.79] [2.x.80] [2.x.81] [2.x.82] int>`、`Vector<float>`、`Vector<double>`、[2.x.83] [2.x.84] `FullMatrix<float>`、`FullMatrix<double>`、[2.x.85] 或[2.x.86]     
* [0.x.15]*
     向数据集写入一个数据超文本。参数总结如下。
* 

* 
* 

* 
 

 
 

 
 

 
 

 
* 
* - [2.x.87] 数据存储块的尺寸。
* 

* 
* 

 
* 

 
 

 
 

 
 

 
* 
* - [2.x.88] 超级板块的起始位置。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.89] 分隔每个要选择的元素或块的元素数量。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.90] 沿着每个维度要选择的元素或块的数量。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.91] 从数据空间选择的块的大小。        参见HDF5用户指南中的[1.x.20]部分。也可参见[1.x.21]。        数据类型转换是在读或写的时候进行的，而且是自动的。参见HDF5用户指南中的[1.x.22]部分。        容器 "可以是[2.x.92] [2.x.93] [2.x.94] [2.x.95] [2.x.96] [2.x.97] int>`、`Vector<float>`、`Vector<double>`、[2.x.98] [2.x.99] `FullMatrix<float>`、`FullMatrix<double>`、[2.x.100] 或[2.x.101]     
* [0.x.16]*
     这个函数不读取任何数据，但它可以为集体读取调用作出贡献。 [2.x.102] 可以是`float`, `double`, [2.x.103] [2.x.104] `int`或`unsigned int`。        数据类型的转换是在读或写时进行的，并且是自动的。参见HDF5用户指南中的[1.x.23]部分。   
* [0.x.17]*
     写入数据集中的数据。 [2.x.105] 可以是`float`，`double`，[2.x.106] [2.x.107] `int`或`unsigned int`。        数据类型的转换是在读或写时进行的，并且是自动的。参见HDF5用户指南中的[1.x.24]部分。        容器 "可以是[2.x.108] [2.x.109] [2.x.110] [2.x.111] [2.x.112] [2.x.113] int>`、`Vector<float>`、`Vector<double>`、[2.x.114] [2.x.115] `FullMatrix<float>`、`FullMatrix<double>`、[2.x.116] 或[2.x.117]     
* [0.x.18]*
     将数据写入数据集的一个子集。 [2.x.118] 可以是`float`, `double`, [2.x.119] [2.x.120] `int`或`unsigned int`。        选择的元素可以是分散的，在数据集中采取任何形状。    例如，在一个等级为4的数据集的情况下，3个点的选择将由一个3乘4的数组来描述。请注意，索引是基于零的。为了选择(1,1,1,1)、(14,6,12,18)和(8,22,30,22)这几个点，点选择阵列将如下。       
* [1.x.25]
* [1.x.26] 数据类型转换在读或写时进行，是自动的。参见HDF5用户指南中的[1.x.27]部分。   
* [0.x.19]*
     向数据集写入一个数据超文本。参数总结如下。
* 

* 
* 

* 
 

 
 

 
 

 
 

 
* 
* - [2.x.121] 超文本的起始位置。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.122] 沿着每个维度要选择的元素数量。        在编写超文本时，HDF5还允许提供 "stride "和 "block "参数（见[HDF5文档](https://support.hdfgroup.org/HDF5/doc1.8/RM/RM_H5S.html#Dataspace-SelectHyperslab)）。    这些参数不会被当前函数使用，而是被设置为 "nullptr"。但是这些参数可以在函数write_hyperslab(const Container &data, const [2.x.123] &data_dimensions, const [2.x.124] &offset, const [2.x.125] &stride, const [2.x.126] &count, const [2.x.127] &block) 中使用。        参见HDF5用户指南中的[1.x.28]部分。也可参见[1.x.29]。        数据类型转换是在读或写的时候进行的，而且是自动的。参见HDF5用户指南中的[1.x.30]部分。   
* [0.x.20]*
     向数据集写入一个数据超文本。参数总结如下。
* 

* 
* 

* 
 

 
 

 
 

 
 

 
* 
* - [2.x.128] 数据存储块的尺寸。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.129] 超级板块的起始位置。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.130] 分隔每个要选择的元素或块的元素数量。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.131] 沿着每个维度要选择的元素或块数。
* 

* 
* 

* 
* 

 
 

 
 

 
 

 
* 
* - [2.x.132] 从数据空间中选择的块的大小。        参见HDF5用户指南中的[1.x.31]部分。也可参见[1.x.32]。        数据类型转换是在读或写的时候进行的，而且是自动的。参见HDF5用户指南中的[1.x.33]部分。        容器 "可以是[2.x.133] [2.x.134] [2.x.135] [2.x.136] [2.x.137] [2.x.138] int>`、`Vector<float>`、`Vector<double>`、[2.x.139] [2.x.140] `FullMatrix<float>`、`FullMatrix<double>`、[2.x.141] 或[2.x.142]     
* [0.x.21]*
     这个函数不写任何数据，但它可以为集体写调用作出贡献。在MPI集体写调用的情况下，如果一个进程根本不写任何数据，该进程应该调用这个函数，因为该操作是集体的*，所有的MPI进程都必须为该调用作出贡献，即使他们没有数据可写。 [2.x.143] 可以是 "float"、"double"、[2.x.144] [2.x.145] `int'或`unsigned int'。        数据类型的转换是在读或写时进行的，并且是自动的。参见HDF5用户指南中的[1.x.34]部分。        如何使用这个函数的例子可以在 [2.x.146] 中找到。   
* [0.x.22]*
     该函数返回boolean query_io_mode。        在必须实现最大性能的情况下，确保所有的MPI读/写操作是集体的，这一点很重要。HDF5库提供了API例程，可以在读/写I/O操作之后使用，以查询I/O模式。如果query_io_mode设置为true，那么在每次读/写操作之后，deal.II的HDF5接口都会调用例程[H5Pget_mpio_actual_io_mode()](https://support.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-GetMpioActualIoMode)和[H5Pget_mpio_no_collective_cause()](https://support.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-GetMpioNoCollectiveCause) 。    结果存储在io_mode、local_no_collective_cause和global_no_collective_cause。我们建议只在Debug模式下查询I/O模式，因为这需要调用额外的HDF5例程。   
* [0.x.23]*
     这个函数设置布尔查询_io_mode。   
* [0.x.24]*
     该函数返回最后一次并行I/O调用时使用的I/O模式。参见[1.x.35]。        返回值是一个[2.x.147]，可以是Value | Meaning。
* 

* 
* 

* 
* 

 
 

 
 

 
* 
* - ---------------------------- |
* 
* - ----- H5D_MPIO_NO_COLLECTIVE | 没有执行集体I/O。没有要求进行集体I/O，或者在这个数据集上不可能进行集体I/O。    H5D_MPIO_CHUNK_INDEPENDENT | HDF5执行了分块集体优化方案，每个分块被独立访问。    H5D_MPIO_CHUNK_COLLECTIVE | HDF5执行大块集体优化方案，每个大块被集体访问。    H5D_MPIO_CHUNK_MIXED | HDF5执行大块集体优化方案，有些大块被独立访问，有些被集体访问。    H5D_MPIO_CONTIGUOUS_COLLECTIVE | 对一个连续的数据集进行了集体I/O。   
* [0.x.25]*
     该函数返回最后一次并行I/O调用时使用的I/O模式。参见[1.x.36]。    返回类型为`H5D_mpio_actual_io_mode_t`，对应于H5Pget_mpio_actual_io_mode的返回值。        返回值可以是Value | Meaning
* 

* 
* 

* 
* 

 
 

 
 

 
* 
* - ---------------------------- |
* 
* - ----- H5D_MPIO_NO_COLLECTIVE | 没有执行集体I/O。没有要求进行集体I/O，或者在这个数据集上不可能进行集体I/O。    H5D_MPIO_CHUNK_INDEPENDENT | HDF5进行了分块集体优化，每个分块被独立访问。    H5D_MPIO_CHUNK_COLLECTIVE | HDF5执行大块集体优化，每个大块被集体访问。    H5D_MPIO_CHUNK_MIXED | HDF5执行大块集体优化，有些大块被独立访问，有些被集体访问。    H5D_MPIO_CONTIGUOUS_COLLECTIVE | 对一个连续的数据集进行了集体I/O。   
* [0.x.26]*
     这个函数返回在最后一次并行I/O调用中破坏集体I/O的本地原因。见[1.x.37]。        返回值是一个字符串，可以是 Value | Meaning
* 

* 
* 

* 
* 

 
 

 
 

 
* 
* - ---------------------------------------- |
* 
* - ----- H5D_MPIO_COLLECTIVE | 集体I/O已成功执行。    H5D_MPIO_SET_INDEPENDENT | 因为要求独立的I/O，所以没有执行集体I/O。    H5D_MPIO_DATATYPE_CONVERSION | 因为需要进行数据类型转换，所以没有执行集体I/O。    H5D_MPIO_DATA_TRANSFORMS | 因为需要应用数据转换，所以没有执行集体I/O。    H5D_MPIO_SET_MPIPOSIX | 因为选择的文件驱动是MPI-POSIX，所以没有执行集体I/O。    H5D_MPIO_NOT_SIMPLE_OR_SCALAR_DATASPACES | 因为其中一个数据空间既不简单也不标量，所以没有执行集体I/O。    H5D_MPIO_POINT_SELECTIONS | 由于其中一个数据空间中存在点选择，所以没有执行集体I/O。    H5D_MPIO_NOT_CONTIGUOUS_OR_CHUNKED_DATASET | 由于数据集既不是连续的也不是分块的，所以没有执行集体I/O。    H5D_MPIO_FILTERS | 因为需要应用过滤器而没有执行集体I/O。   
* [0.x.27]*
     这个函数返回在最后一次并行I/O调用中破坏集体I/O的本地原因。参见[1.x.38]。    返回类型为`uint32_t`，对应于[H5Pget_mpio_no_collective_cause](https://support.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-GetMpioNoCollectiveCause)返回的值。        返回值可以是Value | Meaning
* 

* 
* 

* 
* 

 
 

 
 

 
* 
* - ---------------------------------------- |
* 
* - ----- H5D_MPIO_COLLECTIVE | 集体I/O已成功执行。    H5D_MPIO_SET_INDEPENDENT | 因为要求独立的I/O，所以没有执行集体I/O。    H5D_MPIO_DATATYPE_CONVERSION | 因为需要进行数据类型转换，所以没有执行集体I/O。    H5D_MPIO_DATA_TRANSFORMS | 因为需要应用数据转换，所以没有执行集体I/O。    H5D_MPIO_SET_MPIPOSIX | 因为选择的文件驱动是MPI-POSIX，所以没有执行集体I/O。    H5D_MPIO_NOT_SIMPLE_OR_SCALAR_DATASPACES | 因为其中一个数据空间既不简单也不标量，所以没有执行集体I/O。    H5D_MPIO_POINT_SELECTIONS | 由于其中一个数据空间中存在点选择，所以没有执行集体I/O。    H5D_MPIO_NOT_CONTIGUOUS_OR_CHUNKED_DATASET | 由于数据集既不是连续的也不是分块的，所以没有执行集体I/O。    H5D_MPIO_FILTERS | 因为需要应用过滤器而没有执行集体I/O。   
* [0.x.28]*
     这个函数检索在最后一次并行I/O调用中破坏集体I/O的全局原因。见[1.x.39]。        返回值是一个[2.x.148]，可以是Value | Meaning。
* 

* 
* 

* 
* 

 
 

 
 

 
* 
* - ---------------------------------------- |
* 
* - ----- H5D_MPIO_COLLECTIVE | 集体I/O已成功执行。    H5D_MPIO_SET_INDEPENDENT | 因为要求独立的I/O，所以没有执行集体I/O。    H5D_MPIO_DATATYPE_CONVERSION | 因为需要进行数据类型转换，所以没有执行集体I/O。    H5D_MPIO_DATA_TRANSFORMS | 因为需要应用数据转换，所以没有执行集体I/O。    H5D_MPIO_SET_MPIPOSIX | 因为选择的文件驱动是MPI-POSIX，所以没有执行集体I/O。    H5D_MPIO_NOT_SIMPLE_OR_SCALAR_DATASPACES | 因为其中一个数据空间既不简单也不标量，所以没有执行集体I/O。    H5D_MPIO_POINT_SELECTIONS | 由于其中一个数据空间中存在点选择，所以没有执行集体I/O。    H5D_MPIO_NOT_CONTIGUOUS_OR_CHUNKED_DATASET | 由于数据集既不是连续的也不是分块的，所以没有执行集体I/O。    H5D_MPIO_FILTERS | 因为需要应用过滤器而没有执行集体I/O。   
* [0.x.29]*
     这个函数返回在最后一次并行I/O调用中破坏集体I/O的全局原因。参见[1.x.40]。    返回类型为`uint32_t`，与H5Pget_mpio_no_collective_cause返回的值对应。        返回值可以是 Value | Meaning
* 

* 
* 

* 
* 

 
 

 
 

 
* 
* - ---------------------------------------- |
* 
* - ----- H5D_MPIO_COLLECTIVE | 集体I/O已成功执行。    H5D_MPIO_SET_INDEPENDENT | 因为要求独立的I/O，所以没有执行集体I/O。    H5D_MPIO_DATATYPE_CONVERSION | 因为需要进行数据类型转换，所以没有执行集体I/O。    H5D_MPIO_DATA_TRANSFORMS | 因为需要应用数据转换，所以没有执行集体I/O。    H5D_MPIO_SET_MPIPOSIX | 因为选择的文件驱动是MPI-POSIX，所以没有执行集体I/O。    H5D_MPIO_NOT_SIMPLE_OR_SCALAR_DATASPACES | 因为其中一个数据空间既不简单也不标量，所以没有执行集体I/O。    H5D_MPIO_POINT_SELECTIONS | 由于其中一个数据空间中存在点选择，所以没有执行集体I/O。    H5D_MPIO_NOT_CONTIGUOUS_OR_CHUNKED_DATASET | 由于数据集既不是连续的也不是分块的，所以没有执行集体I/O。    H5D_MPIO_FILTERS | 因为需要应用过滤器，所以没有执行集体I/O。   
* [0.x.30]*
     这个函数返回数据集的尺寸。向量dimensions是一个大小为rank的一维数组，指定数据集的每个维度的大小。   
* [0.x.31]*
     该函数返回数据集的总元素数。   
* [0.x.32]*
     此函数返回数据集的等级。   
* [0.x.33]*
     数据集的等级    
* [0.x.34]*
     向量`dimensions`是一个大小为rank的一维数组，指定数据集的每个维度的大小。   
* [0.x.35]*
     HDF5数据空间标识符。   
* [0.x.36]*
     数据集的总元素数。   
* [0.x.37]*
     如果query_io_mode设置为true，那么在每次读/写操作之后，deal.II的HDF5接口都会调用例程[H5Pget_mpio_actual_io_mode()](https://support.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-GetMpioActualIoMode)和[H5Pget_mpio_no_collective_cause()](https://support.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-GetMpioNoCollectiveCause) 。    结果存储在io_mode、local_no_collective_cause和global_no_collective_cause。   
* [0.x.38]*
     在最后一次并行I/O调用时执行的I/O模式。   
* [0.x.39]*
     在最后一次并行I/O调用中破坏集体I/O的本地原因。见[1.x.41]。   
* [0.x.40]*
     在最后一次并行I/O调用中破坏集体I/O的全局原因。见[1.x.42]。   
* [0.x.41]*
   该类实现了一个HDF5组  
* [0.x.42]*
     组的访问模式    
* [0.x.43]*
       打开一个现有的组      
* [0.x.44]*
       创建一个新的群组      
* [0.x.45]*
     这个构造函数创建或打开一个组，取决于[2.x.149]的值，该组将被放在组内[2.x.150]的参数[2.x.151]定义了I/O操作是串行还是并行。这是一个内部构造函数，应该使用当前类的函数open_group()和create_group()来打开或创建一个组。   
* [0.x.46]*
     文件使用的内部构造函数。该构造函数设置HDF5Group的受保护常量成员。 [2.x.152] 和 [2.x.153] 它不会创建或打开一个组。   
* [0.x.47]*
     打开当前组或文件的一个子组。   
* [0.x.48]*
     在当前组或文件中创建一个子组。   
* [0.x.49]*
     打开一个数据集。   
* [0.x.50]*
     创建一个数据集。 [2.x.154] 可以是`float`, `double`, [2.x.155] [2.x.156] `int`或`unsigned int`。        数据类型的转换是在读或写时进行的，并且是自动的。参见HDF5用户指南中的[1.x.43]部分。   
* [0.x.51]*
     创建并向数据集写入数据。 [2.x.157] 可以是`float`、`double`、[2.x.158] [2.x.159] `int`或`unsigned int`。        数据类型的转换是在读或写时进行的，并且是自动的。参见HDF5用户指南中的[1.x.44]部分。        容器 "可以是[2.x.160] [2.x.161] [2.x.162] [2.x.163] [2.x.164] [2.x.165] int>`、`Vector<float>`、`Vector<double>`、[2.x.166] [2.x.167] `FullMatrix<float>`、`FullMatrix<double>`、[2.x.168] 或[2.x.169]     
* [0.x.52]*
   该类实现了一个HDF5文件  
* [0.x.53]*
     文件访问模式    
* [0.x.54]*
       读/写，文件必须存在      
* [0.x.55]*
       创建文件，如果存在则截断      
* [0.x.56]*
     创建或打开一个HDF5文件进行串行操作。这个调用不需要MPI支持。它创建或打开一个HDF5文件，取决于[2.x.170]的值。    
* [0.x.57]*
     使用MPI并行地创建或打开一个HDF5文件。这需要deal.II和HDF5在编译时支持MPI。它创建或打开一个HDF5文件，取决于[2.x.171] [2.x.172]的值，定义了参与此调用的进程；`MPI_COMM_WORLD`是MPI通信器的一个通用值。   
* [0.x.58]*
     授权的内部构造函数。    File(const [2.x.173] &, const MPI_Comm &, const Mode); 和 File(const [2.x.174] &, const Mode) 应该被用来打开或创建HDF5文件。   
* [0.x.59]*该函数返回与C++类型对应的HDF5数据类型。    在[2.x.175]类型的情况下，HDF5处理程序使用[2.x.176]的析构器自动释放[2.x.177]而不是[2.x.178]，因为[2.x.179]的析构器不需要在模板参数中定义。另一方面，[2.x.180]的析构器必须在模板参数中定义。像`H5T_NATIVE_DOUBLE`这样的本地类型不需要析构器，但是像[2.x.181]这样的复合类型需要一个析构器来释放HDF5资源。   
* [0.x.60]* 返回`data`的尺寸。对于一个[2.x.182]该函数返回[2.x.183]几个HDF5函数，如H5Screate_simple()需要一个一维数组，指定容器的每个维度的大小，见：https://support.hdfgroup.org/HDF5/doc1.8/RM/RM_H5S.html#Dataspace-CreateSimple    
* [0.x.61]* 返回`data`的尺寸。对于一个矢量，这个函数返回[2.x.184]。    
* [0.x.62]* 返回`data`的尺寸。对于FullMatrix，该函数返回[2.x.185]列}`。   
* [0.x.63]* 这个函数返回容器的总尺寸。对于一个[2.x.186]，该函数返回`int(vector_size)`。   
* [0.x.64]* 此函数返回容器的总大小。对于一个向量，该函数返回`int(vector_size)`。   
* [0.x.65]* 此函数返回容器的总大小。对于FullMatrix，该函数返回`int(rows*columns)`。   
* [0.x.66]* 这个函数初始化并返回一个[2.x.187] Vector或FullMatrix类型的容器。该函数不设置容器中元素的值。该容器可以存储HDF5数据集或HDF5选择的数据。维度参数保存HDF5数据集或选择的维度。        在[2.x.188]的情况下，向量的大小将是由维度给出的总大小。例如，在一个等级为3的数据集的情况下，尺寸为[2.x.189]，返回的[2.x.190]的大小将是`dim_0*dim_1*dim_2`。        如果是[2.x.191]，返回的[2.x.192]的大小也将是`dim_0*dim_1*dim_2'。        一个FullMatrix只能存储等级为2的HDF5数据集的数据。FullMatrix的大小将是FullMatrix(dim_0,dim_2)    
* [0.x.67]* 同上。   
* [0.x.68]* 同上。   
* [0.x.69]* 这个辅助函数设置了DataSet的读写操作的属性列表。必须为MPI驱动创建一个属性列表。对于串行驱动，可以使用默认的H5P_DEFAULT。此外，H5Pset_dxpl_mpio被用来设置MPI模式为集体模式。   
* [0.x.70]* 这个辅助函数释放了DataSet的读写操作的属性列表处理程序。对于串行版本，不需要释放属性列表处理程序，因为已经使用了H5P_DEFAULT。如果query_io_mode为True，那么H5Pget_mpio_actual_io_mode和H5Pget_mpio_no_collective_cause被用来检查该操作是否已经被集合。   
* [0.x.71]* 将HDF5 no_collective_cause代码转换成人类可读的字符串。   
* [0.x.72] 创建标量属性。   
* [0.x.73] 编写标量属性。   
* [0.x.74] 创建标量属性。   
* [0.x.75] 编写标量属性。    在大多数情况下，H5Awrite和H5Dwrite需要一个指向数据的指针。    但是在可变长度的字符串的特殊情况下，H5Awrite取的是字符串的指针的地址。   
* [0.x.76]

