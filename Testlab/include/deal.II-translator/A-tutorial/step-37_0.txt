include/deal.II-translator/A-tutorial/step-37_0.txt
[0.x.0]*
 [2.x.0]
* 本教程依赖于 [2.x.1] , [2.x.2] 。
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18][1.x.19][1.x.20][1.x.21][1.x.22][1.x.23][1.x.24][1.x.25][1.x.26][1.x.27][1.x.28][1.x.29][1.x.30][1.x.31]
* [2.x.3]
* [1.x.32][1.x.33] 。
* [1.x.34][1.x.35][1.x.36] 。


* 这个例子展示了如何实现一个无矩阵方法，即一个不明确存储矩阵元素的方法，用于处理超立方体上系数可变的二阶Poissonequation。这个线性系统将用多网格方法来解决，并使用MPI的大规模并行性。
* 无矩阵方法的主要动机是，在今天的处理器上，对主内存的访问（即对不适合缓存的对象）已成为许多偏微分方程求解器的瓶颈。为了执行基于矩阵的矩阵-向量乘积，现代CPU花在等待数据从内存到达的时间远远多于实际进行浮点乘法和加法的时间。因此，如果我们可以通过重新计算矩阵元素，或者更确切地说，通过这些条目所代表的运算符，来替代在内存中查找矩阵元素，我们可能会在整体运行时间方面获胜，即使这需要大量额外的浮点运算。也就是说，用一个微不足道的实现来实现这一点是不够的，我们需要真正关注细节来获得性能。这个教程程序和上面提到的论文展示了如何实现这样一个方案，并展示了可以获得的速度提升。
*

*[1.x.37][1.x.38]


* 在这个例子中，我们考虑泊松问题[1.x.39]，其中[2.x.4]是一个可变系数。下面，我们解释如何为这个问题实现矩阵-向量乘积，而不明确形成矩阵。当然，对于其他方程也可以用类似的方法进行构造。
* 我们选择[2.x.5]和[2.x.6]作为域。由于系数是围绕原点对称的，但域却不是，我们最终会得到一个非对称的解决方案。
*

*[1.x.40][1.x.41]


*为了找出我们如何编写一个执行矩阵-向量乘积的代码，但不需要存储矩阵元素，让我们先看看一个有限元矩阵[1.x.42]是如何组装的：[1.x.43] 。
* 在这个公式中，矩阵[1.x.44]<sub>cell,loc-glob</sub>是一个矩形矩阵，定义了从当前单元的局部自由度到全局自由度的索引映射。可以建立这个运算器的信息通常被编码在[2.x.7]变量中，并被用于交易二中的汇编调用填充矩阵。这里，[1.x.45]<sub>cell</sub>表示与[1.x.46]相关的单元矩阵。
* 如果我们要进行矩阵-向量乘积，我们可以因此使用[1.x.47]。
*其中[1.x.48]<sub>cell</sub>是[1.x.49]在各单元自由度上的值，[1.x.50]<sub>cell</sub>=[1.x.51]<sub>cell</sub>[1.x.52]<sub>cell</sub>相应地得到结果。因此一个天真的尝试来实现拉普拉斯的局部作用将使用以下代码。
* [1.x.53]
*
* 这里我们忽略了边界条件以及我们可能拥有的任何悬空节点，尽管使用AffineConstraints类来包括这两者都不是很困难。请注意，我们首先以常规方式生成局部矩阵，作为每个局部矩阵条目在所有正交点上的总和。为了形成上述公式中表达的实际乘积，我们提取了单元格相关自由度的[2.x.8]的值（[1.x.54]的作用]<sub>cell,loc-glob</sub>的作用），乘以局部矩阵（[1.x.55]<sub>cell</sub>的作用），最后将结果加到目的地向量[2.x.9]（[1.x.56]<sub>cell,loc-glob</sub><sup>T</sup>的作用，在所有元素上加起来）。原则上，这不会比这更难。
* 虽然这个代码是完全正确的，但它非常慢。对于每个单元，我们生成一个局部矩阵，这需要三个嵌套的循环，循环长度等于局部自由度的数量来计算。乘法本身是由两个嵌套循环完成的，这意味着它要便宜得多。
* 改善这个问题的一个方法是，从概念上讲，局部矩阵可以被认为是三个矩阵的乘积，[1.x.57] 。
* 在拉普拉斯算子的例子中，[1.x.58]*dim+[1.x.59])-[1.x.60]<sub>cell</sub>的元素是由[2.x.10]给出。这个矩阵由[2.x.11]行和[2.x.12]列组成。矩阵[1.x.61]<sub>cell</sub>是对角线，包含[2.x.13]的值（或者说，[2.x.14]这些值的二进制副本）。在工程文献中经常可以看到这种关于无限元素矩阵的表述。
* 当单元格矩阵被应用于一个矢量时，[1.x.62]。
* 那么，我们就不会形成矩阵与矩阵的乘积，而是每次将一个矩阵与一个向量从右到左相乘，这样就只形成三个连续的矩阵-向量乘积。这种方法消除了局部矩阵计算中的嵌套循环，从而将一个单元的工作复杂度从类似[2.x.15]降低到[2.x.16] 。对这一算法的解释是，我们首先将局部DoF上的值向量转换为正交点上的梯度向量。在第二个循环中，我们将这些梯度乘以积分权重和系数。第三次循环应用第二个梯度（转置形式），这样我们就得到了单元斗室上的（拉普拉斯）值矢量。
* 上述代码的瓶颈是对每一个[2.x.18]调用[2.x.17]所做的操作，其花费的时间与其他步骤加起来差不多（至少如果网格是非结构化的；deal.II可以识别梯度在结构化的网格上往往是不变的）。这当然不理想，我们希望能做得更好。该函数所做的是计算实空间的梯度，通过使用从实空间到参考单元的变形的Jacobian来转换参考单元上的梯度。这是对单元上的每个基函数和每个正交点进行的。雅各布系数并不取决于基函数，但它在不同的正交点上一般是不同的。如果你只建立一次矩阵，就像我们在之前的所有教程中所做的那样，没有什么需要优化的，因为[2.x.19]需要在每个单元上调用。在这个过程中，转换是在计算本地矩阵元素时应用的。
* 然而，在一个无矩阵的实现中，我们会经常计算这些积分，因为迭代求解器在求解过程中会多次应用矩阵。因此，我们需要考虑是否能够缓存一些在运算器应用中被重用的数据，也就是积分计算。另一方面，我们意识到，我们不能缓存太多的数据，否则我们又会回到内存访问成为主导因素的情况。因此，我们不会在矩阵[1.x.63]中存储转换后的梯度，因为一般来说，对于曲线网格的每个基函数和每个元素上的每个正交点，它们都是不同的。
* 诀窍是去掉雅各布变换的因素，首先只在参考单元上应用梯度。这个操作将局部道夫上的数值矢量插值为正交点上的（单位坐标）梯度矢量。在这里，我们首先应用我们从梯度中分解出来的Jacobian，然后应用正交的权重，最后应用转置的Jacobian来准备第三个循环，通过单元格上的梯度来测试，并对正交点求和。
* 让我们再次以矩阵的形式来写。让矩阵[1.x.64]<sub>cell</sub>表示与单元格相关的梯度矩阵，每一行都包含正交点的值。它由矩阵与矩阵的乘积构成[1.x.65]，其中[1.x.66]<sub>ref_cell</sub>表示参考单元的梯度，[1.x.67]<sup>-T</sup><sub>cell</sub>表示从单元到实数单元转换的反转置Jacobian（在转换语言中，由[1.x.68]<sup>-T</sup><sub>cell</sub>代表的操作为变数转换）。[1.x.69]<sup>-T</sup><sub>cell</sub>是块对角线的，块的大小等于问题的维度。每个对角线块都是雅各布变换，从定义单元到实际单元。
* 把事情放在一起，我们发现[1.x.70]。
* 所以我们计算积（从右边开始计算局部积）[1.x.71] 。
*
* [1.x.72]
*
* 注意我们是如何为参考单元格梯度创建一个额外的FEValues对象，以及如何将其初始化为参考单元格的。然后，实际的衍生数据由反转的雅各布矩阵来应用（deal.II将雅各布矩阵从实心单元到单位单元称为inverse_jacobian，因为前向转换是由单位单元到实心单元）。因子[2.x.20]是块对角线超过正交的。在这种形式下，人们意识到可变系数（可能通过张量表示）和一般的网格拓扑结构与雅各布变换对单元格导数的系数变换有类似的影响。
* 在这一点上，人们可能会想，为什么我们要分别存储矩阵[2.x.21]和系数，而不是只存储完整的系数[2.x.22]。后者将使用更少的内存，因为张量是对称的，在三维中具有六个独立的值，而对于前者，我们需要九个条目用于反转雅各布，一个用于正交权重和雅各布行列式，一个用于系数，总共是11个双数。原因是前者允许通过一个通用的缓存数据框架来实现通用的微分算子，而后者则专门存储拉普拉斯的系数。如果应用需要的话，这种特殊化可能会带来回报，值得考虑。请注意，deal.II的实现足够聪明，可以检测出笛卡尔或仿生几何，在这种情况下，Jacobian在整个单元中是恒定的，不需要为每个单元存储（实际上在不同的单元中也经常是一样的）。
* 从操作数的角度来看，最后一个最关键的优化是利用基函数中的张量积结构。这是可能的，因为我们将梯度从[1.x.73]<sub>ref_cell</sub>描述的关系单元操作中剔除，即在关系单元的完全规则数据域上进行插值操作。我们举例说明在两个空间维度上降低复杂度的过程，但是同样的技术也可以用于更高的维度。在该单元上，基函数为张量积形式 [2.x.23] 。矩阵[1.x.74]<sub>ref_cell</sub>计算第一分量的部分具有[2.x.24]的形式，其中[1.x.75]<sub>grad,x</sub>和[1.x.76]<sub>val,y</sub>包含对所有一维正交点上所有一维基函数的评估。用含有基函数[2.x.25]所属系数的[1.x.78]组成矩阵[1.x.77]，我们得到[2.x.26]。这将计算这个乘积的复杂性从[2.x.27]降低到[2.x.28]，其中[1.x.79]-1是有限元的度数（即，相当于，[1.x.80]是每个坐标方向上的形状函数的数量），或者一般来说[2.x.29] 到[2.x.30]。我们之所以用多项式度数来看复杂度，是因为我们希望能够达到高度，并可能增加多项式度数[1.x.81]而不是网格分辨率。像这里所用的中等度数的好算法是独立于维度的多项式度数的线性算法，而不是基于矩阵的方案或通过FEValues的天真评价。在deal.II的实现中使用的技术自20世纪80年代以来在谱元界已经建立起来。
* 实现一个无矩阵和基于单元的有限元算子需要与以前的教程程序中显示的通常的矩阵装配代码相比，有一些不同的程序设计。这样做的数据结构是MatrixFree类和FEEvaluation类，前者收集所有数据并对所有单元进行（并行）循环，后者利用张量积结构来评估有限元基函数。
* 本教程中显示的无矩阵的矩阵-向量乘积的实现比使用稀疏矩阵的线性元素的矩阵-向量乘积要慢，但由于张量乘积结构降低了复杂性，并且在计算过程中减少了内存转移，所以对所有高阶元素来说，速度更快。当在多核处理器上工作时，减少内存传输的影响尤其有利，因为在多核处理器上有多个处理单元共享内存的访问。在这种情况下，一个受计算约束的算法将显示出几乎完美的并行加速（除了可能通过涡轮模式改变处理器的时钟频率，取决于有多少个核心在工作），而一个受内存传输约束的算法可能无法实现类似的加速（即使当工作是完全并行的，我们可以期待完美的缩放，如在疏散矩阵-向量产品）。这种实现方式的另一个好处是，我们不必建立稀疏矩阵本身，这也可能是相当昂贵的，这取决于基础微分方程。此外，上述框架可以简单地推广到非线性运算，正如我们在[2.x.31]中展示的那样。
*

*[1.x.82][1.x.83] 。


* 以上，我们花了很大的力气来实现一个不实际存储矩阵元素的矩阵-向量积。然而，在许多用户代码中，人们想要的不仅仅是做一些矩阵-向量乘积&mdash；在求解线性系统时，人们想要尽可能少地做这些操作。理论上，我们可以使用CG方法，而不需要预处理；然而，这对拉普拉斯的效率并不高。相反，预处理是用来提高收敛速度的。不幸的是，大多数比较常用的预处理程序，如SSOR、ILU或代数多网格(AMG)不能在这里使用，因为它们的实现需要了解系统矩阵的元素。
* 一个解决方案是使用几何多网格方法，如[2.x.32]所示。它们是已知的非常快的方法，而且适合于我们的目的，因为所有的成分，包括不同网格层之间的转移，都可以用与细胞集合相关的矩阵-向量产品来表达。我们需要做的就是找到一个基于矩阵-向量乘积而不是所有矩阵条目的平滑器。一个这样的候选方法是阻尼雅可比迭代法，它需要访问矩阵对角线，但它在阻尼所有高频误差方面往往不够好。Jacobi方法的特性可以通过所谓的Chebyshev迭代进行几次改进。Chebyshev迭代是由矩阵-向量乘积的多项式表达式描述的，其中的系数可以被选择来实现某些特性，在这种情况下，可以平滑误差的高频分量，这些分量与雅可比预处理矩阵的特征值相关。在零度时，具有最佳阻尼参数的雅各布方法被检索出来，而高阶修正则用于改善平滑特性。切比雪夫平滑法在多网格中的有效性已经在文章[1.x.84][1.x.85]中得到证明。这篇文章还指出了我们在这里利用的Chebyshev平滑器的另一个优势，即它们很容易并行化，而SOR/Gauss&ndash;Seidel平滑器则依赖于替换，对于这种替换，天真的并行化工作在矩阵的对角线子块上，从而降低了效率（更多细节见例如Y. Saad, IterativeMethods for Sparse Linear Systems, SIAM, 2nd edition, 2003, chapters 11 & 12）。
* 因此，在多网格框架中的实现是很简单的。本程序中的多网格实现与[2.x.33]类似，包括aptivity。
*

*[1.x.86][1.x.87]


* FEEvaluation中用于评估的计算内核是以优化使用计算资源的方式编写的。为了达到这个目的，它们不对双倍数据类型进行操作，而是采用我们称之为VectorizedArray的东西（例如，查看[2.x.34]的转向类型，该类型是指ascal元素的VectorizedArray，以及矢量有限元素的Tensor）。矢量数组是一个双数或浮点数的短数组，其长度取决于所使用的特定计算机系统。例如，基于x86-64的系统支持流式SIMD扩展（SSE），处理器的矢量单元可以通过一条CPU指令处理两个双数（或四个单精度浮点）。较新的处理器（大约从2012年起）支持所谓的高级向量扩展（AVX），有256位操作数，可以分别使用四个双数和八个浮点数。矢量化是一个单指令/多数据（SIMD）的概念，也就是说，一条CPU指令被用来同时处理多个数据值。通常情况下，有限元程序不会明确使用矢量化，因为这个概念的好处只体现在算术密集型操作上。大部分典型的有限元工作负载的内存带宽有限（对稀疏矩阵和向量的操作），额外的计算能力是无用的。
* 在幕后，优化的BLAS包可能严重依赖矢量化。另外，优化的编译器可能会自动将涉及标准代码的循环转化为更有效的矢量化形式（deal.II在矢量更新的常规循环中使用OpenMP SIMD pragmas）。然而，数据流必须非常有规律，才能使编译器产生有效的代码。例如，受益于矢量化的原型操作的自动矢量化，即矩阵三乘法，在大多数编译器上都失败了（截至2012年初编写本教程和2016年底更新时，gcc和英特尔编译器都无法为[2.x.35]函数，甚至在更简单的情况下也不行，即矩阵边界是编译时常量而不是[2.x.36]中的运行时常量。主要原因是在最内层循环（即应用矢量化的地方）要处理的信息不一定是矢量长度的倍数，留下部分资源没有使用。此外，有可能被一起处理的数据在内存中可能不是以连续的方式布置的，或者没有对准处理器需要的地址边界。或者编译器可能无法证明在一次加载几个元素时数据阵列不会重叠。
* 在deal.II的无矩阵实现中，我们选择在最适合有限元素计算的层次上应用矢量化。单元计算通常对所有单元完全相同（除了从向量读写时使用的间接寻址中的索引），因此可以使用SIMD来一次处理几个单元。在下面的所有内容中，你可以考虑用一个向量数组来存放几个单元的数据。记住，它与空间维度和元素数量无关，例如在张量或点中。
* 请注意，矢量化取决于代码运行的CPU，以及代码是为哪种CPU编译的。为了给你的计算机生成最快的FEEvaluation内核，你应该用所谓的[1.x.88]处理器变量编译deal.II。当使用gcc编译器时，可以通过在cmake构建设置中设置变量<tt>CMAKE_CXX_FLAGS</tt>为<tt>"-march=native"</tt>来启用它（在命令行中，指定<tt>-DCMAKE_CXX_FLAGS="-march=native"</tt>，更多信息见deal.II阅读手册）。其他编译器也有类似的选项。我们在本例的run()函数中输出当前的矢量化长度。
*

*[1.x.89][1.x.90]


* 如上所述，无矩阵框架中的所有组件都可以很容易地通过MPI使用领域分解进行并行化。由于在deal.II中通过p4est（详见[2.x.37]）可以很容易地访问大规模的并行网格，而且基于单元的无矩阵评估循环[1.x.91]需要将网格分解成每个处理器上大小基本相同的块，因此编写一个使用分布式内存的并行程序所需的工作相对较少。当其他使用MPI的教程程序依赖于PETSc或Trilinos时，这个程序使用deal.II自己的并行向量设施。
* deal.II的并行向量类，[2.x.38]持有解决方案的处理器本地部分，以及ghostedDoFs的数据字段，即由远程处理器拥有的DoFs，但由当前处理器拥有的单元访问。在[2.x.39]的 "词汇表 "中，这些自由度被称为本地活动自由度。函数[2.x.40]提供了一种设置这种设计的方法。请注意，悬挂节点可以与额外的托管自由度有关，这些自由度必须包括在分布式矢量中，但不属于[2.x.41]"词汇表 "意义上的本地活动自由度。此外，分布式向量持有本地拥有但其他处理器需要的DoF的MPI元数据。这个向量类设计的一个好处是对ghostedentries的访问方式。在向量的存储方案中，数据阵列延伸到解决方案的处理器本地部分之外，有更多的向量可用于重现自由度。这为所有本地活动自由度提供了一个连续的索引范围。(注意，索引范围取决于网格的具体配置。)由于无矩阵操作可以被认为是在做性能关键的线性代数，而性能关键的代码不能把时间浪费在做MPI全局到MPI局部的索引转换上，一个MPI等级的局部索引空间的可用性是很重要的。这里访问事物的方式是直接数组访问。这是通过[2.x.42]提供的，但实际上很少需要，因为所有这些都发生在FEEvaluation的内部。
* [2.x.43]的设计与我们之前在[2.x.46]和[2.x.47]中使用的[2.x.44]和[2.x.45]数据类型类似，但由于我们不需要这些库的任何其他并行功能，我们使用deal.II的[2.x.48]类而不是在这个教程程序中链接另一个大型库。还要注意的是，PETSc和Trilinosvectors不提供对直接阵列访问的幽灵条目的细粒度控制，因为它们抽象出了必要的实现细节。
*

* [1.x.92] [1.x.93]。
*首先包括deal.II库中的必要文件。
*


* [1.x.94]
*
* 这包括有效实现无矩阵方法的数据结构，或用MatrixFree类的更通用的有限元算子。
*


* [1.x.95]
*
* 为了提高效率，在无矩阵实现中进行的操作需要在编译时了解循环长度，这些长度是由有限元的度数给出的。因此，我们收集了两个模板参数的值，可以在代码中的一个地方改变。当然，我们可以把有限元的度数作为一个运行时的参数，通过编译所有可能的度数（比如，1到6之间）的计算核，并在运行时选择合适的核。在这里，我们只是选择二阶[2.x.49]元素，并选择维度3作为标准。
*


* [1.x.96]
*
* [1.x.97] [1.x.98]。


*
* 我们为泊松问题定义了一个可变系数函数。它类似于[2.x.50]中的函数，但我们使用的是[2.x.51]的形式，而不是一个不连续的形式。这只是为了证明这种实现的可能性，而不是在物理上有什么意义。我们定义系数的方式与早期教程程序中的函数相同。有一个新的函数，即一个带有模板参数[2.x.53]的[2.x.52]方法
*


* [1.x.99]

* 这就是上面提到的新函数。评估抽象类型[2.x.54]的系数 它可能只是一个普通的双数，但它也可以是一个有点复杂的类型，我们称之为VectorizedArray。这种数据类型本质上是一个短的双数数组，正如在介绍中所讨论的那样，它可以容纳几个单元格的数据。例如，我们在这里评估的系数不是像通常那样在一个简单的点上，而是交给一个Point<dim,VectorizedArray<double>>点，在AVX的情况下，它实际上是四个点的集合。不要把VectorizedArray中的条目与点的不同坐标混淆。事实上，数据的布局是这样的：[2.x.55]返回一个VectorizedArray，它又包含了第一个点和第二个点的x坐标。你可以使用例如 [2.x.56] 单独访问坐标，j=0,1,2,3，但建议尽可能在一个VectorizedArray上定义操作，以便利用矢量操作。   
* 在函数的实现中，我们假设数字类型重载了基本的算术运算，所以我们只需照常写代码。然后，基类函数[2.x.57]是由双倍类型的模板函数计算出来的，以避免重复的代码。
*


* [1.x.100]
*
* [1.x.101] [1.x.102]。


*
* 下面这个名为[2.x.58]的类，实现了微分运算符。就所有的实际目的而言，它是一个矩阵，也就是说，你可以向它询问它的大小（成员函数 [2.x.59] ），你可以将它应用于一个矢量（[2.x.60] 函数）。当然，与实数矩阵的区别在于，这个类实际上并不存储矩阵的[1.x.103]，而只知道如何计算运算符应用于向量时的作用。   
* 描述矩阵大小、从MatrixFree对象初始化以及通过vmult()和Tvmult()方法实现矩阵-向量乘积的各种接口的基础结构，是由本类派生的[2.x.61]类提供的。这里定义的LaplaceOperator类只需要提供几个接口，即通过vmult()函数中使用的apply_add()方法来实现运算符的实际操作，以及计算底层矩阵对角线项的方法。我们需要对角线来定义多梯度平滑器。由于我们考虑的是一个具有可变系数的问题，我们进一步实现了一个可以填充系数值的方法。   
* 注意文件[2.x.62]已经包含了通过类[2.x.63]对拉普拉斯的实现。 出于教育目的，在这个教程程序中重新实现了该运算符，解释了其中的成分和概念。   
* 本程序利用了集成在deal.II中的有限元算子应用的数据缓存。这个数据缓存类被称为MatrixFree。它包含局部和全局自由度之间的映射信息（Jacobian）和索引关系。它还包含约束条件，如来自悬挂节点或迪里切特边界条件的约束。此外，它可以在所有单元上以%并行方式发出一个循环，确保只有不共享任何自由度的单元被处理（这使得循环在写入目标向量时是线程安全的）。与[2.x.64]模块中描述的WorkStream类相比，这是一个更先进的策略。当然，为了不破坏线程安全，我们在写入类全局结构时必须小心。   
* 实现拉普拉斯算子的类有三个模板参数，一个是维度（正如许多deal.II类所携带的），一个是有限元的度数（我们需要通过FEEvaluation类实现高效计算），还有一个是底层标量类型。我们希望对最终矩阵使用[2.x.65]数字（即双精度，64位浮点），但对多网格级矩阵使用浮点数（单精度，32位浮点数字）（因为那只是一个预处理程序，而浮点数的处理速度是两倍）。FEEvaluation类也需要一个模板参数，用于确定一维正交点的数量。在下面的代码中，我们把它硬编码为 [2.x.66] 。如果我们想独立于多项式程度来改变它，我们需要添加一个模板参数，就像在[2.x.67]类中做的那样。   
* 作为附带说明，如果我们在同一个网格和自由度上实现了几个不同的操作（比如质量矩阵和拉普拉斯矩阵），我们将为每个操作者定义两个像现在这样的类（源自[2.x.68]类），并让它们都引用一般问题类中的同一个MatrixFree数据缓存。通过[2.x.69]的接口要求我们只提供一组最小的函数。这个概念允许编写具有许多无矩阵操作的复杂应用代码。   
*

*
* [2.x.70] 储存[2.x.71]类型的值需要注意。在这里，我们使用deal.II表类，它准备以正确的排列方式来保存数据。然而，存储例如一个[2.x.72]是不可能用矢量的。数据与内存地址的边界需要一定的对齐（基本上，在AVX情况下，一个32字节长的VectorizedArray需要从一个能被32整除的内存地址开始）。表类（以及它所基于的AlignedVector类）确保这种对齐方式得到尊重，而[2.x.73]一般不这样做，这可能会导致一些系统在奇怪的地方出现分段故障，或者其他系统的性能不理想。
*


* [1.x.104]
*
* 这是[2.x.74]类的构造函数。它所做的就是调用基类[2.x.75]的默认构造函数，而基类又是基于Subscriptor类的，它断言这个类在超出范围后不会被访问，例如在一个预处理程序中。
*


* [1.x.105]
*
* [1.x.106] [1.x.107]。


*
* 为了初始化系数，我们直接赋予它上面定义的系数类，然后选择方法[2.x.76]与矢量数（编译器可以从点数据类型中推导出来）。下面将解释FEEvaluation类（及其模板参数）的使用。
*


* [1.x.108]
*
* [1.x.109] [1.x.110]。


*
* 这里是这个类的主要功能，矩阵-向量乘积的评估（或者，一般来说，一个有限元算子的评估）。这是在一个需要四个参数的函数中完成的，MatrixFree对象，目标和源向量，以及要处理的单元格的范围。MatrixFree类中的方法[2.x.77]将在内部用一些单元格范围来调用这个函数，这些单元格范围是通过检查哪些单元格可以同时工作来获得的，这样写操作就不会引起任何竞赛条件。请注意，循环中使用的单元格范围并不是直接指当前网格中的（活动）单元格数量，而是一个单元格批次的集合。  换句话说，"单元 "可能是一个错误的开始，因为FEEvaluation将几个单元的数据分组在一起。这意味着在正交点的循环中，我们实际上是将几个单元的正交点作为一个块来看待。这样做是为了实现更高的矢量化程度。  这种 "单元 "或 "单元批 "的数量存储在MatrixFree中，可以通过[2.x.78]查询。与deal.II单元迭代器相比，在这个类别中，所有的单元都被布置在一个普通的数组中，不直接知道水平或相邻关系，这使得通过无符号整数来索引单元成为可能。   
* 拉普拉斯运算符的实现是非常简单的。首先，我们需要创建一个对象FEEvaluation，它包含计算核，并有数据字段来存储临时结果（例如，在几个单元格集合的所有正交点上评估的梯度）。请注意，临时结果不会使用大量的内存，而且由于我们用元素顺序指定模板参数，数据被存储在堆栈中（没有昂贵的内存分配）。通常，只需要设置两个模板参数，维度作为第一个参数，有限元的度数作为第二个参数（这等于每个维度的自由度数减去FE_Q元素的一个）。然而，在这里，我们也希望能够使用浮点数来计算多网格预处理，这是最后一个（第五个）模板参数。因此，我们不能依赖默认的模板参数，因此必须填写第三和第四个字段。第三个参数指定每个方向的正交点的数量，其默认值等于元素的度数加1。第四个参数设置分量的数量（在PDEs系统中也可以评估矢量值的函数，但默认是标量元素），最后一个参数设置数字类型。   
* 接下来，我们在给定的单元格范围内循环，然后继续进行实际的实现。  [2.x.79] [2.x.80] 告诉FEEvaluation对象我们要处理的（宏）单元。   [2.x.81] 读入源向量的值（ [2.x.82] 包括约束的解析。这存储了[2.x.83]，如介绍中所述。   [2.x.84] 计算单元格梯度（有限元函数的评价）。由于FEEvaluation可以结合值计算和梯度计算，它使用一个统一的接口来处理0到2阶之间的各种导数。我们只想要梯度，不想要值，也不想要二阶导数，所以我们在梯度槽（第二槽）中将函数参数设置为真，而在值槽（第一槽）中设置为假。还有一个用于Hessian的第三槽，默认为假，所以不需要给它。请注意，FEEvaluation类在内部以一种有效的方式评估形状函数，一次只处理一个维度（如介绍中提到的使用形状函数和正交点的张量积形式）。与FEValues中使用的在所有局部自由度和正交点上循环的天真方法相比，在[2.x.87]维度上，这给出了等于[2.x.85]的多项式程度[2.x.86]的复杂度，并且花费[2.x.88] 。   [2.x.89] 接下来是雅各布变换的应用，乘以变量系数和正交权重。FEEvaluation有一个访问函数[2.x.90]，可以应用Jacobian并返回实空间中的梯度。然后，我们只需要乘以（标量）系数，并让函数[2.x.91]应用第二个雅各布式（用于测试函数）和正交权重及雅各布式行列式（JxW）。注意，提交的梯度存储在与[2.x.92]中读取梯度的地方相同的数据字段中。因此，你需要确保在调用[2.x.93]后不要再从同一正交点读取该特定正交点。一般来说，当[2.x.94]被多次使用时，复制它的结果是个好主意。   [2.x.95] 接下来是对所有测试函数的正交点进行求和，对应于实际积分步骤。对于拉普拉斯算子，我们只是乘以梯度，所以我们用各自的参数集调用积分函数。如果你有一个方程，同时用测试函数的值和梯度进行测试，那么两个模板参数都需要设置为真。先调用积分函数的值，再单独调用梯度，会导致错误的结果，因为第二次调用会在内部覆盖第一次调用的结果。请注意，积分步骤的二次导数没有函数参数。   [2.x.96] 最终，介绍中提到的向量[2.x.97]中的局部贡献需要被添加到结果向量中（并应用约束）。这是通过调用[2.x.98]来完成的，该函数与AffineConstraints中的相应函数名称相同（只是我们现在将局部向量存储在FEEvaluation对象中，正如局部和全局自由度之间的指数一样）。   [2.x.99]



* [1.x.111]
*
* 这个函数实现了[2.x.100]接口的所有单元的循环。这是通过MatrixFree类的[2.x.101]来实现的，它接受该类的operator()，参数为MatrixFree, OutVector, InVector, cell_range。当使用MPI并行化工作时（但没有线程），如本教程程序中所做的，单元格循环对应于以下三行代码。   
* [2.x.102]
* 这里，两个调用update_ghost_values()和compress()为MPI执行处理器边界上的数据交换，一次是源向量，我们需要从远程处理器拥有的条目中读取，另一次是目的向量，我们已经积累了部分残差，需要添加到所有者处理器的相应条目中。然而，[2.x.103]不仅抽象出了这两个调用，而且还进行了一些额外的优化。一方面，它将把update_ghost_values()和compress()的调用拆开，以允许通信和计算的重叠。然后用三个代表从0到[2.x.104]的单元格范围的分区来调用local_apply函数。另一方面，cell_loop也支持线程并行，在这种情况下，单元格范围被分割成更小的块，并以一种先进的方式安排，避免了几个线程对同一个向量条目的访问。这一特性在 [2.x.105] 中有解释。   
* 请注意，在单元格循环之后，受约束的自由度需要再次被触及，以获得合理的vmult()操作。由于装配循环会自动解决约束问题（就像[2.x.106]中的调用一样），它不会计算约束自由度的任何贡献，使各自的条目为零。这将表示一个矩阵的受限自由度的行和列都是空的。然而，像CG这样的迭代求解器只对非星形矩阵有效。最简单的方法是将矩阵中对应于受限自由度的子块设置为同一矩阵，在这种情况下，矩阵的应用只是将右侧向量的元素复制到左侧。幸运的是，vmult()的实现[2.x.107]在apply_add()函数之外自动为我们做了这个，所以我们不需要在这里采取进一步的行动。   
* 当使用MatrixFree和FEEvaluation的组合与MPI并行时，有一个方面需要注意&mdash；用于访问向量的索引。出于性能的考虑，MatrixFree和FEEvaluation被设计为在MPI本地索引空间中访问向量，当与多个处理器一起工作时也是如此。在本地索引空间工作意味着除了不可避免的间接寻址外，在向量访问发生的地方不需要进行索引转换。然而，本地索引空间是模糊的：虽然标准的惯例是用0和本地大小之间的索引访问向量的本地拥有的范围，但对于重影项的编号并不那么明确，而且有些随意。对于矩阵-向量乘积，只有出现在本地拥有的单元格上的指数（加上那些通过悬挂节点约束引用的指数）是必要的。然而，在deal.II中，我们经常将重影元素上的所有自由度设置为重影向量条目，称为[2.x.108]"术语表中描述的局部相关自由度"。在这种情况下，尽管指的是同一个全局索引，但在两个可能的重影集中，重影向量条目的MPI本地索引一般会有所不同。为了避免问题，FEEvaluation通过一个名为[2.x.109]的检查来检查用于矩阵-向量乘积的向量分区是否确实与MatrixFree中的索引分区相匹配。 为了方便，[2.x.110]类包括一个机制来使鬼魂集适应正确的布局。这发生在向量的ghost区域，所以请记住，在调用vmult()方法后，目标和源向量的ghost区域都可能被修改。这是合法的，因为分布式deal.II矢量的ghost区域是一个可变的部分，并按需填充。在矩阵-向量乘积中使用的向量在进入vmult()函数时不能被重影，所以没有信息丢失。
*


* [1.x.113]

* 下面的函数实现了算子的对角线的计算。计算无矩阵算子评价的矩阵项原来比评价算子更复杂。从根本上说，我们可以通过在[1.x.114]单位向量上应用算子来获得算子的矩阵表示。当然，这将是非常低效的，因为我们需要进行[1.x.115]运算符的评估来检索整个矩阵。此外，这种方法会完全忽视矩阵的稀疏性。然而，在单个单元上，这是一种方法，而且实际上效率并不低，因为单元内的所有自由度之间通常存在着耦合。   
* 我们首先将对角线向量初始化为正确的并行布局。这个向量被封装在基类[2.x.111]中DiagonalMatrix类型的一个名为inverse_diagonal_entries的成员中，这个成员是一个共享指针，我们首先需要初始化它，然后获取代表矩阵中对角线条目的向量。至于实际的对角线计算，我们再次使用MatrixFree的cell_loop基础设施来调用一个名为local_compute_diagonal()的本地工作程序。由于我们只写进一个向量，而没有任何源向量，我们用一个<tt>unsigned int</tt>类型的假参数来代替源向量，以便与cell_loop接口确认。在循环之后，我们需要将受Dirichlet边界条件约束的向量条目设置为1（要么是MatrixFree内部AffineConstraints对象描述的边界上的条目，要么是自适应多网格中不同网格层次之间的索引）。这是通过函数[2.x.112]完成的，并与Base算子提供的矩阵-向量乘积中的设置相匹配。最后，我们需要反转对角线条目，这是基于Jacobi迭代的Chebyshev平滑器所要求的形式。在循环中，我们断言所有条目都是非零的，因为它们应该从积分中获得了正的贡献，或者被约束并被[2.x.113]以下的cell_loop处理。
*


* [1.x.116]
*
* 在本地计算循环中，我们通过循环本地矩阵的所有列来计算对角线，并将条目1放在[1.x.117]的槽中，将条目0放在所有其他槽中，也就是说，我们一次在一个单位向量上应用单元微分算子。调用[2.x.114]的内部部分是对正交点的循环，而[2.x.115]则与local_apply函数完全相同。之后，我们挑选出本地结果的第[1.x.118]个条目，并将其放入一个临时存储器中（因为我们在下一次循环迭代时覆盖了[2.x.116]后面数组中的所有条目）。最后，临时存储被写到目标向量中。注意我们是如何使用[2.x.117]和[2.x.118]来读取和写入FEEvaluation用于积分的数据字段，并在另一方面写入全局向量。   
* 鉴于我们只对矩阵的对角线感兴趣，我们干脆扔掉一路走来计算过的本地矩阵的所有其他条目。虽然计算完整的单元格矩阵，然后扔掉除对角线以外的所有东西看起来很浪费，但整合的效率很高，所以计算不会花费太多的时间。请注意，对于多项式程度来说，每个元素的算子评估的复杂度是[2.x.119]，所以计算整个矩阵要花费我们[2.x.121]次操作，与用FEValues计算对角线的复杂度[2.x.122]相差不大。由于FEEvaluation也由于矢量化和其他优化而大大加快了速度，所以用这个函数计算对角线实际上是最快的（简单的）变量。(有可能用[2.x.123]操作中的和因子化技术来计算对角线，这涉及到特别适应的内核&mdash;但由于这种内核只在特定情况下有用，而对角线的计算通常不在关键路径上，所以它们没有在deal.II中实现。)   
* 请注意，在向量上调用distribution_local_to_global来将对角线条目累积到全局矩阵的代码有一些限制。对于具有悬挂节点约束的操作者来说，将一个受约束的DoF的积分贡献分配到distribution_local_to_global调用中的其他几个条目上，这里使用的向量接口并不完全计算对角线条目，而是将一些位于本地矩阵对角线上的贡献，最终在全局矩阵的对角线以外的位置上堆积起来。正如[1.x.119]中所解释的，该结果在离散化精度上是正确的，但在数学上并不平等。在这个教程程序中，不会发生任何危害，因为对角线只用于没有悬挂节点约束出现的多网格级矩阵。
*


* [1.x.120]
*
* [1.x.121] [1.x.122]。


*
* 这个类是基于 [2.x.124] 中的一个类。然而，我们用我们的无矩阵实现取代了SparseMatrix<double>类，这意味着我们也可以跳过稀疏性模式。请注意，我们定义LaplaceOperator类时，将有限元的度数作为模板参数（该值在文件的顶部定义），并且我们使用浮点数来表示多网格级矩阵。   
* 该类还有一个成员变量，用来记录在我们真正去解决问题之前设置整个数据链的所有详细时间。此外，还有一个输出流（默认情况下是禁用的），可以用来输出各个设置操作的细节，而不是默认情况下仅打印出的摘要。   
* 由于这个程序被设计成与MPI一起使用，我们也提供了通常的[2.x.125]输出流，只打印MPI等级为0的处理器的信息。这个程序使用的网格可以是基于p4est的分布式三角形（如果deal.II被配置为使用p4est），否则它就是一个只在没有MPI的情况下运行的串行网格。
*


* [1.x.123]
*
* 当我们初始化有限元时，我们当然也要使用文件顶部指定的度数（否则，在某些时候会抛出一个异常，因为在模板化的LaplaceOperator类中定义的计算内核和MatrixFree读出的有限元信息将不匹配）。三角形的构造函数需要设置一个额外的标志，告诉网格要符合顶点上的2:1单元平衡，这对于几何多网格例程的收敛是必需的。对于分布式网格，我们还需要特别启用多网格的层次结构。
*


* [1.x.124]
*
* LaplaceProblem类拥有一个额外的输出流，收集关于设置阶段的详细时间。这个流被称为time_details，默认情况下通过这里指定的[2.x.126]参数被禁用。对于详细的时间，去掉[2.x.127]参数可以打印出所有的细节。
*


* [1.x.125]
*
* [1.x.126] [1.x.127]。


*
* 设置阶段与[2.x.128]类似，由于LaplaceOperator类的存在而有相关的变化。首先要做的是设置DoFHandler，包括多网格层次的自由度，以及初始化悬挂节点的约束和同质Dirichlet条件。由于我们打算在%parallel的MPI中使用这个程序，我们需要确保约束条件能知道本地相关的自由度，否则在使用超过几亿个自由度时，存储会爆炸，见[2.x.129] 。
*

*
* 一旦我们创建了多网格dof_handler和约束条件，我们就可以为全局矩阵算子以及多网格方案的每一级调用 reinit 函数。主要的操作是为问题设置[2.x.130]实例。2.x.131]类的基类，[2.x.132]被初始化为一个指向MatrixFree对象的共享指针。这样，我们可以在这里简单地创建它，然后将它分别传递给系统矩阵和水平矩阵。为了设置MatrixFree，我们需要激活MatrixFree的AdditionalData字段中的更新标志，使其能够存储实空间中的正交点坐标（默认情况下，它只缓存梯度（反转置的雅各布）和JxW值的数据）。请注意，如果我们调用 reinit 函数而不指定级别（即给出 [2.x.133] ），MatrixFree 会在活动单元上构建一个循环。在本教程中，除了MPI之外，我们不使用线程，这就是为什么我们通过将[2.x.134]设置为[2.x.135]来明确地禁用它 最后，系数被评估，向量被初始化，如上所述。
*


* [1.x.128]
*
* 接下来，初始化所有层次上的多网格方法的矩阵。数据结构MGConstrainedDoFs保留了受边界条件约束的指数信息，以及不同细化层次之间的边缘指数，如[2.x.136]教程程序中所述。然后，我们穿过网格的各个层次，在每个层次上构建约束和矩阵。这与原始网格上的系统矩阵的构造密切相关，只是在访问各层信息而不是活动单元时，在命名上略有不同。
*


* [1.x.129]
*
* [1.x.130] [1.x.131]。


*
* 组装函数非常简单，因为我们要做的就是组装右手边的数据。多亏了FEEvaluation和所有缓存在MatrixFree类中的数据，我们从[2.x.137]中查询，这可以在几行中完成。由于这个调用没有被包装成一个[2.x.138]（这将是一个替代方案），我们一定不要忘记在装配结束时调用compress()，将右手边的所有贡献发送给各自自由度的所有者。
*


* [1.x.132]
*
* [1.x.133] [1.x.134]。


*
* 解决的过程与[2.x.139]中类似。我们先从转移的设置开始。对于[2.x.140]来说，有一个非常快速的转移类，叫做MGTransferMatrixFree，它用同样的快速和因子化核在网格层之间进行插值，这也被用于FEEvaluation。
*


* [1.x.135]
*
* 作为一个平滑器，本教程程序使用切比雪夫迭代，而不是[2.x.141]中的SOR。（SOR将很难实现，因为我们没有明确的矩阵元素，而且很难使它在%并行中有效工作）。  平滑器是用我们的水平矩阵和切比雪夫平滑器的强制性附加数据初始化的。我们在这里使用一个相对较高的度数（5），因为矩阵-向量乘积是比较便宜的。我们选择在平滑器中平滑出[2.x.142]的范围，其中[2.x.143]是最大特征值的估计值（系数1.2在PreconditionChebyshev内部应用）。为了计算该特征值，Chebyshev初始化执行了几步没有预处理的CG算法。由于最高的特征值通常是最容易找到的，而且一个粗略的估计就足够了，我们选择10次迭代。最后，我们还设置了切比雪夫方法中的内部预处理类型，这是一个雅可比迭代。这由DiagonalMatrix类来表示，该类得到了我们的LaplaceOperator类所提供的反对角线条目。     
* 在零级，我们以不同的方式初始化平滑器，因为我们想使用切比雪夫迭代作为求解器。PreconditionChebyshev允许用户切换到求解器模式，其中迭代次数在内部选择为正确值。在附加数据对象中，通过选择多项式程度为[2.x.144]来激活这一设置，然后算法将攻击粗级矩阵中最小和最大之间的所有特征值。切比雪夫平滑器的步数是这样选择的：切比雪夫收敛估计值保证将残差减少到变量[2.x.145]平滑_范围中指定的数量。注意，对于求解来说，[2.x.146]是一个相对的公差，并且选择小于1，在这种情况下，我们选择三个数量级，而当只对选定的特征值进行平滑时，它是一个大于1的数字。     
* 从计算的角度来看，只要粗粒度适中，Chebyshev迭代是一个非常有吸引力的粗粒度求解器。这是因为Chebyshev方法只执行矩阵-向量乘积和向量更新，这通常比其他迭代方法中涉及的内积更好地并行到具有几万个核心的最大集群规模。前者只涉及（粗）网格中邻居之间的局部通信，而后者则需要在所有处理器上进行全局通信。
*


* [1.x.136]
*
* 下一步是设置悬挂节点情况下所需的接口矩阵。deal.II中的自适应多网格实现了一种叫做局部平滑的方法。这意味着最细级别的平滑只覆盖固定（最细）网格级别所定义的网格的局部部分，而忽略了计算域中终端单元比该级别更粗的部分。随着该方法向更粗的级别发展，越来越多的全局网格将被覆盖。在某个更粗的层次上，整个网格将被覆盖。由于多网格方法中的所有层次矩阵都覆盖了网格中的单一层次，所以在层次矩阵上不会出现悬空节点。在多网格层之间的界面上，在平滑的同时设置同质Dirichlet边界条件。然而，当残差被转移到下一个更粗的层次时，需要考虑到多网格界面的耦合。这是由所谓的界面（或边缘）矩阵来完成的，它计算了被具有同质Dirichlet条件的层次矩阵所遗漏的残差部分。我们参考[2.x.147]"Janssen和Kanschat的多网格论文 "以了解更多细节。     
* 对于这些接口矩阵的实现，已经有一个预定义的类[2.x.148]，它将例程[2.x.149]和[2.x.150]包装在一个带有[2.x.151]vmult()和[2.x.152]操作（最初是为矩阵编写的，因此期待这些名字）的新类中。请注意，vmult_interface_down是在多网格V周期的限制阶段使用的，而vmult_interface_up是在延长阶段使用。     
* 一旦接口矩阵被创建，我们就完全类似于[2.x.153]来设置其余的多重网格预处理基础设施，以获得一个可以应用于矩阵的[2.x.154]对象。
*


* [1.x.137]
*
* 多网格程序的设置非常简单，与[2.x.155]相比，在求解过程中看不出有什么不同。所有的魔法都隐藏在[2.x.156]操作的实现背后。请注意，我们通过标准输出打印出求解时间和累积的设置时间，也就是说，在任何情况下，而设置操作的详细时间只有在构造函数中的detail_times标志被改变的情况下才会打印。
*


*


* [1.x.138]
*
* [1.x.139] [1.x.140]。


*
* 这里是数据输出，是[2.x.157]的简化版本。我们对细化过程中产生的每个网格使用标准的VTU（=压缩的VTK）输出。此外，我们还使用了一种针对速度而不是磁盘使用量进行优化的压缩算法。默认设置（针对磁盘使用进行优化）使得保存输出的时间是运行线性求解器的4倍，而将[2.x.158]设置为[2.x.159]则将其降低到仅为线性求解的四分之一。   
* 当网格过大时，我们会禁用输出。这个程序的一个变种已经在几十万个MPI行列上运行，网格单元多达1000亿个，经典的可视化工具无法直接访问。
*


* [1.x.141]
*
* [1.x.142] [1.x.143]。


*
* 运行该程序的函数与 [2.x.160] 中的函数非常相似。与2D相比，我们在3D中做了很少的细化步骤，但仅此而已。   
* 在我们运行程序之前，我们输出一些关于检测到的矢量化水平的信息，正如介绍中所讨论的那样。
*


* [1.x.144]
*
* [1.x.145] [1.x.146]。


*
* 除了我们根据[2.x.161]设置了MPI框架之外，在主函数中没有任何意外。
*


* [1.x.147]
* [1.x.148][1.x.149] 。


*[1.x.150][1.x.151]


* 由于这个例子解决的是与[2.x.162]相同的问题（除了一个不同的系数），所以对解决方案没有什么可说的。但我们还是展示了一张图片，通过等高线和体积渲染来说明解决方案的大小。
* [2.x.163]
当我们在二维上运行这个程序时，对于二次（[2.x.164]）元素，我们得到以下输出（当在释放模式下在一个核心上运行时）： *更感兴趣的是评估多网格求解器的某些方面。
* [1.x.152]
*
* 如同在[2.x.165]中，我们看到CG迭代的数量在自由度增加的情况下保持不变。恒定的迭代次数（加上最佳的计算特性）意味着计算时间随着问题大小从一个周期到下一个周期的四倍而翻倍增长。该代码在存储方面也非常有效。大约2-4百万度的自由度适合于1GB的内存，也见下面的MPI结果。一个有趣的事实是，尽管没有建立矩阵，但解决一个线性系统比设置要便宜（大约一半的时间花在[2.x.166]和[2.x.167]调用上）。这表明这种方法的效率很高，但也表明deal.II数据结构的设置相当昂贵，设置成本必须在几次系统求解中摊销。
* 如果我们在三个空间维度上运行该程序，则变化不大。由于我们使用统一的网格细化，我们得到八倍的元素和大约八倍的自由度的每个周期。
* [1.x.153]
*
* 既然如此简单，我们来看看如果我们增加多项式的度数会发生什么。当在三维中选择四度，即在[2.x.168]元素上，通过改变程序顶部的<code>const unsigned intdegree_finite_element=4;</code>一行，我们得到以下的程序输出。
* [1.x.154]
*
* 由于某个网格上的[2.x.169]元素对应于一半网格大小上的[2.x.170]元素，我们可以比较在第四周期使用四度多项式和第五周期使用二次多项式的运行时间，两者都是210万自由度。令人惊讶的是，尽管多用了一次线性迭代，[2.x.171]元素的求解器实际上比四次方的情况略快。高阶多项式同样快，甚至比低阶多项式更快，这是通过和因子化进行无矩阵算子评估的主要优势之一，见[1.x.155]。这与基于矩阵的方法有根本的不同，后者随着多项式度数的增加和耦合的密集，每个未知数的成本也越来越高。
* 此外，高阶的设置也会变得便宜一些，这是因为需要设置的元素较少。
* 最后，让我们看一下度数为8的时间，这相当于低阶方法的另一轮网格细化。
* [1.x.156]
*
* 在这里，初始化似乎比以前慢了很多，这主要是由于矩阵对角线的计算，它实际上是在每个单元上计算一个729 x 729的矩阵，并丢弃除对角线以外的所有东西。然而，解算时间又非常接近四分法的情况，表明理论上预期的随着多项式度数增加的线性增长几乎完全被更好的计算特性所抵消，而且高阶方法在几个单元上的自由度份额较小，增加了评估的复杂性。
*[1.x.157][1.x.158]
*

* 为了了解无矩阵实现的能力，我们通过测量问题初始化的计算时间（分配DoF、设置和装配矩阵、设置多网格结构），以及无矩阵变体和基于稀疏矩阵的变体的实际解法，来比较上述3D例子和基于稀疏矩阵的变体的性能。如上所示，我们将预处理程序建立在浮点数上，而实际的矩阵和向量建立在双数上。测试在英特尔Corei7-5500U笔记本处理器上运行（两个核心，支持[1.x.159]，即用一条CPU指令可以完成对双数的四次操作，这在FEE评估中被大量使用），优化模式，以及两个MPI等级。
* [2.x.173]
* 该表清楚地表明，无矩阵实现的求解器速度是原来的两倍多，而在初始化成本方面则是六倍多。由于问题的大小被放大了8倍，我们注意到时间通常也上升了8倍（因为求解器的迭代次数恒定为6）。主要的偏差是在5k到36k自由度的稀疏矩阵中，时间增加了12倍。这是处理器中的(L3)缓存不能再容纳矩阵-向量乘积所需的所有数据的阈值，所有的矩阵元素必须从主内存中获取。
* 当然，这种情况不一定适用于所有情况，因为有些问题，对矩阵项的了解可以使解算器的效果更好（如当系数的变化比上面的例子更强烈时就会发生）。此外，这也取决于计算机系统。目前的系统具有良好的内存性能，因此稀疏矩阵的性能相当好。尽管如此，对于本例中使用的[1.x.160]<sub>2</sub>元素，无矩阵的实现已经给出了一个很好的速度。这一点对于时间依赖性或非线性问题尤其明显，在这些问题中，疏散矩阵需要一次又一次地被重新组合，这在这个类别中变得更加容易。当然，由于products有更好的复杂性，当元素的阶数增加时，该方法会获得越来越大的优势（无矩阵实现的成本是4[1.x.161]<sup>2</sup>[1.x.162]每个自由度，而稀疏矩阵的成本是2[1.x.163]，所以在3D中阶数4和更高时它会赢）。
*[1.x.164][1.x.165]
*

* 正如介绍和代码中的注释所解释的，这个程序可以用MPI并行运行。事实证明，几何多网格方案工作得非常好，可以扩展到非常大的机器。据作者所知，这里显示的几何多网格结果是截至2016年底用deal.II进行的最大计算，在[1.x.166]的147456个核心上运行。超过1000个核心的可扩展性的要素是，没有任何依赖于全局问题大小的数据结构在单个处理器上保持其完整性，并且通信不是太频繁，以避免遇到网络的延迟问题。  对于用迭代求解器求解的PDEs，通信延迟往往是限制性因素，而不是网络的吞吐量。以SuperMUC系统为例，两个处理器之间的点对点延迟在1e-6到1e-5秒之间，这取决于MPI网络的远近。这一类的矩阵-向量积[2.x.174]涉及几个点对点的通信步骤，与每个核上的计算交错进行。矩阵-向量乘积的延迟约为1e-4秒。全局通信，例如一个[2.x.175]操作，在MPInetwork的所有等级上累积每个等级的一个数字之和，其延迟为1e-4秒。这个程序中使用的多网格V型循环也是全局通信的一种形式。想一想发生在单个处理器上的粗略的网格解算。在开始之前，它积累了来自所有处理器的贡献。当完成后，粗网格解决方案被转移到更细的层次，在那里越来越多的处理器帮助进行平滑，直到细网格。从本质上讲，这是在网络中的处理器上的一个树状模式，由网格控制。与[2.x.176]操作不同的是，多网格V型循环是根据MPI网络中的实际链路来优化还原树，而多网格V型循环则是根据网格的划分来进行。因此，我们不能期望有同样的优化效果。此外，多网格循环并不是简单地在细化树上走来走去，而是在做平滑时在每一层上进行通信。换句话说，多网格中的全局通信更具有挑战性，并且与提供较少优化机会的网格有关。测得的V-循环的延迟在6e-3和2e-2秒之间，即与60到200个MPI_Allreduce操作相同。
* 下图显示了在[2.x.177]元素上进行的缩放实验。沿着这条线，问题的大小随着核数的增加而保持不变。当内核数量增加一倍时，人们期望计算时间减少一半，灰色虚线表示。结果显示，在达到0.1秒左右的绝对时间之前，该实现几乎显示了理想的行为。解算器的容差被设定为解算器进行了五次迭代。这种绘制数据的方式是该算法的[1.x.167]。当我们进入非常大的核数时，曲线会提前变平，这是因为SuperMUC的通信网络，较远的处理器之间的通信速度稍慢。
* [2.x.178]
* 此外，该图还包含了[1.x.168]的结果，列出了当处理器内核和元素的数量以同样的速度增加时，算法的表现。在这种情况下，我们希望计算时间保持不变。在算法上，CG的迭代次数恒定在5次，所以我们在这方面做得很好。图中的线条是这样排列的：每个数据系列中的左上角代表每个处理器的相同大小，即131,072个元素（或每个核心约3.5百万自由度）。表示理想的强标度的灰色线条相隔8个相同的系数。结果再次表明，扩展性几乎是理想的。从288个核到147456个核的并行效率约为75%，每个核的局部问题大小为750,000自由度，在288个核上需要1.0秒，在2304个核上需要1.03秒，在18000个核上需要1.19秒，在147000个核上需要1.35秒。这些算法也达到了非常高的处理器利用率。在147k核上的最大计算量在SuperMUC上达到约1.7 PFLOPs/s，其中算术峰值为3.2 PFLOPs/s。对于一个迭代式PDE求解器来说，这是一个非常高的数字，而且通常只有密集线性代数才会达到明显的数字。稀疏线性代数被限制在这个数值的十分之一。
* 正如在介绍中提到的，无矩阵方法减少了数据结构的内存消耗。除了由于较少的内存传输而带来的更高的性能外，这些算法还允许非常大的问题在内存中得到解决。下图显示了当我们增加问题大小时的计算时间，直到计算耗尽内存的上限。我们对1k核、8k核和65k核进行了计算，发现问题的大小几乎可以在两个数量级上进行理想的扩展。这张图中显示的最大的计算涉及2920亿（[2.x.179]）个自由度。在147k核的DG计算中，上述算法也被运行，涉及多达5490亿（2^39）个自由度。
* [2.x.180]
* 最后，我们注意到，在对上述大规模系统进行测试的同时，deal.II中的多网格算法的改进也被开发出来了。最初的版本包含了基于MGSmootherPrecondition的次优代码，其中一些MPI_Allreduce命令（检查所有向量条目是否为零）在每一级的平滑操作上进行，这只有在65k核以上才变得明显。然而，下面的图片显示，改进已经在较小的规模上得到了回报，这里显示的是对[2.x.181]元素在多达14,336个核心上的计算。
* [2.x.182]
*

*[1.x.169][1.x.170]


* 正如代码中所解释的，这里介绍的算法是为运行在自适应细化的网格上而准备的。如果只有部分网格被细化，多网格循环将以局部平滑的方式运行，并在细化程度不同的界面上施加迪里切条件，通过[2.x.183]类进行平滑。由于自由度在层次上的分配方式，将层次单元的所有者与第一个下级活动单元的所有者联系起来，在MPI中不同的处理器之间可能存在不平衡，这限制了可扩展性，约为2-5倍。
*[1.x.171][1.x.172]
*

*[1.x.173][1.x.174]


* 如上所述，代码已准备好用于局部自适应h-精简。对于泊松方程，可以采用KellyErrorEstimator类中实现的Kelly误差指标。为了评估误差指标中的跳跃项，每个MPI进程都需要知道本地相关的DoFs.然而[2.x.184]函数只用一些本地相关的自由度初始化向量。向量中提供的鬼魂指数是一个严格的集合，只有那些在单元积分中被触及的指数（包括约束条件的解决）。]，如下图所示。
* [1.x.175]

* [1.x.176][1.x.177] 。
*

* 这个程序只用MPI来并行化。作为一种选择，MatrixFreeloop也可以在混合模式下发布，例如，在一个集群的节点上使用MPI并行化，在一个节点的共享内存区域内通过Intel TBB使用线程。要使用这个方法，需要在主函数的MPI_InitFinalize数据结构中设置线程数，并设置[2.x.186]topartition_color来实际进行并行循环。这个用例在 [2.x.187] 中进行了讨论。
* [1.x.178][1.x.179] 。
*

*所提出的程序假定了同质的Dirichlet边界条件。如果涉及到非均质条件，情况就比较复杂了。为了了解如何实现这样的设置，让我们首先回顾一下这些条件是如何在数学公式中出现的，以及它们是如何在基于矩阵的变体中实现的。从本质上讲，非均质迪里希特条件将解中的一些节点值设定为给定值，而不是通过变分原理来确定它们，[1.x.180] 。
*其中[2.x.188]表示解决方案的节点值，[2.x.189]表示所有节点的集合。集合[2.x.190]是受Dirichlet边界条件约束的节点子集，其中解决方案被迫等于[2.x.191]作为Dirichlet约束节点点[2.x.192]上的插值边界值。然后我们把这个解的表示插入到弱的形式中，例如上面显示的拉普拉斯，并把已知量移到右边：[1.x.181] 。
* 在这个公式中，方程对所有与迪里希特条件约束的节点无关的基函数[2.x.193]和[2.x.194]进行检验。
* 在deal.II的实现中，右侧的积分[2.x.195]已经包含在我们在每个单元上组装的局部矩阵贡献中。当使用[2.x.196]时，如[2.x.197]和[2.x.198]教程程序中首次描述的那样，我们可以通过将本地矩阵的列[1.x.183]和行[1.x.184]相乘来说明同质约束[1.x.182]的贡献。]的局部矩阵根据积分[2.x.199]乘以不均匀性，然后从全局右侧向量的位置[1.x.185]中减去所得到的结果，也见[2.x.200]模块。实质上，我们使用了一些从方程左手边消除的积分来最终确定右手边的贡献。当首先将所有条目写进左手边的矩阵，然后通过[2.x.201]消除矩阵的行和列时，也会涉及类似的数学。
* 原则上，属于受限自由度的成分可以从线性系统中消除，因为它们不携带任何信息。在实践中，在deal.II中，我们始终保持线性系统的大小不变，以避免处理两种不同的编号系统，并避免对两种不同的索引集产生混淆。为了确保线性系统在不向约束行添加任何东西时不会变得奇异，我们会在矩阵对角线上添加与实际条目无关的假条目。
* 在无矩阵方法中，我们需要采取不同的方法，因为[2.x.202]LaplaceOperator类代表了[1.x.186]算子的矩阵-向量乘积（最后一个公式的左侧）。  传递给[2.x.203]的AffineConstraints对象是否包含不均匀约束并不重要，[2.x.204]调用将只解决约束的均匀部分，只要它代表一个[1.x.187]算子。
* 在我们的无矩阵代码中，非均质条件的贡献最后的右手边计算与矩阵算子完全脱钩，由上述不同的函数处理。因此，我们需要明确地生成进入右手边的数据，而不是使用矩阵装配的副产品。由于我们已经知道如何在向量上应用运算符，我们可以尝试对一个向量使用这些设施，在那里我们只设置Dirichlet值。
* [1.x.188]
* 或者说，如果我们已经将不均匀约束填入AffineConstraints对象中。
* [1.x.189]
*
* 然后我们可以将向量[2.x.205]传递给[2.x.206][2.x.207]函数，并将新的贡献添加到[2.x.208]system_rhs向量中，该向量在[2.x.209]函数中被填充。然而，这个想法并不奏效，因为vmult()函数中使用的[2.x.210]调用假定所有约束条件的值都是同质的（否则算子就不是线性算子，而是仿生算子）。为了同时检索同质性的值，我们可以选择以下两种策略之一。
*[1.x.190][1.x.191]
*

* FEEvaluation类有一个设施，正好解决了这个要求。对于非均质的Dirichlet值，我们确实希望在从向量[2.x.211]中读取数据时跳过对均质（Dirichlet）约束的隐式施加。例如，我们可以扩展[2.x.212][2.x.213]函数来处理非均质的Dirichlet值，如下所示，假设Dirichlet值已被插值到对象[2.x.214]中
* [1.x.192]
*
* 在这段代码中，我们用[2.x.216]代替了用于暂定解向量的[2.x.215]函数，该函数忽略了所有的约束。由于这种设置，我们必须确保其他约束条件，例如悬挂的节点，已经正确地分布到输入向量中，因为它们没有像[2.x.217]中那样被解决。 在循环中，我们然后评估拉普拉斯，并用[2.x.219]类中的[2.x.218]重复二次导数的调用，但将符号调换，因为我们想根据上面的公式减去右侧向量中迪里切条件的贡献。当我们调用[2.x.220]调用时，我们将关于值槽和第一导数槽的两个参数都设置为真，以说明在正交点的循环中增加的这两个条件。一旦右手边组装完毕，我们就继续求解同质问题的线性系统，例如涉及到一个变量[2.x.221]在求解之后，我们可以将[2.x.222]添加到包含最终（非同质）解决方案的[2.x.223]向量。
* 请注意，拉普拉斯的负号与我们需要建立右手边的强制力的正号一起，是一个更普遍的概念。我们所实施的只不过是牛顿的非线性频率方法，但应用于线性系统。我们根据迪里切特边界条件对变量[2.x.224]进行了初始猜测，并计算了一个残差[2.x.225]。然后对线性系统进行求解[2.x.226]，最后计算出[2.x.227]。对于线性系统，我们显然在一次迭代后就能得到精确的解。如果我们想将代码扩展到非线性问题，我们会将[2.x.228]函数命名为一个更具描述性的名字，如[2.x.229] assemble_residual()，计算残差的（弱）形式，而[2.x.230]函数将得到残差相对于解变量的线性化。
*[1.x.193][1.x.194]
*

* 获得重新使用[2.x.231][2.x.232]函数的第二个替代方法是添加第二个LaplaceOperator，跳过Dirichlet约束。为了做到这一点，我们初始化第二个MatrixFreeobject，它没有任何边界值约束。这个[2.x.233]对象然后被传递给一个[2.x.234]类实例[2.x.235]inhomogeneous_operator，它只用于创建右手边。
* [1.x.195]
*
* 这个技术的一个更复杂的实现可以重用原始MatrixFree对象。这可以通过用多个块初始化MatrixFree对象来实现，其中每个块对应于不同的AffineConstraints对象。这样做需要对LaplaceOperator类进行大量修改，但库中的[2.x.236]类可以做到这一点。参见[2.x.237]中关于块的讨论，以了解更多关于如何设置块的信息。
*

* [1.x.196][1.x.197] [2.x.238]。
* [0.x.1]

