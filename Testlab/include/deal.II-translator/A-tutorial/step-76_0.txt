include/deal.II-translator/A-tutorial/step-76_0.txt
[0.x.0]*
 [2.x.0] 
* 本教程依赖于 [2.x.1] 。
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18][1.x.19][1.x.20]
 
* [2.x.2] 
* [1.x.21]
* [1.x.22][1.x.23][1.x.24] 。
 

* 这个教程程序求解流体力学的欧拉方程，使用了一个显式时间积分器，其无矩阵框架应用于空间的高阶不连续Galerkin离散化。这里使用的数值方法与[2.x.3]中使用的相同，但是，我们利用了不同的高级无矩阵技术，以达到更高的吞吐量。
* 本教程的两个主要特点是。
* 
* - 使用MPI-3.0的共享内存特性和
* 
* 使用以单元为中心的循环，它只允许向全局向量写入一次，因此，是使用共享内存的理想选择。
* 我们在本教程中讨论的其他主题是模板参数VectorizedArrayType的用法和好处（而不是简单地使用VectorizedArray<Number>），以及向MatrixFree循环传递lambdas的可能性。
* 关于数字的细节，我们可以参考 [2.x.4] 的文档。我们在这里只集中讨论主要的区别。
* [1.x.25][1.x.26] 。
* 

* [1.x.27][1.x.28] 。
* 

* 存在许多基于线程的共享内存库，如TBB、OpenMP或TaskFlow。将这些库集成到现有的MPI程序中，就可以使用共享内存。然而，这些库对程序员来说有一定的开销，因为所有可并行化的代码部分都要根据所使用的库进行查找和转换，包括当第三方数值库，如迭代求解器包，只依赖MPI时的困难。
* 考虑到一个纯粹的MPI并行化的有限元应用，我们可以发现，使用共享内存的主要时间和内存优势来自于访问同一计算节点上的进程所拥有的解向量的部分，而不需要进行明确的复制和缓冲。
*[1.x.29][1.x.30]
* 

* 一些相关的MPI-3.0命令值得详细讨论。一个新的MPI通信器[2.x.5]，由可以访问相同共享内存的通信器[2.x.6]的进程组成，可以通过以下方式创建。
* [1.x.31]
* 
* 下面的代码片断显示了简化的共享内存的分配程序，包括值类型[2.x.7]和大小[2.x.8]，以及如何查询属于同一共享内存域的进程的数据指针。
* [1.x.32]
* 
* 一旦不再需要数据，窗口就必须被释放，这也会释放本地拥有的数据。
* [1.x.33]
* 
* [1.x.34][1.x.35].
* 

* 上一节提到的命令被整合到了[2.x.9]中，如果为reinit()函数提供了一个可选的（第二）通信器，就可以用来分配共享内存。
* 例如，可以用一个分区器（包含全局通信器）和一个子通信器（包含同一计算节点上的进程）来设置一个向量。
* [1.x.36]
 
*本地拥有的值和幽灵值可以像往常一样被处理。然而，现在用户也可以读取共享内存邻居的值 viathe函数。
* [1.x.37]
* 
* [1.x.38][1.x.39] 。
* 

* 虽然[2.x.10]提供了分配共享内存的选项，并以协调的方式访问相邻进程的共享内存的值，但它实际上并没有利用共享内存本身的使用优势。
* 然而，MatrixFree基础设施做到了。
* 
* - 一方面，在无矩阵循环[2.x.11][2.x.12]和[2.x.13]中，只有需要更新的幽灵值[2.x.14]被更新。来自共享内存邻居的幽灵值可以被直接访问，这使得缓冲，即把值复制到矢量的幽灵区域可能是多余的。 为了处理可能的竞赛条件，在MatrixFree中进行了必要的同步。在数值必须被缓冲的情况下，数值被直接从邻近的共享内存进程中复制，绕过了基于 [2.x.16] 和 [2.x.17] 的更昂贵的MPI操作。
* 
* - 另一方面，像FEEvaluation和FEFaceEvaluation这样的类可以直接从共享内存中读取，所以在某些情况下，缓冲值确实是没有必要。
* 为了能够使用MatrixFree的共享内存能力，MatrixFree必须通过提供用户创建的子通信器进行适当的配置。
* [1.x.40]
* 
* 

* [1.x.41][1.x.42] 。
* 

* [1.x.43][1.x.44]。
* 

* "以面为中心的循环"（简称FCL）访问单元和面（内部和边界的）的不分离的循环。因此，每个实体只被访问一次，单元之间的通量只被评估一次。如何在[2.x.18]的帮助下，通过提供三个函数（一个用于单元积分，一个用于内部，一个用于边界面）来执行以面为中心的循环，已经在[2.x.19]和[2.x.20]中提出。
* "以单元为中心的循环"（简称CCL或ECL（代表以元素为中心的循环），与此相反，处理一个单元并直接连续处理它的所有面（即访问所有面两次）。在文献[2.x.21]中，它们的好处已经很明显了，尽管这种循环意味着通量必须被计算两次（在一个内部面的每一侧）。CCL有两个主要优点。
* 
* 一方面，在CCL的情况下，解向量中的条目正好被写回主内存一次，而在FCL的情况下，尽管单元和面循环的缓存有效调度，但由于缓存容量的缺失，至少有一次。
* 
* 另一方面，由于解向量的每个条目被精确地访问一次，在CCL的情况下，访问解向量时不需要线程之间的同步。在写入目标向量的过程中不存在竞赛条件，这使得CCL特别适合于共享内存并行化。
* 人们还应该注意到，尽管在CCL的情况下通量被计算了两次，但这并不自动转化为计算的加倍，因为已经插值到单元正交点的数值可以通过简单的一维插值插值到一个面。
*[1.x.45][1.x.46]
* 

* 对于以单元为中心的循环实现，可以使用函数[2.x.22]，用户可以向其传递一个应该在每个单元上执行的函数。
* 为了得到一个适当的函数，可以在[2.x.23]中传递，原则上可以转换/合并以下三个函数，它们可以被传递给[2.x.24]。
* [1.x.47]
 
* 以下列方式。
* [1.x.48]
 
* 应该注意的是，FEFaceEvaluation现在是用两个数字初始化的，即单元格号和本地面孔号。给出的例子只是强调了如何将以面为中心的循环转化为以单元为中心的循环，而且绝非高效，因为数据要从全局向量中多次读写，而且计算也要频繁地进行。下面，我们将讨论针对这些问题的高级技术。
* 为了能够使用[2.x.25]，必须启用[2.x.26]的下列标志。
* [1.x.49]
* 
* 特别是，这些标志可以使内部数据结构为所有的单元面设置。
* 目前，deal.II中以单元为中心的循环只适用于均匀细化的网格，如果不应用约束条件（这是DG通常使用的标准情况）。
* 

* [1.x.50][1.x.51] 。
* 

* 上面的例子已经使用了lambdas，它已经提供了无矩阵循环。下面的简短例子介绍了如何在使用类和指向其方法之一的指针的版本和使用lambdas的变量之间转换函数。
* 在下面的代码中，一个类和一个指向其方法之一的指针，应该被解释为单元格积分，被传递给[2.x.27]。
* [1.x.52]
* 
* [1.x.53]
* 
* 然而，也可以通过lambda函数传递匿名函数，其结果是一样的。
* [1.x.54]
* 
* [1.x.55][1.x.56].
* 

* VectorizedArray<Number>类是实现deal.II中无矩阵算法的高节点性能的关键组件。它是一个围绕Number类型的[2.x.28]条目的短向量的封装类，通过内在函数将算术操作映射到适当的单指令/多数据（SIMD）概念。矢量的长度可以通过[2.x.29]查询，其基础数字类型可以通过[2.x.30]查询。
* 在默认情况下（[2.x.31]），向量长度是在库的编译时设置的，以匹配给定的处理器架构所支持的最高值。然而，也可以指定第二个可选的模板参数作为[2.x.32]，明确控制特定指令集能力内的向量长度。下表列出了支持的向量长度的完整列表。
* [2.x.33] 
* 这允许用户选择矢量长度/ISA，因此，在无矩阵运算器评估中一次处理的单元数，可能会减少对缓存的压力，这对于非常高的度数（和尺寸）来说是一个严重的问题。
* 一个可能的进一步原因是减少填充线的数量，以简化调试：而不是不得不看，例如8个单元，一个人可以专注于一个单元。
* VectorizedArray的接口也可以用任何有匹配接口的类型来代替。具体来说，这为deal.II准备了[2.x.34]类，它计划成为C++23标准的一部分。下表比较了deal.II特定的SIMD类和相应的C++23类。
* 

* [2.x.35] 
* 

* [1.x.57] [1.x.58]
* [1.x.59] [1.x.60].
 

* 
* 包括与[2.x.36]中相同的内容。
 

* 
* [1.x.61]
* 
* 一个新的包括，用于根据细胞的边界ID进行分类。
* 

* 
* [1.x.62]
* 
* 与 [2.x.37] 中的输入参数相同。
 

 
* [1.x.63]
* 
* 这个参数指定了共享内存组的大小。目前，只有值1和[2.x.38]是可能的，这导致了内存功能可以被关闭或所有访问同一共享内存域的进程被分组。
* 

* 
* [1.x.64]
* 
* 这里，数据结构的类型被选择为矢量化。在默认情况下，使用VectorizedArray<Number>，也就是说，在给定的硬件上使用最高的指令集架构扩展，有最大数量的向量通道。然而，人们可能会减少填充通道的数量，例如，通过编写[2.x.39]，只处理4个单元。
* 

* 
* [1.x.65]
* 
* 以下参数没有改变。
 

* 
* [1.x.66]
* 
* 指定对性能研究有用的最大时间步骤数。
* 

* 
* [1.x.67]
* 
* 从[2.x.40]复制的Runge-Kutta相关函数，并稍作修改，目的是尽量减少全局向量的访问。
 

* 
* [1.x.68]
 
* 来自[2.x.41]的欧拉特定实用函数。
* 

 
* [1.x.69]
* 
* 来自 [2.x.42] 的通用实用函数。
* 

* 
* [1.x.70]
 
* [1.x.71] [1.x.72]。
 

* 
* 来自[2.x.43]的欧拉算子，有一些变化，详见下文。
* 

* 
* [1.x.73]
* 
* 包含子通信器的SubCommunicatorWrapper实例，我们需要将其传递给[2.x.44]，以便能够利用MPI-3.0的共享内存功能。
* 

* 
* [1.x.74]
* 
* 新的构造函数，可以创建一个子通信器。用户可以通过全局参数group_size指定子通信器的大小。如果大小被设置为
* 
- ，一个共享内存域的所有MPI进程将被合并为一个组。指定的大小对于MatrixFree的共享内存能力的好处是决定性的，因此，设置为[2.x.45]是一个合理的选择。通过设置，大小为[2.x.46]，用户明确地禁用了MatrixFree的MPI-3.0共享内存功能，而完全依赖MPI-2.0功能，如[2.x.47]和[2.x.48] 。
* 

* 
* [1.x.75]
* 
* 新增负责释放子通信器的析构器。
* 

* 
* [1.x.76]
* 
* 修改了reinit()函数，以便在MatrixFree中设置内部数据结构，使其能被以单元为中心的循环使用，并使用MPI-3.0的共享内存功能。
* 

* 
* [1.x.77]
* 
* 对单元格进行分类，使所有通道的每个面都有相同的边界ID。这严格来说是没有必要的，然而，允许在[2.x.49]中写出更简单的代码，而不需要屏蔽，因为它保证所有分组的单元格（在一个VectorizedArray中）必须对面也执行完全相同的操作。
* 

* 
* [1.x.78]
* 
* 通过提供子通信器在MatrixFree中启用MPI-3.0共享内存功能。
* 

* 
* [1.x.79]
 
* 下面的函数做一个Runge--Kutta更新的整个阶段，并且是
* 

* 
* 
* - 旁边的设置稍作修改
* 
* - 与[2.x.50]相比，本教程的核心内容。  
* 与[2.x.51]相比，我们不是依次执行平流步骤（使用[2.x.52]和反质量矩阵步骤（使用[2.x.53]），而是在[2.x.54]中一次性评估所有内容。该函数期望在每个本地拥有的（宏）单元上执行一个函数作为参数，这样我们就需要在该单元的所有面上进行循环并自行执行需要的积分步骤。  
* 下面的函数在很大程度上包含了[2.x.55]中的下列函数的拷贝，所以这里跳过了与弱形式的评估有关的评论。
* 

* 
* 
* - [2.x.56] 
 

* 
 
* - [2.x.57] 
 

* 
* 
* - [2.x.58] 
 

* 
 
* - [2.x.59] 
 

 
* [1.x.80]
* 
* 通过调用[2.x.60]并提供一个包含单元、面和边界面积分效果的lambda，运行一个以单元为中心的循环。
* 

* 
* [1.x.81]
* 
* 循环所有的单元格批次。
* 

* 
* [1.x.82]
* 
*从全局向量中读取数值，并计算正交点的数值。
* 

* 
* [1.x.83]
* 
* 缓冲正交点的计算值，因为这些值在下一步被[2.x.61]所覆盖，但是，在后面的面积分中需要。
* 

* 
* [1.x.84]
* 
* 在单元格正交点应用单元格积分。也可参见来自 [2.x.63] 的函数 [2.x.62] 。
* 

* 
* [1.x.85]
* 
* 用正交点中的测试函数的梯度进行测试。我们跳过插值回到元素的支持点，因为我们首先收集单元正交点的所有贡献，只在最后一步进行插值。
* 

* 
* [1.x.86]
* 
* 循环处理当前单元的所有面。
* 

* 
* [1.x.87]
* 
* 确定当前面的边界ID。由于我们设置MatrixFree的方式是所有填充的车道都保证有相同的边界ID，我们可以选择第一个车道的边界ID。
* 

* 
* [1.x.88]
* 
* 通过简单的一维插值，将单元格正交点的值插到当前面的正交点上。
* 

* 
* [1.x.89]
* 
* 检查该面是内部面还是边界面，并根据这一信息选择不同的编码路径。
* 

* 
* [1.x.90]
* 
* 处理和内部面。以下几行代码是对 [2.x.65] 的函数 [2.x.64] 的复制。
* 

* 
* [1.x.91]
* 
* 处理一个边界面。下面这几行代码是对[2.x.67]中[2.x.66]函数的复制。
* 

* 
* [1.x.92]
* 
* 通过正交评估与单元有关的局部积分，并通过简单的一维插值加入到单元贡献中。
* 

* 
* [1.x.93]
 
* 在单元的正交点上应用反质量矩阵。也可参见来自 [2.x.69] 的函数 [2.x.68] 。
* 

* 
* [1.x.94]
* 
* 将数值从配位空间转换到原始的高斯-洛巴托空间。
* 

* 
* [1.x.95]
* 
* 进行Runge-Kutta更新并将结果写回全局向量。
* 

 
* [1.x.96]
* 
* 从这里开始，[2.x.70]的代码没有改变。
* 

* 
* [1.x.97]
* [1.x.98][1.x.99]。
* 

* 在有40个进程的机器上以默认设置运行该程序，产生以下输出。
* [1.x.100]
* 
* 以及以下视觉输出。
* [2.x.71] 
* 作为参考，使用FCL的[2.x.72]的结果是。
* [1.x.101]
* 
* 通过本教程中的修改，我们能够使Runge-Kutta阶段的速度提高27%。
* [1.x.102][1.x.103]。
* 

* 这些算法很容易扩展到更高的维度：一个高维的[1.x.104]是hyper.deal库的一部分。以单元为中心的循环扩展到局部细化的网格是比较复杂的。
*[1.x.105][1.x.106]。
* 

* 本教程中介绍的求解器也可以通过添加粘性项扩展到可压缩的Navier-Stokes方程，这也是在[2.x.73]中建议的。为了尽量保持这里获得的性能，尽管椭圆项的额外成本，例如通过内部惩罚方法，该教程建议将基础从FE_DGQ切换到FE_DGQHermite，就像在[2.x.74]教程程序中一样。这种转换的理由是，在FE_DGQ的情况下，需要相邻单元的所有数值（即[2.x.75]层），而在FE_DGQHermite的情况下，只需要2层，这使得后者明显更适合于更高的程度。额外的层一方面要在通量计算过程中从主内存加载，另一方面要进行通信。使用本教程中介绍的共享内存能力，第二点可以在单个计算节点上消除，或者在混合环境下减少其影响。
*[1.x.107][1.x.108]
* 

* 以单元为中心的循环可以用来创建块状的高斯-赛德尔预处理程序，该程序在一个过程中是乘法的，在多个过程中是加法的。在通量计算过程中，这种类型的预处理程序与雅可比类型的预处理程序相反，使用来自相邻单元的最新值。下面的伪代码直观地说明了这一目标的实现方式。
* [1.x.109]
* 
* 为此，我们可以利用MatrixFree的单元数据向量功能和VectorizedArray的基于范围的迭代功能。
* 请注意，在给定的例子中，我们处理了[2.x.76]个块，因为每个车道对应着一个块。如果一个矢量寄存器处理的所有块都被更新了，我们就认为块被更新了。在笛卡尔网格的情况下，这是一个合理的方法，然而，对于一般的非结构化网格，这种保守的方法可能会导致预处理程序的效率下降。通过明确减少[2.x.77]使用的通道数量来减少并行处理的单元可能会提高预处理器的质量，但代价是每次迭代可能会更昂贵。这种两难境地使我们看到了进一步的 "扩展可能性"：元素内的矢量化。
* 

* [1.x.110][1.x.111] [2.x.78] 。
* [0.x.1]

