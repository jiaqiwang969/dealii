[0.x.0]*
 [2.x.0] 
* This tutorial depends on  [2.x.1] .
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18][1.x.19][1.x.20]
* [1.x.21][1.x.22][1.x.23]
* 

* This program grew out of a student project by Xing Jin at Texas A&amp;MUniversity. Most of the work for this program is by her. Some of the work onthis tutorial program has been funded by NSF under grant DMS-0604778.
* The program is part of a project that aims to simulate thermoacoustictomography imaging. In thermoacoustic tomography, pulsed electromagneticenergy is delivered into biological issues. Tissues absorb some of this energyand those parts of the tissue that absorb the most energy generatethermoacoustic waves through thermoelastic expansion. For imaging, one usesthat different kinds of tissue, most importantly healthy and diseased tissue,absorb different amounts of energy and therefore expand at differentrates. The experimental setup is to measure the amplitude of the pressurewaves generated by these sources on the surface of the tissue and try toreconstruct the source distributions, which is indicative for the distributionof absorbers and therefore of different kinds of tissue. Part of this projectis to compare simulated data with actual measurements, so one has to solve the"forward problem", i.e. the wave equation that describes the propagation ofpressure waves in tissue. This program is therefore a continuation of  [2.x.2]  " [2.x.3] ", where the wave equation was first introduced.
* 

* [1.x.24][1.x.25]
* 

* The temperature at a given location, neglecting thermal diffusion, can bestated as
* [1.x.26]
* Here  [2.x.4]  is the density;  [2.x.5]  is the specificheat;  [2.x.6]  is the temperature rise dueto the delivered microwave energy; and  [2.x.7]  is the heatingfunction defined as the thermal energy per time and volume transformed fromdeposited microwave energy.
* Let us assume that tissues have heterogeneous dielectric properties buthomogeneous acoustic properties. The basic acoustic generation equation in anacoustically homogeneous medium can be described as follows: if  [2.x.8]  is thevector-valued displacement, then tissue certainly reacts to changes inpressure by acceleration:[1.x.27]Furthermore, it contracts due to excess pressure and expands based on changes in temperature:[1.x.28]Here,  [2.x.9]  is a thermoexpansion coefficient.
* Let us now make the assumption that heating only happens on a timescale much shorter than wave propagation through tissue (i.e. the temporallength of the microwave pulse that heats the tissue is much shorter than thetime it takes a wave to cross the domain). In that case, the heatingrate  [2.x.10]  can be written as  [2.x.11]  (where  [2.x.12]  is a map of absorption strengths formicrowave energy and  [2.x.13]  is the Dirac delta function), which togetherwith the first equation above will yieldan instantaneous jump in the temperature  [2.x.14]  at time  [2.x.15] .Using this assumption, and taking all equations together, we canrewrite and combine the above as follows:[1.x.29]where  [2.x.16] .
* This somewhat strange equation with the derivative of a Dirac delta functionon the right hand side can be rewritten as an initial value problem as follows:[1.x.30]
* (A derivation of this transformation into an initial value problem is given atthe end of this introduction as an appendix.)
* In the inverse problem, it is the initial condition  [2.x.17]  thatone would like to recover, since it is a map of absorption strengths formicrowave energy, and therefore presumably an indicator to discern healthyfrom diseased tissue.
* In real application, the thermoacoustic source is very small as compared tothe medium.  The propagation path of the thermoacoustic waves can then beapproximated as from the source to the infinity. Furthermore, detectors areonly a limited distance from the source. One only needs to evaluate the valueswhen the thermoacoustic waves pass through the detectors, although they docontinue beyond. This is therefore a problem where we are only interested in asmall part of an infinite medium, and we do not want waves generated somewhereto be reflected at the boundary of the domain which we considerinteresting. Rather, we would like to simulate only that part of the wavefield that is contained inside the domain of interest, and waves that hit theboundary of that domain to simply pass undisturbed through the boundary. Inother words, we would like the boundary to absorb any waves that hit it.
* In general, this is a hard problem: Good absorbing boundary conditions arenonlinear and/or numerically very expensive. We therefore opt for a simplefirst order approximation to absorbing boundary conditions that reads[1.x.31]Here,  [2.x.18]  is the normal derivative atthe boundary. It should be noted that this is not a particularly good boundarycondition, but it is one of the very few that are reasonably simple to implement.
* 

* [1.x.32][1.x.33]
* 

* As in  [2.x.19] , one first introduces a second variable, which isdefined as the derivative of the pressure potential:[1.x.34]
* With the second variable, one then transforms the forward problem intotwo separate equations:[1.x.35]
* with initial conditions:[1.x.36]
* Note that we have introduced a right hand side  [2.x.20]  here to showhow to derive these formulas in the general case, although in the applicationto the thermoacoustic problem  [2.x.21] .
* The semi-discretized, weak version of this model, using the general  [2.x.22]  schemeintroduced in  [2.x.23]  is then:[1.x.37]
* where  [2.x.24]  is an arbitrary test function, and where we have used theabsorbing boundary condition to integrate by parts:absorbing boundary conditions are incorporated into the weak form by using[1.x.38]
* From this we obtain the discrete model by introducing a finite number of shapefunctions, and get[1.x.39]
* The matrices  [2.x.25]  and  [2.x.26]  are here as in  [2.x.27] , and theboundary mass matrix[1.x.40]results from the use of absorbing boundary conditions.
* Above two equations can be rewritten in a matrix form with the pressure and its derivative asan unknown vector:[1.x.41]
* where[1.x.42]
* By simple transformations, one then obtains two equations forthe pressure potential and its derivative, just as in the previous tutorial program:[1.x.43]
* 
* 

* [1.x.44][1.x.45]
* 

* Compared to  [2.x.28] , this programs adds the treatment of asimple absorbing boundary conditions. In addition, it deals with data obtainedfrom actual experimental measurements. To this end, we need to evaluate thesolution at points at which the experiment also evaluates a real pressurefield. We will see how to do that using the  [2.x.29]  functionfurther down below.
* 

* 
* [1.x.46][1.x.47]
* 

* In the derivation of the initial value problem for the wave equation, weinitially found that the equation had the derivative of a Dirac delta functionas a right hand side:[1.x.48]In order to see how to transform this single equation into the usual statementof a PDE with initial conditions, let us make the assumption that thephysically quite reasonable medium is at rest initially, i.e.  [2.x.30]  for  [2.x.31] . Next, let us formthe indefinite integral with respect to time of both sides:[1.x.49]This immediately leads to the statement[1.x.50]where  [2.x.32]  is such that  [2.x.33] . Next, we form the (definite) integral over time from  [2.x.34]  to [2.x.35]  to find[1.x.51]If we use the property of the delta function that  [2.x.36] , and assume that  [2.x.37]  is a continuous function in time, we findas we let  [2.x.38]  go to zero that[1.x.52]In other words, using that  [2.x.39] , we retrieve the initialcondition[1.x.53]At the same time, we know that for every  [2.x.40]  the delta function is zero, sofor  [2.x.41]  we get the equation[1.x.54]Consequently, we have obtained a representation of the wave equation and oneinitial condition from the original somewhat strange equation.
* Finally, because we here have an equation with two time derivatives, we stillneed a second initial condition. To this end, let us go back to the equation[1.x.55]and integrate it in time from  [2.x.42]  to  [2.x.43] . This leads to[1.x.56]Using integration by parts of the form[1.x.57]where we use that  [2.x.44]  and inserting  [2.x.45] , wesee that in fact[1.x.58]
* Now, let  [2.x.46] . Assuming that  [2.x.47]  is a continuous function intime, we see that[1.x.59]and consequently[1.x.60]However, we have assumed that  [2.x.48] .Consequently, we obtain as the second initial condition that[1.x.61]completing the system of equations.
* 

*  [1.x.62] [1.x.63]
*   [1.x.64]  [1.x.65]
* 

* 
*  The following have all been covered previously:
* 

* 
* [1.x.66]
* 
*  This is the only new one: We will need a library function defined in the namespace GridTools that computes the minimal cell diameter.
* 

* 
* [1.x.67]
* 
*  The last step is as in all previous programs:
* 

* 
* [1.x.68]
* 
*   [1.x.69]  [1.x.70]
* 

* 
*  The first part of the main class is exactly as in  [2.x.49]  (except for the name):
* 

* 
* [1.x.71]
* 
*  Here's what's new: first, we need that boundary mass matrix  [2.x.50]  that came out of the absorbing boundary condition. Likewise, since this time we consider a realistic medium, we must have a measure of the wave speed  [2.x.51]  that will enter all the formulas with the Laplace matrix (which we still define as  [2.x.52] ):
* 

* 
* [1.x.72]
* 
*  The last thing we have to take care of is that we wanted to evaluate the solution at a certain number of detector locations. We need an array to hold these locations, declared here and filled in the constructor:
* 

* 
* [1.x.73]
* 
*   [1.x.74]  [1.x.75]
* 

* 
*  As usual, we have to define our initial values, boundary conditions, and right hand side functions. Things are a bit simpler this time: we consider a problem that is driven by initial conditions, so there is no right hand side function (though you could look up in  [2.x.53]  to see how this can be done). Secondly, there are no boundary conditions: the entire boundary of the domain consists of absorbing boundary conditions. That only leaves initial conditions, and there things are simple too since for this particular application only nonzero initial conditions for the pressure are prescribed, not for the velocity (which is zero at the initial time).   
*   So this is all we need: a class that specifies initial conditions for the pressure. In the physical setting considered in this program, these are small absorbers, which we model as a series of little circles where we assume that the pressure surplus is one, whereas no absorption and therefore no pressure surplus is everywhere else. This is how we do things (note that if we wanted to expand this program to not only compile but also to run, we would have to initialize the sources with three-dimensional source locations):
* 

* 
* [1.x.76]
* 
*   [1.x.77]  [1.x.78]
* 

* 
*  Let's start again with the constructor. Setting the member variables is straightforward. We use the acoustic wave speed of mineral oil (in millimeters per microsecond, a common unit in experimental biomedical imaging) since this is where many of the experiments we want to compare the output with are made in. The Crank-Nicolson scheme is used again, i.e. theta is set to 0.5. The time step is later selected to satisfy  [2.x.54] : here we initialize it to an invalid number.
* 

* 
* [1.x.79]
* 
*  The second task in the constructor is to initialize the array that holds the detector locations. The results of this program were compared with experiments in which the step size of the detector spacing is 2.25 degree, corresponding to 160 detector locations. The radius of the scanning circle is selected to be half way between the center and the boundary to avoid that the remaining reflections from the imperfect boundary condition spoils our numerical results.     
*   The locations of the detectors are then calculated in clockwise order. Note that the following of course only works if we are computing in 2d, a condition that we guard with an assertion. If we later wanted to run the same program in 3d, we would have to add code here for the initialization of detector locations in 3d. Due to the assertion, there is no way we can forget to do this.
* 

* 
* [1.x.80]
* 
*   [1.x.81]  [1.x.82]
* 

* 
*  The following system is pretty much what we've already done in  [2.x.55] , but with two important differences. First, we have to create a circular (or spherical) mesh around the origin, with a radius of 1. This nothing new: we've done so before in  [2.x.56]  and  [2.x.57] , where we also explain how the PolarManifold or SphericalManifold object places new points on concentric circles when a cell is refined, which we will use here as well.   
*   One thing we had to make sure is that the time step satisfies the CFL condition discussed in the introduction of  [2.x.58] . Back in that program, we ensured this by hand by setting a timestep that matches the mesh width, but that was error prone because if we refined the mesh once more we would also have to make sure the time step is changed. Here, we do that automatically: we ask a library function for the minimal diameter of any cell. Then we set  [2.x.59] . The only problem is: what exactly is  [2.x.60] ? The point is that there is really no good theory on this question for the wave equation. It is known that for uniformly refined meshes consisting of rectangles,  [2.x.61]  is the minimal edge length. But for meshes on general quadrilaterals, the exact relationship appears to be unknown, i.e. it is unknown what properties of cells are relevant for the CFL condition. The problem is that the CFL condition follows from knowledge of the smallest eigenvalue of the Laplace matrix, and that can only be computed analytically for simply structured meshes.   
*   The upshot of all this is that we're not quite sure what exactly we should take for  [2.x.62] . The function  [2.x.63]  computes the minimal diameter of all cells. If the cells were all squares or cubes, then the minimal edge length would be the minimal diameter divided by  [2.x.64] . We simply generalize this, without theoretical justification, to the case of non-uniform meshes.   
*   The only other significant change is that we need to build the boundary mass matrix. We will comment on this further down below.
* 

* 
* [1.x.83]
* 
*  The second difference, as mentioned, to  [2.x.65]  is that we need to build the boundary mass matrix that grew out of the absorbing boundary conditions.     
*   A first observation would be that this matrix is much sparser than the regular mass matrix, since none of the shape functions with purely interior support contribute to this matrix. We could therefore optimize the storage pattern to this situation and build up a second sparsity pattern that only contains the nonzero entries that we need. There is a trade-off to make here: first, we would have to have a second sparsity pattern object, so that costs memory. Secondly, the matrix attached to this sparsity pattern is going to be smaller and therefore requires less memory; it would also be faster to perform matrix-vector multiplications with it. The final argument, however, is the one that tips the scale: we are not primarily interested in performing matrix-vector with the boundary matrix alone (though we need to do that for the right hand side vector once per time step), but mostly wish to add it up to the other matrices used in the first of the two equations since this is the one that is going to be multiplied with once per iteration of the CG method, i.e. significantly more often. It is now the case that the  [2.x.66]  class allows to add one matrix to another, but only if they use the same sparsity pattern (the reason being that we can't add nonzero entries to a matrix after the sparsity pattern has been created, so we simply require that the two matrices have the same sparsity pattern).     
*   So let's go with that:
* 

* 
* [1.x.84]
* 
*  The second thing to do is to actually build the matrix. Here, we need to integrate over faces of cells, so first we need a quadrature object that works on  [2.x.67]  dimensional objects. Secondly, the FEFaceValues variant of FEValues that works on faces, as its name suggest. And finally, the other variables that are part of the assembly machinery. All of this we put between curly braces to limit the scope of these variables to where we actually need them.     
*   The actual act of assembling the matrix is then fairly straightforward: we loop over all cells, over all faces of each of these cells, and then do something only if that particular face is at the boundary of the domain. Like this:
* 

* 
* [1.x.85]
* 
*   [1.x.86]  [1.x.87]
* 

* 
*  The following two functions, solving the linear systems for the pressure and the velocity variable, are taken pretty much verbatim (with the exception of the change of name from  [2.x.68]  to  [2.x.69]  of the primary variable) from  [2.x.70] :
* 

* 
* [1.x.88]
* 
*   [1.x.89]  [1.x.90]
* 

* 
*  The same holds here: the function is from  [2.x.71] .
* 

* 
* [1.x.91]
* 
*   [1.x.92]  [1.x.93]
* 

* 
*  This function that does most of the work is pretty much again like in  [2.x.72] , though we make things a bit clearer by using the vectors G1 and G2 mentioned in the introduction. Compared to the overall memory consumption of the program, the introduction of a few temporary vectors isn't doing much harm.   
*   The only changes to this function are: first, that we do not have to project initial values for the velocity  [2.x.73] , since we know that it is zero. And second that we evaluate the solution at the detector locations computed in the constructor. This is done using the  [2.x.74]  function. These values are then written to a file that we open at the beginning of the function.
* 

* 
* [1.x.94]
* 
*   [1.x.95]  [1.x.96]
* 

* 
*  What remains is the main function of the program. There is nothing here that hasn't been shown in several of the previous programs:
* 

* 
* [1.x.97]
* [1.x.98][1.x.99]
* 

* The program writes both graphical data for each time step as well as thevalues evaluated at each detector location to disk. We thendraw them in plots. Experimental data were also collected for comparison.Currently our experiments have only been done in two dimensions bycircularly scanning a single detector. The tissue sample here is a thin slicein the  [2.x.75]  plane ( [2.x.76] ), and we assume that signals from other  [2.x.77] directions won't contribute to the data. Consequently, we only have to compareour experimental data with two dimensional simulated data.
* [1.x.100][1.x.101]
* 

* This movie shows the thermoacoustic waves generated by a single small absorberpropagating in the medium (in our simulation, we assume the medium is mineraloil, which has a acoustic speed of 1.437  [2.x.78] ):
*  [2.x.79] 
* For a single absorber, we of course have to change the [2.x.80]  class accordingly.
* Next, let us compare experimental and computational results. The visualizationuses a technique long used in seismology, where the data of each detector isplotted all in one graph. The way this is done is by offsetting eachdetector's signal a bit compared to the previous one. For example, here is aplot of the first four detectors (from bottom to top, with time inmicroseconds running from left to right) using the source setup used in theprogram, to make things a bit more interesting compared to the present case ofonly a single source:
*  [2.x.81] 
* One thing that can be seen, for example, is that the arrival of the second andfourth signals shifts to earlier times for greater detector numbers (i.e. thetopmost ones), but not the first and the third; this can be interpreted tomean that the origin of these signals must be closer to the latter detectorsthan to the former ones.
* If we stack not only 4, but all 160 detectors in one graph, the individuallines blur, but where they run together they create a pattern of darker orlighter grayscales.  The following two figures show the results obtained atthe detector locations stacked in that way. The left figure is obtained fromexperiments, and the right is the simulated data.In the experiment, a single small strong absorber was embedded inweaker absorbing tissue:
*  [2.x.82] 
* It is obvious that the source location is closer to the detectors at angle [2.x.83] . All the other signals that can be seen in the experimental dataresult from the fact that there are weak absorbers also in the rest of thetissue, which surrounds the signals generated by the small strong absorber inthe center. On the other hand, in the simulated data, we only simulate thesmall strong absorber.
* In reality, detectors have limited bandwidth. The thermoacoustic waves passingthrough the detector will therefore be filtered. By using a high-pass filter(implemented in MATLAB and run against the data file produced by this program),the simulated results can be made to look closer to the experimentaldata:
*  [2.x.84] 
* In our simulations, we see spurious signals behind the main wave thatresult from numerical artifacts. This problem can be alleviated by using finermesh, resulting in the following plot:
*  [2.x.85] 
* 

* 
* [1.x.102][1.x.103]
* 

* To further verify the program, we will also show simulation results formultiple absorbers. This corresponds to the case that is actually implementedin the program. The following movie shows the propagation of the generatedthermoacoustic waves in the medium by multiple absorbers:
*  [2.x.86] 
* Experimental data and our simulated data are compared in the following twofigures: [2.x.87] 
* Note that in the experimental data, the first signal (i.e. the left-most darkline) results from absorption at the tissue boundary, and therefore reachesthe detectors first and before any of the signals from the interior. Thissignal is also faintly visible at the end of the traces, around 30  [2.x.88] ,which indicates that the signal traveled through the entire tissue to reachdetectors at the other side, after all the signals originating from theinterior have reached them.
* As before, the numerical result better matches experimental ones by applying abandwidth filter that matches the actual behavior of detectors (left) and bychoosing a finer mesh (right):
*  [2.x.89] 
* One of the important differences between the left and the right figure is thatthe curves look much less "angular" at the right. The angularity comes fromthe fact that while waves in the continuous equation travel equally fast inall directions, this isn't the case after discretization: there, waves thattravel diagonal to cells move at slightly different speeds to those that moveparallel to mesh lines. This anisotropy leads to wave fronts that aren'tperfectly circular (and would produce sinusoidal signals in the stackedplots), but are bulged out in certain directions. To make things worse, thecircular mesh we use (see for example  [2.x.90]  for a view of thecoarse mesh) is not isotropic either. The net result is that the signal frontsare not sinusoidal unless the mesh is sufficiently fine. The right image is alot better in this respect, though artifacts in the form of trailing spuriouswaves can still be seen.
* 

* [1.x.104][1.x.105] [2.x.91] 
* [0.x.1]