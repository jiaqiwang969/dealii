[0.x.0]*
 [2.x.0] 
* This tutorial depends on  [2.x.1] .
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18][1.x.19][1.x.20][1.x.21][1.x.22][1.x.23][1.x.24][1.x.25][1.x.26][1.x.27][1.x.28][1.x.29][1.x.30][1.x.31][1.x.32][1.x.33][1.x.34][1.x.35][1.x.36][1.x.37]
* [1.x.38][1.x.39][1.x.40]
* 

* 
* This tutorial program is another one in the series on the elasticity problemthat we have already started with  [2.x.2]  and  [2.x.3] . It extends it into twodifferent directions: first, it solves the quasistatic but time dependentelasticity problem for large deformations with a Lagrangian mesh movementapproach. Secondly, it shows some more techniques for solving such problemsusing %parallel processing with PETSc's linear algebra. In addition to this,we show how to work around one of the two major bottlenecks of  [2.x.4] , namelythat we generated graphical output from only one process, and that this scaledvery badly with larger numbers of processes and on large problems. (The otherbottleneck, namely that every processor has to hold the entire mesh andDoFHandler, is addressed in  [2.x.5] .) Finally, agood number of assorted improvements and techniques are demonstrated that havenot been shown yet in previous programs.
* As before in  [2.x.6] , the program runs just as fine on a single sequentialmachine as long as you have PETSc installed. Information on how to telldeal.II about a PETSc installation on your system can be found in the deal.IIREADME file, which is linked to from the [1.x.41]in your installation of deal.II, or on [1.x.42].
* 

* [1.x.43][1.x.44]
* 

* [1.x.45][1.x.46]
* 

* In general, time-dependent small elastic deformations are described by theelastic wave equation[1.x.47]where  [2.x.7]  is the deformation of the body,  [2.x.8] and  [2.x.9]  the density and attenuation coefficient, and  [2.x.10]  external forces.In addition, initial conditions[1.x.48]and Dirichlet (displacement) or Neumann (traction) boundary conditions needto be specified for a unique solution:[1.x.49]
* In above formulation,  [2.x.11]  is the symmetric gradient of the displacement, also called the [2.x.12] strain [2.x.13] .  [2.x.14]  is a tensor of rank 4, called the  [2.x.15] stress-strain  tensor [2.x.16]  (the inverse of the [1.x.50])that contains knowledge of the elastic strength of the material; itssymmetry properties make sure that it maps symmetric tensors of rank 2(&ldquo;matrices&rdquo; of dimension  [2.x.17] , where  [2.x.18]  is the spatial dimensionality) ontosymmetric tensors of the same rank. We will comment on the roles of the strainand stress tensors more below. For the moment it suffices to say that weinterpret the term  [2.x.19]  as the vector withcomponents  [2.x.20] ,where summation over indices  [2.x.21]  is implied.
* The quasistatic limit of this equation is motivated as follows: each smallperturbation of the body, for example by changes in boundary condition or theforcing function, will result in a corresponding change in the configurationof the body. In general, this will be in the form of waves radiating away fromthe location of the disturbance. Due to the presence of the damping term,these waves will be attenuated on a time scale of, say,  [2.x.22] . Now, assumethat all changes in external forcing happen on times scales that aremuch larger than  [2.x.23] . In that case, the dynamic nature of the change isunimportant: we can consider the body to always be in static equilibrium,i.e. we can assume that at all times the body satisfies[1.x.51]
* Note that the differential equation does not contain any time derivatives anymore
* 
*  -  all time dependence is introduced through boundary conditions and apossibly time-varying force function  [2.x.24] . The changes inconfiguration can therefore be considered as being stationaryinstantaneously. An alternative view of this is that  [2.x.25]  is not really a timevariable, but only a time-like parameter that governs the evolution of theproblem.
* While these equations are sufficient to describe small deformations, computinglarge deformations is a little more complicated and, in general, leadsto nonlinear equations such as those treated in  [2.x.26] . In thefollowing, let us consider some of the tools one would employ whensimulating problems in which the deformation becomes [1.x.52].
*  [2.x.27]  The model we will consider below is not founded on anything thatwould be mathematically sound: we will consider a model in which weproduce a small deformation, deform the physical coordinates of thebody by this deformation, and then consider the next loading stepagain as a linear problem. This isn't consistent, since the assumptionof linearity implies that deformations are infinitesimal and so movingaround the vertices of our mesh by a finite amount before solving thenext linear problem is an inconsistent approach. We should thereforenote that it is not surprising that the equations discussed belowcan't be found in the literature: [1.x.53] On the other hand, the implementationtechniques we consider are very much what one would need to use whenimplementing a [1.x.54] model, as we will see in  [2.x.28] .
* 

* To come back to defining our "artificial" model, let us firstintroduce a tensorial stress variable  [2.x.29] , and write the differentialequations in terms of the stress:[1.x.55]
* Note that these equations are posed on a domain  [2.x.30]  thatchanges with time, with the boundary moving according to thedisplacements  [2.x.31]  of the points on the boundary. Tocomplete this system, we have to specify the incremental relationship betweenthe stress and the strain, as follows:[1.x.56][1.x.57]where a dot indicates a time derivative. Both the stress  [2.x.32]  and thestrain  [2.x.33]  are symmetric tensors of rank 2.
* 

* [1.x.58][1.x.59]
* 

* Numerically, this system is solved as follows: first, we discretizethe time component using a backward Euler scheme. This leads to adiscrete equilibrium of force at time step  [2.x.34] :[1.x.60]where[1.x.61]and  [2.x.35]  the incremental displacement for time step [2.x.36] . In addition, we have to specify initial data  [2.x.37] .This way, if we want to solve for the displacement increment, wehave to solve the following system:
* [1.x.62]
* The weak form of this set of equations, which as usual is the basis for thefinite element formulation, reads as follows: find  [2.x.38] such that[1.x.63]
* [1.x.64]
* Using that  [2.x.39] ,these equations can be simplified to
* [1.x.65]
* 
* We note that, for simplicity, in the program we will always assume that thereare no boundary forces, i.e.  [2.x.40] , and that the deformation of thebody is driven by body forces  [2.x.41]  and prescribed boundary displacements [2.x.42]  alone. It is also worth noting that when integrating by parts, wewould get terms of the form  [2.x.43] , but that we replace them with the term involving thesymmetric gradient  [2.x.44]  instead of  [2.x.45] . Due tothe symmetry of  [2.x.46] , the two terms are mathematically equivalent, butthe symmetric version avoids the potential for round-off errors makingthe resulting matrix slightly non-symmetric.
* The system at time step  [2.x.47] , to be solved on the old domain [2.x.48] , has exactly the form of a stationary elasticproblem, and is therefore similar to what we have already implementedin previous example programs. We will therefore not comment on thespace discretization beyond saying that we again use lowest ordercontinuous finite elements.
* There are differences, however: [2.x.49]    [2.x.50]  We have to move (update) the mesh after each time step, in order to be  able to solve the next time step on a new domain;
*    [2.x.51]  We need to know  [2.x.52]  to compute the next incremental  displacement, i.e. we need to compute it at the end of the time step  to make sure it is available for the next time step. Essentially,  the stress variable is our window to the history of deformation of  the body. [2.x.53] These two operations are done in the functions  [2.x.54]  and [2.x.55]  in the program. While movingthe mesh is only a technicality, updating the stress is a little morecomplicated and will be discussed in the next section.
* 

* [1.x.66][1.x.67]
* 

* As indicated above, we need to have the stress variable  [2.x.56]  availablewhen computing time step  [2.x.57] , and we can compute it using[1.x.68][1.x.69]There are, despite the apparent simplicity of this equation, two questionsthat we need to discuss. The first concerns the way we store  [2.x.58] : evenif we compute the incremental updates  [2.x.59]  using lowest-orderfinite elements, then its symmetric gradient  [2.x.60]  isin general still a function that is not easy to describe. In particular, it isnot a piecewise constant function, and on general meshes (with cells that arenot rectangles %parallel to the coordinate axes) or with non-constantstress-strain tensors  [2.x.61]  it is not even a bi- or trilinear function. Thus, itis a priori not clear how to store  [2.x.62]  in a computer program.
* To decide this, we have to see where it is used. The only place where werequire the stress is in the term [2.x.63] . In practice, we ofcourse replace this term by numerical quadrature:[1.x.70]where  [2.x.64]  are the quadrature weights and  [2.x.65]  the quadrature points oncell  [2.x.66] . This should make clear that what we really need is not the stress [2.x.67]  in itself, but only the values of the stress in the quadraturepoints on all cells. This, however, is a simpler task: we only have to providea data structure that is able to hold one symmetric tensor of rank 2 for eachquadrature point on all cells (or, since we compute in parallel, allquadrature points of all cells that the present MPI process &ldquo;owns&rdquo;). At theend of each time step we then only have to evaluate  [2.x.68] , multiply it by the stress-strain tensor  [2.x.69] , and use theresult to update the stress  [2.x.70]  at quadrature point  [2.x.71] .
* The second complication is not visible in our notation as chosen above. It isdue to the fact that we compute  [2.x.72]  on the domain  [2.x.73] ,and then use this displacement increment to both update the stress as well asmove the mesh nodes around to get to  [2.x.74]  on which the next incrementis computed. What we have to make sure, in this context, is that moving themesh does not only involve moving around the nodes, but also makingcorresponding changes to the stress variable: the updated stress is a variablethat is defined with respect to the coordinate system of the material in theold domain, and has to be transferred to the new domain. The reason for thiscan be understood as follows: locally, the incremental deformation  [2.x.75]  can be decomposed into three parts, a linear translation (the constant partof the displacement increment field in the neighborhood of a point), adilationalcomponent (that part of the gradient of the displacement field that has anonzero divergence), and a rotation. A linear translation of the material doesnot affect the stresses that are frozen into it
* 
*  -  the stress values aresimply translated along. The dilational or compressional change produces acorresponding stress update. However, the rotational component does notnecessarily induce a nonzero stress update (think, in 2d, for example of thesituation where  [2.x.76] , with which  [2.x.77] ). Nevertheless, if the material was prestressed in a certaindirection, then this direction will be rotated along with the material.  Tothis end, we have to define a rotation matrix  [2.x.78]  thatdescribes, in each point the rotation due to the displacement increments. Itis not hard to see that the actual dependence of  [2.x.79]  on  [2.x.80]  canonly be through the curl of the displacement, rather than the displacementitself or its full gradient (as mentioned above, the constant components ofthe increment describe translations, its divergence the dilational modes, andthe curl the rotational modes). Since the exact form of  [2.x.81]  is cumbersome, weonly state it in the program code, and note that the correct updating formulafor the stress variable is then[1.x.71][1.x.72]
* Both stress update and rotation are implemented in the function [2.x.82]  of the example program.
* 

* [1.x.73][1.x.74]
* 

* In  [2.x.83] , the main bottleneck for %parallel computations as far as run timeis concernedwas that only the first processor generated output for the entire domain.Since generating graphical output is expensive, this did not scale well whenlarger numbers of processors were involved. We will address this here. (For adefinition of what it means for a program to "scale", see [2.x.84]  "this glossary entry".)
* Basically, what we need to do is let every processgenerate graphical output for that subset of cells that it owns, write theminto separate files and have a way to display all files for a certain timestepat the same time. This way the code produces one  [2.x.85]  file per process pertime step. The two common VTK file viewers ParaView and VisIt both supportopening more than one  [2.x.86]  file at once. To simplify the process of pickingthe correct files and allow moving around in time, both support record filesthat reference all files for a given timestep. Sadly, the record files have adifferent format between VisIt and Paraview, so we write out both formats.
* The code will generate the files  [2.x.87] ,where  [2.x.88]  is the timestep number (starting from 1) and [2.x.89]  is the process rank (starting from0). These files contain the locally owned cells for the timestep andprocessor. The files  [2.x.90]  is the visit recordfor timestep  [2.x.91]  isthe same for ParaView. (More recent versions of VisIt can actually read [2.x.92]  files as well, but it doesn't hurt to output bothkinds of record files.) Finally, the file [2.x.93]  is a special record only supported by ParaView that referencesall time steps. So in ParaView, only solution.pvd needs to be opened, whileone needs to select the group of all .visit files in VisIt for the sameeffect.
* 

* [1.x.75][1.x.76]
* 

* In  [2.x.94] , we used a regular triangulation that was simply replicated onevery processor, and a corresponding DoFHandler. Both had no idea that theywere used in a %parallel context
* 
*  -  they just existed in their entiretyon every processor, and we argued that this was eventually going to be amajor memory bottleneck.
* We do not address this issue here (we will do so in  [2.x.95] ) but makethe situation slightly more automated. In  [2.x.96] , we created the triangulationand then manually "partitioned" it, i.e., we assigned [2.x.97]  "subdomain ids" to every cell that indicated which [2.x.98]  "MPI process" "owned" the cell. Here, we use a class [2.x.99]  that at least does this part automatically:whenever you create or refine such a triangulation, it automaticallypartitions itself among all involved processes (which it knows about becauseyou have to tell it about the  [2.x.100]  "MPI communicator"that connects these processes upon construction of the triangulation).Otherwise, the  [2.x.101]  looks, for all practicalpurposes, like a regular Triangulation object.
* The convenience of using this class does not only result from being ableto avoid the manual call to  [2.x.102]  Rather, the DoFHandlerclass now also knows that you want to use it in a parallel context, andby default automatically enumerates degrees of freedom in such a waythat all DoFs owned by process zero come before all DoFs owned by process 1,etc. In other words, you can also avoid the call to [2.x.103] 
* There are other benefits. For example, because the triangulation knows thatit lives in a %parallel universe, it also knows that it "owns" certaincells (namely, those whose subdomain id equals its MPI rank; previously,the triangulation only stored these subdomain ids, but had no way tomake sense of them). Consequently, in the assembly function, you cantest whether a cell is "locally owned" (i.e., owned by the currentprocess, see  [2.x.104] ) when you loop over all cellsusing the syntax
* [1.x.77]
* This knowledge extends to the DoFHandler object built on such triangulations,which can then identify which degrees of freedom are locally owned(see  [2.x.105] ) via calls such as [2.x.106]  and [2.x.107]  Finally, the DataOut classalso knows how to deal with such triangulations and will simply skipgenerating graphical output on cells not locally owned.
* Of course, as has been noted numerous times in the discussion in  [2.x.108] ,keeping the entire triangulation on every process will not scale: largeproblems may simply not fit into each process's memory any more, even ifwe have sufficiently many processes around to solve them in a reasonabletime. In such cases, the  [2.x.109]  is no longera reasonable basis for computations and we will show in  [2.x.110]  how the [2.x.111]  class can be used to work aroundthis, namely by letting each process store only a [1.x.78] of thetriangulation.
* 

* [1.x.79][1.x.80]
* 

* The overall structure of the program can be inferred from the  [2.x.112] function that first calls  [2.x.113]  for the first timestep, and then  [2.x.114]  on all subsequent time steps. Thedifference between these functions is only that in the first time step westart on a coarse mesh, solve on it, refine the mesh adaptively, and thenstart again with a clean state on that new mesh. This procedure gives us abetter starting mesh, although we should of course keep adapting the mesh asiterations proceed
* 
*  -  this isn't done in this program, but commented on below.
* The common part of the two functions treating time steps is the followingsequence of operations on the present mesh: [2.x.115]  [2.x.116]   [2.x.117] ]:  This first function is also the most interesting one. It assembles the  linear system corresponding to the discretized version of equation  [1.x.81]. This leads to a system matrix  [2.x.118]  built up of local contributions on each cell  [2.x.119]  with entries  [1.x.82]  In practice,  [2.x.120]  is computed using numerical quadrature according to the  formula  [1.x.83]  with quadrature points  [2.x.121]  and weights  [2.x.122] . We have built these  contributions before, in  [2.x.123]  and  [2.x.124] , but in both of these cases we  have done so rather clumsily by using knowledge of how the rank-4 tensor  [2.x.125]   is composed, and considering individual elements of the strain tensors   [2.x.126] . This is not really  convenient, in particular if we want to consider more complicated elasticity  models than the isotropic case for which  [2.x.127]  had the convenient form   [2.x.128] . While we in fact do not use a more complicated  form than this in the present program, we nevertheless want to write it in a  way that would easily allow for this. It is then natural to introduce  classes that represent symmetric tensors of rank 2 (for the strains and  stresses) and 4 (for the stress-strain tensor  [2.x.129] ). Fortunately, deal.II  provides these: the  [2.x.130]  class template  provides a full-fledged implementation of such tensors of rank  [2.x.131]   (which needs to be an even number) and dimension  [2.x.132] .
*   What we then need is two things: a way to create the stress-strain rank-4  tensor  [2.x.133]  as well as to create a symmetric tensor of rank 2 (the strain  tensor) from the gradients of a shape function  [2.x.134]  at a quadrature  point  [2.x.135]  on a given cell. At the top of the implementation of this  example program, you will find such functions. The first one,   [2.x.136] , takes two arguments corresponding to  the Lam&eacute; constants  [2.x.137]  and  [2.x.138]  and returns the stress-strain tensor  for the isotropic case corresponding to these constants (in the program, we  will choose constants corresponding to steel); it would be simple to replace  this function by one that computes this tensor for the anisotropic case, or  taking into account crystal symmetries, for example. The second one,   [2.x.139]  and indices   [2.x.140]  and  [2.x.141]  and returns the symmetric gradient, i.e. the strain,  corresponding to shape function  [2.x.142] , evaluated on the cell  on which the  [2.x.143]  object was last reinitialized.
*   Given this, the innermost loop of  [2.x.144]  computes the  local contributions to the matrix in the following elegant way (the variable   [2.x.145] , corresponding to the tensor  [2.x.146] , has  previously been initialized with the result of the first function above): 
* [1.x.84]
*   It is worth noting the expressive power of this piece of code, and to  compare it with the complications we had to go through in previous examples  for the elasticity problem. (To be fair, the SymmetricTensor class  template did not exist when these previous examples were written.) For  simplicity,  [2.x.147]  provides for the (double summation) product  between symmetric tensors of even rank here.
*   Assembling the local contributions  [1.x.85]
*   to the right hand side of [1.x.86] is equally  straightforward (note that we do not consider any boundary tractions  [2.x.148]  here). Remember that we only had to store the old stress in the  quadrature points of cells. In the program, we will provide a variable   [2.x.149]  that allows to access the stress   [2.x.150]  in each quadrature point. With this the code for the right  hand side looks as this, again rather elegant: 
* [1.x.87]
*   Note that in the multiplication  [2.x.151] , we have made use of the fact that for the chosen finite element, only  one vector component (namely  [2.x.152] ) of  [2.x.153]  is  nonzero, and that we therefore also have to consider only one component of   [2.x.154] .
*   This essentially concludes the new material we present in this function. It  later has to deal with boundary conditions as well as hanging node  constraints, but this parallels what we had to do previously in other  programs already.
*  [2.x.155]   [2.x.156] ]:  Unlike the previous one, this function is not really interesting, since it  does what similar functions have done in all previous tutorial programs
* 
*  -   solving the linear system using the CG method, using an incomplete LU  decomposition as a preconditioner (in the %parallel case, it uses an ILU of  each processor's block separately). It is virtually unchanged  from  [2.x.157] .
*  [2.x.158]   [2.x.159]  [via   [2.x.160] ]: Based on the displacement field  [2.x.161]  computed before, we update the stress values in all quadrature points  according to [1.x.88] and [1.x.89],  including the rotation of the coordinate system.
*  [2.x.162]   [2.x.163] : Given the solution computed before, in this  function we deform the mesh by moving each vertex by the displacement vector  field evaluated at this particular vertex.
*  [2.x.164]   [2.x.165] : This function simply outputs the solution  based on what we have said above, i.e. every processor computes output only  for its own portion of the domain. In addition to the solution, we also compute the norm of  the stress averaged over all the quadrature points on each cell. [2.x.166] 
* With this general structure of the code, we only have to define what case wewant to solve. For the present program, we have chosen to simulate thequasistatic deformation of a vertical cylinder for which the bottom boundaryis fixed and the top boundary is pushed down at a prescribed verticalvelocity. However, the horizontal velocity of the top boundary is leftunspecified
* 
*  -  one can imagine this situation as a well-greased plate pushingfrom the top onto the cylinder, the points on the top boundary of the cylinderbeing allowed to slide horizontally along the surface of the plate, but forcedto move downward by the plate. The inner and outer boundaries of the cylinderare free and not subject to any prescribed deflection or traction. Inaddition, gravity acts on the body.
* The program text will reveal more about how to implement this situation, andthe results section will show what displacement pattern comes out of thissimulation.
* 

*  [1.x.90] [1.x.91]
*  First the usual list of header files that have already been used in previous example programs:
* 

* 
* [1.x.92]
* 
*  And here the only three new things among the header files: an include file in which symmetric tensors of rank 2 and 4 are implemented, as introduced in the introduction:
* 

* 
* [1.x.93]
* 
*  And lastly a header that contains some functions that will help us compute rotaton matrices of the local coordinate systems at specific points in the domain.
* 

* 
* [1.x.94]
* 
*  This is then simply C++ again:
* 

* 
* [1.x.95]
* 
*  The last step is as in all previous programs:
* 

* 
* [1.x.96]
* 
*   [1.x.97]  [1.x.98]
* 

* 
*  As was mentioned in the introduction, we have to store the old stress in quadrature point so that we can compute the residual forces at this point during the next time step. This alone would not warrant a structure with only one member, but in more complicated applications, we would have to store more information in quadrature points as well, such as the history variables of plasticity, etc. In essence, we have to store everything that affects the present state of the material here, which in plasticity is determined by the deformation history variables.   
*   We will not give this class any meaningful functionality beyond being able to store data, i.e. there are no constructors, destructors, or other member functions. In such cases of `dumb' classes, we usually opt to declare them as  [2.x.167] , to indicate that they are closer to C-style structures than C++-style classes.
* 

* 
* [1.x.99]
* 
*   [1.x.100]  [1.x.101]
* 

* 
*  Next, we define the linear relationship between the stress and the strain in elasticity. It is given by a tensor of rank 4 that is usually written in the form  [2.x.168] . This tensor maps symmetric tensor of rank 2 to symmetric tensors of rank 2. A function implementing its creation for given values of the Lam&eacute; constants  [2.x.169]  and  [2.x.170]  is straightforward:
* 

* 
* [1.x.102]
* 
*  With this function, we will define a static member variable of the main class below that will be used throughout the program as the stress-strain tensor. Note that in more elaborate programs, this will probably be a member variable of some class instead, or a function that returns the stress-strain relationship depending on other input. For example in damage theory models, the Lam&eacute; constants are considered a function of the prior stress/strain history of a point. Conversely, in plasticity the form of the stress-strain tensor is modified if the material has reached the yield stress in a certain point, and possibly also depending on its prior history.   
*   In the present program, however, we assume that the material is completely elastic and linear, and a constant stress-strain tensor is sufficient for our present purposes.
* 

* 
*  
*  
* 

* 
*   [1.x.103]  [1.x.104]
* 

* 
*  Before the rest of the program, here are a few functions that we need as tools. These are small functions that are called in inner loops, so we mark them as  [2.x.171] .   
*   The first one computes the symmetric strain tensor for shape function  [2.x.172]  by forming the symmetric gradient of this shape function. We need that when we want to form the matrix, for example.   
*   We should note that in previous examples where we have treated vector-valued problems, we have always asked the finite element object in which of the vector component the shape function is actually non-zero, and thereby avoided to compute any terms that we could prove were zero anyway. For this, we used the  [2.x.173]  function that returns in which component a shape function was zero, and also that the  [2.x.174]  and  [2.x.175]  functions only returned the value and gradient of the single non-zero component of a shape function if this is a vector-valued element.   
*   This was an optimization, and if it isn't terribly time critical, we can get away with a simpler technique: just ask the  [2.x.176]  for the value or gradient of a given component of a given shape function at a given quadrature point. This is what the  [2.x.177]  call does: return the full gradient of the  [2.x.178] th component of shape function  [2.x.179]  at quadrature point  [2.x.180] . If a certain component of a certain shape function is always zero, then this will simply always return zero.   
*   As mentioned, using  [2.x.181]  instead of the combination of  [2.x.182]  and  [2.x.183]  may be less efficient, but its implementation is optimized for such cases and shouldn't be a big slowdown. We demonstrate the technique here since it is so much simpler and straightforward.
* 

* 
* [1.x.105]
* 
*  Declare a temporary that will hold the return value:
* 

* 
* [1.x.106]
* 
*  First, fill diagonal terms which are simply the derivatives in direction  [2.x.184]  component of the vector-valued shape function:
* 

* 
* [1.x.107]
* 
*  Then fill the rest of the strain tensor. Note that since the tensor is symmetric, we only have to compute one half (here: the upper right corner) of the off-diagonal elements, and the implementation of the  [2.x.185]  class makes sure that at least to the outside the symmetric entries are also filled (in practice, the class of course stores only one copy). Here, we have picked the upper right half of the tensor, but the lower left one would have been just as good:
* 

* 
* [1.x.108]
* 
*  The second function does something very similar (and therefore is given the same name): compute the symmetric strain tensor from the gradient of a vector-valued field. If you already have a solution field, the  [2.x.186]  function allows you to extract the gradients of each component of your solution field at a quadrature point. It returns this as a vector of rank-1 tensors: one rank-1 tensor (gradient) per vector component of the solution. From this we have to reconstruct the (symmetric) strain tensor by transforming the data storage format and symmetrization. We do this in the same way as above, i.e. we avoid a few computations by filling first the diagonal and then only one half of the symmetric tensor (the  [2.x.187]  class makes sure that it is sufficient to write only one of the two symmetric components).   
*   Before we do this, though, we make sure that the input has the kind of structure we expect: that is that there are  [2.x.188]  vector components, i.e. one displacement component for each coordinate direction. We test this with the  [2.x.189]  macro that will simply abort our program if the condition is not met.
* 

* 
* [1.x.109]
* 
*  Finally, below we will need a function that computes the rotation matrix induced by a displacement at a given point. In fact, of course, the displacement at a single point only has a direction and a magnitude, it is the change in direction and magnitude that induces rotations. In effect, the rotation matrix can be computed from the gradients of a displacement, or, more specifically, from the curl.   
*   The formulas by which the rotation matrices are determined are a little awkward, especially in 3d. For 2d, there is a simpler way, so we implement this function twice, once for 2d and once for 3d, so that we can compile and use the program in both space dimensions if so desired
* 
*  -  after all, deal.II is all about dimension independent programming and reuse of algorithm thoroughly tested with cheap computations in 2d, for the more expensive computations in 3d. Here is one case, where we have to implement different algorithms for 2d and 3d, but then can write the rest of the program in a way that is independent of the space dimension.   
*   So, without further ado to the 2d implementation:
* 

* 
* [1.x.110]
* 
*  First, compute the curl of the velocity field from the gradients. Note that we are in 2d, so the rotation is a scalar:
* 

* 
* [1.x.111]
* 
*  From this, compute the angle of rotation:
* 

* 
* [1.x.112]
* 
*  And from this, build the antisymmetric rotation matrix. We want this rotation matrix to represent the rotation of the local coordinate system with respect to the global Cartesian basis, to we construct it with a negative angle. The rotation matrix therefore represents the rotation required to move from the local to the global coordinate system.
* 

* 
* [1.x.113]
* 
*  The 3d case is a little more contrived:
* 

* 
* [1.x.114]
* 
*  Again first compute the curl of the velocity field. This time, it is a real vector:
* 

* 
* [1.x.115]
* 
*  From this vector, using its magnitude, compute the tangent of the angle of rotation, and from it the actual angle of rotation with respect to the Cartesian basis:
* 

* 
* [1.x.116]
* 
*  Now, here's one problem: if the angle of rotation is too small, that means that there is no rotation going on (for example a translational motion). In that case, the rotation matrix is the identity matrix.     
*   The reason why we stress that is that in this case we have that  [2.x.190] . Further down, we need to divide by that number in the computation of the axis of rotation, and we would get into trouble when dividing doing so. Therefore, let's shortcut this and simply return the identity matrix if the angle of rotation is really small:
* 

* 
* [1.x.117]
* 
*  Otherwise compute the real rotation matrix. For this, again we rely on a predefined function to compute the rotation matrix of the local coordinate system.
* 

* 
* [1.x.118]
* 
*   [1.x.119]  [1.x.120]
* 

* 
*  This is the main class of the program. Since the namespace already indicates what problem we are solving, let's call it by what it does: it directs the flow of the program, i.e. it is the toplevel driver.   
*   The member variables of this class are essentially as before, i.e. it has to have a triangulation, a DoF handler and associated objects such as constraints, variables that describe the linear system, etc. There are a good number of more member functions now, which we will explain below.   
*   The external interface of the class, however, is unchanged: it has a public constructor and destructor, and it has a  [2.x.191]  function that initiated all the work.
* 

* 
* [1.x.121]
* 
*  The private interface is more extensive than in  [2.x.192] . First, we obviously need functions that create the initial mesh, set up the variables that describe the linear system on the present mesh (i.e. matrices and vectors), and then functions that actually assemble the system, direct what has to be solved in each time step, a function that solves the linear system that arises in each timestep (and returns the number of iterations it took), and finally output the solution vector on the correct mesh:
* 

* 
* [1.x.122]
* 
*  All, except for the first two, of these functions are called in each timestep. Since the first time step is a little special, we have separate functions that describe what has to happen in a timestep: one for the first, and one for all following timesteps:
* 

* 
* [1.x.123]
* 
*  Then we need a whole bunch of functions that do various things. The first one refines the initial grid: we start on the coarse grid with a pristine state, solve the problem, then look at it and refine the mesh accordingly, and start the same process over again, again with a pristine state. Thus, refining the initial mesh is somewhat simpler than refining a grid between two successive time steps, since it does not involve transferring data from the old to the new triangulation, in particular the history data that is stored in each quadrature point.
* 

* 
* [1.x.124]
* 
*  At the end of each time step, we want to move the mesh vertices around according to the incremental displacement computed in this time step. This is the function in which this is done:
* 

* 
* [1.x.125]
* 
*  Next are two functions that handle the history variables stored in each quadrature point. The first one is called before the first timestep to set up a pristine state for the history variables. It only works on those quadrature points on cells that belong to the present processor:
* 

* 
* [1.x.126]
* 
*  The second one updates the history variables at the end of each timestep:
* 

* 
* [1.x.127]
* 
*  This is the new shared Triangulation:
* 

* 
* [1.x.128]
* 
*  One difference of this program is that we declare the quadrature formula in the class declaration. The reason is that in all the other programs, it didn't do much harm if we had used different quadrature formulas when computing the matrix and the right hand side, for example. However, in the present case it does: we store information in the quadrature points, so we have to make sure all parts of the program agree on where they are and how many there are on each cell. Thus, let us first declare the quadrature formula that will be used throughout...
* 

* 
* [1.x.129]
* 
*  ... and then also have a vector of history objects, one per quadrature point on those cells for which we are responsible (i.e. we don't store history data for quadrature points on cells that are owned by other processors). Note that, instead of storing and managing this data ourself, we could use the CellDataStorage class like is done in  [2.x.193] . However, for the purpose of demonstration, in this case we manage the storage manually.
* 

* 
* [1.x.130]
* 
*  The way this object is accessed is through a  [2.x.194]  that each cell, face, or edge holds: it is a  [2.x.195]  pointer that can be used by application programs to associate arbitrary data to cells, faces, or edges. What the program actually does with this data is within its own responsibility, the library just allocates some space for these pointers, and application programs can set and read the pointers for each of these objects.
* 

* 
*  
*   Further: we need the objects of linear systems to be solved, i.e. matrix, right hand side vector, and the solution vector. Since we anticipate solving big problems, we use the same types as in  [2.x.196] , i.e. distributed %parallel matrices and vectors built on top of the PETSc library. Conveniently, they can also be used when running on only a single machine, in which case this machine happens to be the only one in our %parallel universe.     
*   However, as a difference to  [2.x.197] , we do not store the solution vector
* 
*  -  which here is the incremental displacements computed in each time step
* 
*  -  in a distributed fashion. I.e., of course it must be a distributed vector when computing it, but immediately after that we make sure each processor has a complete copy. The reason is that we had already seen in  [2.x.198]  that many functions needed a complete copy. While it is not hard to get it, this requires communication on the network, and is thus slow. In addition, these were repeatedly the same operations, which is certainly undesirable unless the gains of not always having to store the entire vector outweighs it. When writing this program, it turned out that we need a complete copy of the solution in so many places that it did not seem worthwhile to only get it when necessary. Instead, we opted to obtain the complete copy once and for all, and instead get rid of the distributed copy immediately. Thus, note that the declaration of  [2.x.199]  does not denote a distribute vector as would be indicated by the middle namespace  [2.x.200] :
* 

* 
* [1.x.131]
* 
*  The next block of variables is then related to the time dependent nature of the problem: they denote the length of the time interval which we want to simulate, the present time and number of time step, and length of present timestep:
* 

* 
* [1.x.132]
* 
*  Then a few variables that have to do with %parallel processing: first, a variable denoting the MPI communicator we use, and then two numbers telling us how many participating processors there are, and where in this world we are. Finally, a stream object that makes sure only one processor is actually generating output to the console. This is all the same as in  [2.x.201] :
* 

* 
* [1.x.133]
* 
*  We are storing the locally owned and the locally relevant indices:
* 

* 
* [1.x.134]
* 
*  Finally, we have a static variable that denotes the linear relationship between the stress and strain. Since it is a constant object that does not depend on any input (at least not in this program), we make it a static variable and will initialize it in the same place where we define the constructor of this class:
* 

* 
* [1.x.135]
* 
*   [1.x.136]  [1.x.137]
* 

* 
*  Before we go on to the main functionality of this program, we have to define what forces will act on the body whose deformation we want to study. These may either be body forces or boundary forces. Body forces are generally mediated by one of the four basic physical types of forces: gravity, strong and weak interaction, and electromagnetism. Unless one wants to consider subatomic objects (for which quasistatic deformation is irrelevant and an inappropriate description anyway), only gravity and electromagnetic forces need to be considered. Let us, for simplicity assume that our body has a certain mass density, but is either non-magnetic and not electrically conducting or that there are no significant electromagnetic fields around. In that case, the body forces are simply  [2.x.202]  is the material density and  [2.x.203]  is a vector in negative z-direction with magnitude 9.81 m/s^2.  Both the density and  [2.x.204]  are defined in the function, and we take as the density 7700 kg/m^3, a value commonly assumed for steel.   
*   To be a little more general and to be able to do computations in 2d as well, we realize that the body force is always a function returning a  [2.x.205]  dimensional vector. We assume that gravity acts along the negative direction of the last, i.e.  [2.x.206] th coordinate. The rest of the implementation of this function should be mostly self-explanatory given similar definitions in previous example programs. Note that the body force is independent of the location; to avoid compiler warnings about unused function arguments, we therefore comment out the name of the first argument of the  [2.x.207]  function:
* 

* 
* [1.x.138]
* 
*   [1.x.139]  [1.x.140]
* 

* 
*  In addition to body forces, movement can be induced by boundary forces and forced boundary displacement. The latter case is equivalent to forces being chosen in such a way that they induce certain displacement.   
*   For quasistatic displacement, typical boundary forces would be pressure on a body, or tangential friction against another body. We chose a somewhat simpler case here: we prescribe a certain movement of (parts of) the boundary, or at least of certain components of the displacement vector. We describe this by another vector-valued function that, for a given point on the boundary, returns the prescribed displacement.   
*   Since we have a time-dependent problem, the displacement increment of the boundary equals the displacement accumulated during the length of the timestep. The class therefore has to know both the present time and the length of the present time step, and can then approximate the incremental displacement as the present velocity times the present timestep.   
*   For the purposes of this program, we choose a simple form of boundary displacement: we displace the top boundary with constant velocity downwards. The rest of the boundary is either going to be fixed (and is then described using an object of type  [2.x.208] ) or free (Neumann-type, in which case nothing special has to be done).  The implementation of the class describing the constant downward motion should then be obvious using the knowledge we gained through all the previous example programs:
* 

* 
* [1.x.141]
* 
*   [1.x.142]  [1.x.143]
* 

* 
*  Now for the implementation of the main class. First, we initialize the stress-strain tensor, which we have declared as a static const variable. We chose Lam&eacute; constants that are appropriate for steel:
* 

* 
* [1.x.144]
* 
*   [1.x.145]  [1.x.146]
* 

* 
*  The next step is the definition of constructors and destructors. There are no surprises here: we choose linear and continuous finite elements for each of the  [2.x.209]  vector components of the solution, and a Gaussian quadrature formula with 2 points in each coordinate direction. The destructor should be obvious:
* 

* 
* [1.x.147]
* 
*  The last of the public functions is the one that directs all the work,  [2.x.210] . It initializes the variables that describe where in time we presently are, then runs the first time step, then loops over all the other time steps. Note that for simplicity we use a fixed time step, whereas a more sophisticated program would of course have to choose it in some more reasonable way adaptively:
* 

* 
* [1.x.148]
* 
*   [1.x.149]  [1.x.150]
* 

* 
*  The next function in the order in which they were declared above is the one that creates the coarse grid from which we start. For this example program, we want to compute the deformation of a cylinder under axial compression. The first step therefore is to generate a mesh for a cylinder of length 3 and with inner and outer radii of 0.8 and 1, respectively. Fortunately, there is a library function for such a mesh.   
*   In a second step, we have to associated boundary conditions with the upper and lower faces of the cylinder. We choose a boundary indicator of 0 for the boundary faces that are characterized by their midpoints having z-coordinates of either 0 (bottom face), an indicator of 1 for z=3 (top face); finally, we use boundary indicator 2 for all faces on the inside of the cylinder shell, and 3 for the outside.
* 

* 
* [1.x.151]
* 
*  Once all this is done, we can refine the mesh once globally:
* 

* 
* [1.x.152]
* 
*  As the final step, we need to set up a clean state of the data that we store in the quadrature points on all cells that are treated on the present processor.
* 

* 
* [1.x.153]
* 
*   [1.x.154]  [1.x.155]
* 

* 
*  The next function is the one that sets up the data structures for a given mesh. This is done in most the same way as in  [2.x.211] : distribute the degrees of freedom, then sort these degrees of freedom in such a way that each processor gets a contiguous chunk of them. Note that subdivisions into chunks for each processor is handled in the functions that create or refine grids, unlike in the previous example program (the point where this happens is mostly a matter of taste; here, we chose to do it when grids are created since in the  [2.x.212]  and  [2.x.213]  functions we want to output the number of cells on each processor at a point where we haven't called the present function yet).
* 

* 
* [1.x.156]
* 
*  The next step is to set up constraints due to hanging nodes. This has been handled many times before:
* 

* 
* [1.x.157]
* 
*  And then we have to set up the matrix. Here we deviate from  [2.x.214] , in which we simply used PETSc's ability to just know about the size of the matrix and later allocate those nonzero elements that are being written to. While this works just fine from a correctness viewpoint, it is not at all efficient: if we don't give PETSc a clue as to which elements are written to, it is (at least at the time of this writing) unbearably slow when we set the elements in the matrix for the first time (i.e. in the first timestep). Later on, when the elements have been allocated, everything is much faster. In experiments we made, the first timestep can be accelerated by almost two orders of magnitude if we instruct PETSc which elements will be used and which are not.     
*   To do so, we first generate the sparsity pattern of the matrix we are going to work with, and make sure that the condensation of hanging node constraints add the necessary additional entries in the sparsity pattern:
* 

* 
* [1.x.158]
* 
*  Note that we have used the  [2.x.215]  class here that was already introduced in  [2.x.216] , rather than the  [2.x.217]  class that we have used in all other cases. The reason for this is that for the latter class to work we have to give an initial upper bound for the number of entries in each row, a task that is traditionally done by  [2.x.218] . However, this function suffers from a serious problem: it has to compute an upper bound to the number of nonzero entries in each row, and this is a rather complicated task, in particular in 3d. In effect, while it is quite accurate in 2d, it often comes up with much too large a number in 3d, and in that case the  [2.x.219]  allocates much too much memory at first, often several 100 MBs. This is later corrected when  [2.x.220]  is called and we realize that we don't need all that much memory, but at time it is already too late: for large problems, the temporary allocation of too much memory can lead to out-of-memory situations.     
*   In order to avoid this, we resort to the  [2.x.221]  class that is slower but does not require any up-front estimate on the number of nonzero entries per row. It therefore only ever allocates as much memory as it needs at any given time, and we can build it even for large 3d problems.     
*   It is also worth noting that due to the specifics of  [2.x.222]  the sparsity pattern we construct is global, i.e. comprises all degrees of freedom whether they will be owned by the processor we are on or another one (in case this program is run in %parallel via MPI). This of course is not optimal
* 
*  -  it limits the size of the problems we can solve, since storing the entire sparsity pattern (even if only for a short time) on each processor does not scale well. However, there are several more places in the program in which we do this, for example we always keep the global triangulation and DoF handler objects around, even if we only work on part of them. At present, deal.II does not have the necessary facilities to completely distribute these objects (a task that, indeed, is very hard to achieve with adaptive meshes, since well-balanced subdivisions of a domain tend to become unbalanced as the mesh is adaptively refined).     
*   With this data structure, we can then go to the PETSc sparse matrix and tell it to preallocate all the entries we will later want to write to:
* 

* 
* [1.x.159]
* 
*  After this point, no further explicit knowledge of the sparsity pattern is required any more and we can let the  [2.x.223]  variable go out of scope without any problem.
* 

* 
*  The last task in this function is then only to reset the right hand side vector as well as the solution vector to its correct size; remember that the solution vector is a local one, unlike the right hand side that is a distributed %parallel one and therefore needs to know the MPI communicator over which it is supposed to transmit messages:
* 

* 
* [1.x.160]
* 
*   [1.x.161]  [1.x.162]
* 

* 
*  Again, assembling the system matrix and right hand side follows the same structure as in many example programs before. In particular, it is mostly equivalent to  [2.x.224] , except for the different right hand side that now only has to take into account internal stresses. In addition, assembling the matrix is made significantly more transparent by using the  [2.x.225]  class: note the elegance of forming the scalar products of symmetric tensors of rank 2 and 4. The implementation is also more general since it is independent of the fact that we may or may not be using an isotropic elasticity tensor.   
*   The first part of the assembly routine is as always:
* 

* 
* [1.x.163]
* 
*  As in  [2.x.226] , we only need to loop over all cells that belong to the present processor:
* 

* 
* [1.x.164]
* 
*  Then loop over all indices i,j and quadrature points and assemble the system matrix contributions from this cell.  Note how we extract the symmetric gradients (strains) of the shape functions at a given quadrature point from the  [2.x.227]  object, and the elegance with which we form the triple contraction  [2.x.228] ; the latter needs to be compared to the clumsy computations needed in  [2.x.229] , both in the introduction as well as in the respective place in the program:
* 

* 
* [1.x.165]
* 
*  Then also assemble the local right hand side contributions. For this, we need to access the prior stress value in this quadrature point. To get it, we use the user pointer of this cell that points into the global array to the quadrature point data corresponding to the first quadrature point of the present cell, and then add an offset corresponding to the index of the quadrature point we presently consider:
* 

* 
* [1.x.166]
* 
*  In addition, we need the values of the external body forces at the quadrature points on this cell:
* 

* 
* [1.x.167]
* 
*  Then we can loop over all degrees of freedom on this cell and compute local contributions to the right hand side:
* 

* 
* [1.x.168]
* 
*  Now that we have the local contributions to the linear system, we need to transfer it into the global objects. This is done exactly as in  [2.x.230] :
* 

* 
* [1.x.169]
* 
*  Now compress the vector and the system matrix:
* 

* 
* [1.x.170]
* 
*  The last step is to again fix up boundary values, just as we already did in previous programs. A slight complication is that the  [2.x.231]  function wants to have a solution vector compatible with the matrix and right hand side (i.e. here a distributed %parallel vector, rather than the sequential vector we use in this program) in order to preset the entries of the solution vector with the correct boundary values. We provide such a compatible vector in the form of a temporary vector which we then copy into the sequential one.
* 

* 
*  We make up for this complication by showing how boundary values can be used flexibly: following the way we create the triangulation, there are three distinct boundary indicators used to describe the domain, corresponding to the bottom and top faces, as well as the inner/outer surfaces. We would like to impose boundary conditions of the following type: The inner and outer cylinder surfaces are free of external forces, a fact that corresponds to natural (Neumann-type) boundary conditions for which we don't have to do anything. At the bottom, we want no movement at all, corresponding to the cylinder being clamped or cemented in at this part of the boundary. At the top, however, we want a prescribed vertical downward motion compressing the cylinder; in addition, we only want to restrict the vertical movement, but not the horizontal ones
* 
*  -  one can think of this situation as a well-greased plate sitting on top of the cylinder pushing it downwards: the atoms of the cylinder are forced to move downward, but they are free to slide horizontally along the plate.
* 

* 
*  The way to describe this is as follows: for boundary indicator zero (bottom face) we use a dim-dimensional zero function representing no motion in any coordinate direction. For the boundary with indicator 1 (top surface), we use the  [2.x.232]  class, but we specify an additional argument to the  [2.x.233]  function denoting which vector components it should apply to; this is a vector of bools for each vector component and because we only want to restrict vertical motion, it has only its last component set:
* 

* 
* [1.x.171]
* 
*   [1.x.172]  [1.x.173]
* 

* 
*  The next function is the one that controls what all has to happen within a timestep. The order of things should be relatively self-explanatory from the function names:
* 

* 
* [1.x.174]
* 
*   [1.x.175]  [1.x.176]
* 

* 
*  Solving the linear system again works mostly as before. The only difference is that we want to only keep a complete local copy of the solution vector instead of the distributed one that we get as output from PETSc's solver routines. To this end, we declare a local temporary variable for the distributed vector and initialize it with the contents of the local variable (remember that the  [2.x.234]  function called in  [2.x.235]  preset the values of boundary nodes in this vector), solve with it, and at the end of the function copy it again into the complete local vector that we declared as a member variable. Hanging node constraints are then distributed only on the local copy, i.e. independently of each other on each of the processors:
* 

* 
* [1.x.177]
* 
*   [1.x.178]  [1.x.179]
* 

* 
*  This function generates the graphical output in .vtu format as explained in the introduction. Each process will only work on the cells it owns, and then write the result into a file of its own. Additionally, processor 0 will write the record files the reference all the .vtu files.   
*   The crucial part of this function is to give the  [2.x.236]  class a way to only work on the cells that the present process owns.
* 

* 
*  

* 
* [1.x.180]
* 
*  Then, just as in  [2.x.237] , define the names of solution variables (which here are the displacement increments) and queue the solution vector for output. Note in the following switch how we make sure that if the space dimension should be unhandled that we throw an exception saying that we haven't implemented this case yet (another case of defensive programming):
* 

* 
* [1.x.181]
* 
*  The next thing is that we wanted to output something like the average norm of the stresses that we have stored in each cell. This may seem complicated, since on the present processor we only store the stresses in quadrature points on those cells that actually belong to the present process. In other words, it seems as if we can't compute the average stresses for all cells. However, remember that our class derived from  [2.x.238]  only iterates over those cells that actually do belong to the present processor, i.e. we don't have to compute anything for all the other cells as this information would not be touched. The following little loop does this. We enclose the entire block into a pair of braces to make sure that the iterator variables do not remain accidentally visible beyond the end of the block in which they are used:
* 

* 
* [1.x.182]
* 
*  Loop over all the cells...
* 

* 
* [1.x.183]
* 
*  On these cells, add up the stresses over all quadrature points...
* 

* 
* [1.x.184]
* 
*  ...then write the norm of the average to their destination:
* 

* 
* [1.x.185]
* 
*  And on the cells that we are not interested in, set the respective value in the vector to a bogus value (norms must be positive, and a large negative value should catch your eye) in order to make sure that if we were somehow wrong about our assumption that these elements would not appear in the output file, that we would find out by looking at the graphical output:
* 

* 
* [1.x.186]
* 
*  Finally attach this vector as well to be treated for output:
* 

* 
* [1.x.187]
* 
*  As a last piece of data, let us also add the partitioning of the domain into subdomains associated with the processors if this is a parallel job. This works in the exact same way as in the  [2.x.239]  program:
* 

* 
* [1.x.188]
* 
*  Finally, with all this data, we can instruct deal.II to munge the information and produce some intermediate data structures that contain all these solution and other data vectors:
* 

* 
* [1.x.189]
* 
*  Let us call a function that opens the necessary output files and writes the data we have generated into them. The function automatically constructs the file names from the given directory name (the first argument) and file name base (second argument). It augments the resulting string by pieces that result from the time step number and a "piece number" that corresponds to a part of the overall domain that can consist of one or more subdomains.     
*   The function also writes a record files (with suffix `.pvd`) for Paraview that describes how all of these output files combine into the data for this single time step:
* 

* 
* [1.x.190]
* 
*  The record files must be written only once and not by each processor, so we do this on processor 0:
* 

* 
* [1.x.191]
* 
*  Finally, we write the paraview record, that references all .pvtu files and their respective time. Note that the variable times_and_names is declared static, so it will retain the entries from the previous timesteps.
* 

* 
* [1.x.192]
* 
*   [1.x.193]  [1.x.194]
* 

* 
*  This and the next function handle the overall structure of the first and following timesteps, respectively. The first timestep is slightly more involved because we want to compute it multiple times on successively refined meshes, each time starting from a clean state. At the end of these computations, in which we compute the incremental displacements each time, we use the last results obtained for the incremental displacements to compute the resulting stress updates and move the mesh accordingly. On this new mesh, we then output the solution and any additional data we consider important.   
*   All this is interspersed by generating output to the console to update the person watching the screen on what is going on. As in  [2.x.240] , the use of  [2.x.241]  makes sure that only one of the parallel processes is actually writing to the console, without having to explicitly code an if-statement in each place where we generate output:
* 

* 
* [1.x.195]
* 
*   [1.x.196]  [1.x.197]
* 

* 
*  Subsequent timesteps are simpler, and probably do not require any more documentation given the explanations for the previous function above:
* 

* 
* [1.x.198]
* 
*   [1.x.199]  [1.x.200]
* 

* 
*  The following function is called when solving the first time step on successively refined meshes. After each iteration, it computes a refinement criterion, refines the mesh, and sets up the history variables in each quadrature point again to a clean state.
* 

* 
* [1.x.201]
* 
*  First, let each process compute error indicators for the cells it owns:
* 

* 
* [1.x.202]
* 
*  Then set up a global vector into which we merge the local indicators from each of the %parallel processes:
* 

* 
* [1.x.203]
* 
*  Once we have that, copy it back into local copies on all processors and refine the mesh accordingly:
* 

* 
* [1.x.204]
* 
*  Finally, set up quadrature point data again on the new mesh, and only on those cells that we have determined to be ours:
* 

* 
* [1.x.205]
* 
*   [1.x.206]  [1.x.207]
* 

* 
*  At the end of each time step, we move the nodes of the mesh according to the incremental displacements computed in this time step. To do this, we keep a vector of flags that indicate for each vertex whether we have already moved it around, and then loop over all cells and move those vertices of the cell that have not been moved yet. It is worth noting that it does not matter from which of the cells adjacent to a vertex we move this vertex: since we compute the displacement using a continuous finite element, the displacement field is continuous as well and we can compute the displacement of a given vertex from each of the adjacent cells. We only have to make sure that we move each node exactly once, which is why we keep the vector of flags.   
*   There are two noteworthy things in this function. First, how we get the displacement field at a given vertex using the  [2.x.242]  function that returns the index of the  [2.x.243]  of the given cell. In the present case, displacement in the k-th coordinate direction corresponds to the k-th component of the finite element. Using a function like this bears a certain risk, because it uses knowledge of the order of elements that we have taken together for this program in the  [2.x.244]  element. If we decided to add an additional variable, for example a pressure variable for stabilization, and happened to insert it as the first variable of the element, then the computation below will start to produce nonsensical results. In addition, this computation rests on other assumptions: first, that the element we use has, indeed, degrees of freedom that are associated with vertices. This is indeed the case for the present Q1 element, as would be for all Qp elements of polynomial order  [2.x.245] . However, it would not hold for discontinuous elements, or elements for mixed formulations. Secondly, it also rests on the assumption that the displacement at a vertex is determined solely by the value of the degree of freedom associated with this vertex; in other words, all shape functions corresponding to other degrees of freedom are zero at this particular vertex. Again, this is the case for the present element, but is not so for all elements that are presently available in deal.II. Despite its risks, we choose to use this way in order to present a way to query individual degrees of freedom associated with vertices.   
*   In this context, it is instructive to point out what a more general way would be. For general finite elements, the way to go would be to take a quadrature formula with the quadrature points in the vertices of a cell. The  [2.x.246]  formula for the trapezoidal rule does exactly this. With this quadrature formula, we would then initialize an  [2.x.247]  object in each cell, and use the  [2.x.248]  function to obtain the values of the solution function in the quadrature points, i.e. the vertices of the cell. These are the only values that we really need, i.e. we are not at all interested in the weights (or the  [2.x.249]  values) associated with this particular quadrature formula, and this can be specified as the last argument in the constructor to  [2.x.250] . The only point of minor inconvenience in this scheme is that we have to figure out which quadrature point corresponds to the vertex we consider at present, as they may or may not be ordered in the same order.   
*   This inconvenience could be avoided if finite elements have support points on vertices (which the one here has; for the concept of support points, see  [2.x.251]  "support points"). For such a case, one could construct a custom quadrature rule using  [2.x.252]  The first  [2.x.253]  quadrature points will then correspond to the vertices of the cell and are ordered consistent with  [2.x.254] , taking into account that support points for vector elements will be duplicated  [2.x.255]  times.   
*   Another point worth explaining about this short function is the way in which the triangulation class exports information about its vertices: through the  [2.x.256]  function, it advertises how many vertices there are in the triangulation. Not all of them are actually in use all the time
* 
*  -  some are left-overs from cells that have been coarsened previously and remain in existence since deal.II never changes the number of a vertex once it has come into existence, even if vertices with lower number go away. Secondly, the location returned by  [2.x.257]  is not only a read-only object of type  [2.x.258] , but in fact a reference that can be written to. This allows to move around the nodes of a mesh with relative ease, but it is worth pointing out that it is the responsibility of an application program using this feature to make sure that the resulting cells are still useful, i.e. are not distorted so much that the cell is degenerated (indicated, for example, by negative Jacobians). Note that we do not have any provisions in this function to actually ensure this, we just have faith.   
*   After this lengthy introduction, here are the full 20 or so lines of code:
* 

* 
* [1.x.208]
* 
*   [1.x.209]  [1.x.210]
* 

* 
*  At the beginning of our computations, we needed to set up initial values of the history variables, such as the existing stresses in the material, that we store in each quadrature point. As mentioned above, we use the  [2.x.259]  for this that is available in each cell.   
*   To put this into larger perspective, we note that if we had previously available stresses in our model (which we assume do not exist for the purpose of this program), then we would need to interpolate the field of preexisting stresses to the quadrature points. Likewise, if we were to simulate elasto-plastic materials with hardening/softening, then we would have to store additional history variables like the present yield stress of the accumulated plastic strains in each quadrature points. Pre-existing hardening or weakening would then be implemented by interpolating these variables in the present function as well.
* 

* 
* [1.x.211]
* 
*  For good measure, we set all user pointers of all cells, whether ours of not, to the null pointer. This way, if we ever access the user pointer of a cell which we should not have accessed, a segmentation fault will let us know that this should not have happened:
* 

* 
*  

* 
* [1.x.212]
* 
*  Next, allocate the quadrature objects that are within the responsibility of this processor. This, of course, equals the number of cells that belong to this processor times the number of quadrature points our quadrature formula has on each cell. Since the `resize()` function does not actually shrink the amount of allocated memory if the requested new size is smaller than the old size, we resort to a trick to first free all memory, and then reallocate it: we declare an empty vector as a temporary variable and then swap the contents of the old vector and this temporary variable. This makes sure that the `quadrature_point_history` is now really empty, and we can let the temporary variable that now holds the previous contents of the vector go out of scope and be destroyed. In the next step we can then re-allocate as many elements as we need, with the vector default-initializing the `PointHistory` objects, which includes setting the stress variables to zero.
* 

* 
* [1.x.213]
* 
*  Finally loop over all cells again and set the user pointers from the cells that belong to the present processor to point to the first quadrature point objects corresponding to this cell in the vector of such objects:
* 

* 
* [1.x.214]
* 
*  At the end, for good measure make sure that our count of elements was correct and that we have both used up all objects we allocated previously, and not point to any objects beyond the end of the vector. Such defensive programming strategies are always good checks to avoid accidental errors and to guard against future changes to this function that forget to update all uses of a variable at the same time. Recall that constructs using the  [2.x.260]  macro are optimized away in optimized mode, so do not affect the run time of optimized runs:
* 

* 
* [1.x.215]
* 
*   [1.x.216]  [1.x.217]
* 

* 
*  At the end of each time step, we should have computed an incremental displacement update so that the material in its new configuration accommodates for the difference between the external body and boundary forces applied during this time step minus the forces exerted through preexisting internal stresses. In order to have the preexisting stresses available at the next time step, we therefore have to update the preexisting stresses with the stresses due to the incremental displacement computed during the present time step. Ideally, the resulting sum of internal stresses would exactly counter all external forces. Indeed, a simple experiment can make sure that this is so: if we choose boundary conditions and body forces to be time independent, then the forcing terms (the sum of external forces and internal stresses) should be exactly zero. If you make this experiment, you will realize from the output of the norm of the right hand side in each time step that this is almost the case: it is not exactly zero, since in the first time step the incremental displacement and stress updates were computed relative to the undeformed mesh, which was then deformed. In the second time step, we again compute displacement and stress updates, but this time in the deformed mesh
* 
*  -  there, the resulting updates are very small but not quite zero. This can be iterated, and in each such iteration the residual, i.e. the norm of the right hand side vector, is reduced; if one makes this little experiment, one realizes that the norm of this residual decays exponentially with the number of iterations, and after an initial very rapid decline is reduced by roughly a factor of about 3.5 in each iteration (for one testcase I looked at, other testcases, and other numbers of unknowns change the factor, but not the exponential decay).
* 

* 
*  In a sense, this can then be considered as a quasi-timestepping scheme to resolve the nonlinear problem of solving large-deformation elasticity on a mesh that is moved along in a Lagrangian manner.   
*   Another complication is that the existing (old) stresses are defined on the old mesh, which we will move around after updating the stresses. If this mesh update involves rotations of the cell, then we need to also rotate the updated stress, since it was computed relative to the coordinate system of the old cell.   
*   Thus, what we need is the following: on each cell which the present processor owns, we need to extract the old stress from the data stored with each quadrature point, compute the stress update, add the two together, and then rotate the result together with the incremental rotation computed from the incremental displacement at the present quadrature point. We will detail these steps below:
* 

* 
* [1.x.218]
* 
*  First, set up an  [2.x.261]  object by which we will evaluate the incremental displacements and the gradients thereof at the quadrature points, together with a vector that will hold this information:
* 

* 
* [1.x.219]
* 
*  Then loop over all cells and do the job in the cells that belong to our subdomain:
* 

* 
* [1.x.220]
* 
*  Next, get a pointer to the quadrature point history data local to the present cell, and, as a defensive measure, make sure that this pointer is within the bounds of the global array:
* 

* 
* [1.x.221]
* 
*  Then initialize the  [2.x.262]  object on the present cell, and extract the gradients of the displacement at the quadrature points for later computation of the strains
* 

* 
* [1.x.222]
* 
*  Then loop over the quadrature points of this cell:
* 

* 
* [1.x.223]
* 
*  On each quadrature point, compute the strain increment from the gradients, and multiply it by the stress-strain tensor to get the stress update. Then add this update to the already existing strain at this point:
* 

* 
* [1.x.224]
* 
*  Finally, we have to rotate the result. For this, we first have to compute a rotation matrix at the present quadrature point from the incremental displacements. In fact, it can be computed from the gradients, and we already have a function for that purpose:
* 

* 
* [1.x.225]
* 
*  Note that the result, a rotation matrix, is in general an antisymmetric tensor of rank 2, so we must store it as a full tensor.
* 

* 
*  With this rotation matrix, we can compute the rotated tensor by contraction from the left and right, after we expand the symmetric tensor  [2.x.263]  into a full tensor:
* 

* 
* [1.x.226]
* 
*  Note that while the result of the multiplication of these three matrices should be symmetric, it is not due to floating point round off: we get an asymmetry on the order of 1e-16 of the off-diagonal elements of the result. When assigning the result to a  [2.x.264] , the constructor of that class checks the symmetry and realizes that it isn't exactly symmetric; it will then raise an exception. To avoid that, we explicitly symmetrize the result to make it exactly symmetric.
* 

* 
*  The result of all these operations is then written back into the original place:
* 

* 
* [1.x.227]
* 
*  This ends the project specific namespace  [2.x.265] . The rest is as usual and as already shown in  [2.x.266] : A  [2.x.267]  function that initializes and terminates PETSc, calls the classes that do the actual work, and makes sure that we catch all exceptions that propagate up to this point:
* 

* 
* [1.x.228]
* [1.x.229][1.x.230]
* 

* 
* Running the program takes a good while if one uses debug mode; it takes abouteleven minutes on my i7 desktop. Fortunately, the version compiled withoptimizations is much faster; the program only takes about a minute and a halfafter recompiling with the command <tt>make release</tt> on the same machine, amuch more reasonable time.
* 

* If run, the program prints the following output, explaining what it isdoing during all that time:
* [1.x.231]
* In other words, it is computing on 12,000 cells and with some 52,000unknowns. Not a whole lot, but enough for a coupled three-dimensionalproblem to keep a computer busy for a while. At the end of the day,this is what we have for output:
* [1.x.232]
* 
* 

* If we visualize these files with VisIt or Paraview, we get to see the full pictureof the disaster our forced compression wreaks on the cylinder (colors in theimages encode the norm of the stress in the material):
* 

*  [2.x.268] 
* 

*  [2.x.269] 
* 

* As is clearly visible, as we keep compressing the cylinder, it startsto bow out near the fully constrained bottom surface and, after about eighttime units, buckle in an azimuthally symmetric manner.
* 

* Although the result appears plausible for the symmetric geometry and loading,it is yet to be established whether or not the computation is fully converged.In order to see whether it is, we ran the program again with one more globalrefinement at the beginning and with the time step halved. This would havetaken a very long time on a single machine, so we used a proper workstation andran it on 16 processors in parallel. The beginning of the output now looks likethis:
* [1.x.233]
* That's quite a good number of unknowns, given that we are in 3d. The output ofthis program are 16 files for each time step:
* [1.x.234]
* 
* 

* Here are first the mesh on which we compute as well as the partitioningfor the 16 processors:
* 

*  [2.x.270] 
* 

* Finally, here is the same output as we have shown before for the much smallersequential case:
*  [2.x.271] 
* 

*  [2.x.272] 
* 

* As before, we observe that at high axial compression the cylinder beginsto buckle, but this time ultimately collapses on itself. In contrast to ourfirst run, towards the end of the simulation the deflection pattern becomesnonsymmetric (the central bulge deflects laterally). The model clearly does notprovide for this (all our forces and boundary deflections are symmetric) but theeffect is probably physically correct anyway: in reality, small inhomogeneitiesin the body's material properties would lead it to buckle to one sideto evade the forcing; in numerical simulations, small perturbationssuch as numerical round-off or an inexact solution of a linear systemby an iterative solver could have the same effect. Another typical source forasymmetries in adaptive computations is that only a certain fraction of cellsis refined in each step, which may lead to asymmetric meshes even if theoriginal coarse mesh was symmetric.
* 

* If one compares this with the previous run, the results both qualitativelyand quantitatively different. The previous computation wastherefore certainly not converged, though we can't say for sure anything aboutthe present one. One would need an even finer computation to find out. However,the point may be moot: looking at the last picture in detail, it is prettyobvious that not only is the linear small deformation model we chose completelyinadequate, but for a realistic simulation we would also need to make sure thatthe body does not intersect itself during deformation (if we continuedcompressing the cylinder we would observe some self-intersection).Without such a formulation we cannot expect anything to make physical sense,even if it produces nice pictures!
* 

* [1.x.235][1.x.236]
* 

* The program as is does not really solve an equation that has many applicationsin practice: quasi-static material deformation based on a purely elastic lawis almost boring. However, the program may serve as the starting point formore interesting experiments, and that indeed was the initial motivation forwriting it. Here are some suggestions of what the program is missing and inwhat direction it may be extended:
* [1.x.237][1.x.238]
* 

*  The most obvious extension is to use a morerealistic material model for large-scale quasistatic deformation. The naturalchoice for this would be plasticity, in which a nonlinear relationship betweenstress and strain replaces equation [1.x.239]. Plasticitymodels are usually rather complicated to program since the stress-straindependence is generally non-smooth. The material can be thought of being ableto withstand only a maximal stress (the yield stress) after which it starts to&ldquo;flow&rdquo;. A mathematical description to this can be given in the form of avariational inequality, which alternatively can be treated as minimizing theelastic energy[1.x.240]subject to the constraint[1.x.241]on the stress. This extension makes the problem to be solved in each time stepnonlinear, so we need another loop within each time step.
* Without going into further details of this model, we refer to the excellentbook by Simo and Hughes on &ldquo;Computational Inelasticity&rdquo; for acomprehensive overview of computational strategies for solving plasticmodels. Alternatively, a brief but concise description of an algorithm forplasticity is given in an article by S. Commend, A. Truty, and Th. Zimmermann; [2.x.273] .
* 

* [1.x.242][1.x.243]
* 

* The formulation we have chosen, i.e. usingpiecewise (bi-, tri-)linear elements for all components of the displacementvector, and treating the stress as a variable dependent on the displacement isappropriate for most materials. However, this so-called displacement-basedformulation becomes unstable and exhibits spurious modes for incompressible ornearly-incompressible materials. While fluids are usually not elastic (in mostcases, the stress depends on velocity gradients, not displacement gradients,although there are exceptions such as electro-rheologic fluids), there are afew solids that are nearly incompressible, for example rubber. Another case isthat many plasticity models ultimately let the material become incompressible,although this is outside the scope of the present program.
* Incompressibility is characterized by Poisson's ratio[1.x.244]where  [2.x.274]  are the Lam&eacute; constants of the material.Physical constraints indicate that  [2.x.275]  (the conditionalso follows from mathematical stability considerations). If  [2.x.276] approaches  [2.x.277] , then the material becomes incompressible. In thatcase, pure displacement-based formulations are no longer appropriate for thesolution of such problems, and stabilization techniques have to be employedfor a stable and accurate solution. The book and paper cited above giveindications as to how to do this, but there is also a large volume ofliterature on this subject; a good start to get an overview of the topic canbe found in the references of the paper by H.-Y. Duan and Q. Lin;  [2.x.278] .
* 

* [1.x.245][1.x.246]
* 

* In the present form, the programonly refines the initial mesh a number of times, but then never again. For anykind of realistic simulation, one would want to extend this so that the meshis refined and coarsened every few time steps instead. This is not hard to do,in fact, but has been left for future tutorial programs or as an exercise, ifyou wish.
* The main complication one has to overcome is that one has totransfer the data that is stored in the quadrature points of the cells of theold mesh to the new mesh, preferably by some sort of projection scheme. Thegeneral approach to this would go like this:
* 
*  - At the beginning, the data is only available in the quadrature points of  individual cells, not as a finite element field that is defined everywhere.
* 
*  - So let us find a finite element field that [1.x.247] defined everywhere so  that we can later interpolate it to the quadrature points of the new  mesh. In general, it will be difficult to find a continuous finite element  field that matches the values in the quadrature points exactly because the  number of degrees of freedom of these fields does not match the number of  quadrature points there are, and the nodal values of this global field will  either be over- or underdetermined. But it is usually not very difficult to  find a discontinuous field that matches the values in the quadrature points;  for example, if you have a QGauss(2) quadrature formula (i.e. 4 points per  cell in 2d, 8 points in 3d), then one would use a finite element of kind  FE_DGQ(1), i.e. bi-/tri-linear functions as these have 4 degrees of freedom  per cell in 2d and 8 in 3d.
* 
*  - There are functions that can make this conversion from individual points to  a global field simpler. The following piece of pseudo-code should help if  you use a QGauss(2) quadrature formula. Note that the multiplication by the  projection matrix below takes a vector of scalar components, i.e., we can only  convert one set of scalars at a time from the quadrature points to the degrees  of freedom and vice versa. So we need to store each component of stress separately,  which requires  [2.x.279]  vectors. We'll store this set of vectors in a 2D array to  make it easier to read off components in the same way you would the stress tensor.  Thus, we'll loop over the components of stress on each cell and store  these values in the global history field. (The prefix  [2.x.280]   indicates that we work with quantities related to the history variables defined  in the quadrature points.) 
* [1.x.248]
* 
* 
*  - Now that we have a global field, we can refine the mesh and transfer the  history_field vector as usual using the SolutionTransfer class. This will  interpolate everything from the old to the new mesh.
* 
*  - In a final step, we have to get the data back from the now interpolated  global field to the quadrature points on the new mesh. The following code  will do that: 
* [1.x.249]
* 
* It becomes a bit more complicated once we run the program in parallel, sincethen each process only stores this data for the cells it owned on the oldmesh. That said, using a parallel vector for  [2.x.281]  willdo the trick if you put a call to  [2.x.282]  after the transferfrom quadrature points into the global vector.
* 

* [1.x.250][1.x.251]
* 

* At present, the program makes no attemptto make sure that a cell, after moving its vertices at the end of the timestep, still has a valid geometry (i.e. that its Jacobian determinant ispositive and bounded away from zero everywhere). It is, in fact, not very hardto set boundary values and forcing terms in such a way that one gets distortedand inverted cells rather quickly. Certainly, in some cases of largedeformation, this is unavoidable with a mesh of finite mesh size, but in someother cases this should be preventable by appropriate mesh refinement and/or areduction of the time step size. The program does not do that, but a moresophisticated version definitely should employ some sort of heuristic definingwhat amount of deformation of cells is acceptable, and what isn't.
* 

* [1.x.252][1.x.253] [2.x.283] 
* [0.x.1]