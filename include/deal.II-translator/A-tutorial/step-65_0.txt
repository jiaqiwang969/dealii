[0.x.0]*
 [2.x.0] 
* This tutorial depends on  [2.x.1] .
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18][1.x.19][1.x.20][1.x.21]
* 
*  [2.x.2] 
* [1.x.22]
* [1.x.23][1.x.24][1.x.25]
* 

* This tutorial program presents an advanced manifold class,TransfiniteInterpolationManifold, and how to work around its maindisadvantage, the relatively high cost.
* [1.x.26][1.x.27]
* 

* [1.x.28][1.x.29]
* 

* In many applications, the finite element mesh must be able to represent arelatively complex geometry. In the  [2.x.3] ,  [2.x.4] , and  [2.x.5]  tutorialprograms, some techniques to generate grids available within the deal.IIlibrary have been introduced. Given a base mesh, deal.II is then able tocreate a finer mesh by subdividing the cells into children, either uniformlyor only in selected parts of the computational domain. Besides the basicmeshing capabilities collected in the GridGenerator namespace, deal.II alsocomes with interfaces to read in meshes generated by (quad- and hex-only) meshgenerators using the functions of namespace GridIn, as for exampledemonstrated in  [2.x.6] . A fundamental limitation ofexternally generated meshes is that the information provided by the generatedcells in the mesh only consists of the position of the vertices and theirconnectivity, without the context of the underlying geometry that used to beavailable in the mesh generator that originally created this mesh. Thisbecomes problematic once the mesh is refined within deal.II and additionalpoints need to be placed. The  [2.x.7]  tutorial program shows how toovercome this limitation by using CAD surfaces in terms of the OpenCASCADElibrary, and  [2.x.8]  by providing the same kind of informationprogrammatically from within the source code.
* Within deal.II, the placement of new points during mesh refinement or for thedefinition of higher order mappings is controlled by manifold objects, see the [2.x.9]  "manifold module"for details.To give an example, consider the following situation of a two-dimensionalannulus (with pictures taken from the manifold module). If we start with aninitial mesh of 10 cells and refine the mesh three times globally withoutattaching any manifolds, we would obtain the following mesh:
*  [2.x.10] 
* The picture looks like this because, by default, deal.II only knowswhere to put the vertices of child cells by averaging the locations ofthe vertices of the parent cell. This yields a polygonal domain whosefaces are the edges of the original (coarse mesh) cells.Obviously, we must attach a curved description to the boundary faces of thetriangulation to reproduce the circular shape upon mesh refinement, like inthe following picture:
*  [2.x.11] 
* This is better: At least the inner and outer boundaries are nowapproaching real circles if we continue to refine the mesh.However, the mesh in this picture is still not optimal for an annulus in thesense that the [1.x.30] lines from one cell to the next have kinks at certain vertices,and one would rather like to use the following mesh:
*  [2.x.12] 
* In this last (optimal) case, which is also the default produced by [2.x.13]  the curved manifold description (in this case apolar manifold description) is applied not only to the boundary faces, but tothe whole domain. Whenever the triangulation requests a new point, e.g., themid point of the edges or the cells when it refines a cell into four children,it will place them along the respective mid points in the polar coordinatesystem. By contrast, the case above where only the boundary was subject to thepolar manifold, only mid points along the boundary would be placed along thecurved description, whereas mid points in the interior would be computed bysuitable averages of the surrounding points in the Cartesian coordinate system(see the  [2.x.14]  "manifold module" for more details).
* At this point, one might assume that curved volume descriptions are the way togo. This is generally not wrong, though it is sometimes not so easy todescribe how exactly this should work. Here are a couple of examples:
* 
*  - Imagine that the mesh above had actually been a disk, not just a ring.  In that case the polar manifold degenerates at the origin and  would not produce reasonable new points. In fact, defining a  manifold description for things that are supposed "to look round"  but might have points at or close to the origin is surprisingly very  difficult.
* 
*  - A similar thing happens at the origin  of the three-dimensional ball when one tries to attach a spherical manifold to  the whole volume &ndash; in this case, the computation of new manifold points  would abort with an exception.
* 
*  - CAD geometries often only describe the boundary of the domain, in a  similar way to how we only attached a manifold to the boundary in  the second picture above. Similarly,  [2.x.15]  only uses the CAD  geometry to generate a surface mesh (maybe because that is what is  needed to solve the problem in question), but if one wanted to solve  a problem in the water or the air around the ship described there,  we would need to have a volume mesh. The question is then how  exactly we should describe what is supposed to happen in the  interior of the domain.
* These simple examples make it clear thatfor many interesting cases we must step back from the desire to have ananalytic curved description for the full volume: There will need to be[1.x.31] kind of information that leads to curvature also in theinterior, but it must be possible to do this without actually writingdown an explicit formula that describes the kind of geometry.
* So what happens if we don't do anything at all in the interior andonly describe the surface as a manifold? Sometimes, as in the ringshown above, the result is not terrible. But sometimes it is. Consider thecase of a torus (e.g. generated with  [2.x.16]  with aTorusManifold object attached to the surface only, no additional manifolds onthe interior cells and faces, and with six cells in toroidal direction beforerefinement. If the mesh is refined once, we would obtain the following mesh,shown with the upper half of the mesh clipped away:
*  [2.x.17] 
* This is clearly sub-optimal. Indeed, if we had started with fewer thanthe six cells shown above in toroidal direction, the mapping actuallyinverts in some regionsbecause the new points placed along interior cells intersect with the boundaryas they are not following the circular shape along the toroidal direction. Thesimple case of a torus can still be fixed because we know that the toroidaldirection follows a cylindrical coordinate system, so attaching aTorusManifold to the surface combined with CylindricalManifold withappropriate periodicity in toroidal direction applied to all interior entitieswould produce a high-quality mesh as follows, now shown with two top cellshidden:
*  [2.x.18] 
* This mesh is pretty good, but obviously it is linked to a good description ofthe volume, which we lack in other cases. Actually, there is an imperfectionalso in this case, as we can see some unnatural kinks of two adjacent cells inthe interior of the domain which are hidden by the top two boundary cells, asopposed to the following setup (the default manifolds applied by [2.x.19]  and using the TransfiniteInterpolationManifold):
*  [2.x.20] 
* [1.x.32][1.x.33]
* 

* In order to find a better strategy, let us look at the two-dimensional diskagain (that is also the base entity rotated along the toroidal direction inthe torus). As we learned above, we can only apply the curved polardescription to the boundary (or a rim of cells sufficiently far away from theorigin) but must eventually transition to a straight description towards thedisk's center. If we use a flat manifold in the interior of the cells(i.e., one in which new vertices are created by averaging of theadjacent existing ones) and apolar manifold only for the boundary of the disk, we get the following meshupon four global refinements:
*  [2.x.21] 
* That's not a terrible mesh. At the same time,if you know that the original coarse mesh consisted of a single squarein the middle, with four caps around it, then it's not hard to seeevery refinement step that happened to this mesh to get the pictureabove.
* While the triangulation class of deal.II tries to propagate information fromthe boundary into the interior when creating new points, the reach of thisalgorithm is limited:
*  [2.x.22] 
* The picture above highlights those cells on the disk that are touching theboundary and where boundary information could in principle be taken intoaccount when only looking at a single cell at the time. Clearly, the areawhere some curvature can be taken into account gets more limited as the meshis refined, thus creating the seemingly irregular spots in the mesh: Whencomputing the center of any one of the boundary cells in the leftmost picture,the ideal position is the mid point between the outer circle and the cell inthe middle. This is exactly what is used for the first refinement step in theTriangulation class. However, for the second refinement all interior edges aswell as the interior cell layers can only add points according to a flatmanifold description.
* At this point, we realize what would be needed to create a better mesh: For[1.x.34] new points in [1.x.35] child cell that is created within the red shadedlayer on the leftmost picture, we want to compute the interpolation withrespect to the curvature in the area covered by the respective coarsecell. This is achieved by adding the class TransfiniteInterpolationManifold tothe highlighted cells of the coarse grid in the leftmost panel of the figureabove. This class adheres to the general manifold interfaces, i.e., given anyset of points within its domain of definition, it can compute weightedaverages conforming to the manifold (using a formula that will be given in aminute). These weighted averages are used whenever the mesh is refined, orwhen a higher order mapping (such as MappingQGeneric or MappingC1)is evaluated on a given cellsubject to this manifold. Using this manifold on the shaded cells of thecoarse grid of the disk (i.e., not only in the outer-most layer ofcells) produces the following mesh upon four globalsteps of refinement:
*  [2.x.23] 
* There are still some kinks in the lines of this mesh, but they arerestricted to the faces between coarse mesh cells, whereas the rest ofthe mesh is about as smooth as one would like. Indeed,given a straight-sided central cell, this representation is the best possibleone as all mesh cells follow a smooth transition from the straight sides inthe square block in the interior to the circular shape on the boundary. (Onecould possibly do a bit better by allowing some curvature also in the centralsquare block, that eventually vanishes as the center is approached.)
* 

* [1.x.36][1.x.37]
* 

* In the simple case of a disk with one curved and three straight edges, we canexplicitly write down how to achieve the blending of the shapes. For this, itis useful to map the physical cell, like the top one, back to the referencecoordinate system  [2.x.24]  where we compute averages betweencertain points. If we were to use a simple bilinear map spanned by fourvertices  [2.x.25] , the image of a point [2.x.26]  would be
* [1.x.38]
* 
* For the case of the curved surface, we want to modify this formula. For thetop cell of the coarse mesh of the disk, we can assume that the points [2.x.27]  and  [2.x.28]  sit along the straight line at the lower end andthe points  [2.x.29]  and  [2.x.30]  are connected by a quarter circle alongthe top. We would then map a point  [2.x.31]  as
* [1.x.39]
* where  [2.x.32]  is a curve that describes the  [2.x.33]  coordinates ofthe quarter circle in terms of an arclength parameter  [2.x.34] . Thisrepresents a linear interpolation between the straight lower edge and thecurved upper edge of the cell, and is the basis for the picture shown above.
* This formula is easily generalized to the case where all four edges aredescribed by a curve rather than a straight line. We call the four functions,parameterized by a single coordinate  [2.x.35]  or  [2.x.36]  in the horizontal andvertical directions,  [2.x.37]  for the left, right, lower, and upper edge of aquadrilateral, respectively. The interpolation then reads
* [1.x.40]
* 
* This formula assumes that the boundary curves match and coincide with thevertices  [2.x.38] , e.g.  [2.x.39]  or  [2.x.40] . The subtraction of the bilinearinterpolation in the second line of the formula makes sure that the prescribedcurves are followed exactly on the boundary: Along each of the four edges, weneed to subtract the contribution of the two adjacent edges evaluated in thecorners, which is then simply a vertex position. It is easy to checkthat the formula for the circle above is reproduced if three of the fourcurves  [2.x.41]  are straight and thus coincide with the bilinearinterpolation.
* This formula, called transfinite interpolation, was introduced in 1973 by [1.x.41]. Eventhough transfinite interpolation essentially only represents a linear blendingof the bounding curves, the interpolation exactly follows the boundary curvesfor each real number  [2.x.42]  or  [2.x.43] , i.e., it interpolatesin an infinite number of points, which was the original motivation to labelthis variant of interpolation a transfinite one by Gordon and Hall. Anotherinterpretation is that the transfinite interpolation interpolates from theleft and right and the top and bottom linearly, from which we need to subtractthe bilinear interpolation to ensure a unit weight in the interior of thedomain.
* The transfinite interpolation is easily generalized to three spatialdimensions. In that case, the interpolation allows to blend 6 differentsurface descriptions for any of the quads of a three-dimensional cell and 12edge descriptions for the lines of a cell. Again, to ensure a consistent map,it is necessary to subtract the contribution of edges and add the contributionof vertices again to make the curves follow the prescribed surface or edgedescription. In the three-dimensional case, it is also possible to use atransfinite interpolation from a curved edge both into the adjacent faces andthe adjacent cells.
* The interpolation of the transfinite interpolation in deal.II is general inthe sense that it can deal with arbitrary curves. It will evaluate the curvesin terms of their original coordinates of the  [2.x.44] -dimensional space but withone (or two, in the case of edges in 3D) coordinate held fixed at  [2.x.45]  or  [2.x.46]  to ensurethat any other manifold class, including CAD files if desired, can be appliedout of the box. Transfinite interpolation is a standard ingredient in meshgenerators, so the main strength of the integration of this feature within thedeal.II library is to enable it during adaptive refinement and coarsening ofthe mesh, and for creating higher-degree mappings that use manifolds to insertadditional points beyond the mesh vertices.
* As a final remark on transfinite interpolation, we mention that the meshrefinement strategies in deal.II in absence of a volume manifold descriptionare also based on the weights of the transfinite interpolation and optimal inthat sense. The difference is that the default algorithm sees only onecell at a time, and so will apply the optimal algorithm only on thosecells touching the curved manifolds. In contrast, using thetransfinite mapping on entire [1.x.42] of cells (originatingfrom one coarser cell) allows to use the transfinite interpolationmethod in a way that propagates information from the boundary to cellsfar away.
* 

* [1.x.43][1.x.44]
* 

* A mesh with a transfinite manifold description is typically set up in twosteps. The first step is to create a coarse mesh (or read it in from a file) and toattach a curved manifold to some of the mesh entities. For the above exampleof the disk, we attach a polar manifold to the faces along the outer circle(this is done automatically by  [2.x.47]  Before we startrefining the mesh, we then assign a TransfiniteInterpolationManifold to allinterior cells and edges of the mesh, which of course needs to be based onsome manifold id that we have assigned to those entities (everything exceptthe circle on the boundary). It does not matter whether we also assign aTransfiniteInterpolationManifold to the inner square of the disk or notbecause the transfinite interpolation on a coarse cell with straightedges (or flat faces in 3d) simply yields subdivided children withstraight edges (flat faces).
* Later, when the mesh is refined or when a higher-order mapping is set up basedon this mesh, the cells will query the underlying manifold object for newpoints. This process takes a set of surrounding points, for example the fourvertices of a two-dimensional cell, and a set of weights to each of thesepoints, for definition a new point. For the mid point of a cell, each of thefour vertices would get weight 0.25. For the transfinite interpolationmanifold, the process of building weighted sums requires some serious work. Byconstruction, we want to combine the points in terms of the referencecoordinates  [2.x.48]  and  [2.x.49]  (or  [2.x.50]  in 3D) of the surroundingpoints. However, the interface of the manifold classes in deal.II does not getthe reference coordinates of the surrounding points (as they are not storedglobally) but rather the physical coordinates only. Thus, the first step thetransfinite interpolation manifold has to do is to invert the mapping and findthe reference coordinates within one of the coarse cells of the transfiniteinterpolation (e.g. one of the four shaded coarse-grid cells of the disk meshabove). This inversion is done by a Newton iteration (or rather,finite-difference based Newton scheme combined with Broyden's method) andqueries the transfinite interpolation according to the formula above severaltimes. Each of these queries in turn might call an expensive manifold, e.g. aspherical description of a ball, and be expensive on its own. Since theManifold interface class of deal.II only provides a set of points, thetransfinite interpolation initially does not even know to which coarse gridcell the set of surrounding points belong to and needs to search among severalcells based on some heuristics. In terms of [1.x.45],one could describe theimplementation of the transfinite interpolation as an [1.x.46]-basedimplementation: Each cell of the initial coarse grid of the triangulationrepresents a chart with its own reference space, and the surrounding manifoldsprovide a way to transform from the chart space (i.e., the reference cell) tothe physical space. The collection of the charts of the coarse grid cells isan atlas, and as usual, the first thing one does when looking up something inan atlas is to find the right chart.
* Once the reference coordinates of the surrounding points have been found, anew point in the reference coordinate system is computed by a simple weightedsum. Finally, the reference point is inserted into the formula for thetransfinite interpolation, which gives the desired new point.
* In a number of cases, the curved manifold is not only used during meshrefinement, but also to ensure a curved representation of boundaries withinthe cells of the computational domain. This is a necessity to guaranteehigh-order convergence for high-order polynomials on complex geometriesanyway, but sometimes an accurate geometry is also desired with linear shapefunctions. This is often done by polynomial descriptions of the cells andcalled the isoparametric concept if the polynomial degree to represent thecurved mesh elements is the same as the degree of the polynomials for thenumerical solution. If the degree of the geometry is higher or lower than thesolution, one calls that a super- or sub-parametric geometry representation,respectively. In deal.II, the standard class for polynomial representation isMappingQGeneric. If, for example, this class is used with polynomial degree  [2.x.51]  in 3D, atotal of 125 (i.e.,  [2.x.52] ) points are needed for theinterpolation. Among these points, 8 are the cell's vertices and alreadyavailable from the mesh, but the other 117 need to be provided by themanifold. In case the transfinite interpolation manifold is used, we canimagine that going through the pull-back into reference coordinates of someyet to be determined coarse cell, followed by subsequent push-forward on eachof the 117 points, is a lot of work and can be very time consuming.
* What makes things worse is that the structure of many programs is suchthat themapping is queried several times independently for the same cell. Its primaryuse is in the assembly of the linear system, i.e., the computation of thesystem matrix and the right hand side, via the `mapping` argument of theFEValues object. However, also the interpolation of boundary values, thecomputation of numerical errors, writing the output, and evaluation of errorestimators must involve the same mapping to ensure a consistent interpretationof the solution vectors. Thus, even a linear stationary problem that is solvedonce will evaluate the points of the mapping several times. For the cubic casein 3D mentioned above, this means computing 117 points per cell by anexpensive algorithm many times. The situation is more pressing for nonlinearor time-dependent problems where those operations are done over and overagain.
* As the manifold description via a transfinite interpolation can easily behundreds of times more expensive than a similar query on a flat manifold, itmakes sense to compute the additional points only once and use them in allsubsequent calls. The deal.II library provides the class MappingQCache forexactly this purpose. The cache is typically not overly big compared to thememory consumed by a system matrix, as will become clear when looking at theresults of this tutorial program. The usage of MappingQCache is simple: Oncethe mesh has been set up (or changed during refinement), we call [2.x.53]  with the desired triangulation as well as adesired mapping as arguments. The initialization then goes through all cellsof the mesh and queries the given mapping for its additional points. Those getstored for an identifier of the cell so that they can later be returnedwhenever the mapping computes some quantities related to the cell (like theJacobians of the map between the reference and physical coordinates).
* As a final note, we mention that the TransfiniteInterpolationManifold alsomakes the refinement of the mesh more expensive. In this case, theMappingQCache does not help because it would compute points that cansubsequently not be re-used; there currently does not exist a moreefficient mechanism in deal.II. However, the mesh refinement contains manyother expensive steps as well, so it is not as big as an issue compared to therest of the computation. It also only happens at most once per timestep or nonlinear iteration.
* [1.x.47][1.x.48]
* 

* In this tutorial program, the usage of TransfiniteInterpolationManifold isexemplified in combination with MappingQCache. The test case is relativelysimple and takes up the solution stages involved in many typical programs,e.g., the  [2.x.54]  tutorial program. As a geometry, we select one prototype useof TransfiniteInterpolationManifold, namely a setup involving a spherical ballthat is in turn surrounded by a cube. Such a setup would be used, for example,for a spherical inclusion embedded in a background medium, and if thatinclusion has different material properties that require that theinterface between the two materials needs to be tracked by element interfaces. Avisualization of the grid is given here:
*  [2.x.55] 
* For this case, we want to attach a spherical description to the surface insidethe domain and use the transfinite interpolation to smoothly switch to thestraight lines of the outer cube and the cube at the center of the ball.
* Within the program, we will follow a typical flow in finite element programs,starting from the setup of DoFHandler and sparsity patterns, the assembly of alinear system for solving the Poisson equation with a jumping coefficient, itssolution with a simple iterative method, computation of some numerical errorwith  [2.x.56]  as well as an error estimator. Werecord timings for each section and run the code twice. In the first run, wehand a MappingQGeneric object to each stage of the program separately, wherepoints get re-computed over and over again. In the second run, we useMappingQCache instead.
* 

*  [1.x.49] [1.x.50]
*   [1.x.51]  [1.x.52]
* 

* 
*  The include files for this tutorial are essentially the same as in  [2.x.57] . Importantly, the TransfiniteInterpolationManifold class we will be using is provided by `deal.II/grid/manifold_lib.h`.
* 

* 
*  

* 
* [1.x.53]
* 
*  The only new include file is the one for the MappingQCache class.
* 

* 
* [1.x.54]
* 
*   [1.x.55]  [1.x.56]
* 

* 
*  In this tutorial program, we want to solve the Poisson equation with a coefficient that jumps along a sphere of radius 0.5, and using a constant right hand side of value  [2.x.58] . (This setup is similar to  [2.x.59]  and  [2.x.60] , but the concrete values for the coefficient and the right hand side are different.) Due to the jump in the coefficient, the analytical solution must have a kink where the coefficient switches from one value to the other. To keep things simple, we select an analytical solution that is quadratic in all components, i.e.,  [2.x.61]  in the ball of radius 0.5 and  [2.x.62]  in the outer part of the domain. This analytical solution is compatible with the right hand side in case the coefficient is 0.5 in the inner ball and 5 outside. It is also continuous along the circle of radius 0.5.
* 

* 
* [1.x.57]
* 
*   [1.x.58]  [1.x.59]   
*   The implementation of the Poisson problem is very similar to what we used in the  [2.x.63]  tutorial program. The two main differences are that we pass a mapping object to the various steps in the program in order to switch between two mapping representations as explained in the introduction, and the `timer` object (of type TimerOutput) that will be used for measuring the run times in the various cases. (The concept of mapping objects was first introduced in  [2.x.64]  and  [2.x.65] , in case you want to look up the use of these classes.)
* 

* 
* [1.x.60]
* 
*  In the constructor, we set up the timer object to record wall times but be quiet during the normal execution. We will query it for timing details in the  [2.x.66]  function. Furthermore, we select a relatively high polynomial degree of three for the finite element in use.
* 

* 
* [1.x.61]
* 
*   [1.x.62]  [1.x.63]   
*   The next function presents the typical usage of TransfiniteInterpolationManifold. The first step is to create the desired grid, which can be done by composition of two grids from GridGenerator. The inner ball mesh is simple enough: We run  [2.x.67]  centered at the origin with radius 0.5 (third function argument). The second mesh is more interesting and constructed as follows: We want to have a mesh that is spherical in the interior but flat on the outer surface. Furthermore, the mesh topology of the inner ball should be compatible with the outer grid in the sense that their vertices coincide so as to allow the two grid to be merged. The grid coming out of  [2.x.68]  fulfills the requirements on the inner side in case it is created with  [2.x.69]  coarse cells (6 coarse cells in 3D which we are going to use) &ndash; this is the same number of cells as there are boundary faces for the ball. For the outer surface, we use the fact that the 6 faces on the surface of the shell without a manifold attached would degenerate to the surface of a cube. What we are still missing is the radius of the outer shell boundary. Since we desire a cube of extent  [2.x.70]  and the 6-cell shell puts its 8 outer vertices at the 8 opposing diagonals, we must translate the points  [2.x.71]  into a radius: Clearly, the radius must be  [2.x.72]  in  [2.x.73]  dimensions, i.e.,  [2.x.74]  for the three-dimensional case we want to consider.   
*   Thus, we have a plan: After creating the inner triangulation for the ball and the one for the outer shell, we merge those two grids but remove all manifolds that the functions in GridGenerator may have set from the resulting triangulation, to ensure that we have full control over manifolds. In particular, we want additional points added on the boundary during refinement to follow a flat manifold description. To start the process of adding more appropriate manifold ids, we assign the manifold id 0 to all mesh entities (cells, faces, lines), which will later be associated with the TransfiniteInterpolationManifold. Then, we must identify the faces and lines that are along the sphere of radius 0.5 and mark them with a different manifold id, so as to then assign a SphericalManifold to those. We will choose the manifold id of 1. Since we have thrown away all manifolds that pre-existed after calling  [2.x.75]  we manually go through the cells of the mesh and all their faces. We have found a face on the sphere if all four vertices have a radius of 0.5, or, as we write in the program, have  [2.x.76] . Note that we call `cell->face(f)->set_all_manifold_ids(1)` to set the manifold id both on the faces and the surrounding lines. Furthermore, we want to distinguish the cells inside the ball and outside the ball by a material id for visualization, corresponding to the picture in the introduction.
* 

* 
* [1.x.64]
* 
*  With all cells, faces and lines marked appropriately, we can attach the Manifold objects to those numbers. The entities with manifold id 1 will get a spherical manifold, whereas the other entities, which have the manifold id 0, will be assigned the TransfiniteInterpolationManifold. As mentioned in the introduction, we must explicitly initialize the manifold with the current mesh using a call to  [2.x.77]  in order to pick up the coarse mesh cells and the manifolds attached to the boundaries of those cells. We also note that the manifold objects we create locally in this function are allowed to go out of scope (as they do at the end of the function scope), because the Triangulation object internally copies them.     
*   With all manifolds attached, we will finally go about and refine the mesh a few times to create a sufficiently large test case.
* 

* 
* [1.x.65]
* 
*   [1.x.66]  [1.x.67]   
*   The following function is well-known from other tutorials in that it enumerates the degrees of freedom, creates a constraint object and sets up a sparse matrix for the linear system. The only thing worth mentioning is the fact that the function receives a reference to a mapping object that we then pass to the  [2.x.78]  function to ensure that our boundary values are evaluated on the high-order mesh used for assembly. In the present example, it does not really matter because the outer surfaces are flat, but for curved outer cells this leads to more accurate approximation of the boundary values.
* 

* 
* [1.x.68]
* 
*   [1.x.69]  [1.x.70]   
*   The function that assembles the linear system is also well known from the previous tutorial programs. One thing to note is that we set the number of quadrature points to the polynomial degree plus two, not the degree plus one as in most other tutorials. This is because we expect some extra accuracy as the mapping also involves a degree one more than the polynomials for the solution.   
*   The only somewhat unusual code in the assembly is the way we compute the cell matrix. Rather than using three nested loop over the quadrature point index, the row, and the column of the matrix, we first collect the derivatives of the shape function, multiplied by the square root of the product of the coefficient and the integration factor `JxW` in a separate matrix `partial_matrix`. To compute the cell matrix, we then execute `cell_matrix = partial_matrix transpose(partial_matrix)` in the line `partial_matrix.mTmult(cell_matrix, partial_matrix);`. To understand why this works, we realize that the matrix-matrix multiplication performs a summation over the columns of `partial_matrix`. If we denote the coefficient by  [2.x.79] , the entries in the temporary matrix are  [2.x.80] . If we take the product of the [1.x.71]th row with the [1.x.72]th column of that matrix, we compute a nested sum involving  [2.x.81] , which is exactly the terms needed for the bilinear form of the Laplace equation.   
*   The reason for choosing this somewhat unusual scheme is due to the heavy work involved in computing the cell matrix for a relatively high polynomial degree in 3D. As we want to highlight the cost of the mapping in this tutorial program, we better do the assembly in an optimized way in order to not chase bottlenecks that have been solved by the community already. Matrix-matrix multiplication is one of the best optimized kernels in the HPC context, and the  [2.x.82]  function will call into those optimized BLAS functions. If the user has provided a good BLAS library when configuring deal.II (like OpenBLAS or Intel's MKL), the computation of the cell matrix will execute close to the processor's peak arithmetic performance. As a side note, we mention that despite an optimized matrix-matrix multiplication, the current strategy is sub-optimal in terms of complexity as the work to be done is proportional to  [2.x.83]  operations for degree  [2.x.84]  (this also applies to the usual evaluation with FEValues). One could compute the cell matrix with  [2.x.85]  operations by utilizing the tensor product structure of the shape functions, as is done by the matrix-free framework in deal.II. We refer to  [2.x.86]  and the documentation of the tensor-product-aware evaluators FEEvaluation for details on how an even more efficient cell matrix computation could be realized.
* 

* 
* [1.x.73]
* 
*   [1.x.74]  [1.x.75]   
*   For solving the linear system, we pick a simple Jacobi-preconditioned conjugate gradient solver, similar to the settings in the early tutorials.
* 

* 
* [1.x.76]
* 
*   [1.x.77]  [1.x.78]   
*   In the next function we do various post-processing steps with the solution, all of which involve the mapping in one way or the other.   
*   The first operation we do is to write the solution as well as the material ids to a VTU file. This is similar to what was done in many other tutorial programs. The new ingredient presented in this tutorial program is that we want to ensure that the data written to the file used for visualization is actually a faithful representation of what is used internally by deal.II. That is because most of the visualization data formats only represent cells by their vertex coordinates, but have no way of representing the curved boundaries that are used in deal.II when using higher order mappings
* 
*  -  in other words, what you see in the visualization tool is not actually what you are computing on. (The same, incidentally, is true when using higher order shape functions: Most visualization tools only render bilinear/trilinear representations. This is discussed in detail in  [2.x.87]    
*   So we need to ensure that a high-order representation is written to the file. We need to consider two particular topics. Firstly, we tell the DataOut object via the  [2.x.88]  that we intend to interpret the subdivisions of the elements as a high-order Lagrange polynomial rather than a collection of bilinear patches. Recent visualization programs, like ParaView version 5.5 or newer, can then render a high-order solution (see a [1.x.79] for more details). Secondly, we need to make sure that the mapping is passed to the  [2.x.89]  method. Finally, the DataOut class only prints curved faces for [1.x.80] cells by default, so we need to ensure that also inner cells are printed in a curved representation via the mapping.
* 

* 
* [1.x.81]
* 
*  The next operation in the postprocessing function is to compute the  [2.x.90]  and  [2.x.91]  errors against the analytical solution. As the analytical solution is a quadratic polynomial, we expect a very accurate result at this point. If we were solving on a simple mesh with planar faces and a coefficient whose jumps are aligned with the faces between cells, then we would expect the numerical result to coincide with the analytical solution up to roundoff accuracy. However, since we are using deformed cells following a sphere, which are only tracked by polynomials of degree 4 (one more than the degree for the finite elements), we will see that there is an error around  [2.x.92] . We could get more accuracy by increasing the polynomial degree or refining the mesh.
* 

* 
* [1.x.82]
* 
*  The final post-processing operation we do here is to compute an error estimate with the KellyErrorEstimator. We use the exact same settings as in the  [2.x.93]  tutorial program, except for the fact that we also hand in the mapping to ensure that errors are evaluated along the curved element, consistent with the remainder of the program. However, we do not really use the result here to drive a mesh adaptation step (that would refine the mesh around the material interface along the sphere), as the focus here is on the cost of this operation.
* 

* 
* [1.x.83]
* 
*   [1.x.84]  [1.x.85]   
*   Finally, we define the `run()` function that controls how we want to execute this program (which is called by the main() function in the usual way). We start by calling the `create_grid()` function that sets up our geometry with the appropriate manifolds. We then run two instances of a solver chain, starting from the setup of the equations, the assembly of the linear system, its solution with a simple iterative solver, and the postprocessing discussed above. The two instances differ in the way they use the mapping. The first uses a conventional MappingQGeneric mapping object which we initialize to a degree one more than we use for the finite element &ndash; after all, we expect the geometry representation to be the bottleneck as the analytic solution is only a quadratic polynomial. (In reality, things are interlinked to quite some extent because the evaluation of the polynomials in real coordinates involves the mapping of a higher-degree polynomials, which represent some smooth rational functions. As a consequence, higher-degree polynomials still pay off, so it does not make sense to increase the degree of the mapping further.) Once the first pass is completed, we let the timer print a summary of the compute times of the individual stages.
* 

* 
* [1.x.86]
* 
*  For the second instance, we instead set up the MappingQCache class. Its use is very simple: After constructing it (with the degree, given that we want it to show the correct degree functionality in other contexts), we fill the cache via the  [2.x.94]  function. At this stage, we specify which mapping we want to use (obviously, the same MappingQGeneric as previously in order to repeat the same computations) for the cache, and then run through the same functions again, now handing in the modified mapping. In the end, we again print the accumulated wall times since the reset to see how the times compare to the original setting.
* 

* 
* [1.x.87]
* 
* [1.x.88][1.x.89]
* 

* [1.x.90][1.x.91]
* 

* If we run the three-dimensional version of this program with polynomials ofdegree three, we get the following program output:
* [1.x.92]
* 
* Before discussing the timings, we look at the memory consumption for theMappingQCache object: Our program prints that it utilizes 23 MB ofmemory. If we relate this number to the memory consumption of a single(solution or right hand side) vector,which is 1.5 MB (namely, 181,609 elements times 8 bytes per entry indouble precision), or to the memory consumed by thesystem matrix and the sparsity pattern (which is 274 MB), we realize that it isnot an overly heavy data structure, given its benefits.
* With respect to the timers, we see a clear improvement in the overall run timeof the program by a factor of 2.7. If we disregard the iterative solver, whichis the same in both cases (and not optimal, given the simple preconditioner weuse, and the fact that sparse matrix-vector products waste operations forcubic polynomials), the advantage is a factor of almost 5. This is prettyimpressive for a linear stationary problem, and cost savings would indeed bemuch more prominent for time-dependent and nonlinear problems where assemblyis called several times. If we look into the individual components, we get aclearer picture of what is going on and why the cache is so efficient: In theMappingQGeneric case, essentially every operation that involves a mapping takeat least 5 seconds to run. The norm computation runs two [2.x.95]  functions, which each take almost 5seconds. (The computation of constraints is cheaper because it only evaluatesthe mapping in cells at the boundary for the interpolation of boundaryconditions.) If we compare these 5 seconds to the time it takes to fill theMappingQCache, which is 5.2 seconds (for all cells, not just the active ones),it becomes obvious that the computation of the mapping support pointsdominates over everything else in the MappingQGeneric case. Perhaps the moststriking result is the time for the error estimator, labeled "Compute errorestimator", where the MappingQGeneric implementation takes 17.3 seconds andthe MappingQCache variant less than 0.5 seconds. The reason why the former isso expensive (three times more expensive than the assembly, for instance) isthat the error estimation involves evaluation of quantities over faces, whereeach face in the mesh requests additional points of the mapping that in turngo through the very expensive TransfiniteInterpolationManifold class. As thereare six faces per cell, this happens much more often than in assembly. Again,MappingQCache nicely eliminates the repeated evaluation, aggregating all theexpensive steps involving the manifold in a single initialization call thatgets repeatedly used.
* 

* [1.x.93][1.x.94] [2.x.96] 
* [0.x.1]