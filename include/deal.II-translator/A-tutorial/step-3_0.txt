[0.x.0]*
 [2.x.0] 
* This tutorial depends on  [2.x.1] .
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18][1.x.19][1.x.20][1.x.21][1.x.22][1.x.23][1.x.24][1.x.25]
* [1.x.26][1.x.27][1.x.28]
* 

*  [2.x.2] 
* [1.x.29][1.x.30]
* 

* This is the first example where we actually use finite elements to computesomething. Wewill solve a simple version of Poisson's equation with zero boundaryvalues, but a nonzero right hand side:
* [1.x.31]
* We will solve this equation on the square,  [2.x.3] , for whichyou've already learned how to generate a mesh in  [2.x.4]  and  [2.x.5] . Inthis program, we will also only consider the particular case [2.x.6]  and come back to how to implement the more generalcase in the next tutorial program,  [2.x.7] .
* If you've learned about the basics of the finite element method, you willremember the steps we need to take to approximate the solution  [2.x.8]  by a finitedimensional approximation. Specifically, we first need to derive the weak formof the equation above, which we obtain by multiplying the equation by a testfunction  [2.x.9]  [1.x.32] (we will come back to the reason formultiplying from the left and not from the right below) and integrating overthe domain  [2.x.10] :
* [1.x.33]
* This can be integrated by parts:
* [1.x.34]
* The test function  [2.x.11]  has to satisfy the same kind of boundaryconditions (in mathematical terms: it needs to come from the tangent space ofthe set in which we seek the solution), so on the boundary  [2.x.12]  andconsequently the weak form we are looking for reads
* [1.x.35]
* where we have used the common notation  [2.x.13] . The problemthen asks for a function  [2.x.14]  for which this statement is true for all testfunctions  [2.x.15]  from the appropriate space (which here is the space [2.x.16] ).
* Of course we can't find such a function on a computer in the general case, andinstead we seek an approximation  [2.x.17] , where the  [2.x.18]  are unknown expansion coefficients we need to determine(the "degrees of freedom" of this problem), and  [2.x.19]  are thefinite element shape functions we will use. To define these shape functions,we need the following:
* 
*  - A mesh on which to define shape functions. You have already seen how to  generate and manipulate the objects that describe meshes in  [2.x.20]  and   [2.x.21] .
* 
*  - A finite element that describes the shape functions we want to use on the  reference cell (which in deal.II is always the unit interval  [2.x.22] , the  unit square  [2.x.23]  or the unit cube  [2.x.24] , depending on which space  dimension you work in). In  [2.x.25] , we had already used an object of type  FE_Q<2>, which denotes the usual Lagrange elements that define shape  functions by interpolation on support points. The simplest one is  FE_Q<2>(1), which uses polynomial degree 1. In 2d, these are often referred  to as [1.x.36], since they are linear in each of the two coordinates  of the reference cell. (In 1d, they would be [1.x.37] and in 3d  [1.x.38]; however, in the deal.II documentation, we will frequently  not make this distinction and simply always call these functions "linear".)
* 
*  - A DoFHandler object that enumerates all the degrees of freedom on the mesh,  taking the reference cell description the finite element object provides as  the basis. You've also already seen how to do this in  [2.x.26] .
* 
*  - A mapping that tells how the shape functions on the real cell are obtained  from the shape functions defined by the finite element class on the  reference cell. By default, unless you explicitly say otherwise, deal.II  will use a (bi-, tri-)linear mapping for this, so in most cases you don't  have to worry about this step.
* Through these steps, we now have a set of functions  [2.x.27] , and we candefine the weak form of the discrete problem: Find a function  [2.x.28] , i.e., findthe expansion coefficients  [2.x.29]  mentioned above, so that
* [1.x.39]
* Note that we here follow the convention that everything is counted starting atzero, as common in C and C++. This equation can be rewritten as a linearsystem if you insert the representation  [2.x.30]  and then observe that
* [1.x.40]
* With this, the problem reads: Find a vector  [2.x.31]  so that
* [1.x.41]
* where the matrix  [2.x.32]  and the right hand side  [2.x.33]  are defined as
* [1.x.42]
* 
* 

* [1.x.43][1.x.44]
* 

* Before we move on with describing how these quantities can be computed, notethat if we had multiplied the original equation from the [1.x.45] by atest function rather than from the left, then we would have obtained a linearsystem of the form
* [1.x.46]
* with a row vector  [2.x.34] . By transposing this system, this is of courseequivalent to solving
* [1.x.47]
* which here is the same as above since  [2.x.35] . But in general is not,and in order to avoidany sort of confusion, experience has shown that simply getting into the habitof multiplying the equation from the left rather than from the right (as isoften done in the mathematical literature) avoids a common class of errors asthe matrix is automatically correct and does not need to be transposed whencomparing theory and implementation. See  [2.x.36]  for the first example in thistutorial where we have a non-symmetric bilinear form for which it makes adifference whether we multiply from the right or from the left.
* 

* [1.x.48][1.x.49]
* 

* Now we know what we need (namely: objects that hold the matrix andvectors, as well as ways to compute  [2.x.37] ), and we can look at what ittakes to make that happen:
* 
*  - The object for  [2.x.38]  is of type SparseMatrix while those for  [2.x.39]  and  [2.x.40]  are of  type Vector. We will see in the program below what classes are used to solve  linear systems.
* 
*  - We need a way to form the integrals. In the finite element method, this is  most commonly done using quadrature, i.e. the integrals are replaced by a  weighted sum over a set of points on each cell. That is, we first split the  integral over  [2.x.41]  into integrals over all cells, 
* [1.x.50]
*   and then approximate each cell's contribution by quadrature: 
* [1.x.51]
*   where  [2.x.42]  is the  [2.x.43] th quadrature point on cell  [2.x.44] , and  [2.x.45]   the  [2.x.46] th quadrature weight. There are different parts to what is needed in  doing this, and we will discuss them in turn next.
* 
*  - First, we need a way to describe the location  [2.x.47]  of quadrature  points and their weights  [2.x.48] . They are usually mapped from the reference  cell in the same way as shape functions, i.e., implicitly using the  MappingQ1 class or, if you explicitly say so, through one of the other  classes derived from Mapping. The locations and weights on the reference  cell are described by objects derived from the Quadrature base  class. Typically, one chooses a quadrature formula (i.e. a set of points and  weights) so that the quadrature exactly equals the integral in the matrix;  this can be achieved because all factors in the integral are polynomial, and  is done by Gaussian quadrature formulas, implemented in the QGauss class.
* 
*  - We then need something that can help us evaluate  [2.x.49]   on cell  [2.x.50] . This is what the FEValues class does: it takes a finite element  objects to describe  [2.x.51]  on the reference cell, a quadrature object to  describe the quadrature points and weights, and a mapping object (or  implicitly takes the MappingQ1 class) and provides values and derivatives of  the shape functions on the real cell  [2.x.52]  as well as all sorts of other  information needed for integration, at the quadrature points located on  [2.x.53] .
* FEValues really is the central class in the assembly process. One way you canview it is as follows: The FiniteElement and derived classes describe shape[1.x.52], i.e., infinite dimensional objects: functions have values atevery point. We need this for theoretical reasons because we want to performour analysis with integrals over functions. However, for a computer, this is avery difficult concept, since they can in general only deal with a finiteamount of information, and so we replace integrals by sums over quadraturepoints that we obtain by mapping (the Mapping object) using  points defined ona reference cell (the Quadrature object) onto points on the real cell. Inessence, we reduce the problem to one where we only need a finite amount ofinformation, namely shape function values and derivatives, quadrature weights,normal vectors, etc, exclusively at a finite set of points. The FEValues classis the one that brings the three components together and provides this finiteset of information on a particular cell  [2.x.54] . You will see it in action when weassemble the linear system below.
* It is noteworthy that all of this could also be achieved if you simply createdthese three objects yourself in an application program, and juggled theinformation yourself. However, this would neither be simpler (the FEValuesclass provides exactly the kind of information you actually need) nor faster:the FEValues class is highly optimized to only compute on each cell theparticular information you need; if anything can be re-used from the previouscell, then it will do so, and there is a lot of code in that class to makesure things are cached wherever this is advantageous.
* The final piece of this introduction is to mention that after a linearsystem is obtained, it is solved using an iterative solver and thenpostprocessed: we create an output file using the DataOut class that can thenbe visualized using one of the common visualization programs.
*  [2.x.55]  The preceding overview of all the important steps of any finite elementimplementation has its counterpart in deal.II: The library can naturally begrouped into a number of "modules" that cover the basic concepts justoutlined. You can access these modules through the tab at the top of thispage. An overview of the most fundamental groups of concepts is also availableon the [1.x.53].
* 

* [1.x.54][1.x.55]
* 

* Although this is the simplest possible equation you can solve using the finiteelement method, this program shows the basic structure of most finiteelement programs and also serves as the template that almost all of thefollowing programs will essentially follow. Specifically, the main class ofthis program looks like this:
* [1.x.56]
* 
* This follows the object oriented programming mantra of [1.x.57], i.e. we do our best to hide almost all internal details ofthis class in private members that are not accessible to the outside.
* Let's start with the member variables: These follow the building blocks wehave outlined above in the bullet points, namely we need a Triangulation and aDoFHandler object, and a finite element object that describes the kinds ofshape functions we want to use. The second group of objects relate to thelinear algebra: the system matrix and right hand side as well as the solutionvector, and an object that describes the sparsity pattern of the matrix. Thisis all this class needs (and the essentials that any solver for a stationaryPDE requires) and that needs to survive throughout the entire program. Incontrast to this, the FEValues object we need for assembly is only requiredthroughout assembly, and so we create it as a local object in the functionthat does that and destroy it again at its end.
* Secondly, let's look at the member functions. These, as well, already form thecommon structure that almost all following tutorial programs will use: [2.x.56]    [2.x.57]   [2.x.58] : This is what one could call a       [1.x.58]. As its name suggests, it sets up the       object that stores the triangulation. In later examples, it could also       deal with boundary conditions, geometries, etc.   [2.x.59]   [2.x.60] : This then is the function in which all the       other data structures are set up that are needed to solve the       problem. In particular, it will initialize the DoFHandler object and       correctly size the various objects that have to do with the linear       algebra. This function is often separated from the preprocessing       function above because, in a time dependent program, it may be called       at least every few time steps whenever the mesh       is adaptively refined (something we will see how to do in  [2.x.61] ). On       the other hand, setting up the mesh itself in the preprocessing       function above is done only once at the beginning of the program and       is, therefore, separated into its own function.   [2.x.62]   [2.x.63] : This, then is where the contents of the       matrix and right hand side are computed, as discussed at length in the       introduction above. Since doing something with this linear system is       conceptually very different from computing its entries, we separate it       from the following function.   [2.x.64]   [2.x.65] : This then is the function in which we compute the       solution  [2.x.66]  of the linear system  [2.x.67] . In the current program, this       is a simple task since the matrix is so simple, but it will become a       significant part of a program's size whenever the problem is not so       trivial any more (see, for example,  [2.x.68] ,  [2.x.69] , or  [2.x.70]  once       you've learned a bit more about the library).   [2.x.71]   [2.x.72] : Finally, when you have computed a       solution, you probably want to do something with it. For example, you       may want to output it in a format that can be visualized, or you may       want to compute quantities you are interested in: say, heat fluxes in a       heat exchanger, air friction coefficients of a wing, maximum bridge       loads, or simply the value of the numerical solution at a point. This       function is therefore the place for postprocessing your solution. [2.x.73] All of this is held together by the single public function (other than theconstructor), namely the  [2.x.74]  function. It is the one that iscalled from the place where an object of this type is created, and it is theone that calls all the other functions in their proper order. Encapsulatingthis operation into the  [2.x.75]  function, rather than calling allthe other functions from  [2.x.76]  makes sure that youcan change how the separation of concerns within this class isimplemented. For example, if one of the functions becomes too big, you cansplit it up into two, and the only places you have to be concerned aboutchanging as a consequence are within this very same class, and not anywhereelse.
* As mentioned above, you will see this general structure &mdash; sometimes withvariants in spelling of the functions' names, but in essentially this order ofseparation of functionality &mdash; again in many of thefollowing tutorial programs.
* 

* [1.x.59][1.x.60]
* 

* deal.II defines a number of integral %types via alias in namespace  [2.x.77] (In the previous sentence, the word "integral" is used as the [1.x.61]that corresponds to the noun "integer". It shouldn't be confused with the[1.x.62] "integral" that represents the area or volume under a curveor surface. The adjective "integral" is widely used in the C++ world incontexts such as "integral type", "integral constant", etc.)In particular, in this program you will see  [2.x.78]  in a couple ofplaces: an integer type that is used to denote the [1.x.63] index of adegree of freedom, i.e., the index of a particular degree of freedom within theDoFHandler object that is defined on top of a triangulation (as opposed to theindex of a particular degree of freedom within a particular cell). For thecurrent program (as well as almost all of the tutorial programs), you will havea few thousand to maybe a few million unknowns globally (and, for  [2.x.79] elements, you will have 4 [1.x.64] in 2d and 8 in 3d).Consequently, a data type that allows to store sufficiently large numbers forglobal DoF indices is  [2.x.80]  given that it allows to storenumbers between 0 and slightly more than 4 billion (on most systems, whereintegers are 32-bit). In fact, this is what  [2.x.81]  is.
* So, why not just use  [2.x.82]  right away? deal.II used to dothis until version 7.3. However, deal.II supports very large computations (viathe framework discussed in  [2.x.83] ) that may have more than 4 billion unknownswhen spread across a few thousand processors. Consequently, there aresituations where  [2.x.84]  is not sufficiently large and weneed a 64-bit unsigned integral type. To make this possible, we introduced [2.x.85]  which by default is defined as simply <code>unsignedint</code> whereas it is possible to define it as <code>unsigned long longint</code> if necessary, by passing a particular flag during configuration(see the ReadMe file).
* This covers the technical aspect. But there is also a documentation purpose:everywhere in the library and codes that are built on it, if you see a placeusing the data type  [2.x.86]  you immediately know that thequantity that is being referenced is, in fact, a global dof index. No suchmeaning would be apparent if we had just used  [2.x.87]  (whichmay also be a local index, a boundary indicator, a material id,etc.). Immediately knowing what a variable refers to also helps avoid errors:it's quite clear that there must be a bug if you see an object of type [2.x.88]  being assigned to variable of type [2.x.89]  even though they are both represented by unsignedintegers and the compiler will, consequently, not complain.
* In more practical terms what the presence of this type means is that duringassembly, we create a  [2.x.90]  matrix (in 2d, using a  [2.x.91]  element) of thecontributions of the cell we are currently sitting on, and then we need to addthe elements of this matrix to the appropriate elements of the global (system)matrix. For this, we need to get at the global indices of the degrees offreedom that are local to the current cell, for which we will always use thefollowing piece of the code:
* [1.x.65]
* where  [2.x.92]  is declared as
* [1.x.66]
* The name of this variable might be a bit of a misnomer
* 
*  -  it stands for "theglobal indices of those degrees of freedom locally defined on the currentcell"
* 
*  -  but variables that hold this information are universally named thisway throughout the library.
*  [2.x.93]   [2.x.94]  is not the only type defined in this namespace.Rather, there is a whole family, including  [2.x.95]  [2.x.96]  and  [2.x.97]  All of these are alias for integerdata types but, as explained above, they are used throughout the library so that(i) the intent of a variable becomes more easily discerned, and (ii) so that itbecomes possible to change the actual type to a larger one if necessary withouthaving to go through the entire library and figure out whether a particular useof  [2.x.98]  corresponds to, say, a material indicator.
* 

*  [1.x.67] [1.x.68]
*   [1.x.69]  [1.x.70]
* 

* 
*  These include files are already known to you. They declare the classes which handle triangulations and enumeration of degrees of freedom:
* 

* 
* [1.x.71]
* 
*  And this is the file in which the functions are declared that create grids:
* 

* 
* [1.x.72]
* 
*  This file contains the description of the Lagrange interpolation finite element:
* 

* 
* [1.x.73]
* 
*  And this file is needed for the creation of sparsity patterns of sparse matrices, as shown in previous examples:
* 

* 
* [1.x.74]
* 
*  The next two files are needed for assembling the matrix using quadrature on each cell. The classes declared in them will be explained below:
* 

* 
* [1.x.75]
* 
*  The following three include files we need for the treatment of boundary values:
* 

* 
* [1.x.76]
* 
*  We're now almost to the end. The second to last group of include files is for the linear algebra which we employ to solve the system of equations arising from the finite element discretization of the Laplace equation. We will use vectors and full matrices for assembling the system of equations locally on each cell, and transfer the results into a sparse matrix. We will then use a Conjugate Gradient solver to solve the problem, for which we need a preconditioner (in this program, we use the identity preconditioner which does nothing, but we need to include the file anyway):
* 

* 
* [1.x.77]
* 
*  Finally, this is for output to a file and to the console:
* 

* 
* [1.x.78]
* 
*  ...and this is to import the deal.II namespace into the global scope:
* 

* 
* [1.x.79]
* 
*   [1.x.80]  [1.x.81]
* 

* 
*  Instead of the procedural programming of previous examples, we encapsulate everything into a class for this program. The class consists of functions which each perform certain aspects of a finite element program, a `main` function which controls what is done first and what is done next, and a list of member variables.
* 

* 
*  The public part of the class is rather short: it has a constructor and a function `run` that is called from the outside and acts as something like the `main` function: it coordinates which operations of this class shall be run in which order. Everything else in the class, i.e. all the functions that actually do anything, are in the private section of the class:
* 

* 
* [1.x.82]
* 
*  Then there are the member functions that mostly do what their names suggest and whose have been discussed in the introduction already. Since they do not need to be called from outside, they are made private to this class.
* 

* 
*  

* 
* [1.x.83]
* 
*  And finally we have some member variables. There are variables describing the triangulation and the global numbering of the degrees of freedom (we will specify the exact polynomial degree of the finite element in the constructor of this class)...
* 

* 
* [1.x.84]
* 
*  ...variables for the sparsity pattern and values of the system matrix resulting from the discretization of the Laplace equation...
* 

* 
* [1.x.85]
* 
*  ...and variables which will hold the right hand side and solution vectors.
* 

* 
* [1.x.86]
* 
*   [1.x.87]  [1.x.88]
* 

* 
*  Here comes the constructor. It does not much more than first to specify that we want bi-linear elements (denoted by the parameter to the finite element object, which indicates the polynomial degree), and to associate the dof_handler variable to the triangulation we use. (Note that the triangulation isn't set up with a mesh at all at the present time, but the DoFHandler doesn't care: it only wants to know which triangulation it will be associated with, and it only starts to care about an actual mesh once you try to distribute degree of freedom on the mesh using the distribute_dofs() function.) All the other member variables of the Step3 class have a default constructor which does all we want.
* 

* 
* [1.x.89]
* 
*   [1.x.90]  [1.x.91]
* 

* 
*  Now, the first thing we've got to do is to generate the triangulation on which we would like to do our computation and number each vertex with a degree of freedom. We have seen these two steps in  [2.x.99]  and  [2.x.100]  before, respectively.
* 

* 
*  This function does the first part, creating the mesh.  We create the grid and refine all cells five times. Since the initial grid (which is the square  [2.x.101] ) consists of only one cell, the final grid has 32 times 32 cells, for a total of 1024.
* 

* 
*  Unsure that 1024 is the correct number? We can check that by outputting the number of cells using the  [2.x.102]  function on the triangulation.
* 

* 
* [1.x.92]
* 
* 

* 
*  [2.x.103]  We call the  [2.x.104]  function, rather than  [2.x.105]  Here, [1.x.93] means the cells that aren't refined any further. We stress the adjective "active" since there are more cells, namely the parent cells of the finest cells, their parents, etc, up to the one cell which made up the initial grid. Of course, on the next coarser level, the number of cells is one quarter that of the cells on the finest level, i.e. 256, then 64, 16, 4, and 1. If you called  [2.x.106]  instead in the code above, you would consequently get a value of 1365 instead. On the other hand, the number of cells (as opposed to the number of active cells) is not typically of much interest, so there is no good reason to print it.
* 

* 
*  
*  
*  [1.x.94]  [1.x.95]
* 

* 
*  Next we enumerate all the degrees of freedom and set up matrix and vector objects to hold the system data. Enumerating is done by using  [2.x.107]  as we have seen in the  [2.x.108]  example. Since we use the FE_Q class and have set the polynomial degree to 1 in the constructor, i.e. bilinear elements, this associates one degree of freedom with each vertex. While we're at generating output, let us also take a look at how many degrees of freedom are generated:
* 

* 
* [1.x.96]
* 
*  There should be one DoF for each vertex. Since we have a 32 times 32 grid, the number of DoFs should be 33 times 33, or 1089.
* 

* 
*  As we have seen in the previous example, we set up a sparsity pattern by first creating a temporary structure, tagging those entries that might be nonzero, and then copying the data over to the SparsityPattern object that can then be used by the system matrix.
* 

* 
* [1.x.97]
* 
*  Note that the SparsityPattern object does not hold the values of the matrix, it only stores the places where entries are. The entries themselves are stored in objects of type SparseMatrix, of which our variable system_matrix is one.   
*   The distinction between sparsity pattern and matrix was made to allow several matrices to use the same sparsity pattern. This may not seem relevant here, but when you consider the size which matrices can have, and that it may take some time to build the sparsity pattern, this becomes important in large-scale problems if you have to store several matrices in your program.
* 

* 
* [1.x.98]
* 
*  The last thing to do in this function is to set the sizes of the right hand side vector and the solution vector to the right values:
* 

* 
* [1.x.99]
* 
*   [1.x.100]  [1.x.101]
* 

* 
*  
*   The next step is to compute the entries of the matrix and right hand side that form the linear system from which we compute the solution. This is the central function of each finite element program and we have discussed the primary steps in the introduction already.
* 

* 
*  The general approach to assemble matrices and vectors is to loop over all cells, and on each cell compute the contribution of that cell to the global matrix and right hand side by quadrature. The point to realize now is that we need the values of the shape functions at the locations of quadrature points on the real cell. However, both the finite element shape functions as well as the quadrature points are only defined on the reference cell. They are therefore of little help to us, and we will in fact hardly ever query information about finite element shape functions or quadrature points from these objects directly.
* 

* 
*  Rather, what is required is a way to map this data from the reference cell to the real cell. Classes that can do that are derived from the Mapping class, though one again often does not have to deal with them directly: many functions in the library can take a mapping object as argument, but when it is omitted they simply resort to the standard bilinear Q1 mapping. We will go this route, and not bother with it for the moment (we come back to this in  [2.x.109] ,  [2.x.110] , and  [2.x.111] ).
* 

* 
*  So what we now have is a collection of three classes to deal with: finite element, quadrature, and mapping objects. That's too much, so there is one type of class that orchestrates information exchange between these three: the FEValues class. If given one instance of each three of these objects (or two, and an implicit linear mapping), it will be able to provide you with information about values and gradients of shape functions at quadrature points on a real cell.
* 

* 
*  Using all this, we will assemble the linear system for this problem in the following function:
* 

* 
* [1.x.102]
* 
*  Ok, let's start: we need a quadrature formula for the evaluation of the integrals on each cell. Let's take a Gauss formula with two quadrature points in each direction, i.e. a total of four points since we are in 2D. This quadrature formula integrates polynomials of degrees up to three exactly (in 1D). It is easy to check that this is sufficient for the present problem:
* 

* 
* [1.x.103]
* 
*  And we initialize the object which we have briefly talked about above. It needs to be told which finite element we want to use, and the quadrature points and their weights (jointly described by a Quadrature object). As mentioned, we use the implied Q1 mapping, rather than specifying one ourselves explicitly. Finally, we have to tell it what we want it to compute on each cell: we need the values of the shape functions at the quadrature points (for the right hand side  [2.x.112] ), their gradients (for the matrix entries  [2.x.113] ), and also the weights of the quadrature points and the determinants of the Jacobian transformations from the reference cell to the real cells.   
*   This list of what kind of information we actually need is given as a collection of flags as the third argument to the constructor of FEValues. Since these values have to be recomputed, or updated, every time we go to a new cell, all of these flags start with the prefix  [2.x.114]  and then indicate what it actually is that we want updated. The flag to give if we want the values of the shape functions computed is #update_values; for the gradients it is #update_gradients. The determinants of the Jacobians and the quadrature weights are always used together, so only the products (Jacobians times weights, or short  [2.x.115] ) are computed; since we need them, we have to list #update_JxW_values as well:
* 

* 
* [1.x.104]
* 
*  The advantage of this approach is that we can specify what kind of information we actually need on each cell. It is easily understandable that this approach can significantly speed up finite element computations, compared to approaches where everything, including second derivatives, normal vectors to cells, etc are computed on each cell, regardless of whether they are needed or not.   
*  

* 
*  [2.x.116]  The syntax <code>update_values | update_gradients | update_JxW_values</code> is not immediately obvious to anyone not used to programming bit operations in C for years already. First,  [2.x.117]  is the [1.x.105], i.e., it takes two integer arguments that are interpreted as bit patterns and returns an integer in which every bit is set for which the corresponding bit is set in at least one of the two arguments. For example, consider the operation  [2.x.118]  (where the prefix  [2.x.119]  indicates that the number is to be interpreted as a binary number) and  [2.x.120] . Going through each bit and seeing whether it is set in one of the argument, we arrive at  [2.x.121]  or, in decimal notation,  [2.x.122] . The second piece of information you need to know is that the various  [2.x.123]  flags are all integers that have [1.x.106]. For example, assume that  [2.x.124] ,  [2.x.125] ,  [2.x.126] . Then <code>update_values | update_gradients | update_JxW_values = 0b10011 = 19</code>. In other words, we obtain a number that [1.x.107], where each operation corresponds to exactly one bit in the integer that, if equal to one, means that a particular piece should be updated on each cell and, if it is zero, means that we need not compute it. In other words, even though  [2.x.127]  is the [1.x.108], what it really represents is [1.x.109]. Such binary masks are quite common in C programming, but maybe not so in higher level languages like C++, but serve the current purpose quite well.
* 

* 
*  For use further down below, we define a shortcut for a value that will be used very frequently. Namely, an abbreviation for the number of degrees of freedom on each cell (since we are in 2D and degrees of freedom are associated with vertices only, this number is four, but we rather want to write the definition of this variable in a way that does not preclude us from later choosing a different finite element that has a different number of degrees of freedom per cell, or work in a different space dimension).   
*   In general, it is a good idea to use a symbolic name instead of hard-coding these numbers even if you know them, since for example, you may want to change the finite element at some time. Changing the element would have to be done in a different function and it is easy to forget to make a corresponding change in another part of the program. It is better to not rely on your own calculations, but instead ask the right object for the information: Here, we ask the finite element to tell us about the number of degrees of freedom per cell and we will get the correct number regardless of the space dimension or polynomial degree we may have chosen elsewhere in the program.   
*   The shortcut here, defined primarily to discuss the basic concept and not because it saves a lot of typing, will then make the following loops a bit more readable. You will see such shortcuts in many places in larger programs, and `dofs_per_cell` is one that is more or less the conventional name for this kind of object.
* 

* 
* [1.x.110]
* 
*  Now, we said that we wanted to assemble the global matrix and vector cell-by-cell. We could write the results directly into the global matrix, but this is not very efficient since access to the elements of a sparse matrix is slow. Rather, we first compute the contribution of each cell in a small matrix with the degrees of freedom on the present cell, and only transfer them to the global matrix when the computations are finished for this cell. We do the same for the right hand side vector. So let's first allocate these objects (these being local objects, all degrees of freedom are coupling with all others, and we should use a full matrix object rather than a sparse one for the local operations; everything will be transferred to a global sparse matrix later on):
* 

* 
* [1.x.111]
* 
*  When assembling the contributions of each cell, we do this with the local numbering of the degrees of freedom (i.e. the number running from zero through dofs_per_cell-1). However, when we transfer the result into the global matrix, we have to know the global numbers of the degrees of freedom. When we query them, we need a scratch (temporary) array for these numbers (see the discussion at the end of the introduction for the type,  [2.x.128]  used here):
* 

* 
* [1.x.112]
* 
*  Now for the loop over all cells. We have seen before how this works for a triangulation. A DoFHandler has cell iterators that are exactly analogous to those of a Triangulation, but with extra information about the degrees of freedom for the finite element you're using. Looping over the active cells of a degree-of-freedom handler works the same as for a triangulation.   
*   Note that we declare the type of the cell as `const auto &` instead of `auto` this time around. In step 1, we were modifying the cells of the triangulation by flagging them with refinement indicators. Here we're only examining the cells without modifying them, so it's good practice to declare `cell` as `const` in order to enforce this invariant.
* 

* 
* [1.x.113]
* 
*  We are now sitting on one cell, and we would like the values and gradients of the shape functions be computed, as well as the determinants of the Jacobian matrices of the mapping between reference cell and true cell, at the quadrature points. Since all these values depend on the geometry of the cell, we have to have the FEValues object re-compute them on each cell:
* 

* 
* [1.x.114]
* 
*  Next, reset the local cell's contributions to global matrix and global right hand side to zero, before we fill them:
* 

* 
* [1.x.115]
* 
*  Now it is time to start integration over the cell, which we do by looping over all quadrature points, which we will number by q_index.
* 

* 
* [1.x.116]
* 
*  First assemble the matrix: For the Laplace problem, the matrix on each cell is the integral over the gradients of shape function i and j. Since we do not integrate, but rather use quadrature, this is the sum over all quadrature points of the integrands times the determinant of the Jacobian matrix at the quadrature point times the weight of this quadrature point. You can get the gradient of shape function  [2.x.129]  at quadrature point with number q_index by using  [2.x.130] ; this gradient is a 2-dimensional vector (in fact it is of type Tensor [2.x.131]  with here dim=2) and the product of two such vectors is the scalar product, i.e. the product of the two shape_grad function calls is the dot product. This is in turn multiplied by the Jacobian determinant and the quadrature point weight (that one gets together by the call to  [2.x.132]  ). Finally, this is repeated for all shape functions  [2.x.133]  and  [2.x.134] :
* 

* 
* [1.x.117]
* 
*  We then do the same thing for the right hand side. Here, the integral is over the shape function i times the right hand side function, which we choose to be the function with constant value one (more interesting examples will be considered in the following programs).
* 

* 
* [1.x.118]
* 
*  Now that we have the contribution of this cell, we have to transfer it to the global matrix and right hand side. To this end, we first have to find out which global numbers the degrees of freedom on this cell have. Let's simply ask the cell for that information:
* 

* 
* [1.x.119]
* 
*  Then again loop over all shape functions i and j and transfer the local elements to the global matrix. The global numbers can be obtained using local_dof_indices[i]:
* 

* 
* [1.x.120]
* 
*  And again, we do the same thing for the right hand side vector.
* 

* 
* [1.x.121]
* 
*  Now almost everything is set up for the solution of the discrete system. However, we have not yet taken care of boundary values (in fact, Laplace's equation without Dirichlet boundary values is not even uniquely solvable, since you can add an arbitrary constant to the discrete solution). We therefore have to do something about the situation.   
*   For this, we first obtain a list of the degrees of freedom on the boundary and the value the shape function shall have there. For simplicity, we only interpolate the boundary value function, rather than projecting it onto the boundary. There is a function in the library which does exactly this:  [2.x.135]  Its parameters are (omitting parameters for which default values exist and that we don't care about): the DoFHandler object to get the global numbers of the degrees of freedom on the boundary; the component of the boundary where the boundary values shall be interpolated; the boundary value function itself; and the output object.   
*   The component of the boundary is meant as follows: in many cases, you may want to impose certain boundary values only on parts of the boundary. For example, you may have inflow and outflow boundaries in fluid dynamics, or clamped and free parts of bodies in deformation computations of bodies. Then you will want to denote these different parts of the boundary by indicators, and tell the interpolate_boundary_values function to only compute the boundary values on a certain part of the boundary (e.g. the clamped part, or the inflow boundary). By default, all boundaries have a 0 boundary indicator, unless otherwise specified. If sections of the boundary have different boundary conditions, you have to number those parts with different boundary indicators. The function call below will then only determine boundary values for those parts of the boundary for which the boundary indicator is in fact the zero specified as the second argument.   
*   The function describing the boundary values is an object of type Function or of a derived class. One of the derived classes is  [2.x.136]  which describes (not unexpectedly) a function which is zero everywhere. We create such an object in-place and pass it to the  [2.x.137]  function.   
*   Finally, the output object is a list of pairs of global degree of freedom numbers (i.e. the number of the degrees of freedom on the boundary) and their boundary values (which are zero here for all entries). This mapping of DoF numbers to boundary values is done by the  [2.x.138]  class.
* 

* 
* [1.x.122]
* 
*  Now that we got the list of boundary DoFs and their respective boundary values, let's use them to modify the system of equations accordingly. This is done by the following function call:
* 

* 
* [1.x.123]
* 
*   [1.x.124]  [1.x.125]
* 

* 
*  The following function simply solves the discretized equation. As the system is quite a large one for direct solvers such as Gauss elimination or LU decomposition, we use a Conjugate Gradient algorithm. You should remember that the number of variables here (only 1089) is a very small number for finite element computations, where 100.000 is a more usual number.  For this number of variables, direct methods are no longer usable and you are forced to use methods like CG.
* 

* 
* [1.x.126]
* 
*  First, we need to have an object that knows how to tell the CG algorithm when to stop. This is done by using a SolverControl object, and as stopping criterion we say: stop after a maximum of 1000 iterations (which is far more than is needed for 1089 variables; see the results section to find out how many were really used), and stop if the norm of the residual is below  [2.x.139] . In practice, the latter criterion will be the one which stops the iteration:
* 

* 
* [1.x.127]
* 
*  Then we need the solver itself. The template parameter to the SolverCG class is the type of the vectors, and leaving the empty angle brackets would indicate that we are taking the default argument (which is  [2.x.140] ). However, we explicitly mention the template argument:
* 

* 
* [1.x.128]
* 
*  Now solve the system of equations. The CG solver takes a preconditioner as its fourth argument. We don't feel ready to delve into this yet, so we tell it to use the identity operation as preconditioner:
* 

* 
* [1.x.129]
* 
*  Now that the solver has done its job, the solution variable contains the nodal values of the solution function.
* 

* 
* [1.x.130]
* 
*   [1.x.131]  [1.x.132]
* 

* 
*  The last part of a typical finite element program is to output the results and maybe do some postprocessing (for example compute the maximal stress values at the boundary, or the average flux across the outflow, etc). We have no such postprocessing here, but we would like to write the solution to a file.
* 

* 
* [1.x.133]
* 
*  To write the output to a file, we need an object which knows about output formats and the like. This is the DataOut class, and we need an object of that type:
* 

* 
* [1.x.134]
* 
*  Now we have to tell it where to take the values from which it shall write. We tell it which DoFHandler object to use, and the solution vector (and the name by which the solution variable shall appear in the output file). If we had more than one vector which we would like to look at in the output (for example right hand sides, errors per cell, etc) we would add them as well:
* 

* 
* [1.x.135]
* 
*  After the DataOut object knows which data it is to work on, we have to tell it to process them into something the back ends can handle. The reason is that we have separated the frontend (which knows about how to treat DoFHandler objects and data vectors) from the back end (which knows many different output formats) and use an intermediate data format to transfer data from the front- to the backend. The data is transformed into this intermediate format by the following function:
* 

* 
* [1.x.136]
* 
*  Now we have everything in place for the actual output. Just open a file and write the data into it, using VTK format (there are many other functions in the DataOut class we are using here that can write the data in postscript, AVS, GMV, Gnuplot, or some other file formats):
* 

* 
* [1.x.137]
* 
*   [1.x.138]  [1.x.139]
* 

* 
*  Finally, the last function of this class is the main function which calls all the other functions of the  [2.x.141]  class. The order in which this is done resembles the order in which most finite element programs work. Since the names are mostly self-explanatory, there is not much to comment about:
* 

* 
* [1.x.140]
* 
*   [1.x.141]  [1.x.142]
* 

* 
*  This is the main function of the program. Since the concept of a main function is mostly a remnant from the pre-object oriented era before C++ programming, it often does not do much more than creating an object of the top-level class and calling its principle function.
* 

* 
*  Finally, the first line of the function is used to enable output of some diagnostics that deal.II can generate.  The  [2.x.142]  variable (which stands for deal-log, not de-allog) represents a stream to which some parts of the library write output. For example, iterative solvers will generate diagnostics (starting residual, number of solver steps, final residual) as can be seen when running this tutorial program.
* 

* 
*  The output of  [2.x.143]  can be written to the console, to a file, or both. Both are disabled by default since over the years we have learned that a program should only generate output when a user explicitly asks for it. But this can be changed, and to explain how this can be done, we need to explain how  [2.x.144]  works: When individual parts of the library want to log output, they open a "context" or "section" into which this output will be placed. At the end of the part that wants to write output, one exits this section again. Since a function may call another one from within the scope where this output section is open, output may in fact be nested hierarchically into these sections. The LogStream class of which  [2.x.145]  is a variable calls each of these sections a "prefix" because all output is printed with this prefix at the left end of the line, with prefixes separated by colons. There is always a default prefix called "DEAL" (a hint at deal.II's history as the successor of a previous library called "DEAL" and from which the LogStream class is one of the few pieces of code that were taken into deal.II).
* 

* 
*  By default,  [2.x.146]  only outputs lines with zero prefixes
* 
*  -  i.e., all output is disabled because the default "DEAL" prefix is always there. But one can set a different maximal number of prefixes for lines that should be output to something larger, and indeed here we set it to two by calling  [2.x.147]  This means that for all screen output, a context that has pushed one additional prefix beyond the default "DEAL" is allowed to print its output to the screen ("console"), whereas all further nested sections that would have three or more prefixes active would write to  [2.x.148]  but  [2.x.149]  does not forward this output to the screen. Thus, running this example (or looking at the "Results" section), you will see the solver statistics prefixed with "DEAL:CG", which is two prefixes. This is sufficient for the context of the current program, but you will see examples later on (e.g., in  [2.x.150] ) where solvers are nested more deeply and where you may get useful information by setting the depth even higher.
* 

* 
* [1.x.143]
* [1.x.144][1.x.145]
* 

* The output of the program looks as follows:
* [1.x.146]
* 
* The first two lines is what we wrote to  [2.x.151] . The lasttwo lines were generated without our intervention by the CGsolver. The first two lines state the residual at the start of theiteration, while the last line tells us that the solver needed 47iterations to bring the norm of the residual to 5.3e-13, i.e. belowthe threshold 1e-12 which we have set in the `solve' function. We willshow in the next program how to suppress this output, which issometimes useful for debugging purposes, but often clutters up thescreen display.
* Apart from the output shown above, the program generated the file [2.x.152] , which is in the VTK format that is widelyused by many visualization programs today
* 
*  -  including the twoheavy-weights [1.x.147] and[1.x.148] that are the mostcommonly used programs for this purpose today.
* Using VisIt, it is not very difficult to generate a picture of thesolution like this: [2.x.153] It shows both the solution and the mesh, elevated above the  [2.x.154] - [2.x.155]  planebased on the value of the solution at each point. Of course the solutionhere is not particularly exciting, but that is a result of both what theLaplace equation represents and the right hand side  [2.x.156]  wehave chosen for this program: The Laplace equation describes (among manyother uses) the vertical deformation of a membrane subject to an external(also vertical) force. In the current example, the membrane's bordersare clamped to a square frame with no vertical variation; a constantforce density will therefore intuitively lead to a membrane thatsimply bulges upward
* 
*  -  like the one shown above.
* VisIt and Paraview both allow playing with various kinds of visualizationsof the solution. Several video lectures show how to use these programs. [2.x.157] 
* 

* 
* [1.x.149][1.x.150][1.x.151]
* 

* If you want to play around a little bit with this program, here are a fewsuggestions: [2.x.158] 
*  [2.x.159]    [2.x.160]   Change the geometry and mesh: In the program, we have generated a square  domain and mesh by using the  [2.x.161]   function. However, the  [2.x.162]  has a good number of other  functions as well. Try an L-shaped domain, a ring, or other domains you find  there.   [2.x.163] 
*    [2.x.164]   Change the boundary condition: The code uses the  [2.x.165]   function to generate zero boundary conditions. However, you may want to try  non-zero constant boundary values using   [2.x.166]  instead of   [2.x.167]  to have unit Dirichlet boundary  values. More exotic functions are described in the documentation of the  Functions namespace, and you may pick one to describe your particular boundary  values.   [2.x.168] 
*    [2.x.169]  Modify the type of boundary condition: Presently, what happens  is that we use Dirichlet boundary values all around, since the  default is that all boundary parts have boundary indicator zero, and  then we tell the   [2.x.170]  function to  interpolate boundary values to zero on all boundary components with  indicator zero.   [2.x.171]  We can change this behavior if we assign parts  of the boundary different indicators. For example, try this  immediately after calling  [2.x.172]  
* [1.x.152]
* 
*   What this does is it first asks the triangulation to  return an iterator that points to the first active cell. Of course,  this being the coarse mesh for the triangulation of a square, the  triangulation has only a single cell at this moment, and it is  active. Next, we ask the cell to return an iterator to its first  face, and then we ask the face to reset the boundary indicator of  that face to 1. What then follows is this: When the mesh is refined,  faces of child cells inherit the boundary indicator of their  parents, i.e. even on the finest mesh, the faces on one side of the  square have boundary indicator 1. Later, when we get to  interpolating boundary conditions, the   [2.x.173]  call will only produce boundary  values for those faces that have zero boundary indicator, and leave  those faces alone that have a different boundary indicator. What  this then does is to impose Dirichlet boundary conditions on the  former, and homogeneous Neumann conditions on the latter (i.e. zero  normal derivative of the solution, unless one adds additional terms  to the right hand side of the variational equality that deal with  potentially non-zero Neumann conditions). You will see this if you  run the program.
*   An alternative way to change the boundary indicator is to label  the boundaries based on the Cartesian coordinates of the face centers.  For example, we can label all of the cells along the top and  bottom boundaries with a boundary indicator 1 by checking to  see if the cell centers' y-coordinates are within a tolerance  (here 1e-12) of
* 
*  -  and 1. Try this immediately after calling   [2.x.174]  as before: 
* [1.x.153]
*   Although this code is a bit longer than before, it is useful for  complex geometries, as it does not require knowledge of face labels.
*    [2.x.175]   A slight variation of the last point would be to set different boundary  values as above, but then use a different boundary value function for  boundary indicator one. In practice, what you have to do is to add a second  call to  [2.x.176]  for boundary indicator one: 
* [1.x.154]
*   If you have this call immediately after the first one to this function, then  it will interpolate boundary values on faces with boundary indicator 1 to the  unit value, and merge these interpolated values with those previously  computed for boundary indicator 0. The result will be that we will get  discontinuous boundary values, zero on three sides of the square, and one on  the fourth.
*    [2.x.177]   Observe convergence: We will only discuss computing errors in norms in   [2.x.178] , but it is easy to check that computations converge  already here. For example, we could evaluate the value of the solution in a  single point and compare the value for different %numbers of global  refinement (the number of global refinement steps is set in   [2.x.179]  above). To evaluate the  solution at a point, say at  [2.x.180] , we could add the  following code to the  [2.x.181]  function: 
* [1.x.155]
*   For 1 through 9 global refinement steps, we then get the following sequence  of point values:   [2.x.182]   By noticing that the difference between each two consecutive values reduces  by about a factor of 4, we can conjecture that the "correct" value may be   [2.x.183] . In fact, if we assumed this to be  the correct value, we could show that the sequence above indeed shows  [2.x.184]  convergence &mdash; theoretically, the convergence order should be   [2.x.185]  but the symmetry of the domain and the mesh may lead  to the better convergence order observed.
*   A slight variant of this would be to repeat the test with quadratic  elements. All you need to do is to set the polynomial degree of the finite  element to two in the constructor   [2.x.186] .
*    [2.x.187] Convergence of the mean: A different way to see that the solution  actually converges (to something &mdash; we can't tell whether it's really  the correct value!) is to compute the mean of the solution. To this end, add  the following code to  [2.x.188] : 
* [1.x.156]
*   The documentation of the function explains what the second and fourth  parameters mean, while the first and third should be obvious. Doing the same  study again where we change the number of global refinement steps, we get  the following result:   [2.x.189]   Again, the difference between two adjacent values goes down by about a  factor of four, indicating convergence as  [2.x.190] . [2.x.191] 
* 

* 
* [1.x.157][1.x.158]
* 

* %HDF5 is a commonly used format that can be read by many scriptinglanguages (e.g. R or Python). It is not difficult to get deal.II toproduce some %HDF5 files that can then be used in external scripts topostprocess some of the data generated by this program. Here are someideas on what is possible.
* 

* [1.x.159][1.x.160]
* 

* To fully make use of the automation we first need to introduce a private variable for the number ofglobal refinement steps  [2.x.192] , which will be used for the output filename.In  [2.x.193]  with
* [1.x.161]
* The deal.II library has two different %HDF5 bindings, one in the HDF5namespace (for interfacing to general-purpose data files)and another one in DataOut (specifically for writing files for thevisualization of solutions).Although the HDF5 deal.II binding supports both serial and MPI, the %HDF5 DataOut bindingonly supports parallel output.For this reason we need to initialize an MPIcommunicator with only one processor. This is done by adding the following code.
* [1.x.162]
* Next we change the  [2.x.194]  output routine asdescribed in the DataOutBase namespace documentation:
* [1.x.163]
* The resulting file can then be visualized just like the VTK file thatthe original version of the tutorial produces; but, since %HDF5 is amore general file format, it can also easily be processed in scriptinglanguages for other purposes.
* 

* [1.x.164][1.x.165]
* 

* After outputting the solution, the file can be opened again to includemore datasets.  This allows us to keep all the necessary informationof our experiment in a single result file, which can then be read andprocessed by some postprocessing script.(Have a look at  [2.x.195]  for furtherinformation on the possible output options.)
* To make this happen, we first include the necessary header into our file:
* [1.x.166]
* Adding the following lines to the endof our output routine adds the information about the value of thesolution at a particular point, as well as the mean value of thesolution, to our %HDF5 file:
* [1.x.167]
* 
* 

* 
* [1.x.168][1.x.169]
* 

* The data put into %HDF5 files above can then be used from scriptinglanguages for further postprocessing. In the following, let us showhow this can, in particular, be done with the[1.x.170], a widely used language in statistical dataanalysis. (Similar things can also be done in Python, for example.)If you are unfamiliar with R and ggplot2 you could check out the data carpentry course on R[1.x.171].Furthermore, since most search engines struggle with searches of the form "R + topic",we recommend using the specializes service [1.x.172] instead.
* The most prominent difference between R and other languages is thatthe assignment operator (`a = 5`) is typically written as`a <- 5`. As the latter is considered standard we will use it in our examples as well.To open the `.h5` file in R you have to install the [1.x.173] package, which is a part of the Bioconductor package.
* First we will include all necessary packages and have a look at how the data is structured in our file.
* [1.x.174]
* This gives the following output
* [1.x.175]
* The datasets can be accessed by  [2.x.196] . The function [2.x.197]  gives us the dimensions of the matrixthat is used to store our cells.We can see the following three matrices, as well as the twoadditional data points we added. [2.x.198]  [2.x.199]   [2.x.200] : a 4x1024 matrix that stores the  (C++) vertex indices for each cell [2.x.201]   [2.x.202] : a 2x1089 matrix storing the position values (x,y) for our cell vertices [2.x.203]   [2.x.204] : a 1x1089 matrix storing the values of our solution at each vertex [2.x.205] Now we can use this data to generate various plots. Plotting with ggplot2 usually splits into two steps.At first the data needs to be manipulated and added to a  [2.x.206] .After that, a  [2.x.207]  object is constructed and manipulated by adding plot elements to it.
*  [2.x.208]  contain all the information we need to plot our grid.The following code wraps all the data into one dataframe for plotting our grid:
* [1.x.176]
* 
* With the finished dataframe we have everything we need to plot our grid:
* [1.x.177]
* 
* The contents of this file then look as follows (not very exciting, butyou get the idea): [2.x.209] 
* We can also visualize the solution itself, and this is going to lookmore interesting.To make a 2D pseudocolor plot of our solution we will use  [2.x.210] .This function needs a structured grid, i.e. uniform in x and y directions.Luckily our data at this point is structured in the right way.The following code plots a pseudocolor representation of our surface into a new PDF:
* [1.x.178]
* This is now going to look as follows: [2.x.211] 
* For plotting the converge curves we need to re-run the C++ code multiple times with different values for  [2.x.212] starting from 1.Since every file only contains a single data point we need to loop over them and concatenate the results into a single vector.
* [1.x.179]
* As we are not interested in the values themselves but rather in the error compared to a "exact" solution we willassume our highest refinement level to be that solution and omit it from the data.
* [1.x.180]
* Now we have all the data available to generate our plots.It is often useful to plot errors on a log-log scale, which isaccomplished in the following code:
* [1.x.181]
* This results in the following plot that shows how the errors in themean value and the solution value at the chosen point nicely convergeto zero: [2.x.213] 
* 

* [1.x.182][1.x.183] [2.x.214] 
* [0.x.1]