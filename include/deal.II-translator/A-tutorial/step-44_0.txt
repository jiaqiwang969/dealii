[0.x.0]*
 [2.x.0] 
* This tutorial depends on  [2.x.1] .
* [1.x.0][1.x.1][1.x.2][1.x.3][1.x.4][1.x.5][1.x.6][1.x.7][1.x.8][1.x.9][1.x.10][1.x.11][1.x.12][1.x.13][1.x.14][1.x.15][1.x.16][1.x.17][1.x.18][1.x.19][1.x.20][1.x.21][1.x.22][1.x.23][1.x.24][1.x.25][1.x.26][1.x.27][1.x.28][1.x.29][1.x.30][1.x.31][1.x.32][1.x.33][1.x.34][1.x.35][1.x.36][1.x.37][1.x.38][1.x.39][1.x.40][1.x.41][1.x.42][1.x.43][1.x.44][1.x.45][1.x.46][1.x.47][1.x.48][1.x.49][1.x.50][1.x.51]
*  [2.x.2] 
* [1.x.52]
*  [2.x.3] 
* [1.x.53][1.x.54][1.x.55]
* 

* The subject of this tutorial is nonlinear solid mechanics.Classical single-field approaches (see e.g.  [2.x.4] ) can not correctly describe the response of quasi-incompressible materials.The response is overly stiff; a phenomenon known as locking.Locking problems can be circumvented using a variety of alternative strategies.One such strategy is the  three-field formulation.It is used here  to model the three-dimensional, fully-nonlinear (geometrical and material) response of an isotropic continuum body.The material response is approximated as hyperelastic.Additionally, the three-field formulation employed is valid for quasi-incompressible as well as compressible materials.
* The objective of this presentation is to provide a basis for using deal.II for problems in nonlinear solid mechanics.The linear problem was addressed in  [2.x.5] .A non-standard, hypoelastic-type form of the geometrically nonlinear problem was partially considered in  [2.x.6] : a rate form of the linearised constitutive relations is used and the problem domain evolves with the motion.Important concepts surrounding the nonlinear kinematics are absent in the theory and implementation. [2.x.7]  does, however, describe many of the key concepts to implement elasticity within the framework of deal.II.
* We begin with a crash-course in nonlinear kinematics.For the sake of simplicity, we restrict our attention to the quasi-static problem.Thereafter, various key stress measures are introduced and the constitutive model described.We then describe the three-field formulation in detail prior to explaining the structure of the class used to manage the material.The setup of the example problem is then presented.
*  [2.x.8]  This tutorial has been developed (and is described in the introduction) for the problem of elasticity in three dimensions. While the space dimension could be changed in the main() routine, care needs to be taken. Two-dimensional elasticity problems, in general, exist only as idealizations of three-dimensional ones. That is, they are either plane strain or plane stress. The assumptions that follow either of these choices needs to be consistently imposed. For more information see the note in  [2.x.9] .
* [1.x.56][1.x.57]
* 

* The three-field formulation implemented here was pioneered by Simo et al. (1985) and is known as the mixed Jacobian-pressure formulation.Important related contributions include those by Simo and Taylor (1991), and Miehe (1994).The notation adopted here draws heavily on the excellent overview of the theoretical aspects of nonlinear solid mechanics by Holzapfel (2001).A nice overview of issues pertaining to incompressible elasticity (at small strains) is given in Hughes (2000).
*  [2.x.10] 	 [2.x.11]  J.C. Simo, R.L. Taylor and K.S. Pister (1985),		Variational and projection methods for the volume constraint in finite deformation elasto-plasticity,		 [2.x.12]  Computer Methods in Applied Mechanics and Engineering  [2.x.13] ,		<strong> 51 </strong>, 1-3,		177-208.		DOI: [1.x.58];	 [2.x.14]  J.C. Simo and R.L. Taylor (1991),  		Quasi-incompressible finite elasticity in principal stretches. Continuum			basis and numerical algorithms,		 [2.x.15]  Computer Methods in Applied Mechanics and Engineering  [2.x.16] ,		<strong> 85 </strong>, 3,		273-310.		DOI: [1.x.59];	 [2.x.17]  C. Miehe (1994),		Aspects of the formulation and finite element implementation of large strain isotropic elasticity		 [2.x.18]  International Journal for Numerical Methods in Engineering  [2.x.19] 		<strong> 37 </strong>, 12,		1981-2004.		DOI: [1.x.60];	 [2.x.20]  G.A. Holzapfel (2001),		Nonlinear Solid Mechanics. A Continuum Approach for Engineering,		John Wiley & Sons.		ISBN: 0-471-82304-X;	 [2.x.21]  T.J.R. Hughes (2000),		The Finite Element Method: Linear Static and Dynamic Finite Element Analysis,		Dover.		ISBN: 978-0486411811 [2.x.22] 
* An example where this three-field formulation is used in a coupled problem is documented in [2.x.23] 	 [2.x.24]  J-P. V. Pelteret, D. Davydov, A. McBride, D. K. Vu, and P. Steinmann (2016),		Computational electro- and magneto-elasticity for quasi-incompressible media immersed in free space,		 [2.x.25]  International Journal for Numerical Methods in Engineering  [2.x.26] .		DOI: [1.x.61] [2.x.27] 
* [1.x.62][1.x.63]
* 

* One can think of fourth-order tensors as linear operators mapping second-ordertensors (matrices) onto themselves in much the same way as matrices mapvectors onto vectors.There are various fourth-order unit tensors that will be required in the forthcoming presentation.The fourth-order unit tensors  [2.x.28]  and  [2.x.29]  are defined by[1.x.64]Note  [2.x.30] .Furthermore, we define the symmetric and skew-symmetric fourth-order unit tensors by[1.x.65]such that[1.x.66]The fourth-order  [2.x.31]  returned by identity_tensor() is  [2.x.32] .
* 

* [1.x.67][1.x.68]
* 

* Let the time domain be denoted  [2.x.33] , where  [2.x.34]  and  [2.x.35]  is the total problem duration.Consider a continuum body that occupies the reference configuration  [2.x.36]  at time  [2.x.37] .%Particles in the reference configuration are identified by the position vector  [2.x.38] .The configuration of the body at a later time  [2.x.39]  is termed the current configuration, denoted  [2.x.40] , with particles identified by the vector  [2.x.41] .The nonlinear map between the reference and current configurations, denoted  [2.x.42] , acts as follows:[1.x.69]The material description of the displacement of a particle is defined by[1.x.70]
* The deformation gradient  [2.x.43]  is defined as the material gradient of the motion:[1.x.71]The determinant of the of the deformation gradient [2.x.44] maps corresponding volume elements in the reference and current configurations, denoted [2.x.45]  and  [2.x.46] ,respectively, as[1.x.72]
* Two important measures of the deformation in terms of the spatial and material coordinates are the left and right Cauchy-Green tensors, respectively,and denoted  [2.x.47]  and  [2.x.48] .They are both symmetric and positive definite.
* The Green-Lagrange strain tensor is defined by[1.x.73]If the assumption of infinitesimal deformations is made, then the second termon the right can be neglected, and  [2.x.49]  (the linearisedstrain tensor) is the only component of the strain tensor.This assumption is, looking at the setup of the problem, not valid in  [2.x.50] ,making the use of the linearized  [2.x.51]  as the strainmeasure in that tutorial program questionable.
* In order to handle the different response that materials exhibit when subjected to bulk and shear type deformations we consider the following decomposition of the deformation gradient  [2.x.52]   and the left Cauchy-Green tensor  [2.x.53]  into volume-changing (volumetric) and volume-preserving (isochoric) parts:[1.x.74]Clearly,  [2.x.54] .
* The spatial velocity field is denoted  [2.x.55] .The derivative of the spatial velocity field with respect to the spatial coordinates gives the spatial velocity gradient  [2.x.56] , that is[1.x.75]where  [2.x.57] .
* 

* [1.x.76][1.x.77]
* 

* Cauchy's stress theorem equates the Cauchy traction  [2.x.58]  acting on an infinitesimal surface element in the current configuration  [2.x.59]  to the product of the Cauchy stress tensor  [2.x.60]  (a spatial quantity)  and the outward unit normal to the surface  [2.x.61]  as[1.x.78]The Cauchy stress is symmetric.Similarly,  the first Piola-Kirchhoff traction  [2.x.62]  which acts on an infinitesimal surface element in the reference configuration  [2.x.63]  is the product of the first Piola-Kirchhoff stress tensor  [2.x.64]  (a two-point tensor)  and the outward unit normal to the surface  [2.x.65]  as[1.x.79]The Cauchy traction  [2.x.66]  and the first Piola-Kirchhoff traction  [2.x.67]  are related as[1.x.80]This can be demonstrated using [1.x.81].
* The first Piola-Kirchhoff stress tensor is related to the Cauchy stress as[1.x.82]Further important stress measures are the (spatial) Kirchhoff stress   [2.x.68] and the (referential) second Piola-Kirchhoff stress [2.x.69] .
* 

* [1.x.83][1.x.84]
* 

* Push-forward and pull-back operators allow one to transform various measures between the material and spatial settings.The stress measures used here are contravariant, while the strain measures are covariant.
* The push-forward and-pull back operations for second-order covariant tensors  [2.x.70]  are respectively given by:[1.x.85]
* The push-forward and pull back operations for second-order contravariant tensors  [2.x.71]  are respectively given by:[1.x.86]For example  [2.x.72] .
* 

* [1.x.87][1.x.88]
* 

* A hyperelastic material response is governed by a Helmholtz free energy function  [2.x.73]  which serves as a potential for the stress.For example, if the Helmholtz free energy depends on the right Cauchy-Green tensor  [2.x.74]  then the isotropic hyperelastic response is[1.x.89]If the Helmholtz free energy depends on the left Cauchy-Green tensor  [2.x.75]  then the isotropic hyperelastic response is[1.x.90]
* Following the multiplicative decomposition of the deformation gradient, the Helmholtz free energy can be decomposed as[1.x.91]Similarly, the Kirchhoff stress can be decomposed into volumetric and isochoric parts as  [2.x.76]  where:
* [1.x.92]
* where [2.x.77]  is the pressure response. [2.x.78]  is the projection tensor which provides the deviatoric operator in the Eulerian setting.The fictitious Kirchhoff stress tensor  [2.x.79]  is defined by[1.x.93]
* 

* 
*  [2.x.80]  The pressure response as defined above differs from the widely-used definition of thepressure in solid mechanics as [2.x.81] .Here  [2.x.82]  is the hydrostatic pressure.We make use of the pressure response throughout this tutorial (although we refer to it as the pressure).
* [1.x.94][1.x.95]
* 

* The Helmholtz free energy corresponding to a compressible [1.x.96] is given by[1.x.97]where  [2.x.83]  is the bulk modulus ( [2.x.84]  and  [2.x.85]  are the Lam&eacute; parameters)and  [2.x.86] .The function  [2.x.87]  is required to be strictly convex and satisfy the condition  [2.x.88] ,among others, see Holzapfel (2001) for further details.In this work  [2.x.89] .
* Incompressibility imposes the isochoric constraint that  [2.x.90]  for all motions  [2.x.91] .The Helmholtz free energy corresponding to an incompressible neo-Hookean material is given by[1.x.98]where  [2.x.92] .Thus, the incompressible response is obtained by removing the volumetric component from the compressible free energy and enforcing  [2.x.93] .
* 

* [1.x.99][1.x.100]
* 

* We will use a Newton-Raphson strategy to solve the nonlinear boundary value problem.Thus, we will need to linearise the constitutive relations.
* The fourth-order elasticity tensor in the material description is defined by[1.x.101]The fourth-order elasticity tensor in the spatial description  [2.x.94]  is obtained from the push-forward of  [2.x.95]  as[1.x.102]The fourth-order elasticity tensors (for hyperelastic materials) possess both major and minor symmetries.
* The fourth-order spatial elasticity tensor can be written in the following decoupled form:[1.x.103]where
* [1.x.104]
* where the fictitious elasticity tensor  [2.x.96]  in the spatial description is defined by[1.x.105]
* [1.x.106][1.x.107]
* 

* The total potential energy of the system  [2.x.97]  is the sum of the internal and external potential energies, denoted  [2.x.98]  and  [2.x.99] , respectively.We wish to find the equilibrium configuration by minimising the potential energy.
* As mentioned above, we adopt a three-field formulation.We denote the set of primary unknowns by [2.x.100] .The independent kinematic variable  [2.x.101]  enters the formulation as a constraint on  [2.x.102]  enforced by the Lagrange multiplier  [2.x.103]  (the pressure, as we shall see).
* The three-field variational principle used here is given by[1.x.108]where the external potential is defined by[1.x.109]The boundary of the current configuration   [2.x.104]  is composed into two parts as [2.x.105] ,where [2.x.106] .The prescribed Cauchy traction, denoted  [2.x.107] , is applied to  [2.x.108]  while the motion is prescribed on the remaining portion of the boundary  [2.x.109] .The body force per unit current volume is denoted  [2.x.110] .
* 

* 
* The stationarity of the potential follows as
* [1.x.110]
* for all virtual displacements  [2.x.111]  subject to the constraint that  [2.x.112]  on  [2.x.113] , and all virtual pressures  [2.x.114]  and virtual dilatations  [2.x.115] .
* One should note that the definitions of the volumetric Kirchhoff stress in the three field formulation [2.x.116]  and the subsequent volumetric tangent differs slightly from the general form given in the section on hyperelastic materials where [2.x.117] .This is because the pressure  [2.x.118]  is now a primary field as opposed to a constitutively derived quantity.One needs to carefully distinguish between the primary fields and those obtained from the constitutive relations.
*  [2.x.119]  Although the variables are all expressed in terms of spatial quantities, the domain of integration is the initial configuration.This approach is called a  [2.x.120]  total-Lagrangian formulation  [2.x.121] .The approach given in  [2.x.122] , where the domain of integration is the current configuration, could be called an  [2.x.123]  updated Lagrangian formulation  [2.x.124] .The various merits of these two approaches are discussed widely in the literature.It should be noted however that they are equivalent.
* 

* The Euler-Lagrange equations corresponding to the residual are:
* [1.x.111]
* The first equation is the (quasi-static) equilibrium equation in the spatial setting.The second is the constraint that  [2.x.125] .The third is the definition of the pressure  [2.x.126] .
*  [2.x.127]  The simplified single-field derivation ( [2.x.128]  is the only primary variable) below makes it clear how we transform the limits of integration to the reference domain:
* [1.x.112]
* where [2.x.129] .
* We will use an iterative Newton-Raphson method to solve the nonlinear residual equation  [2.x.130] .For the sake of simplicity we assume dead loading, i.e. the loading does not change due to the deformation.
* The change in a quantity between the known state at  [2.x.131] and the currently unknown state at  [2.x.132]  is denoted [2.x.133] .The value of a quantity at the current iteration  [2.x.134]  is denoted [2.x.135] .The incremental change between iterations  [2.x.136]  and  [2.x.137]  is denoted [2.x.138] .
* Assume that the state of the system is known for some iteration  [2.x.139] .The linearised approximation to nonlinear governing equations to be solved using the  Newton-Raphson method is:Find  [2.x.140]  such that[1.x.113]then set [2.x.141] .The tangent is given by
* [1.x.114]Thus,
* [1.x.115]
* where
* [1.x.116]
* 
* Note that the following terms are termed the geometrical stress and  the material contributions to the tangent matrix:
* [1.x.117]
* 
* 

* [1.x.118][1.x.119]
* 

* The three-field formulation used here is effective for quasi-incompressible materials,that is where  [2.x.142]  (where  [2.x.143]  is [1.x.120]), subject to a good choice of the interpolation fieldsfor  [2.x.144]  and  [2.x.145] .Typically a choice of  [2.x.146]  is made.Here  [2.x.147]  is the FE_DGPMonomial class.A popular choice is  [2.x.148]  which is known as the mean dilatation method (see Hughes (2000) for an intuitive discussion).This code can accommodate a  [2.x.149]  formulation.The discontinuous approximationallows  [2.x.150]  and  [2.x.151]  to be condensed outand a classical displacement based method is recovered.
* For fully-incompressible materials  [2.x.152]  and the three-field formulation will still exhibitlocking behavior.This can be overcome by introducing an additional constraint into the free energy of the form [2.x.153] .Here  [2.x.154]  is a Lagrange multiplier to enforce the isochoric constraint.For further details see Miehe (1994).
* The linearised problem can be written as[1.x.121]where
* [1.x.122]
* 
* There are no derivatives of the pressure and dilatation (primary) variables present in the formulation.Thus the discontinuous finite element interpolation of the pressure and dilatation yields a blockdiagonal matrix for [2.x.155] , [2.x.156]  and [2.x.157] .Therefore we can easily express the fields  [2.x.158]  and  [2.x.159]  on each cell simplyby inverting a local matrix and multiplying it by the local right handside. We can then insert the result into the remaining equations and recovera classical displacement-based method.In order to condense out the pressure and dilatation contributions at the element level we need the following results:
* [1.x.123]
* and thus[1.x.124]where[1.x.125]Note that due to the choice of  [2.x.160]  and  [2.x.161]  as discontinuous at the element level, all matrices that need to be inverted are defined at the element level.
* The procedure to construct the various contributions is as follows:
* 
*  - Construct  [2.x.162] .
* 
*  - Form  [2.x.163]  for element and store where  [2.x.164]  was stored in  [2.x.165] .
* 
*  - Form  [2.x.166]  and add to  [2.x.167]  to get  [2.x.168] 
* 
*  - The modified system matrix is called  [2.x.169] .  That is  [1.x.126]
* 

* [1.x.127][1.x.128]
* 

* A good object-oriented design of a Material class would facilitate the extension of this tutorial to a wide range of material types.In this tutorial we simply have one Material class named Material_Compressible_Neo_Hook_Three_Field.Ideally this class would derive from a class HyperelasticMaterial which would derive from the base class Material.The three-field nature of the formulation used here also complicates the matter.
* The Helmholtz free energy function for the three field formulation is  [2.x.170] .The isochoric part of the Kirchhoff stress  [2.x.171]  is identical to that obtained using a one-field formulation for a hyperelastic material.However, the volumetric part of the free energy is now a function of the primary variable  [2.x.172] .Thus, for a three field formulation the constitutive response for the volumetric part of the Kirchhoff stress  [2.x.173]  (and the tangent) is not given by the hyperelastic constitutive law as in a one-field formulation.One can label the term [2.x.174] as the volumetric Kirchhoff stress, but the pressure  [2.x.175]  is not derived from the free energy; it is a primary field.
* In order to have a flexible approach, it was decided that the Material_Compressible_Neo_Hook_Three_Field would still be able to calculate and return a volumetric Kirchhoff stress and tangent.In order to do this, we choose to store the interpolated primary fields  [2.x.176]  and  [2.x.177]  in the Material_Compressible_Neo_Hook_Three_Field class associated with the quadrature point.This decision should be revisited at a later stage when the tutorial is extended to account for other materials.
* 

* [1.x.129][1.x.130]
* 

* The numerical example considered here is a nearly-incompressible block under compression.This benchmark problem is taken from
* 
*  - S. Reese, P. Wriggers, B.D. Reddy (2000),  A new locking-free brick element technique for large deformation problems in elasticity,   [2.x.178]  Computers and Structures  [2.x.179] ,  <strong> 75 </strong>,  291-304.  DOI: [1.x.131]
*   [2.x.180] 
* The material is quasi-incompressible neo-Hookean with [1.x.132]  [2.x.181]  and  [2.x.182] .For such a choice of material properties a conventional single-field  [2.x.183]  approach would lock.That is, the response would be overly stiff.The initial and final configurations are shown in the image above.Using symmetry, we solve for only one quarter of the geometry (i.e. a cube with dimension  [2.x.184] ).The inner-quarter of the upper surface of the domain is subject to a load of  [2.x.185] .
* 

*  [1.x.133] [1.x.134]
*  We start by including all the necessary deal.II header files and some C++ related ones. They have been discussed in detail in previous tutorial programs, so you need only refer to past tutorials for details.
* 

* 
* [1.x.135]
* 
*  This header gives us the functionality to store data at quadrature points
* 

* 
* [1.x.136]
* 
*  Here are the headers necessary to use the LinearOperator class. These are also all conveniently packaged into a single header file, namely <deal.II/lac/linear_operator_tools.h> but we list those specifically required here for the sake of transparency.
* 

* 
* [1.x.137]
* 
*  Defined in these two headers are some operations that are pertinent to finite strain elasticity. The first will help us compute some kinematic quantities, and the second provides some stanard tensor definitions.
* 

* 
* [1.x.138]
* 
*  We then stick everything that relates to this tutorial program into a namespace of its own, and import all the deal.II function and class names into it:
* 

* 
* [1.x.139]
* 
*   [1.x.140]  [1.x.141]   
*   There are several parameters that can be set in the code so we set up a ParameterHandler object to read in the choices at run-time.
* 

* 
* [1.x.142]
* 
*   [1.x.143]  [1.x.144]
* 

* 
*  As mentioned in the introduction, a different order interpolation should be used for the displacement  [2.x.186]  than for the pressure  [2.x.187]  and the dilatation  [2.x.188] .  Choosing  [2.x.189]  and  [2.x.190]  as discontinuous (constant) functions at the element level leads to the mean-dilatation method. The discontinuous approximation allows  [2.x.191]  and  [2.x.192]  to be condensed out and a classical displacement based method is recovered. Here we specify the polynomial order used to approximate the solution. The quadrature order should be adjusted accordingly.
* 

* 
* [1.x.145]
* 
*   [1.x.146]  [1.x.147]
* 

* 
*  Make adjustments to the problem geometry and the applied load.  Since the problem modelled here is quite specific, the load scale can be altered to specific values to compare with the results given in the literature.
* 

* 
* [1.x.148]
* 
*   [1.x.149]  [1.x.150]
* 

* 
*  We also need the shear modulus  [2.x.193]  and Poisson ration  [2.x.194]  for the neo-Hookean material.
* 

* 
* [1.x.151]
* 
*   [1.x.152]  [1.x.153]
* 

* 
*  Next, we choose both solver and preconditioner settings.  The use of an effective preconditioner is critical to ensure convergence when a large nonlinear motion occurs within a Newton increment.
* 

* 
* [1.x.154]
* 
*   [1.x.155]  [1.x.156]
* 

* 
*  A Newton-Raphson scheme is used to solve the nonlinear system of governing equations.  We now define the tolerances and the maximum number of iterations for the Newton-Raphson nonlinear solver.
* 

* 
* [1.x.157]
* 
*   [1.x.158]  [1.x.159]
* 

* 
*  Set the timestep size  [2.x.195]  and the simulation end-time.
* 

* 
* [1.x.160]
* 
*   [1.x.161]  [1.x.162]
* 

* 
*  Finally we consolidate all of the above structures into a single container that holds all of our run-time selections.
* 

* 
* [1.x.163]
* 
*   [1.x.164]  [1.x.165]
* 

* 
*  A simple class to store time data. Its functioning is transparent so no discussion is necessary. For simplicity we assume a constant time step size.
* 

* 
* [1.x.166]
* 
*   [1.x.167]  [1.x.168]
* 

* 
*  As discussed in the Introduction, Neo-Hookean materials are a type of hyperelastic materials.  The entire domain is assumed to be composed of a compressible neo-Hookean material.  This class defines the behavior of this material within a three-field formulation.  Compressible neo-Hookean materials can be described by a strain-energy function (SEF)  [2.x.196] .   
*   The isochoric response is given by  [2.x.197]  where  [2.x.198]  and  [2.x.199]  is the first invariant of the left- or right-isochoric Cauchy-Green deformation tensors. That is  [2.x.200] . In this example the SEF that governs the volumetric response is defined as  [2.x.201] , where  [2.x.202]  is the [1.x.169] and  [2.x.203]  is [1.x.170].   
*   The following class will be used to characterize the material we work with, and provides a central point that one would need to modify if one were to implement a different material model. For it to work, we will store one object of this type per quadrature point, and in each of these objects store the current state (characterized by the values or measures  of the three fields) so that we can compute the elastic coefficients linearized around the current state.
* 

* 
* [1.x.171]
* 
*  We update the material model with various deformation dependent data based on  [2.x.204]  and the pressure  [2.x.205]  and dilatation  [2.x.206] , and at the end of the function include a physical check for internal consistency:
* 

* 
* [1.x.172]
* 
*  The second function determines the Kirchhoff stress  [2.x.207] 
* 

* 
* [1.x.173]
* 
*  The fourth-order elasticity tensor in the spatial setting  [2.x.208]  is calculated from the SEF  [2.x.209]  as  [2.x.210]  where  [2.x.211] 
* 

* 
* [1.x.174]
* 
*  Derivative of the volumetric free energy with respect to  [2.x.212]  return  [2.x.213] 
* 

* 
* [1.x.175]
* 
*  Second derivative of the volumetric free energy wrt  [2.x.214] . We need the following computation explicitly in the tangent so we make it public.  We calculate  [2.x.215] 
* 

* 
* [1.x.176]
* 
*  The next few functions return various data that we choose to store with the material:
* 

* 
* [1.x.177]
* 
*  Define constitutive model parameters  [2.x.216]  (bulk modulus) and the neo-Hookean model parameter  [2.x.217] :
* 

* 
* [1.x.178]
* 
*  Model specific data that is convenient to store with the material:
* 

* 
* [1.x.179]
* 
*  The following functions are used internally in determining the result of some of the public functions above. The first one determines the volumetric Kirchhoff stress  [2.x.218] :
* 

* 
* [1.x.180]
* 
*  Next, determine the isochoric Kirchhoff stress  [2.x.219] :
* 

* 
* [1.x.181]
* 
*  Then, determine the fictitious Kirchhoff stress  [2.x.220] :
* 

* 
* [1.x.182]
* 
*  Calculate the volumetric part of the tangent  [2.x.221] :
* 

* 
* [1.x.183]
* 
*  Calculate the isochoric part of the tangent  [2.x.222] :
* 

* 
* [1.x.184]
* 
*  Calculate the fictitious elasticity tensor  [2.x.223] . For the material model chosen this is simply zero:
* 

* 
* [1.x.185]
* 
*   [1.x.186]  [1.x.187]
* 

* 
*  As seen in  [2.x.224] , the  [2.x.225]  class offers a method for storing data at the quadrature points.  Here each quadrature point holds a pointer to a material description.  Thus, different material models can be used in different regions of the domain.  Among other data, we choose to store the Kirchhoff stress  [2.x.226]  and the tangent  [2.x.227]  for the quadrature points.
* 

* 
* [1.x.188]
* 
*  The first function is used to create a material object and to initialize all tensors correctly: The second one updates the stored values and stresses based on the current deformation measure  [2.x.228] , pressure  [2.x.229]  and dilation  [2.x.230]  field values.
* 

* 
* [1.x.189]
* 
*  To this end, we calculate the deformation gradient  [2.x.231]  from the displacement gradient  [2.x.232] , i.e.  [2.x.233]  and then let the material model associated with this quadrature point update itself. When computing the deformation gradient, we have to take care with which data types we compare the sum  [2.x.234] : Since  [2.x.235]  has data type SymmetricTensor, just writing  [2.x.236]  would convert the second argument to a symmetric tensor, perform the sum, and then cast the result to a Tensor (i.e., the type of a possibly nonsymmetric tensor). However, since  [2.x.237]  is nonsymmetric in general, the conversion to SymmetricTensor will fail. We can avoid this back and forth by converting  [2.x.238]  to Tensor first, and then performing the addition as between nonsymmetric tensors:
* 

* 
* [1.x.190]
* 
*  The material has been updated so we now calculate the Kirchhoff stress  [2.x.239] , the tangent  [2.x.240]  and the first and second derivatives of the volumetric free energy.       
*   We also store the inverse of the deformation gradient since we frequently use it:
* 

* 
* [1.x.191]
* 
*  We offer an interface to retrieve certain data.  Here are the kinematic variables:
* 

* 
* [1.x.192]
* 
*  ...and the kinetic variables.  These are used in the material and global tangent matrix and residual assembly operations:
* 

* 
* [1.x.193]
* 
*  And finally the tangent:
* 

* 
* [1.x.194]
* 
*  In terms of member functions, this class stores for the quadrature point it represents a copy of a material type in case different materials are used in different regions of the domain, as well as the inverse of the deformation gradient...
* 

* 
* [1.x.195]
* 
*  ... and stress-type variables along with the tangent  [2.x.241] :
* 

* 
* [1.x.196]
* 
*   [1.x.197]  [1.x.198]
* 

* 
*  The Solid class is the central class in that it represents the problem at hand. It follows the usual scheme in that all it really has is a constructor, destructor and a  [2.x.242]  function that dispatches all the work to private functions of this class:
* 

* 
* [1.x.199]
* 
*  In the private section of this class, we first forward declare a number of objects that are used in parallelizing work using the WorkStream object (see the  [2.x.243]  module for more information on this).     
*   We declare such structures for the computation of tangent (stiffness) matrix and right hand side vector, static condensation, and for updating quadrature points:
* 

* 
* [1.x.200]
* 
*  We start the collection of member functions with one that builds the grid:
* 

* 
* [1.x.201]
* 
*  Set up the finite element system to be solved:
* 

* 
* [1.x.202]
* 
*  Create Dirichlet constraints for the incremental displacement field:
* 

* 
* [1.x.203]
* 
*  Several functions to assemble the system and right hand side matrices using multithreading. Each of them comes as a wrapper function, one that is executed to do the work in the WorkStream model on one cell, and one that copies the work done on this one cell into the global object that represents it:
* 

* 
* [1.x.204]
* 
*  And similar to perform global static condensation:
* 

* 
* [1.x.205]
* 
*  Create and update the quadrature points. Here, no data needs to be copied into a global object, so the copy_local_to_global function is empty:
* 

* 
* [1.x.206]
* 
*  Solve for the displacement using a Newton-Raphson method. We break this function into the nonlinear loop and the function that solves the linearized Newton-Raphson step:
* 

* 
* [1.x.207]
* 
*  Solution retrieval as well as post-processing and writing data to file:
* 

* 
* [1.x.208]
* 
*  Finally, some member variables that describe the current state: A collection of the parameters used to describe the problem setup...
* 

* 
* [1.x.209]
* 
*  ...the volume of the reference configuration...
* 

* 
* [1.x.210]
* 
*  ...and description of the geometry on which the problem is solved:
* 

* 
* [1.x.211]
* 
*  Also, keep track of the current time and the time spent evaluating certain functions
* 

* 
* [1.x.212]
* 
*  A storage object for quadrature point information. As opposed to  [2.x.244] , deal.II's native quadrature point data manager is employed here.
* 

* 
* [1.x.213]
* 
*  A description of the finite-element system including the displacement polynomial degree, the degree-of-freedom handler, number of DoFs per cell and the extractor objects used to retrieve information from the solution vectors:
* 

* 
* [1.x.214]
* 
*  Description of how the block-system is arranged. There are 3 blocks, the first contains a vector DOF  [2.x.245]  while the other two describe scalar DOFs,  [2.x.246]  and  [2.x.247] .
* 

* 
* [1.x.215]
* 
*  Rules for Gauss-quadrature on both the cell and faces. The number of quadrature points on both cells and faces is recorded.
* 

* 
* [1.x.216]
* 
*  Objects that store the converged solution and right-hand side vectors, as well as the tangent matrix. There is an AffineConstraints object used to keep track of constraints.  We make use of a sparsity pattern designed for a block system.
* 

* 
* [1.x.217]
* 
*  Then define a number of variables to store norms and update norms and normalization factors.
* 

* 
* [1.x.218]
* 
*  Methods to calculate error measures
* 

* 
* [1.x.219]
* 
*  Compute the volume in the spatial configuration
* 

* 
* [1.x.220]
* 
*  Print information to screen in a pleasing way...
* 

* 
* [1.x.221]
* 
*   [1.x.222]  [1.x.223]
* 

* 
*   [1.x.224]  [1.x.225]
* 

* 
*  We initialize the Solid class using data extracted from the parameter file.
* 

* 
* [1.x.226]
* 
*  The Finite Element System is composed of dim continuous displacement DOFs, and discontinuous pressure and dilatation DOFs. In an attempt to satisfy the Babuska-Brezzi or LBB stability conditions (see Hughes (2000)), we setup a  [2.x.248]  system.  [2.x.249]  elements satisfy this condition, while  [2.x.250]  elements do not. However, it has been shown that the latter demonstrate good convergence characteristics nonetheless.
* 

* 
* [1.x.227]
* 
*  In solving the quasi-static problem, the time becomes a loading parameter, i.e. we increasing the loading linearly with time, making the two concepts interchangeable. We choose to increment time linearly using a constant time step size.   
*   We start the function with preprocessing, setting the initial dilatation values, and then output the initial grid before starting the simulation proper with the first time (and loading) increment.   
*   Care must be taken (or at least some thought given) when imposing the constraint  [2.x.251]  on the initial solution field. The constraint corresponds to the determinant of the deformation gradient in the undeformed configuration, which is the identity tensor. We use FE_DGPMonomial bases to interpolate the dilatation field, thus we can't simply set the corresponding dof to unity as they correspond to the monomial coefficients. Thus we use the  [2.x.252]  function to do the work for us. The  [2.x.253]  function requires an argument indicating the hanging node constraints. We have none in this program So we have to create a constraint object. In its original state, constraint objects are unsorted, and have to be sorted (using the  [2.x.254]  function) before they can be used. Have a look at  [2.x.255]  for more information. We only need to enforce the initial condition on the dilatation. In order to do this, we make use of a ComponentSelectFunction which acts as a mask and sets the J_component of n_components to 1. This is exactly what we want. Have a look at its usage in  [2.x.256]  for more information.
* 

* 
* [1.x.228]
* 
*  We then declare the incremental solution update  [2.x.257]  and start the loop over the time domain.     
*   At the beginning, we reset the solution update for this time step...
* 

* 
* [1.x.229]
* 
*  ...solve the current time step and update total solution vector  [2.x.258] ...
* 

* 
* [1.x.230]
* 
*  ...and plot the results before moving on happily to the next time step:
* 

* 
* [1.x.231]
* 
*   [1.x.232]  [1.x.233]
* 

* 
*   [1.x.234]  [1.x.235]
* 

* 
*  The first group of private member functions is related to parallelization. We use the Threading Building Blocks library (TBB) to perform as many computationally intensive distributed tasks as possible. In particular, we assemble the tangent matrix and right hand side vector, the static condensation contributions, and update data stored at the quadrature points using TBB. Our main tool for this is the WorkStream class (see the  [2.x.259]  threads module for more information).
* 

* 
*  Firstly we deal with the tangent matrix and right-hand side assembly structures. The PerTaskData object stores local contributions to the global system.
* 

* 
* [1.x.236]
* 
*  On the other hand, the ScratchData object stores the larger objects such as the shape-function values array ( [2.x.260] ) and a shape function gradient and symmetric gradient vector which we will use during the assembly.
* 

* 
* [1.x.237]
* 
*  Then we define structures to assemble the statically condensed tangent matrix. Recall that we wish to solve for a displacement-based formulation. We do the condensation at the element level as the  [2.x.261]  and  [2.x.262]  fields are element-wise discontinuous.  As these operations are matrix-based, we need to setup a number of matrices to store the local contributions from a number of the tangent matrix sub-blocks.  We place these in the PerTaskData struct.   
*   We choose not to reset any data in the  [2.x.263]  function as the matrix extraction and replacement tools will take care of this
* 

* 
* [1.x.238]
* 
*  The ScratchData object for the operations we wish to perform here is empty since we need no temporary data, but it still needs to be defined for the current implementation of TBB in deal.II.  So we create a dummy struct for this purpose.
* 

* 
* [1.x.239]
* 
*  And finally we define the structures to assist with updating the quadrature point information. Similar to the SC assembly process, we do not need the PerTaskData object (since there is nothing to store here) but must define one nonetheless. Note that this is because for the operation that we have here
* 
*  -  updating the data on quadrature points
* 
*  -  the operation is purely local: the things we do on every cell get consumed on every cell, without any global aggregation operation as is usually the case when using the WorkStream class. The fact that we still have to define a per-task data structure points to the fact that the WorkStream class may be ill-suited to this operation (we could, in principle simply create a new task using  [2.x.264]  for each cell) but there is not much harm done to doing it this way anyway. Furthermore, should there be different material models associated with a quadrature point, requiring varying levels of computational expense, then the method used here could be advantageous.
* 

* 
* [1.x.240]
* 
*  The ScratchData object will be used to store an alias for the solution vector so that we don't have to copy this large data structure. We then define a number of vectors to extract the solution values and gradients at the quadrature points.
* 

* 
* [1.x.241]
* 
*   [1.x.242]  [1.x.243]
* 

* 
*  On to the first of the private member functions. Here we create the triangulation of the domain, for which we choose the scaled cube with each face given a boundary ID number.  The grid must be refined at least once for the indentation problem.   
*   We then determine the volume of the reference configuration and print it for comparison:
* 

* 
* [1.x.244]
* 
*  Since we wish to apply a Neumann BC to a patch on the top surface, we must find the cell faces in this part of the domain and mark them with a distinct boundary ID number.  The faces we are looking for are on the +y surface and will get boundary ID 6 (zero through five are already used when creating the six faces of the cube domain):
* 

* 
* [1.x.245]
* 
*   [1.x.246]  [1.x.247]
* 

* 
*  Next we describe how the FE system is setup.  We first determine the number of components per block. Since the displacement is a vector component, the first dim components belong to it, while the next two describe scalar pressure and dilatation DOFs.
* 

* 
* [1.x.248]
* 
*  The DOF handler is then initialized and we renumber the grid in an efficient manner. We also record the number of DOFs per block.
* 

* 
* [1.x.249]
* 
*  Setup the sparsity pattern and tangent matrix
* 

* 
* [1.x.250]
* 
*  The global system matrix initially has the following structure

* 
* [1.x.251]
*  We optimize the sparsity pattern to reflect this structure and prevent unnecessary data creation for the right-diagonal block components.
* 

* 
* [1.x.252]
* 
*  We then set up storage vectors
* 

* 
* [1.x.253]
* 
*  ...and finally set up the quadrature point history:
* 

* 
* [1.x.254]
* 
*   [1.x.255]  [1.x.256] Next we compute some information from the FE system that describes which local element DOFs are attached to which block component.  This is used later to extract sub-blocks from the global matrix.   
*   In essence, all we need is for the FESystem object to indicate to which block component a DOF on the reference cell is attached to.  Currently, the interpolation fields are setup such that 0 indicates a displacement DOF, 1 a pressure DOF and 2 a dilatation DOF.
* 

* 
* [1.x.257]
* 
*   [1.x.258]  [1.x.259] The method used to store quadrature information is already described in  [2.x.265] . Here we implement a similar setup for a SMP machine.   
*   Firstly the actual QPH data objects are created. This must be done only once the grid is refined to its finest level.
* 

* 
* [1.x.260]
* 
*  Next we setup the initial quadrature point data. Note that when the quadrature point data is retrieved, it is returned as a vector of smart pointers.
* 

* 
* [1.x.261]
* 
*   [1.x.262]  [1.x.263] As the update of QP information occurs frequently and involves a number of expensive operations, we define a multithreaded approach to distributing the task across a number of CPU cores.   
*   To start this, we first we need to obtain the total solution as it stands at this Newton increment and then create the initial copy of the scratch and copy data objects:
* 

* 
* [1.x.264]
* 
*  We then pass them and the one-cell update function to the WorkStream to be processed:
* 

* 
* [1.x.265]
* 
*  Now we describe how we extract data from the solution vector and pass it along to each QP storage object for processing.
* 

* 
* [1.x.266]
* 
*  We first need to find the values and gradients at quadrature points inside the current cell and then we update each local QP using the displacement gradient and total pressure and dilatation solution values:
* 

* 
* [1.x.267]
* 
*   [1.x.268]  [1.x.269]
* 

* 
*  The next function is the driver method for the Newton-Raphson scheme. At its top we create a new vector to store the current Newton update step, reset the error storage objects and print solver header.
* 

* 
* [1.x.270]
* 
*  We now perform a number of Newton iterations to iteratively solve the nonlinear problem.  Since the problem is fully nonlinear and we are using a full Newton method, the data stored in the tangent matrix and right-hand side vector is not reusable and must be cleared at each Newton step. We then initially build the linear system and check for convergence (and store this value in the first iteration). The unconstrained DOFs of the rhs vector hold the out-of-balance forces, and collectively determine whether or not the equilibrium solution has been attained.     
*   Although for this particular problem we could potentially construct the RHS vector before assembling the system matrix, for the sake of extensibility we choose not to do so. The benefit to assembling the RHS vector and system matrix separately is that the latter is an expensive operation and we can potentially avoid an extra assembly process by not assembling the tangent matrix when convergence is attained. However, this makes parallelizing the code using MPI more difficult. Furthermore, when extending the problem to the transient case additional contributions to the RHS may result from the time discretization and application of constraints for the velocity and acceleration fields.
* 

* 
* [1.x.271]
* 
*  We construct the linear system, but hold off on solving it (a step that should be significantly more expensive than assembly):
* 

* 
* [1.x.272]
* 
*  We can now determine the normalized residual error and check for solution convergence:
* 

* 
* [1.x.273]
* 
*  If we have decided that we want to continue with the iteration, we solve the linearized system:
* 

* 
* [1.x.274]
* 
*  We can now determine the normalized Newton update error:
* 

* 
* [1.x.275]
* 
*  Lastly, since we implicitly accept the solution step we can perform the actual update of the solution increment for the current time step, update all quadrature point information pertaining to this new displacement and stress state and continue iterating:
* 

* 
* [1.x.276]
* 
*  At the end, if it turns out that we have in fact done more iterations than the parameter file allowed, we raise an exception that can be caught in the main() function. The call <code>AssertThrow(condition, exc_object)</code> is in essence equivalent to <code>if (!cond) throw exc_object;</code> but the former form fills certain fields in the exception object that identify the location (filename and line number) where the exception was raised to make it simpler to identify where the problem happened.
* 

* 
* [1.x.277]
* 
*   [1.x.278]  [1.x.279]
* 

* 
*  This program prints out data in a nice table that is updated on a per-iteration basis. The next two functions set up the table header and footer:
* 

* 
* [1.x.280]
* 
*   [1.x.281]  [1.x.282]
* 

* 
*  Calculate the volume of the domain in the spatial configuration
* 

* 
* [1.x.283]
* 
*  In contrast to that which was previously called for, in this instance the quadrature point data is specifically non-modifiable since we will only be accessing data. We ensure that the right get_data function is called by marking this update function as constant.
* 

* 
* [1.x.284]
* 
*  Calculate how well the dilatation  [2.x.266]  agrees with  [2.x.267]  from the  [2.x.268]  error  [2.x.269] . We also return the ratio of the current volume of the domain to the reference volume. This is of interest for incompressible media where we want to check how well the isochoric constraint has been enforced.
* 

* 
* [1.x.285]
* 
*   [1.x.286]  [1.x.287]
* 

* 
*  Determine the true residual error for the problem.  That is, determine the error in the residual for the unconstrained degrees of freedom.  Note that to do so, we need to ignore constrained DOFs by setting the residual in these vector components to zero.
* 

* 
* [1.x.288]
* 
*   [1.x.289]  [1.x.290]
* 

* 
*  Determine the true Newton update error for the problem
* 

* 
* [1.x.291]
* 
*   [1.x.292]  [1.x.293]
* 

* 
*  This function provides the total solution, which is valid at any Newton step. This is required as, to reduce computational error, the total solution is only updated at the end of the timestep.
* 

* 
* [1.x.294]
* 
*   [1.x.295]  [1.x.296]
* 

* 
*  Since we use TBB for assembly, we simply setup a copy of the data structures required for the process and pass them, along with the assembly functions to the WorkStream object for processing. Note that we must ensure that the matrix and RHS vector are reset before any assembly operations can occur. Furthermore, since we are describing a problem with Neumann BCs, we will need the face normals and so must specify this in the face update flags.
* 

* 
* [1.x.297]
* 
*  The syntax used here to pass data to the WorkStream class is discussed in  [2.x.270] .
* 

* 
* [1.x.298]
* 
*  Of course, we still have to define how we assemble the tangent matrix contribution for a single cell.  We first need to reset and initialize some of the scratch data structures and retrieve some basic information regarding the DOF numbering on this cell.  We can precalculate the cell shape function values and gradients. Note that the shape function gradients are defined with regard to the current configuration.  That is  [2.x.271] .
* 

* 
* [1.x.299]
* 
*  Now we build the local cell stiffness matrix and RHS vector. Since the global and local system matrices are symmetric, we can exploit this property by building only the lower half of the local matrix and copying the values to the upper half.  So we only assemble half of the  [2.x.272] ,  [2.x.273] ,  [2.x.274]  blocks, while the whole  [2.x.275] ,  [2.x.276] ,  [2.x.277]  blocks are built.     
*   In doing so, we first extract some configuration dependent variables from our quadrature history objects for the current quadrature point.
* 

* 
* [1.x.300]
* 
*  These two tensors store some precomputed data. Their use will explained shortly.
* 

* 
* [1.x.301]
* 
*  Next we define some aliases to make the assembly process easier to follow.
* 

* 
* [1.x.302]
* 
*  We first compute the contributions from the internal forces.  Note, by definition of the rhs as the negative of the residual, these contributions are subtracted.
* 

* 
* [1.x.303]
* 
*  Before we go into the inner loop, we have one final chance to introduce some optimizations. We've already taken into account the symmetry of the system, and we can now precompute some common terms that are repeatedly applied in the inner loop. We won't be excessive here, but will rather focus on expensive operations, namely those involving the rank-4 material stiffness tensor and the rank-2 stress tensor.             
*   What we may observe is that both of these tensors are contracted with shape function gradients indexed on the "i" DoF. This implies that this particular operation remains constant as we loop over the "j" DoF. For that reason, we can extract this from the inner loop and save the many operations that, for each quadrature point and DoF index "i" and repeated over index "j" are required to double contract a rank-2 symmetric tensor with a rank-4 symmetric tensor, and a rank-1 tensor with a rank-2 tensor.             
*   At the loss of some readability, this small change will reduce the assembly time of the symmetrized system by about half when using the simulation default parameters, and becomes more significant as the h-refinement level increases.
* 

* 
* [1.x.304]
* 
*  Now we're prepared to compute the tangent matrix contributions:
* 

* 
* [1.x.305]
* 
*  This is the  [2.x.278]  contribution. It comprises a material contribution, and a geometrical stress contribution which is only added along the local matrix diagonals:
* 

* 
* [1.x.306]
* 
*  The material contribution:
* 

* 
* [1.x.307]
* 
*  The geometrical stress contribution:
* 

* 
* [1.x.308]
* 
*  Next is the  [2.x.279]  contribution
* 

* 
* [1.x.309]
* 
*  and lastly the  [2.x.280]  and  [2.x.281]  contributions:
* 

* 
* [1.x.310]
* 
*  Next we assemble the Neumann contribution. We first check to see it the cell face exists on a boundary on which a traction is applied and add the contribution if this is the case.
* 

* 
* [1.x.311]
* 
*  Using the face normal at this quadrature point we specify the traction in reference configuration. For this problem, a defined pressure is applied in the reference configuration. The direction of the applied traction is assumed not to evolve with the deformation of the domain. The traction is defined using the first Piola-Kirchhoff stress is simply  [2.x.282]  We use the time variable to linearly ramp up the pressure load.               
*   Note that the contributions to the right hand side vector we compute here only exist in the displacement components of the vector.
* 

* 
* [1.x.312]
* 
*  Finally, we need to copy the lower half of the local matrix into the upper half:
* 

* 
* [1.x.313]
* 
*   [1.x.314]  [1.x.315] The constraints for this problem are simple to describe. In this particular example, the boundary values will be calculated for the two first iterations of Newton's algorithm. In general, one would build non-homogeneous constraints in the zeroth iteration (that is, when `apply_dirichlet_bc == true` in the code block that follows) and build only the corresponding homogeneous constraints in the following step. While the current example has only homogeneous constraints, previous experiences have shown that a common error is forgetting to add the extra condition when refactoring the code to specific uses. This could lead to errors that are hard to debug. In this spirit, we choose to make the code more verbose in terms of what operations are performed at each Newton step.
* 

* 
* [1.x.316]
* 
*  Since we (a) are dealing with an iterative Newton method, (b) are using an incremental formulation for the displacement, and (c) apply the constraints to the incremental displacement field, any non-homogeneous constraints on the displacement update should only be specified at the zeroth iteration. No subsequent contributions are to be made since the constraints will be exactly satisfied after that iteration.
* 

* 
* [1.x.317]
* 
*  Furthermore, after the first Newton iteration within a timestep, the constraints remain the same and we do not need to modify or rebuild them so long as we do not clear the  [2.x.283]  object.
* 

* 
* [1.x.318]
* 
*  At the zeroth Newton iteration we wish to apply the full set of non-homogeneous and homogeneous constraints that represent the boundary conditions on the displacement increment. Since in general the constraints may be different at each time step, we need to clear the constraints matrix and completely rebuild it. An example case would be if a surface is accelerating; in such a scenario the change in displacement is non-constant between each time step.
* 

* 
* [1.x.319]
* 
*  The boundary conditions for the indentation problem in 3D are as follows: On the
* 
*  - ,
* 
*  -  and
* 
*  -  faces (IDs 0,2,4) we set up a symmetry condition to allow only planar movement while the +x and +z faces (IDs 1,5) are traction free. In this contrived problem, part of the +y face (ID 3) is set to have no motion in the x- and z-component. Finally, as described earlier, the other part of the +y face has an the applied pressure but is also constrained in the x- and z-directions.         
*   In the following, we will have to tell the function interpolation boundary values which components of the solution vector should be constrained (i.e., whether it's the x-, y-, z-displacements or combinations thereof). This is done using ComponentMask objects (see  [2.x.284] ) which we can get from the finite element if we provide it with an extractor object for the component we wish to select. To this end we first set up such extractor objects and later use it when generating the relevant component masks:
* 

* 
* [1.x.320]
* 
*  As all Dirichlet constraints are fulfilled exactly after the zeroth Newton iteration, we want to ensure that no further modification are made to those entries. This implies that we want to convert all non-homogeneous Dirichlet constraints into homogeneous ones.         
*   In this example the procedure to do this is quite straightforward, and in fact we can (and will) circumvent any unnecessary operations when only homogeneous boundary conditions are applied. In a more general problem one should be mindful of hanging node and periodic constraints, which may also introduce some inhomogeneities. It might then be advantageous to keep disparate objects for the different types of constraints, and merge them together once the homogeneous Dirichlet constraints have been constructed.
* 

* 
* [1.x.321]
* 
*  Since the affine constraints were finalized at the previous Newton iteration, they may not be modified directly. So we need to copy them to another temporary object and make modification there. Once we're done, we'll transfer them back to the main  [2.x.285]  object.
* 

* 
* [1.x.322]
* 
*   [1.x.323]  [1.x.324] Solving the entire block system is a bit problematic as there are no contributions to the  [2.x.286]  block, rendering it noninvertible (when using an iterative solver). Since the pressure and dilatation variables DOFs are discontinuous, we can condense them out to form a smaller displacement-only system which we will then solve and subsequently post-process to retrieve the pressure and dilatation solutions.
* 

* 
*  The static condensation process could be performed at a global level but we need the inverse of one of the blocks. However, since the pressure and dilatation variables are discontinuous, the static condensation (SC) operation can also be done on a per-cell basis and we can produce the inverse of the block-diagonal  [2.x.287]  block by inverting the local blocks. We can again use TBB to do this since each operation will be independent of one another.   
*   Using the TBB via the WorkStream class, we assemble the contributions to form  [2.x.288]  from each element's contributions. These contributions are then added to the global stiffness matrix. Given this description, the following two functions should be clear:
* 

* 
* [1.x.325]
* 
*  Now we describe the static condensation process. As per usual, we must first find out which global numbers the degrees of freedom on this cell have and reset some data structures:
* 

* 
* [1.x.326]
* 
*  We now extract the contribution of the dofs associated with the current cell to the global stiffness matrix.  The discontinuous nature of the  [2.x.289]  and  [2.x.290]  interpolations mean that their is no coupling of the local contributions at the global level. This is not the case with the  [2.x.291]  dof.  In other words,  [2.x.292] ,  [2.x.293]  and  [2.x.294] , when extracted from the global stiffness matrix are the element contributions.  This is not the case for  [2.x.295] .     
*   Note: A lower-case symbol is used to denote element stiffness matrices.
* 

* 
*  Currently the matrix corresponding to the dof associated with the current element (denoted somewhat loosely as  [2.x.296] ) is of the form:

* 
* [1.x.327]
*      
*   We now need to modify it such that it appear as

* 
* [1.x.328]
*  with  [2.x.297]  where  [2.x.298]  and  [2.x.299] .     
*   At this point, we need to take note of the fact that global data already exists in the  [2.x.300] ,  [2.x.301]  and  [2.x.302]  sub-blocks.  So if we are to modify them, we must account for the data that is already there (i.e. simply add to it or remove it if necessary).  Since the copy_local_to_global operation is a "+=" operation, we need to take this into account     
*   For the  [2.x.303]  block in particular, this means that contributions have been added from the surrounding cells, so we need to be careful when we manipulate this block.  We can't just erase the sub-blocks.     
*   This is the strategy we will employ to get the sub-blocks we want:
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 
*  -  [2.x.304] : Since we don't have access to  [2.x.305] , but we know its contribution is added to the global  [2.x.306]  matrix, we just want to add the element wise static-condensation  [2.x.307] .
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 
*  -  [2.x.308] : Similarly,  [2.x.309]  exists in the subblock. Since the copy operation is a += operation, we need to subtract the existing  [2.x.310]  submatrix in addition to "adding" that which we wish to replace it with.
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 

* 
* 
*  -  [2.x.311] : Since the global matrix is symmetric, this block is the same as the one above and we can simply use  [2.x.312]  as a substitute for this one.     
*   We first extract element data from the system matrix. So first we get the entire subblock for the cell, then extract  [2.x.313]  for the dofs associated with the current element
* 

* 
* [1.x.329]
* 
*  and next the local matrices for  [2.x.314]   [2.x.315]  and  [2.x.316] :
* 

* 
* [1.x.330]
* 
*  To get the inverse of  [2.x.317] , we invert it directly.  This operation is relatively inexpensive since  [2.x.318]  since block-diagonal.
* 

* 
* [1.x.331]
* 
*  Now we can make condensation terms to add to the  [2.x.319]  block and put them in the cell local matrix  [2.x.320] :
* 

* 
* [1.x.332]
* 
*   [2.x.321] 
* 

* 
* [1.x.333]
* 
*   [2.x.322] 
* 

* 
* [1.x.334]
* 
*   [2.x.323] 
* 

* 
* [1.x.335]
* 
*  Next we place  [2.x.324]  in the  [2.x.325]  block for post-processing.  Note again that we need to remove the contribution that already exists there.
* 

* 
* [1.x.336]
* 
*   [1.x.337]  [1.x.338] We now have all of the necessary components to use one of two possible methods to solve the linearised system. The first is to perform static condensation on an element level, which requires some alterations to the tangent matrix and RHS vector. Alternatively, the full block system can be solved by performing condensation on a global level. Below we implement both approaches.
* 

* 
* [1.x.339]
* 
*  Firstly, here is the approach using the (permanent) augmentation of the tangent matrix. For the following, recall that

* 
* [1.x.340]
*  and

* 
* [1.x.341]
*  and thus [1.x.342] where [1.x.343]
* 

* 
*  At the top, we allocate two temporary vectors to help with the static condensation, and variables to store the number of linear solver iterations and the (hopefully converged) residual.
* 

* 
* [1.x.344]
* 
*  In the first step of this function, we solve for the incremental displacement  [2.x.326] .  To this end, we perform static condensation to make  [2.x.327]  and put  [2.x.328]  in the original  [2.x.329]  block. That is, we make  [2.x.330] .
* 

* 
* [1.x.345]
* 
*   [2.x.331] 
* 

* 
* [1.x.346]
* 
*   [2.x.332] 
* 

* 
* [1.x.347]
* 
*   [2.x.333] 
* 

* 
* [1.x.348]
* 
*   [2.x.334] 
* 

* 
* [1.x.349]
* 
*   [2.x.335] 
* 

* 
* [1.x.350]
* 
*   [2.x.336] 
* 

* 
* [1.x.351]
* 
*  We've chosen by default a SSOR preconditioner as it appears to provide the fastest solver convergence characteristics for this problem on a single-thread machine.  However, this might not be true for different problem sizes.
* 

* 
* [1.x.352]
* 
*  Otherwise if the problem is small enough, a direct solver can be utilised.
* 

* 
* [1.x.353]
* 
*  Now that we have the displacement update, distribute the constraints back to the Newton update:
* 

* 
* [1.x.354]
* 
*  The next step after solving the displacement problem is to post-process to get the dilatation solution from the substitution:  [2.x.337] 
* 

* 
* [1.x.355]
* 
*   [2.x.338] 
* 

* 
* [1.x.356]
* 
*   [2.x.339] 
* 

* 
* [1.x.357]
* 
*   [2.x.340] 
* 

* 
* [1.x.358]
* 
*   [2.x.341] 
* 

* 
* [1.x.359]
* 
*  we ensure here that any Dirichlet constraints are distributed on the updated solution:
* 

* 
* [1.x.360]
* 
*  Finally we solve for the pressure update with the substitution:  [2.x.342] 
* 

* 
* [1.x.361]
* 
*   [2.x.343] 
* 

* 
* [1.x.362]
* 
*   [2.x.344] 
* 

* 
* [1.x.363]
* 
*   [2.x.345] 
* 

* 
* [1.x.364]
* 
*  and finally....  [2.x.346] 
* 

* 
* [1.x.365]
* 
*  We are now at the end, so we distribute all constrained dofs back to the Newton update:
* 

* 
* [1.x.366]
* 
*  Manual condensation of the dilatation and pressure fields on a local level, and subsequent post-processing, took quite a bit of effort to achieve. To recap, we had to produce the inverse matrix  [2.x.347] , which was permanently written into the global tangent matrix. We then permanently modified  [2.x.348]  to produce  [2.x.349] . This involved the extraction and manipulation of local sub-blocks of the tangent matrix. After solving for the displacement, the individual matrix-vector operations required to solve for dilatation and pressure were carefully implemented. Contrast these many sequence of steps to the much simpler and transparent implementation using functionality provided by the LinearOperator class.
* 

* 
*  For ease of later use, we define some aliases for blocks in the RHS vector
* 

* 
* [1.x.367]
* 
*  ... and for blocks in the Newton update vector.
* 

* 
* [1.x.368]
* 
*  We next define some linear operators for the tangent matrix sub-blocks We will exploit the symmetry of the system, so not all blocks are required.
* 

* 
* [1.x.369]
* 
*  We then construct a LinearOperator that represents the inverse of (square block)  [2.x.350] . Since it is diagonal (or, when a higher order ansatz it used, nearly diagonal), a Jacobi preconditioner is suitable.
* 

* 
* [1.x.370]
* 
*  Now we can construct that transpose of  [2.x.351]  and a linear operator that represents the condensed operations  [2.x.352]  and  [2.x.353]  and the final augmented matrix  [2.x.354] . Note that the schur_complement() operator could also be of use here, but for clarity and the purpose of demonstrating the similarities between the formulation and implementation of the linear solution scheme, we will perform these operations manually.
* 

* 
* [1.x.371]
* 
*  Lastly, we define an operator for inverse of augmented stiffness matrix, namely  [2.x.355] . Note that the preconditioner for the augmented stiffness matrix is different to the case when we use static condensation. In this instance, the preconditioner is based on a non-modified  [2.x.356] , while with the first approach we actually modified the entries of this sub-block. However, since  [2.x.357]  and  [2.x.358]  operate on the same space, it remains adequate for this problem.
* 

* 
* [1.x.372]
* 
*  Now we are in a position to solve for the displacement field. We can nest the linear operations, and the result is immediately written to the Newton update vector. It is clear that the implementation closely mimics the derivation stated in the introduction.
* 

* 
* [1.x.373]
* 
*  The operations need to post-process for the dilatation and pressure fields are just as easy to express.
* 

* 
* [1.x.374]
* 
*  Solve the full block system with a direct solver. As it is relatively robust, it may be immune to problem arising from the presence of the zero  [2.x.359]  block.
* 

* 
* [1.x.375]
* 
*  Finally, we again ensure here that any Dirichlet constraints are distributed on the updated solution:
* 

* 
* [1.x.376]
* 
*   [1.x.377]  [1.x.378] Here we present how the results are written to file to be viewed using ParaView or VisIt. The method is similar to that shown in previous tutorials so will not be discussed in detail.
* 

* 
* [1.x.379]
* 
*  Since we are dealing with a large deformation problem, it would be nice to display the result on a displaced grid!  The MappingQEulerian class linked with the DataOut class provides an interface through which this can be achieved without physically moving the grid points in the Triangulation object ourselves.  We first need to copy the solution to a temporary vector and then create the Eulerian mapping. We also specify the polynomial degree to the DataOut object in order to produce a more refined output data set when higher order polynomials are used.
* 

* 
* [1.x.380]
* 
*   [1.x.381]  [1.x.382] Lastly we provide the main driver function which appears no different to the other tutorials.
* 

* 
* [1.x.383]
* [1.x.384][1.x.385]
* 

* Firstly, we present a comparison of a series of 3-d results with thosein the literature (see Reese et al (2000)) to demonstrate that the program works as expected.
* We begin with a comparison of the convergence with mesh refinement for the  [2.x.360]  and [2.x.361]  formulations, as summarised in the figure below.The vertical displacement of the midpoint of the upper surface of the block is used to assess convergence.Both schemes demonstrate good convergence properties for varying values of the load parameter  [2.x.362] .The results agree with those in the literature.The lower-order formulation typically overestimates the displacement for low levels of refinement,while the higher-order interpolation scheme underestimates it, but be a lesser degree.This benchmark, and a series of others not shown here, give us confidence that the code is workingas it should.
*  [2.x.363] 
* 

* A typical screen output generated by running the problem is shown below.The particular case demonstrated is that of the  [2.x.364]  formulation.It is clear that, using the Newton-Raphson method, quadratic convergence of the solution is obtained.Solution convergence is achieved within 5 Newton increments for all time-steps.The converged displacement's  [2.x.365] -norm is several orders of magnitude less than the geometry scale.
* [1.x.386]
* 
* 

* 
* Using the Timer class, we can discern which parts of the code require the highest computational expense.For a case with a large number of degrees-of-freedom (i.e. a high level of refinement), a typical output of the Timer is given below.Much of the code in the tutorial has been developed based on the optimizations described,discussed and demonstrated in  [2.x.366]  and others.With over 93% of the time being spent in the linear solver, it is obvious that it may be necessaryto invest in a better solver for large three-dimensional problems.The SSOR preconditioner is not multithreaded but is effective for this class of solid problems.It may be beneficial to investigate the use of another solver such as those available through the Trilinos library.
* 

* 
* [1.x.387]
* 
* 

* We then used ParaView to visualize the results for two cases.The first was for the coarsest grid and the lowest-order interpolation method:  [2.x.367] .The second was on a refined grid using a  [2.x.368]  formulation.The vertical component of the displacement, the pressure  [2.x.369]  and the dilatation  [2.x.370]  fieldsare shown below.
* 

* For the first case it is clear that the coarse spatial discretization coupled with large displacements leads to a low quality solution(the loading ratio is   [2.x.371] ).Additionally, the pressure difference between elements is very large.The constant pressure field on the element means that the large pressure gradient is not captured.However, it should be noted that locking, which would be present in a standard  [2.x.372]  displacement formulation does not ariseeven in this poorly discretised case.The final vertical displacement of the tracked node on the top surface of the block is still within 12.5% of the converged solution.The pressure solution is very coarse and has large jumps between adjacent cells.It is clear that the volume nearest to the applied traction undergoes compression while the outer extentsof the domain are in a state of expansion.The dilatation solution field and pressure field are clearly linked,with positive dilatation indicating regions of positive pressure and negative showing regions placed in compression.As discussed in the Introduction, a compressive pressure has a negative signwhile an expansive pressure takes a positive sign.This stems from the definition of the volumetric strain energy functionand is opposite to the physically realistic interpretation of pressure.
* 

*  [2.x.373] 
* Combining spatial refinement and a higher-order interpolation scheme results in a high-quality solution.Three grid refinements coupled with a  [2.x.374]  formulation producesa result that clearly captures the mechanics of the problem.The deformation of the traction surface is well resolved.We can now observe the actual extent of the applied traction, with the maximum force being appliedat the central point of the surface causing the largest compression.Even though very high strains are experienced in the domain,especially at the boundary of the region of applied traction,the solution remains accurate.The pressure field is captured in far greater detail than before.There is a clear distinction and transition between regions of compression and expansion,and the linear approximation of the pressure field allows a refined visualizationof the pressure at the sub-element scale.It should however be noted that the pressure field remains discontinuousand could be smoothed on a continuous grid for the post-processing purposes.
* 

* 
*  [2.x.375] 
* This brief analysis of the results demonstrates that the three-field formulation is effectivein circumventing volumetric locking for highly-incompressible media.The mixed formulation is able to accurately simulate the displacement of anear-incompressible block under compression.The command-line output indicates that the volumetric change under extreme compression resulted inless than 0.01% volume change for a Poisson's ratio of 0.4999.
* In terms of run-time, the  [2.x.376]  formulation tends to be more computationally expensivethan the  [2.x.377]  for a similar number of degrees-of-freedom(produced by adding an extra grid refinement level for the lower-order interpolation).This is shown in the graph below for a batch of tests run consecutively on a single 4-core (8-thread) machine.The increase in computational time for the higher-order method is likely due tothe increased band-width required for the higher-order elements.As previously mentioned, the use of a better solver and preconditioner may mitigate theexpense of using a higher-order formulation.It was observed that for the given problem using the multithreaded Jacobi preconditioner can reduce thecomputational runtime by up to 72% (for the worst case being a higher-order formulation with a large numberof degrees-of-freedom) in comparison to the single-thread SSOR preconditioner.However, it is the author's experience that the Jacobi method of preconditioning may not be suitable forsome finite-strain problems involving alternative constitutive models.
* 

*  [2.x.378] 
* 

* Lastly, results for the displacement solution for the 2-d problem are showcased below fortwo different levels of grid refinement.It is clear that due to the extra constraints imposed by simulating in 2-d that the resultingdisplacement field, although qualitatively similar, is different to that of the 3-d case.
* 

*  [2.x.379] 
* [1.x.388][1.x.389][1.x.390]
* 

* There are a number of obvious extensions for this work:
* 
*  - Firstly, an additional constraint could be added to the free-energy  function in order to enforce a high degree of incompressibility in  materials. An additional Lagrange multiplier would be introduced,  but this could most easily be dealt with using the principle of  augmented Lagrange multipliers. This is demonstrated in  [2.x.380] Simo and  Taylor (1991)  [2.x.381] .
* 
*  - The constitutive relationship used in this  model is relatively basic. It may be beneficial to split the material  class into two separate classes, one dealing with the volumetric  response and the other the isochoric response, and produce a generic  materials class (i.e. having abstract virtual functions that derived  classes have to implement) that would allow for the addition of more complex  material models. Such models could include other hyperelastic  materials, plasticity and viscoelastic materials and others.
* 
*  - The program has been developed for solving problems on single-node  multicore machines. With a little effort, the program could be  extended to a large-scale computing environment through the use of  Petsc or Trilinos, using a similar technique to that demonstrated in   [2.x.382] . This would mostly involve changes to the setup, assembly,   [2.x.383]  and linear solver routines.
* 
*  - As this program assumes quasi-static equilibrium, extensions to  include dynamic effects would be necessary to study problems where  inertial effects are important, e.g. problems involving impact.
* 
*  - Load and solution limiting procedures may be necessary for highly  nonlinear problems. It is possible to add a linesearch algorithm to  limit the step size within a Newton increment to ensure optimum  convergence. It may also be necessary to use a load limiting method,  such as the Riks method, to solve unstable problems involving  geometric instability such as buckling and snap-through.
* 
*  - Many physical problems involve contact. It is possible to include  the effect of frictional or frictionless contact between objects  into this program. This would involve the addition of an extra term  in the free-energy functional and therefore an addition to the  assembly routine. One would also need to manage the contact problem  (detection and stress calculations) itself. An alternative to  additional penalty terms in the free-energy functional would be to  use active set methods such as the one used in  [2.x.384] .
* 
*  - The complete condensation procedure using LinearOperators has been  coded into the linear solver routine. This could also have been  achieved through the application of the schur_complement()  operator to condense out one or more of the fields in a more  automated manner.
* 
*  - Finally, adaptive mesh refinement, as demonstrated in  [2.x.385]  and   [2.x.386] , could provide additional solution accuracy.
* 

* [1.x.391][1.x.392] [2.x.387] 
* [0.x.1]