[0.x.0]!  [2.x.0]  TrilinosWrappers [2.x.1] 

* 
* [0.x.1]*
   The base class for all preconditioners based on Trilinos sparse matrices.    
*  [2.x.2]   
*  [2.x.3]   
* [0.x.2]*
     Declare the type for container size.    
* [0.x.3]*
     Standardized data struct to pipe additional flags to the     preconditioner.    
* [0.x.4]*
     Constructor. Does not do anything. The <tt>initialize</tt> function of     the derived classes will have to create the preconditioner from a given     sparse matrix.    
* [0.x.5]*
     Copy constructor.    
* [0.x.6]*
     Destructor.    
* [0.x.7]*
     Destroys the preconditioner, leaving an object like just after having     called the constructor.    
* [0.x.8]*
     Return the MPI communicator object in use with this matrix.    
* [0.x.9]*
     Sets an internal flag so that all operations performed by the matrix,     i.e., multiplications, are done in transposed order. However, this does     not reshape the matrix to transposed form directly, so care should be     taken when using this flag.        
*  [2.x.4]  Calling this function any even number of times in succession will     return the object to its original state.    
* [0.x.10]*
     Apply the preconditioner.    
* [0.x.11]*
     Apply the transpose preconditioner.    
* [0.x.12]*
     Apply the preconditioner on deal.II data structures instead of the ones     provided in the Trilinos wrapper class.    
* [0.x.13]*
     Apply the transpose preconditioner on deal.II data structures instead     of the ones provided in the Trilinos wrapper class.    
* [0.x.14]*
     Apply the preconditioner on deal.II parallel data structures instead of     the ones provided in the Trilinos wrapper class.    
* [0.x.15]*
     Apply the transpose preconditioner on deal.II parallel data structures     instead of the ones provided in the Trilinos wrapper class.    
* [0.x.16]*
      [2.x.5]  Access to underlying Trilinos data    
* [0.x.17]*
         Calling this function from an uninitialized object will cause an     exception.    
* [0.x.18]*
      [2.x.6]  Partitioners    
* [0.x.19]*
     Return the partitioning of the domain space of this matrix, i.e., the     partitioning of the vectors this matrix has to be multiplied with.    
* [0.x.20]*
     Return the partitioning of the range space of this matrix, i.e., the     partitioning of the vectors that are result from matrix-vector     products.    
* [0.x.21]*
      [2.x.7]  Exceptions    
* [0.x.22]*
     Exception.    
* [0.x.23]*
     This is a pointer to the preconditioner object that is used when     applying the preconditioner.    
* [0.x.24]*
     Internal communication pattern in case the matrix needs to be copied     from deal.II format.    
* [0.x.25]*
     Internal Trilinos map in case the matrix needs to be copied from     deal.II format.    
* [0.x.26]*
   A wrapper class for a (pointwise) Jacobi preconditioner for Trilinos   matrices. This preconditioner works both in serial and in parallel,   depending on the matrix it is based on.     The AdditionalData data structure allows to set preconditioner options.   For the Jacobi preconditioner, these options are the damping parameter   <tt>omega</tt> and a <tt>min_diagonal</tt> argument that can be used to   make the preconditioner work even if the matrix contains some zero   elements on the diagonal. The default settings are 1 for the damping   parameter and zero for the diagonal augmentation.    
*  [2.x.8]   
*  [2.x.9]   
* [0.x.27]*
     Standardized data struct to pipe additional flags to the     preconditioner. The parameter <tt>omega</tt> specifies the relaxation     parameter in the Jacobi preconditioner. The parameter     <tt>min_diagonal</tt> can be used to make the application of the     preconditioner also possible when some diagonal elements are zero. In a     default application this would mean that we divide by zero, so by     setting the parameter <tt>min_diagonal</tt> to a small nonzero value     the SOR will work on a matrix that is not too far away from the one we     want to treat.    
* [0.x.28]*
       Constructor. By default, set the damping parameter to one, and do not       modify the diagonal.      
* [0.x.29]*
       This specifies the relaxation parameter in the Jacobi preconditioner.      
* [0.x.30]*
       This specifies the minimum value the diagonal elements should have.       This might be necessary when the Jacobi preconditioner is used on       matrices with zero diagonal elements. In that case, a straight-       forward application would not be possible since we would divide by       zero.      
* [0.x.31]*
       Sets how many times the given operation should be applied during the       vmult() operation.      
* [0.x.32]*
     Take the sparse matrix the preconditioner object should be built of,     and additional flags (damping parameter, etc.) if there are any.    
* [0.x.33]*
   A wrapper class for a (pointwise) SSOR preconditioner for Trilinos   matrices. This preconditioner works both in serial and in parallel,   depending on the matrix it is based on.     The AdditionalData data structure allows to set preconditioner options.   For the SSOR preconditioner, these options are the damping/relaxation   parameter <tt>omega</tt>, a <tt>min_diagonal</tt> argument that can be   used to make the preconditioner work even if the matrix contains some   zero elements on the diagonal, and a parameter <tt>overlap</tt> that   determines if and how much overlap there should be between the matrix   partitions on the various MPI processes. The default settings are 1 for   the relaxation parameter, 0 for the diagonal augmentation and 0 for the   overlap.     Note that a parallel application of the SSOR preconditioner is actually a   block-Jacobi preconditioner with block size equal to the local matrix   size. Spoken more technically, this parallel operation is an [1.x.0] with an SSOR  [2.x.10] approximate solve [2.x.11]  as inner   solver, based on the outer parallel partitioning.    
*  [2.x.12]   
*  [2.x.13]   
* [0.x.34]*
     Standardized data struct to pipe additional flags to the     preconditioner. The parameter <tt>omega</tt> specifies the relaxation     parameter in the SSOR preconditioner. The parameter     <tt>min_diagonal</tt> can be used to make the application of the     preconditioner also possible when some diagonal elements are zero. In a     default application this would mean that we divide by zero, so by     setting the parameter <tt>min_diagonal</tt> to a small nonzero value     the SOR will work on a matrix that is not too far away from the one we     want to treat. Finally, <tt>overlap</tt> governs the overlap of the     partitions when the preconditioner runs in parallel, forming a so-     called additive Schwarz preconditioner.    
* [0.x.35]*
       Constructor. By default, set the damping parameter to one, we do not       modify the diagonal, and there is no overlap (i.e. in parallel, we       run a BlockJacobi preconditioner, where each block is inverted       approximately by an SSOR).      
* [0.x.36]*
       This specifies the (over-) relaxation parameter in the SSOR       preconditioner.      
* [0.x.37]*
       This specifies the minimum value the diagonal elements should have.       This might be necessary when the SSOR preconditioner is used on       matrices with zero diagonal elements. In that case, a straight-       forward application would not be possible since we divide by the       diagonal element.      
* [0.x.38]*
       This determines how large the overlap of the local matrix portions on       each processor in a parallel application should be.      
* [0.x.39]*
       Sets how many times the given operation should be applied during the       vmult() operation.      
* [0.x.40]*
     Take the sparse matrix the preconditioner object should be built of,     and additional flags (damping parameter, overlap in parallel     computations, etc.) if there are any.    
* [0.x.41]*
   A wrapper class for a (pointwise) SOR preconditioner for Trilinos   matrices. This preconditioner works both in serial and in parallel,   depending on the matrix it is based on.     The AdditionalData data structure allows to set preconditioner options.   For the SOR preconditioner, these options are the damping/relaxation   parameter <tt>omega</tt>, a <tt>min_diagonal</tt> argument that can be   used to make the preconditioner work even if the matrix contains some   zero elements on the diagonal, and a parameter <tt>overlap</tt> that   determines if and how much overlap there should be between the matrix   partitions on the various MPI processes. The default settings are 1 for   the relaxation parameter, 0 for the diagonal augmentation and 0 for the   overlap.     Note that a parallel application of the SOR preconditioner is actually a   block-Jacobi preconditioner with block size equal to the local matrix   size. Spoken more technically, this parallel operation is an [1.x.1] with an SOR  [2.x.14] approximate solve [2.x.15]  as inner   solver, based on the outer parallel partitioning.    
*  [2.x.16]   
*  [2.x.17]   
* [0.x.42]*
     Standardized data struct to pipe additional flags to the     preconditioner. The parameter <tt>omega</tt> specifies the relaxation     parameter in the SOR preconditioner. The parameter     <tt>min_diagonal</tt> can be used to make the application of the     preconditioner also possible when some diagonal elements are zero. In a     default application this would mean that we divide by zero, so by     setting the parameter <tt>min_diagonal</tt> to a small nonzero value     the SOR will work on a matrix that is not too far away from the one we     want to treat. Finally, <tt>overlap</tt> governs the overlap of the     partitions when the preconditioner runs in parallel, forming a so-     called additive Schwarz preconditioner.    
* [0.x.43]*
       Constructor. By default, set the damping parameter to one, we do not       modify the diagonal, and there is no overlap (i.e. in parallel, we       run a BlockJacobi preconditioner, where each block is inverted       approximately by an SOR.      
* [0.x.44]*
       This specifies the (over-) relaxation parameter in the SOR       preconditioner.      
* [0.x.45]*
       This specifies the minimum value the diagonal elements should have.       This might be necessary when the SOR preconditioner is used on       matrices with zero diagonal elements. In that case, a straight-       forward application would not be possible since we divide by the       diagonal element.      
* [0.x.46]*
       This determines how large the overlap of the local matrix portions on       each processor in a parallel application should be.      
* [0.x.47]*
       Sets how many times the given operation should be applied during the       vmult() operation.      
* [0.x.48]*
     Take the sparse matrix the preconditioner object should be built of,     and additional flags (damping parameter, overlap in parallel     computations etc.) if there are any.    
* [0.x.49]*
   A wrapper class for a block Jacobi preconditioner for Trilinos matrices.   As opposed to PreconditionSOR where each row is treated separately, this   scheme collects block of a given size and inverts a full matrix for all   these rows simultaneously. Trilinos allows to select several strategies   for selecting which rows form a block, including "linear" (i.e., divide   the local range of the matrix in slices of the block size), "greedy" or   "metis". Note that the term  [2.x.18] block Jacobi [2.x.19]  does not relate to   possible blocks in the MPI setting, but small blocks of dense matrices   extracted from the sparse matrix local to each processor.     The AdditionalData data structure allows to set preconditioner options.    
*  [2.x.20]   
*  [2.x.21]   
* [0.x.50]*
     Standardized data struct to pipe additional flags to the     preconditioner. The parameter <tt>block_size</tt> sets the size of     small blocks. It is recommended to choose this parameter not too large     (a few hundreds at most) since this implementation uses a dense matrix     for the block. The parameter <tt>block_creation_type</tt> allows to     pass the strategy for finding the blocks to Ifpack. The parameter     <tt>omega</tt> specifies the relaxation parameter in the SOR     preconditioner. The parameter <tt>min_diagonal</tt> can be used to make     the application of the preconditioner also possible when some diagonal     elements are zero. In a default application this would mean that we     divide by zero, so by setting the parameter <tt>min_diagonal</tt> to a     small nonzero value the SOR will work on a matrix that is not too far     away from the one we want to treat.    
* [0.x.51]*
       Constructor. By default, use a block size of 1, use linear       subdivision of the rows, set the damping parameter to one, and do not       modify the diagonal.      
* [0.x.52]*
       This specifies the size of blocks.      
* [0.x.53]*
       Strategy for creation of blocks passed on to Ifpack block relaxation       (variable 'partitioner: type') with this string as the given value.       Available types in Ifpack include "linear" (i.e., divide the local       range of the matrix in slices of the block size), "greedy" "metis".       For a full list, see the documentation of Ifpack.      
* [0.x.54]*
       This specifies the (over-) relaxation parameter in the Jacobi       preconditioner.      
* [0.x.55]*
       This specifies the minimum value the diagonal elements should have.       This might be necessary when the block Jacobi preconditioner is used       on matrices with zero diagonal elements. In that case, a straight-       forward application would not be possible since we divide by the       diagonal element.      
* [0.x.56]*
       Sets how many times the given operation should be applied during the       vmult() operation.      
* [0.x.57]*
     Take the sparse matrix the preconditioner object should be built of,     and additional flags (damping parameter, etc.) if there are any.    
* [0.x.58]*
   A wrapper class for a block SSOR preconditioner for Trilinos matrices. As   opposed to PreconditionSSOR where each row is treated separately (point-   wise), this scheme collects block of a given size and inverts a full   matrix for all these rows simultaneously. Trilinos allows to select   several strategies for selecting which rows form a block, including   "linear" (i.e., divide the local range of the matrix in slices of the   block size), "greedy" or "metis".     The AdditionalData data structure allows to set preconditioner options.     Note that a parallel application of this preconditioner is actually a   block-Jacobi preconditioner with (outer) block size equal to the local   matrix size. Spoken more technically, this parallel operation is an [1.x.2] with a block SSOR  [2.x.22] approximate solve [2.x.23]  as inner   solver, based on the outer parallel partitioning.    
*  [2.x.24]   
*  [2.x.25]   
* [0.x.59]*
     Standardized data struct to pipe additional flags to the     preconditioner. The parameter <tt>block_size</tt> sets the size of     small blocks. It is recommended to choose this parameter not too large     (a few hundreds at most) since this implementation uses a dense matrix     for the block. The parameter <tt>block_creation_type</tt> allows to     pass the strategy for finding the blocks to Ifpack. The parameter     <tt>omega</tt> specifies the relaxation parameter in the SSOR     preconditioner. The parameter <tt>min_diagonal</tt> can be used to make     the application of the preconditioner also possible when some diagonal     elements are zero. In a default application this would mean that we     divide by zero, so by setting the parameter <tt>min_diagonal</tt> to a     small nonzero value the SOR will work on a matrix that is not too far     away from the one we want to treat. Finally, <tt>overlap</tt> governs     the overlap of the partitions when the preconditioner runs in parallel,     forming a so-called additive Schwarz preconditioner.    
* [0.x.60]*
       Constructor. By default, use a block size of 1, use linear       subdivision of the rows, set the damping parameter to one, we do not       modify the diagonal, and there is no overlap (i.e. in parallel, we       run a BlockJacobi preconditioner, where each block is inverted       approximately by a block SOR).      
* [0.x.61]*
       This specifies the size of blocks.      
* [0.x.62]*
       Strategy for creation of blocks passed on to Ifpack block relaxation       (variable 'partitioner: type') with this string as the given value.       Available types in Ifpack include "linear" (i.e., divide the local       range of the matrix in slices of the block size), "greedy" "metis".       For a full list, see the documentation of Ifpack.      
* [0.x.63]*
       This specifies the (over-) relaxation parameter in the SOR       preconditioner.      
* [0.x.64]*
       This specifies the minimum value the diagonal elements should have.       This might be necessary when the SSOR preconditioner is used on       matrices with zero diagonal elements. In that case, a straight-       forward application would not be possible since we divide by the       diagonal element.      
* [0.x.65]*
       This determines how large the overlap of the local matrix portions on       each processor in a parallel application should be.      
* [0.x.66]*
       Sets how many times the given operation should be applied during the       vmult() operation.      
* [0.x.67]*
     Take the sparse matrix the preconditioner object should be built of,     and additional flags (damping parameter, overlap in parallel     computations, etc.) if there are any.    
* [0.x.68]*
   A wrapper class for a block SOR preconditioner for Trilinos matrices. As   opposed to PreconditionSOR where each row is treated separately, this   scheme collects block of a given size and inverts a full matrix for all   these rows simultaneously. Trilinos allows to select several strategies   for selecting which rows form a block, including "linear" (i.e., divide   the local range of the matrix in slices of the block size), "greedy" or   "metis".     The AdditionalData data structure allows to set preconditioner options.     Note that a parallel application of this preconditioner is actually a   block-Jacobi preconditioner with (outer) block size equal to the local   matrix size. Spoken more technically, this parallel operation is an [1.x.3] with a block SOR  [2.x.26] approximate solve [2.x.27]  as inner   solver, based on the outer parallel partitioning.    
*  [2.x.28]   
*  [2.x.29]   
* [0.x.69]*
     Standardized data struct to pipe additional flags to the     preconditioner. The parameter <tt>block_size</tt> sets the size of     small blocks. It is recommended to choose this parameter not too large     (a few hundreds at most) since this implementation uses a dense matrix     for the block. The parameter <tt>block_creation_type</tt> allows to     pass the strategy for finding the blocks to Ifpack. The parameter     <tt>omega</tt> specifies the relaxation parameter in the SOR     preconditioner. The parameter <tt>min_diagonal</tt> can be used to make     the application of the preconditioner also possible when some diagonal     elements are zero. In a default application this would mean that we     divide by zero, so by setting the parameter <tt>min_diagonal</tt> to a     small nonzero value the SOR will work on a matrix that is not too far     away from the one we want to treat. Finally, <tt>overlap</tt> governs     the overlap of the partitions when the preconditioner runs in parallel,     forming a so-called additive Schwarz preconditioner.    
* [0.x.70]*
       Constructor. By default, use a block size of 1, use linear       subdivision of the rows, set the damping parameter to one, we do not       modify the diagonal, and there is no overlap (i.e. in parallel, we       run a BlockJacobi preconditioner, where each block is inverted       approximately by a block SOR).      
* [0.x.71]*
       This specifies the size of blocks.      
* [0.x.72]*
       Strategy for creation of blocks passed on to Ifpack block relaxation       (variable 'partitioner: type') with this string as the given value.       Available types in Ifpack include "linear" (i.e., divide the local       range of the matrix in slices of the block size), "greedy" "metis".       For a full list, see the documentation of Ifpack.      
* [0.x.73]*
       This specifies the (over-) relaxation parameter in the SOR       preconditioner.      
* [0.x.74]*
       This specifies the minimum value the diagonal elements should have.       This might be necessary when the SOR preconditioner is used on       matrices with zero diagonal elements. In that case, a straight-       forward application would not be possible since we divide by the       diagonal element.      
* [0.x.75]*
       This determines how large the overlap of the local matrix portions on       each processor in a parallel application should be.      
* [0.x.76]*
       Sets how many times the given operation should be applied during the       vmult() operation.      
* [0.x.77]*
     Take the sparse matrix the preconditioner object should be built of,     and additional flags (damping parameter, overlap in parallel     computations etc.) if there are any.    
* [0.x.78]*
   A wrapper class for an incomplete Cholesky factorization (IC)   preconditioner for  [2.x.30]  symmetric Trilinos matrices. This preconditioner   works both in serial and in parallel, depending on the matrix it is based   on. In general, an incomplete factorization does not take all fill-in   elements that would appear in a full factorization (that is the basis for   a direct solve). Trilinos allows to set the amount of fill-in elements,   governed by the additional data argument <tt>ic_fill</tt>, so one can   gradually choose between a factorization on the sparse matrix structure   only (<tt>ic_fill=0</tt>) to a full factorization (<tt>ic_fill</tt> in   the range of 10 to 50, depending on the spatial dimension of the PDE   problem and the degree of the finite element basis functions; generally,   more required fill-in elements require this parameter to be set to a   higher integer value).     The AdditionalData data structure allows to set preconditioner options.   Besides the fill-in argument, these options are some options for   perturbations (see the documentation of the AdditionalData structure for   details), and a parameter <tt>overlap</tt> that determines if and how   much overlap there should be between the matrix partitions on the various   MPI processes.  The default settings are 0 for the additional fill-in, 0   for the absolute augmentation tolerance, 1 for the relative augmentation   tolerance, 0 for the overlap.     Note that a parallel application of the IC preconditioner is actually a   block-Jacobi preconditioner with block size equal to the local matrix   size. Spoken more technically, this parallel operation is an [1.x.4] with an IC  [2.x.31] approximate solve [2.x.32]  as inner solver,   based on the (outer) parallel partitioning.    
*  [2.x.33]   
*  [2.x.34]   
* [0.x.79]*
     Standardized data struct to pipe additional parameters to the     preconditioner. The Trilinos IC decomposition allows for some fill-in,     so it actually is a threshold incomplete Cholesky factorization. The     amount of fill-in, and hence, the amount of memory used by this     preconditioner, is controlled by the parameter <tt>ic_fill</tt>, which     specifies this as a double. When forming the preconditioner, for     certain problems bad conditioning (or just bad luck) can cause the     preconditioner to be very poorly conditioned. Hence it can help to add     diagonal perturbations to the original matrix and form the     preconditioner for this slightly better matrix. <tt>ic_atol</tt> is an     absolute perturbation that is added to the diagonal before forming the     prec, and <tt>ic_rtol</tt> is a scaling factor  [2.x.35] . The last     parameter specifies the overlap of the partitions when the     preconditioner runs in parallel.    
* [0.x.80]*
       Constructor. By default, set the drop tolerance to 0, the level of       extra fill-ins is set to be zero (just use the matrix structure, do       not generate any additional fill-in), the tolerance level are 0 and       1, respectively, and the overlap in case of a parallel execution is       zero. This overlap in a block-application of the IC in the parallel       case makes the preconditioner a so-called additive Schwarz       preconditioner.      
* [0.x.81]*
       This specifies the amount of additional fill-in elements besides the       sparse matrix structure. When <tt>ic_fill</tt> is large, this means       that many fill-ins will be added, so that the IC preconditioner comes       closer to a direct sparse Cholesky decomposition. Note, however, that       this will drastically increase the memory requirement, especially       when the preconditioner is used in 3D.      
* [0.x.82]*
       This specifies the amount of an absolute perturbation that will be       added to the diagonal of the matrix, which sometimes can help to get       better preconditioners.      
* [0.x.83]*
       This specifies the factor by which the diagonal of the matrix will be       scaled, which sometimes can help to get better preconditioners.      
* [0.x.84]*
       This determines how large the overlap of the local matrix portions on       each processor in a parallel application should be.      
* [0.x.85]*
     Initialize function. Takes the matrix the preconditioner should be     computed of, and additional flags if there are any.    
* [0.x.86]*
   A wrapper class for an incomplete LU factorization (ILU(k))   preconditioner for Trilinos matrices. This preconditioner works both in   serial and in parallel, depending on the matrix it is based on. In   general, an incomplete factorization does not take all fill-in elements   that would appear in a full factorization (that is the basis for a direct   solve). Trilinos allows to set the amount of fill-in elements, governed   by the additional data argument <tt>ilu_fill</tt>, so one can gradually   choose between a factorization on the sparse matrix structure only   (<tt>ilu_fill=0</tt>) to a full factorization (<tt>ilu_fill</tt> in the   range of 10 to 50, depending on the spatial dimension of the PDE problem   and the degree of the finite element basis functions; generally, more   required fill-in elements require this parameter to be set to a higher   integer value).     The AdditionalData data structure allows to set preconditioner options.   See the documentation of the AdditionalData structure for details.     Note that a parallel application of the ILU preconditioner is actually a   block-Jacobi preconditioner with block size equal to the local matrix   size. Spoken more technically, this parallel operation is an [1.x.5] with an ILU  [2.x.36] approximate solve [2.x.37]  as inner   solver, based on the (outer) parallel partitioning.    
*  [2.x.38]   
*  [2.x.39]   
* [0.x.87]*
     Standardized data struct to pipe additional parameters to the     preconditioner:      [2.x.40]           [2.x.41]   [2.x.42]  This specifies the amount of additional fill-in     elements besides the original sparse matrix structure. If  [2.x.43]  is  [2.x.44]      fill, the sparsity pattern of  [2.x.45]  is used for the storage of the     result of the Gaussian elimination. This is known as ILU( [2.x.46] ) in the     literature.  When  [2.x.47]  is large, the preconditioner comes closer to     a (direct) sparse LU decomposition. Note, however, that this will     drastically increase the memory requirement, especially when the     preconditioner is used in 3D.          [2.x.48]   [2.x.49]  and  [2.x.50]  These two parameters allow     perturbation of the diagonal of the matrix, which sometimes can help to     get better preconditioners especially in the case of bad conditioning.     Before factorization, the diagonal entry  [2.x.51]  is replaced by      [2.x.52] , where  [2.x.53]  is the     absolute threshold  [2.x.54]  and  [2.x.55]  is the relative     threshold  [2.x.56]  The default values ( [2.x.57] ,  [2.x.58] )     therefore use the original, unmodified diagonal entry. Suggested values     are in the order of  [2.x.59]  to  [2.x.60]  for  [2.x.61]  and 1.01 for      [2.x.62]           [2.x.63]   [2.x.64]  This determines how large the overlap of the local     matrix portions on each processor in a parallel application should be.     An overlap of 0 corresponds to a block diagonal decomposition on each     processor, an overlap of 1 will additionally include a row j if there     is a nonzero entry in column j in one of the own rows. Higher overlap     numbers work accordingly in a recursive fashion. Increasing  [2.x.65]      will increase communication and storage cost. According to the IFPACK     documentation, an overlap of 1 is often effective and values of more     than 3 are rarely needed.          [2.x.66]     
* [0.x.88]*
       Constructor with default values for all parameters.      
* [0.x.89]*
       Additional fill-in, see class documentation above.      
* [0.x.90]*
       The amount of perturbation to add to diagonal entries. See the class       documentation above for details.      
* [0.x.91]*
       Scaling actor for diagonal entries. See the class documentation above       for details.      
* [0.x.92]*
       Overlap between processors. See the class documentation for details.      
* [0.x.93]*
     Initialize function. Takes the matrix which is used to form the     preconditioner, and additional flags if there are any.    
* [0.x.94]*
   A wrapper class for a thresholded incomplete LU factorization (ILU-T)   preconditioner for Trilinos matrices. This preconditioner works both in   serial and in parallel, depending on the matrix it is based on. In   general, an incomplete factorization does not take all fill-in elements   that would appear in a full factorization (that is the basis for a direct   solve). For the ILU-T preconditioner, the parameter <tt>ilut_drop</tt>   lets the user specify which elements should be dropped (i.e., should not   be part of the incomplete decomposition). Trilinos calculates first the   complete factorization for one row, and then skips those elements that   are lower than the threshold. This is the main difference to the non-   thresholded ILU preconditioner, where the parameter <tt>ilut_fill</tt>   governs the incomplete factorization structure. This parameter is   available here as well, but provides only some extra information here.     The AdditionalData data structure allows to set preconditioner options.   Besides the fill-in arguments, these options are some options for   perturbations (see the documentation of the AdditionalData structure for   details), and a parameter <tt>overlap</tt> that determines if and how   much overlap there should be between the matrix partitions on the various   MPI processes. The default settings are 0 for the additional fill-in, 0   for the absolute augmentation tolerance, 1 for the relative augmentation   tolerance, 0 for the overlap.     Note that a parallel application of the ILU-T preconditioner is actually   a block-Jacobi preconditioner with block size equal to the local matrix   size. Spoken more technically, this parallel operation is an [1.x.6] with an ILU  [2.x.67] approximate solve [2.x.68]  as inner   solver, based on the (outer) parallel partitioning.    
*  [2.x.69]   
*  [2.x.70]   
* [0.x.95]*
     Standardized data struct to pipe additional parameters to the     preconditioner. The Trilinos ILU-T decomposition allows for some fill-     in, so it actually is a threshold incomplete LU factorization. The     amount of fill-in, and hence, the amount of memory used by this     preconditioner, is controlled by the parameters <tt>ilut_drop</tt> and     <tt>ilut_fill</tt>, which specifies a threshold about which values     should form the incomplete factorization and the level of additional     fill-in. When forming the preconditioner, for certain problems bad     conditioning (or just bad luck) can cause the preconditioner to be very     poorly conditioned. Hence it can help to add diagonal perturbations to     the original matrix and form the preconditioner for this slightly     better matrix. <tt>ilut_atol</tt> is an absolute perturbation that is     added to the diagonal before forming the prec, and <tt>ilu_rtol</tt> is     a scaling factor  [2.x.71] . The last parameter specifies the     overlap of the partitions when the preconditioner runs in parallel.    
* [0.x.96]*
       Constructor. By default, no element will be dropped, the level of       extra fill-ins is set to be zero (just use the matrix structure, do       not generate any additional fill-in except the one that results from       non-dropping large elements), the tolerance level are 0 and 1,       respectively, and the overlap in case of a parallel execution is       zero. This overlap in a block-application of the ILU in the parallel       case makes the preconditioner a so-called additive Schwarz       preconditioner.      
* [0.x.97]*
       This specifies the relative size of elements which should be dropped       when forming an incomplete LU decomposition with threshold.      
* [0.x.98]*
       This specifies the amount of additional fill-in elements besides the       sparse matrix structure. When <tt>ilu_fill</tt> is large, this means       that many fill-ins will be added, so that the ILU preconditioner       comes closer to a (direct) sparse LU decomposition. Note, however,       that this will drastically increase the memory requirement,       especially when the preconditioner is used in 3D.      
* [0.x.99]*
       This specifies the amount of an absolute perturbation that will be       added to the diagonal of the matrix, which sometimes can help to get       better preconditioners.      
* [0.x.100]*
       This specifies the factor by which the diagonal of the matrix will be       scaled, which sometimes can help to get better preconditioners.      
* [0.x.101]*
       This determines how large the overlap of the local matrix portions on       each processor in a parallel application should be.      
* [0.x.102]*
     Initialize function. Takes the matrix which is used to form the     preconditioner, and additional flags if there are any.    
* [0.x.103]*
   A wrapper class for a sparse direct LU decomposition on parallel blocks   for Trilinos matrices. When run in serial, this corresponds to a direct   solve on the matrix.     The AdditionalData data structure allows to set preconditioner options.     Note that a parallel application of the block direct solve preconditioner   is actually a block-Jacobi preconditioner with block size equal to the   local matrix size. Spoken more technically, this parallel operation is an   [1.x.7] with an  [2.x.72] exact solve [2.x.73]  as inner solver, based on   the (outer) parallel partitioning.    
*  [2.x.74]   
*  [2.x.75]   
* [0.x.104]*
     Standardized data struct to pipe additional parameters to the     preconditioner.    
* [0.x.105]*
       Constructor.      
* [0.x.106]*
       This determines how large the overlap of the local matrix portions on       each processor in a parallel application should be.      
* [0.x.107]*
     Initialize function. Takes the matrix which is used to form the     preconditioner, and additional flags if there are any.    
* [0.x.108]*
   A wrapper class for a Chebyshev preconditioner for Trilinos matrices.     The AdditionalData data structure allows to set preconditioner options.    
*  [2.x.76]   
*  [2.x.77]   
* [0.x.109]*
     Standardized data struct to pipe additional parameters to the     preconditioner.    
* [0.x.110]*
       Constructor.      
* [0.x.111]*
       This determines the degree of the Chebyshev polynomial. The degree of       the polynomial gives the number of matrix-vector products to be       performed for one application of the vmult() operation.      
* [0.x.112]*
       This sets the maximum eigenvalue of the matrix, which needs to be set       properly for appropriate performance of the Chebyshev preconditioner.      
* [0.x.113]*
       This sets the ratio between the maximum and the minimum eigenvalue.      
* [0.x.114]*
       This sets the minimum eigenvalue, which is an optional parameter only       used internally for checking whether we use an identity matrix.      
* [0.x.115]*
       This sets a threshold below which the diagonal element will not be       inverted in the Chebyshev algorithm.      
* [0.x.116]*
       When this flag is set to <tt>true</tt>, it enables the method       <tt>vmult(dst, src)</tt> to use non-zero data in the vector       <tt>dst</tt>, appending to it the Chebyshev corrections. This can be       useful in some situations (e.g. when used for high-frequency error       smoothing), but not the way the solver classes expect a       preconditioner to work (where one ignores the content in <tt>dst</tt>       for the preconditioner application). The user should really know what       they are doing when touching this flag.      
* [0.x.117]*
     Initialize function. Takes the matrix which is used to form the     preconditioner, and additional flags if there are any.    
* [0.x.118]*
   This class implements an algebraic multigrid (AMG) preconditioner based   on the Trilinos ML implementation, which is a black-box preconditioner   that works well for many PDE-based linear problems.  What this class does   is twofold.  When the initialize() function is invoked, a ML   preconditioner object is created based on the matrix that we want the   preconditioner to be based on. A call of the respective    [2.x.78]  function does call the respective operation in the   Trilinos package, where it is called  [2.x.79] . Use of   this class is explained in the  [2.x.80]  tutorial program.     Since the Trilinos objects we want to use are heavily dependent on Epetra   objects, we recommend using this class in conjunction with Trilinos   (Epetra) sparse matrices and vectors. There is support for use with   matrices of the  [2.x.81]  class and corresponding vectors,   too, but this requires generating a copy of the matrix, which is slower   and takes (much) more memory. When doing such a copy operation, we can   still profit from the fact that some of the entries in the preconditioner   matrix are zero and hence can be neglected.     The implementation is able to distinguish between matrices from elliptic   problems and convection dominated problems. We use the standard options   provided by Trilinos ML for elliptic problems, except that we use a   Chebyshev smoother instead of a symmetric Gauss-Seidel smoother.  For   most elliptic problems, Chebyshev provides a better damping of high   frequencies (in the algebraic sense) than Gauss-Seidel (SSOR), and is   faster (Chebyshev requires only some matrix-vector products, whereas SSOR   requires substitutions which are more expensive). Moreover, Chebyshev is   perfectly parallel in the sense that it does not degenerate when used on   many processors. SSOR, on the other hand, gets more Jacobi-like on many   processors.     For proper functionality of this class we recommend using Trilinos v9.0   and higher. Older versions may have problems with generating the coarse-   matrix structure when using matrices with many nonzero entries per row   (i.e., matrices stemming from higher order finite element   discretizations).    
*  [2.x.82]   
*  [2.x.83]   
* [0.x.119]*
     A data structure that is used to control details of how the algebraic     multigrid is set up. The flags detailed in here are then passed to the     Trilinos ML implementation. A structure of the current type are passed     to the constructor of PreconditionAMG.    
* [0.x.120]*
       Constructor. By default, we pretend to work on elliptic problems with       linear finite elements on a scalar equation.             Making use of the  [2.x.84]  function, the        [2.x.85]  vector can be initialized for a given field in the       following manner:            
* [1.x.8]
*       
* [0.x.121]*
       Fill in a  [2.x.86]  that can be used to initialize the       AMG preconditioner.             The  [2.x.87]  is used in conjunction with the  [2.x.88]  to       configure the null space settings for the preconditioner.       The  [2.x.89]  are initialized by this function, and       must remain in scope until  [2.x.90]  has been       called.            
*  [2.x.91]  The set parameters reflect the current settings in this       object, with various options being set both directly though the state       of the member variables (e.g. the "smoother: type") as well as       indirectly (e.g. the "aggregation: type"). If you wish to have       fine-grained control over the configuration of the AMG preconditioner,       then you can create the parameter list using this function (which       conveniently sets the null space of the operator), change the relevant       settings, and use the amended parameters list as an argument to        [2.x.92]  instead of the AdditionalData object       itself.             See the documentation for the       [1.x.9] for details on what options are available for       modification.            
*  [2.x.93]  Any user-defined parameters that are not in conflict with those       set by this data structure will be retained.      
* [0.x.122]*
       Fill in a parameter list that can be used to initialize the       AMG preconditioner.            
*  [2.x.94]  Any user-defined parameters that are not in conflict with those       set by this data structure will be retained.      
* [0.x.123]*
       Configure the null space setting in the  [2.x.95]  for       the input  [2.x.96]  based on the state of the  [2.x.97]        variable.      
* [0.x.124]*
       Configure the null space setting in the  [2.x.98]  for       the input  [2.x.99]  based on the state of the  [2.x.100]        variable.      
* [0.x.125]*
       Determines whether the AMG preconditioner should be optimized for       elliptic problems (ML option smoothed aggregation SA, using a       Chebyshev smoother) or for non-elliptic problems (ML option non-       symmetric smoothed aggregation NSSA, smoother is SSOR with       underrelaxation).      
* [0.x.126]*
       Determines whether the matrix that the preconditioner is built upon       is generated from linear or higher-order elements.      
* [0.x.127]*
       Defines how many multigrid cycles should be performed by the       preconditioner.      
* [0.x.128]*
       Defines whether a w-cycle should be used instead of the standard       setting of a v-cycle.      
* [0.x.129]*
       This threshold tells the AMG setup how the coarsening should be       performed. In the AMG used by ML, all points that strongly couple       with the tentative coarse-level point form one aggregate. The term        [2.x.101] strong coupling [2.x.102]  is controlled by the variable       <tt>aggregation_threshold</tt>, meaning that all elements that are       not smaller than <tt>aggregation_threshold</tt> times the diagonal       element do couple strongly.      
* [0.x.130]*
       Specifies the constant modes (near null space) of the matrix. This       parameter tells AMG whether we work on a scalar equation (where the       near null space only consists of ones, and default value is OK) or on       a vector-valued equation. For vector-valued equation problem with       <tt>n_component</tt>, the provided  [2.x.103]  should fulfill       the following requirements:        [2.x.104]         [2.x.105]   n_component.size() == <tt>n_component</tt>  [2.x.106]         [2.x.107]   n_component[*].size() == n_dof_local or n_component[*].size()       == n_dof_global  [2.x.108]         [2.x.109]   n_component[<tt>ic</tt>][<tt>id</tt>] ==       "<tt>id</tt> [2.x.110] th [2.x.111]  DoF is corresponding to component <tt>ic</tt>        [2.x.112]         [2.x.113]       
* [0.x.131]*
       Determines how many sweeps of the smoother should be performed. When       the flag <tt>elliptic</tt> is set to <tt>true</tt>, i.e., for       elliptic or almost elliptic problems, the polynomial degree of the       Chebyshev smoother is set to <tt>smoother_sweeps</tt>. The term       sweeps refers to the number of matrix-vector products performed in       the Chebyshev case. In the non-elliptic case,       <tt>smoother_sweeps</tt> sets the number of SSOR relaxation sweeps       for post-smoothing to be performed.      
* [0.x.132]*
       Determines the overlap in the SSOR/Chebyshev error smoother when run       in parallel.      
* [0.x.133]*
       If this flag is set to <tt>true</tt>, then internal information from       the ML preconditioner is printed to screen. This can be useful when       debugging the preconditioner.      
* [0.x.134]*
       Determines which smoother to use for the AMG cycle. Possibilities for       smoother_type are the following:        [2.x.114]         [2.x.115]   "Aztec"  [2.x.116]         [2.x.117]   "IFPACK"  [2.x.118]         [2.x.119]   "Jacobi"  [2.x.120]         [2.x.121]   "ML symmetric Gauss-Seidel"  [2.x.122]         [2.x.123]   "symmetric Gauss-Seidel"  [2.x.124]         [2.x.125]   "ML Gauss-Seidel"  [2.x.126]         [2.x.127]   "Gauss-Seidel"  [2.x.128]         [2.x.129]   "block Gauss-Seidel"  [2.x.130]         [2.x.131]   "symmetric block Gauss-Seidel"  [2.x.132]         [2.x.133]   "Chebyshev"  [2.x.134]         [2.x.135]   "MLS"  [2.x.136]         [2.x.137]   "Hiptmair"  [2.x.138]         [2.x.139]   "Amesos-KLU"  [2.x.140]         [2.x.141]   "Amesos-Superlu"  [2.x.142]         [2.x.143]   "Amesos-UMFPACK"  [2.x.144]         [2.x.145]   "Amesos-Superludist"  [2.x.146]         [2.x.147]   "Amesos-MUMPS"  [2.x.148]         [2.x.149]   "user-defined"  [2.x.150]         [2.x.151]   "SuperLU"  [2.x.152]         [2.x.153]   "IFPACK-Chebyshev"  [2.x.154]         [2.x.155]   "self"  [2.x.156]         [2.x.157]   "do-nothing"  [2.x.158]         [2.x.159]   "IC"  [2.x.160]         [2.x.161]   "ICT"  [2.x.162]         [2.x.163]   "ILU"  [2.x.164]         [2.x.165]   "ILUT"  [2.x.166]         [2.x.167]   "Block Chebyshev"  [2.x.168]         [2.x.169]   "IFPACK-Block Chebyshev"  [2.x.170]         [2.x.171]       
* [0.x.135]*
       Determines which solver to use on the coarsest level. The same       settings as for the smoother type are possible.      
* [0.x.136]*
     Destructor.    
* [0.x.137]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. The function uses the matrix     format specified in  [2.x.172]     
* [0.x.138]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. As opposed to the other initialize     function above, this function uses an abstract interface to an object     of type Epetra_RowMatrix which allows a user to pass quite general     objects to the ML preconditioner.         This initialization routine is useful in cases where the operator to be     preconditioned is not a  [2.x.173]  object but still     allows getting a copy of the entries in each of the locally owned matrix     rows (method ExtractMyRowCopy) and implements a matrix-vector product     (methods Multiply or Apply). An example are operators which provide     faster matrix-vector multiplications than possible with matrix entries     (matrix-free methods). These implementations can be beneficially     combined with Chebyshev smoothers that only perform matrix-vector     products. The interface class Epetra_RowMatrix is very flexible to     enable this kind of implementation.    
* [0.x.139]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. The function uses the matrix     format specified in  [2.x.174]          This function is similar to the one above, but allows the user     to set all the options of the Trilinos ML preconditioner. In     order to find out about all the options for ML, we refer to the     [1.x.10]. In particular, users need to follow the     ML instructions in case a vector-valued problem ought to be     solved.    
* [0.x.140]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. As opposed to the other initialize     function above, this function uses an abstract interface to an object     of type Epetra_RowMatrix which allows a user to pass quite general     objects to the ML preconditioner.    
* [0.x.141]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. This function takes a deal.II     matrix and copies the content into a Trilinos matrix, so the function     can be considered rather inefficient.    
* [0.x.142]*
     This function can be used for a faster recalculation of the     preconditioner construction when the matrix entries underlying the     preconditioner have changed, but the matrix sparsity pattern has     remained the same. What this function does is taking the already     generated coarsening structure, computing the AMG prolongation and     restriction according to a smoothed aggregation strategy and then     building the whole multilevel hierarchy. This function can be     considerably faster than the initialize function, since the coarsening     pattern is usually the most difficult thing to do when setting up the     AMG ML preconditioner.    
* [0.x.143]*
     Destroys the preconditioner, leaving an object like just after having     called the constructor.    
* [0.x.144]*
     Prints an estimate of the memory consumption of this class.    
* [0.x.145]*
     A copy of the deal.II matrix into Trilinos format.    
* [0.x.146]*
   This class implements an algebraic multigrid (AMG) preconditioner based   on the Trilinos MueLu implementation, which is a black-box preconditioner   that works well for many PDE-based linear problems. The interface of   PreconditionerAMGMueLu is the same as the interface of PreconditionerAMG   except for the higher_order_elements parameter which does not exist in   PreconditionerAMGMueLu.    
*  [2.x.175]  You need to configure Trilinos with MueLU support for this   preconditioner to work.    
*  [2.x.176]  At the moment 64bit-indices are not supported.      [2.x.177]  This interface should not be considered as stable.    
*  [2.x.178]   
*  [2.x.179]   
* [0.x.147]*
     A data structure that is used to control details of how the algebraic     multigrid is set up. The flags detailed in here are then passed to the     Trilinos MueLu implementation. A structure of the current type are     passed to the constructor of PreconditionAMGMueLu.    
* [0.x.148]*
       Constructor. By default, we pretend to work on elliptic problems with       linear finite elements on a scalar equation.      
* [0.x.149]*
       Determines whether the AMG preconditioner should be optimized for       elliptic problems (MueLu option smoothed aggregation SA, using a       Chebyshev smoother) or for non-elliptic problems (MueLu option non-       symmetric smoothed aggregation NSSA, smoother is SSOR with       underrelaxation).      
* [0.x.150]*
       Defines how many multigrid cycles should be performed by the       preconditioner.      
* [0.x.151]*
       Defines whether a w-cycle should be used instead of the standard       setting of a v-cycle.      
* [0.x.152]*
       This threshold tells the AMG setup how the coarsening should be       performed. In the AMG used by MueLu, all points that strongly couple       with the tentative coarse-level point form one aggregate. The term        [2.x.180] strong coupling [2.x.181]  is controlled by the variable       <tt>aggregation_threshold</tt>, meaning that all elements that are       not smaller than <tt>aggregation_threshold</tt> times the diagonal       element do couple strongly.      
* [0.x.153]*
       Specifies the constant modes (near null space) of the matrix. This       parameter tells AMG whether we work on a scalar equation (where the       near null space only consists of ones) or on a vector-valued       equation.      
* [0.x.154]*
       Determines how many sweeps of the smoother should be performed. When       the flag <tt>elliptic</tt> is set to <tt>true</tt>, i.e., for       elliptic or almost elliptic problems, the polynomial degree of the       Chebyshev smoother is set to <tt>smoother_sweeps</tt>. The term       sweeps refers to the number of matrix-vector products performed in       the Chebyshev case. In the non-elliptic case,       <tt>smoother_sweeps</tt> sets the number of SSOR relaxation sweeps       for post-smoothing to be performed.      
* [0.x.155]*
       Determines the overlap in the SSOR/Chebyshev error smoother when run       in parallel.      
* [0.x.156]*
       If this flag is set to <tt>true</tt>, then internal information from       the ML preconditioner is printed to screen. This can be useful when       debugging the preconditioner.      
* [0.x.157]*
       Determines which smoother to use for the AMG cycle. Possibilities for       smoother_type are the following:        [2.x.182]         [2.x.183]   "Aztec"  [2.x.184]         [2.x.185]   "IFPACK"  [2.x.186]         [2.x.187]   "Jacobi"  [2.x.188]         [2.x.189]   "ML symmetric Gauss-Seidel"  [2.x.190]         [2.x.191]   "symmetric Gauss-Seidel"  [2.x.192]         [2.x.193]   "ML Gauss-Seidel"  [2.x.194]         [2.x.195]   "Gauss-Seidel"  [2.x.196]         [2.x.197]   "block Gauss-Seidel"  [2.x.198]         [2.x.199]   "symmetric block Gauss-Seidel"  [2.x.200]         [2.x.201]   "Chebyshev"  [2.x.202]         [2.x.203]   "MLS"  [2.x.204]         [2.x.205]   "Hiptmair"  [2.x.206]         [2.x.207]   "Amesos-KLU"  [2.x.208]         [2.x.209]   "Amesos-Superlu"  [2.x.210]         [2.x.211]   "Amesos-UMFPACK"  [2.x.212]         [2.x.213]   "Amesos-Superludist"  [2.x.214]         [2.x.215]   "Amesos-MUMPS"  [2.x.216]         [2.x.217]   "user-defined"  [2.x.218]         [2.x.219]   "SuperLU"  [2.x.220]         [2.x.221]   "IFPACK-Chebyshev"  [2.x.222]         [2.x.223]   "self"  [2.x.224]         [2.x.225]   "do-nothing"  [2.x.226]         [2.x.227]   "IC"  [2.x.228]         [2.x.229]   "ICT"  [2.x.230]         [2.x.231]   "ILU"  [2.x.232]         [2.x.233]   "ILUT"  [2.x.234]         [2.x.235]   "Block Chebyshev"  [2.x.236]         [2.x.237]   "IFPACK-Block Chebyshev"  [2.x.238]         [2.x.239]       
* [0.x.158]*
       Determines which solver to use on the coarsest level. The same       settings as for the smoother type are possible.      
* [0.x.159]*
     Constructor.    
* [0.x.160]*
     Destructor.    
* [0.x.161]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. The function uses the matrix     format specified in  [2.x.240]     
* [0.x.162]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. As opposed to the other initialize     function above, this function uses an object of type     Epetra_CrsMatrixCrs.    
* [0.x.163]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. The function uses the matrix     format specified in  [2.x.241]          This function is similar to the one above, but allows the user     to set most of the options of the Trilinos ML     preconditioner. In order to find out about all the options for     ML, we refer to the [1.x.11]. Not all ML options have a corresponding     MueLu option.    
* [0.x.164]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. As opposed to the other initialize     function above, this function uses an object of type Epetra_CrsMatrix.    
* [0.x.165]*
     Let Trilinos compute a multilevel hierarchy for the solution of a     linear system with the given matrix. This function takes a deal.ii     matrix and copies the content into a Trilinos matrix, so the function     can be considered rather inefficient.    
* [0.x.166]*
     Destroys the preconditioner, leaving an object like just after having     called the constructor.    
* [0.x.167]*
     Prints an estimate of the memory consumption of this class.    
* [0.x.168]*
     A copy of the deal.II matrix into Trilinos format.    
* [0.x.169]*
   A wrapper class for an identity preconditioner for Trilinos matrices.    
*  [2.x.242]   
*  [2.x.243]   
* [0.x.170]*
     This function is only present to provide the interface of a     preconditioner to be handed to a smoother.  This does nothing.    
* [0.x.171]*
     The matrix argument is ignored and here just for compatibility with more     complex preconditioners.    
*  [2.x.244]  This function must be called when this preconditioner is to be     wrapped in a LinearOperator without an exemplar materix.    
* [0.x.172]*
     Apply the preconditioner, i.e., dst = src.    
* [0.x.173]*
     Apply the transport conditioner, i.e., dst = src.    
* [0.x.174]*
     Apply the preconditioner on deal.II data structures instead of the ones     provided in the Trilinos wrapper class, i.e., dst = src.    
* [0.x.175]*
     Apply the transpose preconditioner on deal.II data structures instead     of the ones provided in the Trilinos wrapper class, i.e. dst = src.    
* [0.x.176]*
     Apply the preconditioner on deal.II parallel data structures instead of     the ones provided in the Trilinos wrapper class, i.e., dst = src.    
* [0.x.177]*
     Apply the transpose preconditioner on deal.II parallel data structures     instead of the ones provided in the Trilinos wrapper class, i.e., dst =     src.    
* [0.x.178]