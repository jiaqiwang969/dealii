include/deal.II-translator/numerics/adaptation_strategies_0.txt
[0.x.0]*
 When data is transferred during adaptation, it is not trivial to decide how to process data from former cells on the old mesh that have been changed into current cells on the new mesh. Or in other words, how data should be stored in the cells on the adapted mesh.
*  In this namespace, we offer a few strategies that cope with this problem. Such strategies can be passed to the CellDataTransfer and  [2.x.0]  constructors.

* 
* [0.x.1]*
   For refinement, all strategies take the parent cell and its associated   data. They return a vector containing data for each individual child that   the parent cell will be refined to.     The ordering of values in the vector for children data corresponds to the   index when calling  [2.x.1]   
* [0.x.2]*
     Return a vector containing copies of data of the parent cell for each     child.         [1.x.0]    
* [0.x.3]*
     Return a vector which contains data of the parent cell being equally     divided among all children.         [1.x.1]         This strategy preserves the  [2.x.2] -norm of the corresponding global data     Vector before and after adaptation.    
* [0.x.4]*
     Return a vector which contains squared data of the parent cell being     equally divided among the squares of all children.         [1.x.2]         This strategy preserves the  [2.x.3] -norm of the corresponding global data     Vector before and after adaptation.    
* [0.x.5]*
   For coarsening, all strategies take the parent cell and a vector of data   that belonged to its former children. They return the value that will be   assigned to the parent cell.     The ordering of values in the vector for children data corresponds to the   index when calling  [2.x.4]   
* [0.x.6]*
     Check if data on all children match, and return value of the first child.         [1.x.3]    
* [0.x.7]*
     Return sum of data on all children.         [1.x.4]         This strategy preserves the  [2.x.5] -norm of the corresponding global data     vector before and after adaptation.    
* [0.x.8]*
     Return  [2.x.6] -norm of data on all children.         [1.x.5]         This strategy preserves the  [2.x.7] -norm of the corresponding global data     vector before and after adaptation.    
* [0.x.9]*
     Return mean value of data on all children.         [1.x.6]    
* [0.x.10]*
     Return maximum value of data on all children.         [1.x.7]    
* [0.x.11]

include/deal.II-translator/numerics/cell_data_transfer.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/cell_data_transfer_0.txt
[0.x.0]*
 Transfer data that is associated with each active cell (like error indicators) while refining and/or coarsening a triangulation.
*  This class therefore does for cell-related information what SolutionTransfer does for the values of degrees of freedom defined on a Triangulation.
*  A non-distributed container (like Vector or  [2.x.0]  has to be provided, which holds the cell-wise data in the same order as active cells are traversed. In other words, each entry corresponds to the cell with the same index  [2.x.1]  and the container has to be of size  [2.x.2] 
*  [1.x.0]
*  The following code snippet demonstrates how to transfer cell-related data across refinement/coarsening of the registered triangulation.
* 

* 
* [1.x.1]
* 
*  When using a  [2.x.3]  we need to ensure that we have the global data available in our local vector before refinement happened. We can achieve this as follows:
* 

* 
* [1.x.2]
* 
*  For the parallel distributed case, a designated class  [2.x.4]  is available. Please refer to this particular class when using a  [2.x.5] 
* 

* 
*  [2.x.6]  See the documentation of SolutionTransfer for matching code snippets   for transfer.
* 

* 
*  [2.x.7] 

* 
* [0.x.1]*
   An alias that defines the data type of provided container template.  
* [0.x.2]*
   Constructor.      [2.x.8]  triangulation The triangulation on which all operations will     happen. At the time when this constructor is called, the refinement     in question has not happened yet.    [2.x.9]  refinement_strategy %Function deciding how data will be stored     on refined cells from its parent cell.    [2.x.10]  coarsening_strategy %Function deciding which data to store on     a cell whose children will get coarsened into.  
* [0.x.3]*
   Prepare the current object for coarsening and refinement.     Stores the active_cell_indices of all active cells on the associated   triangulation and attribute them to either persisting, refined or coarsened   cells.  
* [0.x.4]*
   Transfer the information from the previous mesh to the updated one.     Data from the previous mesh supplied by  [2.x.11]  will be transferred to the updated   mesh and stored in  [2.x.12]   [2.x.13]  has to provide enough space to hold the   transferred data, i.e. has to be of size `triangulation.n_active_cells()`.  
* [0.x.5]*
   Pointer to the triangulation to work with.  
* [0.x.6]*
   %Function deciding how data will be stored on refined cells from its parent   cell.  
* [0.x.7]*
   %Function deciding on how to process data from children to be stored on the   parent cell.  
* [0.x.8]*
   Container to temporarily store the iterator and active cell index   of cells that persist.  
* [0.x.9]*
   Container to temporarily store the iterator and active cell index   of cells that will be refined.  
* [0.x.10]*
   Container to temporarily store the iterator of parent cells that will   remain after coarsening along with the active cell indices of the   corresponding children cells.  
* [0.x.11]*
   Number of active cells on the initial triangulation that has not been   refined yet.     It will be set in prepare_for_coarsening_and_refinement() and used to   validate user inputs after refinement happened (only in debug mode).  
* [0.x.12]

include/deal.II-translator/numerics/data_component_interpretation_0.txt
[0.x.0]*
 A namespace solely for the declaration of the  [2.x.0]  enum.

* 
* [0.x.1]*
   The members of this enum are used to describe the logical interpretation   of what the various components of a vector-valued data set mean. For   example, if one has a finite element for the Stokes equations in 2d,   representing components  [2.x.1] , one would like to indicate that the   first two,  [2.x.2]  and  [2.x.3] , represent a logical vector so that later on when   we generate graphical output we can hand them off to a visualization   program that will automatically know to render them as a vector field,   rather than as two separate and independent scalar fields.     By passing a set of enums of the current kind to the    [2.x.4]  functions, this can be achieved.     See the  [2.x.5]  tutorial program for an example on how this information   can be used in practice.  
* [0.x.2]*
     Indicates that a component of a data set corresponds to a scalar field     independent of the others.    
* [0.x.3]*
     Indicates that a component of a data set is part of a vector-valued     quantity.    
* [0.x.4]*
     Indicates that a component of a data set is part of a tensor-valued     (2nd order) quantity.    
* [0.x.5]

include/deal.II-translator/numerics/data_out_0.txt
[0.x.0]*
     A derived class for use in the DataOut class. This is a class for the     AdditionalData kind of data structure discussed in the documentation of     the WorkStream context.    
* [0.x.1]*
 This class is the main class to provide output of data described by finite element fields defined on a collection of cells.
*  This class is an actual implementation of the functionality proposed by the DataOut_DoFData class. It offers a function build_patches() that generates the data to be written in some graphics format. Most of the interface and an example of its use is described in the documentation of this base class.
*  The only thing this class offers is the function build_patches() which loops over all cells of the triangulation stored by the attach_dof_handler() function of the base class (with the exception of cells of  [2.x.0]  objects that are not owned by the current processor) and converts the data on these to actual patches which are the objects that are later output by the functions of the base classes. You can give a parameter to the function which determines how many subdivisions in each coordinate direction are to be performed, i.e. of how many subcells each patch shall consist. The default is one, but you may want to choose a higher number for higher order elements, for example two for quadratic elements, three for cubic elements, and so on. (See  [2.x.1]  for an example.) The purpose of this parameter is because most graphics programs do not allow to specify higher order polynomial functions in the file formats: only data at vertices can be plotted and is then shown as a bilinear interpolation within the interior of cells. This may be insufficient if you have higher order finite elements, and the only way to achieve better output is to subdivide each cell of the mesh into several cells for graphical output. Of course, what you get to see is still a bilinear interpolation on each cell of the output (where these cells are not subdivisions of the cells of the triangulation in use) due to the same limitations in output formats, but at least a bilinear interpolation of a higher order polynomial on a finer mesh.
*  Note that after having called build_patches() once, you can call one or more of the write() functions of DataOutInterface. You can therefore output the same data in more than one format without having to rebuild the patches.
* 

*  [1.x.0]
*  The base classes of this class, DataOutBase, DataOutInterface and DataOut_DoFData offer several interfaces of their own. Refer to the DataOutBase class's documentation for a discussion of the different output formats presently supported, DataOutInterface for ways of selecting which format to use upon output at run-time and without the need to adapt your program when new formats become available, as well as for flags to determine aspects of output. The DataOut_DoFData() class's documentation has an example of using nodal data to generate output.
* 

*  [1.x.1]
*  By default, this class produces patches for all active cells. Sometimes, this is not what you want, maybe because there are simply too many (and too small to be seen individually) or because you only want to see a certain region of the domain (for example only in the fluid part of the domain in  [2.x.2] ), or for some other reason.
*  For this, internally build_patches() does not generate the sequence of cells to be converted into patches itself, but relies on the two private  [2.x.3]  objects first_cell_function() and next_cell_function(). By default, they return the first active cell, and the next active cell, respectively. But this can be changed using the set_cell_selection() function that allows you to replace this behavior. What set_cell_selection() wants to know is how you want to pick out the first cell on which output should be generated, and how given one cell on which output is generated you want to pick the next cell.
*  This may, for example, include only cells that are in parts of a domain (e.g., if you don't care about the solution elsewhere, think for example a buffer region in which you attenuate outgoing waves in the Perfectly Matched Layer method) or if you don't want output to be generated at all levels of an adaptively refined mesh because this creates too much data (in this case, the set of cells returned by your implementations of the `first_cell` and `next_cell` arguments to set_cell_selection() will include non-active cells, and  [2.x.4]  will simply take interpolated values of the solution instead of the exact values on these cells children for output).
* 

* 
*  [2.x.5] 

* 
* [0.x.2]*
   Typedef to the iterator type of the dof handler class under   consideration.  
* [0.x.3]*
   The type of the function object returning the first cell as used in   set_cell_selection().  
* [0.x.4]*
   The type of the function object returning the next cell as used in   set_cell_selection().  
* [0.x.5]*
   Enumeration describing the part of the domain in which cells   should be written with curved boundaries. In reality, no file   format we are aware of really supports curved boundaries, but   this can be emulated by plotting edges as a sequence of straight   lines (and faces in 3d as a collection of bilinear patches) if    [2.x.6]  is called with a number of subdivisions   greater than 1.     The elements of this enumeration then describe for which cells    [2.x.7]  will query the manifold or boundary   description for curved geometries.  
* [0.x.6]*
     The geometry or boundary description will never be queried for     curved geometries. This means that even if you have more than     one subdivision per cell (see  [2.x.8]  for what     exactly this means) and even if the geometry really is curved,     each cell will still be subdivided as if it was just a bi- or     trilinear cell.    
* [0.x.7]*
     The geometry or boundary description will be queried for curved     geometries for cells located at the boundary, i.e., for cells     that have at least one face at the boundary. This is sufficient     if you have not attached a manifold description to the     interiors of cells but only to faces at the boundary.    
* [0.x.8]*
     The geometry description will be queried for all cells and all     faces, whether they are at the boundary or not. This option is     appropriate if you have attached a manifold object to cells     (not only to boundary faces).    
* [0.x.9]*
   Constructor.  
* [0.x.10]*
   This is the central function of this class since it builds the list of   patches to be written by the low-level functions of the base class. A   patch is, in essence, some intermediate representation of the data on   each cell of a triangulation and DoFHandler object that can then be used   to write files in some format that is readable by visualization programs.     You can find an overview of the use of this function in the general   documentation of this class. An example is also provided in the   documentation of this class's base class DataOut_DoFData.      [2.x.9]  n_subdivisions A parameter that determines how many "patches" this   function will build out of every cell. If you do not specify this value   in calling, or provide the default value zero, then this is interpreted   as  [2.x.10]  which most of the time will be   equal to one (unless you have set it to something else). The purpose of   this parameter is to subdivide each cell of the mesh into  [2.x.11]  "patches" in 2d, and  [2.x.12]  (if passed the value 2, 3, etc) where each patch   represents the data from a regular subdivision of the cell into equal   parts. Most of the times, this is not necessary and outputting one patch   per cell is exactly what you want to plot the solution. That said, the   data we write into files for visualization can only represent (bi-,   tri)linear data on each cell, and most visualization programs can in fact   only visualize this kind of data. That's good enough if you work with   (bi-, tri)linear finite elements, in which case what you get to see is   exactly what has been computed. On the other hand, if you work with (bi-,   tri)quadratic elements, then what is written into the output file is just   a (bi-, tri)linear interpolation onto the current mesh, i.e., only the   values at the vertices. If this is not good enough, you can, for example,   specify  [2.x.13]  equal to 2 to plot the solution on a once-   refined mesh, or if set to 3, on a mesh where each cell is represented by   3-by-3 patches. On each of these smaller patches, given the limitations   of output formats, the data is still linearly interpolated, but a linear   interpolation of quadratic data on a finer mesh is still a better   representation of the actual quadratic surface than on the original mesh.   In other words, using this parameter can not help you plot the solution   exactly, but it can get you closer if you use finite elements of higher   polynomial degree.    
*  [2.x.14]  Specifying `n_subdivisions>1` is useful when using higher order     finite elements, but in general it does not actually result in the     visualization showing higher order polynomial surfaces
* 
*  -  rather, you     just get a (bi-, tri-)linear interpolation of that higher order     surface on a finer mesh. However, when outputting the solution in the     VTK and VTU file formats via  [2.x.15]  or      [2.x.16]  (where DataOutInterface is a base     class of the current class) as we often do in the tutorials,     you can provide a set of flags via the  [2.x.17]      structure that includes the      [2.x.18]  flag. When set, the     subdivisions produced by this function will be interpreted as     support points for a higher order polynomial that will then actually     be visualized as such. This is shown in  [2.x.19] , for example. It     is worth noting, however, that this requires a     sufficiently new version of one of the VTK-based visualization     programs.  
* [0.x.11]*
   Same as above, except that the additional first parameter defines a   mapping that is to be used in the generation of output. If   <tt>n_subdivisions>1</tt>, the points interior of subdivided patches   which originate from cells at the boundary of the domain can be computed   using the mapping, i.e., a higher order mapping leads to a representation   of a curved boundary by using more subdivisions. Some mappings like   MappingQEulerian result in curved cells in the interior of the domain.   The same is true if you have attached a manifold description to   the cells of a triangulation (see    [2.x.20]  "Manifolds"   for more information). However, there is no easy way to query the mapping   or manifold whether it really does lead to curved cells.   Thus the last argument  [2.x.21]  takes one of three values   resulting in no curved cells at all, curved cells at the boundary   (default) or curved cells in the whole domain. For more information   about these three options, see the CurvedCellRegion enum's   description.     Even for non-curved cells, the mapping argument can be used for   Eulerian mappings (see class MappingQ1Eulerian) where a mapping is used   not only to determine the position of points interior to a cell, but also   of the vertices.  It offers an opportunity to watch the solution on a   deformed triangulation on which the computation was actually carried out,   even if the mesh is internally stored in its undeformed configuration and   the deformation is only tracked by an additional vector that holds the   deformation of each vertex.  
* [0.x.12]*
   Same as above, but for  [2.x.22]   
* [0.x.13]*
   A function that allows selecting for which cells output should be   generated. This function takes two arguments, both  [2.x.23]    objects that can be used what the first cell on which output is   generated is supposed to be, and what given one cell the next   function is supposed to be. Through these function objects,   it is possible to select a subset of cells on which output should   be produced (e.g., only selecting those cells that belong to a   part of the domain
* 
*  -  say, the fluid domain in a code such as  [2.x.24] ),   or to completely changewhere* output is produced (e.g., to produce   output on non-active cells of a multigrid hierarchy or if the finest   level of a mesh is so fine that generating graphical output would lead   to an overwhelming amount of data).      [2.x.25]  first_cell A function object that takes as argument the     triangulation this class works on and that should return the first cell     on which output should be generated.    [2.x.26]  next_cell A function object that takes as arguments the     triangulation as well as the last cell     on which output was generated, and that should return the next     cell on which output should be generated. If there is no next     cell, i.e., if the input argument to the `next_cell` function object     is the last cell on which output is to be generated, then `next_cell`     must return `triangulation.end()`.     These function objects are not difficult to write, but also not immediately   obvious. As a consequence, there is a second variation of this function   that takes a IteratorFilter argument and generates the corresponding   functions itself.    
*  [2.x.27]  This function is also called in the constructor of this class,     where the default behavior is set. By default, this class will select all      [2.x.28]  "locally owned"     and      [2.x.29]  "active"     cells for output.    
*  [2.x.30]  If you have cell data (in contrast to nodal, or dof, data) such as     error indicators, then you must make sure that the `first_cell` and     `next_cell` function objects only walk over active cells, since cell data     cannot be interpolated to a coarser cell. If you do have cell data and     use this pair of functions and they return a non-active cell, then an     exception will be thrown.  
* [0.x.14]*
   A variation of the previous function that selects a subset of all   cells for output based on the filter encoded in the FilteredIterator   object given as argument. A typical way to generate the argument   is via the make_filtered_iterator() function.     Alternatively, since FilteredIterator objects can be created from   just a predicate (i.e., a function object that returns a `bool`), it is   possible to call this function with just a lambda function, which will then   automatically be converted to a FilteredIterator object. For example, the   following piece of code works:  
* [1.x.2]
*    In this case, the lambda function selects all of those cells that are    [2.x.31]  "active"   and whose subdomain id is zero. These will then be the only cells on   which output is generated.    
*  [2.x.32]  Not all filters will result in subsets of cells for which     output can actually be generated. For example, if you are working     on parallel meshes where data is only available on some cells,     then you better make sure that your `filtered_iterator` only     loops over the      [2.x.33]  "locally owned"     cells; likewise, in most cases you will probably only want to work on      [2.x.34]  "active"     cells since this is where the solution actually lives. In particular,     if you have added vectors that represent data defined on cells     (instead of nodal data), then you can not generate output on non-active     cells and your iterator filter should reflect this.  
* [0.x.15]*
   Return the two function objects that are in use for determining the first   and the next cell as set by set_cell_selection().  
* [0.x.16]*
   A function object that is used to select what the first cell is going to   be on which to generate graphical output. See the set_cell_selection()   function for more information.  
* [0.x.17]*
   A function object that is used to select what the next cell is going to   be on which to generate graphical output, given a previous cell. See   the set_cell_selection() function for more information.  
* [0.x.18]*
   Build one patch. This function is called in a WorkStream context.     The first argument here is the iterator, the second the scratch data   object. All following are tied to particular values when calling    [2.x.35]  The function does not take a CopyData object but   rather allocates one on its own stack for memory access efficiency   reasons.  
* [0.x.19]*
    [2.x.36]  Use  [2.x.37]  without the DoFHandlerType template   instead.  
* [0.x.20]

include/deal.II-translator/numerics/data_out_dof_data.templates_0.txt
[0.x.0]*
     Generate evaluation points on a simplex with arbitrary number of     subdivisions.    
* [0.x.1]*
     Helper function to create evaluation points recursively with     subdivisions=0,1,2 being the base case:                                            +                                            |\                                +           +-+                                |\          |\|\                      +         +-+         +-+-+                      |\        |\|\        |\|\|\              +       +-+       +-+-+       +-+-+-+              |\      |\|\      |\|\|\      |\|\|\|\        +     +-+     +-+-+     +-+-+-+     +-+-+-+-+            0      1        2          3            4        ^      ^                   |            |        |      |                   |            |        +--------------------------+            |               |                                |               +--------------------------------+    
* [0.x.2]*
     Specialization for triangles.    
* [0.x.3]*
     Set up vectors of FEValues and FEFaceValues needed inside of     ParallelDataBase and return the maximum number of quadrature points     needed to allocate enough memory for the scratch data.    
* [0.x.4]*
     In a WorkStream context, use this function to append the patch computed     by the parallel stage to the array of patches.    
* [0.x.5]*
     Extract the specified component of a number. This template is used when     the given value is assumed to be a real scalar, so asking for the real     part is the only valid choice for the second argument.    
* [0.x.6]*
     Extract the specified component of a number. This template is used when     the given value is a complex number    
* [0.x.7]*
     Helper class templated on vector type to allow different implementations     to extract information from a vector.    
* [0.x.8]*
       extract the  [2.x.0]  from  [2.x.1]  and put them into  [2.x.2]       
* [0.x.9]*
     Class that stores a pointer to a vector of type equal to the template     argument, and provides the functions to extract data from it.    
* [0.x.10]*
       Constructor. Give a list of names for the individual components of       the vector and their interpretation as scalar or vector data. This       constructor assumes that no postprocessor is going to be used.      
* [0.x.11]*
       Constructor when a data postprocessor is going to be used. In that       case, the names and vector declarations are going to be acquired from       the postprocessor.      
* [0.x.12]*
       Assuming that the stored vector is a cell vector, extract the given       element from it.      
* [0.x.13]*
       Given a FEValuesBase object, extract the values on the present cell       from the vector we actually store.      
* [0.x.14]*
       Given a FEValuesBase object, extract the values on the present cell       from the vector we actually store. This function does the same as the       one above but for vector-valued finite elements.      
* [0.x.15]*
       Given a FEValuesBase object, extract the gradients on the present       cell from the vector we actually store.      
* [0.x.16]*
       Given a FEValuesBase object, extract the gradients on the present       cell from the vector we actually store. This function does the same       as the one above but for vector-valued finite elements.      
* [0.x.17]*
       Given a FEValuesBase object, extract the second derivatives on the       present cell from the vector we actually store.      
* [0.x.18]*
       Given a FEValuesBase object, extract the second derivatives on the       present cell from the vector we actually store. This function does       the same as the one above but for vector-valued finite elements.      
* [0.x.19]*
       Return whether the data represented by (a derived class of) this object       represents a complex-valued (as opposed to real-valued) information.      
* [0.x.20]*
       Clear all references to the vectors.      
* [0.x.21]*
       Determine an estimate for the memory consumption (in bytes) of this       object.      
* [0.x.22]*
       Pointer to the data vector. Note that ownership of the vector pointed       to remains with the caller of this class.      
* [0.x.23]*
     Like DataEntry, but used to look up data from multigrid computations.     Data will use level-DoF indices to look up in a     MGLevelObject<VectorType> given on the specific level instead of     interpolating data to coarser cells.    
* [0.x.24]*
       Given a FEValuesBase object, extract the values on the present cell       from the vector we actually store. This function does the same as the       one above but for vector-valued finite elements.      
* [0.x.25]*
       Given a FEValuesBase object, extract the gradients on the present       cell from the vector we actually store.      
* [0.x.26]*
       Given a FEValuesBase object, extract the gradients on the present       cell from the vector we actually store. This function does the same       as the one above but for vector-valued finite elements.      
* [0.x.27]*
       Given a FEValuesBase object, extract the second derivatives on the       present cell from the vector we actually store.      
* [0.x.28]*
       Given a FEValuesBase object, extract the second derivatives on the       present cell from the vector we actually store. This function does       the same as the one above but for vector-valued finite elements.      
* [0.x.29]*
       Return whether the data represented by (a derived class of) this object       represents a complex-valued (as opposed to real-valued) information.      
* [0.x.30]*
       Clear all references to the vectors.      
* [0.x.31]*
       Determine an estimate for the memory consumption (in bytes) of this       object.      
* [0.x.32]

include/deal.II-translator/numerics/data_out_dof_data_0.txt
[0.x.0]*
   A namespace for exceptions that are used throughout the DataOut*
   collection of classes.  
* [0.x.1]*
     Exception    
* [0.x.2]*
     Exception    
* [0.x.3]*
     Exception    
* [0.x.4]*
     Exception    
* [0.x.5]*
     Exception    
* [0.x.6]*
     Exception    
* [0.x.7]*
     Exception    
* [0.x.8]*
     Exception    
* [0.x.9]*
     Exception    
* [0.x.10]*
     The DataEntry classes abstract away the concrete data type of vectors     users can attach to DataOut (and similar) objects and allow the     underlying DataOut functions to query for individual elements of solution     vectors without having to know the concrete vector type. This avoids that     DataOut has to know what vectors are being used, but it has the downside     that DataOut also doesn't know the underlying scalar type of these     vectors.         If the underlying scalar types all represent real numbers (in the     mathematical sense
* 
*  -  i.e., the scalar type would be  [2.x.0]       [2.x.1]  etc) then that is not a problem
* 
*  -  DataOut simply     receives the values of individual vector components as  [2.x.2]      objects. On the other hand, if the vector type uses a  [2.x.3]      scalar type, then DataEntry returning a  [2.x.4]  for a vector     entry is not sufficient
* 
*  -  we need to provide DataOut with a way     to query both the real and the imaginary part, so that they can     be written into output files separately.         This enum allows DataOut to tell a DataEntry function which component     of a vector entry it wants to query, i.e., whether it wants the real     or the imaginary part of a vector entry.    
* [0.x.11]*
     For each vector that has been added through the add_data_vector()     functions, we need to keep track of a pointer to it, and allow data     extraction from it when we generate patches. Unfortunately, we need to     do this for a number of different vector types. Fortunately, they all     have the same interface. So the way we go is to have a base class that     provides the functions to access the vector's information, and to have     a derived template class that can be instantiated for each vector type.     Since the vectors all have the same interface, this is no big problem,     as they can all use the same general templatized code.        
*  [2.x.5]  This class is an example of the     [1.x.0] design pattern.    
* [0.x.12]*
       Constructor. Give a list of names for the individual components of       the vector and their interpretation as scalar or vector data. This       constructor assumes that no postprocessor is going to be used.      
* [0.x.13]*
       Constructor when a data postprocessor is going to be used. In that       case, the names and vector declarations are going to be acquired from       the postprocessor.      
* [0.x.14]*
       Destructor made virtual.      
* [0.x.15]*
       Assuming that the stored vector is a cell vector, extract the given       element from it.      
* [0.x.16]*
       Given a FEValuesBase object, extract the values on the present cell       from the vector we actually store.      
* [0.x.17]*
       Given a FEValuesBase object, extract the values on the present cell       from the vector we actually store. This function does the same as the       one above but for vector-valued finite elements.      
* [0.x.18]*
       Given a FEValuesBase object, extract the gradients on the present       cell from the vector we actually store.      
* [0.x.19]*
       Given a FEValuesBase object, extract the gradients on the present       cell from the vector we actually store. This function does the same       as the one above but for vector-valued finite elements.      
* [0.x.20]*
       Given a FEValuesBase object, extract the second derivatives on the       present cell from the vector we actually store.      
* [0.x.21]*
       Given a FEValuesBase object, extract the second derivatives on the       present cell from the vector we actually store. This function does       the same as the one above but for vector-valued finite elements.      
* [0.x.22]*
       Return whether the data represented by (a derived class of) this object       represents a complex-valued (as opposed to real-valued) information.      
* [0.x.23]*
       Clear all references to the vectors.      
* [0.x.24]*
       Determine an estimate for the memory consumption (in bytes) of this       object.      
* [0.x.25]*
       Pointer to the DoFHandler object that the vector is based on.      
* [0.x.26]*
       Names of the components of this data vector.      
* [0.x.27]*
       A vector that for each of the n_output_variables variables of the       current data set indicates whether they are scalar fields, parts of a       vector-field, or any of the other supported kinds of data.      
* [0.x.28]*
       Pointer to a DataPostprocessing object which shall be applied to this       data vector.      
* [0.x.29]*
       Number of output variables this dataset provides (either number of       components in vector valued function / data vector or number of       computed quantities, if DataPostprocessor is applied). This variable       is determined via and thus equivalent to <tt>names.size()</tt>.      
* [0.x.30]*
     A data structure that holds all data needed in one thread when building     patches in parallel. These data structures are created globally rather     than on each cell to avoid allocation of memory in the threads. This is     a base class for the AdditionalData kind of data structure discussed in     the documentation of the WorkStream class.         The  [2.x.6]  is an array that stores for     index <tt>[i][j]</tt> the number of the patch that associated with the     cell with index  [2.x.7]  on level  [2.x.8]  This information is set up prior to     generation of the patches, and is needed to generate neighborship     information.         This structure is used by several of the DataOut* classes, which     derived their own ParallelData classes from it for additional fields.    
* [0.x.31]*
 This is an abstract class which provides the functionality to generate patches for output by base classes from data vectors on a grid. It allows to attach one or more pointers to a DoFHandler and attached node and cell data denoting functions on the grid which shall later be written in any of the implemented data formats.
* 

*  [1.x.1]
*  The user visible interface of this class allows the user to specify data in two different ways. One is to make a DoFHandler object known to this class and to add data vectors that all correspond to this DoFHandler or the grid cells which will later be written to a file in some format. The second approach is to pass a DoFHandler object along with the vector. This allows setting data from different DoFHandlers in a neat way (of course, they both need to be based on the same triangulation). Instead of pondering about the different functions, an example for the first kind is probably the best explanation:

* 
* [1.x.2]
* 
*  attach_dof_handler() tells this class that all future operations are to take place with the DoFHandler object and the triangulation it lives on. We then add the solution vector and the error estimator; note that they have different dimensions, because the solution is a nodal vector, here consisting of two components ("x-displacement" and "y-displacement") while the error estimator probably is a vector holding cell data. When attaching a data vector, you have to give a name to each component of the vector, which is done through an object of type <tt>vector<string></tt> as second argument; if only one component is in the vector, for example if we are adding cell data as in the second case, or if the finite element used by the DoFHandler has only one component, then you can use the second add_data_vector() function which takes a  [2.x.9]  instead of the <tt>vector<string></tt>.
*  The add_data_vector() functions have additional arguments (with default values) that can be used to specify certain transformations. In particular, it allows to attach DataPostprocessor arguments to compute derived information from a data vector at each point at which the field will be evaluated so that it can be written to a file (for example, the Mach number in hypersonic flow can be computed from density and velocities;  [2.x.10]  also shows an example); another piece of information specified through arguments with default values is how certain output components should be interpreted, i.e. whether each component of the data is logically an independent scalar field, or whether some of them together form logically a vector-field (see the  [2.x.11]  enum, and the  [2.x.12]  " [2.x.13] " tutorial program).
*  This class does not copy the vector given to it through the add_data_vector() functions, for memory consumption reasons. It only stores a reference to it, so it is in your responsibility to make sure that the data vectors exist long enough.
*  After adding all data vectors, you need to call a function which generates the patches (i.e., some intermediate data representation) for output from the stored data. Derived classes name this function build_patches(). Finally, you write() the data in one format or other, to a file.
*  In the example above, an object of type DataOut was used, i.e. an object of a derived class. This is necessary since the current class does not provide means to actually generate the patches, only aids to store and access data. Any real functionality is implemented in derived classes such as DataOut.
*  Note that the base class of this class, DataOutInterface offers several functions to ease programming with run-time determinable output formats (i.e. you need not use a fixed format by calling  [2.x.14]  in the above example, but you can select it by a run-time parameter without having to write the <tt>if () ... else ...</tt> clauses yourself), and also functions and classes offering ways to control the appearance of the output by setting flags for each output format.
* 

*  [1.x.3]
*  What this class lacks is a way to produce the patches for output itself, from the stored data and degree of freedom information. Since this task is often application dependent it is left to derived classes. For example, in many applications, it might be wanted to limit the depth of output to a certain number of refinement levels and write data from finer cells only in a way interpolated to coarser cells, to reduce the amount of output. Also, it might be wanted to use different numbers of subdivisions on different cells when forming a patch, for example to accomplish for different polynomial degrees of the trial space on different cells. Also, the output need not necessarily consist of a patch for each cell, but might be made up of patches for faces, of other things. Take a look at derived classes to what is possible in this respect.
*  For this reason, it is left to a derived class to provide a function, named usually build_patches() or the like, which fills the #patches array of this class.
*  Regarding the templates of this class, it needs three values: first the space dimension in which the triangulation and the DoF handler operate, second the dimension of the objects which the patches represent.  Although in most cases they are equal, there are also classes for which this does not hold, for example if one outputs the result of a computation exploiting rotational symmetry in the original domain (in which the space dimension of the output would be one higher than that of the DoF handler, see the DataOut_Rotation() class), or one might conceive that one could write a class that only outputs the solution on a cut through the domain, in which case the space dimension of the output is less than that of the DoF handler. The last template argument denotes the dimension of the space into which the patches are embedded; usually, this dimension is the same as the dimensio of the patches themselves (which is also the default value of the template parameter), but there might be cases where this is not so. For example, in the DataOut_Faces() class, patches are generated from faces of the triangulation. Thus, the dimension of the patch is one less than the dimension of the embedding space, which is, in this case, equal to the dimension of the triangulation and DoF handler. However, for the cut through the domain mentioned above, if the cut is a straight one, then the cut can be embedded into a space of one dimension lower than the dimension of the triangulation, so that the last template parameter has the same value as the second one.
* 

* 
*  [2.x.15] 

* 
* [0.x.32]*
   Typedef to the iterator type of the dof handler class under   consideration.  
* [0.x.33]*
   Type describing what the vector given to add_data_vector() is: a vector   that has one entry per degree of freedom in a DoFHandler object (such as   solution vectors), or one entry per cell in the triangulation underlying   the DoFHandler object (such as error per cell data). The value   #type_automatic tells add_data_vector() to find out itself (see the   documentation of add_data_vector() for the method used).  
* [0.x.34]*
     Data vector entries are associated to degrees of freedom    
* [0.x.35]*
     Data vector entries are one per grid cell    
* [0.x.36]*
     Find out automatically    
* [0.x.37]*
   Constructor  
* [0.x.38]*
   Destructor.  
* [0.x.39]*
   Designate a dof handler to be used to extract geometry data and the   mapping between nodes and node values. This call is not necessary if all   added data vectors are supplemented with a DoFHandler argument.     This call is optional: If you add data vectors with specified DoFHandler   object, then that contains all information needed to generate the output.  
* [0.x.40]*
   Designate a triangulation to be used to extract geometry data and the   mapping between nodes and node values.     This call is optional: If you add data vectors with specified DoFHandler   object, then that contains all information needed to generate the output.   This call is useful when you only output cell vectors and no DoFHandler   at all, in which case it provides the geometry.  
* [0.x.41]*
   Add a data vector together with its name.     A pointer to the vector is stored, so you have to make sure the vector   exists at that address at least as long as you call the <tt>write_*</tt>   functions.     It is assumed that the vector has the same number of components as there   are degrees of freedom in the dof handler, in which case it is assumed to   be a vector storing nodal data; or the size may be the number of active   cells on the present grid, in which case it is assumed to be a cell data   vector. As the number of degrees of freedom and of cells is usually not   equal, the function can determine itself which type of vector it is   given. However, there are corner cases where this automatic determination   does not work.  One example is if you compute with piecewise constant   elements and have a scalar solution, then there are as many cells as   there are degrees of freedom (though they may be numbered differently).   Another possibility is if you have a 1d mesh embedded in 2d space and the   mesh consists of a closed curve of cells; in this case, there are as many   nodes as there are cells, and when using a Q1 element you will have as   many degrees of freedom as there are cells.  In these cases, you can   change the last argument of the function from its default value   #type_automatic to either #type_dof_data or #type_cell_data, depending on   what the vector represents. Apart from such corner cases, you can leave   the argument at its default value and let the function determine the type   of the vector itself.     If it is a vector holding DoF data, the names given shall be one for each   component of the underlying finite element.  If it is a finite element   composed of only one subelement, then there is another function following   which takes a single name instead of a vector of names.     The data_component_interpretation argument contains information about how   the individual components of output files that consist of more than one   data set are to be interpreted.     For example, if one has a finite element for the Stokes equations in 2d,   representing components (u,v,p), one would like to indicate that the   first two, u and v, represent a logical vector so that later on when we   generate graphical output we can hand them off to a visualization program   that will automatically know to render them as a vector field, rather   than as two separate and independent scalar fields.     The default value of this argument (i.e. an empty vector) corresponds is   equivalent to a vector of values    [2.x.16]  indicating that all   output components are independent scalar fields. However, if the given   data vector represents logical vectors, you may pass a vector that   contains values  [2.x.17]    In the example above, one would pass in a vector with components    [2.x.18]     [2.x.19]     [2.x.20]  for (u,v,p).     The names of a data vector shall only contain characters which are   letters, underscore and a few other ones. Refer to the   ExcInvalidCharacter exception declared in this class to see which   characters are valid and which are not.    
*  [2.x.21]  The actual type for the vector argument may be any vector type from   which FEValues can extract values on a cell using the    [2.x.22]  function.    
*  [2.x.23]  When working in parallel, the vector to be written needs to be ghosted   with read access to all degrees of freedom on the locally owned cells, see   the  [2.x.24]  or  [2.x.25]  tutorial programs for details, i.e., it might be   necessary to call data.update_ghost_values().  
* [0.x.42]*
   This function is an abbreviation to the above one (see there for a   discussion of the various arguments), intended for use with finite   elements that are not composed of subelements. In this case, only one   name per data vector needs to be given, which is what this function   takes. It simply relays its arguments after a conversion of the  [2.x.26]    to a vector of strings, to the other add_data_vector() function above.     If  [2.x.27]  is a vector with multiple components this function will   generate distinct names for all components by appending an underscore and   the number of each component to  [2.x.28]      The actual type for the template argument may be any vector type from   which FEValues can extract values on a cell using the    [2.x.29]  function.  
* [0.x.43]*
   This function is an extension of the above one (see there for a   discussion of the arguments except the first one) and allows to set a   vector with its own DoFHandler object. This DoFHandler needs to be   compatible with the other DoFHandler objects assigned with calls to  [2.x.30]    add_data_vector or  [2.x.31]  in the sense that all of the   DoFHandler objects need to be based on the same triangulation. This   function allows you to export data from multiple DoFHandler objects that   describe different solution components. An example of using this function   is given in  [2.x.32] .     Since this function takes a DoFHandler object and hence naturally   represents dof data, the data vector type argument present in the other   methods above is not necessary.  
* [0.x.44]*
   This function is an abbreviation of the function above with only a scalar    [2.x.33]  given and a single data name.  
* [0.x.45]*
   This function is an alternative to the above ones, allowing the output of   derived quantities instead of the given data. This conversion has to be   done in a class derived from DataPostprocessor. This function is used in    [2.x.34] . Other uses are shown in  [2.x.35]  and  [2.x.36] .     The names for these derived quantities are provided by the  [2.x.37]    data_postprocessor argument. Likewise, the data_component_interpretation   argument of the other add_data_vector() functions is provided by the   data_postprocessor argument. As only data of type  [2.x.38]  can be   transformed, this type is also known implicitly and does not have to be   given.    
*  [2.x.39]  The actual type for the vector argument may be any vector type from   which FEValues can extract values on a cell using the    [2.x.40]  function.    
*  [2.x.41]  The DataPostprocessor object (i.e., in reality the object of your   derived class) has to live until the DataOut object is destroyed as the   latter keeps a pointer to the former and will complain if the object   pointed to is destroyed while the latter still has a pointer to it. If   both the data postprocessor and DataOut objects are local variables of a   function (as they are, for example, in  [2.x.42] ), then you can avoid this   error by declaring the data postprocessor variable before the DataOut   variable as objects are destroyed in reverse order of declaration.  
* [0.x.46]*
   Same function as above, but with a DoFHandler object that does not need   to coincide with the DoFHandler initially set. Note that the   postprocessor can only read data from the given DoFHandler and solution   vector, not other solution vectors or DoFHandlers.  
* [0.x.47]*
   Add a multilevel data vector.     This function adds the vector-valued multilevel vector  [2.x.43]  in the   form of a vector on each level that belongs to the DoFHandler  [2.x.44]    dof_handler to the graphical output. This function is typically used in   conjunction with a call to set_cell_selection() that selects cells on a   specific level and not the active cells (the default).     A vector  [2.x.45]  can be obtained in several ways, for example by using    [2.x.46]  or  [2.x.47]  during or after a multigrid   cycle or by interpolating a solution via    [2.x.48]      The handling of  [2.x.49]  and  [2.x.50]  is identical   to the add_data_vector() function.  
* [0.x.48]*
   Scalar version of the function above.  
* [0.x.49]*
   Release the pointers to the data vectors. This allows output of a new set   of vectors without supplying the DoF handler again. Therefore, the   DataOut object can be used in an algebraic context. Note that besides the   data vectors also the patches already computed are deleted.  
* [0.x.50]*
   Release pointers to all input data elements, i.e. pointers to data   vectors and to the DoF handler object. This function may be useful when   you have called the  [2.x.51]  function of derived class, since   then the patches are built and the input data is no more needed, nor is   there a need to reference it. You can then output the patches detached   from the main thread and need not make sure anymore that the DoF handler   object and vectors must not be deleted before the output thread is   finished.  
* [0.x.51]*
   This function can be used to merge the patches that were created using   the  [2.x.52]  function of the object given as argument into the   list of patches created by this object. This is sometimes handy if one   has, for example, a domain decomposition algorithm where each block is   represented by a DoFHandler of its own, but one wants to output the   solution on all the blocks at the same time.     For this to work, the given argument and this object need to have the   same number of output vectors, and they need to use the same number of   subdivisions per patch. The output will probably look rather funny if   patches in both objects overlap in space.     If you call build_patches() for this object after merging in patches, the   previous state is overwritten, and the merged-in patches are lost.     The second parameter allows to shift each node of the patches in the   object passed in in the first parameter by a certain amount. This is   sometimes useful to generate "exploded" views of a collection of blocks.     This function will fail if either this or the other object did not yet   set up any patches.  
* [0.x.52]*
    [2.x.53]  Use merge_patches() without the DoFHandlerType2 template   instead.  
* [0.x.53]*
   Release the pointers to the data vectors and the DoF handler. You have to   set all data entries again using the add_data_vector() function. The   pointer to the dof handler is cleared as well, along with all other data.   In effect, this function resets everything to a virgin state.  
* [0.x.54]*
   Determine an estimate for the memory consumption (in bytes) of this   object.  
* [0.x.55]*
   Abbreviate the somewhat lengthy name for the Patch class.  
* [0.x.56]*
   Pointer to the triangulation object.  
* [0.x.57]*
   Pointer to the optional handler object.  
* [0.x.58]*
   List of data elements with vectors of values for each degree of freedom.  
* [0.x.59]*
   List of data elements with vectors of values for each cell.  
* [0.x.60]*
   This is a list of patches that is created each time build_patches() is   called. These patches are used in the output routines of the base   classes.  
* [0.x.61]*
   %Function by which the base class's functions get to know what patches   they shall write to a file.  
* [0.x.62]*
   Virtual function through which the names of data sets are obtained by the   output functions of the base class.  
* [0.x.63]*
   Extracts the finite elements stored in the dof_data object, including a   dummy object of FE_DGQ<dim>(0) in case only the triangulation is used.  
* [0.x.64]*
   Overload of the respective  [2.x.54]    function. See there for a more extensive documentation.  
* [0.x.65]*
   Common function called by the four public add_data_vector methods.  
* [0.x.66]*
    [2.x.55]  Use  [2.x.56]  without the DoFHandlerType   template instead.  
* [0.x.67]

include/deal.II-translator/numerics/data_out_faces_0.txt
[0.x.0]*
     A derived class for use in the DataOutFaces class. This is a class for     the AdditionalData kind of data structure discussed in the     documentation of the WorkStream context.    
* [0.x.1]*
 This class generates output from faces of a triangulation. It might be used to generate output only for the surface of the triangulation (this is the default of this class), or for all faces of active cells, as specified in the constructor. The output of this class is a set of patches (as defined by the class  [2.x.0]  one for each face for which output is to be generated. These patches can then be written in several graphical data formats by the functions of the underlying classes.
*  [1.x.0]
*  The interface of this class is copied from the DataOut class. Furthermore, they share the common parent class DataOut_DoFData. See the reference of these two classes for a discussion of the interface.
* 

*  [1.x.1]
*  The sequence of faces to generate patches from is generated in the same way as in the DataOut class; see there for a description of the respective interface. The functions generating the sequence of faces which shall be used to generate output, are called first_face() and next_face().
*  Since we need to initialize objects of type FEValues with the faces generated from these functions, it is not sufficient that they only return face iterators. Rather, we need a pair of cell and the number of the face, as the values of finite element fields need not necessarily be unique on a face (think of discontinuous finite elements, where the value of the finite element field depend on the direction from which you approach a face, thus it is necessary to use a pair of cell and face, rather than only a face iterator). Therefore, this class defines an  [2.x.1]  which creates a type  [2.x.2]  that is an abbreviation for a pair of cell iterator and face number. The functions  [2.x.3]  and  [2.x.4]  operate on objects of this type.
*  Extending this class might, for example, be useful if you only want output from certain portions of the boundary, e.g. as indicated by the boundary indicator of the respective faces. However, it is also conceivable that one generates patches not from boundary faces, but from interior faces that are selected due to other criteria; one application might be to use only those faces where one component of the solution attains a certain value, in order to display the values of other solution components on these faces. Other applications certainly exist, for which the author is not imaginative enough.
*   [2.x.5]  Reimplement this whole class using actual FEFaceValues and MeshWorker.
* 

* 
*  [2.x.6] 

* 
* [0.x.2]*
   Dimension parameters for the patches.  
* [0.x.3]*
   Alias to the iterator type of the dof handler class under   consideration.  
* [0.x.4]*
   Constructor determining whether a surface mesh (default) or the whole   wire basket is written.  
* [0.x.5]*
   This is the central function of this class since it builds the list of   patches to be written by the low-level functions of the base class. A   patch is, in essence, some intermediate representation of the data on   each face of a triangulation and DoFHandler object that can then be used   to write files in some format that is readable by visualization programs.     You can find an overview of the use of this function in the general   documentation of this class. An example is also provided in the   documentation of this class's base class DataOut_DoFData.      [2.x.7]  n_subdivisions See  [2.x.8]  for an extensive   description of this parameter.  
* [0.x.6]*
   Same as above, except that the additional first parameter defines a   mapping that is to be used in the generation of output. If   <tt>n_subdivisions>1</tt>, the points interior of subdivided patches   which originate from cells at the boundary of the domain can be computed   using the mapping, i.e. a higher order mapping leads to a representation   of a curved boundary by using more subdivisions.     Even for non-curved cells the mapping argument can be used for the   Eulerian mappings (see class MappingQ1Eulerian) where a mapping is used   not only to determine the position of points interior to a cell, but also   of the vertices.  It offers an opportunity to watch the solution on a   deformed triangulation on which the computation was actually carried out,   even if the mesh is internally stored in its undeformed configuration and   the deformation is only tracked by an additional vector that holds the   deformation of each vertex.      [2.x.9]  The  [2.x.10]  argument should be replaced by a    [2.x.11]  in case of a DoFHandler with hp-capabilities.  
* [0.x.7]*
   Declare a way to describe a face which we would like to generate output   for. The usual way would, of course, be to use an object of type    [2.x.12]  but since we have to describe   faces to objects of type FEValues, we can only represent faces by pairs   of a cell and the number of the face. This pair is here aliased to a name   that is better to type.  
* [0.x.8]*
   Return the first face which we want output for. The default   implementation returns the first face of a (locally owned) active cell   or, if the  [2.x.13]  option was set in the destructor (as is the   default), the first such face that is located on the boundary.     If you want to use a different logic to determine which faces should   contribute to the creation of graphical output, you can overload this   function in a derived class.  
* [0.x.9]*
   Return the next face after which we want output for. If there are no more   faces, <tt>dofs->end()</tt> is returned as the first component of the   return value.     The default implementation returns the next face of a (locally owned)   active cell, or the next such on the boundary (depending on whether the    [2.x.14]  option was provided to the constructor).     This function traverses the mesh active cell by active cell (restricted to   locally owned cells), and then through all faces of the cell. As a result,   interior faces are output twice, a feature that is useful for   discontinuous Galerkin methods or if a DataPostprocessor is used that   might produce results that are discontinuous between cells).     This function can be overloaded in a derived class to select a   different set of faces. Note that the default implementation assumes that   the given  [2.x.15]  is active, which is guaranteed as long as first_face()   is also used from the default implementation. Overloading only one of the   two functions should be done with care.  
* [0.x.10]*
   Parameter deciding between surface meshes and full wire basket.  
* [0.x.11]*
   Build one patch. This function is called in a WorkStream context.  
* [0.x.12]*
    [2.x.16]  Use  [2.x.17]  without the DoFHandlerType template   instead.  
* [0.x.13]

include/deal.II-translator/numerics/data_out_rotation_0.txt
[0.x.0]*
     A derived class for use in the DataOutFaces class. This is a class for     the AdditionalData kind of data structure discussed in the     documentation of the WorkStream class.    
* [0.x.1]*
 This class generates output in the full domain of computations that were done using rotational symmetry of domain and solution. In particular, if a computation of a three dimensional problem with rotational symmetry around the  [2.x.0]  (i.e. in the  [2.x.1]  was done, then this class can be used to generate the output in the original  [2.x.2]  space. In order to do so, it generates from each cell in the computational mesh a cell in the space with dimension one greater than that of the DoFHandler object. The resulting output will then consist of hexahedra forming an object that has rotational symmetry around the z-axis. As most graphical programs can not represent ring-like structures, the angular (rotation) variable is discretized into a finite number of intervals as well; the number of these intervals must be given to the  [2.x.3]  function. It is noted, however, that while this function generates nice pictures of the whole domain, it often produces  [2.x.4] very [2.x.5]  large output files.
* 

*  [1.x.0]
*  The interface of this class is copied from the DataOut class. Furthermore, they share the common parent class DataOut_DoFData(). See the reference of these two classes for a discussion of the interface and how to extend it by deriving further classes from this class.
* 

*  [1.x.1]
*  The one coordinate in the triangulation used by the DoFHandler object passed to this class is taken as the radial variable, and the output will then be either a circle or a ring domain. It is in the user's responsibility to assure that the radial coordinate only attains non- negative values.
* 

*  [1.x.2]
*  We consider the computation (represented by the DoFHandler object that is attached to this class) to have happened in the  [2.x.6]  where  [2.x.7]  is the radial variable and  [2.x.8]  denotes the axis of revolution around which the solution is symmetric. The output is in  [2.x.9]  space, where the radial dependence is transformed to the  [2.x.10]  plane. At present, it is not possible to exchange the meaning of the first and second variable of the plane in which the simulation was made, i.e. generate output from a simulation where the first variable denoted the symmetry axis, and the second denoted the radial variable. You have to take that into account when first programming your application.
*  It is in the responsibility of the user to make sure that the radial variable attains only non-negative values.
* 

* 
*  [2.x.11] 

* 
* [0.x.2]*
   Dimension parameters for the patches.  
* [0.x.3]*
   Typedef to the iterator type of the dof handler class under   consideration.  
* [0.x.4]*
   This is the central function of this class since it builds the list of   patches to be written by the low-level functions of the base class. A   patch is, in essence, some intermediate representation of the data on   each cell of a triangulation and DoFHandler object that can then be used   to write files in some format that is readable by visualization programs.     You can find an overview of the use of this function in the general   documentation of this class. An example is also provided in the   documentation of this class's base class DataOut_DoFData.      [2.x.12]  n_patches_per_circle Denotes into how many intervals the angular   (rotation) variable is to be subdivided.      [2.x.13]  n_subdivisions See  [2.x.14]  for an extensive   description of this parameter.  
* [0.x.5]*
   Return the first cell which we want output for. The default   implementation returns the first    [2.x.15]  "active cell",   but you might want to return other cells in a derived class.  
* [0.x.6]*
   Return the next cell after  [2.x.16]  which we want output for. If there are   no more cells, <tt>dofs->end()</tt> shall be returned.     The default implementation returns the next active cell, but you might   want to return other cells in a derived class. Note that the default   implementation assumes that the given  [2.x.17]  is active, which is   guaranteed as long as  [2.x.18]  is also used from the default   implementation. Overloading only one of the two functions might not be a   good idea.  
* [0.x.7]*
   Exception  
* [0.x.8]*
   Build all of the patches that correspond to the cell given in the first   argument. Use the second argument as scratch space for parallel   invocation in WorkStream, and put the results into the last argument.  
* [0.x.9]*
    [2.x.19]  Use  [2.x.20]  without the DoFHandlerType   template instead.  
* [0.x.10]

include/deal.II-translator/numerics/data_out_stack_0.txt
[0.x.0]*
  [2.x.0]  Use DataOutStack<dim, spacedim> instead.

* 
* [0.x.1]*
 This class is used to stack the output from several computations into one output file by stacking the data sets in another coordinate direction orthogonal to the space directions. The most common use is to stack the results of several time steps into one space-time output file, or for example to connect the results of solutions of a parameter dependent equation for several parameter value together into one. The interface is mostly modelled after the DataOut class, see there for some more documentation.
*  We will explain the concept for a time dependent problem, but instead of the time any parameter can be substituted. In our example, a solution of an equation is computed for each discrete time level. This is then added to an object of the present class and after all time levels are added, a space- time plot will be written in any of the output formats supported by the base class. Upon output, the (spatial) solution on each time level is extended into the time direction by writing it twice, once for the time level itself and once for a time equal to the time level minus a given time step. These two copies are connected, to form a space-time slab, with constant values in time.
*  Due to the piecewise constant output in time, the written solution will in general be discontinuous at discrete time levels, but the output is still sufficient in most cases. More sophisticated interpolations in time may be added in the future.
* 

*  [1.x.0]
*  The following little example shall illustrate the different steps of use of this class. It is assumed that the finite element used is composed of two components,  [2.x.1]  and  [2.x.2]  that the solution vector is named  [2.x.3]  and that a vector  [2.x.4]  is computed which contains an error indicator for each spatial cell.
*  Note that unlike for the DataOut class it is necessary to first declare data vectors and the names of the components before first use. This is because on all time levels the same data should be present to produce reasonable time-space output. The output is generated with two subdivisions in each space and time direction, which is suitable for quadratic finite elements in space, for example.
* 

* 
* [1.x.1]
* 
* 

* 
*  [2.x.5] 

* 
* [0.x.2]*
   Dimension parameters for the patches.  
* [0.x.3]*
   Data type declaring the two types of vectors which are used in this   class.  
* [0.x.4]*
     The data describes one value for each cell.    
* [0.x.5]*
     The data describes one value for each DoF.    
* [0.x.6]*
   Destructor. Only declared to make it  [2.x.6]   
* [0.x.7]*
   Start the next set of data for a specific parameter value. The argument    [2.x.7]  denotes the interval (in backward direction, counted   from  [2.x.8]  with which the output will be extended in   parameter direction, i.e. orthogonal to the space directions.  
* [0.x.8]*
   Attach the DoF handler for the grid and data associated with the   parameter previously set by  [2.x.9]      This has to happen before adding data vectors for the present parameter   value.  
* [0.x.9]*
   Declare a data vector. The  [2.x.10]  argument determines whether the   data vector will be considered as DoF or cell data.     This version may be called if the finite element presently used by the   DoFHandler (and previously attached to this object) has only one   component and therefore only one name needs to be given.  
* [0.x.10]*
   Declare a data vector. The  [2.x.11]  argument determines whether the   data vector will be considered as DoF or cell data.     This version must be called if the finite element presently used by the   DoFHandler (and previously attached to this object) has more than one   component and therefore more than one name needs to be given. However,   you can also call this function with a    [2.x.12]  containing only one element if the   finite element has only one component.  
* [0.x.11]*
   Add a data vector for the presently set value of the parameter.     This version may be called if the finite element presently used by the   DoFHandler (and previously attached to this object) has only one   component and therefore only one name needs to be given.     If  [2.x.13]  is a vector with multiple components this function will   generate distinct names for all components by appending an underscore and   the number of each component to  [2.x.14]      The data vector must have been registered using the  [2.x.15]    declare_data_vector function before actually using it the first time.     Note that a copy of this vector is stored until  [2.x.16]    is called the next time, so if you are short of memory you may want to   call this function only after all computations involving large matrices   are already done.  
* [0.x.12]*
   Add a data vector for the presently set value of the parameter.     This version must be called if the finite element presently used by the   DoFHandler (and previously attached to this object) has more than one   component and therefore more than one name needs to be given. However,   you can also call this function with a    [2.x.17]  containing only one element if the   finite element has only one component.     The data vector must have been registered using the  [2.x.18]    declare_data_vector function before actually using it the first time.     Note that a copy of this vector is stored until  [2.x.19]    is called the next time, so if you are short of memory you may want to   call this function only after all computations involving large matrices   are already done.  
* [0.x.13]*
   This is the central function of this class since it builds the list of   patches to be written by the low-level functions of the base class. A   patch is, in essence, some intermediate representation of the data on   each cell of a triangulation and DoFHandler object that can then be used   to write files in some format that is readable by visualization programs.     You can find an overview of the use of this function in the general   documentation of this class. An example is also provided in the   documentation of this class's base class DataOut_DoFData.      [2.x.20]  n_subdivisions See  [2.x.21]  for an extensive   description of this parameter. The number of subdivisions is always one   in the direction of the time-like parameter used by this class.  
* [0.x.14]*
   Release all data that is no more needed once  [2.x.22]  was called   and all other transactions for a given parameter value are done.     Counterpart of  [2.x.23]   
* [0.x.15]*
   Determine an estimate for the memory consumption (in bytes) of this   object.  
* [0.x.16]*
   Exception  
* [0.x.17]*
   Exception  
* [0.x.18]*
   Exception  
* [0.x.19]*
   Exception  
* [0.x.20]*
   Present parameter value.  
* [0.x.21]*
   Present parameter step, i.e. length of the parameter interval to be   written next.  
* [0.x.22]*
   DoF handler to be used for the data corresponding to the present   parameter value.  
* [0.x.23]*
   List of patches of all past and present parameter value data sets.  
* [0.x.24]*
   Structure holding data vectors (cell and dof data) for the present   parameter value.  
* [0.x.25]*
     Data vector.    
* [0.x.26]*
     Names of the different components within each such data set.    
* [0.x.27]*
     Determine an estimate for the memory consumption (in bytes) of this     object.    
* [0.x.28]*
   List of DoF data vectors.  
* [0.x.29]*
   List of cell data vectors.  
* [0.x.30]*
   This is the function through which derived classes propagate preprocessed   data in the form of Patch structures (declared in the base class   DataOutBase) to the actual output function.  
* [0.x.31]*
   Virtual function through which the names of data sets are obtained by the   output functions of the base class.  
* [0.x.32]

include/deal.II-translator/numerics/data_postprocessor_0.txt
[0.x.0]*
 A namespace for data structures that are going to be passed from DataOut to the member functions of DataPostprocessor.

* 
* [0.x.1]*
   A base class containing common elements for the Scalar and Vector classes   that are passed as arguments to    [2.x.0]  and    [2.x.1]  This common base class   provides access to the points at which the solution is being evaluated,   and a few other fields, as described in the following.     [1.x.0]     If appropriate, i.e., if the object that is currently being processed   is a face of a cell and the DataPostprocessor object is called from   DataOutFaces or a similar class, then the current object also   stores the normal vectors to the geometry on which output   is generated, at these evaluation points.     On the other hand, if the solution is being evaluated on a cell,   then the  [2.x.2]  member variable does not contain anything   useful.     [1.x.1]     DataPostprocessor is typically called from classes such as DataOut   or DataOutFaces that evaluate solution fields on a cell-by-cell   basis. As a consequence, classes derived from DataPostprocessor   (or DataPostprocessorScalar, DataPostprocessorVector, or   DataPostprocessorTensor) sometimes   need to use which cell is currently under investigation. Consequently,   DataOut and similar classes pass the cell they are currently working   on to DataPostprocessor via the classes in this namespace (and   specifically the current base class).     However, the situation is not so simple. This is because the current   class (and those derived from it) only knows the space dimension in   which the output lives. But this can come from many sources. For example,   if we are in 3d, this may be because we are working on a DoFHandler<3> or   a DoFHandler<2,3> (i.e., either a 3d mesh, or a 2d meshes of a 2d surface   embedded in 3d space). Another case is classes like DataOutRotation or   DataOutStack, then  [2.x.3]  being equal to 3 might mean that we are   actually working on a DoFHandler<2>.     In other words, just because we know the value of the  [2.x.4]    template argument of the current class does not mean that the   data type of the cell iterator that is currently being worked on   is obvious.     To make the cell iterator accessible nevertheless, this class uses   an object of type  [2.x.5]  to store the cell iterator. You can   think of this as being a void pointer that can point to anything.   To use what is being used therefore requires the user to know the   data type of the thing being pointed to.     To make this work, the DataOut and related classes store in objects   of the current type a representation of the cell. To get it back out,   you would use the get_cell() function that requires you to say,   as a template parameter, the dimension of the cell that is currently   being processed. This is knowledge you typically have in an   application: for example, if your application runs in  [2.x.6]  space   dimensions and you are currently using the DataOut class, then the cells   that are worked on have data type  [2.x.7] .   Consequently, in a postprocessor, you can call <code>inputs.get_cell [2.x.8]    </code>. For technical reasons, however, C++ will typically require you to   write this as  [2.x.9]  because the   member function we call here requires that we explicitly provide the   template argument.     Let us consider a complete example of a postprocessor that computes   the fluid norm of the stress  [2.x.10]  from the   viscosity  [2.x.11]  and the gradient of the fluid velocity,  [2.x.12] ,   assuming that the viscosity is something that depends on the cell's   material id. This can be done using a class we derive from   DataPostprocessorScalar where we overload the    [2.x.13]  function that receives the   values and gradients of the velocity (plus of other solution variables such   as the pressure, but let's ignore those for the moment). Then we could use   code such as this:  
* [1.x.2]
*   
* [0.x.2]*
     An array of vectors normal to the faces of cells, evaluated at the points     at which we are generating graphical output. This array is only used by     the DataOutFaces class, and is left empty by all other classes for     which the DataPostprocessor framework can be used. In the case of     DataOutFaces, the array contains the outward normal vectors to the     face, seen from the interior of the cell.         This array is only filled if a user-derived class overloads the      [2.x.14]  and the function     returns (possibly among other flags)      [2.x.15]   Alternatively, a class     derived from DataPostprocessorScalar, DataPostprocessorVector,     or DataPostprocessorTensor may pass this flag to the constructor of     these three classes.    
* [0.x.3]*
     An array of coordinates corresponding to the locations at which     we are generating graphical output on one cell.         This array is only filled if a user-derived class overloads the      [2.x.16]  and the function     returns (possibly among other flags)      [2.x.17]   Alternatively, a class     derived from DataPostprocessorScalar, DataPostprocessorVector,     or DataPostprocessorTensor may pass this flag to the constructor of     these three classes.    
* [0.x.4]*
     Set the cell that is currently being used in evaluating the data     for which the DataPostprocessor object is being called.         This function is not usually called from user space, but is instead     called by DataOut and similar classes when creating the object that     is then passed to DataPostprocessor.    
* [0.x.5]*
     Set the cell that is currently being used in evaluating the data     for which the DataPostprocessor object is being called.         This function is not usually called from user space, but is instead     called by DataOut and similar classes when creating the object that     is then passed to DataPostprocessor.          [2.x.18]  Use the equivalent function with the dim template parameter     instead.    
* [0.x.6]*
     Query the cell on which we currently produce graphical output.     See the documentation of the current class for an example on how     to use this function.    
* [0.x.7]*
     Query the cell on which we currently produce graphical output.     See the documentation of the current class for an example on how     to use this function.          [2.x.19]  Use the equivalent function with the dim template parameter     instead.    
* [0.x.8]*
     The place where set_cell() stores the cell. Since the actual data     type of the cell iterator can be many different things, the     interface uses  [2.x.20]  here. This makes assignment in set_cell()     simple, but requires knowing the data type of the stored object in     get_cell().    
* [0.x.9]*
   A structure that is used to pass information to    [2.x.21]  It contains   the values and (if requested) derivatives of a scalar solution   variable at the evaluation points on a cell or face. (This class   is not used if a scalar solution is complex-valued, however,   since in that case the real and imaginary parts are treated   separately
* 
*  -  resulting in vector-valued inputs to data   postprocessors, which are then passed to    [2.x.22]  instead.)     Through the fields in the CommonInputs base class, this class also   makes available access to the locations of evaluations points,   normal vectors (if appropriate), and which cell data is currently   being evaluated on (also if appropriate).  
* [0.x.10]*
     An array of values of the (scalar) solution at each of the evaluation     points used to create graphical output from one cell, face, or other     object.    
* [0.x.11]*
     An array of gradients of the (scalar) solution at each of the evaluation     points used to create graphical output from one cell, face, or other     object.         This array is only filled if a user-derived class overloads the      [2.x.23]  and the function     returns (possibly among other flags)      [2.x.24]   Alternatively, a class     derived from DataPostprocessorScalar, DataPostprocessorVector,     or DataPostprocessorTensor may pass this flag to the constructor of     these three classes.    
* [0.x.12]*
     An array of second derivatives of the (scalar) solution at each of the     evaluation points used to create graphical output from one cell, face, or     other object.         This array is only filled if a user-derived class overloads the      [2.x.25]  and the function     returns (possibly among other flags)      [2.x.26]   Alternatively, a class     derived from DataPostprocessorScalar, DataPostprocessorVector,     or DataPostprocessorTensor may pass this flag to the constructor of     these three classes.    
* [0.x.13]*
   A structure that is used to pass information to    [2.x.27]  It contains   the values and (if requested) derivatives of a vector-valued solution   variable at the evaluation points on a cell or face.     This class is also used if the solution vector is complex-valued   (whether it is scalar- or vector-valued is immaterial in that case)   since in that case, the DataOut and related classes take apart the real   and imaginary parts of a solution vector. In practice, that means that   if a solution vector has  [2.x.28]  vector components (i.e., there are    [2.x.29]  functions that form the solution of the PDE you are dealing with;    [2.x.30]  is not the size of the solution vector), then if the solution is   real-valued the `solution_values` variable below will be an array   with as many entries as there are evaluation points on a cell,   and each entry is a vector of length  [2.x.31]  representing the  [2.x.32]    solution functions evaluated at a point. On the other hand, if   the solution is complex-valued (i.e., the vector passed to    [2.x.33]  has complex-valued entries), then the   `solution_values` member variable of this class will have  [2.x.34]    entries for each evaluation point. The first  [2.x.35]  of these entries   represent the real parts of the solution, and the second  [2.x.36]  entries   correspond to the imaginary parts of the solution evaluated at the   evaluation point. The same layout is used for the `solution_gradients`   and `solution_hessians` fields: First the gradients/Hessians of   the real components, then all the gradients/Hessians of the   imaginary components. There is more information about the subject in the   documentation of the DataPostprocessor class itself.  [2.x.37]  provides an   example of how this class is used in a complex-valued situation.     Through the fields in the CommonInputs base class, this class also   makes available access to the locations of evaluations points,   normal vectors (if appropriate), and which cell data is currently   being evaluated on (also if appropriate).  
* [0.x.14]*
     An array of values of a vector-valued solution at each of the evaluation     points used to create graphical output from one cell, face, or other     object.         The outer vector runs over the evaluation points, whereas the inner     vector runs over the components of the finite element field for which     output will be generated.    
* [0.x.15]*
     An array of gradients of a vector-valued solution at each of the     evaluation points used to create graphical output from one cell, face, or     other object.         The outer vector runs over the evaluation points, whereas the inner     vector runs over the components of the finite element field for which     output will be generated.         This array is only filled if a user-derived class overloads the      [2.x.38]  and the function     returns (possibly among other flags)      [2.x.39]   Alternatively, a class     derived from DataPostprocessorScalar, DataPostprocessorVector,     or DataPostprocessorTensor may pass this flag to the constructor of     these three classes.    
* [0.x.16]*
     An array of second derivatives of a vector-valued solution at each of the     evaluation points used to create graphical output from one cell, face, or     other object.         The outer vector runs over the evaluation points, whereas the inner     vector runs over the components of the finite element field for which     output will be generated.         This array is only filled if a user-derived class overloads the      [2.x.40]  and the function     returns (possibly among other flags)      [2.x.41]   Alternatively, a class     derived from DataPostprocessorScalar, DataPostprocessorVector,     or DataPostprocessorTensor may pass this flag to the constructor of     these three classes.    
* [0.x.17]*
 This class provides an interface to compute derived quantities from a solution that can then be output in graphical formats for visualization, using facilities such as the DataOut class.
*  For the (graphical) output of a FE solution one frequently wants to include derived quantities, which are calculated from the values of the solution and possibly the first and second derivatives of the solution. Examples are the calculation of Mach numbers from velocity and density in supersonic flow computations, or the computation of the magnitude of a complex-valued solution as demonstrated in  [2.x.42]  and  [2.x.43]  (where it is actually thesquare* of the magnitude). Other uses are shown in  [2.x.44]  and  [2.x.45] . This class offers the interface to perform such postprocessing. Given the values and derivatives of the solution at those points where we want to generated output, the functions of this class can be overloaded to compute new quantities.
*  A data vector and an object of a class derived from the current one can be given to the  [2.x.46]  function (and similarly for DataOutRotation and DataOutFaces). This will cause  [2.x.47]  to compute the derived quantities instead of using the data provided by the data vector (typically the solution vector). Note that the DataPostprocessor object (i.e., in reality the object of your derived class) has to live until the DataOut object is destroyed as the latter keeps a pointer to the former and will complain if the object pointed to is destroyed while the latter still has a pointer to it. If both the data postprocessor and DataOut objects are local variables of a function (as they are, for example, in  [2.x.48] ), then you can avoid this error by declaring the data postprocessor variable before the DataOut variable as objects are destroyed in reverse order of declaration.
*  In order not to perform needless calculations, DataPostprocessor has to provide information which input data is needed for the calculation of the derived quantities, i.e. whether it needs the values, the first derivative and/or the second derivative of the provided data. DataPostprocessor objects which are used in combination with a DataOutFaces object can also ask for the normal vectors at each point. The information which data is needed has to be provided via the UpdateFlags returned by the virtual function get_needed_update_flags(). It is your responsibility to use only those values which were updated in the calculation of derived quantities. The DataOut object will provide references to the requested data in the call to evaluate_scalar_field() or evaluate_vector_field() (DataOut decides which of the two functions to call depending on whether the finite element in use has only a single, or multiple vector components; note that this is only determined by the number of components in the finite element in use, and not by whether the data computed by a class derived from the current one is scalar or vector valued).
*  Furthermore, derived classes have to implement the get_names() function, where the number of output variables returned by the latter function has to match the size of the vector returned by the former. Furthermore, this number has to match the number of computed quantities, of course.
* 

*  [1.x.3]
*  Deriving from the current class allows to implement very general postprocessors. For example, in the  [2.x.49]  program, we implement a postprocessor that takes a solution that consists of velocity, pressure and temperature (dim+2 components) and computes a variety of output quantities, some of which are vector valued and some of which are scalar. On the other hand, in  [2.x.50]  we implement a postprocessor that only computes the magnitude of a complex number given by a two-component finite element. It seems silly to have to implement four virtual functions for this (evaluate_scalar_field() or evaluate_vector_field(), get_names(), get_update_flags() and get_data_component_interpretation()).
*  To this end there are three classes DataPostprocessorScalar, DataPostprocessorVector, and DataPostprocessorTensor that are meant to be used if the output quantity is either a single scalar, a single vector (here used meaning to have exactly  [2.x.51]  components), or a single tensor (here used meaning to have exactly  [2.x.52]  components). When using these classes, one only has to write a constructor that passes the name of the output variable and the update flags to the constructor of the base class and overload the function that actually computes the results.
*  The DataPostprocessorVector and DataPostprocessorTensor class documentations also contains a extensive examples of how they can be used. The  [2.x.53]  tutorial program contains an example of using the DataPostprocessorScalar class.
* 

*  [1.x.4]
*  There are PDEs whose solutions are complex-valued. For example,  [2.x.54]  and  [2.x.55]  solve problems whose solutions at each point consists of a complex number represented by a  [2.x.56]  variable. ( [2.x.57]  also solves such a problem, but there we choose to represent the solution by two real-valued fields.) In such cases, the vector that is handed to  [2.x.58]  is of type  [2.x.59]  or something essentially equivalent to this. The issue with this, as also discussed in the documentation of DataOut itself, is that the most widely used file formats for visualization (notably, the VTK and VTU formats) can not actually represent complex quantities. The only thing that can be stored in these data files are real-valued quantities.
*  As a consequence, DataOut is forced to take things apart into their real and imaginary parts, and both are output as separate quantities. This is the case for data that is written directly to a file by DataOut, but it is also the case for data that is first routed through DataPostprocessor objects (or objects of their derived classes): All these objects see is a collection of real values, even if the underlying solution vector was complex-valued.
*  All of this has two implications:
* 

* 
* 
*  - If a solution vector is complex-valued, then this results in at least   two input components at each evaluation point. As a consequence, the    [2.x.60]  function is never called,   even if the underlying finite element had only a single solution   component. Instead, DataOut willalways* call    [2.x.61] 
* 

* 
* 
*  - Implementations of the  [2.x.62]  in   derived classes must understand how the solution values are arranged   in the  [2.x.63]  objects they receive as input.   The rule here is: If the finite element has  [2.x.64]  vector components   (including the case  [2.x.65] , i.e., a scalar element), then the inputs   for complex-valued solution vectors will have  [2.x.66]  components. These   first contain the values (or gradients, or Hessians) of the real   parts of all solution components, and then the values (or gradients,   or Hessians) of the imaginary parts of all solution components.
*   [2.x.67]  provides an example of how this class (or, rather, the derived DataPostprocessorScalar class) is used in a complex-valued situation.
* 

* 
*  [2.x.68] 

* 
* [0.x.18]*
   Destructor. This function doesn't actually do anything but is marked as   virtual to ensure that data postprocessors can be destroyed through   pointers to the base class.  
* [0.x.19]*
   This is the main function which actually performs the postprocessing. The   second argument is a reference to the postprocessed data which already has   correct size and must be filled by this function.     The function takes the values, gradients, and higher derivatives of the   solution at all evaluation points, as well as other data such as the   cell, via the first argument. Not all of the member vectors of this   argument will be filled with data
* 
*  -  in fact, derivatives and other   quantities will only be contain valid data if the corresponding flags   are returned by an overridden version of the get_needed_update_flags()   function (implemented in a user's derived class).   Otherwise those vectors will be in an unspecified state.     This function is called when the finite element field that is being   converted into graphical data by DataOut or similar classes represents   scalar data, i.e., if the finite element in use has only a single   real-valued vector component.  
* [0.x.20]*
   Same as the evaluate_scalar_field() function, but this   function is called when the original data vector represents vector data,   i.e., the finite element in use has multiple vector components. This   function is also called if the finite element is scalar but the solution   vector is complex-valued. If the solution vector to be visualized   is complex-valued (whether scalar or not), then the input data contains   first all real parts of the solution vector at each evaluation point, and   then all imaginary parts.  
* [0.x.21]*
   Return the vector of strings describing the names of the computed   quantities.  
* [0.x.22]*
   This function returns information about how the individual components of   output files that consist of more than one data set are to be   interpreted.     For example, if one has a finite element for the Stokes equations in 2d,   representing components (u,v,p), one would like to indicate that the   first two, u and v, represent a logical vector so that later on when we   generate graphical output we can hand them off to a visualization program   that will automatically know to render them as a vector field, rather   than as two separate and independent scalar fields.     The default implementation of this function returns a vector of values    [2.x.69]  indicating that all   output components are independent scalar fields. However, if a derived   class produces data that represents vectors, it may return a vector that   contains values  [2.x.70]    In the example above, one would return a vector with components    [2.x.71]     [2.x.72]     [2.x.73]  for (u,v,p).  
* [0.x.23]*
   Return, which data has to be provided to compute the derived quantities.   This has to be a combination of  [2.x.74]   [2.x.75]     [2.x.76]  and  [2.x.77]  Note that the flag    [2.x.78]  updates    [2.x.79]  If the   DataPostprocessor is to be used in combination with DataOutFaces, you may   also ask for a update of normals via the  [2.x.80]  flag.   The description of the flags can be found at  [2.x.81]   
* [0.x.24]*
 This class provides a simpler interface to the functionality offered by the DataPostprocessor class in case one wants to compute only a single scalar quantity from the finite element field passed to the DataOut class. For this particular case, it is clear what the returned value of  [2.x.82]  should be and we pass the values returned by get_names() and get_needed_update_flags() to the constructor so that derived classes do not have to implement these functions by hand.
*  All derived classes have to do is implement a constructor and overload either  [2.x.83]  or  [2.x.84]  as discussed in the DataPostprocessor class's documentation.
*  An example of how this class can be used can be found in  [2.x.85]  for the case where we are interested in computing the magnitude (a scalar) of a complex-valued solution. While in  [2.x.86] , the solution vector consists of separate real and imaginary parts of the solution,  [2.x.87]  computes the solution vector as a vector with complex entries and the DataPostprocessorScalar class is used there to compute the magnitude and phase of the solution in a different way there.
*  An example of how the closely related DataPostprocessorVector class can be used is found in the documentation of that class. The same is true for the DataPostprocessorTensor class.
* 

* 
*  [2.x.88] 

* 
* [0.x.25]*
   Constructor. Take the name of the single scalar variable computed by   classes derived from the current one, as well as the update flags   necessary to compute this quantity.      [2.x.89]  name The name by which the scalar variable computed by this class   should be made available in graphical output files.    [2.x.90]  update_flags This has to be a combination of  [2.x.91]     [2.x.92]   [2.x.93]  and  [2.x.94]    Note that the flag  [2.x.95]  updates    [2.x.96]  If the   DataPostprocessor is to be used in combination with DataOutFaces, you may   also ask for a update of normals via the  [2.x.97]  flag.   The description of the flags can be found at  [2.x.98]   
* [0.x.26]*
   Return the vector of strings describing the names of the computed   quantities. Given the purpose of this class, this is a vector with a   single entry equal to the name given to the constructor.  
* [0.x.27]*
   This function returns information about how the individual components of   output files that consist of more than one data set are to be   interpreted. Since the current class is meant to be used for a single   scalar result variable, the returned value is obviously    [2.x.99]   
* [0.x.28]*
   Return, which data has to be provided to compute the derived quantities.   The flags returned here are the ones passed to the constructor of this   class.  
* [0.x.29]*
   Copies of the two arguments given to the constructor of this class.  
* [0.x.30]*
 This class provides a simpler interface to the functionality offered by the DataPostprocessor class in case one wants to compute only a single vector quantity (defined as having exactly  [2.x.100]  components) from the finite element field passed to the DataOut class. For this particular case, it is clear what the returned value of  [2.x.101]  should be and we pass the values returned by get_names() and get_needed_update_flags() to the constructor so that derived classes do not have to implement these functions by hand.
*  All derived classes have to do is implement a constructor and overload either  [2.x.102]  or  [2.x.103]  as discussed in the DataPostprocessor class's documentation.
*  An example of how the closely related class DataPostprocessorScalar is used can be found in  [2.x.104] . An example of how the DataPostprocessorTensor class can be used is found in the documentation of that class.
* 

*  [1.x.5]
*  A common example of what one wants to do with postprocessors is to visualize not just the value of the solution, but the gradient. This is, in fact, precisely what  [2.x.105]  needs, and it consequently uses the code below almost verbatim. Let's, for simplicity, assume that you have only a scalar solution. In fact, because it's readily available, let us simply take the  [2.x.106]  solver to produce such a scalar solution. The gradient is a vector (with exactly  [2.x.107]  components), so the current class fits the bill to produce the gradient through postprocessing. Then, the following code snippet implements everything you need to have to visualize the gradient:

* 
* [1.x.6]
*  The only thing that is necessary is to add another output to the call of  [2.x.108]  in the  [2.x.109]  function of the  [2.x.110]  class of that example program. The corresponding code snippet would then look like this (where we also use VTU as the file format to output the data):

* 
* [1.x.7]
* 
*  This leads to the following output for the solution and the gradients (you may want to compare with the solution shown in the results section of  [2.x.111] ; the current data is generated on a coarser mesh for simplicity):
*   [2.x.112]   [2.x.113] 
*  In the second image, the background color corresponds to the magnitude of the gradient vector and the vector glyphs to the gradient itself. It may be surprising at first to see that from each vertex, multiple vectors originate, going in different directions. But that is because the solution is only continuous: in general, the gradient is discontinuous across edges, and so the multiple vectors originating from each vertex simply represent the differing gradients of the solution at each adjacent cell.
*  The output above
* 
*  -  namely, the gradient  [2.x.114]  of the solution
* 
*  -  corresponds to the temperature gradient if one interpreted  [2.x.115]  as solving a steady-state heat transfer problem. It is very small in the central part of the domain because in  [2.x.116]  we are solving an equation that has a coefficient  [2.x.117]  that is large in the central part and small on the outside. This can be thought as a material that conducts heat well, and consequently the temperature gradient is small. On the other hand, the "heat flux" corresponds to the quantity  [2.x.118] . For the solution of that equation, the flux should be continuous across the interface. This is easily verified by the following modification of the postprocessor:

* 
* [1.x.8]
*  With this postprocessor, we get the following picture of the heat flux:
*   [2.x.119] 
*  As the background color shows, the gradient times the coefficient is now a continuous function. There are (large) vectors around the interface where the coefficient jumps (at half the distance between the center of the disk to the perimeter) that seem to point in the wrong direction; this is an artifact of the fact that the solution has a discontinuous gradient at these points and that the numerical solution on the current grid does not adequately resolve this interface. This, however, is not important to the current discussion.
* 

*  [1.x.9]
*  The example above uses a scalar solution and its gradient as an example. On the other hand, one may want to do something similar for the gradient of a vector-valued displacement field (such as the strain or stress of a displacement field, like those computed in  [2.x.120] ,  [2.x.121] ,  [2.x.122] , or  [2.x.123] ). In that case, the solution is already vector valued and the stress is a (symmetric) tensor.
*  deal.II does not currently support outputting tensor-valued quantities, but they can of course be output as a collection of scalar-valued components of the tensor. This can be facilitated using the DataPostprocessorTensor class. The documentation of that class contains an example.
* 

* 

* 
*  [2.x.124] 

* 
* [0.x.31]*
   Constructor. Take the name of the single vector variable computed by   classes derived from the current one, as well as the update flags   necessary to compute this quantity.      [2.x.125]  name The name by which the vector variable computed by this class   should be made available in graphical output files.    [2.x.126]  update_flags This has to be a combination of  [2.x.127]     [2.x.128]   [2.x.129]  and  [2.x.130]    Note that the flag  [2.x.131]  updates    [2.x.132]  If the   DataPostprocessor is to be used in combination with DataOutFaces, you may   also ask for a update of normals via the  [2.x.133]  flag.   The description of the flags can be found at  [2.x.134]   
* [0.x.32]*
   Return the vector of strings describing the names of the computed   quantities. Given the purpose of this class, this is a vector with dim   entries all equal to the name given to the constructor.  
* [0.x.33]*
   This function returns information about how the individual components of   output files that consist of more than one data set are to be   interpreted. Since the current class is meant to be used for a single   vector result variable, the returned value is obviously    [2.x.135]  repeated dim times.  
* [0.x.34]*
   Return which data has to be provided to compute the derived quantities.   The flags returned here are the ones passed to the constructor of this   class.  
* [0.x.35]*
   Copies of the two arguments given to the constructor of this class.  
* [0.x.36]*
 This class provides a simpler interface to the functionality offered by the DataPostprocessor class in case one wants to compute only a single tensor quantity (defined as having exactly  [2.x.136]  components) from the finite element field passed to the DataOut class.
*  For this case, we would like to output all of these components as parts of a tensor-valued quantity. Unfortunately, the various backends that write DataOut data in graphical file formats (see the DataOutBase namespace for what formats can be written) do not support tensor data at the current time. In fact, neither does the DataComponentInterpretation namespace that provides semantic information how individual components of graphical data should be interpreted. Nevertheless, like DataPostprocessorScalar and DataPostprocessorVector, this class helps with setting up what the get_names() and get_needed_update_flags() functions required by the DataPostprocessor base class should return, and so the current class implements these based on information that the constructor of the current class receives from further derived classes.
*  (In order to visualize this collection of scalar fields that, together, are then supposed to be interpreted as a tensor, one has to (i) use a visualization program that can visualize tensors, and (ii) teach it how to re-combine the scalar fields into tensors. In the case of VisIt
* 
*  -  see https://wci.llnl.gov/simulation/computer-codes/visit/
* 
*  -  this is done by creating a new "Expression": in essence, one creates a variable, say "grad_u", that is tensor-valued and whose value is given by the expression <code>{{grad_u_xx,grad_u_xy}, {grad_u_yx, grad_u_yy}}</code>, where the referenced variables are the names of scalar fields that, here, are produced by the example below. VisIt is then able to visualize this "new" variable as a tensor.)
*  All derived classes have to do is implement a constructor and overload either  [2.x.137]  or  [2.x.138]  as discussed in the DataPostprocessor class's documentation.
*  An example of how the closely related class DataPostprocessorScalar is used can be found in  [2.x.139] . An example of how the DataPostprocessorVector class can be used is found in the documentation of that class.
* 

*  [1.x.10]
*  A common example of what one wants to do with postprocessors is to visualize not just the value of the solution, but the gradient. This class is meant for tensor-valued outputs, so we will start with a vector-valued solution: the displacement field of  [2.x.140] . The gradient is a rank-2 tensor (with exactly  [2.x.141]  components), so the current class fits the bill to produce the gradient through postprocessing. Then, the following code snippet implements everything you need to have to visualize the gradient:

* 
* [1.x.11]
*  The only tricky part in this piece of code is how to sort the  [2.x.142]  elements of the strain tensor into the one vector of computed output quantities
* 
*  -  in other words, how to [1.x.12] the elements of the tensor into the vector. This is facilitated by the  [2.x.143]  function that takes a pair of indices that specify a particular element of the tensor and returns a vector index that is then used in the code above to fill the  [2.x.144]  array.
*  The last thing that is necessary is to add another output to the call of  [2.x.145]  in the  [2.x.146]  function of the  [2.x.147]  class of that example program. The corresponding code snippet would then look like this:

* 
* [1.x.13]
* 
*  This leads to the following output for the displacement field (i.e., the solution) and the gradients (you may want to compare with the solution shown in the results section of  [2.x.148] ; the current data is generated on a uniform mesh for simplicity):
*   [2.x.149]   [2.x.150] 
*  These pictures show an ellipse representing the gradient tensor at, on average, every tenth mesh point. You may want to read through the documentation of the VisIt visualization program (see https://wci.llnl.gov/simulation/computer-codes/visit/) for an interpretation of how exactly tensors are visualizated.
*  In elasticity, one is often interested not in the gradient of the displacement, but in the "strain", i.e., the symmetrized version of the gradient  [2.x.151] . This is easily facilitated with the following minor modification:

* 
* [1.x.14]
* 
*  Using this class in  [2.x.152]  leads to the following visualization:
*   [2.x.153] 
*  Given how easy it is to output the strain, it would also not be very complicated to write a postprocessor that computes the [1.x.15] in the solution field as the stress is easily computed from the strain by multiplication with either the strain-stress tensor or, in simple cases, the Lam&eacute; constants.
* 

* 
*  [2.x.154] 

* 
* [0.x.37]*
   Constructor. Take the name of the single vector variable computed by   classes derived from the current one, as well as the update flags   necessary to compute this quantity.      [2.x.155]  name The name by which the vector variable computed by this class   should be made available in graphical output files.    [2.x.156]  update_flags This has to be a combination of  [2.x.157]     [2.x.158]   [2.x.159]  and  [2.x.160]    Note that the flag  [2.x.161]  updates    [2.x.162]  If the   DataPostprocessor is to be used in combination with DataOutFaces, you may   also ask for a update of normals via the  [2.x.163]  flag.   The description of the flags can be found at  [2.x.164]   
* [0.x.38]*
   Return the vector of strings describing the names of the computed   quantities. Given the purpose of this class, this is a vector with dim   entries all equal to the name given to the constructor.  
* [0.x.39]*
   This function returns information about how the individual components of   output files that consist of more than one data set are to be   interpreted. Since the current class is meant to be used for a single   vector result variable, the returned value is obviously    [2.x.165]  repeated dim times.  
* [0.x.40]*
   Return which data has to be provided to compute the derived quantities.   The flags returned here are the ones passed to the constructor of this   class.  
* [0.x.41]*
   Copies of the two arguments given to the constructor of this class.  
* [0.x.42]

include/deal.II-translator/numerics/derivative_approximation_0.txt
[0.x.0]*
 This namespace provides functions that compute a cell-wise approximation of the norm of a derivative of a finite element field by taking difference quotients between neighboring cells. This is a rather simple but efficient form to get an error indicator, since it can be computed with relatively little numerical effort and yet gives a reasonable approximation.
*  The way the difference quotients are computed on cell  [2.x.0]  is the following (here described for the approximation of the gradient of a finite element field, but see below for higher derivatives): let  [2.x.1]  be a neighboring cell, and let  [2.x.2]  be the distance vector between the centers of the two cells, then  [2.x.3]  is an approximation of the directional derivative  [2.x.4]  By multiplying both terms by  [2.x.5]  from the left and summing over all neighbors  [2.x.6] , we obtain  [2.x.7] 
*  Thus, if the matrix  [2.x.8]  is regular (which is the case when the vectors  [2.x.9]  to all neighbors span the whole space), we can obtain an approximation to the true gradient by  [2.x.10]  This is a quantity that is easily computed. The value returned for each cell when calling the  [2.x.11]  function of this class is the  [2.x.12]  norm of this approximation to the gradient. To make this a useful quantity, you may want to scale each element by the correct power of the respective cell size.
*  The computation of this quantity must fail if a cell has only neighbors for which the direction vectors  [2.x.13]  do not span the whole space, since then the matrix  [2.x.14]  is no longer invertible. If this happens, you will get an error similar to this one:

* 
* [1.x.0]
*  As can easily be verified, this can only happen on very coarse grids, when some cells and all their neighbors have not been refined even once. You should therefore only call the functions of this class if all cells are at least once refined. In practice this is not much of a restriction.
* 

*  [1.x.1]
*  Similar to the reasoning above, approximations to higher derivatives can be computed in a similar fashion. For example, the tensor of second derivatives is approximated by the formula  [2.x.15]  where  [2.x.16]  denotes the outer product of two vectors. Note that unlike the true tensor of second derivatives, its approximation is not necessarily symmetric. This is due to the fact that in the derivation, it is not clear whether we shall consider as projected second derivative the term  [2.x.17]  or  [2.x.18] . Depending on which choice we take, we obtain one approximation of the tensor of second derivatives or its transpose. To avoid this ambiguity, as result we take the symmetrized form, which is the mean value of the approximation and its transpose.
*  The returned value on each cell is the spectral norm of the approximated tensor of second derivatives, i.e. the largest eigenvalue by absolute value. This equals the largest curvature of the finite element field at each cell, and the spectral norm is the matrix norm associated to the  [2.x.19]  vector norm.
*  Even higher than the second derivative can be obtained along the same lines as exposed above.
* 

*  [1.x.2]
*  If you would like to base a refinement criterion upon these approximation of the derivatives, you will have to scale the results of this class by an appropriate power of the mesh width. For example, since  [2.x.20] , it might be the right thing to scale the indicators as  [2.x.21] , i.e.  [2.x.22] , i.e. the right power is  [2.x.23] .
*  Likewise, for the second derivative, one should choose a power of the mesh size  [2.x.24]  one higher than for the gradient.
* 

*  [1.x.3]
*  The formulae for the computation of approximations to the gradient and to the tensor of second derivatives shown above are very much alike. The basic difference is that in one case the finite difference quotient is a scalar, while in the other case it is a vector. For higher derivatives, this would be a tensor of even higher rank. We then have to form the outer product of this difference quotient with the distance vector  [2.x.25] , symmetrize it, contract it with the matrix  [2.x.26]  and compute its norm. To make the implementation simpler and to allow for code reuse, all these operations that are dependent on the actual order of the derivatives to be approximated, as well as the computation of the quantities entering the difference quotient, have been separated into auxiliary nested classes (names  [2.x.27]  and  [2.x.28]  and the main algorithm is simply passed one or the other data types and asks them to perform the order dependent operations. The main framework that is independent of this, such as finding all active neighbors, or setting up the matrix  [2.x.29]  is done in the main function  [2.x.30] 
*  Due to this way of operation, the class may be easily extended for higher order derivatives than are presently implemented. Basically, only an additional class along the lines of the derivative descriptor classes  [2.x.31]  Gradient and  [2.x.32]  has to be implemented, with the respective alias and functions replaced by the appropriate analogues for the derivative that is to be approximated.
* 

* 
*  [2.x.33] 

* 
* [0.x.1]*
   This function is used to obtain an approximation of the gradient. Pass it   the DoF handler object that describes the finite element field, a nodal   value vector, and receive the cell-wise Euclidean norm of the   approximated gradient.     The last parameter denotes the solution component, for which the gradient   is to be computed. It defaults to the first component. For scalar   elements, this is the only valid choice; for vector-valued ones, any   component between zero and the number of vector components can be given   here.     In a parallel computation the  [2.x.34]  vector needs to contain the   locally relevant unknowns.  
* [0.x.2]*
   Call the function above with <tt>mapping=MappingQGeneric [2.x.35]   
* [0.x.3]*
   This function is the analogue to the one above, computing finite   difference approximations of the tensor of second derivatives. Pass it   the DoF handler object that describes the finite element field, a nodal   value vector, and receive the cell-wise spectral norm of the approximated   tensor of second derivatives. The spectral norm is the matrix norm   associated to the  [2.x.36]  vector norm.     The last parameter denotes the solution component, for which the gradient   is to be computed. It defaults to the first component. For scalar   elements, this is the only valid choice; for vector-valued ones, any   component between zero and the number of vector components can be given   here.     In a parallel computation the  [2.x.37]  vector needs to contain the   locally relevant unknowns.  
* [0.x.4]*
   Call the function above with <tt>mapping=MappingQGeneric [2.x.38]   
* [0.x.5]*
   This function calculates the <tt>order</tt>-th order approximate   derivative and returns the full tensor for a single cell.     The last parameter denotes the solution component, for which the gradient   is to be computed. It defaults to the first component. For scalar   elements, this is the only valid choice; for vector-valued ones, any   component between zero and the number of vector components can be given   here.     In a parallel computation the  [2.x.39]  vector needs to contain the   locally relevant unknowns.  
* [0.x.6]*
   Same as above, with <tt>mapping=MappingQGeneric [2.x.40]   
* [0.x.7]*
   Return the norm of the derivative.  
* [0.x.8]*
   Exception  
* [0.x.9]*
   Exception  
* [0.x.10]

include/deal.II-translator/numerics/dof_output_operator.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/dof_output_operator_0.txt
[0.x.0]*
   An output operator writing a separate file in each step and writing the   vectors as finite element functions with respect to a given DoFHandler.  
* [0.x.1]     Constructor. The <tt>filename</tt> is the common base name of     all files and the argument <tt>digits</tt> should be the number     of digits of the highest number in the sequence. File names by     default have the form "outputNNN" with NNN the number set by the     last step command. Numbers with less digits are filled with     zeros from the left.    
* [0.x.2]

include/deal.II-translator/numerics/dof_print_solver_step_0.txt
[0.x.0]*
 Print intermediate solutions in solvers.  This is derived from a solver class provided as template argument.  It implements the  [2.x.0]  function of the solver using a DoFHandler. This way, the intermediate vectors can be viewed as finite element functions. This class might be used first to understand how solvers work (for example to visualize the smoothing properties of various solvers, e.g. in a multigrid context), and second to investigate why and how a solver fails to solve certain classes of problems.
*  Objects of this class are provided with a solver class through a template argument, and with a file name (as a string), with which a new file is constructed in each iteration (named <tt>basename.[step].[suffix]</tt>) and into which the solution is written as a finite element field using the DataOut class. Please note that this class may produce enormous amounts of data!
* 

* 
*  [2.x.1] 

* 
* [0.x.1]*
   Constructor.  First, we take the arguments needed for the solver.  [2.x.2]    data_out is the object doing the output as a finite element function.     One output file with the name <tt>basename.[step].[suffix]</tt> will be   produced for each iteration step.  
* [0.x.2]*
   Call-back function for the iterative method.  
* [0.x.3]*
   Output object.  
* [0.x.4]*
   Base of filenames.  
* [0.x.5]

include/deal.II-translator/numerics/error_estimator.templates_0.txt
[0.x.0]*
   All small temporary data objects that are needed once per thread by the   several functions of the error estimator are gathered in this struct.   The reason for this structure is mainly that we have a number of   functions that operate on cells or faces and need a number of small   temporary data objects. Since these functions may run in parallel, we   cannot make these objects member variables of the enclosing class. On   the other hand, declaring them locally in each of these functions would   require their reallocating every time we visit the next cell or face,   which we found can take a significant amount of time if it happens   often even in the single threaded case (10-20 per cent in our   measurements); however, most importantly, memory allocation requires   synchronization in multithreaded mode. While that is done by the C++   library and has not to be handcoded, it nevertheless seriously damages   the ability to efficiently run the functions of this class in parallel,   since they are quite often blocked by these synchronization points,   slowing everything down by a factor of two or three.     Thus, every thread gets an instance of this class to work with and   needs not allocate memory itself, or synchronize with other threads.     The sizes of the arrays are initialized with the maximal number of   entries necessary for the hp-case. Within the loop over individual   cells, we then resize the arrays as necessary. Since for  [2.x.0]    resizing to a smaller size doesn't imply memory allocation, this is   fast.  
* [0.x.1]*
     The finite element to be used.    
* [0.x.2]*
     The quadrature formulas to be used for the faces.    
* [0.x.3]*
     FEFaceValues objects to integrate over the faces of the current and     potentially of neighbor cells.    
* [0.x.4]*
     A vector to store the jump of the normal vectors in the quadrature     points for each of the solution vectors (i.e. a temporary value).     This vector is not allocated inside the functions that use it, but     rather globally, since memory allocation is slow, in particular in     presence of multiple threads where synchronization makes things even     slower.    
* [0.x.5]*
     A vector for the gradients of the finite element function on one cell         Let psi be a short name for <tt>a grad u_h</tt>, where the third     index be the component of the finite element, and the second index     the number of the quadrature point. The first index denotes the index     of the solution vector.    
* [0.x.6]*
     The same vector for a neighbor cell    
* [0.x.7]*
     The normal vectors of the finite element function on one face    
* [0.x.8]*
     Normal vectors of the opposing face.    
* [0.x.9]*
     Two arrays needed for the values of coefficients in the jumps, if     they are given.    
* [0.x.10]*
     Array for the products of Jacobian determinants and weights of     quadraturs points.    
* [0.x.11]*
     The subdomain id we are to care for.    
* [0.x.12]*
     The material id we are to care for.    
* [0.x.13]*
     Some more references to input data to the      [2.x.1]  function.    
* [0.x.14]*
     Constructor.    
* [0.x.15]*
     Resize the arrays so that they fit the number of quadrature points     associated with the given finite element index into the hp-     collections.    
* [0.x.16]*
   Copy data from the local_face_integrals map of a single ParallelData   object into a global such map. This is the copier stage of a WorkStream   pipeline.  
* [0.x.17]*
   Actually do the computation based on the evaluated gradients in   ParallelData.  
* [0.x.18]*
   A factor to scale the integral for the face at the boundary. Used for   Neumann BC.  
* [0.x.19]*
   A factor to scale the integral for the regular face.  
* [0.x.20]*
   A factor to scale the integral for the irregular face.  
* [0.x.21]*
   A factor used when summing up all the contribution from different faces   of each cell.  
* [0.x.22]*
   Actually do the computation on a face which has no hanging nodes (it is   regular), i.e. either on the other side there is nirvana (face is at   boundary), or the other side's refinement level is the same as that of   this side, then handle the integration of these both cases together.  
* [0.x.23]*
   The same applies as for the function above, except that integration is   over face  [2.x.2]  of  [2.x.3]  where the respective neighbor is   refined, so that the integration is a bit more complex.  
* [0.x.24]*
   Computate the error on the faces of a single cell.     This function is only needed in two or three dimensions.  The error   estimator in one dimension is implemented separately.  
* [0.x.25]

include/deal.II-translator/numerics/error_estimator_0.txt
[0.x.0]*
 Implementation of the error indicator by Kelly, De S. R. Gago, Zienkiewicz and Babuska (see  [2.x.0] ) and its modification for the hp-FEM. This error indicator tries to approximate the error per cell by integration of the jump of the gradient of the solution along the faces of each cell.  It can be understood as a gradient recovery estimator; see the survey of Ainsworth and Oden, "A Posteriori Error Estimation in Finite Element Analysis" (Wiley, 2000) for a complete discussion.
*  In the original Kelly error estimator, the contribution of each face to the cell error is scaled with the cell diagonal. In the modified version, however, we employ a scaling factor which depends on the face diagonal and polynomial degrees of the adjacent elements. The choice between the two is done by means of the enumerator, defined within the class.
* 

* 
*  [2.x.1]  In spite of the name, Kelly estimator is not truly an a posteriori error estimator, even if applied to the Poisson problem only. It gives good hints for mesh refinement, but the estimate is not to be trusted. For higher order trial spaces the integrals computed here tend to zero faster than the error itself, thus ruling out the values as error estimators. However, the modified version discussed below can be utilised to obtain the reliable error estimator by adding the residual (volume) part.
*  The error estimator really only estimates the error for the generalized Poisson equation  [2.x.2]  with either Dirichlet boundary conditions or generalized Neumann boundary conditions involving the conormal derivative  [2.x.3] .
*  The error estimator returns a vector of estimated errors per cell which can be used to feed the  [2.x.4]   [2.x.5]  and similar functions. This vector contains elements of data type  [2.x.6]  rather than  [2.x.7]  since accuracy is not important in the current context.
* 

*  [1.x.0]
*  In principle, the implementation of the error estimation is simple: let [1.x.1] be the error estimator for cell  [2.x.8] .  [2.x.9]  denotes the jump of the function in square brackets at the face, and  [2.x.10]  is a factor discussed below. This is the general form of the interface terms of the error estimator derived by Kelly et al. in the paper referenced above. The overall error estimate is then computed as [1.x.2] so that  [2.x.11]  for the Laplace equation. The functions of this class compute a vector of values that corresponds to  [2.x.12]  (i.e., the square root of the quantity above).
*  In the paper of Ainsworth  [2.x.13] , but this factor is a bit esoteric, stemming from interpolation estimates and stability constants which may hold for the Poisson problem, but may not hold for more general situations. Alternatively, we consider the case when  [2.x.14] , where  [2.x.15]  is the diameter of the face and  [2.x.16]  is the maximum polynomial degree of adjacent elements; or  [2.x.17] . The choice between these factors is done by means of the enumerator, provided as the last argument in all functions.
*  To perform the integration, use is made of the FEFaceValues and FESubfaceValues classes. The integration is performed by looping over all cells and integrating over faces that are not yet treated. This way we avoid integration on faces twice, once for each time we visit one of the adjacent cells. In a second loop over all cells, we sum up the contributions of the faces (which are the integrated square of the jumps times some factor) of each cell and take the square root.
*  The integration is done using a quadrature formula on the face provided by the caller of the estimate() functions declared by this class. For linear trial functions (FE_Q(1)), QGauss with two points or even the QMidpoint rule might actually suffice. For higher order elements, it is necessary to utilize higher order quadrature formulae with `fe.degree+1` Gauss points.
*  We store the contribution of each face in a  [2.x.18]  as provided by the C++ standard library, with the iterator pointing to that face being the key into the map. When looping the second time over all cells, we have to sum up the contributions of the faces and take the square root. For the Kelly estimator, the multiplication with  [2.x.19]  is done in the second loop. By doing so we avoid problems to decide with which  [2.x.20]  to multiply, that of the cell on the one or that of the cell on the other side of the face. Whereas for the hp-estimator the  [2.x.21]  stores integrals multiplied by  [2.x.22] , which are then summed in the second loop.
*   [2.x.23]  ( [2.x.24] ) is taken to be the greatest length of the diagonals of the cell (face). For more or less uniform cells (faces) without deformed angles, this coincides with the diameter of the cell (face).
* 

*  [1.x.3]
*  If the finite element field for which the error is to be estimated is vector-valued, i.e. the finite element has more than one component, then all the above can be applied to all or only some components at the same time. The main function of this class takes a list of flags denoting the components for which components the error estimator is to be applied; by default, it is a list of only  [2.x.25]  meaning that all variables shall be treated.
*  In case the different components of a field have different physical meaning (for example velocity and pressure in the Stokes equations), it would be senseless to use the same coefficient for all components. In that case, you can pass a function with as many components as there are components in the finite element field and each component of the error estimator will then be weighted by the respective component in this coefficient function. In the other case, when all components have the same meaning (for example the displacements in Lam&eacute;'s equations of elasticity), you can specify a scalar coefficient which will then be used for all components.
* 

*  [1.x.4]
*  If the face is at the boundary, i.e. there is no neighboring cell to which the jump in the gradient could be computed, there are two possibilities:  [2.x.26]   [2.x.27]  The face belongs to a Dirichlet boundary. Then the face is not considered, which can be justified looking at a dual problem technique and should hold exactly if the boundary can be approximated exactly by the finite element used (i.e. it is a linear boundary for linear finite elements, quadratic for isoparametric quadratic elements, etc). For boundaries which can not be exactly approximated, one should consider the difference  [2.x.28]  on the face,  [2.x.29]  being a dual problem's solution which is zero at the true boundary and  [2.x.30]  being an approximation, which in most cases will be zero on the numerical boundary. Since on the numerical boundary  [2.x.31]  will not be zero in general, we would get another term here, but this one is neglected for practical reasons, in the hope that the error made here will tend to zero faster than the energy error we wish to estimate.
*  Though no integration is necessary, in the list of face contributions we store a zero for this face, which makes summing up the contributions of the different faces to the cells easier.
*   [2.x.32]  The face belongs to a Neumann boundary.  In this case, the contribution of the face  [2.x.33]  looks like [1.x.5] where  [2.x.34]  is the Neumann boundary function,  [2.x.35]  and  [2.x.36]  for the Kelly and hp-estimator, respectively. If the finite element is vector- valued, then obviously the function denoting the Neumann boundary conditions needs to be vector-valued as well.
*   [2.x.37]  No other boundary conditions are considered.  [2.x.38] 
*  In practice, if you have Robin boundary conditions or are too lazy to accurately describe Neumann values, then this is rarely an issue: if you don't say anything in the map about a particular part of the boundary then the Kelly indicator will simply assume that the solution is correct on that part of the boundary and not touch it. Of course, if you have a have a Neumann or Robin boundary, that isn't quite true, there is going to be a difference between the normal derivative of the numerical solution and the Neumann values these normal derivatives should equal. So if we simply ignore those parts of the boundary, we'll underestimate the error. In practice, this rarely appears to be a problem
* 
*  -  you may not refine the cell this time around but you'll probably refine it in the next refinement step and everything is good again. After all, for all problems but the Laplace equation, the Kelly indicator is only an indicator, not an estimator, and so the values it computes are not exact error representations anyway.
* 

*  [1.x.6]
*  The integration along faces with hanging nodes is quite tricky, since one of the elements has to be shifted one level up or down. See the documentation for the FESubFaceValues class for more information about technical issues regarding this topic.
*  In praxi, since we integrate over each face only once, we do this when we are on the coarser one of the two cells adjacent to a subface (a subface is defined to be the child of a face; seen from the coarse cell, it is a subface, while seen from the refined cell it is one of its faces). The reason is that finding neighborship information is a bit easier then, but that's all practical reasoning, nothing fundamental.
*  Since we integrate from the coarse side of the face, we have the mother face readily at hand and store the result of the integration over that mother face (being the sum of the integrals along the subfaces) in the abovementioned map of integrals as well. This consumes some memory more than needed, but makes the summing up of the face contributions to the cells easier, since then we have the information from all faces of all cells at hand and need not think about explicitly determining whether a face was refined or not. The same applies for boundary faces, see above.
* 

*  [1.x.7]
*  In some cases, for example in time-dependent problems, one would like to compute the error estimates for several solution vectors on the same grid at once, with the same coefficients, boundary condition object, etc, e.g. for the solutions on several successive time steps. One could then call the functions of this class several times for each solution. However, the largest factor in the computation of the error estimates (in terms of computing time) is initialization of FEFaceValues and FESubFaceValues objects, and iterating through all faces and subfaces. If the solution vectors live on the same grid, this effort can be reduced significantly by treating all solution vectors at the same time, initializing the FEFaceValues objects only once per cell and for all solution vectors at once, and also only looping through the triangulation only once. For this reason, besides the  [2.x.39]  function in this class that takes a single input vector and returns a single output vector, there is also a function that accepts several in- and output vectors at the same time.
* 

* 
*  [2.x.40] 

* 
* [0.x.1]*
   The enum type given to the class functions to decide on the scaling   factors of the face integrals.  
* [0.x.2]*
   Implementation of the error estimator described above. You may give a   coefficient, but there is a default value which denotes the constant   coefficient with value one. The coefficient function may either be a   scalar one, in which case it is used for all components of the finite   element, or a vector-valued one with as many components as there are in   the finite element; in the latter case, each component is weighted by the   respective component in the coefficient.     You might give a list of components you want to evaluate, in case the   finite element used by the DoFHandler object is vector-valued. You then   have to set those entries to true in the bit-vector  [2.x.41]    (see    [2.x.42]    ) for which the respective component is to be used in the error   estimator. The default is to use all components, which is done by either   providing a bit-vector with all-set entries, or an empty bit-vector.     The  [2.x.43]  parameter indicates whether we shall compute   indicators for all cells (in case its value is the default,    [2.x.44]  or only for the cells belonging   to a certain subdomain with the given indicator. The latter case is used   for parallel computations where all processor nodes have the global grid   stored, and could well compute all the indicators for all cells   themselves, but where it is more efficient to have each process compute   only indicators for the cells it owns, and have them exchange the   resulting information afterwards. This is in particular true for the case   where meshes are very large and computing indicators for  [2.x.45]  every cell   is too expensive, while computing indicators for only local cells is   acceptable. Note that if you only ask for the indicators of a certain   subdomain to be computed, you must nevertheless make sure that this   function has access to the correct node values of  [2.x.46]  all degrees of   freedom. This is since the function needs to access DoF values on   neighboring cells as well, even if they belong to a different subdomain.     The  [2.x.47]  parameter has a similar meaning: if not set to its   default value (which is  [2.x.48]  it means that   indicators will only be computed for cells with this particular material   id.     The  [2.x.49]  parameter used to indicate the number of threads to be   used to compute the error estimator. This parameter is now ignored, with   the number of threads determined automatically. The parameter is retained   for compatibility with old versions of the library.     The  [2.x.50]  parameter is used to choose the scaling factor for the   integral over cell's faces.    
*  [2.x.51]  If the DoFHandler object given as an argument to this function   builds on a  [2.x.52]  this function skips   computations on all cells that are not locally owned. In that case, the   only valid value for the subdomain_id argument (besides the invalid   value) is the subdomain id that is associated with the currently   processor, as reported by    [2.x.53]  Even   though nothing is computed on cells that we don't locally own, the error   indicator vector must still have a length equal to the number of active   cell in the mesh as reported by    [2.x.54]   
* [0.x.3]*
   Call the  [2.x.55]  function, see above, with   <tt>mapping=MappingQGeneric [2.x.56]   
* [0.x.4]*
   Same function as above, but accepts more than one solution vector and   returns one error vector for each solution vector. For the reason of   existence of this function, see the general documentation of this class.     Since we do not want to force the user of this function to copy around   their solution vectors, the vector of solution vectors takes pointers to   the solutions, rather than being a vector of vectors. This makes it   simpler to have the solution vectors somewhere in memory, rather than to   have them collected somewhere special. (Note that it is not possible to   construct of vector of references, so we had to use a vector of   pointers.)  
* [0.x.5]*
   Call the  [2.x.57]  function, see above, with   <tt>mapping=MappingQGeneric [2.x.58]   
* [0.x.6]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.7]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.8]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.9]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.10]*
   Exception  
* [0.x.11]*
   Exception  
* [0.x.12]*
   Exception  
* [0.x.13]*
   Exception  
* [0.x.14]*
   Exception  
* [0.x.15]*
 This is a specialization of the general template for 1d. The implementation is sufficiently different for 1d to justify this specialization. The basic difference between 1d and all other space dimensions is that in 1d, there are no faces of cells, just the vertices between line segments, so we have to compute the jump terms differently. However, this class offers exactly the same public functions as the general template, so that a user will not see any difference.

* 
* [0.x.16]*
   The enum type given to the class functions to decide on the scaling   factors of the face integrals.  
* [0.x.17]*
   Implementation of the error estimator described above. You may give a   coefficient, but there is a default value which denotes the constant   coefficient with value one. The coefficient function may either be a   scalar one, in which case it is used for all components of the finite   element, or a vector-valued one with as many components as there are in   the finite element; in the latter case, each component is weighted by the   respective component in the coefficient.     You might give a list of components you want to evaluate, in case the   finite element used by the DoFHandler object is vector-valued. You then   have to set those entries to true in the bit-vector  [2.x.59]  for   which the respective component is to be used in the error estimator. The   default is to use all components, which is done by either providing a   bit-vector with all-set entries, or an empty bit-vector. All the other   parameters are as in the general case used for 2d and higher.     The parameter n_threads is no longer used and will be ignored.   Multithreading is not presently implemented for 1d, but we retain the   respective parameter for compatibility with the function signature in the   general case.  
* [0.x.18]*
   Call the  [2.x.60]  function, see above, with   <tt>mapping=MappingQGeneric1<1>()</tt>.  
* [0.x.19]*
   Same function as above, but accepts more than one solution vectors and   returns one error vector for each solution vector. For the reason of   existence of this function, see the general documentation of this class.     Since we do not want to force the user of this function to copy around   their solution vectors, the vector of solution vectors takes pointers to   the solutions, rather than being a vector of vectors. This makes it   simpler to have the solution vectors somewhere in memory, rather than to   have them collected somewhere special. (Note that it is not possible to   construct of vector of references, so we had to use a vector of   pointers.)  
* [0.x.20]*
   Call the  [2.x.61]  function, see above, with   <tt>mapping=MappingQGeneric1<1>()</tt>.  
* [0.x.21]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.22]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.23]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.24]*
   Equivalent to the set of functions above, except that this one takes a   quadrature collection for hp-finite element dof handlers.  
* [0.x.25]*
   Exception  
* [0.x.26]*
   Exception  
* [0.x.27]*
   Exception  
* [0.x.28]*
   Exception  
* [0.x.29]*
   Exception  
* [0.x.30]

include/deal.II-translator/numerics/fe_field_function.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/fe_field_function_0.txt
[0.x.0]*
   This is an interpolation function for the given dof handler and the given   solution vector. The points at which this function can be evaluated MUST   be inside the domain of the dof handler, but except from this, no other   requirement is given. This function is rather slow, as it needs to   construct a quadrature object for the point (or set of points) where you   want to evaluate your finite element function. In order to do so, it   needs to find out where the points lie.     If you know in advance in which cell your points lie, you can accelerate   things a bit, by calling set_active_cell() before asking for values or   gradients of the function. If you don't do this, and your points don't   lie in the cell that is currently stored, the function    [2.x.0]  is called to find out where the   point is.   You can specify an optional mapping to use when looking for points in   the grid. If you don't do so, this function uses a Q1 mapping.     Once the FEFieldFunction knows where the points lie, it creates a   quadrature formula for those points, and calls    [2.x.1]  or  [2.x.2]  with   the given quadrature points.     If you only need the quadrature points but not the values of the finite   element function (you might want this for the adjoint interpolation), you   can also use the function compute_point_locations() alone.     An example of how to use this function is the following:    
* [1.x.0]
*      The snippet of code above will work assuming that the second   triangulation is entirely included in the first one.     FEFieldFunction is designed to be an easy way to get the results of your   computations across different, possibly non matching, grids. No knowledge   of the location of the points is assumed in this class, which makes it   rely entirely on the  [2.x.3]  utility for   its job. However the class can be fed an "educated guess" of where the   points that will be computed actually are by using the    [2.x.4]  method, so if you have a smart way to   tell where your points are, you will save a lot of computational time by   letting this class know.       [1.x.1]     When using this class with a parallel distributed triangulation object   and evaluating the solution at a particular point, not every processor   will own the cell at which the solution is evaluated. Rather, it may be   that the cell in which this point is found is in fact a ghost or   artificial cell (see    [2.x.5]    and    [2.x.6] ).   The solution can be evaluated on ghost cells, but for artificial cells   we have no access to the solution there and   functions that evaluate the solution at such a point will trigger an   exception of type  [2.x.7]      To deal with this situation, you will want to use code as follows when,   for example, evaluating the solution at the origin (here using a parallel   TrilinosWrappers vector to hold the solution):  
* [1.x.2]
*     
*  [2.x.8]   
* [0.x.1]*
     Construct a vector function. A smart pointers is stored to the dof     handler, so you have to make sure that it make sense for the entire     lifetime of this object. The number of components of this functions is     equal to the number of components of the finite element object. If a     mapping is specified, that is what is used to find out where the points     lay. Otherwise the standard Q1 mapping is used.    
* [0.x.2]*
     Set the current cell. If you know in advance where your points lie, you     can tell this object by calling this function. This will speed things     up a little.    
* [0.x.3]*
     Get one vector value at the given point. It is inefficient to use     single points. If you need more than one at a time, use the     vector_value_list() function. For efficiency reasons, it is better if     all the points lie on the same cell. This is not mandatory, however it     does speed things up.        
*  [2.x.9]  When using this function on a      [2.x.10]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.11] ).     See the section in the general documentation of this class for more     information.    
* [0.x.4]*
     Return the value of the function at the given point. Unless there is     only one component (i.e. the function is scalar), you should state the     component you want to have evaluated; it defaults to zero, i.e. the     first component. It is inefficient to use single points. If you need     more than one at a time, use the vector_value_list() function. For     efficiency reasons, it is better if all the points lie on the same     cell. This is not mandatory, however it does speed things up.        
*  [2.x.12]  When using this function on a      [2.x.13]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.14] ).     See the section in the general documentation of this class for more     information.    
* [0.x.5]*
     Set  [2.x.15]  to the point values of the specified component of the     function at the  [2.x.16]  It is assumed that  [2.x.17]  already has the     right size, i.e. the same size as the points array. This is rather     efficient if all the points lie on the same cell. If this is not the     case, things may slow down a bit.        
*  [2.x.18]  When using this function on a      [2.x.19]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.20] ).     See the section in the general documentation of this class for more     information.    
* [0.x.6]*
     Set  [2.x.21]  to the point values of the function at the  [2.x.22]  It     is assumed that  [2.x.23]  already has the right size, i.e. the same     size as the points array. This is rather efficient if all the points     lie on the same cell. If this is not the case, things may slow down a     bit.        
*  [2.x.24]  When using this function on a      [2.x.25]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.26] ).     See the section in the general documentation of this class for more     information.    
* [0.x.7]*
     Return the gradient of all components of the function at the given     point.  It is inefficient to use single points. If you need more than     one at a time, use the vector_value_list() function. For efficiency     reasons, it is better if all the points lie on the same cell. This is     not mandatory, however it does speed things up.        
*  [2.x.27]  When using this function on a      [2.x.28]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.29] ).     See the section in the general documentation of this class for more     information.    
* [0.x.8]*
     Return the gradient of the specified component of the function at the     given point. It is inefficient to use single points. If you need more     than one at a time, use the vector_value_list() function. For efficiency     reasons, it is better if all the points lie on the same cell. This is     not mandatory, however it does speed things up.        
*  [2.x.30]  When using this function on a      [2.x.31]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.32] ).     See the section in the general documentation of this class for more     information.    
* [0.x.9]*
     Return the gradient of all components of the function at all the given     points. This is rather efficient if all the points lie on the same     cell. If this is not the case, things may slow down a bit.        
*  [2.x.33]  When using this function on a      [2.x.34]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.35] ).     See the section in the general documentation of this class for more     information.    
* [0.x.10]*
     Return the gradient of the specified component of the function at all     the given points.  This is rather efficient if all the points lie on     the same cell. If this is not the case, things may slow down a bit.        
*  [2.x.36]  When using this function on a      [2.x.37]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.38] ).     See the section in the general documentation of this class for more     information.    
* [0.x.11]*
     Compute the Laplacian of a given component at point <tt>p</tt>.        
*  [2.x.39]  When using this function on a      [2.x.40]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.41] ).     See the section in the general documentation of this class for more     information.    
* [0.x.12]*
     Compute the Laplacian of all components at point <tt>p</tt> and store     them in <tt>values</tt>.        
*  [2.x.42]  When using this function on a      [2.x.43]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.44] ).     See the section in the general documentation of this class for more     information.    
* [0.x.13]*
     Compute the Laplacian of one component at a set of points.        
*  [2.x.45]  When using this function on a      [2.x.46]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.47] ).     See the section in the general documentation of this class for more     information.    
* [0.x.14]*
     Compute the Laplacians of all components at a set of points.        
*  [2.x.48]  When using this function on a      [2.x.49]  you may get an exception when     trying to evaluate the solution at a point that lies on an artificial     cell (see      [2.x.50] ).     See the section in the general documentation of this class for more     information.    
* [0.x.15]*
     Given a set of points located in the domain (or, in the case of     a parallel Triangulation, in the locally owned part of the domain     or on the ghost cells for the current processor), sort these     points into buckets for each of the cells on which at least     one of the points is located.         This function fills three output vectors:  [2.x.51]   [2.x.52]      and  [2.x.53]  The first is a list of the cells that contain the     points, the second is a list of quadrature points matching each     cell of the first list, and the third contains the index of the     given quadrature points, i.e.,  [2.x.54]  ends up as     the 5th quadrature point in the 4th cell.          [2.x.55]  This function returns the number of cells that       collectively contain the set of points give as  [2.x.56]        points. This also equals the lengths of the output arrays.         This function simply calls  [2.x.57]  :     using the original function avoids computing a     new Cache at every function call.    
* [0.x.16]*
     Typedef holding the local cell_hint.    
* [0.x.17]*
     Pointer to the dof handler.    
* [0.x.18]*
     A reference to the actual data vector.    
* [0.x.19]*
     A reference to the mapping being used.    
* [0.x.20]*
     The Cache object    
* [0.x.21]*
     The latest cell hint.    
* [0.x.22]*
     Given a cell, return the reference coordinates of the given point     within this cell if it indeed lies within the cell. Otherwise return an     uninitialized  [2.x.58]  object.    
* [0.x.23]*
      [2.x.59]  Use  [2.x.60]  without the     DoFHandlerType template instead.    
* [0.x.24]

include/deal.II-translator/numerics/histogram_0.txt
[0.x.0]*
 This class provides some facilities to generate 2d and 3d histograms. It is used by giving it one or several data sets and a rule how to break the range of values therein into intervals (e.g. linear spacing or logarithmic spacing of intervals). The values are then sorted into the different intervals and the number of values in each interval is stored for output later. In case only one data set was given, the resulting histogram will be a 2d one, while it will be a 3d one if more than one data set was given. For more than one data set, the same intervals are used for each of them anyway, to make comparison easier.
* 

*  [1.x.0]
*  At present, the following schemes for interval spacing are implemented:  [2.x.0]   [2.x.1]  Linear spacing: The intervals are distributed in constant steps between the minimum and maximum values of the data.  [2.x.2]  Logarithmic spacing: The intervals are distributed in constant steps between the minimum and maximum values of the logs of the values. This scheme is only useful if the data has only positive values. Negative and zero values are sorted into the leftmost interval.  [2.x.3] 
*  To keep programs extensible, you can use the two functions  [2.x.4]  get_interval_spacing_names and  [2.x.5]  which always give you a complete list of spacing formats presently supported and are able to generate the respective value of the  [2.x.6]  If you use them, you can write your program in a way such that it only needs to be recompiled to take effect of newly added formats, without changing your code.
* 

*  [1.x.1]
*  At present, only GNUPLOT output is supported.
* 

* 

* 
*  [2.x.7] 

* 
* [0.x.1]*
   Definition of several ways to arrange the spacing of intervals.  
* [0.x.2]*
     Space intervals linearly.    
* [0.x.3]*
     Space intervals logarithmically.    
* [0.x.4]*
   Take several lists of values, each on to produce one histogram that will   then be arrange one behind each other.     Using several data sets at once allows to compare them more easily, since   the intervals into which the data is sorted is the same for all data   sets.     The histograms will be arranged such that the computed intervals of the   <tt>values[i][j]</tt> form the x-range, and the number of values in each   interval will be the y-range (for 2d plots) or the z-range (for 3d   plots). For 3d plots, the  [2.x.8]  parameter is used to assign each   data set a value in the y direction, which is the depth coordinate in the   resulting plot. For 2d plots, the  [2.x.9]  are ignored.     If you give only one data set, i.e. <tt>values.size()==1</tt>, then the   resulting histogram will be a 2d one.      [2.x.10]  denotes the number of intervals into which the data will   be sorted;  [2.x.11]  denotes the way the bounds of the   intervals are computed. Refer to the general documentation for more   information on this.  
* [0.x.5]*
   This function is only a wrapper to the above one in case you have only   one data set.  
* [0.x.6]*
   Write the histogram computed by the  [2.x.12]  function to a stream in a   format suitable to the GNUPLOT program. The function generates 2d or 3d   histograms.  
* [0.x.7]*
   Return allowed names for the interval spacing as string. At present this   is "linear|logarithmic".  
* [0.x.8]*
   Get a string containing one of the names returned by the above function   and return the respective value of  [2.x.13]  Throw an error if   the string is no valid one.  
* [0.x.9]*
   Determine an estimate for the memory consumption (in bytes) of this   object.  
* [0.x.10]*
   Exception.  
* [0.x.11]*
   Exception.  
* [0.x.12]*
   Exception.  
* [0.x.13]*
   Structure denoting one interval.  
* [0.x.14]*
     Constructor. Sets the bounds and sets the number of values in this     interval to zero.    
* [0.x.15]*
     Determine an estimate for the memory consumption (in bytes) of this     object.    
* [0.x.16]*
     Left bound of the interval.    
* [0.x.17]*
     Right bound of the interval.    
* [0.x.18]*
     Number of values in this interval.    
* [0.x.19]*
   "Less-than" operation which finds the minimal positive value by sorting   zero and negative value to be larger than the largest positive number.   Used to find the lower bound of the leftmost interval in the logarithmic   case interval spacing scheme.     Return  [2.x.14]  if (<tt>n1<n2</tt>, and (<tt>n1>0</tt> or   <tt>n2<0</tt>)), or (n2<n1 and n1>0 and n2<=0). This in effect sorts all   negative numbers to be larger than the largest positive number.  
* [0.x.20]*
   Vector holding one set of intervals for each data set given to the  [2.x.15]    evaluate function.  
* [0.x.21]*
   Values for the depth axis of 3d histograms. Stored in the  [2.x.16]    function.  
* [0.x.22]

include/deal.II-translator/numerics/history_0.txt
[0.x.0]*
 A helper class to store a finite-size collection of objects of type `T`. If the number of elements exceeds the specified maximum size of the container, the oldest element is removed. Additionally, random access and removal of elements is implemented. Indexing is done relative to the last added element.
*  In order to optimize the container for usage with memory-demanding objects (i.e. linear algebra vectors), the removal of an element does not free the memory. Instead the element is being kept in a separate cache so that subsequent addition does not require re-allocation of memory.
*  The primary usage of this class is in solvers to store a history of vectors. That is, if at the iteration  [2.x.0]  we store  [2.x.1]  vectors from previous iterations  [2.x.2] , then addition of the new element will make the object contain elements from iterations  [2.x.3] .

* 
* [0.x.1]*
   Constructor.      [2.x.4]  max_elements maximum number of elements to be stored in the   history.  
* [0.x.2]*
   Add new object by copying.   If the maximum number of elements is reached, the oldest element is   removed.  
* [0.x.3]*
   Remove an element with index  [2.x.5]    counting from the last added element.   `index==0` therefore corresponds to removing   the newset element.  
* [0.x.4]*
   Read/write access to an element with index  [2.x.6]    counting from the last added element.   `index==0` therefore corresponds to the newset element.  
* [0.x.5]*
   Read access to an element with index  [2.x.7]    counting from the last added element.   `index==0` therefore corresponds to the newset element.  
* [0.x.6]*
   Return the current size of the history.  
* [0.x.7]*
   Return the maximum allowed size of the history.  
* [0.x.8]*
   Clear the contents, including the cache.  
* [0.x.9]*
   Maximum number of elements to be stored.  
* [0.x.10]*
   A deque which stores the data.  
* [0.x.11]*
   A deque to cache data, in particular for the case when   removal is followed by addition.  
* [0.x.12]

include/deal.II-translator/numerics/matrix_creator.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/matrix_tools_0.txt
[0.x.0]*
 This namespace provides functions that assemble certain standard matrices for a given triangulation, using a given finite element, a given mapping and a quadrature formula.
* 

*  [1.x.0]
*  There exist two versions of almost all functions, one that takes an explicit Mapping argument and one that does not. The second one generally calls the first with an implicit  [2.x.0]  argument (i.e., with an argument of kind MappingQGeneric(1)). If your intend your code to use a different mapping than a (bi-/tri-)linear one, then you need to call the functions [1.x.1] mapping argument should be used.
*  All functions take a sparse matrix object to hold the matrix to be created. The functions assume that the matrix is initialized with a sparsity pattern (SparsityPattern) corresponding to the given degree of freedom handler, i.e. the sparsity structure is already as needed. You can do this by calling the  [2.x.1]  function.
*  Furthermore it is assumed that no relevant data is in the matrix. Some entries will be overwritten and some others will contain invalid data if the matrix wasn't empty before. Therefore you may want to clear the matrix before assemblage.
*  By default, all created matrices are `raw': they are not condensed, i.e. hanging nodes are not eliminated. The reason is that you may want to add several matrices and could then condense afterwards only once, instead of for every matrix. To actually do computations with these matrices, you have to condense the matrix using the  [2.x.2]  function; you also have to condense the right hand side accordingly and distribute the solution afterwards. Alternatively, you can give an optional argument AffineConstraints that writes cell matrix (and vector) entries with distribute_local_to_global into the global matrix and vector. This way, adding several matrices from different sources is more complicated and you should make sure that you do not mix different ways of applying constraints. Particular caution is necessary when the given AffineConstraints object contains inhomogeneous constraints: In that case, the matrix assembled this way must be the only matrix (or you need to assemble the [1.x.2] right hand side for [1.x.3] matrix you generate and add together).
*  If you want to use boundary conditions with the matrices generated by the functions of this namespace in addition to the ones in a possible AffineConstraints object, you have to use a function like <tt>apply_boundary_values</tt> with the matrix, solution, and right hand side.
* 

*  [1.x.4]
*  At present there are functions to create the following matrices:  [2.x.3]   [2.x.4]   [2.x.5]  create the matrix with entries  [2.x.6]  by numerical quadrature. Here, the  [2.x.7]  are the basis functions of the finite element space given.
*  A coefficient may be given to evaluate  [2.x.8]  instead.
*   [2.x.9]   [2.x.10]  create the matrix with entries  [2.x.11]  by numerical quadrature.
*  Again, a coefficient may be given to evaluate  [2.x.12]  instead.  [2.x.13] 
*  Make sure that the order of the Quadrature formula given to these functions is sufficiently high to compute the matrices with the required accuracy. For the choice of this quadrature rule you need to take into account the polynomial degree of the FiniteElement basis functions, the roughness of the coefficient  [2.x.14]  as well as the degree of the given  [2.x.15]  (if any).
*  Note, that for vector-valued elements the mass matrix and the laplace matrix is implemented in such a way that each component couples only with itself, i.e. there is no coupling of shape functions belonging to different components. If the degrees of freedom have been sorted according to their vector component (e.g., using  [2.x.16]  then the resulting matrices will be block diagonal.
*  If the finite element for which the mass matrix or the Laplace matrix is to be built has more than one component, the functions accept a single coefficient as well as a vector valued coefficient function. For the latter case, the number of components must coincide with the number of components of the system finite element.
* 

*  [1.x.5]
*  The create_boundary_mass_matrix() creates the matrix with entries  [2.x.17] , where  [2.x.18]  is the union of boundary parts with indicators contained in a  [2.x.19]  const Function<spacedim,number>*> passed to the function (i.e. if you want to set up the mass matrix for the parts of the boundary with indicators zero and 2, you pass the function a map with key type  [2.x.20]  as the parameter  [2.x.21]  containing the keys zero and 2). The size of the matrix is equal to the number of degrees of freedom that have support on the boundary, i.e. it is  [2.x.22] not [2.x.23]  a matrix on all degrees of freedom, but only a subset. (The  [2.x.24]  in the formula are the subset of basis functions which have at least part of their support on  [2.x.25] .) In order to determine which shape functions are to be considered, and in order to determine in which order, the function takes a  [2.x.26]  this object maps global DoF numbers to a numbering of the degrees of freedom located on the boundary, and can be obtained using the function  [2.x.27] 
*  In order to work, the function needs a matrix of the correct size, built on top of a corresponding sparsity pattern. Since we only work on a subset of the degrees of freedom, we can't use the matrices and sparsity patterns that are created for the entire set of degrees of freedom. Rather, you should use the  [2.x.28]  function to create the correct sparsity pattern, and build a matrix on top of it.
*  Note that at present there is no function that computes the mass matrix for  [2.x.29] all [2.x.30]  shape functions, though such a function would be trivial to implement.
* 

*  [1.x.6]
*  In many cases, you will not only want to build the matrix, but also a right hand side, which will give a vector with  [2.x.31] . For this purpose, each function exists in two versions, one only building the matrix and one also building the right hand side vector. If you want to create a right hand side vector without creating a matrix, you can use the  [2.x.32]  function. The use of the latter may be useful if you want to create many right hand side vectors.
* 

* 
*  [2.x.33] 

* 
* [0.x.1]*
   Assemble the mass matrix. If no coefficient is given (i.e., if the   pointer to a function object is zero as it is by default), the   coefficient is taken as being constant and equal to one.   In case you want to specify  [2.x.34]  and use the default argument   for the coefficient you have to specify the (unused) coefficient argument   as  [2.x.35] .     If the library is configured to use multithreading, this function works   in parallel.     The optional argument  [2.x.36]  allows to apply constraints on the   resulting matrix directly. Note, however, that this becomes difficult   when you have inhomogeneous constraints and later want to add several   such matrices, for example in time dependent settings such as the main   loop of  [2.x.37] .     See the general documentation of this namespace for more information.  
* [0.x.2]*
   Call the create_mass_matrix() function, see above, with   <tt>mapping=MappingQGeneric [2.x.38]   
* [0.x.3]*
   Assemble the mass matrix and a right hand side vector. If no coefficient   is given (i.e., if the pointer to a function object is zero as it is by   default), the coefficient is taken as being constant and equal to one.   In case you want to specify  [2.x.39]  and use the default argument   for the coefficient you have to specify the (unused) coefficient argument   as  [2.x.40] .     If the library is configured to use multithreading, this function works   in parallel.     The optional argument  [2.x.41]  allows to apply constraints on the   resulting matrix directly. Note, however, that this becomes difficult   when you have inhomogeneous constraints and later want to add several   such matrices, for example in time dependent settings such as the main   loop of  [2.x.42] .     See the general documentation of this namespace for more information.  
* [0.x.4]*
   Call the create_mass_matrix() function, see above, with   <tt>mapping=MappingQGeneric [2.x.43]   
* [0.x.5]*
   Same function as above, but for hp-objects.  
* [0.x.6]*
   Same function as above, but for hp-objects.  
* [0.x.7]*
   Same function as above, but for hp-objects.  
* [0.x.8]*
   Same function as above, but for hp-objects.  
* [0.x.9]*
   Assemble the mass matrix and a right hand side vector along the boundary.     The matrix is assumed to already be initialized with a suiting sparsity   pattern (the DoFHandler provides an appropriate function).     If the library is configured to use multithreading, this function works   in parallel.      [2.x.44]   [2.x.45]  an optional weight for the computation of the mass   matrix. If no weight is given, it is set to one.   In case you want to specify  [2.x.46]  and use the default argument   for the coefficient you have to specify the (unused) coefficient argument   as  [2.x.47] .      [2.x.48]   [2.x.49]  if the components in  [2.x.50]  and    [2.x.51]  do not coincide, this vector allows them to be remapped. If the   vector is not empty, it has to have one entry for each component in  [2.x.52]    dof. This entry is the component number in  [2.x.53]  that   should be used for this component in  [2.x.54]  By default, no remapping is   applied.      [2.x.55]  This function does not work for finite elements with cell-dependent   shape functions.  
* [0.x.10]*
   Call the create_boundary_mass_matrix() function, see above, with   <tt>mapping=MappingQGeneric [2.x.56]   
* [0.x.11]*
   Same function as above, but for hp-objects.  
* [0.x.12]*
   Same function as above, but for hp-objects.  
* [0.x.13]*
   Assemble the Laplace matrix. If no coefficient is given (i.e., if the   pointer to a function object is zero as it is by default), the   coefficient is taken as being constant and equal to one.   In case you want to specify  [2.x.57]  and use the default argument   for the coefficient you have to specify the (unused) coefficient argument   as  [2.x.58] .     If the library is configured to use multithreading, this function works   in parallel.     The optional argument  [2.x.59]  allows to apply constraints on the   resulting matrix directly. Note, however, that this becomes difficult   when you have inhomogeneous constraints and later want to add several   such matrices, for example in time dependent settings such as the main   loop of  [2.x.60] .     See the general documentation of this namespace for more information.  
* [0.x.14]*
   Call the create_laplace_matrix() function, see above, with   <tt>mapping=MappingQGeneric [2.x.61]   
* [0.x.15]*
   Assemble the Laplace matrix and a right hand side vector. If no   coefficient is given, it is assumed to be constant one.   In case you want to specify  [2.x.62]  and use the default argument   for the coefficient you have to specify the (unused) coefficient argument   as  [2.x.63] .     If the library is configured to use multithreading, this function works   in parallel.     The optional argument  [2.x.64]  allows to apply constraints on the   resulting matrix directly. Note, however, that this becomes difficult   when you have inhomogeneous constraints and later want to add several   such matrices, for example in time dependent settings such as the main   loop of  [2.x.65] .     See the general documentation of this namespace for more information.  
* [0.x.16]*
   Call the create_laplace_matrix() function, see above, with   <tt>mapping=MappingQGeneric [2.x.66]   
* [0.x.17]*
   Like the functions above, but for hp-objects.  
* [0.x.18]*
   Like the functions above, but for hp-objects.  
* [0.x.19]*
   Like the functions above, but for hp-objects.  
* [0.x.20]*
   Like the functions above, but for hp-objects.  
* [0.x.21]*
   Exception  
* [0.x.22]*
 Provide a collection of functions operating on matrices. These include the application of boundary conditions to a linear system of equations and others.
* 

*  [1.x.7]
*  The apply_boundary_values() functions modifies a linear system to incorporate the constraints that result from Dirichlet-type boundary conditions (or, more specifically: "strong" boundary conditions). To actually do this, the functions of this name in the current namespace require a list of degree of freedom indices along with the values these degrees of freedom should have. To see how to get such a list, see the discussion of the  [2.x.67]  function as one example.
*  There are two ways to incorporate fixed degrees of freedom such as boundary nodes into a linear system, as discussed below. Both operate at either the level of local contributions to the global linear system, or the global system itself. A third way, using  [2.x.68]  performs the same process as part of adding the local contributions of one cell into the global linear system (the "assembly" step) and is the method predominantly used in the tutorial programs today.
*   [2.x.69] 
* 

* 
*  [1.x.8]
*  In the first method, we first assemble the global linear system without respect for fixed degrees of freedom, and in a second step eliminate them again from the linear system. The inclusion into the assembly process is as follows: when the matrix and vectors are set up, a list of nodes subject to Dirichlet boundary conditions is made and matrix and vectors are modified accordingly. This is done by deleting all entries in the matrix in the line of this degree of freedom, setting the main diagonal entry to a suitable positive value and the right hand side element to a value so that the solution of the linear system will have the boundary value at this node. To decouple the remaining linear system of equations and to make the system symmetric again (at least if it was before), one Gauss elimination step is performed with this line, by adding this (now almost empty) line to all other lines which couple with the given degree of freedom and thus eliminating all coupling between this degree of freedom and others. Now the respective column also consists only of zeroes, apart from the main diagonal entry. Alternatively, the functions in this namespace take a boolean parameter that allows to omit this last step, if symmetry of the resulting linear system is not required. Note that usually even CG can cope with a non-symmetric linear system with this particular structure.
*  Finding which rows contain an entry in the column for which we are presently performing a Gauss elimination step is either difficult or very simple, depending on the circumstances. If the sparsity pattern is symmetric (whether the matrix is symmetric is irrelevant here), then we can infer the rows which have a nonzero entry in the present column by looking at which columns in the present row are nonempty. In this case, we only need to look into a fixed number of rows and need not search all rows. On the other hand, if the sparsity pattern is nonsymmetric, then we need to use an iterative solver which can handle nonsymmetric matrices in any case, so there may be no need to do the Gauss elimination anyway. In fact, this is the way the function works: it takes a parameter ( [2.x.70]  that specifies whether the sparsity pattern is symmetric; if so, then the column is eliminated and the right hand side is also modified accordingly. If not, then only the row is deleted and the column is not touched at all, and all right hand side values apart from the one corresponding to the present row remain unchanged.
*  If the sparsity pattern for your matrix is non-symmetric, you must set the value of this parameter to  [2.x.71]  in any case, since then we can't eliminate the column without searching all rows, which would be too expensive (if  [2.x.72]  be the number of rows, and  [2.x.73]  the number of nonzero elements per row, then eliminating one column is an <tt>O(N*log(m))</tt> operation, since searching in each row takes <tt>log(m)</tt> operations). If your sparsity pattern is symmetric, but your matrix is not, then you might specify  [2.x.74]  as well. If your sparsity pattern and matrix are both symmetric, you might want to specify  [2.x.75]  (the complexity of eliminating one row is then <tt>O(m*log(m))</tt>, since we only have to search  [2.x.76]  rows for the respective element of the column). Given the fact that  [2.x.77]  is roughly constant, irrespective of the discretization, and that the number of boundary nodes is <tt>sqrt(N)</tt> in 2d, the algorithm for symmetric sparsity patterns is <tt>O(sqrt(N)*m*log(m))</tt>, while it would be <tt>O(N*sqrt(N)*log(m))</tt> for the general case; the latter is too expensive to be performed.
*  It seems as if we had to make clear not to overwrite the lines of other boundary nodes when doing the Gauss elimination step. However, since we reset the right hand side when passing such a node, it is not a problem to change the right hand side values of other boundary nodes not yet processed. It would be a problem to change those entries of nodes already processed, but since the matrix entry of the present column on the row of an already processed node is zero, the Gauss step does not change the right hand side. We need therefore not take special care of other boundary nodes.
*  To make solving faster, we preset the solution vector with the right boundary values (as to why this is necessary, see the discussion below in the description of local elimination). It it not clear whether the deletion of coupling between the boundary degree of freedom and other dofs really forces the corresponding entry in the solution vector to have the right value when using iterative solvers, since their search directions may contain components in the direction of the boundary node. For this reason, we perform a very simple line balancing by not setting the main diagonal entry to unity, but rather to the value it had before deleting this line, or to the first nonzero main diagonal entry if it is zero for some reason. Of course we have to change the right hand side appropriately. This is not a very good strategy, but it at least should give the main diagonal entry a value in the right order of dimension, which makes the solution process a bit more stable. A refined algorithm would set the entry to the mean of the other diagonal entries, but this seems to be too expensive.
*  In some cases, it might be interesting to solve several times with the same matrix, but for different right hand sides or boundary values. A typical case would be the solution of a time-dependent problem in which the boundary values or right hand side change, but the matrix itself does not. One may then be tempted to just assemble the matrix once and just call the  [2.x.78]  function repeatedly on the same matrix object, with a right hand side vector newly formed in each time step. However, since the modification for boundary values of the right hand side vector depends on the original matrix, this is not possible without storing the original matrix somewhere, and in every time step initializing the system matrix with the unmodified matrix stored elsewhere.  [2.x.79]  does a variation of this process by storing building blocks from which the system matrix is composed, but the general principle is the same. Alternatively, one can use the constrained_linear_operator() function. In its documentation you can also find a formal (mathematical) description of the process of modifying the matrix and right hand side vectors for boundary values.
* 

*  [1.x.9]
*  The second way of handling boundary values is to modify the local matrix and vector contributions appropriately before transferring them into the global sparse matrix and vector. This is what local_apply_boundary_values() does. The advantage is that we save the call to the apply_boundary_values function (which is expensive because it has to work on sparse data structures). On the other hand, the local_apply_boundary_values() function is called many times, even if we only have a very small number of fixed boundary nodes, and the main drawback is that this function doesn't work as expected if there are hanging nodes that also need to be treated. The reason that this function doesn't work is that it is meant to be run before distribution into the global matrix, i.e. before hanging nodes are distributed; since hanging nodes can be constrained to a boundary node, the treatment of hanging nodes can add entries again to rows and columns corresponding to boundary values and that we have already vacated in the local elimination step. To make things worse, in 3d constrained nodes can even lie on the boundary. Thus, it is imperative that boundary node elimination happens  [2.x.80]  after hanging node elimination, but this can't be achieved with local elimination of boundary nodes unless there are no hanging node constraints at all.
*  Local elimination has one additional drawback: we don't have access to the solution vector, only to the local contributions to the matrix and right hand side. The problem with this is subtle, but can lead to very hard to find difficulties: when we eliminate a degree of freedom, we delete the row and column of this unknown, and set the diagonal entry to some positive value. To make the problem more or less well-conditioned, we set this diagonal entry to the absolute value of its prior value if that was non- zero, or to the average magnitude of all other nonzero diagonal elements. Then we set the right hand side value such that the resulting solution entry has the right value as given by the boundary values. Since we add these contributions up over all local contributions, the diagonal entry and the respective value in the right hand side are added up correspondingly, so that the entry in the solution of the linear system is still valid.
*  A problem arises, however, if the diagonal entries so chosen are not appropriate for the linear system. Consider, for example, a mixed Laplace problem with matrix <tt>[[A B][C^T 0]]</tt>, where we only specify boundary values for the second component of the solution. In the mixed formulation, the stress-strain tensor only appears in either the matrix  [2.x.81]  or  [2.x.82]  so one of them may be significantly larger or smaller than the other one. Now, if we eliminate boundary values, we delete some rows and columns, but we also introduce a few entries on the diagonal of the lower right block, so that we get the system <tt>[[A' B'][C'^T X]]</tt>. The diagonal entries in the matrix  [2.x.83]  will be of the same order of magnitude as those in  [2.x.84]  Now, if we solve this system in the Schur complement formulation, we have to invert the matrix <tt>X-C'^TA'^{-1}B'</tt>. Deleting rows and columns above makes sure that boundary nodes indeed have empty rows and columns in the Schur complement as well, except for the entries in  [2.x.85]  However, the entries in  [2.x.86]  may be of significantly different orders of magnitude than those in <tt>C'^TA'^{-1}B'</tt>! If this is the case, we may run into trouble with iterative solvers. For example, assume that we start with zero entries in the solution vector and that the entries in  [2.x.87]  are several orders of magnitude too small; in this case, iterative solvers will compute the residual vector in each step and form correction vectors, but since the entries in  [2.x.88]  are so small, the residual contributions for boundary nodes are really small, despite the fact that the boundary nodes are still at values close to zero and not in accordance with the prescribed boundary values. Since the residual is so small, the corrections the iterative solver computes are very small, and in the end the solver will indicate convergence to a small total residual with the boundary values still being significantly wrong.
*  We avoid this problem in the global elimination process described above by 'priming' the solution vector with the correct values for boundary nodes. However, we can't do this for the local elimination process. Therefore, if you experience a problem like the one above, you need to either increase the diagonal entries in  [2.x.89]  to a size that matches those in the other part of the Schur complement, or, simpler, prime the solution vector before you start the solver.
*  In conclusion, local elimination of boundary nodes only works if there are no hanging nodes and even then doesn't always work fully satisfactorily.
* 

* 
*  [2.x.90] 

* 
* [0.x.23]*
   Import namespace MatrixCreator for backward compatibility with older   versions of deal.II in which these namespaces were classes and class   MatrixTools was publicly derived from class MatrixCreator.  
* [0.x.24]*
   Apply Dirichlet boundary conditions to the system matrix and vectors as   described in the general documentation of this namespace.  
* [0.x.25]*
   Apply Dirichlet boundary conditions to the system matrix and vectors as   described in the general documentation of this namespace. This function   works for block sparse matrices and block vectors.  
* [0.x.26]*
   Apply Dirichlet boundary conditions to the system matrix and vectors as   described in the general documentation of this namespace. This function   works on the classes that are used to wrap PETSc objects.     [1.x.10] This function is not very efficient: it needs to   alternatingly read and write into the matrix, a situation that PETSc does   not handle well. In addition, we only get rid of rows corresponding to   boundary nodes, but the corresponding case of deleting the respective   columns (i.e. if  [2.x.91]  is  [2.x.92]  is not presently   implemented, and probably will never because it is too expensive without   direct access to the PETSc data structures. (This leads to the situation   where the action indicated by the default value of the last argument is   actually not implemented; that argument has  [2.x.93]  as its   default value to stay consistent with the other functions of same name in   this namespace.)     This function is used in  [2.x.94]  and  [2.x.95] .    
*  [2.x.96]  If the matrix is stored in parallel across multiple processors   using MPI, this function only touches rows that are locally stored and   simply ignores all other rows. In other words, each processor is   responsible for its own rows, and the  [2.x.97]  argument needs   to contain all locally owned rows of the matrix that you want to have   treated. (But it can also contain entries for degrees of freedom not   owned locally; these will simply be ignored.) Further, in the context of   parallel computations, you will get into trouble if you treat a row while   other processors still have pending writes or additions into the same   row. In other words, if another processor still wants to add something to   an element of a row and you call this function to zero out the row, then   the next time you call compress() may add the remote value to the zero   you just created. Consequently, you will want to call compress() after   you made the last modifications to a matrix and before starting to clear   rows.  
* [0.x.27]*
   Same as above but for the parallel BlockSparseMatrix.  
* [0.x.28]*
   Apply Dirichlet boundary conditions to the system matrix and vectors as   described in the general documentation of this namespace. This function   works on the classes that are used to wrap Trilinos objects.     [1.x.11] This function is not very efficient: it needs to   alternatingly read and write into the matrix, a situation that Trilinos   does not handle well. In addition, we only get rid of rows corresponding   to boundary nodes, but the corresponding case of deleting the respective   columns (i.e. if  [2.x.98]  is  [2.x.99]  is not presently   implemented, and probably will never because it is too expensive without   direct access to the Trilinos data structures. (This leads to the   situation where the action indicated by the default value of the last   argument is actually not implemented; that argument has  [2.x.100]    as its default value to stay consistent with the other functions of same   name in this namespace.)    
*  [2.x.101]  If the matrix is stored in parallel across multiple processors   using MPI, this function only touches rows that are locally stored and   simply ignores all other rows. In other words, each processor is   responsible for its own rows, and the  [2.x.102]  argument needs   to contain all locally owned rows of the matrix that you want to have   treated. (But it can also contain entries for degrees of freedom not   owned locally; these will simply be ignored.) Further, in the context of   parallel computations, you will get into trouble if you treat a row while   other processors still have pending writes or additions into the same   row. In other words, if another processor still wants to add something to   an element of a row and you call this function to zero out the row, then   the next time you call compress() may add the remote value to the zero   you just created. Consequently, you will want to call compress() after   you made the last modifications to a matrix and before starting to clear   rows.  
* [0.x.29]*
   This function does the same as the one above, except now working on block   structures.  
* [0.x.30]*
   Rather than applying boundary values to the global matrix and vector   after creating the global matrix, this function does so during assembly,   by modifying the local matrix and vector contributions. If you call this   function on all local contributions, the resulting matrix will have the   same entries, and the final call to apply_boundary_values() on the global   system will not be necessary.     Since this function does not have to work on the complicated data   structures of sparse matrices, it is relatively cheap. It may therefore   be a win if you have many fixed degrees of freedom (e.g. boundary nodes),   or if access to the sparse matrix is expensive (e.g. for block sparse   matrices, or for PETSc or Trilinos matrices). However, it doesn't work as   expected if there are also hanging nodes to be considered. More caveats   are listed in the general documentation of this namespace.      [2.x.103]   
* [0.x.31]*
   Exception  
* [0.x.32]

include/deal.II-translator/numerics/point_value_history_0.txt
[0.x.0]*
     A class that stores the data needed to reference the support points     closest to one requested point.    
* [0.x.1]*
 PointValueHistory tackles the overhead of plotting time (or any other iterative process) graphs of solution values at specific points on the mesh. The user specifies the points which the solution should be monitored at ahead of time, as well as giving each solution vector that they want to record a mnemonic name. Then, for each step the user calls one of the three available "evaluate field" methods to store the data from each time step, and the class extracts data for the requested points to store it. Finally, once the computation is finished, the user can request output files to be generated; these files are in Gnuplot format but are basically just regular text and can easily be imported into other programs well, for example into spreadsheets.
*  The user can store extra variables which do not relate to mesh location specifying n_independent_variables. The class then expects a  [2.x.0]  of size n_independent_variables to be added during each step using the method  [2.x.1]  This may be used for example for recording external input, logging solver performance data such as time taken to solve the step and solver steps before convergence, saving norms calculated, or simply saving the time, number of time step, or number of nonlinear iteration along with the data evaluated from the mesh.
*  The three "evaluate field" methods each have different strengths and weaknesses making each suitable for different contexts:  [2.x.2]   [2.x.3] Firstly, the  [2.x.4]  version that does not take a  [2.x.5]  DataPostprocessor object selects the nearest support point (see  [2.x.6]  "this entry in the glossary" ) to a given point to extract data from. This makes the code that needs to be run at each time step very short, since looping over the mesh to extract the needed dof_index can be done just once at the start. However, this method is not suitable for FiniteElement objects that do not assign dofs to actual mesh locations (i.e. FEs without  [2.x.7]  "support points" ) or if adaptive mesh refinement is used. The reason for the latter restriction is that the location of the closest support point to a given point may change upon mesh refinement. The class will throw an exception if any change to the triangulation is made (Although the nearest support point could be re- computed upon mesh refinement, the location of the support point will most likely change slightly, making the interpretation of the data difficult, hence this is not implemented currently.)
*   [2.x.8]  Secondly,  [2.x.9]  calls  [2.x.10]   [2.x.11]  to compute values at the specific point requested. This method is valid for any FE that is supported by  [2.x.12]   [2.x.13]  Specifically, this method can be called by codes using adaptive mesh refinement.
*   [2.x.14] Finally, the class offers a function  [2.x.15]  that takes a  [2.x.16]  DataPostprocessor object. This method allows the deal.II data postprocessor to be used to compute new quantities from the solution on the fly. The values are located at the nearest quadrature point to the requested point. If the mesh is refined between calls, this point will change, so care must be taken when using this method in code using adaptive refinement, but as the output will be meaningful (in the sense that the quadrature point selected is guaranteed to remain in the same vicinity, the class does not prevent the use of this method in adaptive codes. The class provides warnings in the output files if the mesh has changed. Note that one can reduce the error this procedure introduces by providing a quadrature formula that has more points, at the expense of performing more work since then the closest quadrature points is nearer to the point at which the evaluation is really supposed to happen. (As a sidenote: Why not do the evaluation at the requested point right away? The reason for this is that it would require setting up a new quadrature point object on each cell that has only a single point corresponding to the reference coordinates of the point you really want; then initializing a FEValues object with it; then evaluating the solution at this point; then handing the result to the DataPostprocessor object. This sequence of things is expensive
* 
*  -  which is the reason why  [2.x.17]  is expensive. Using the same quadrature formula on each cell on which we want to evaluate the solution and only having to initialize a FEValue object once is a much cheaper alternative, albeit of course at the expense of getting only an approximate result.)  [2.x.18] 
*  When recording a new mnemonic name, the user must supply a component_mask (see  [2.x.19]  "this glossary entry" ) to indicate the  [2.x.20]  "(vector) components" to be extracted from the given input. If the user simply wants to extract all the components, the mask need not be explicitly supplied to the  [2.x.21]  add_field_name method and the default value of the parameter is sufficient. If the  [2.x.22]  with a  [2.x.23]  object is used, the component_mask is interpreted as the mask of the  [2.x.24]  return vector. The size of this mask can be different to that of the FE space, but must be provided when the  [2.x.25]  method is called. One variant of the  [2.x.26]  method allows an unsigned int input to construct a suitable mask, if all values from the  [2.x.27]  are desired.
*  The class automatically generates names for the data stored based on the mnemonics supplied. The methods  [2.x.28]  and  [2.x.29]  add_independent_names allow the user to provide lists of names to use instead if desired.
*  Following is a little code snippet that shows a common usage of this class:
* 

* 
* [1.x.0]
* 

* 
* [0.x.2]*
   Provide a stripped down instance of the class which does not support   adding points or mesh data.  This may be used for example for recording   external input or logging solver performance data.  
* [0.x.3]*
   Constructor linking the class to a specific  [2.x.30]  This class   reads specific data from the  [2.x.31]  and stores it internally for   quick access (in particular dof indices of closest neighbors to requested   points) the class is fairly intolerant to changes to the  [2.x.32]  if   data at support points is required. Mesh refinement and  [2.x.33]    methods should be performed before the  [2.x.34]  method is called and   adaptive grid refinement is only supported by some methods.     The user can store extra variables which do not relate to mesh location   by specifying the number required using n_independent_variables and   making calls to  [2.x.35]  as needed.  This may be used for   example for recording external input or logging solver performance data.  
* [0.x.4]*
   Copy constructor. This constructor can be safely called with a  [2.x.36]    PointValueHistory object that contains data, but this could be expensive   and should be avoided.  
* [0.x.5]*
   Assignment operator. This assignment operator can be safely called once   the class is closed and data added, but this is provided primarily to   allow a  [2.x.37]  object declared in a class to be   reinitialized later in the class. Using the assignment operator when the   object contains data could be expensive.  
* [0.x.6]*
   Deconstructor.  
* [0.x.7]*
   Add a single point to the class. The support points (one per component)   in the mesh that are closest to that point are found and their details   stored for use when  [2.x.38]  is called. If more than one point   is required rather use the  [2.x.39]  method since this minimizes   iterations over the mesh.  
* [0.x.8]*
   Add multiple points to the class. The support points (one per component)   in the mesh that are closest to that point is found and their details   stored for use when  [2.x.40]  is called. If more than one point   is required, rather call this method as it is more efficient than the   add_point method since it minimizes iterations over the mesh. The points   are added to the internal database in the order they appear in the list   and there is always a one to one correspondence between the requested   point and the added point, even if a point is requested multiple times.  
* [0.x.9]*
   Put another mnemonic string (and hence  [2.x.41]  into the class.   This method adds storage space for variables equal to the number of true   values in component_mask. This also adds extra entries for points that   are already in the class, so  [2.x.42]  and  [2.x.43]  can be   called in any order.  
* [0.x.10]*
   Put another mnemonic string (and hence  [2.x.44]  into the class.   This method adds storage space for n_components variables. This also adds   extra entries for points that are already in the class, so  [2.x.45]    add_field_name and  [2.x.46]  can be called in any order. This method   generates a  [2.x.47]  0, ..., n_components-1 and calls the previous   function.  
* [0.x.11]*
   Provide optional names for each component of a field. These names will be   used instead of names generated from the field name, if supplied.  
* [0.x.12]*
   Provide optional names for the independent values. These names will be   used instead of "Indep_...", if supplied.  
* [0.x.13]*
   Extract values at the stored points from the VectorType supplied and add   them to the new dataset in vector_name. The component mask supplied when   the field was added is used to select components to extract. If a  [2.x.48]    DoFHandler is used, one (and only one) evaluate_field method must be   called for each dataset (time step, iteration, etc) for each vector_name,   otherwise a  [2.x.49]  error can occur.  
* [0.x.14]*
   Compute values using a  [2.x.50]  object with the  [2.x.51]    supplied and add them to the new dataset in vector_name. The   component_mask supplied when the field was added is used to select   components to extract from the  [2.x.52]  return vector. This   method takes a vector of field names to process and is preferred if many   fields use the same  [2.x.53]  object as each cell is only   located once. The quadrature object supplied is used for all components   of a vector field. Although this method will not throw an exception if   the mesh has changed. (No internal data structures are invalidated as the   quadrature points are repicked each time the function is called.)   Nevertheless the user must be aware that if the mesh changes the point   selected will also vary slightly, making interpretation of the data more   difficult. If a  [2.x.54]  is used, one (and only one) evaluate_field   method must be called for each dataset (time step, iteration, etc) for   each vector_name, otherwise a  [2.x.55]  error can occur.  
* [0.x.15]*
   Construct a  [2.x.56]   [2.x.57]  containing only vector_name and   call the above function. The above function is more efficient if multiple   fields use the same  [2.x.58]  object.  
* [0.x.16]*
   Extract values at the points actually requested from the VectorType   supplied and add them to the new dataset in vector_name. Unlike the other   evaluate_field methods this method does not care if the dof_handler has   been modified because it uses calls to  [2.x.59]  to   extract there data. Therefore, if only this method is used, the class is   fully compatible with adaptive refinement. The component_mask supplied   when the field was added is used to select components to extract. If a  [2.x.60]    DoFHandler is used, one (and only one) evaluate_field method must be   called for each dataset (time step, iteration, etc) for each vector_name,   otherwise a  [2.x.61]  error can occur.  
* [0.x.17]*
   Add the key for the current dataset to the dataset. Although calling this   method first is sensible, the order in which this method,  [2.x.62]    evaluate_field and  [2.x.63]  is not important. It is   however important that all the data for a give dataset is added to each   dataset and that it is added before a new data set is started. This   prevents a  [2.x.64]   
* [0.x.18]*
   If independent values have been set up, this method stores these values.   This should only be called once per dataset, and if independent values   are used it must be called for every dataset. A  [2.x.65]    exception can be thrown if this method is not called.  
* [0.x.19]*
   Write out a series of .gpl files named base_name + "-00.gpl", base_name +   "-01.gpl" etc. The data file gives information about where the support   points   selected and interpreting the data. If  [2.x.66]  != 0 an additional file   base_name + "_indep.gpl" containing key and independent data. The file   name agrees with the order the points were added to the class. The names   of the data columns can be supplied using the functions  [2.x.67]    add_component_names and  [2.x.68]  The support point   information is only meaningful if the dof_handler has not been changed.   Therefore, if adaptive mesh refinement has been used the support point   data should not be used. The optional parameter postprocessor_locations   is used to add the postprocessor locations to the output files. If this   is desired, the data should be obtained from a call to   get_postprocessor_locations while the dof_handler is usable. The default   parameter is an empty vector of strings, and will suppress postprocessor   locations output.  
* [0.x.20]*
   Return a  [2.x.69]  with the indices of selected points flagged with a 1.   This method is mainly for testing and verifying that the class is working   correctly. By passing this vector to a DataOut object, the user can   verify that the positions returned by  [2.x.70]  agree with   the positions that  [2.x.71]  interprets from the  [2.x.72]  returned. The   code snippet below demonstrates how this could be done:  
* [1.x.1]
*   
* [0.x.21]*
   Stores the actual location of each support point selected by the  [2.x.73]    add_point(s) method.  This can be used to compare with the point   requested, for example by using the  [2.x.74]  function. For   convenience, location is resized to the correct number of points by the   method.  
* [0.x.22]*
   Stores the actual location of the points used by the data_postprocessor.   This can be used to compare with the points requested, for example by   using the  [2.x.75]  function. Unlike the support_locations,   these locations are computed every time the evaluate_field method is   called with a postprocessor. This method uses the same algorithm so can   will find the same points. For convenience, location is resized to the   correct number of points by the method.  
* [0.x.23]*
   Once datasets have been added to the class, requests to add additional   points will make the data interpretation unclear. The boolean  [2.x.76]    defines a state of the class and ensures this does not happen. Additional   points or vectors can only be added while the class is not closed, and   the class must be closed before datasets can be added or written to file.    [2.x.77]  and  [2.x.78]    do not require the class to be closed. If a method that requires a class to   be open or close is called while in the wrong state a  [2.x.79]    exception is thrown.  
* [0.x.24]*
   Delete the lock this object has to the  [2.x.80]  used the last time   the class was created.  This method should not normally need to be   called, but can be useful to ensure that the  [2.x.81]  is released   before it goes out of scope if the  [2.x.82]  class might live   longer than it. Once this method has been called, the majority of methods   will throw a  [2.x.83]  exception, so if used this method should   be the last call to the class.  
* [0.x.25]*
   Print useful debugging information about the class, include details about   which support points were selected for each point and sizes of the data   stored.  
* [0.x.26]*
   Check the internal data sizes to test for a loss of data sync. This is   often used in  [2.x.84]  statements with the  [2.x.85]  exception.   If  [2.x.86]  is  [2.x.87]  this method returns  [2.x.88]  if all sizes are   within 1 of each other (needed to allow data to be added), with  [2.x.89]    =  [2.x.90]  they must be exactly equal.  
* [0.x.27]*
   Exception  
* [0.x.28]*
   Exception  
* [0.x.29]*
   Exception  
* [0.x.30]*
   Exception  
* [0.x.31]*
   Stores keys, values on the abscissa. This will often be time, but   possibly time step, iteration etc.  
* [0.x.32]*
   Values that do not depend on grid location.  
* [0.x.33]*
   Save a vector listing component names associated with a   independent_values. This will be an empty vector if the user does not   supplies names.  
* [0.x.34]*
   Save data for each mnemonic entry. data_store: mnemonic
* 
->   [point_0_components point_1_components ... point_n-1_components][key]   This format facilitates scalar mnemonics in a vector space, because   scalar mnemonics will only have one component per point. Vector   components are strictly FE.n_components () long.  
* [0.x.35]*
   Save a component mask for each mnemonic.  
* [0.x.36]*
   Save a vector listing component names associated with a mnemonic. This   will be an empty vector if the user does not supplies names.  
* [0.x.37]*
   Save the location and other mesh information about support points.  
* [0.x.38]*
   Used to enforce  [2.x.91]  state for some methods.  
* [0.x.39]*
   Used to enforce  [2.x.92]  state for some methods.  
* [0.x.40]*
   A smart pointer to the dof_handler supplied to the constructor. This can   be released by calling  [2.x.93]   
* [0.x.41]*
   Variable to check if the triangulation has changed. If it has changed,   certain data is out of date (especially the    [2.x.94]   
* [0.x.42]*
   A boolean to record whether the class was initialized with a DoFHandler   or not.  
* [0.x.43]*
   Used to detect signals from the Triangulation.  
* [0.x.44]*
   Stores the number of independent variables requested.  
* [0.x.45]*
   A function that will be triggered through signals whenever the   triangulation is modified.     It is currently used to check if the triangulation has changed,   invalidating precomputed values.  
* [0.x.46]

include/deal.II-translator/numerics/rtree_0.txt
[0.x.0]*
 A wrapper for the  [2.x.0]  class, implementing a self-balancing spatial index (the R-tree) capable of storing various types of values, using different balancing algorithms.
*  From [Wikipedia](https://en.wikipedia.org/wiki/R-tree): <blockquote> R-trees are tree data structures used for spatial access methods, i.e., for indexing multi-dimensional information such as geographical coordinates, rectangles or polygons. The R-tree was proposed by Antonin Guttman in 1984 and has found significant use in both theoretical and applied contexts. A common real-world usage for an R-tree might be to store spatial objects such as restaurant locations or the polygons that typical maps are made of: streets, buildings, outlines of lakes, coastlines, etc. and then find answers quickly to queries such as "Find all museums within 2 km of my current location", "retrieve all road segments within 2 km of my location" (to display them in a navigation system) or "find the nearest gas station" (although not taking roads into account). The R-tree can also accelerate nearest neighbor search for various distance metrics, including great-circle distance.
*  The key idea of the data structure is to group nearby objects and represent them with their minimum bounding rectangle in the next higher level of the tree; the "R" in R-tree is for rectangle. Since all objects lie within this bounding rectangle, a query that does not intersect the bounding rectangle also cannot intersect any of the contained objects. At the leaf level, each rectangle describes a single object; at higher levels the aggregation of an increasing number of objects. This can also be seen as an increasingly coarse approximation of the data set.
*  The key difficulty of R-tree is to build an efficient tree that on one hand is balanced (so the leaf nodes are at the same height) on the other hand the rectangles do not cover too much empty space and do not overlap too much (so that during search, fewer subtrees need to be processed). For example, the original idea for inserting elements to obtain an efficient tree is to always insert into the subtree that requires least enlargement of its bounding box. Once that page is full, the data is split into two sets that should cover the minimal area each. Most of the research and improvements for R-trees aims at improving the way the tree is built and can be grouped into two objectives: building an efficient tree from scratch (known as bulk-loading) and performing changes on an existing tree (insertion and deletion). </blockquote>
*  An RTree may store any type of  [2.x.1]  as long as it is possible to extract an  [2.x.2]  that the RTree can handle and compare values. An  [2.x.3]  is a type adapted to the Point, BoundingBox or Segment concept, for which distance and equality comparison are implemented. The deal.II Point, Segment, and BoundingBox classes satisfy this requirement, but you can mix in any geometry object that  [2.x.4]  accepts as indexable.
*  In particular, given an  [2.x.5]  type (for example a Point,  a BoundingBox, or a Segment),  [2.x.6]  can by any of  [2.x.7]   [2.x.8]  T>`,  [2.x.9]  ...>` or  [2.x.10]  ...>`.
*  The optional argument  [2.x.11]  is used only when adding elements to the tree one by one. If a range insertion is used, then the tree is built using the packing algorithm.
*  Linear, quadratic, and rstar algorithms are available if one wants to construct the tree sequentially. However, none of these is very efficient, and users should use the packing algorithm when possible.
*  The packing algorithm constructs the tree all at once, and may be used when you have all the leaves at your disposal.
*  This class is usually used in combination with one of the two helper functions pack_rtree(), that takes a container or a range of iterators to construct the RTree using the packing algorithm.
*  An example usage is the following:
* 

* 
* [1.x.0]
* 
*  The tree is accessed by using  [2.x.12]  queries](https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/geometry/spatial_indexes/queries.html). For example, after constructing the tree with the snippet above, one can ask for the closest points to a segment in the following way:
* 

* 
* [1.x.1]
* 
*  In general, a tree does not need to store the actual objects, as long as it knows how to access a const reference to an indexable type. This is achieved by passing the optional template argument  [2.x.13]  that extracts a const reference to one of the possible indexable types given an object of type  [2.x.14]  As an example, one may store points in a container, and only create a tree of the indices within the container, using the IndexableGetterFromIndices class defined below, and the function pack_rtree_of_indices().

* 
* [0.x.1]*
 Construct the correct RTree object by passing an iterator range.
*  Notice that the order of the parameters is the opposite with respect to the RTree class, since we can automatically infer the  [2.x.15]  from the arguments.

* 
* [0.x.2]*
 Construct an RTree object by passing an STL container type. This function is used in  [2.x.16] .
*  Notice that the order of the template parameters is the opposite with respect to the RTree class, since we can automatically infer the  [2.x.17]  from the arguments, and we only need to specify the  [2.x.18]  if the default is not adequate.

* 
* [0.x.3]*
 A class that may be used as an  [2.x.19]  template argument for an RTree that stores indices to entries in a  [2.x.20]  type.
*  This class may be used as a proxy to extract an indexable type from compatible containers. For example:

* 
* [1.x.2]
* 
*  This class is used by the pack_rtree_of_indices() function to construct an RTree where the leaves are indices pointing to the entries of the container passed to this class.

* 
* [0.x.4]*
   An alias for the boost type that is used to extract a Point, Segment, or   BoundingBox from compatible types (pairs, tuples, etc.).  
* [0.x.5]*
   An alias to the actual geometrical type.  
* [0.x.6]*
   An alias to the index type.  
* [0.x.7]*
   Constructor. Store a const reference to a container.  
* [0.x.8]*
   Implements the  [2.x.21]  requirements of the rtree class.  
* [0.x.9]*
   A const reference to the container.  
* [0.x.10]*
   An instantiation of the getter that allows easy translation from the   container  [2.x.22]  and the actual indexable type.  
* [0.x.11]*
 Construct a RTree object that stores the indices of an existing container of indexable types. The only requirement on the container is that it supports operator[] for any index between 0 and the size of the container (i.e., a  [2.x.23]  or an  [2.x.24]  will do, however an  [2.x.25]  won't).
*  Differently from the object created by the pack_rtree() function, in this case we don't store the actual geometrical types, but just their indices:
* 

* 
* [1.x.3]
* 
*  The leaves stored in the tree are the indices of the corresponding entry in the container. A reference to the external container is stored internally, but keep in mind that if you change the container, you should rebuild the tree.

* 
* [0.x.12]*
 Helper structure that allows one to extract a level from an RTree as a vector of BoundingBox objects.
*  This structure implements a  [2.x.26]  object, allowing one to visit any existing RTree object, and return the vector of bounding boxes associated to a specific target level of the tree.
*  Although possible, direct usage of this structure is cumbersome. The suggested usage of this class is through the helper function extract_rtree_level().

* 
* [0.x.13]*
   Construct a vector  [2.x.27]  of BoundingBox objects corresponding to the    [2.x.28]  of the tree.  
* [0.x.14]*
   An alias that identifies an InternalNode of the tree.  
* [0.x.15]*
   An alias that identifies a Leaf of the tree.  
* [0.x.16]*
   Implements the visitor interface for InternalNode objects. If the node   belongs to the  [2.x.29]  then fill the bounding box vector.  
* [0.x.17]*
   Implements the visitor interface for Leaf objects.  
* [0.x.18]*
   Translator interface, required by the boost implementation of the rtree.  
* [0.x.19]*
   Store the level we are currently visiting.  
* [0.x.20]*
   The level we want to extract from the RTree object.  
* [0.x.21]*
   A reference to the input vector of BoundingBox objects.  
* [0.x.22]*
 Given a RTree object  [2.x.30]  and a target level  [2.x.31]  return a vector of BoundingBox objects containing all the bounding boxes that make the given  [2.x.32]  of the  [2.x.33]  This function is a convenient wrapper around the ExtractLevelVisitor class. It is used in  [2.x.34] .
*  Since an RTree object is a balanced tree, you can expect each entry of the resulting vector to contain roughly the same number of children, and ultimately, the same number of leaf objects. If you request for a level that is not present in the RTree, the last level is returned.
*  A typical usage of this function is in the context of  [2.x.35]  objects, where one would like to construct a rough representation of the area which is covered by the locally owned cells of the active process, and exchange this information with other processes. The finest level of information is given by the leaves, which in this context would be the collection of all the bounding boxes associated to the locally owned cells of the triangulation. Exchanging this information with all participating processes would defeat the purpuse of parallel computations. If however one constructs an RTree containing these bounding boxes (for example, by calling  [2.x.36]  and then extracts one of the first levels of the RTree, only a handful of BoundingBox objects would be returned, allowing the user to have a very efficient description of the geometry of the domain, and of its distribution among processes.
*  An example usage is given by the following snippet of code:

* 
* [1.x.4]
* 
*  When run on three processes, the complete set of the BoundingBox objects surrounding only the locally owned cells and the second level of the rtree constructed with those boxes would look like in the following pictures (one image per process):
*   [2.x.37]   [2.x.38]   [2.x.39] 

* 
* [0.x.23]

include/deal.II-translator/numerics/smoothness_estimator_0.txt
[0.x.0]*
 A namespace for various smoothness estimation strategies for hp-adaptive FEM.
*  Smoothness estimation is one strategy to decide whether a cell with a large error estimate should undergo h- or p-refinement. Typical strategies decide to increase the polynomial degree on a cell if the solution is particularly smooth, whereas one would refine the mesh if the solution on the cell is singular, has kinks in some derivative, or is otherwise not particularly smooth. All of these strategies rely on a way to identify how "smooth" a function is on a given cell.

* 
* [0.x.1]*
   Smoothness estimation strategy based on the decay of Legendre expansion   coefficients.     In one dimension, the finite element solution on cell  [2.x.0]  with polynomial   degree  [2.x.1]  can be written as   [1.x.0]
*    where  [2.x.2]  are degrees of freedom and  [2.x.3]  are the corresponding   shape functions.  [2.x.4]  are Legendre polynomials on cell    [2.x.5] .  [2.x.6]  and  [2.x.7]  are coefficients and transformation   matrices from the Legendre expansion of each shape function. For practical   reasons, we will perform the calculation of these matrices and coefficients   only on the reference cell  [2.x.8] . We only have to calculate the   transformation matrices once this way. However, results are only applicable   if the mapping from the reference cell to the actual cell is affine. We use   the class  [2.x.9]  to determine all coefficients  [2.x.10] .     A function is analytic, i.e., representable by a power series, if and only   if their Legendre expansion coefficients decay as (see  [2.x.11] )   [1.x.1]   We determine their decay rate  [2.x.12]  by performing the linear regression   fit of   [1.x.2]   for  [2.x.13] , with  [2.x.14]  the polynomial degree of the finite element.   The rate of the decay  [2.x.15]  can be used to estimate the smoothness. For   example, one strategy to implement hp-refinement criteria is to perform   p-refinement if  [2.x.16]  (see  [2.x.17] ).  
* [0.x.2]*
     In this variant of the estimation strategy for higher dimensions, we will     consider all mode vectors  [2.x.18]  describing Legendre polynomials      [2.x.19]  and perform one least-squares fit over all     coefficients at once. If there are multiple coefficients corresponding to     the same absolute value of modes  [2.x.20] , we take the maximum     among those. Thus, the least-squares fit is performed on     [1.x.3]
*      for  [2.x.21]  and  [2.x.22] , with  [2.x.23]  the     polynomial degree of the finite element.         For a finite element approximation  [2.x.24]  this function writes the     decay rate for every cell into the output vector  [2.x.25]           [2.x.26]  [in] fe_legendre  [2.x.27]  object to calculate coefficients.     This object needs to be initialized to have at least  [2.x.28]  coefficients     in each direction for every finite element in the collection, where  [2.x.29]      is its polynomial degree.      [2.x.30]  [in] dof_handler A DoFHandler.      [2.x.31]  [in] solution A solution vector.      [2.x.32]  [out] smoothness_indicators A vector for smoothness indicators.      [2.x.33]  [in] regression_strategy Determines which norm will be used on the     subset of coefficients  [2.x.34]  with the same absolute value      [2.x.35] . Default is  [2.x.36]  for a maximum     approximation.      [2.x.37]  [in] smallest_abs_coefficient The smallest absolute value of the     coefficient to be used in linear regression. Note that Legendre     coefficients of some functions may have a repeating pattern of zero     coefficients (i.e. for functions that are locally symmetric or     antisymmetric about the midpoint of the element in any coordinate     direction). Thus this parameters allows to ignore small (in absolute     value) coefficients within the linear regression fit. In case there are     less than two nonzero coefficients, the returned value for this cell will     be  [2.x.38] .      [2.x.39]  [in] only_flagged_cells Smoothness indicators are usually used to     decide whether to perform h- or p-adaptation. So in most cases, we only     need to calculate those indicators on cells flagged for refinement or     coarsening. This parameter controls whether this particular subset or all     cells will be considered. By default, all cells will be considered. When     only flagged cells are supposed to be considered, smoothness indicators     will only be set on those vector entries of flagged cells; the others     will be set to a signaling NaN.         For more theoretical details see  [2.x.40]       [2.x.41]   [2.x.42] .    
* [0.x.3]*
     In this variant of the estimation strategy for higher dimensions, we only     consider modes in each coordinate direction, i.e., only mode vectors      [2.x.43]  with one nonzero entry. We perform the least-squares fit in     each coordinate direction separately and take the lowest decay rate      [2.x.44]  among them.         For a finite element approximation  [2.x.45]  this function writes the     decay rate for every cell into the output vector  [2.x.46]           [2.x.47]  [in] fe_legendre  [2.x.48]  object to calculate coefficients.     This object needs to be initialized to have at least  [2.x.49]  coefficients     in each direction, where  [2.x.50]  is the maximum polynomial degree to be used.      [2.x.51]  [in] dof_handler A DoFHandler      [2.x.52]  [in] solution A solution vector      [2.x.53]  [out] smoothness_indicators A vector for smoothness indicators      [2.x.54]  [in] coefficients_predicate A predicate to select Legendre     coefficients  [2.x.55] ,  [2.x.56]  for linear regression in each     coordinate direction. The user is responsible for updating the vector of     `flags` provided to this function. Note that its size is  [2.x.57] , where  [2.x.58]      is the polynomial degree of the FE basis on a given element. The default     implementation will use all Legendre coefficients in each coordinate     direction, i.e. set all elements of the vector to `true`.      [2.x.59]  [in] smallest_abs_coefficient The smallest absolute value of the     coefficient to be used in linear regression in each coordinate direction.     Note that Legendre coefficients of some functions may have a repeating     pattern of zero coefficients (i.e. for functions that are locally     symmetric or antisymmetric about the midpoint of the element in any     coordinate direction). Thus this parameters allows to ignore small (in     absolute value) coefficients within the linear regression fit. In case     there are less than two nonzero coefficients for a coordinate direction,     this direction will be skipped. If all coefficients are zero, the     returned value for this cell will be  [2.x.60] .      [2.x.61]  [in] only_flagged_cells Smoothness indicators are usually used to     decide whether to perform h- or p-adaptation. So in most cases, we only     need to calculate those indicators on cells flagged for refinement or     coarsening. This parameter controls whether this particular subset or all     cells will be considered. By default, all cells will be considered. When     only flagged cells are supposed to be considered, smoothness indicators     will only be set on those vector entries of flagged cells; the others     will be set to NaN.         For more theoretical details and the application within the deal.II     library see  [2.x.62] .    
* [0.x.4]*
     Returns a  [2.x.63]  object for Legendre series expansions with     the default configuration for smoothness estimation purposes.         For each finite element of the provided  [2.x.64]  we use as many     modes as its polynomial degree plus two. This includes the first Legendre     polynomial which is just a constant. Further for each element, we use a     Gaussian quadrature designed to yield exact results for the highest order     Legendre polynomial used.         As the Legendre expansion can only be performed on scalar fields, this     class does not operate on vector-valued finite elements and will     therefore throw an assertion. However, each component of a finite element     field can be treated as a scalar field, respectively, on which Legendre     expansions are again possible. For this purpose, the optional parameter      [2.x.65]  defines which component of each FiniteElement will be used.     The default value of  [2.x.66]  only applies to scalar FEs, in which     case it indicates that the sole component is to be decomposed. For     vector-valued FEs, a non-default value must be explicitly provided.    
* [0.x.5]*
   Smoothness estimation strategy based on the decay of Fourier expansion   coefficients.     From the definition, we can write our Fourier series expansion    [2.x.67]  of the finite element solution on cell  [2.x.68]  with polynomial   degree  [2.x.69]  as a matrix product   [1.x.4]
*    with  [2.x.70]  the degrees of freedom and  [2.x.71]  the corresponding shape   functions.  [2.x.72]  are exponential functions on cell  [2.x.73] .  [2.x.74]  and  [2.x.75]  are coefficients and transformation matrices from the   Fourier expansion of each shape function. For practical reasons, we will   perform the calculation of these matrices and coefficients only on the   reference cell  [2.x.76] . We only have to calculate the transformation   matrices once this way. However, results are only applicable if mapping   from the reference cell to the actual cell is linear. We use the class    [2.x.77]  to determine all coefficients  [2.x.78] .     If the finite element approximation on cell  [2.x.79]  is part of the Hilbert   space  [2.x.80] , then the following integral must exist for both the finite   element and spectral representation of our solution   [1.x.5]
*    The sum is finite only if the summands decay at least with order   [1.x.6]   for all  [2.x.81] . The additional factor stems from the fact that,   since we sum over all multi-indices  [2.x.82]  that are located on a   dim-dimensional sphere, we actually have, up to a constant,    [2.x.83]  modes located in each increment  [2.x.84]  that need to be taken into account. By a comparison of   exponents, we can rewrite this condition as   [1.x.7]     The next step is to estimate how fast these coefficients   decay with  [2.x.85] . Thus, we perform a least-squares fit   [1.x.8]   with regression coefficients  [2.x.86]  and  [2.x.87] . For simplification, we   apply a logarithm on our minimization problem   [1.x.9]   where  [2.x.88] . This is now a problem for which the optimality   conditions  [2.x.89] , are linear in  [2.x.90] . We can   write these conditions as follows:   [1.x.10]   Solving for  [2.x.91]  and  [2.x.92]  is just a linear regression fit and to do   that we will use  [2.x.93]      While we are not particularly interested in the actual value of    [2.x.94] , the formula above gives us a means to calculate the value of   the exponent  [2.x.95]  that we can then use to determine that    [2.x.96]  is in  [2.x.97]  with  [2.x.98] . The   decay rates  [2.x.99]  will suffice as our smoothness indicators and   will be calculated on each cell for any provided solution.    
*  [2.x.100]  An extensive demonstration of the use of these functions is   provided in  [2.x.101] .  
* [0.x.6]*
     In this variant of the estimation strategy for higher dimensions, we will     consider all mode vectors  [2.x.102]  describing Fourier polynomials      [2.x.103]  and perform one least-squares fit over all coefficients     at once. If there are multiple coefficients corresponding to the same     absolute value of modes  [2.x.104] , we take the maximum among those.     Thus, the least-squares fit is performed on     [1.x.11]     for  [2.x.105]  and  [2.x.106] , with  [2.x.107]  the     polynomial degree of the finite element. We exclude the  [2.x.108]      modes to avoid the singularity of the logarithm.         The  [2.x.109]  parameter determines which norm will be used     on the subset of coefficients  [2.x.110]  with the same absolute value      [2.x.111] . Default is  [2.x.112]  for a maximum     approximation.         For a provided solution vector  [2.x.113]  defined on a DoFHandler      [2.x.114]  this function returns a vector  [2.x.115]      with as many elements as there are cells where each element contains the     estimated regularity  [2.x.116] .         A series expansion object  [2.x.117]  has to be supplied, which needs     to be constructed with the same FECollection object as the  [2.x.118]          The parameter  [2.x.119]  allows to ignore small (in     absolute value) coefficients within the linear regression fit. In case     there are less than two nonzero coefficients for a coordinate direction,     this direction will be skipped. If all coefficients are zero, the     returned value for this cell will be  [2.x.120] .         Smoothness indicators are usually used to decide whether to perform h- or     p-adaptation. So in most cases, we only need to calculate those     indicators on cells flagged for refinement or coarsening. The parameter      [2.x.121]  controls whether this particular subset or all     cells will be considered. By default, all cells will be considered.     When only flagged cells are supposed to be considered, smoothness     indicators will only be set on those vector entries of flagged cells;     the others will be set to a signaling NaN.    
* [0.x.7]*
     In this variant of the estimation strategy for higher dimensions, we only     consider modes in each coordinate direction, i.e., only mode vectors      [2.x.122]  with one nonzero entry. We perform the least-squares fit in     each coordinate direction separately and take the lowest decay rate      [2.x.123]  among them.         The  [2.x.124]  parameter selects Fourier coefficients      [2.x.125] ,  [2.x.126]  for linear regression in each coordinate     direction. The user is responsible for updating the vector of `flags`     provided to this function. Note that its size is  [2.x.127] , where  [2.x.128]  is the     polynomial degree of the FE basis on a given element. The default     implementation will use all Fourier coefficients in each coordinate     direction, i.e., set all the elements of the vector to `true`.         For a provided solution vector  [2.x.129]  defined on a DoFHandler      [2.x.130]  this function returns a vector  [2.x.131]      with as many elements as there are cells where each element contains the     estimated regularity  [2.x.132] .         A series expansion object  [2.x.133]  has to be supplied, which needs     to be constructed with the same FECollection object as the  [2.x.134]          The parameter  [2.x.135]  allows to ignore small (in     absolute value) coefficients within the linear regression fit. In case     there are fewer than two nonzero coefficients for a coordinate direction,     this direction will be skipped. If all coefficients are zero, the     returned value for this cell will be  [2.x.136] .         Smoothness indicators are usually used to decide whether to perform h- or     p-adaptation. So in most cases, we only need to calculate those     indicators on cells flagged for refinement or coarsening. The parameter      [2.x.137]  controls whether this particular subset or all     cells will be considered. By default, all cells will be considered.     When only flagged cells are supposed to be considered, smoothness     indicators will only be set on those vector entries of flagged cells;     the others will be set to a signaling NaN.    
* [0.x.8]*
     Returns a  [2.x.138]  object for Fourier series expansions with     the default configuration for smoothness estimation purposes.         For each finite element of the provided  [2.x.139]  we use as many     modes as its polynomial degree plus two. Further for each element, we use     a 5-point Gaussian quarature iterated in each dimension by the maximal     wave number, which is the number of modes decreased by one since we start     with  [2.x.140] .         As the Fourier expansion can only be performed on scalar fields, this     class does not operate on vector-valued finite elements and will     therefore throw an assertion. However, each component of a finite element     field can be treated as a scalar field, respectively, on which Fourier     expansions are again possible. For this purpose, the optional parameter      [2.x.141]  defines which component of each FiniteElement will be used.     The default value of  [2.x.142]  only applies to scalar FEs, in which     case it indicates that the sole component is to be decomposed. For     vector-valued FEs, a non-default value must be explicitly provided.    
* [0.x.9]

include/deal.II-translator/numerics/solution_transfer_0.txt
[0.x.0]*
 This class implements the transfer of a discrete FE function (e.g. a solution vector) from one mesh to another that is obtained from the first by a single refinement and/or coarsening step. During interpolation the vector is reinitialized to the new size and filled with the interpolated values. This class is used in the  [2.x.0] ,  [2.x.1] ,  [2.x.2] , and  [2.x.3]  tutorial programs. A version of this class that works on parallel triangulations is available as  [2.x.4] 
*  [1.x.0]
*  This class implements the algorithms in two different ways:  [2.x.5]   [2.x.6]  If the grid will only be refined (i.e. no cells are coarsened) then use  [2.x.7]  as follows:

* 
* [1.x.1]
* 
*  Then to proceed do

* 
* [1.x.2]
* 
*  Although the  [2.x.8]  functions are allowed to be called multiple times, e.g. for interpolating several solution vectors, there is the following possibility of interpolating several functions simultaneously.

* 
* [1.x.3]
*  This is used in several of the tutorial programs, for example  [2.x.9] .
*   [2.x.10]  If the grid has cells that will be coarsened, then use  [2.x.11]  SolutionTransfer as follows:

* 
* [1.x.4]
* 
*  If the grid is partitioned across several MPI processes, then it is important to note that the old solution(s) must be copied to one that also provides access to the locally relevant DoF values (these values required for the interpolation process):

* 
* [1.x.5]
* 
*  Multiple calls to the function <code>interpolate (const VectorType &in, VectorType &out)</code> are NOT allowed. Interpolating several functions can be performed in one step by using <tt>void interpolate (const vector<VectorType> &all_in, vector<VectorType> &all_out) const</tt>, and using the respective  [2.x.12]  prepare_for_coarsening_and_refinement function taking several vectors as input before actually refining and coarsening the triangulation (see there).  [2.x.13] 
*  For deleting all stored data in  [2.x.14]  and reinitializing it use the <tt>clear()</tt> function.
*  The template argument  [2.x.15]  denotes the type of data container you want to transfer.
* 

*  [1.x.6]
*  The interpolation onto the new mesh is a local operation, i.e., it interpolates onto the new mesh only. If that new mesh has hanging nodes, you will therefore get a solution that does not satisfy hanging node constraints. The same is true with boundary values: the interpolated solution will just be the interpolation of the old solution at the boundary, and this may or may not satisfy boundary values at newly introduced boundary nodes.
*  Consequently, you may have to apply hanging node or boundary value constraints after interpolation.  [2.x.16]  and  [2.x.17]  have examples of dealing with this.
* 

*  [1.x.7]
*   [2.x.18]   [2.x.19]  Solution transfer with only refinement. Assume that we have got a solution vector on the current (original) grid. Each entry of this vector belongs to one of the DoFs of the discretization. If we now refine the grid then the calling of  [2.x.20]  will change at least some of the DoF indices. Hence we need to store the DoF indices of all active cells before the refinement. A pointer for each active cell is used to point to the vector of these DoF indices of that cell. This is done by prepare_for_pure_refinement().
*  In the function <tt>refine_interpolate(in,out)</tt> and on each cell where the pointer is set (i.e. the cells that were active in the original grid) we can now access the local values of the solution vector  [2.x.21]  on that cell by using the stored DoF indices. These local values are interpolated and set into the vector  [2.x.22]  that is at the end the discrete function  [2.x.23]  in interpolated on the refined mesh.
*  The <tt>refine_interpolate(in,out)</tt> function can be called multiple times for arbitrary many discrete functions (solution vectors) on the original grid.
*   [2.x.24]  Solution transfer with coarsening and refinement. After calling  [2.x.25]  the coarsen flags of either all or none of the children of a (father-)cell are set. While coarsening  [2.x.26]  the cells that are not needed any more will be deleted from the Triangulation.
*  For the interpolation from the (to be coarsenend) children to their father the children cells are needed. Hence this interpolation and the storing of the interpolated values of each of the discrete functions that we want to interpolate needs to take place before these children cells are coarsened (and deleted!!). Again a pointer for each relevant cell is set to point to these values (see below). Additionally the DoF indices of the cells that will not be coarsened need to be stored according to the solution transfer with pure refinement (cf there). All this is performed by <tt>prepare_for_coarsening_and_refinement(all_in)</tt> where the <tt>vector<VectorType> all_in</tt> includes all discrete functions to be interpolated onto the new grid.
*  As we need two different kinds of pointers (<tt>vector<unsigned int></tt> for the Dof indices and <tt>vector<VectorType></tt> for the interpolated DoF values) we use the  [2.x.27]  that includes both of these pointers and the pointer for each cell points to these  [2.x.28]  Pointerstructs. On each cell only one of the two different pointers is used at one time hence we could use a <tt>void pointer</tt> as <tt>vector<unsigned int></tt> at one time and as <tt>vector<VectorType></tt> at the other but using this  [2.x.29]  Pointerstruct in between makes the use of these pointers more safe and gives better possibility to expand their usage.
*  In <tt>interpolate(all_in, all_out)</tt> the refined cells are treated according to the solution transfer while pure refinement. Additionally, on each cell that is coarsened (hence previously was a father cell), the values of the discrete functions in  [2.x.30]  are set to the stored local interpolated values that are accessible due to the 'vector<VectorType>' pointer in  [2.x.31]  that is pointed to by the pointer of that cell. It is clear that <tt>interpolate(all_in, all_out)</tt> only can be called with the <tt>vector<VectorType> all_in</tt> that previously was the parameter of the <tt>prepare_for_coarsening_and_refinement(all_in)</tt> function. Hence <tt>interpolate(all_in, all_out)</tt> can (in contrast to <tt>refine_interpolate(in, out)</tt>) only be called once.  [2.x.32] 
* 

*  [1.x.8]
*  This class does its best to represent on the new mesh the finite element function that existed on the old mesh, but this may lead to situations where the function on the new mesh is no longer conforming at hanging nodes. To this end, consider a situation of a twice refined mesh that started with a single square cell (i.e., we now have 16 cells). Consider also that we coarsen 4 of the cells back to the first refinement level. In this case, we end up with a mesh that will look as follows if we were to use a  [2.x.33]  element:
*   [2.x.34] 
*  The process of interpolating from the old to the new mesh would imply that the values of the finite element function will not change on all of the cells that remained as they are (i.e., the fine cells) but that on the coarse cell at the top right, the four values at the vertices are obtained by interpolating down from its former children.  If the original function was not linear, this implies that the marked hanging nodes will retain their old values which, in general, will not lead to a continuous function along the corresponding edges. In other words, the solution vector obtained after  [2.x.35]  does not satisfy hanging node constraints: it corresponds to the pointwise interpolation, but not to the interpolation [1.x.9].
*  Whether this is a problem you need to worry about or not depends on your application. The situation is easily corrected, of course, by applying  [2.x.36]  to your solution vector after transfer, using a constraints object computed on the new DoFHandler object (you probably need to create this object anyway if you have hanging nodes). This is also what is done, for example, in  [2.x.37] .
* 

* 
*  [2.x.38]  This situation can only happen if you do coarsening. If all cells remain as they are or are refined, then  [2.x.39]  computes a new vector of nodal values, but the function represented is of course exactly the same because the old finite element space is a subspace of the new one. Thus, if the old function was conforming (i.e., satisfied hanging node constraints), then so does the new one, and it is not necessary to call  [2.x.40] 
* 

*  [1.x.10]
*  In the case of DoFHandlers with hp-capabilities, nothing defines which of the finite elements that are part of the  [2.x.41]  associated with the DoFHandler, should be considered on cells that are not active (i.e., that have children). This is because degrees of freedom are only allocated for active cells and, in fact, it is not allowed to set an active FE index on non- active cells using  [2.x.42] 
*  It is, thus, not entirely natural what should happen if, for example, a few cells are coarsened away. This class then implements the following algorithm:
* 

* 
* 
*  - If a cell is refined, then the values of the solution vector(s) are   interpolated before refinement on the to-be-refined cell from the space of   the active finite element to the one of the future finite element. These   values are then distributed on the finite element spaces of the children   post-refinement. This may lose information if, for example, the old cell   used a Q2 space and the children use Q1 spaces, or the information may be   prolonged if the mother cell used a Q1 space and the children are Q2s.
* 

* 
* 
*  - If cells are to be coarsened, then the values from the child cells are   interpolated to the mother cell using the largest of the child cell future   finite element spaces, which will be identified as the least dominant   element following the FiniteElementDomination logic (consult    [2.x.43]  for more information). For   example, if the children of a cell use Q1, Q2 and Q3 spaces, then the   values from the children are interpolated into a Q3 space on the mother   cell. After refinement, this Q3 function on the mother cell is then   interpolated into the space the user has selected for this cell (which may   be different from Q3, in this example, if the user has set the   active FE index for a different space post-refinement and before calling    [2.x.44] 
* 

* 
*  [2.x.45]  In the context of hp-refinement, if cells are coarsened or the polynomial degree is lowered on some cells, then the old finite element space is not a subspace of the new space and you may run into the same situation as discussed above with hanging nodes. You may want to consider calling  [2.x.46]  on the vector obtained by transferring the solution.
* 

* 
*  [2.x.47] 

* 
* [0.x.1]*
   Constructor, takes the current DoFHandler as argument.  
* [0.x.2]*
   Destructor  
* [0.x.3]*
   Reinit this class to the state that it has directly after calling the   Constructor  
* [0.x.4]*
   Prepares the  [2.x.48]  for pure refinement. It stores the dof   indices of each cell. After calling this function only calling the  [2.x.49]    refine_interpolate functions is allowed.  
* [0.x.5]*
   Prepares the  [2.x.50]  for coarsening and refinement. It stores   the dof indices of each cell and stores the dof values of the vectors in    [2.x.51]  in each cell that'll be coarsened.  [2.x.52]  includes all   vectors that are to be interpolated onto the new (refined and/or   coarsenend) grid.  
* [0.x.6]*
   Same as previous function but for only one discrete function to be   interpolated.  
* [0.x.7]*
   This function interpolates the discrete function  [2.x.53]  which is a vector   on the grid before the refinement, to the function  [2.x.54]  which then is a   vector on the refined grid. It assumes the vectors having the right sizes   (i.e. <tt>in.size()==n_dofs_old</tt>,   <tt>out.size()==n_dofs_refined</tt>)     Calling this function is allowed only if  [2.x.55]    is called and the refinement is executed before. Multiple calling of this   function is allowed. e.g. for interpolating several functions.  
* [0.x.8]*
   This function interpolates the discrete functions that are stored in  [2.x.56]    all_in onto the refined and/or coarsenend grid. It assumes the vectors in    [2.x.57]  denote the same vectors as in  [2.x.58]  as parameter of   <tt>prepare_for_refinement_and_coarsening(all_in)</tt>. However, there is   no way of verifying this internally, so be careful here.     Calling this function is allowed only if first    [2.x.59]  second  [2.x.60]     [2.x.61]  an then third    [2.x.62]  are called before.   Multiple calling of this function is NOT allowed. Interpolating several   functions can be performed in one step.     The number of output vectors is assumed to be the same as the number of   input vectors. Also, the sizes of the output vectors are assumed to be of   the right size ( [2.x.63]  Otherwise an assertion will be   thrown.  
* [0.x.9]*
   Same as the previous function. It interpolates only one function. It   assumes the vectors having the right sizes (i.e.   <tt>in.size()==n_dofs_old</tt>, <tt>out.size()==n_dofs_refined</tt>)     Multiple calling of this function is NOT allowed. Interpolating several   functions can be performed in one step by using <tt>interpolate (all_in,   all_out)</tt>  
* [0.x.10]*
   Determine an estimate for the memory consumption (in bytes) of this   object.  
* [0.x.11]*
   Exception  
* [0.x.12]*
   Exception  
* [0.x.13]*
   Exception  
* [0.x.14]*
   Pointer to the degree of freedom handler to work with.  
* [0.x.15]*
   Stores the number of DoFs before the refinement and/or coarsening.  
* [0.x.16]*
   Declaration of  [2.x.64]  that denotes the three possible states   of the  [2.x.65]  being prepared for 'pure refinement',   prepared for 'coarsening and refinement' or not prepared.  
* [0.x.17]*
     The SolutionTransfer is not yet prepared.    
* [0.x.18]*
     The SolutionTransfer is prepared for purely refinement.    
* [0.x.19]*
     The SolutionTransfer is prepared for coarsening and refinement.    
* [0.x.20]*
   Definition of the respective variable.  
* [0.x.21]*
   Is used for  [2.x.66]  (of course also for  [2.x.67]    repare_for_refining_and_coarsening) and stores all dof indices of the   cells that'll be refined  
* [0.x.22]*
   All cell data (the dof indices and the dof values) should be accessible   from each cell. As each cell has got only one  [2.x.68]  multiple   pointers to the data need to be packetized in a structure. Note that in   our case on each cell either the <tt>vector<unsigned int> indices</tt>   (if the cell will be refined) or the <tt>vector<double> dof_values</tt>   (if the children of this cell will be deleted) is needed, hence one  [2.x.69]    user_pointer should be sufficient, but to allow some error checks and to   preserve the user from making user errors the  [2.x.70]  will be   'multiplied' by this structure.  
* [0.x.23]*
   Map mapping from level and index of cell to the  [2.x.71]  (cf.   there). This map makes it possible to keep all the information needed to   transfer the solution inside this object rather than using user pointers   of the Triangulation for this purpose.  
* [0.x.24]*
   Is used for  [2.x.72]  The interpolated dof   values of all cells that'll be coarsened will be stored in this vector.  
* [0.x.25]*
    [2.x.73]  Use  [2.x.74]  without the DoFHandlerType   template instead.  
* [0.x.26]

include/deal.II-translator/numerics/time_dependent_0.txt
[0.x.0]*
 This class provides an abstract interface to time dependent problems in that it addresses some of the most annoying aspects of this class of problems: data management. These problems frequently need large amounts of computer resources, most notably computing time, main memory and disk space. Main memory reduction is often the most pressing need, methods to implement it are almost always quite messy, though, quickly leading to code that stores and reloads data at places scattered all over the program, and which becomes unmaintainable sometimes. The present class tries to offer a more structured interface, albeit simple, which emerged in my mind after messing with my wave equation simulation for several months.
*  The design of this class is mostly tailored for the solution of time dependent partial differential equations where the computational meshes may differ between each two timesteps and where the computations on each time step take a rather long time compared with the overhead of this class. Since no reference to the class of problems is made within this class, it is not restricted to PDEs, though, and it seems likely that a solver for large ordinary matrix differential equations may successfully use the same setup and therefore this class.
* 

*  [1.x.0]
*  The general structure of a time dependent problem solver using a timestepping scheme is about the following: we have a collection of time step objects on which we solve our problem subsequently. In order to do so, we need knowledge of the data on zero or several previous timesteps (when using single or multiple step methods, that is) and maybe also some data of time steps ahead (for example the computational grid on these). Depending on the problem in question, a second loop over all timesteps may be done solving a dual problem, where the loop may run forward (one dual problem for each time step) or backward (using a global dual problem). Within one of these loops or using a separate loop, error estimators may be computed and the grids may be refined. Each of these loops are initiated by a call preparing each timestep object for the next loop, before actually starting the loop itself.
*  We will denote a complete set of all these loops with the term "sweep". Since this library is mostly about adaptive methods, it is likely that the last loop within a sweep will generate refined meshes and that we will perform another sweep on these refined meshes. A total run will therefore often be a sequence of several sweeps. The global setup therefore looks like this:

* 
* [1.x.1]
*  The user may specify that a loop shall run forward or backward (the latter being needed for the solution of global dual problems, for example).
*  Going from the global overview to a more local viewpoint, we note that when a loop visits one timestep (e.g. to solve the primal or dual problem, or to compute error information), we need information on this, one or more previous time steps and zero or more timesteps in the future. However, often it is not needed to know all information from these timesteps and it is often a computational requirement to delete data at the first possible time when it is no more needed. Likewise, data should be reloaded at the latest time possible.
*  In order to facilitate these principles, the concept of waking up and letting sleep a time step object was developed. Assume we have a time stepping scheme which needs to look ahead one time step and needs the data of the last two time steps, the following pseudocode describes what the central loop function of this class will do when we move from timestep  [2.x.0]  n-1 to timestep  [2.x.1] 

* 
* [1.x.2]
*  The signal number here denotes the distance of the timestep being sent the signal to the timestep where computations are done on. The calls to the  [2.x.2]  wake_up and  [2.x.3]  functions with signal 0 could in principle be absorbed into the function doing the computation; we use these redundant signals, however, in order to separate computations and data management from each other, allowing to put all stuff around grid management, data reload and storage into one set of functions and computations into another.
*  In the example above, possible actions might be: timestep <tt>n+1</tt> rebuilds the computational grid (there is a specialized class which can do this for you); timestep  [2.x.4]  builds matrices and sets solution vectors to the right size, maybe using an initial guess; then it does the computations; then it deletes the matrices since they are not needed by subsequent timesteps; timestep  [2.x.5]  deletes those data vectors which are only needed by one timestep ahead; timestep  [2.x.6]  deletes the remaining vectors and deletes the computational grid, somewhere storing information how to rebuild it eventually.
*  From the given sketch above, it is clear that each time step object sees the following sequence of events:

* 
* [1.x.3]
*  This pattern is repeated for each loop in each sweep.
*  For the different loops within each sweep, the numbers of timesteps to look ahead (i.e. the maximum signal number to the  [2.x.7]  function) and the look-behind (i.e. the maximum signal number to the  [2.x.8]  function) can be chosen separately. For example, it is usually only needed to look one time step behind when computing error estimation (in some cases, it may even be possible to not look ahead or back at all, in which case only signals zero will be sent), while one needs a look back of at least one for a timestepping method.
*  Finally, a note on the direction of look-ahead and look-back is in place: look-ahead always refers to the direction the loop is running in, i.e. for loops running forward,  [2.x.9]  is called for timestep objects with a greater time value than the one previously computed on, while  [2.x.10]  is called for timesteps with a lower time. If the loop runs in the opposite direction, e.g. when solving a global dual problem, this order is reversed.
* 

*  [1.x.4]
*  The main loop of a program using this class will usually look like the following one, taken modified from an application program that isn't distributed as part of the library:

* 
* [1.x.5]
*  Here,  [2.x.11]  is an object of type TimeDependent_Wave<dim>, which is a class derived from TimeDependent.  [2.x.12]   [2.x.13]  solve_primal_problem,  [2.x.14]   [2.x.15]  and  [2.x.16]  end_sweep are functions inherited from this class. They all do a loop over all timesteps within this object and call the respective function on each of these objects. For example, here are two of the functions as they are implemented by the library:

* 
* [1.x.6]
*  The latter function shows rather clear how most of the loops are invoked ( [2.x.17]   [2.x.18]   [2.x.19]   [2.x.20]  refine_grids and  [2.x.21]  all have this form, where the latter two give functions of the derived timestep class, rather than from the base class). The function  [2.x.22]  and the respective ones for the other operations defined by that class are only used to store the type of operation which the loop presently performed will do.
*  As can be seen, most of the work is done by the  [2.x.23]  function of this class, which takes the addresses of two functions which are used to initialize all timestep objects for the loop and to actually perform some action. The next parameter gives some information on the look-ahead and look-back and the last one denotes in which direction the loop is to be run.
*  Using lambda functions it is possible to do neat tricks, like the following in this case from the function  [2.x.24] 

* 
* [1.x.7]
*   [2.x.25]  is a function taking an argument, unlike all the other functions used above within the loops. However, in this special case the parameter was the same for all timesteps and known before the loop was started, so we fixed it and made a function object which to the outside world does not take parameters.
*  Since it is the central function of this class, we finally present a stripped down version of the  [2.x.26]  method, which is shown in order to provide a better understanding of the internals of this class. For brevity we have omitted the parts that deal with backward running loops as well as the checks whether wake-up and sleep operations act on timesteps outside <tt>0..n_timesteps-1</tt>.

* 
* [1.x.8]
* 

* 
* [0.x.1]*
   Structure holding the two basic entities that control a loop over all   time steps: how many time steps ahead of the present one we shall start   waking up timestep objects and how many timesteps behind we shall call   their  [2.x.27]  method.  
* [0.x.2]*
     Constructor; see the different fields for a description of the meaning     of the parameters.    
* [0.x.3]*
     This denotes the number of timesteps the timestepping algorithm needs     to look ahead. Usually, this number will be zero, since algorithms     looking ahead can't act as timestepping schemes since they can't     compute their data from knowledge of the past only and are therefore     global in time.         However, it may be necessary to look ahead in other circumstances, when     not wanting to access the data of the next time step(s), but for     example to know the next grid, the solution of a dual problem on the     next time level, etc.         Note that for a dual problem walking back in time, "looking ahead"     means looking towards smaller time values.         The value of this number determines, how many time steps ahead the time     step manager start to call the  [2.x.28]  function for each time step.    
* [0.x.4]*
     This is the opposite variable to the above one. It denotes the number     of time steps behind the present one for which we need to keep all data     in order to do the computations on the present time level.         For one step schemes (e.g. the Euler schemes, or the Crank-Nicolson     scheme), this value will be one.         The value of this number determines, how many time steps after having     done computations on a time level the time step manager will call the  [2.x.29]      sleep function for each time step.    
* [0.x.5]*
   Enum offering the different directions in which a loop executed by  [2.x.30]    do_loop may be run.  
* [0.x.6]*
     Go in the forward direction.    
* [0.x.7]*
     Go in the backward direction.    
* [0.x.8]*
   Constructor.  
* [0.x.9]*
   Destructor. This will delete the objects pointed to by the pointers given   to the <tt>insert_*</tt> and  [2.x.31]  functions, i.e. it will   delete the objects doing the computations on each time step.  
* [0.x.10]*
   Add a timestep at any position. The position is a pointer to an existing   time step object, or a null pointer denoting the end of the timestep   sequence. If  [2.x.32]  is non-null, the new time step will be inserted   before the respective element.     Note that by giving an object to this function, the TimeDependent object   assumes ownership of the object; it will therefore also take care of   deletion of the objects its manages.     There is another function,  [2.x.33]  which inserts a time step at   the end of the list.     Note that this function does not change the timestep numbers stored   within the other timestep objects, nor does it set the timestep number of   this new timestep. This is only done upon calling the  [2.x.34]    function. In not changing the timestep numbers, it is simpler to operate   on a space-time triangulation since one can always use the timestep   numbers that were used in the previous sweep.  
* [0.x.11]*
   Just like  [2.x.35]  but insert at the end.     This mechanism usually will result in a set-up loop like this  
* [1.x.9]
*   
* [0.x.12]*
   Delete a timestep. This is only necessary to call, if you want to delete   it between two sweeps; at the end of the lifetime of this object, care is   taken automatically of deletion of the time step objects. Deletion of the   object by the destructor is done through this function also.     Note that this function does not change the timestep numbers stored   within the other timestep objects. This is only done upon calling the  [2.x.36]    start_sweep function. In not changing the timestep numbers, it is simpler   to operate on a space-time triangulation since one can always use the   timestep numbers that were used in the previous sweep.  
* [0.x.13]*
   Solve the primal problem; uses the functions  [2.x.37]    and  [2.x.38]  of the TimeStepBase class through the  [2.x.39]    do_loop function of this class.     Look ahead and look back are determined by the  [2.x.40]    timestepping_data_primal object given to the constructor.  
* [0.x.14]*
   Solve the dual problem; uses the functions  [2.x.41]  and    [2.x.42]  of the TimeStepBase class through the  [2.x.43]    function of this class.     Look ahead and look back are determined by the  [2.x.44]    object given to the constructor.  
* [0.x.15]*
   Do a postprocessing round; uses the functions  [2.x.45]    and  [2.x.46]  of the TimeStepBase class through the  [2.x.47]    function of this class.     Look ahead and look back are determined by the  [2.x.48]    timestepping_data_postprocess object given to the constructor.  
* [0.x.16]*
   Do a loop over all timesteps, call the  [2.x.49]  at the beginning   and the  [2.x.50]  of each time step. The  [2.x.51]    determine how many timesteps in front and behind the present one the  [2.x.52]    wake_up and  [2.x.53]  functions are called.     To see how this function work, note that the function  [2.x.54]    solve_primal_problem only consists of the following call:  
* [1.x.10]
*      Note also, that the given class from which the two functions are taken   needs not necessarily be TimeStepBase, but it could also be a derived   class, that is  [2.x.55]  from a TimeStepBase. The function may   be a virtual function (even a pure one) of that class, which should help   if the actual class where it is implemented is one which is derived   through virtual base classes and thus unreachable by  [2.x.56]  from   the TimeStepBase class.     Instead of using the above form, you can equally well use   <tt>[args...](Xconst x){x->unary_function(args...);}</tt>   which lets the  [2.x.57]  function call the given function with the   specified parameters.  
* [0.x.17]*
   Initialize the objects for the next sweep. This function specifically   does the following: assign each time level the number it presently has   within the array (which may change, if time levels are inserted or   deleted) and transmit the number of the present sweep to these objects.     It also calls the  [2.x.58]  function of each time step object, after   the numbers above are set.     This function is virtual, so you may overload it. You should, however not   forget to call this function as well from your overwritten version, at   best at the beginning of your function since this is some kind of   "constructor-like" function, which should be called bottom-up.     The default implementation of this function calls  [2.x.59]  on all   time step objects.  
* [0.x.18]*
   Analogous to the above function, calling  [2.x.60]  of each time step   object. The same applies with respect to the  [2.x.61]  of this   function as for the previous one.    
*  [2.x.62]  This function does not guarantee that  [2.x.63]  is called for   successive time steps successively, rather the order of time step objects   for which the function is called is arbitrary. You should therefore not   assume that that function has been called for previous time steps   already. If in multithread mode, the  [2.x.64]  function of several   time steps may be called at once, so you should use synchronization   mechanisms if your program requires so.  
* [0.x.19]*
   Determine an estimate for the memory consumption (in bytes) of this   object.  
* [0.x.20]*
   Exception.  
* [0.x.21]*
   Vector holding pointers to the time level objects. This is the main data   this object operates on. Note that this object takes possession of the   objects pointed to by the pointers in this collection.  
* [0.x.22]*
   Number of the present sweep. This is reset by the  [2.x.65]  function   called at the outset of each sweep.  
* [0.x.23]*
   Some flags telling the  [2.x.66]  function what to do. See   the documentation of this struct for more information.  
* [0.x.24]*
   Some flags telling the  [2.x.67]  function what to do. See the   documentation of this struct for more information.  
* [0.x.25]*
   Some flags telling the  [2.x.68]  function what to do. See the   documentation of this struct for more information.  
* [0.x.26]*
   Do the work of <tt>end_sweep()</tt> for some timesteps only. This is   useful in multithread mode.  
* [0.x.27]*
 Base class for a time step in time dependent problems. This class provides barely more than the basic framework, defining the necessary virtual functions (namely  [2.x.69]  and  [2.x.70]  the interface to previous and following grids, and some functions to be called before a new loop over all time steps is started.

* 
* [0.x.28]*
   Enum denoting the type of problem which will have to be solved next.  
* [0.x.29]*
     Solve the primal problem next.    
* [0.x.30]*
     Solve the dual problem next.    
* [0.x.31]*
     Perform postprocessing next.    
* [0.x.32]*
   Constructor. Does nothing here apart from setting the time.  
* [0.x.33]*
   Destructor. At present, this does nothing.  
* [0.x.34]*
   The copy constructor is deleted to avoid shallow copies with unexpected   behavior.  
* [0.x.35]*
   The copy assignment operator is deleted to avoid shallow copies with   unexpected behavior.  
* [0.x.36]*
   Reconstruct all the data that is needed for this time level to work. This   function serves to reget all the variables and data structures to work   again after they have been send to sleep some time before, or at the   first time we visit this time level. In particular, it is used to   reconstruct the triangulation, degree of freedom handlers, to reload data   vectors in case they have been stored to disk, etc.     The actual implementation of this function does nothing.     Since this is an important task, you should call this function from your   own function, should you choose to overload it in your own class (which   likely is the case), preferably at the beginning so that your function   can take effect of the triangulation already existing.  
* [0.x.37]*
   This is the opposite function to  [2.x.71]  It is used to delete data or   save it to disk after they are no more needed for the present sweep.   Typical kinds of data for this are data vectors, degree of freedom   handlers, triangulation objects, etc. which occupy large amounts of   memory and may therefore be externalized.     By default, this function does nothing.  
* [0.x.38]*
   This function is called each time before a new sweep is started. You may   want to set up some fields needed in the course of the computations, and   so on. You should take good care, however, not to install large objects,   which should be deferred until the  [2.x.72]  function is called.     A typical action of this function would be sorting out names of temporary   files needed in the process of solving, etc.     At the time this function is called, the values of  [2.x.73]   [2.x.74]    sweep_no and the pointer to the previous and next time step object   already have their correct value.     The default implementation of this function does nothing.  
* [0.x.39]*
   This is the analogous to the above function, but it is called at the end   of a sweep. You will usually want to do clean-ups in this function, such   as deleting temporary files and the like.  
* [0.x.40]*
   Before the primal problem is solved on each time level, this function is   called (i.e. before the solution takes place on the first time level). By   default, this function sets the  [2.x.75]  variable of this class.   You may overload this function, but you should call this function within   your own one.  
* [0.x.41]*
   Same as above, but called before a round of dual problem solves.  
* [0.x.42]*
   Same as above, but called before a round of postprocessing steps.  
* [0.x.43]*
   This function is called by the manager object when solving the primal   problem on this time level is needed. It is called after the  [2.x.76]    function was called and before the  [2.x.77]  function will be called.   There is no default implementation for obvious reasons, so you have to   overload this function.  
* [0.x.44]*
   This function is called by the manager object when solving the dual   problem on this time level is needed. It is called after the  [2.x.78]    function was called and before the  [2.x.79]  function will be called.   There is a default implementation doing plain nothing since some problems   may not need solving a dual problem. However, it will abort the program   when being called anyway, since then you should really overload the   function.  
* [0.x.45]*
   This function is called by the manager object when postprocessing this   time level is needed. It is called after the  [2.x.80]  function was   called and before the  [2.x.81]  function will be called. There is a   default implementation doing plain nothing since some problems may not   need doing a postprocess step, e.g. if everything was already done when   solving the primal problem. However, it will abort the program when being   called anyway, since then you should really overload the function.  
* [0.x.46]*
   Return the time value of this time step.  
* [0.x.47]*
   Return the number of this time step. Note that this number may vary   between different sweeps, if timesteps are added or deleted.  
* [0.x.48]*
   Compute the time difference to the last time step. If this timestep is   the first one, this function will result in an exception. Though this   behavior seems a bit drastic, it is appropriate in most cases since if   there is no previous time step you will need special treatment anyway and   this way no invalid value is returned which could lead to wrong but   unnoticed results of your computation. (The only sensible value to return   in that case would not be zero, since valid computation can be done with   that, but would be a denormalized value such as  [2.x.82]  However, there is   not much difference in finding that the results of a computation are all   denormalized values or in getting an exception; in the latter case you at   least get the exact place where your problem lies.)  
* [0.x.49]*
   Return the time difference to the next time step. With regard to the case   that there is no next time step, the same applies as for the function   above.  
* [0.x.50]*
   Determine an estimate for the memory consumption (in bytes) of this   object.     You will want to overload this function in derived classes to compute the   amount memory used by the derived class, and add the result of this   function to your result.  
* [0.x.51]*
   Pointer to the previous time step object in the list.  
* [0.x.52]*
   Pointer to the next time step object in the list.  
* [0.x.53]*
   Number of the sweep we are presently in. This number is reset by the time   level manager before a sweep is started.  
* [0.x.54]*
   Number of the time step, counted from zero onwards. This number is reset   at the start of each sweep by the time level manager, since some time   steps may have been inserted or deleted after the previous sweep.  
* [0.x.55]*
   Discrete time this level operates on.  
* [0.x.56]*
   Variable storing whether the solution of a primal or a dual problem is   actual, or any of the other actions specified. This variable is set by   the <tt>init_for_*</tt> functions.  
* [0.x.57]*
   Reset the pointer to the previous time step; shall only be called by the   time level manager object.     This function is called at the set-up of the manager object and whenever   a timestep is inserted or deleted.  
* [0.x.58]*
   Reset the pointer to the next time step; shall only be called by the time   level manager object.     This function is called at the set-up of the manager object and whenever   a timestep is inserted or deleted.  
* [0.x.59]*
   Set the number this time step has in the list of timesteps. This function   is called by the time step management object at the beginning of each   sweep, to update information which may have changed due to addition or   deletion of time levels.  
* [0.x.60]*
   Set the number of the sweep we are presently in. This function is called   by the time level management object at start-up time of each sweep.  
* [0.x.61]*
 Namespace in which some classes are declared that encapsulate flags for the TimeStepBase_Tria() class. These used to be local data types of that class, but some compilers choked on some aspects, so we put them into a namespace of their own.

* 
* [0.x.62]*
   This structure is used to tell the TimeStepBase_Tria() class how grids   should be handled. It has flags defining the moments where grids shall be   re-made and when they may be deleted. Also, one variable states whether   grids should be kept in memory or should be deleted between to uses to   save memory.  
* [0.x.63]*
     Default constructor; yields an exception, so is not really usable.    
* [0.x.64]*
     Constructor; see the different fields for a description of the meaning     of the parameters.    
* [0.x.65]*
     This flag determines whether the  [2.x.83]  and  [2.x.84]  functions     shall delete and rebuild the triangulation.  While for small problems,     this is not necessary, for large problems it is indispensable to save     memory.  The reason for this is that there may be several hundred time     levels in memory, each with its own triangulation, which may require     large amounts if there are many cells on each. Having a total of     100.000.000 cells on all time levels taken together is not uncommon,     which makes this flag understandable.    
* [0.x.66]*
     This number denotes the parameter to the  [2.x.85]  function at which     it shall rebuild the grid. Obviously, it shall be less than or equal to     the  [2.x.86]  number passed to the time step management object; if     it is equal, then the grid is rebuilt the first time the  [2.x.87]      function is called. If  [2.x.88]  is  [2.x.89]  this     number has no meaning.    
* [0.x.67]*
     This is the opposite flag to the one above: it determines at which call     to  [2.x.90]  the grid shall be deleted.    
* [0.x.68]*
   This structure is used to tell the TimeStepBase_Tria() class how grids   should be refined. Before we explain all the different variables, fist   some terminology:    [2.x.91]     [2.x.92]  Correction: after having flagged some cells of the triangulation for   following some given criterion, we may want to change the number of   flagged cells on this grid according to another criterion that the number   of cells may be only a certain fraction more or less then the number of   cells on the previous grid. This change of refinement flags will be   called "correction" in the sequel.    [2.x.93]  Adaption: in order to make the change between one grid and the next   not to large, we may want to flag some additional cells on one of the two   grids such that there are not too grave differences. This process will be   called "adaption".    [2.x.94]        [1.x.11]      [2.x.95]     [2.x.96]   [2.x.97]  Cut the refinement of cells at a given   level. This flag does not influence the flagging of cells, so not more   cells on the coarser levels are flagged than usual. Rather, the flags are   all set, but when it comes to the actual refinement, the maximum   refinement level is truncated.     This option is only really useful when you want to compare global   refinement with adaptive refinement when you don't want the latter to   refine more than the global refinement.      [2.x.98]   [2.x.99]  When using cell number correction as   defined above, it may be worth while to start with this only in later   sweeps, not already in the first one. If this variable is zero, then   start with the first sweep, else with a higher one. The rationale for   only starting later is that we do not want to block the development of   grids at the beginning and only impose restrictions in the sweeps where   we start to be interested in the actual results of the computations.      [2.x.100]   [2.x.101]  If we want a more free process of grid   development, we may want to impose less rules for grids with few cells   also. This variable sets a lower bound for the cell number of grids where   corrections are to be performed.      [2.x.102]   [2.x.103]  Fraction of the number of cells by   which the number of cells of one grid may be higher than that on the   previous grid. Common values are 10 per cent (i.e. 0.1). The naming of   the variable results from the goal to define a target corridor for the   number of cells after refinement has taken place.      [2.x.104]   [2.x.105]  Fraction of the number of cells by   which the number of cells of one grid may be lower than that on the   previous grid. Common values are 5 per cent (i.e. 0.05). Usually this   number will be smaller than  [2.x.106]  since an increase   of the number of cells is not harmful (though it increases the numerical   amount of work needed to solve the problem) while a sharp decrease may   reduce the accuracy of the final result even if the time steps computed   before the decrease were computed to high accuracy.     Note however, that if you compute the dual problem as well, then the time   direction is reversed, so the two values defining the cell number   corridor should be about equal.      [2.x.107]   [2.x.108]  This is a list of pairs of number with   the following meaning: just as for  [2.x.109]  it may be   worth while to reduce the requirements upon grids if the have few cells.   The present variable stores a list of cell numbers along with some values   which tell us that the cell number corridor should be enlarged by a   certain factor. For example, if this list was <tt>((100 5) (200 3) (500   2))</tt>, this would mean that for grids with a cell number below 100,   the <tt>cell_number_corridor_*</tt> variables are to be multiplied by 5   before they are applied, for cell numbers below 200 they are to be   multiplied by 3, and so on.      [2.x.110]  is actually a vector of such list. Each entry   in this vector denotes the relaxation rules for one sweep. The last entry   defines the relaxation rules for all following sweeps. This scheme is   adopted to allow for stricter corrections in later sweeps while the   relaxations may be more generous in the first sweeps.     There is a static variable  [2.x.111]  which you   can use as a default value. It is an empty list and thus defines no   relaxations.      [2.x.112]   [2.x.113]  Usually, if you want the number of   cells to be corrected, the target corridor for the cell number is   computed and some additional cells are flagged or flags are removed. But   since the cell number resulting after flagging and deflagging can not be   easily computed, it will usually not be within the corridor. We therefore   need to iteratively get to our goal. Usually, three or four iterations   are needed, but using this variable, you can reduce the allowed number of   iterations; breaking the loop after two iterations yields good results   regularly. Setting the variable to zero will result in no correction   steps at all.      [2.x.114]   [2.x.115]  If a cell on the present grid is   flagged for refinement, also flag the corresponding cell on the previous   grid. This is useful if, for example, error indicators are computed for   space-time cells, but are stored for the second grid only. Now, since the   first grid has the same contributions to the indicators as the second, it   may be useful to flag both if necessary. This is done if the present   variable is set.      [2.x.116]   [2.x.117]  adapt the present grid to the previous one in the   sense defined above. What is actually done here is the following: if   going from the previous to the present grid would result in double   refinement or double coarsening of some cells, then we try to flag these   cells for refinement or coarsening such as to avoid the double step.   Obviously, more than double refinement of coarsening is also caught.     Grid adaption can try to avoid such changes between two grids, but it can   never promise that they don't occur. This is because the next grid may   change the present one, but then again there may be jumps in refinement   level between the present and the previous one; this could only be   avoided by looping iteratively through all grids, back and forth, until   nothing changes anymore, which is obviously impossible if there are many   time steps with very large grids.    [2.x.118]   
* [0.x.69]*
     Typedef of a data type describing some relaxations of the correction     process. See the general description of this class for more     information.    
* [0.x.70]*
     Default values for the relaxations: no relaxations.    
* [0.x.71]*
     Constructor. The default values are chosen such that almost no     restriction on the mesh refinement is imposed.    
* [0.x.72]*
     Maximum level of a cell in the triangulation of a time level. If it is     set to zero, then no limit is imposed on the number of refinements a     coarse grid cell may undergo. Usually, this field is used, if for some     reason you want to limit refinement in an adaptive process, for example     to avoid overly large numbers of cells or to compare with grids which     have a certain number of refinements.    
* [0.x.73]*
     First sweep to perform cell number correction steps on; for sweeps     before, cells are only flagged and no number-correction to previous     grids is performed.    
* [0.x.74]*
     Apply cell number correction with the previous time level only if there     are more than this number of cells.    
* [0.x.75]*
     Fraction by which the number of cells on a time level may differ from     the number on the previous time level (first: top deviation, second:     bottom deviation).    
* [0.x.76]*
      [2.x.119]     
* [0.x.77]*
     List of relaxations to the correction step.    
* [0.x.78]*
     Number of iterations to be performed to adjust the number of cells on a     time level to those on the previous one. Zero means: do no such     iteration.    
* [0.x.79]*
     Flag all cells which are flagged on this timestep for refinement on the     previous one also. This is useful in case the error indicator was     computed by integration over time-space cells, but are now associated     to a grid on a discrete time level. Since the error contribution comes     from both grids, however, it is appropriate to refine both grids.         Since the previous grid does not mirror the flags to the one before it,     this does not lead to an almost infinite growth of cell numbers. You     should use this flag with cell number correction switched on only,     however.         Mirroring is done after cell number correction is done, but before grid     adaption, so the cell number on this grid is not noticeably influenced     by the cells flagged additionally on the previous grid.    
* [0.x.80]*
     Adapt this grid to the previous one.    
* [0.x.81]*
     Exception    
* [0.x.82]*
   Structure given to the actual refinement function, telling it which   thresholds to take for coarsening and refinement. The actual refinement   criteria are loaded by calling the virtual function  [2.x.120]    get_tria_refinement_criteria.  
* [0.x.83]*
     Constructor    
* [0.x.84]*
     Threshold for refinement: cells having a larger value will be refined     (at least in the first round; subsequent steps of the refinement     process may flag other cells as well or remove the flag from cells with     a criterion higher than this threshold).    
* [0.x.85]*
     Same threshold for coarsening: cells with a smaller threshold will be     coarsened if possible.    
* [0.x.86]*
     Exception    
* [0.x.87]*
 Specialization of TimeStepBase which addresses some aspects of grid handling. In particular, this class is thought to make handling of grids available that are adaptively refined on each time step separately or with a loose coupling between time steps. It also takes care of deleting and rebuilding grids when memory resources are a point, through the  [2.x.121]  and  [2.x.122]  functions declared in the base class.
*  In addition to that, it offers functions which do some rather hairy refinement rules for time dependent problems, trying to avoid too much change in the grids between subsequent time levels, while also trying to retain the freedom of refining each grid separately. There are lots of flags and numbers controlling this function, which might drastically change the behavior of the function
* 
*  -  see the description of the flags for further information.

* 
* [0.x.88]*
   Typedef the data types of the TimeStepBase_Tria_Flags() namespace into   local scope.  
* [0.x.89]*
   Extension of the enum in the base class denoting the next action to be   done.  
* [0.x.90]*
     Perform grid refinement next.    
* [0.x.91]*
   Default constructor. Does nothing but throws an exception. We need to   have such a constructor in order to satisfy the needs of derived classes,   which take this class as a virtual base class and don't need to call this   constructor of they are not terminal classes. The compiler would like to   know a constructor to call anyway since it can't know that the class is   not terminal.  
* [0.x.92]*
   Constructor. Takes a coarse grid from which the grids on this time level   will be derived and some flags steering the behavior of this object.     The ownership of the coarse grid stays with the creator of this object.   However, it is locked from destruction to guarantee the lifetime of the   coarse grid is longer than it is needed by this object.     You need to give the general flags structure to this function since it is   needed anyway; the refinement flags can be omitted if you do not intend   to call the refinement function of this class.  
* [0.x.93]*
   Destructor. At present, this does not more than releasing the lock on the   coarse grid triangulation given to the constructor.  
* [0.x.94]*
   Reconstruct all the data that is needed for this time level to work. This   function serves to reget all the variables and data structures to work   again after they have been send to sleep some time before, or at the   first time we visit this time level. In particular, it is used to   reconstruct the triangulation, degree of freedom handlers, to reload data   vectors in case they have been stored to disk, etc. By default, this   function rebuilds the triangulation if the respective flag has been set   to destroy it in the  [2.x.123]  function. It does so also the first time we   hit this function and  [2.x.124]  equals   <tt>flags.wakeup_level_to_build_grid</tt>, independently of the value of   the mentioned flag. (Actually, it does so whenever the triangulation   pointer equals the Null pointer and the value of  [2.x.125]  is   right.)     Since this is an important task, you should call this function from your   own function, should you choose to overload it in your own class (which   likely is the case), preferably at the beginning so that your function   can take effect of the triangulation already existing.  
* [0.x.95]*
   This is the opposite function to  [2.x.126]  It is used to delete data or   save it to disk after they are no more needed for the present sweep.   Typical kinds of data for this are data vectors, degree of freedom   handlers, triangulation objects, etc. which occupy large amounts of   memory and may therefore be externalized.     By default, if the user specified so in the flags for this object, the   triangulation is deleted and the refinement history is saved such that the   respective  [2.x.127]  function can rebuild it. You should therefore call   this function from your overloaded version, preferably at the end so that   your function can use the triangulation as long as you need it.  
* [0.x.96]*
   Do the refinement according to the flags passed to the constructor of   this object and the data passed to this function. For a description of   the working of this function refer to the general documentation of this   class.     In fact, this function does not actually refine or coarsen the   triangulation, but only sets the respective flags. This is done because   usually you will not need the grid immediately afterwards but only in the   next sweep, so it suffices to store the flags and rebuild it the next   time we need it. Also, it may be that the next time step would like to   add or delete some flags, so we have to wait anyway with the use of this   grid.  
* [0.x.97]*
   Respective init function for the refinement loop; does nothing in the   default implementation, apart from setting  [2.x.128]  to  [2.x.129]    grid_refinement but can be overloaded.  
* [0.x.98]*
   Virtual function that should fill the vector with the refinement criteria   for the present triangulation. It is used within the  [2.x.130]    function to get the criteria for the present time step, since they can't   be passed through its argument when using the loop of the time step   management object.  
* [0.x.99]*
   The refinement flags of the triangulation are stored in a local variable   thus allowing a restoration. The coarsening flags are also stored.  
* [0.x.100]*
   Determine an estimate for the memory consumption (in bytes) of this   object.     You will want to overload this function in derived classes to compute the   amount memory used by the derived class, and add the result of this   function to your result.  
* [0.x.101]*
   Exception  
* [0.x.102]*
   Triangulation used at this time level. Since this is something that every   time stepping scheme needs to have, we can safely put it into the base   class. Note that the triangulation is frequently deleted and rebuilt by   the functions  [2.x.131]  and  [2.x.132]  to save memory, if such a behavior   is specified in the  [2.x.133]  structure.  
* [0.x.103]*
   Pointer to a grid which is to be used as the coarse grid for this time   level.  This pointer is set through the constructor; ownership remains   with the owner of this management object.  
* [0.x.104]*
   Some flags about how this time level shall behave. See the documentation   of this struct to find out more about that.  
* [0.x.105]*
   Flags controlling the refinement process; see the documentation of the   respective structure for more information.  
* [0.x.106]*
   Vectors holding the refinement and coarsening flags of the different   sweeps on this time level. The vectors therefore hold the history of the   grid.  
* [0.x.107]*
    [2.x.134]   
* [0.x.108]*
   Restore the grid according to the saved data. For this, the coarse grid   is copied and the grid is stepwise rebuilt using the saved flags.  
* [0.x.109]

include/deal.II-translator/numerics/vector_tools.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/vector_tools_0.txt
[0.x.0]*
 Provide a namespace which offers some operations on vectors. Among these are assembling of standard vectors, integration of the difference of a finite element solution and a continuous function, interpolations and projections of continuous functions to the finite element space and other operations.
* 

* 
*  [2.x.0]  There exist two versions of almost all functions, one that takes an explicit Mapping argument and one that does not. The second one generally calls the first with an implicit  [2.x.1]  argument (i.e., with an argument of kind MappingQGeneric(1)). If your intend your code to use a different mapping than a (bi-/tri-)linear one, then you need to call the functions [1.x.0] mapping argument should be used.
* 

*  [1.x.1]
*  This collection of methods offers the following operations:  [2.x.2]   [2.x.3]  Interpolation: assign each degree of freedom in the vector to be the value of the function given as argument. This is identical to saying that the resulting finite element function (which is isomorphic to the output vector) has exact function values in all support points of trial functions. The support point of a trial function is the point where its value equals one, e.g. for linear trial functions the support points are four corners of an element. This function therefore relies on the assumption that a finite element is used for which the degrees of freedom are function values (Lagrange elements) rather than gradients, normal derivatives, second derivatives, etc (Hermite elements, quintic Argyris element, etc.).
*  It seems inevitable that some values of the vector to be created are set twice or even more than that. The reason is that we have to loop over all cells and get the function values for each of the trial functions located thereon. This applies also to the functions located on faces and corners which we thus visit more than once. While setting the value in the vector is not an expensive operation, the evaluation of the given function may be, taking into account that a virtual function has to be called.
*   [2.x.4]  Projection: compute the [1.x.2]<sup>2</sup>-projection of the given function onto the finite element space, i.e. if [1.x.3] is the function to be projected, compute [1.x.4] in [1.x.5] such that ([1.x.6],[1.x.7])=([1.x.8],[1.x.9]) for all discrete test functions [1.x.10]. This is done through the solution of the linear system of equations [1.x.11] where [1.x.12] is the mass matrix  [2.x.5]  and  [2.x.6] . The solution vector  [2.x.7]  then is the nodal representation of the projection [1.x.13]. The project() functions are used in the  [2.x.8]  and  [2.x.9]  tutorial programs.
*  In order to get proper results, it be may necessary to treat boundary conditions right. Below are listed some cases where this may be needed.  If needed, this is done by [1.x.14]<sup>2</sup>-projection of the trace of the given function onto the finite element space restricted to the boundary of the domain, then taking this information and using it to eliminate the boundary nodes from the mass matrix of the whole domain, using the  [2.x.10]  function. The projection of the trace of the function to the boundary is done with the  [2.x.11]  (see below) function, which is called with a map of boundary functions  [2.x.12]  const Function<spacedim,number>*> in which all boundary indicators from zero to  [2.x.13]   [2.x.14]  is used for other purposes, see the Triangulation class documentation) point to the function to be projected. The projection to the boundary takes place using a second quadrature formula on the boundary given to the project() function. The first quadrature formula is used to compute the right hand side and for numerical quadrature of the mass matrix.
*  The projection of the boundary values first, then eliminating them from the global system of equations is not needed usually. It may be necessary if you want to enforce special restrictions on the boundary values of the projected function, for example in time dependent problems: you may want to project the initial values but need consistency with the boundary values for later times. Since the latter are projected onto the boundary in each time step, it is necessary that we also project the boundary values of the initial values, before projecting them to the whole domain.
*  Obviously, the results of the two schemes for projection are different. Usually, when projecting to the boundary first, the [1.x.15]<sup>2</sup>-norm of the difference between original function and projection over the whole domain will be larger (factors of five have been observed) while the [1.x.16]<sup>2</sup>-norm of the error integrated over the boundary should of course be less. The reverse should also hold if no projection to the boundary is performed.
*  The selection whether the projection to the boundary first is needed is done with the <tt>project_to_boundary_first</tt> flag passed to the function.  If  [2.x.15]  is given, the additional quadrature formula for faces is ignored.
*  You should be aware of the fact that if no projection to the boundary is requested, a function with zero boundary values may not have zero boundary values after projection. There is a flag for this especially important case, which tells the function to enforce zero boundary values on the respective boundary parts. Since enforced zero boundary values could also have been reached through projection, but are more economically obtain using other methods, the  [2.x.16]  flag is ignored if the  [2.x.17]  flag is set.
*  The solution of the linear system is presently done using a simple CG method without preconditioning and without multigrid. This is clearly not too efficient, but sufficient in many cases and simple to implement. This detail may change in the future.
*   [2.x.18]  Creation of right hand side vectors: The create_right_hand_side() function computes the vector  [2.x.19] . This is the same as what the  [2.x.20]  functions which take a right hand side do, but without assembling a matrix.
*   [2.x.21]  Creation of right hand side vectors for point sources: The create_point_source_vector() function computes the vector  [2.x.22] .
*   [2.x.23]  Creation of boundary right hand side vectors: The create_boundary_right_hand_side() function computes the vector  [2.x.24] . This is the right hand side contribution of boundary forces when having inhomogeneous Neumann boundary values in Laplace's equation or other second order operators. This function also takes an optional argument denoting over which parts of the boundary the integration shall extend. If the default argument is used, it is applied to all boundaries.
*   [2.x.25]  Interpolation of boundary values: The  [2.x.26]  function takes a list of boundary nodes and their values. You can get such a list by interpolation of a boundary function using the interpolate_boundary_values() function. To use it, you have to specify a list of pairs of boundary indicators (of type  [2.x.27]  see the section in the documentation of the Triangulation class for more details) and the according functions denoting the Dirichlet boundary values of the nodes on boundary faces with this boundary indicator.
*  Usually, all other boundary conditions, such as inhomogeneous Neumann values or mixed boundary conditions are handled in the weak formulation. No attempt is made to include these into the process of matrix and vector assembly therefore.
*  Within this function, boundary values are interpolated, i.e. a node is given the point value of the boundary function. In some cases, it may be necessary to use the L2-projection of the boundary function or any other method. For this purpose we refer to the project_boundary_values() function below.
*  You should be aware that the boundary function may be evaluated at nodes on the interior of faces. These, however, need not be on the true boundary, but rather are on the approximation of the boundary represented by the mapping of the unit cell to the real cell. Since this mapping will in most cases not be the exact one at the face, the boundary function is evaluated at points which are not on the boundary and you should make sure that the returned values are reasonable in some sense anyway.
*  In 1d the situation is a bit different since there faces (i.e. vertices) have no boundary indicator. It is assumed that if the boundary indicator zero is given in the list of boundary functions, the left boundary point is to be interpolated while the right boundary point is associated with the boundary index 1 in the map. The respective boundary functions are then evaluated at the place of the respective boundary point.
*   [2.x.28]  Projection of boundary values: The project_boundary_values() function acts similar to the interpolate_boundary_values() function, apart from the fact that it does not get the nodal values of boundary nodes by interpolation but rather through the [1.x.17]<sup>2</sup>-projection of the trace of the function to the boundary.
*  The projection takes place on all boundary parts with boundary indicators listed in the map  [2.x.29]  const Function<spacedim,number>*>) of boundary functions. These boundary parts may or may not be continuous. For these boundary parts, the mass matrix is assembled using the  [2.x.30]  function, as well as the appropriate right hand side. Then the resulting system of equations is solved using a simple CG method (without preconditioning), which is in most cases sufficient for the present purpose.
*   [2.x.31]  Computing errors: The function integrate_difference() performs the calculation of the error between a given (continuous) reference function and the finite element solution in different norms. The integration is performed using a given quadrature formula and assumes that the given finite element objects equals that used for the computation of the solution.
*  The result is stored in a vector (named  [2.x.32]  where each entry equals the given norm of the difference on a cell. The order of entries is the same as a  [2.x.33]  takes when started with  [2.x.34]  and promoted with the <tt>++</tt> operator.
*  This data, one number per active cell, can be used to generate graphical output by directly passing it to the DataOut class through the  [2.x.35]  function. Alternatively, the global error can be computed using  [2.x.36]  Finally, the output per cell from  [2.x.37]  can be interpolated to the nodal points of a finite element field using the  [2.x.38]  function.
*  Presently, there is the possibility to compute the following values from the difference, on each cell:  [2.x.39]   [2.x.40]   [2.x.41]   [2.x.42]  Linfty_norm,  [2.x.43]  and  [2.x.44]  see  [2.x.45]  For the mean difference value, the reference function minus the numerical solution is computed, not the other way round.
*  The infinity norm of the difference on a given cell returns the maximum absolute value of the difference at the quadrature points given by the quadrature formula parameter. This will in some cases not be too good an approximation, since for example the Gauss quadrature formulae do not evaluate the difference at the end or corner points of the cells. You may want to choose a quadrature formula with more quadrature points or one with another distribution of the quadrature points in this case. You should also take into account the superconvergence properties of finite elements in some points: for example in 1D, the standard finite element method is a collocation method and should return the exact value at nodal points. Therefore, the trapezoidal rule should always return a vanishing L-infinity error. Conversely, in 2D the maximum L-infinity error should be located at the vertices or at the center of the cell, which would make it plausible to use the Simpson quadrature rule. On the other hand, there may be superconvergence at Gauss integration points. These examples are not intended as a rule of thumb, rather they are thought to illustrate that the use of the wrong quadrature formula may show a significantly wrong result and care should be taken to chose the right formula.
*  The [1.x.18]<sup>1</sup> seminorm is the [1.x.19]<sup>2</sup> norm of the gradient of the difference. The square of the full [1.x.20]<sup>1</sup> norm is the sum of the square of seminorm and the square of the [1.x.21]<sup>2</sup> norm.
*  To get the global [1.x.22] error, you have to sum up the entries in  [2.x.46]  e.g. using  [2.x.47]  function.  For the global [1.x.23]<sup>2</sup> difference, you have to sum up the squares of the entries and take the root of the sum, e.g. using  [2.x.48]  These two operations represent the [1.x.24]<sub>1</sub> and [1.x.25]<sub>2</sub> norms of the vectors, but you need not take the absolute value of each entry, since the cellwise norms are already positive.
*  To get the global mean difference, simply sum up the elements as above. To get the  [2.x.49]  norm, take the maximum of the vector elements, e.g. using the  [2.x.50]  function.
*  For the global [1.x.26]<sup>1</sup> norm and seminorm, the same rule applies as for the [1.x.27]<sup>2</sup> norm: compute the [1.x.28]<sub>2</sub> norm of the cell error vector.
*  Note that, in the codimension one case, if you ask for a norm that requires the computation of a gradient, then the provided function is automatically projected along the curve, and the difference is only computed on the tangential part of the gradient, since no information is available on the normal component of the gradient anyway.  [2.x.51] 
*  All functions use the finite element given to the DoFHandler object the last time that the degrees of freedom were distributed over the triangulation. Also, if access to an object describing the exact form of the boundary is needed, the pointer stored within the triangulation object is accessed.
* 

* 
*  [2.x.52]  Instantiations for this template are provided for some vector types, in particular <code>Vector&lt;float&gt;, Vector&lt;double&gt;, BlockVector&lt;float&gt;, BlockVector&lt;double&gt;</code>; others can be generated in application code (see the section on  [2.x.53]  in the manual).
* 

* 
*  [2.x.54] 

* 
* [0.x.1]

include/deal.II-translator/numerics/vector_tools_boundary.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/vector_tools_boundary_0.txt
[0.x.0]*
    [2.x.0]  Interpolation and projection  
* [0.x.1]*
   Compute constraints on the solution that corresponds to the imposition   of Dirichlet boundary conditions.  This function creates a map of   degrees of freedom subject to Dirichlet boundary conditions and the   corresponding values to be assigned to them, by interpolation around the   boundary. For each degree of freedom at the boundary, if its index   already exists in  [2.x.1]  then its boundary value will be   overwritten, otherwise a new entry with proper index and boundary value   for this degree of freedom will be inserted into  [2.x.2]      The parameter  [2.x.3]  provides a list of boundary indicators to   be handled by this function and corresponding boundary value functions.   The keys of this map correspond to the number  [2.x.4]  of the face.    [2.x.5]  is an illegal value for this key since   it is reserved for interior faces. For an example of how to use this   argument with a non-empty map, see the  [2.x.6]  tutorial program.     The flags in the last parameter,  [2.x.7]  denote which   components of the finite element space shall be interpolated. If it is   left as specified by the default value (i.e. an empty array), all   components are interpolated. If it is different from the default value,   it is assumed that the number of entries equals the number of components   in the boundary functions and the finite element, and those components in   the given boundary function will be used for which the respective flag   was set in the component mask. See also    [2.x.8] .   As an example, assume that you are solving the Stokes equations in 2d,   with variables  [2.x.9]  and that you only want to interpolate boundary   values for the velocity, then the component mask should correspond to    [2.x.10] .    
*  [2.x.11]  Whether a component mask has been specified or not, the number of   components of the functions in  [2.x.12]  must match that of the   finite element used by  [2.x.13]  In other words, for the example above, you   need to provide a Function object that has 3 components (the two   velocities and the pressure), even though you are only interested in the   first two of them. interpolate_boundary_values() will then call this   function to obtain a vector of 3 values at each interpolation point but   only take the first two and discard the third. In other words, you are   free to return whatever you like in the third component of the vector   returned by  [2.x.14]  but the Function object must state   that it has 3 components.     If the finite element used has shape functions that are non-zero in more   than one component (in deal.II speak: they are non-primitive), then these   components can presently not be used for interpolating boundary values.   Thus, the elements in the component mask corresponding to the components   of these non-primitive shape functions must be  [2.x.15]      See the general documentation of this namespace for more information.    
*  [2.x.16]  When solving a partial differential equation with boundary     conditions  [2.x.17]  (or onparts* of the boundary),     then this boundary condition is in general not satisfiable exactly     using finite elements in the form  [2.x.18] . That is     because the function  [2.x.19]  is generally not a polynomial, whereas      [2.x.20] is* a polynomial on each face of the     mesh that is located at the boundary. In other words, it is in     general not possible toimpose* such boundary condition; what one    can* do, however, is to impose       [1.x.0]     where  [2.x.21]  is a function that equals  [2.x.22]  at each node     of the finite element space located on the boundary, and is piecewise     polynomial in between. In other words,  [2.x.23]  is an    interpolation operator* and  [2.x.24]  are the     interpolated boundary values
* 
*  -  thus the name. The use of      [2.x.25]  instead of  [2.x.26]  as boundary values imposes     an additional error (in the same spirit as using quadrature introduces     an additional error compared to being able to compute the integrals of     the weak form exactly). In most cases, this additional error is of the     same order as the other error terms in the finite element method,     though there are some subtle differences when measuring the error in     the  [2.x.27]  norm. For some details, see  [2.x.28]  .    
*  [2.x.29]  An alternative to using the interpolant,       [1.x.1]     is to use theprojection* of the boundary values  [2.x.30]  onto the     finite element space on the boundary:       [1.x.2]     The projection is available using the project_boundary_values()     function. Using the projection may have some theoretical advantages     (see again  [2.x.31] ) but has the practical disadvantage     that computing the projection is far more expensive than computing     the interpolation because the latter can be done one face at a time     whereas the projection requires the solution of a problem on the entire     boundary. On the other hand, interpolation is only possible for     "nodal" finite element spaces (such as FE_Q, but not     FE_Q_Hierarchical), whereas the projection is always possible.  
* [0.x.2]*
   Like the previous function, but take a mapping collection to go with   DoFHandler objects with hp-capabilities.  
* [0.x.3]*
   Same function as above, but taking only one pair of boundary indicator   and corresponding boundary function. The same comments apply as for the   previous function, in particular about the use of the component mask and   the requires size of the function object.      [2.x.32]     [2.x.33]  "Glossary entry on boundary indicators"  
* [0.x.4]*
   Like the previous function, but take a mapping collection to go with   DoFHandler objects with hp-capabilities.  
* [0.x.5]*
   Call the other interpolate_boundary_values() function, see above, with   <tt>mapping=MappingQGeneric [2.x.34]  The same comments   apply as for the previous function, in particular about the use of the   component mask and the requires size of the function object.      [2.x.35]     [2.x.36]  "Glossary entry on boundary indicators"  
* [0.x.6]*
   Call the other interpolate_boundary_values() function, see above, with   <tt>mapping=MappingQGeneric [2.x.37]  The same comments   apply as for the previous function, in particular about the use of the   component mask and the requires size of the function object.  
* [0.x.7]*
   Insert the (algebraic) constraints due to Dirichlet boundary conditions   into a AffineConstraints  [2.x.38]  This function identifies the   degrees of freedom subject to Dirichlet boundary conditions, adds them to   the list of constrained DoFs in  [2.x.39]  and sets the respective   inhomogeneity to the value interpolated around the boundary. If this   routine encounters a DoF that already is constrained (for instance by a   hanging node constraint, see below, or any other type of constraint, e.g.   from periodic boundary conditions), the old setting of the constraint   (dofs the entry is constrained to, inhomogeneities) is kept and nothing   happens.    
*  [2.x.40]  When combining adaptively refined meshes with hanging node   constraints and boundary conditions like from the current function within   one AffineConstraints object, the hanging node constraints should always   be set first, and then the boundary conditions since boundary conditions   are not set in the second operation on degrees of freedom that are   already constrained. This makes sure that the discretization remains   conforming as is needed. See the discussion on conflicting constraints in   the module on    [2.x.41] .     This function is fundamentally equivalent to the ones above except that it   puts its results into an AffineConstraint object rather than a  [2.x.42]    See the functions above for more comments.    
*  [2.x.43]   
* [0.x.8]*
   Like the previous function, but take a mapping collection to go with   DoFHandler objects with hp-capabilities.  
* [0.x.9]*
   Same function as above, but taking only one pair of boundary indicator   and corresponding boundary function. The same comments apply as for the   previous function, in particular about the use of the component mask and   the requires size of the function object.    
*  [2.x.44]       [2.x.45]     [2.x.46]  "Glossary entry on boundary indicators"  
* [0.x.10]*
   Like the previous function, but take a mapping collection to go with   DoFHandler objects with hp-capabilities.  
* [0.x.11]*
   Call the other interpolate_boundary_values() function, see above, with   <tt>mapping=MappingQGeneric [2.x.47]  The same comments   apply as for the previous function, in particular about the use of the   component mask and the requires size of the function object.    
*  [2.x.48]       [2.x.49]     [2.x.50]  "Glossary entry on boundary indicators"  
* [0.x.12]*
   Call the other interpolate_boundary_values() function, see above, with   <tt>mapping=MappingQGeneric [2.x.51]  The same comments   apply as for the previous function, in particular about the use of the   component mask and the requires size of the function object.    
*  [2.x.52]   
* [0.x.13]*
   Project a function or a set of functions to the boundary of the domain.   In other words, compute the solution of the following problem: Find  [2.x.53]  (where  [2.x.54]  is the finite element space represented by the   DoFHandler argument of this function) so that  
* [1.x.3]
*    where  [2.x.55] ,  [2.x.56] ,  [2.x.57]  is the set of indices and  [2.x.58]  the   corresponding boundary functions represented in the function map argument    [2.x.59]  to this function, and the integrals are evaluated by   quadrature. This problem has a non-unique solution in the interior, but   it is well defined for the degrees of freedom on the part of the   boundary,  [2.x.60] , for which we do the integration. The values of    [2.x.61] , i.e., the nodal values of the degrees of freedom of this   function along the boundary, are then what is computed by this function.     In case this function is used with  [2.x.62]  conforming finite element   space, the solution of a different problem is computed, namely: Find    [2.x.63]  so that  
* [1.x.4]
*    where  [2.x.64]  is an outward normal vector.     This function throws an exception if used with  [2.x.65]  conforming   elements, so the project_boundary_values_curl_conforming_l2() should be   used instead.      [2.x.66]  mapping The mapping that will be used in the transformations   necessary to integrate along the boundary.    [2.x.67]  dof The DoFHandler that describes the finite element space and   the numbering of degrees of freedom.    [2.x.68]  boundary_functions A map from boundary indicators to pointers   to functions that describe the desired values on those parts of the   boundary marked with this boundary indicator (see    [2.x.69]  "Boundary indicator").   The projection happens on only those parts of the boundary whose   indicators are represented in this map.    [2.x.70]  q The face quadrature used in the integration necessary to   compute the mass matrix and right hand side of the projection.    [2.x.71]  boundary_values The result of this function. It is a map   containing all indices of degrees of freedom at the boundary (as covered   by the boundary parts in  [2.x.72]  and the computed dof   value for this degree of freedom. For each degree of freedom at the   boundary, if its index already exists in  [2.x.73]  then its   boundary value will be overwritten, otherwise a new entry with proper   index and boundary value for this degree of freedom will be inserted into    [2.x.74]     [2.x.75]  component_mapping It is sometimes convenient to project a   vector-valued function onto only parts of a finite element space (for   example, to project a function with  [2.x.76]  components onto the   velocity components of a  [2.x.77]  component DoFHandler for a   Stokes problem). To allow for this, this argument allows components to be   remapped. If the vector is not empty, it has to have one entry for each   vector component of the finite element used in  [2.x.78]  This entry is the   component number in  [2.x.79]  that should be used for this   component in  [2.x.80]  By default, no remapping is applied.    
*  [2.x.81]  Using theprojection* rather than theinterpolation* of     boundary values makes relatively little difference in     practice. That said, it is far more computationally expensive     to compute projections because the require the solution of a     problem that couples all unknowns on the boundary, whereas     interpolation works on one face at a time. On the other hand,     interpolation is only possible for "nodal" finite element     spaces (such as FE_Q, but not FE_Q_Hierarchical), whereas the     projection is always possible. (For some more theoretical     considerations, see the documentation of the first     interpolate_boundary_values() function above.)  
* [0.x.14]*
   Call the project_boundary_values() function, see above, with   <tt>mapping=MappingQGeneric [2.x.82]   
* [0.x.15]*
   Same as above, but with hp-capabilities.  
* [0.x.16]*
   Call the project_boundary_values() function, see above, with   <tt>mapping=MappingQGeneric [2.x.83]   
* [0.x.17]*
   Project a function to the boundary of the domain, using the given   quadrature formula for the faces. This function identifies the degrees of   freedom subject to Dirichlet boundary conditions, adds them to the list   of constrained DoFs in  [2.x.84]  and sets the respective   inhomogeneity to the value resulting from the projection operation. If   this routine encounters a DoF that already is constrained (for instance   by a hanging node constraint, see below, or any other type of constraint,   e.g. from periodic boundary conditions), the old setting of the   constraint (dofs the entry is constrained to, inhomogeneities) is kept   and nothing happens.    
*  [2.x.85]  When combining adaptively refined meshes with hanging node   constraints and boundary conditions like from the current function within   one AffineConstraints object, the hanging node constraints should always   be set first, and then the boundary conditions since boundary conditions   are not set in the second operation on degrees of freedom that are   already constrained. This makes sure that the discretization remains   conforming as is needed. See the discussion on conflicting constraints in   the module on    [2.x.86] .     If  [2.x.87]  is empty, it is assumed that the number of   components of  [2.x.88]  matches that of the finite element   used by  [2.x.89]      In 1d, projection equals interpolation. Therefore,   interpolate_boundary_values is called.      [2.x.90]   [2.x.91]  if the components in  [2.x.92]  and    [2.x.93]  do not coincide, this vector allows them to be remapped. If the   vector is not empty, it has to have one entry for each component in  [2.x.94]    dof. This entry is the component number in  [2.x.95]  that   should be used for this component in  [2.x.96]  By default, no remapping is   applied.    
*  [2.x.97]   
* [0.x.18]*
   Call the project_boundary_values() function, see above, with   <tt>mapping=MappingQGeneric [2.x.98]     
*  [2.x.99]   
* [0.x.19]*
   This function is an updated version of the   project_boundary_values_curl_conforming function. The intention is to fix   a problem when using the previous function in conjunction with non-   rectangular geometries (i.e. elements with non-rectangular faces). The   L2-projection method used has been taken from the paper "Electromagnetic   scattering simulation using an H (curl) conforming hp-finite element   method in three dimensions" by PD Ledger, K Morgan and O Hassan ( Int. J.   Num. Meth. Fluids, Volume 53, Issue 8, pages 1267-1296).     This function will compute constraints that correspond to Dirichlet   boundary conditions of the form    [2.x.100]  i.e. the tangential   components of  [2.x.101]  and  [2.x.102]  shall coincide.     [1.x.5]     To compute the constraints we use a projection method based upon the   paper mentioned above. In 2D this is done in a single stage for the edge-   based shape functions, regardless of the order of the finite element. In   3D this is done in two stages, edges first and then faces.     For each cell, each edge,  [2.x.103] , is projected by solving the linear system    [2.x.104]  where  [2.x.105]  is the vector of constraints on degrees of freedom on the   edge and      [2.x.106]       [2.x.107]      with  [2.x.108]  the  [2.x.109]  shape function and  [2.x.110]  the tangent   vector.     Once all edge constraints,  [2.x.111] , have been computed, we may compute the   face constraints in a similar fashion, taking into account the residuals   from the edges.     For each face on the cell,  [2.x.112] , we solve the linear system  [2.x.113]  where    [2.x.114]  is the vector of constraints on degrees of freedom on the face and      [2.x.115]       [2.x.116]      and  [2.x.117] ,   the edge residual.     The resulting constraints are then given in the solutions  [2.x.118]  and  [2.x.119] .     If the AffineConstraints  [2.x.120]  contained values or other   constraints before, the new ones are added or the old ones overwritten,   if a node of the boundary part to be used was already in the list of   constraints. This is handled by using inhomogeneous constraints. Please   note that when combining adaptive meshes and this kind of constraints,   the Dirichlet conditions should be set first, and then completed by   hanging node constraints, in order to make sure that the discretization   remains consistent. See the discussion on conflicting constraints in the   module on    [2.x.121] .     [1.x.6]     This function is explicitly for use with FE_Nedelec elements, or with   FESystem elements which contain FE_Nedelec elements. It will throw an   exception if called with any other finite element. The user must ensure   that FESystem elements are correctly setup when using this function as   this check not possible in this case.     The second argument of this function denotes the first vector component   of the finite element which corresponds to the vector function that you   wish to constrain. For example, if we are solving Maxwell's equations in   3D and have components  [2.x.122]  and we want the   boundary conditions  [2.x.123] , then  [2.x.124]    first_vector_component would be 3. The  [2.x.125]  must return 6   components in this example, with the first 3 corresponding to  [2.x.126]    and the second 3 corresponding to  [2.x.127] . Vectors are implicitly   assumed to have exactly  [2.x.128]  components that are ordered in   the same way as we usually order the coordinate directions, i.e.  [2.x.129] -,    [2.x.130] -, and finally  [2.x.131] -component.     The parameter  [2.x.132]  corresponds to the number  [2.x.133]    boundary_id of the face.  [2.x.134]  is an illegal   value, since it is reserved for interior faces.     The last argument is denoted to compute the normal vector  [2.x.135]  at   the boundary points.      
*  [2.x.136]       [2.x.137]     [2.x.138]  "Glossary entry on boundary indicators"  
* [0.x.20]*
   hp-namespace version of project_boundary_values_curl_conforming_l2   (above).    
*  [2.x.139]   
* [0.x.21]*
   Compute constraints that correspond to boundary conditions of the form    [2.x.140] , i.e. the normal components of the   solution  [2.x.141]  and a given  [2.x.142]  shall coincide. The function  [2.x.143]  is given by    [2.x.144]  and the resulting constraints are added to  [2.x.145]    constraints for faces with boundary indicator  [2.x.146]      This function is explicitly written to use with the FE_RaviartThomas   elements. Thus it throws an exception, if it is called with other finite   elements.     If the AffineConstraints object  [2.x.147]  contained values or other   constraints before, the new ones are added or the old ones overwritten,   if a node of the boundary part to be used was already in the list of   constraints. This is handled by using inhomogeneous constraints. Please   note that when combining adaptive meshes and this kind of constraints,   the Dirichlet conditions should be set first, and then completed by   hanging node constraints, in order to make sure that the discretization   remains consistent. See the discussion on conflicting constraints in the   module on    [2.x.148] .     The argument  [2.x.149]  denotes the first vector component   in the finite element that corresponds to the vector function  [2.x.150]    that you want to constrain. Vectors are implicitly assumed to have   exactly  [2.x.151]  components that are ordered in the same way as   we usually order the coordinate directions, i.e.,  [2.x.152] -,  [2.x.153] -, and finally    [2.x.154] -component.     The parameter  [2.x.155]  corresponds to the  [2.x.156]  of   the faces where the boundary conditions are applied.    [2.x.157]  is an illegal value, since it is   reserved for interior faces. The  [2.x.158]  is used to compute the normal   vector  [2.x.159]  at the boundary points.     [1.x.7]     To compute the constraints we use interpolation operator proposed in   Brezzi, Fortin (Mixed and Hybrid Finite Element Methods, Springer, 1991)   on every face located at the boundary.    
*  [2.x.160]       [2.x.161]     [2.x.162]  "Glossary entry on boundary indicators"  
* [0.x.22]*
   Same as above for the hp-namespace.    
*  [2.x.163]       [2.x.164]     [2.x.165]  "Glossary entry on boundary indicators"  
* [0.x.23]

include/deal.II-translator/numerics/vector_tools_common_0.txt
[0.x.0]*
   Denote which norm/integral is to be computed by the   integrate_difference() function on each cell and compute_global_error()   for the whole domain.   Let  [2.x.0]  be a finite element function   with  [2.x.1]  components where component  [2.x.2]  is denoted by  [2.x.3]  and  [2.x.4]    be the reference function (the  [2.x.5]  and  [2.x.6]    arguments to integrate_difference()). Let  [2.x.7]    be the difference or error between the two. Further,   let   [2.x.8]  be the  [2.x.9]  function of integrate_difference(), which is   assumed to be equal to one if not supplied. Finally, let  [2.x.10]  be the    [2.x.11]  argument (for  [2.x.12] -norms).     In the following,we denote by  [2.x.13]  the local error computed by   integrate_difference() on cell  [2.x.14] , whereas  [2.x.15]  is the global error   computed by compute_global_error(). Note that integrals are   approximated by quadrature in the usual way:   [1.x.0]   Similarly for suprema over a cell  [2.x.16] :   [1.x.1]  
* [0.x.1]*
     The function or difference of functions is integrated on each cell  [2.x.17] :     [1.x.2]     and summed up to get     [1.x.3]     or, for  [2.x.18] :     [1.x.4]         Note: This differs from what is typically known as     the mean of a function by a factor of  [2.x.19] . To     compute the mean you can also use compute_mean_value(). Finally,     pay attention to the sign: if  [2.x.20] , this will compute the     negative of the mean of  [2.x.21] .    
* [0.x.2]*
     The absolute value of the function is integrated:     [1.x.5]     and     [1.x.6]     or, for  [2.x.22] :     [1.x.7]    
* [0.x.3]*
     The square of the function is integrated and the square root of the     result is computed on each cell:     [1.x.8]     and     [1.x.9]     or, for  [2.x.23] :     [1.x.10]    
* [0.x.4]*
     The absolute value to the  [2.x.24] -th power is integrated and the  [2.x.25] -th     root is computed on each cell. The exponent  [2.x.26]  is the  [2.x.27]      exponent argument of integrate_difference() and compute_mean_value():     [1.x.11]     and     [1.x.12]     or, for  [2.x.28] :     [1.x.13]    
* [0.x.5]*
     The maximum absolute value of the function:     [1.x.14]     and     [1.x.15]     or, for  [2.x.29] :     [1.x.16]    
* [0.x.6]*
     #L2_norm of the gradient:     [1.x.17]     and     [1.x.18]     or, for  [2.x.30] :     [1.x.19]    
* [0.x.7]*
     #L2_norm of the divergence of a vector field. The function  [2.x.31]  is     expected to have  [2.x.32]  components and the first  [2.x.33]      will be used to compute the divergence:     [1.x.20]     and     [1.x.21]     or, for  [2.x.34] :     [1.x.22]    
* [0.x.8]*
     The square of this norm is the square of the #L2_norm plus the square     of the #H1_seminorm:     [1.x.23]     and     [1.x.24]     or, for  [2.x.35] :     [1.x.25]    
* [0.x.9]*
     #Lp_norm of the gradient:     [1.x.26]     and     [1.x.27]     or, for  [2.x.36] :     [1.x.28]    
* [0.x.10]*
     The same as the #H1_norm but using [1.x.29]:     [1.x.30]     and     [1.x.31]     or, for  [2.x.37] :     [1.x.32]    
* [0.x.11]*
     #Linfty_norm of the gradient:     [1.x.33]     and     [1.x.34]     or, for  [2.x.38] :     [1.x.35]    
* [0.x.12]*
     The sum of #Linfty_norm and #W1infty_seminorm:     [1.x.36]     The global norm is not implemented in compute_global_error(),     because it is impossible to compute the sum of the global     norms from the values  [2.x.39] . As a work-around, you can compute the     global #Linfty_norm and #W1infty_seminorm separately and then add them     to get (with  [2.x.40] ):     [1.x.37]    
* [0.x.13]*
   Exception  
* [0.x.14]*
       Return the Correct pattern for NormType.      
* [0.x.15]*
       Convert a NormType to a string.      
* [0.x.16]*
       Convert a string to a NormType.      
* [0.x.17]

include/deal.II-translator/numerics/vector_tools_constraints.templates_0.txt
[0.x.0]*
     A structure that stores the dim DoF indices that correspond to a     vector-valued quantity at a single support point.    
* [0.x.1]*
     Add the constraint  [2.x.0]  to the list of     constraints.         Here,  [2.x.1]  is represented by the set of given DoF indices, and      [2.x.2]  by the vector specified as the second argument.         The function does not add constraints if a degree of freedom is already     constrained in the constraints object.    
* [0.x.2]*
     Add the constraint  [2.x.3]  to the list of     constraints. In 2d, this is a single constraint, in 3d these are two     constraints.         Here,  [2.x.4]  is represented by the set of given DoF indices, and      [2.x.5]  by the vector specified as the second argument.         The function does not add constraints if a degree of freedom is already     constrained in the constraints object.    
* [0.x.3]*
     Given a vector, compute a set of dim-1 vectors that are orthogonal to     the first one and mutually orthonormal as well.    
* [0.x.4]

include/deal.II-translator/numerics/vector_tools_constraints_0.txt
[0.x.0]*
    [2.x.0]  Interpolation and projection  
* [0.x.1]*
   This function computes the constraints that correspond to boundary   conditions of the form  [2.x.1] ,   i.e., normal flux constraints where  [2.x.2]  is a vector-valued solution   variable and  [2.x.3]  is a prescribed vector field whose normal   component we want to be equal to the normal component of the solution.   These conditions have exactly the form handled by the   AffineConstraints class, in that they relate a [1.x.0] of boundary degrees of freedom to a corresponding   value (the inhomogeneity of the constraint). Consequently, the current   function creates a list of constraints that are written into an   AffineConstraints container. This object may already have some   content, for example from hanging node constraints, that remains   untouched. These constraints have to be applied to the linear system   like any other such constraints, i.e., you have to condense the linear   system with the constraints before solving, and you have to distribute   the solution vector afterwards.     This function treats a more general case than    [2.x.4]  (which can only handle   the case where  [2.x.5] , and is used in    [2.x.6]  and  [2.x.7] ). However, because everything that would apply   to that function also applies as a special case to the current   function, the following discussion is relevant to both.    
*  [2.x.8]  This function doesn't make much sense in 1d, so it throws an     exception if  [2.x.9]  equals one.       [1.x.1]     The second argument of this function denotes the first vector component   in the finite element that corresponds to the vector function that you   want to constrain. For example, if we were solving a Stokes equation in   2d and the finite element had components  [2.x.10] , then  [2.x.11]    first_vector_component needs to be zero if you intend to constraint   the vector  [2.x.12] .   On the other hand, if we solved the   Maxwell equations in 3d and the finite element has components    [2.x.13]  and we want the boundary condition  [2.x.14] , then  [2.x.15]    would be 3. Vectors are implicitly assumed to have exactly    [2.x.16]  components that are ordered in the same way as we   usually order the coordinate directions, i.e.  [2.x.17] -,  [2.x.18] -, and finally    [2.x.19] -component. The function assumes, but can't check, that the vector   components in the range    [2.x.20]  come   from the same base finite element. For example, in the Stokes example   above, it would not make sense to use a    [2.x.21]    (note that the first velocity vector component is a  [2.x.22]  element,   whereas all the other ones are  [2.x.23]  elements) as there would be points   on the boundary where the  [2.x.24] -velocity is defined but no corresponding    [2.x.25] - or  [2.x.26] -velocities.     The third argument denotes the set of boundary indicators on which the   boundary condition is to be enforced. Note that, as explained below, this   is one of the few functions where it makes a difference where we call the   function multiple times with only one boundary indicator, or whether we   call the function once with the whole set of boundary indicators at once.     Argument four ( [2.x.27]  describes the boundary function  [2.x.28]  for each boundary id. The function  [2.x.29]    is used on boundary with id  [2.x.30]  taken from the set  [2.x.31]    Each function in  [2.x.32]  is expected to have  [2.x.33]    components, which are used independent of  [2.x.34]      The mapping argument is used to compute the boundary points at which the   function needs to request the normal vector  [2.x.35]  from the boundary   description.    
*  [2.x.36]  When combining adaptively refined meshes with hanging node   constraints and boundary conditions like from the current function within   one AffineConstraints object, the hanging node constraints should always   be set first, and then the boundary conditions since boundary conditions   are not set in the second operation on degrees of freedom that are   already constrained. This makes sure that the discretization remains   conforming as is needed. See the discussion on conflicting constraints in   the module on    [2.x.37] .       [1.x.2]     Computing these constraints requires some smarts. The main question   revolves around the question what the normal vector is. Consider the   following situation:      [2.x.38]      Here, we have two cells that use a bilinear mapping (i.e.,   MappingQGeneric(1)). Consequently, for each of the cells, the normal   vector is perpendicular to the straight edge. If the two edges at the top   and right are meant to approximate a curved boundary (as indicated by the   dashed line), then neither of the two computed normal vectors are equal   to the exact normal vector (though they approximate it as the mesh is   refined further). What is worse, if we constrain  [2.x.39]  at the common vertex with the normal vector   from both cells, then we constrain the vector  [2.x.40]  with respect to   two linearly independent vectors; consequently, the constraint would be    [2.x.41]  at this point (i.e. [1.x.3] components of the   vector), which is not what we wanted.     To deal with this situation, the algorithm works in the following way: at   each point where we want to constrain  [2.x.42] , we first collect all   normal vectors that adjacent cells might compute at this point. We then   do not constrain  [2.x.43]  for   [1.x.4] of these normal vectors but only for the [1.x.5] of   the normal vectors. In the example above, we therefore record only a   single constraint  [2.x.44] , where  [2.x.45]  is the average of the two indicated   normal vectors.     Unfortunately, this is not quite enough. Consider the situation here:      [2.x.46]      If again the top and right edges approximate a curved boundary, and the   left boundary a separate boundary (for example straight) so that the   exact boundary has indeed a corner at the top left vertex, then the above   construction would not work: here, we indeed want the constraint that    [2.x.47]  at this point (because the normal velocities with respect to   both the left normal as well as the top normal vector should be zero),   not that the velocity in the direction of the average normal vector is   zero.     Consequently, we use the following heuristic to determine whether all   normal vectors computed at one point are to be averaged: if two normal   vectors for the same point are computed on [1.x.6] cells, then   they are to be averaged. This covers the first example above. If they are   computed from the same cell, then the fact that they are different is   considered indication that they come from different parts of the boundary   that might be joined by a real corner, and must not be averaged.     There is one problem with this scheme. If, for example, the same domain   we have considered above, is discretized with the following mesh, then we   get into trouble:      [2.x.48]      Here, the algorithm assumes that the boundary does not have a corner at   the point where faces  [2.x.49]  and  [2.x.50]  join because at that point there are   two different normal vectors computed from different cells. If you intend   for there to be a corner of the exact boundary at this point, the only   way to deal with this is to assign the two parts of the boundary   different boundary indicators and call this function twice, once for each   boundary indicators; doing so will yield only one normal vector at this   point per invocation (because we consider only one boundary part at a   time), with the result that the normal vectors will not be averaged. This   situation also needs to be taken into account when using this function   around reentrant corners on Cartesian meshes. If normal-flux boundary   conditions are to be enforced on non-Cartesian meshes around reentrant   corners, one may even get cycles in the constraints as one will in   general constrain different components from the two sides. In that case,   set a no-slip constraint on the reentrant vertex first.       [1.x.7]     The situation is more complicated in 3d. Consider the following case   where we want to compute the constraints at the marked vertex:      [2.x.51]      Here, we get four different normal vectors, one from each of the four   faces that meet at the vertex. Even though they may form a complete set   of vectors, it is not our intent to constrain all components of the   vector field at this point. Rather, we would like to still allow   tangential flow, where the term "tangential" has to be suitably defined.     In a case like this, the algorithm proceeds as follows: for each cell   that has computed two tangential vectors at this point, we compute the   unconstrained direction as the outer product of the two tangential   vectors (if necessary multiplied by minus one). We then average these   tangential vectors. Finally, we compute constraints for the two   directions perpendicular to this averaged tangential direction.     There are cases where one cell contributes two tangential directions and   another one only one; for example, this would happen if both top and   front faces of the left cell belong to the boundary selected whereas only   the top face of the right cell belongs to it, maybe indicating that the   entire front part of the domain is a smooth manifold whereas the top   really forms two separate manifolds that meet in a ridge, and that   normal-flux boundary conditions are only desired on the front manifold   and the right one on top. In cases like these, it's difficult to define   what should happen. The current implementation simply ignores the one   contribution from the cell that only contributes one normal vector. In   the example shown, this is acceptable because the normal vector for the   front face of the left cell is the same as the normal vector provided by   the front face of the right cell (the surface is planar) but it would be   a problem if the front manifold would be curved. Regardless, it is   unclear how one would proceed in this case and ignoring the single cell   is likely the best one can do.       [1.x.8]     Because it makes for good pictures, here are two images of vector fields   on a circle and on a sphere to which the constraints computed by this   function have been applied (for illustration purposes, we enforce zero   normal flux, which can more easily be computed using    [2.x.52]  as this must   lead to a [1.x.9] vector field):      [2.x.53]      The vectors fields are not physically reasonable but the tangentiality   constraint is clearly enforced. The fact that the vector fields are zero   at some points on the boundary is an artifact of the way it is created,   it is not constrained to be zero at these points.    
*  [2.x.54]       [2.x.55]     [2.x.56]  "Glossary entry on boundary indicators"  
* [0.x.2]*
   This function does the same as the   compute_nonzero_normal_flux_constraints() function (see there for more   information), but for the simpler case of homogeneous normal-flux   constraints, i.e., for imposing the condition    [2.x.57] . This function is used in  [2.x.58]  and  [2.x.59] .    
*  [2.x.60]       [2.x.61]     [2.x.62]  "Glossary entry on boundary indicators"  
* [0.x.3]*
   Compute the constraints that correspond to boundary conditions of the   form  [2.x.63] , i.e., tangential   flow constraints where  [2.x.64]  is a vector-valued solution   variable and  [2.x.65]  is prescribed vector field whose tangential   component(s) we want to be equal to the tangential component(s) of the   solution. This function constrains exactly those dim-1 vector-valued   components that are left unconstrained by    [2.x.66]  and leaves the one   component unconstrained that is constrained by that function.    
*  [2.x.67]       [2.x.68]     [2.x.69]  "Glossary entry on boundary indicators"  
* [0.x.4]*
   Same as above for homogeneous tangential-flux constraints.    
*  [2.x.70]       [2.x.71]     [2.x.72]  "Glossary entry on boundary indicators"  
* [0.x.5]

include/deal.II-translator/numerics/vector_tools_evaluate_0.txt
[0.x.0]*
   Namespace for the flags for point_values() and point_gradients().  
* [0.x.1]*
     Flags for point_values() and point_gradients().    
* [0.x.2]*
       Compute average.      
* [0.x.3]*
       Compute maximum.            
*  [2.x.0]  Only available for scalar values.      
* [0.x.4]*
       Compute minimum.            
*  [2.x.1]  Only available for scalar values.      
* [0.x.5]*
       Take any value.      
* [0.x.6]*
   Given a (distributed) solution vector  [2.x.2]  evaluate the values at   the (arbitrary and even remote) points specified by  [2.x.3]       [2.x.4]  This is a collective call that needs to be executed by all     processors in the communicator.  
* [0.x.7]*
   Given a (distributed) solution vector  [2.x.5]  evaluate the values at   the points specified by  [2.x.6]  which might have been set up by the   above function.    
*  [2.x.7]  Refinement/coarsening/repartitioning leads to the invalidation of the     cache so that the above function has to be called again.      [2.x.8]  This is a collective call that needs to be executed by all     processors in the communicator.  
* [0.x.8]*
   Given a (distributed) solution vector  [2.x.9]  evaluate the gradients at   the (arbitrary and even remote) points specified by  [2.x.10]   
* [0.x.9]*
   Given a (distributed) solution vector  [2.x.11]  evaluate the gradients at   the points specified by  [2.x.12]  which might have been set up by the   above function.    
*  [2.x.13]  Refinement/coarsening/repartitioning leads to the invalidation of the     cache so that the above function has to be called again.  
* [0.x.10]*
     Perform reduction for scalars.    
* [0.x.11]*
     Perform reduction for tensors.    
* [0.x.12]

include/deal.II-translator/numerics/vector_tools_integrate_difference.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/vector_tools_integrate_difference_0.txt
[0.x.0]*
    [2.x.0]  Evaluation of functions and errors  
* [0.x.1]*
   Compute the cellwise error of the finite element solution.  Integrate the   difference between a reference function which is given as a continuous   function object, and a finite element function. The result of this   function is the vector  [2.x.1]  that contains one value per active   cell  [2.x.2]  of the triangulation. Each of the values of this vector  [2.x.3]    equals  
* [1.x.0]
*    where  [2.x.4]  denotes the norm chosen and  [2.x.5]  represents the exact solution.     It is assumed that the number of components of the function  [2.x.6]    exact_solution matches that of the finite element used by  [2.x.7]      To compute a global error norm of a finite element solution, use    [2.x.8]  with the output vector computed with   this function.      [2.x.9]  mapping The mapping that is used when integrating the   difference  [2.x.10] .    [2.x.11]  dof The DoFHandler object that describes the finite element   space in which the solution vector lives.    [2.x.12]  fe_function A vector with nodal values representing the   numerical approximation  [2.x.13] . This vector needs to correspond to the   finite element space represented by  [2.x.14]     [2.x.15]  exact_solution The exact solution that is used to compute the   error.    [2.x.16]  difference The vector of values  [2.x.17]  computed as above.    [2.x.18]  q The quadrature formula used to approximate the integral   shown above. Note that some quadrature formulas are more useful than   other in integrating  [2.x.19] . For example, it is known that the  [2.x.20]    approximation  [2.x.21]  to the exact solution  [2.x.22]  of a Laplace equation is   particularly accurate (in fact, superconvergent, i.e. accurate to higher   order) at the 4 Gauss points of a cell in 2d (or 8 points in 3d) that   correspond to a QGauss(2) object. Consequently, because a QGauss(2)   formula only evaluates the two solutions at these particular points,   choosing this quadrature formula may indicate an error far smaller than   it actually is.    [2.x.23]  norm The norm  [2.x.24]  shown above that should be computed. If the   norm is  [2.x.25]  then the finite element on which this   function is called needs to have at least dim vector components, and the   divergence will be computed on the first div components. This works, for   example, on the finite elements used for the mixed Laplace ( [2.x.26] ) and   the Stokes equations ( [2.x.27] ).    [2.x.28]  weight The additional argument  [2.x.29]  allows to evaluate   weighted norms.  The weight function may be scalar, establishing a   spatially variable weight in the domain for all components equally. This   may be used, for instance, to only integrate over parts of the domain.   The weight function may also be vector-valued, with as many components as   the finite element: Then, different components get different weights. A   typical application is when the error with respect to only one or a   subset of the solution variables is to be computed, in which case the   other components would have weight values equal to zero. The   ComponentSelectFunction class is particularly useful for this purpose as   it provides such a "mask" weight. The weight function is expected to be   positive, but negative values are not filtered. The default value of this   function, a null pointer, is interpreted as "no weighting function",   i.e., weight=1 in the whole domain for all vector components uniformly.    [2.x.30]  exponent This value denotes the  [2.x.31]  used in computing    [2.x.32] -norms and  [2.x.33] -norms. The value is ignored if a  [2.x.34]  other   than  [2.x.35]   [2.x.36]  or  [2.x.37]    is chosen.       See the general documentation of this namespace for more information.    
*  [2.x.38]  If the integration here happens over the cells of a    [2.x.39]  object, then this function computes   the vector elements  [2.x.40]  for an output vector with as many cells as   there are active cells of the triangulation object of the current   processor. However, not all active cells are in fact locally owned: some   may be ghost or artificial cells (see    [2.x.41]  "here"   and    [2.x.42]  "here").   The vector computed will, in the case of a distributed triangulation,   contain zeros for cells that are not locally owned. As a consequence, in   order to compute the [1.x.1]  [2.x.43]  error (for example), the errors   from different processors need to be combined, see    [2.x.44]      Instantiations for this template are provided for some vector types (see   the general documentation of the namespace), but only for InVectors as in   the documentation of the namespace, OutVector only Vector<double> and   Vector<float>.  
* [0.x.2]*
   Call the integrate_difference() function, see above, with   <tt>mapping=MappingQGeneric [2.x.45]   
* [0.x.3]*
   Same as above for hp.  
* [0.x.4]*
   Call the integrate_difference() function, see above, with   <tt>mapping=MappingQGeneric [2.x.46]   
* [0.x.5]*
   Take a Vector  [2.x.47]  of errors on each cell with   <tt>tria.n_active_cells()</tt> entries and return the global   error as given by  [2.x.48]      The  [2.x.49]  vector is typically an output produced by    [2.x.50]  and you normally want to supply the   same value for  [2.x.51]  as you used in  [2.x.52]      If the given Triangulation is a  [2.x.53]  entries   in  [2.x.54]  that do not correspond to locally owned cells are   assumed to be 0.0 and a parallel reduction using MPI is done to compute   the global error.      [2.x.55]  tria The Triangulation with active cells corresponding with the   entries in  [2.x.56]     [2.x.57]  cellwise_error Vector of errors on each active cell.    [2.x.58]  norm The type of norm to compute.    [2.x.59]  exponent The exponent  [2.x.60]  to use for  [2.x.61] -norms and    [2.x.62] -norms. The value is ignored if a  [2.x.63]  other   than  [2.x.64]   [2.x.65]  or  [2.x.66]    is chosen.    
*  [2.x.67]  Instantiated for type Vector<double> and Vector<float>.  
* [0.x.6]

include/deal.II-translator/numerics/vector_tools_interpolate.templates_0.txt
[0.x.0]*
     Return whether the cell and all of its descendants are locally owned.    
* [0.x.1]

include/deal.II-translator/numerics/vector_tools_interpolate_0.txt
[0.x.0]*
    [2.x.0]  Interpolation and projection  
* [0.x.1]*
   Compute the interpolation of  [2.x.1]  at the support points to the   finite element space described by the Triangulation and FiniteElement   object with which the given DoFHandler argument is initialized. It is   assumed that the number of components of  [2.x.2]  matches that of the   finite element used by  [2.x.3]      Note that you may have to call <tt>hanging_nodes.distribute(vec)</tt>   with the hanging nodes from space  [2.x.4]  afterwards, to make the result   continuous again.     See the general documentation of this namespace for further information.  
* [0.x.2]*
   Same as above but in an hp-context.  
* [0.x.3]*
   Call the  [2.x.5]  function above with   <tt>mapping=MappingQGeneric [2.x.6]   
* [0.x.4]*
   Interpolate different finite element spaces. The interpolation of vector    [2.x.7]  (which is assumed to be ghosted, see    [2.x.8] )   is executed from the FE space represented by  [2.x.9]    to the vector  [2.x.10]  on FE space  [2.x.11]    The interpolation on each cell is represented by the matrix  [2.x.12]    Curved boundaries are neglected so far.     Note that you may have to call <tt>hanging_nodes.distribute(data_2)</tt>   with the hanging nodes from space  [2.x.13]  afterwards, to make the result   continuous again.    
*  [2.x.14]  Instantiations for this template are provided for some vector types   (see the general documentation of the namespace), but only the same   vector for InVector and OutVector. Other combinations must be   instantiated by hand.  
* [0.x.5]*
   This function is a kind of generalization or modification of the very   first interpolate() function in the series. It interpolates a set of   functions onto the finite element space defined by the DoFHandler argument,   where the determination which function to use on each cell is made   based on the material id (see    [2.x.15] )   of each cell.      [2.x.16]  mapping        The mapping to use to determine the location of     support points at which the functions are to be evaluated.    [2.x.17]  dof_handler    DoFHandler initialized with Triangulation and     FiniteElement objects and that defines the finite element space.    [2.x.18]  function_map   A  [2.x.19]  reflecting the correspondence between     material ids on those cells on which something should be interpolated,     and the functions to be interpolated onto the finite element space.    [2.x.20]  dst           The global finie element vector holding the     output of the interpolated values.    [2.x.21]  component_mask A mask of components that shall be interpolated.    
*  [2.x.22]  If the algorithm encounters a cell whose material id is not listed   in the given  [2.x.23]  then  [2.x.24]  will not be updated in the   respective degrees of freedom of the output vector. For example, if    [2.x.25]  was initialized to zero, then those zeros which correspond to   the missed material ids will still remain in  [2.x.26]  after calling   this function.    
*  [2.x.27]  Degrees of freedom located on faces between cells of different   material ids will get their value by that cell which was called last in   the respective loop over cells implemented in this function. Since the   order of cells is somewhat arbitrary, you cannot control it. However, if   you want to have control over the order in which cells are visited, let us   take a   look at the following example: Let  [2.x.28]  be a variable of interest which   is approximated by some CG finite element. Let  [2.x.29]   [2.x.30]  and  [2.x.31]  be   material ids of cells on the triangulation. Let 0: 0.0, 1: 1.0, 2: 2.0 be   the whole  [2.x.32]  that you want to pass to this function, where    [2.x.33]  is a material id and  [2.x.34]  is a value of  [2.x.35]  By using the   whole  [2.x.36]  you do not really know which values will be   assigned to the face DoFs. On the other hand, if you split the whole  [2.x.37]    function_map into three smaller independent objects 0: 0.0 and 1: 1.0 and   2: 2.0 and make three distinct calls of this function passing each of   these objects separately (the order depends on what you want to get   between cells), then each subsequent call will rewrite the intercell  [2.x.38]    dofs of the previous one.  
* [0.x.6]*
   Compute the interpolation of a  [2.x.39]   [2.x.40]  to a  [2.x.41]     [2.x.42]  where  [2.x.43]  and  [2.x.44]  represent different triangulations with   a common coarse grid.     dof1 and dof2 need to have the same finite element discretization.     Note that for continuous elements on grids with hanging nodes (i.e.   locally refined grids) this function does not give the expected output.   Indeed, the resulting output vector does not necessarily respect   continuity requirements at hanging nodes, due to local cellwise   interpolation.     For this case (continuous elements on grids with hanging nodes), please   use the interpolate_to_different_mesh function with an additional   AffineConstraints argument, see below, or make the field conforming   yourself by calling the  [2.x.45]  function of your   hanging node constraints object.    
*  [2.x.46]  This function works with  [2.x.47]  but   only if the parallel partitioning is the same for both meshes (see the    [2.x.48]    flag).  
* [0.x.7]*
   Compute the interpolation of a  [2.x.49]   [2.x.50]  to a  [2.x.51]     [2.x.52]  where  [2.x.53]  and  [2.x.54]  represent different triangulations with   a common coarse grid.     dof1 and dof2 need to have the same finite element discretization.      [2.x.55]  is a hanging node constraints object corresponding to  [2.x.56]    dof2. This object is particularly important when interpolating onto   continuous elements on grids with hanging nodes (locally refined grids):   Without it
* 
*  - due to cellwise interpolation
* 
*  - the resulting output vector   does not necessarily respect continuity requirements at hanging nodes.  
* [0.x.8]*
   The same function as above, but takes an InterGridMap object directly as   a parameter. Useful for interpolating several vectors at the same time.      [2.x.57]  has to be initialized via  [2.x.58]    pointing from a source DoFHandler to a destination DoFHandler.  
* [0.x.9]*
   Geometrical interpolation  
* [0.x.10]*
   Given a DoFHandler containing at least a spacedim vector field, this   function interpolates the Triangulation at the support points of a FE_Q()   finite element of the same degree as the degree of the required   components.     Curved manifold are respected, and the resulting VectorType will be   geometrically consistent. The resulting map is guaranteed to be   interpolatory at the support points of a FE_Q() finite element of the   same degree as the degree of the required components.     If the underlying finite element is an FE_Q(1)^spacedim, then the   resulting  [2.x.59]  is a finite element field representation of the   vertices of the Triangulation.     The optional ComponentMask argument can be used to specify what   components of the FiniteElement to use to describe the   geometry. If no mask is specified at construction time, then a   default-constructed mask is used, which is then interpreted as   saying that the first `spacedim` components of the FiniteElement   are assumed to represent the geometry of the problem.     This function is only implemented for FiniteElements where the specified   components are primitive.  
* [0.x.11]*
   Like the above function but also taking  [2.x.60]  as argument.   This will introduce an additional approximation between the true geometry   specified by the manifold if the degree of the mapping is lower than the   degree of the finite element in the DoFHandler  [2.x.61]  but more   importantly it allows to fill location vectors for mappings that do not   preserve vertex locations (like Eulerian mappings).  
* [0.x.12]

include/deal.II-translator/numerics/vector_tools_mean_value.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/vector_tools_mean_value_0.txt
[0.x.0]*
   Mean value operations  
* [0.x.1]*
   Subtract the (algebraic) mean value from a vector.     This function is most frequently used as a mean-value filter for Stokes:   The pressure in Stokes' equations with only Dirichlet boundaries for the   velocities is only determined up to a constant. This function allows to   subtract the mean value of the pressure. It is usually called in a   preconditioner and generates updates with mean value zero. The mean value   is computed as the mean value of the degrees of freedom values as given   by the input vector; they are not weighted by the area of cells, i.e. the   mean is computed as  [2.x.0] , rather than as  [2.x.1] . The latter can be obtained from the    [2.x.2]  however.     Apart from the vector  [2.x.3]  to operate on, this function takes a boolean   mask  [2.x.4]  that has a true entry for every element of the vector   for which the mean value shall be computed and later subtracted. The   argument is used to denote which components of the solution vector   correspond to the pressure, and avoid touching all other components of   the vector, such as the velocity components. (Note, however, that the   mask is not a    [2.x.5]    operating on the vector components of the finite element the solution   vector  [2.x.6]  may be associated with; rather, it is a mask on the entire   vector, without reference to what the vector elements mean.)     The boolean mask  [2.x.7]  has an empty vector as default value, which   will be interpreted as selecting all vector elements, hence, subtracting   the algebraic mean value on the whole vector. This allows to call this   function without a boolean mask if the whole vector should be processed.    
*  [2.x.8]  In the context of using this function to filter out the kernel of   an operator (such as the null space of the Stokes operator that consists   of the constant pressures), this function only makes sense for finite   elements for which the null space indeed consists of the vector    [2.x.9] . This is the case for example for the usual Lagrange   elements where the sum of all shape functions equals the function that is   constant one. However, it is not true for some other functions: for   example, for the FE_DGP element (another valid choice for the pressure in   Stokes discretizations), the first shape function on each cell is   constant while further elements are  [2.x.10]  orthogonal to it (on the   reference cell); consequently, the sum of all shape functions is not   equal to one, and the vector that is associated with the constant mode is   not equal to  [2.x.11] . For such elements, a different procedure   has to be used when subtracting the mean value.      [2.x.12]  This function can only be used for distributed vector classes   provided the boolean mask is empty, i.e. selecting the whole vector.  
* [0.x.2]*
   Compute the mean value of one component of the solution.     This function integrates the chosen component over the whole domain and   returns the result, i.e. it computes  [2.x.13]  where  [2.x.14]  is the vector component and  [2.x.15]  is the   function representation of the nodal vector given as fourth argument. The   integral is evaluated numerically using the quadrature formula given as   third argument.     This function is used in the "Possibilities for extensions" part of the   results section of    [2.x.16]  " [2.x.17] ".    
*  [2.x.18]  The function is most often used when solving a problem whose   solution is only defined up to a constant, for example a pure Neumann   problem or the pressure in a Stokes or Navier-Stokes problem. In both   cases, subtracting the mean value as computed by the current function,   from the nodal vector does not generally yield the desired result of a   finite element function with mean value zero. In fact, it only works for   Lagrangian elements. For all other elements, you will need to compute the   mean value and subtract it right inside the evaluation routine.  
* [0.x.3]*
   Call the other compute_mean_value() function, see above, with   <tt>mapping=MappingQGeneric [2.x.19]   
* [0.x.4]

include/deal.II-translator/numerics/vector_tools_point_gradient.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/vector_tools_point_gradient_0.txt
[0.x.0]*
    [2.x.0]  Evaluation of functions and errors  
* [0.x.1]*
   Evaluate a possibly vector-valued finite element function defined by the   given DoFHandler and nodal vector at the given point, and return the   (vector) gradient of this function through the last argument.     This is a wrapper function using a Q1-mapping for cell boundaries to call   the other point_gradient() function.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.0]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.1] at the same point, you may   want to look at the  [2.x.1]    function.    
*  [2.x.2]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.3]  is thrown.    
*  [2.x.4]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.2]*
   Same as above for hp.    
*  [2.x.5]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.6]  is thrown.    
*  [2.x.7]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.3]*
   Evaluate a scalar finite element function defined by the given DoFHandler   and nodal vector at the given point, and return the gradient of this   function.     Compared with the other function of the same name, this is a wrapper   function using a Q1-mapping for cells.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.2]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.3] at the same point, you may   want to look at the  [2.x.8]    function.    
*  [2.x.9]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.10]  is thrown.    
*  [2.x.11]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.4]*
   Same as above for hp.    
*  [2.x.12]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.13]  is thrown.    
*  [2.x.14]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.5]*
   Evaluate a possibly vector-valued finite element function defined by the   given DoFHandler and nodal vector at the given point, and return the   gradients of this function through the last argument.     Compared with the other function of the same name, this function uses an   arbitrary mapping for evaluation.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.4]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.5] at the same point, you may   want to look at the  [2.x.15]    function.    
*  [2.x.16]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.17]  is thrown.    
*  [2.x.18]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.6]*
   Same as above for hp.    
*  [2.x.19]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.20]  is thrown.    
*  [2.x.21]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.7]*
   Evaluate a scalar finite element function defined by the given DoFHandler   and nodal vector at the given point, and return the gradient of this   function.     Compared with the other function of the same name, this function uses an   arbitrary mapping for evaluation.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.6]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.7] at the same point, you may   want to look at the  [2.x.22]    function.    
*  [2.x.23]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.24]  is thrown.    
*  [2.x.25]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.8]*
   Same as above for hp.    
*  [2.x.26]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.27]  is thrown.    
*  [2.x.28]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the gradient of the finite element field either     here or there, depending on which cell the point is found in. Since     the gradient is, for most elements, discontinuous from one cell or     the other, you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.9]

include/deal.II-translator/numerics/vector_tools_point_value.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/vector_tools_point_value_0.txt
[0.x.0]*
    [2.x.0]  Assembling of right hand sides  
* [0.x.1]*
   Create a right hand side vector for a point source at point  [2.x.1]  In   other words, it creates a vector  [2.x.2]  so that  [2.x.3]  where  [2.x.4]  are the shape functions   described by  [2.x.5]  and  [2.x.6]  is the point at which the delta   function is located. Prior content of the given  [2.x.7]    vector is deleted. This function is for the case of a scalar finite   element.     This function is typically used in one of these two contexts:
* 

* 
* 

* 
* 

* 
* 
*  - Let's say you want to solve the same kind of problems many times     over, with different values for right hand sides or coefficients,     and then evaluate the solution at the same point every time. You     could do this by calling  [2.x.8]  after each     solve, or you could realize that to evaluate the solution  [2.x.9]      at a point  [2.x.10] , you could rearrange operations like this:    
* [1.x.0]
*      with the vector as defined above. In other words, point evaluation     can be achieved with just a single vector-vector product, and the     vector  [2.x.11]  can be computed once and for all and reused     for each solve, without having to go through the mesh every time     to find out which cell (and where in the cell) the point  [2.x.12]  is     located.
* 

* 
* 

* 
* 

* 
* 
*  - This function is also useful if you wanted to compute the Green's     function for the problem you are solving. This is because the     Green's function  [2.x.13]  is defined by    
* [1.x.1]
*      where  [2.x.14]  is the differential operator of your problem. The discrete     version then requires computing the right hand side vector      [2.x.15] , which is exactly     the vector computed by the current function.     While maybe not relevant for documenting [1.x.2] this   function does, it may be interesting to note that delta functions   do not exist in reality, and consequently, using this function   does not model any real situation. This is, because no real   object is able to focus an infinite force density at an   infinitesimally small part of the domain (rather, all real   devices will spread out the force over a finite area); nor is it   possible to measure values at individual points (but all   measurements will somehow be averaged over small areas). Only if   this area is so small that it cannot be resolved by any mesh does   it make sense to model the situation in a way that uses a delta   function with the same overall force or sensitivity. On the other   hand, a situation that is probably more fruitfully simulated with   a delta function is the electric potential of a point source; in   this case, the solution is known to have a logarithmic   singularity (in 2d) or a  [2.x.16]  singularity (in 3d),   neither of which is bounded.     Mathematically, the use of delta functions typically leads to exact   solutions to which the numerically obtained, approximate solution does   not converge. This is because, taking the Laplace equation as an example,   the error between exact and numerical solution can be bounded by the   expression  
* [1.x.3]
*    but when using a delta function on the right hand side, the term    [2.x.17]  is not finite. This can be seen   by using the a-priori bound for solutions of the Laplace equation    [2.x.18]  that states that  [2.x.19] .   When using a delta function as right hand side,  [2.x.20] ,   one would need to take the  [2.x.21]  norm of a delta function, which   however is not finite because  [2.x.22] .     The consequence of all of this is that the exact solution of the   Laplace equation with a delta function on the right hand side
* 
*  -    i.e., the [1.x.4]
* 
*  -  has a singularity at  [2.x.23]  that   is so strong that it cannot be resolved by a finite element   solution, and consequently finite element approximations do not   converge towards the exact solution in any of the usual norms.     All of this is also the case for all of the other usual second-order   partial differential equations in dimensions two or higher. (Because   in dimension two and higher,  [2.x.24]  functions are not necessarily   continuous, and consequently the delta function is not in the dual   space  [2.x.25] .)  
* [0.x.2]*
   Like the previous function, but for hp-objects.  
* [0.x.3]*
   Call the create_point_source_vector() function, see above, with   an implied default  [2.x.26]  mapping object.     Note that if your DoFHandler uses any active FE index other than zero, then   you need to call the function above that provides a mapping object for each   active FE index.  
* [0.x.4]*
   Create a right hand side vector for a point source at point  [2.x.27]  This   variation of the function is meant for vector-valued problems with   exactly dim components (it will also work for problems with more than dim   components, and in this case simply consider only the first dim   components of the shape functions). It computes a right hand side that   corresponds to a forcing function that is equal to a delta function times   a given direction. In other words, it creates a vector  [2.x.28]  so that  [2.x.29] . Note here that    [2.x.30]  is a vector-valued function.  [2.x.31]  is the given direction   of the source term  [2.x.32]  and corresponds to the  [2.x.33]    direction argument to be passed to this function.     Prior content of the given  [2.x.34]  vector is deleted.     See the discussion of the first create_point_source_vector() variant for   more on the use of delta functions.  
* [0.x.5]*
   Like the previous function, but for hp-objects.  
* [0.x.6]*
   Call the create_point_source_vector() function for vector-valued finite   elements, see above, with an implied default  [2.x.35]  mapping object.     Note that if your DoFHandler uses any active FE index other than zero, then   you need to call the function above that provides a mapping object for each   active FE index.  
* [0.x.7]*
    [2.x.36]  Evaluation of functions and errors  
* [0.x.8]*
   Point error evaluation. Find the first cell containing the given point   and compute the difference of a (possibly vector-valued) finite element   function and a continuous function (with as many vector components as the   finite element) at this point.     This is a wrapper function using a Q1-mapping for cell boundaries to call   the other point_difference() function.    
*  [2.x.37]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.38]  is thrown.  
* [0.x.9]*
   Point error evaluation. Find the first cell containing the given point   and compute the difference of a (possibly vector-valued) finite element   function and a continuous function (with as many vector components as the   finite element) at this point.     Compared with the other function of the same name, this function uses an   arbitrary mapping to evaluate the difference.    
*  [2.x.39]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.40]  is thrown.  
* [0.x.10]*
   Evaluate a possibly vector-valued finite element function defined by the   given DoFHandler and nodal vector  [2.x.41]  at the given point  [2.x.42]    point, and return the (vector) value of this function through the last   argument.     This function uses a  [2.x.43] -mapping for the cell the point is evaluated   in. If you need to evaluate using a different mapping (for example when   using curved boundaries), use the point_difference() function that takes   a mapping.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.5]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.6] at the same point, you may   want to look at the  [2.x.44]    function.    
*  [2.x.45]  If the cell in which the point is found is not locally owned, an     exception of type  [2.x.46]  is thrown.    
*  [2.x.47]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.7] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.11]*
   Same as above for hp.    
*  [2.x.48]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.49]  is thrown.    
*  [2.x.50]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.8] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.12]*
   Evaluate a scalar finite element function defined by the given DoFHandler   and nodal vector  [2.x.51]  at the given point  [2.x.52]  and return   the value of this function.     This function uses a Q1-mapping for the cell the point is evaluated   in. If you need to evaluate using a different mapping (for example when   using curved boundaries), use the point_difference() function that takes   a mapping.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.9]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.10] at the same point, you may   want to look at the  [2.x.53]    function.     This function is used in the "Possibilities for extensions" part of the   results section of    [2.x.54]  " [2.x.55] ".    
*  [2.x.56]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.57]  is thrown.    
*  [2.x.58]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.11] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.13]*
   Same as above for hp.    
*  [2.x.59]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.60]  is thrown.    
*  [2.x.61]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.12] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.14]*
   Evaluate a possibly vector-valued finite element function defined by the   given DoFHandler and nodal vector  [2.x.62]  at the given point  [2.x.63]    point, and return the (vector) value of this function through the last   argument.     Compared with the other function of the same name, this function uses an   arbitrary mapping to evaluate the point value.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.13]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.14] at the same point, you may   want to look at the  [2.x.64]    function.    
*  [2.x.65]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.66]  is thrown.    
*  [2.x.67]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.15] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.15]*
   Same as above for hp.    
*  [2.x.68]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.69]  is thrown.    
*  [2.x.70]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.16] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.16]*
   Evaluate a scalar finite element function defined by the given DoFHandler   and nodal vector  [2.x.71]  at the given point  [2.x.72]  and return   the value of this function.     Compared with the other function of the same name, this function uses an   arbitrary mapping to evaluate the difference.     This function is not particularly cheap. This is because it first   needs to find which cell a given point is in, then find the point   on the reference cell that matches the given evaluation point,   and then evaluate the shape functions there. You probably do not   want to use this function to evaluate the solution at [1.x.17]   points. For this kind of application, the FEFieldFunction class   offers at least some optimizations. On the other hand, if you   want to evaluate [1.x.18] at the same point, you may   want to look at the  [2.x.73]    function.    
*  [2.x.74]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.75]  is thrown.    
*  [2.x.76]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.19] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.17]*
   Same as above for hp.    
*  [2.x.77]  If the cell in which the point is found is not locally owned, an   exception of type  [2.x.78]  is thrown.    
*  [2.x.79]  This function needs to find the cell within which a point lies,     and this can only be done up to a certain numerical tolerance of course.     Consequently, for points that are on, or close to, the boundary of     a cell, you may get the value of the finite element field either     here or there, depending on which cell the point is found in. This     does not matter (to within the same tolerance) if the finite element     field is continuous. On the other hand, if the finite element in use     is [1.x.20] continuous, then you will get unpredictable values for     points on or close to the boundary of the cell, as one would expect     when trying to evaluate point values of discontinuous functions.  
* [0.x.18]

include/deal.II-translator/numerics/vector_tools_project.templates_0.txt
[0.x.0]*
     Interpolate zero boundary values. We don't need to worry about a     mapping here because the function we evaluate for the DoFs is zero in     the mapped locations as well as in the original, unmapped locations    
* [0.x.1]*
     Compute the boundary values to be used in the project() functions.    
* [0.x.2]     MatrixFree implementation of project() for an arbitrary number of     components of the FiniteElement.    
* [0.x.3]*
     Helper interface for the matrix-free implementation of project(): avoid     instantiating the other helper functions for more than one VectorType     by copying from a  [2.x.0]     
* [0.x.4]*
     Return whether the boundary values try to constrain a degree of freedom     that is already constrained to something else    
* [0.x.5]*
     Generic implementation of the project() function    
* [0.x.6]*
     Specialization of project() for the case dim==spacedim.     Check if we can use the MatrixFree implementation or need     to use the matrix based one.    
* [0.x.7]

include/deal.II-translator/numerics/vector_tools_project_0.txt
[0.x.0]*
    [2.x.0]  Interpolation and projection  
* [0.x.1]*
   Compute the projection of  [2.x.1]  to the finite element space. In other   words, given a function  [2.x.2] , the current function computes a   finite element function  [2.x.3]    characterized by the (output) vector of nodal values  [2.x.4]  that satisfies   the equation  
* [1.x.0]
*    for all test functions  [2.x.5] . This requires solving a linear system   involving the mass matrix since the equation above is equivalent to   the linear system  
* [1.x.1]
*    which can also be written as  [2.x.6]  with    [2.x.7]  and    [2.x.8] .     By default, no boundary values for  [2.x.9]  are needed nor   imposed, but there are optional parameters to this function that allow   imposing either zero boundary values or, in a first step, to project   the boundary values of  [2.x.10]  onto the finite element space on the boundary   of the mesh in a similar way to above, and then using these values as the   imposed boundary values for  [2.x.11] . The ordering of arguments to this   function is such that you need not give a second quadrature formula (of   type `Quadrature<dim-1>` and used for the computation of the matrix and   right hand side for the projection of boundary values) if you   don't want to project to the boundary first, but that you must if you want   to do so.     A MatrixFree implementation is used if the following conditions are met:
* 

* 
* 

* 
* 

* 
* 
*  -  [2.x.12]  is false,
* 

* 
* 

* 
* 

* 
* 
*  -  [2.x.13]  is false,
* 

* 
* 

* 
* 

* 
* 
*  - the FiniteElement is supported by the MatrixFree class,
* 

* 
* 

* 
* 

* 
* 
*  - the FiniteElement has less than five components
* 

* 
* 

* 
* 

* 
* 
*  - the degree of the FiniteElement is less than nine.
* 

* 
* 

* 
* 

* 
* 
*  - dim==spacedim     In this case, this function performs numerical quadrature using the given   quadrature formula for integration of the right hand side  [2.x.14]  while a   QGauss(fe_degree+2) object is used for the mass operator. You should   therefore make sure that the given quadrature formula is sufficiently   accurate for creating the right-hand side.     Otherwise, only serial Triangulations are supported and the mass matrix   is assembled using  [2.x.15]  The given   quadrature rule is then used for both the matrix and the right-hand side.   You should therefore make sure that the given quadrature formula is also   sufficient for creating the mass matrix. In particular, the degree of the   quadrature formula must be sufficiently high to ensure that the mass   matrix is invertible. For example, if you are using a FE_Q(k) element,   then the integrand of the matrix entries  [2.x.16]  is of polynomial   degree  [2.x.17]  in each variable, and you need a Gauss quadrature formula   with  [2.x.18]  points in each coordinate direction to ensure that  [2.x.19]    is invertible.     See the general documentation of this namespace for further information.     In 1d, the default value of the boundary quadrature formula is an invalid   object since integration on the boundary doesn't happen in 1d.      [2.x.20]  mapping The mapping object to use.    [2.x.21]  dof The DoFHandler the describes the finite element space to   project into and that corresponds to  [2.x.22]     [2.x.23]  constraints Constraints to be used when assembling the mass   matrix, typically needed when you have hanging nodes.    [2.x.24]  quadrature The quadrature formula to be used for assembling the   mass matrix.    [2.x.25]  function The function to project into the finite element space.    [2.x.26]  vec The output vector where the projected function will be   stored in. This vector is required to be already initialized and must not   have ghost elements.    [2.x.27]  enforce_zero_boundary If true,  [2.x.28]  will have zero boundary   conditions.    [2.x.29]  q_boundary Quadrature rule to be used if  [2.x.30]    is true.    [2.x.31]  project_to_boundary_first If true, perform a projection on the   boundary before projecting the interior of the function.  
* [0.x.2]*
   Call the project() function above, with   <tt>mapping=MappingQGeneric [2.x.32]   
* [0.x.3]*
   Same as above, but with hp-capabilities.  
* [0.x.4]*
   Call the project() function above, with a collection of  [2.x.33]  mapping   objects, i.e., with  [2.x.34]   
* [0.x.5]*
   The same as above for projection of scalar-valued quadrature data.   The user provided function should return a value at the quadrature point   based on the cell iterator and quadrature number and of course should be   consistent with the provided  [2.x.35]  object, which will be used   to assemble the right-hand-side.     This function can be used with lambdas:  
* [1.x.2]
*    where  [2.x.36]  is a CellDataStorage object, which stores   quadrature point data.  
* [0.x.6]*
   The same as above for projection of scalar-valued MatrixFree quadrature   data.   The user provided function  [2.x.37]  should return a VectorizedArray value   at the quadrature point based on the cell number and quadrature number and   should be consistent with the  [2.x.38]      This function can be used with lambdas:  
* [1.x.3]
*    where  [2.x.39]  is a an object of type Table<2,   VectorizedArray<double> >, which stores quadrature point data.      [2.x.40]  allow to additionally specify which component of  [2.x.41]    to use in case it was constructed with an  [2.x.42]    DoFHandler<dim>*></code>. It will be used internally in constructor of   FEEvaluation object.  
* [0.x.7]*
   Same as above but for <code>n_q_points_1d =   matrix_free.get_dof_handler().get_fe().degree+1</code>.  
* [0.x.8]

include/deal.II-translator/numerics/vector_tools_rhs.templates_0.txt
[0.x.0]

include/deal.II-translator/numerics/vector_tools_rhs_0.txt
[0.x.0]*
    [2.x.0]  Assembling of right hand sides  
* [0.x.1]*
   Create a right hand side vector. Prior content of the given  [2.x.1]    vector is deleted.     See the general documentation of this namespace for further information.  
* [0.x.2]*
   Call the create_right_hand_side() function, see above, with   <tt>mapping=MappingQGeneric [2.x.2]   
* [0.x.3]*
   Like the previous set of functions, but for hp-objects.  
* [0.x.4]*
   Like the previous set of functions, but for hp-objects.  
* [0.x.5]*
   Create a right hand side vector from boundary forces. Prior content of   the given  [2.x.3]  vector is deleted.     See the general documentation of this namespace for further information.      [2.x.4]     [2.x.5]  "Glossary entry on boundary indicators"  
* [0.x.6]*
   Call the create_boundary_right_hand_side() function, see above, with   <tt>mapping=MappingQGeneric [2.x.6]       [2.x.7]     [2.x.8]  "Glossary entry on boundary indicators"  
* [0.x.7]*
   Same as the set of functions above, but for hp-objects.      [2.x.9]     [2.x.10]  "Glossary entry on boundary indicators"  
* [0.x.8]*
   Call the create_boundary_right_hand_side() function, see above, with a   single Q1 mapping as collection. This function therefore will only work   if the only active FE index in use is zero.      [2.x.11]     [2.x.12]  "Glossary entry on boundary indicators"  
* [0.x.9]

