<!-- HTML header for doxygen 1.8.17-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="canonical" href="https://www.dealii.org/current/doxygen/deal.II/classUtilities_1_1MPI_1_1Partitioner.html" />
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>The deal.II Library: Utilities::MPI::Partitioner Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link rel="SHORTCUT ICON" href="deal.ico"></link>
<script type="text/javascript" src="custom.js"></script>
<meta name="author" content="The deal.II Authors <authors@dealii.org>"></meta>
<meta name="copyright" content="Copyright (C) 1998 - 2021 by the deal.II authors"></meta>
<meta name="deal.II-version" content="10.0.0-pre"></meta>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo200.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">Reference documentation for deal.II version 10.0.0-pre</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!--Extra macros for MathJax:-->
<div style="display:none">
\(\newcommand{\dealvcentcolon}{\mathrel{\mathop{:}}}\)
\(\newcommand{\dealcoloneq}{\dealvcentcolon\mathrel{\mkern-1.2mu}=}\)
\(\newcommand{\jump}[1]{\left[\!\left[ #1 \right]\!\right]}\)
\(\newcommand{\average}[1]{\left\{\!\left\{ #1 \right\}\!\right\}}\)
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceUtilities.html">Utilities</a></li><li class="navelem"><a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a></li><li class="navelem"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="classUtilities_1_1MPI_1_1Partitioner-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Utilities::MPI::Partitioner Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="base_2partitioner_8h_source.html">deal.II/base/partitioner.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for Utilities::MPI::Partitioner:</div>
<div class="dyncontent">
<div class="center"><!-- SVG 0 -->
</div>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ad9658977e422b669a966673692d8cd7e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad9658977e422b669a966673692d8cd7e">Partitioner</a> ()</td></tr>
<tr class="separator:ad9658977e422b669a966673692d8cd7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a809df85f8965a4cf27ec7e171d250043"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a809df85f8965a4cf27ec7e171d250043">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a>)</td></tr>
<tr class="separator:a809df85f8965a4cf27ec7e171d250043"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26d6f941603139d1701cc85d82e7ce99"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a26d6f941603139d1701cc85d82e7ce99">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a40d257bdf99e2ce1edceaaab997a6dcb">local_size</a>, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> ghost_size, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a00c7935cfbc45bf05e54b804302d20af">communicator</a>)</td></tr>
<tr class="separator:a26d6f941603139d1701cc85d82e7ce99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e1d676591853dc94e1466c577e1f7ee"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a1e1d676591853dc94e1466c577e1f7ee">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;ghost_indices_in, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;communicator_in)</td></tr>
<tr class="separator:a1e1d676591853dc94e1466c577e1f7ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a556204a8a9aa00b96f283b7330846322"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a556204a8a9aa00b96f283b7330846322">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;communicator_in)</td></tr>
<tr class="separator:a556204a8a9aa00b96f283b7330846322"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a895bdd6d93c5bf296c53b39dc3b2248d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a895bdd6d93c5bf296c53b39dc3b2248d">reinit</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;vector_space_vector_index_set, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;read_write_vector_index_set, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a00c7935cfbc45bf05e54b804302d20af">communicator</a>) override</td></tr>
<tr class="separator:a895bdd6d93c5bf296c53b39dc3b2248d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a209816de3a347481b172efc7b2afa11e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a209816de3a347481b172efc7b2afa11e">set_owned_indices</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices)</td></tr>
<tr class="separator:a209816de3a347481b172efc7b2afa11e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa05cff1b3f359e104d4d533e0d245f0f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices</a>, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;larger_ghost_index_set=<a class="el" href="classIndexSet.html">IndexSet</a>())</td></tr>
<tr class="separator:aa05cff1b3f359e104d4d533e0d245f0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3b457f661fec81683f5893a252ee8f3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ad3b457f661fec81683f5893a252ee8f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40d257bdf99e2ce1edceaaab997a6dcb"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a40d257bdf99e2ce1edceaaab997a6dcb">local_size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a40d257bdf99e2ce1edceaaab997a6dcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b4a475abc0b200583fd897a0869b7af"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a8b4a475abc0b200583fd897a0869b7af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8b23309278c2d8994b4d42bae05c4aa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad8b23309278c2d8994b4d42bae05c4aa">locally_owned_range</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ad8b23309278c2d8994b4d42bae05c4aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5b55ec94360152e50fa10ad39fadf0d"><td class="memItemLeft" align="right" valign="top">std::pair&lt; <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af5b55ec94360152e50fa10ad39fadf0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a158e25d33cc3477b873b4281b7bc222a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a158e25d33cc3477b873b4281b7bc222a">in_local_range</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a158e25d33cc3477b873b4281b7bc222a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11316c010d3d51912cdfe1939651ad72"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a11316c010d3d51912cdfe1939651ad72">global_to_local</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a11316c010d3d51912cdfe1939651ad72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bef6ce5fdcdc556e35d2f9afd9a3e64"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8bef6ce5fdcdc556e35d2f9afd9a3e64">local_to_global</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> local_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a8bef6ce5fdcdc556e35d2f9afd9a3e64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5d416287d1d4286044e45cdf8f2dc34"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ae5d416287d1d4286044e45cdf8f2dc34">is_ghost_entry</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ae5d416287d1d4286044e45cdf8f2dc34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff4396480641e9e88a8bef38a54b7f32"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aff4396480641e9e88a8bef38a54b7f32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32ffda295e9a5b81ae40359c592a31d9"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a32ffda295e9a5b81ae40359c592a31d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50ad28f00d8ed112756a3b34c5f4a02c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a50ad28f00d8ed112756a3b34c5f4a02c">ghost_indices_within_larger_ghost_set</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a50ad28f00d8ed112756a3b34c5f4a02c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0712b38533b13a65285a2d73bb43ce4c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a0712b38533b13a65285a2d73bb43ce4c">ghost_targets</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a0712b38533b13a65285a2d73bb43ce4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30aa27640e582dd380694c6904c53796"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a30aa27640e582dd380694c6904c53796">import_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a30aa27640e582dd380694c6904c53796"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf1656017a302e6e2a3ad84625ac63d8"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:abf1656017a302e6e2a3ad84625ac63d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af669a7aadb35f85a4e2edc21e50da374"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af669a7aadb35f85a4e2edc21e50da374">import_targets</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af669a7aadb35f85a4e2edc21e50da374"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec126befa3eaa12723033cf3a2c44373"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;<a class="el" href="data__out__dof__data__0_8txt.html#a5ac6413decc3bcd12e49889ff104da8a">part</a>) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aec126befa3eaa12723033cf3a2c44373"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c331ade4bbd7571a3741fd2747d1f1d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a1c331ade4bbd7571a3741fd2747d1f1d">is_globally_compatible</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;<a class="el" href="data__out__dof__data__0_8txt.html#a5ac6413decc3bcd12e49889ff104da8a">part</a>) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a1c331ade4bbd7571a3741fd2747d1f1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a528645b3631f18c7f84304a85511a54b"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a528645b3631f18c7f84304a85511a54b">this_mpi_process</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a528645b3631f18c7f84304a85511a54b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74d37fa18c73e1277afb996827080a4e"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a74d37fa18c73e1277afb996827080a4e">n_mpi_processes</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a74d37fa18c73e1277afb996827080a4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdd62432c1d0bdec701b79528dab3ef9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#acdd62432c1d0bdec701b79528dab3ef9">get_mpi_communicator</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> override</td></tr>
<tr class="separator:acdd62432c1d0bdec701b79528dab3ef9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af353fd142ec460dce6e2b3ddf29b1697"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af353fd142ec460dce6e2b3ddf29b1697">ghost_indices_initialized</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af353fd142ec460dce6e2b3ddf29b1697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5138501f56f373ab880ecfb2a8ed876b"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:a5138501f56f373ab880ecfb2a8ed876b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> communication_channel, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;locally_owned_array, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a5138501f56f373ab880ecfb2a8ed876b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> vector_operation, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> communication_channel, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a699b46b2256bcb38119b5faac1b242cd"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:a699b46b2256bcb38119b5faac1b242cd"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> vector_operation, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;locally_owned_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a699b46b2256bcb38119b5faac1b242cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f154243f694679910f605359a739fa1"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a0f154243f694679910f605359a739fa1">memory_consumption</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a0f154243f694679910f605359a739fa1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9658977e422b669a966673692d8cd7e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad9658977e422b669a966673692d8cd7e">Partitioner</a> ()</td></tr>
<tr class="separator:ad9658977e422b669a966673692d8cd7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a809df85f8965a4cf27ec7e171d250043"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a809df85f8965a4cf27ec7e171d250043">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a>)</td></tr>
<tr class="separator:a809df85f8965a4cf27ec7e171d250043"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26d6f941603139d1701cc85d82e7ce99"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a26d6f941603139d1701cc85d82e7ce99">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a40d257bdf99e2ce1edceaaab997a6dcb">local_size</a>, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> ghost_size, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a00c7935cfbc45bf05e54b804302d20af">communicator</a>)</td></tr>
<tr class="separator:a26d6f941603139d1701cc85d82e7ce99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e1d676591853dc94e1466c577e1f7ee"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a1e1d676591853dc94e1466c577e1f7ee">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;ghost_indices_in, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;communicator_in)</td></tr>
<tr class="separator:a1e1d676591853dc94e1466c577e1f7ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a556204a8a9aa00b96f283b7330846322"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a556204a8a9aa00b96f283b7330846322">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;communicator_in)</td></tr>
<tr class="separator:a556204a8a9aa00b96f283b7330846322"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44313c9910bc19d27bfbccde2bf051a2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a44313c9910bc19d27bfbccde2bf051a2">reinit</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;vector_space_vector_index_set, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;read_write_vector_index_set, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a00c7935cfbc45bf05e54b804302d20af">communicator</a>) override</td></tr>
<tr class="separator:a44313c9910bc19d27bfbccde2bf051a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a209816de3a347481b172efc7b2afa11e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a209816de3a347481b172efc7b2afa11e">set_owned_indices</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices)</td></tr>
<tr class="separator:a209816de3a347481b172efc7b2afa11e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa05cff1b3f359e104d4d533e0d245f0f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices</a>, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;larger_ghost_index_set=<a class="el" href="classIndexSet.html">IndexSet</a>())</td></tr>
<tr class="separator:aa05cff1b3f359e104d4d533e0d245f0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3b457f661fec81683f5893a252ee8f3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ad3b457f661fec81683f5893a252ee8f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40d257bdf99e2ce1edceaaab997a6dcb"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a40d257bdf99e2ce1edceaaab997a6dcb">local_size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a40d257bdf99e2ce1edceaaab997a6dcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b4a475abc0b200583fd897a0869b7af"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a8b4a475abc0b200583fd897a0869b7af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8b23309278c2d8994b4d42bae05c4aa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad8b23309278c2d8994b4d42bae05c4aa">locally_owned_range</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ad8b23309278c2d8994b4d42bae05c4aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5b55ec94360152e50fa10ad39fadf0d"><td class="memItemLeft" align="right" valign="top">std::pair&lt; <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af5b55ec94360152e50fa10ad39fadf0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a158e25d33cc3477b873b4281b7bc222a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a158e25d33cc3477b873b4281b7bc222a">in_local_range</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a158e25d33cc3477b873b4281b7bc222a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11316c010d3d51912cdfe1939651ad72"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a11316c010d3d51912cdfe1939651ad72">global_to_local</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a11316c010d3d51912cdfe1939651ad72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bef6ce5fdcdc556e35d2f9afd9a3e64"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8bef6ce5fdcdc556e35d2f9afd9a3e64">local_to_global</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> local_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a8bef6ce5fdcdc556e35d2f9afd9a3e64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5d416287d1d4286044e45cdf8f2dc34"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ae5d416287d1d4286044e45cdf8f2dc34">is_ghost_entry</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ae5d416287d1d4286044e45cdf8f2dc34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff4396480641e9e88a8bef38a54b7f32"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aff4396480641e9e88a8bef38a54b7f32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32ffda295e9a5b81ae40359c592a31d9"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a32ffda295e9a5b81ae40359c592a31d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50ad28f00d8ed112756a3b34c5f4a02c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a50ad28f00d8ed112756a3b34c5f4a02c">ghost_indices_within_larger_ghost_set</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a50ad28f00d8ed112756a3b34c5f4a02c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0712b38533b13a65285a2d73bb43ce4c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a0712b38533b13a65285a2d73bb43ce4c">ghost_targets</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a0712b38533b13a65285a2d73bb43ce4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30aa27640e582dd380694c6904c53796"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a30aa27640e582dd380694c6904c53796">import_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a30aa27640e582dd380694c6904c53796"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf1656017a302e6e2a3ad84625ac63d8"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:abf1656017a302e6e2a3ad84625ac63d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af669a7aadb35f85a4e2edc21e50da374"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af669a7aadb35f85a4e2edc21e50da374">import_targets</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af669a7aadb35f85a4e2edc21e50da374"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec126befa3eaa12723033cf3a2c44373"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;<a class="el" href="data__out__dof__data__0_8txt.html#a5ac6413decc3bcd12e49889ff104da8a">part</a>) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aec126befa3eaa12723033cf3a2c44373"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c331ade4bbd7571a3741fd2747d1f1d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a1c331ade4bbd7571a3741fd2747d1f1d">is_globally_compatible</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;<a class="el" href="data__out__dof__data__0_8txt.html#a5ac6413decc3bcd12e49889ff104da8a">part</a>) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a1c331ade4bbd7571a3741fd2747d1f1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a528645b3631f18c7f84304a85511a54b"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a528645b3631f18c7f84304a85511a54b">this_mpi_process</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a528645b3631f18c7f84304a85511a54b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74d37fa18c73e1277afb996827080a4e"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a74d37fa18c73e1277afb996827080a4e">n_mpi_processes</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a74d37fa18c73e1277afb996827080a4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdd62432c1d0bdec701b79528dab3ef9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#acdd62432c1d0bdec701b79528dab3ef9">get_mpi_communicator</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> override</td></tr>
<tr class="separator:acdd62432c1d0bdec701b79528dab3ef9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af353fd142ec460dce6e2b3ddf29b1697"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af353fd142ec460dce6e2b3ddf29b1697">ghost_indices_initialized</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af353fd142ec460dce6e2b3ddf29b1697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5138501f56f373ab880ecfb2a8ed876b"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:a5138501f56f373ab880ecfb2a8ed876b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> communication_channel, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;locally_owned_array, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a5138501f56f373ab880ecfb2a8ed876b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> vector_operation, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> communication_channel, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a699b46b2256bcb38119b5faac1b242cd"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:a699b46b2256bcb38119b5faac1b242cd"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> vector_operation, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;locally_owned_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a699b46b2256bcb38119b5faac1b242cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f154243f694679910f605359a739fa1"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a0f154243f694679910f605359a739fa1">memory_consumption</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a0f154243f694679910f605359a739fa1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77df9bf9b64a44fbb6ad03b0c8f17515"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a77df9bf9b64a44fbb6ad03b0c8f17515">DeclException2</a> (<a class="el" href="group__Exceptions.html#gaf6b2aa39da7267d2daceec0d03af4b79">ExcIndexNotPresent</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>,&lt;&lt; &quot;Global <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> &quot;&lt;&lt; arg1&lt;&lt; &quot; neither <a class="el" href="vector__tools__point__gradient__0_8txt.html#aef5058968290d0a16ef792424d0e1ba2">owned</a> <a class="el" href="chunk__sparsity__pattern__0_8txt.html#a31362234916f6aac38d1392e801099d6">nor</a> ghost <a class="el" href="data__postprocessor__0_8txt.html#a232fd208d0a301873073f51d8474883a">on</a> proc &quot;&lt;&lt; arg2&lt;&lt; &quot;.&quot;)</td></tr>
<tr class="separator:a77df9bf9b64a44fbb6ad03b0c8f17515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56ebf907bcd8ef8506a7ded78ed9db70"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a56ebf907bcd8ef8506a7ded78ed9db70">DeclException3</a> (<a class="el" href="group__Exceptions.html#ga293b358739542847d88c8cd447f9adc7">ExcGhostIndexArrayHasWrongSize</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>,&lt;&lt; &quot;The <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> ghost <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> <a class="el" href="matrix__free_2dof__info__0_8txt.html#a597165203ae66b8aa2d96f3bd238b626">array</a> (&quot;&lt;&lt; arg1&lt;&lt; &quot;) must <a class="el" href="grid_2manifold__0_8txt.html#a9dc1c289073d97c27ef2fd7d201521c5">either</a> equal <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> <a class="el" href="generators__0_8txt.html#a52d07c1744d923546e9cafc255f70465">number</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> ghost <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> &quot;&lt;&lt; &quot;<a class="el" href="base_2partitioner__0_8txt.html#a936b2264a337bdb80dd12b8f90f72767">partitioner</a> (&quot;&lt;&lt; arg2&lt;&lt; &quot;) or <a class="el" href="tria__iterator__0_8txt.html#ae2c744f7850c09a43eafeafedf8e2619">be</a> equal <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="error__estimator__0_8txt.html#a4ec80ded5cb4f47bcabf0a970c68075b">to</a> <a class="el" href="vector__tools__constraints__0_8txt.html#a5bb8955c98135fbb60012ceeee4b7839">a</a> <a class="el" href="petsc__matrix__base__0_8txt.html#a91d0bc46add3efe5a167829805522d28">more</a> comprehensive <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a>&quot;&lt;&lt; &quot;<a class="el" href="histogram__0_8txt.html#a1f28b62a413a3352bc54e62ef004750e">set</a> <a class="el" href="function__restriction__0_8txt.html#a79f2798b238440d7e1841d2cf4711885">which</a> contains &quot;&lt;&lt; arg3&lt;&lt; &quot; elements <a class="el" href="chunk__sparse__matrix__0_8txt.html#aae7ed603ea40c1e6a20bb18bab713802">for</a> <a class="el" href="data__postprocessor__0_8txt.html#a600bd43d5bd41af065e85ec3e40fed92">this</a> partitioner.&quot;)</td></tr>
<tr class="separator:a56ebf907bcd8ef8506a7ded78ed9db70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9658977e422b669a966673692d8cd7e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad9658977e422b669a966673692d8cd7e">Partitioner</a> ()</td></tr>
<tr class="separator:ad9658977e422b669a966673692d8cd7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a809df85f8965a4cf27ec7e171d250043"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a809df85f8965a4cf27ec7e171d250043">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a>)</td></tr>
<tr class="separator:a809df85f8965a4cf27ec7e171d250043"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26d6f941603139d1701cc85d82e7ce99"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a26d6f941603139d1701cc85d82e7ce99">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a40d257bdf99e2ce1edceaaab997a6dcb">local_size</a>, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> ghost_size, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a00c7935cfbc45bf05e54b804302d20af">communicator</a>)</td></tr>
<tr class="separator:a26d6f941603139d1701cc85d82e7ce99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e1d676591853dc94e1466c577e1f7ee"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a1e1d676591853dc94e1466c577e1f7ee">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;ghost_indices_in, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;communicator_in)</td></tr>
<tr class="separator:a1e1d676591853dc94e1466c577e1f7ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a556204a8a9aa00b96f283b7330846322"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a556204a8a9aa00b96f283b7330846322">Partitioner</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;communicator_in)</td></tr>
<tr class="separator:a556204a8a9aa00b96f283b7330846322"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44313c9910bc19d27bfbccde2bf051a2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a44313c9910bc19d27bfbccde2bf051a2">reinit</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;vector_space_vector_index_set, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;read_write_vector_index_set, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a00c7935cfbc45bf05e54b804302d20af">communicator</a>) override</td></tr>
<tr class="separator:a44313c9910bc19d27bfbccde2bf051a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a209816de3a347481b172efc7b2afa11e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a209816de3a347481b172efc7b2afa11e">set_owned_indices</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;locally_owned_indices)</td></tr>
<tr class="separator:a209816de3a347481b172efc7b2afa11e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa05cff1b3f359e104d4d533e0d245f0f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices</a>, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;larger_ghost_index_set=<a class="el" href="classIndexSet.html">IndexSet</a>())</td></tr>
<tr class="separator:aa05cff1b3f359e104d4d533e0d245f0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3b457f661fec81683f5893a252ee8f3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ad3b457f661fec81683f5893a252ee8f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40d257bdf99e2ce1edceaaab997a6dcb"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a40d257bdf99e2ce1edceaaab997a6dcb">local_size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a40d257bdf99e2ce1edceaaab997a6dcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b4a475abc0b200583fd897a0869b7af"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a8b4a475abc0b200583fd897a0869b7af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad8b23309278c2d8994b4d42bae05c4aa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad8b23309278c2d8994b4d42bae05c4aa">locally_owned_range</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ad8b23309278c2d8994b4d42bae05c4aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5b55ec94360152e50fa10ad39fadf0d"><td class="memItemLeft" align="right" valign="top">std::pair&lt; <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af5b55ec94360152e50fa10ad39fadf0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a158e25d33cc3477b873b4281b7bc222a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a158e25d33cc3477b873b4281b7bc222a">in_local_range</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a158e25d33cc3477b873b4281b7bc222a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11316c010d3d51912cdfe1939651ad72"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a11316c010d3d51912cdfe1939651ad72">global_to_local</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a11316c010d3d51912cdfe1939651ad72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bef6ce5fdcdc556e35d2f9afd9a3e64"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8bef6ce5fdcdc556e35d2f9afd9a3e64">local_to_global</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> local_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a8bef6ce5fdcdc556e35d2f9afd9a3e64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5d416287d1d4286044e45cdf8f2dc34"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ae5d416287d1d4286044e45cdf8f2dc34">is_ghost_entry</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> global_index) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ae5d416287d1d4286044e45cdf8f2dc34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff4396480641e9e88a8bef38a54b7f32"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aff4396480641e9e88a8bef38a54b7f32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32ffda295e9a5b81ae40359c592a31d9"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a32ffda295e9a5b81ae40359c592a31d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50ad28f00d8ed112756a3b34c5f4a02c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a50ad28f00d8ed112756a3b34c5f4a02c">ghost_indices_within_larger_ghost_set</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a50ad28f00d8ed112756a3b34c5f4a02c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0712b38533b13a65285a2d73bb43ce4c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a0712b38533b13a65285a2d73bb43ce4c">ghost_targets</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a0712b38533b13a65285a2d73bb43ce4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30aa27640e582dd380694c6904c53796"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a30aa27640e582dd380694c6904c53796">import_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a30aa27640e582dd380694c6904c53796"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf1656017a302e6e2a3ad84625ac63d8"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:abf1656017a302e6e2a3ad84625ac63d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af669a7aadb35f85a4e2edc21e50da374"><td class="memItemLeft" align="right" valign="top"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af669a7aadb35f85a4e2edc21e50da374">import_targets</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af669a7aadb35f85a4e2edc21e50da374"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec126befa3eaa12723033cf3a2c44373"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;<a class="el" href="data__out__dof__data__0_8txt.html#a5ac6413decc3bcd12e49889ff104da8a">part</a>) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aec126befa3eaa12723033cf3a2c44373"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c331ade4bbd7571a3741fd2747d1f1d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a1c331ade4bbd7571a3741fd2747d1f1d">is_globally_compatible</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;<a class="el" href="data__out__dof__data__0_8txt.html#a5ac6413decc3bcd12e49889ff104da8a">part</a>) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a1c331ade4bbd7571a3741fd2747d1f1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a528645b3631f18c7f84304a85511a54b"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a528645b3631f18c7f84304a85511a54b">this_mpi_process</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a528645b3631f18c7f84304a85511a54b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74d37fa18c73e1277afb996827080a4e"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a74d37fa18c73e1277afb996827080a4e">n_mpi_processes</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a74d37fa18c73e1277afb996827080a4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdd62432c1d0bdec701b79528dab3ef9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#acdd62432c1d0bdec701b79528dab3ef9">get_mpi_communicator</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> override</td></tr>
<tr class="separator:acdd62432c1d0bdec701b79528dab3ef9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af353fd142ec460dce6e2b3ddf29b1697"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af353fd142ec460dce6e2b3ddf29b1697">ghost_indices_initialized</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:af353fd142ec460dce6e2b3ddf29b1697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5138501f56f373ab880ecfb2a8ed876b"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:a5138501f56f373ab880ecfb2a8ed876b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> communication_channel, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;locally_owned_array, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a5138501f56f373ab880ecfb2a8ed876b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:ab3d760ded3110fb5e4d60d1202147bf0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> vector_operation, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> communication_channel, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:aca3a9b8e1840bf9539e6335817f1a8fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a699b46b2256bcb38119b5faac1b242cd"><td class="memTemplParams" colspan="2">template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </td></tr>
<tr class="memitem:a699b46b2256bcb38119b5faac1b242cd"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish</a> (<a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> vector_operation, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;temporary_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;locally_owned_storage, <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;ghost_array, <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;requests) <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a699b46b2256bcb38119b5faac1b242cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f154243f694679910f605359a739fa1"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a0f154243f694679910f605359a739fa1">memory_consumption</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a0f154243f694679910f605359a739fa1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77df9bf9b64a44fbb6ad03b0c8f17515"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a77df9bf9b64a44fbb6ad03b0c8f17515">DeclException2</a> (<a class="el" href="group__Exceptions.html#gaf6b2aa39da7267d2daceec0d03af4b79">ExcIndexNotPresent</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>,&lt;&lt; &quot;Global <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> &quot;&lt;&lt; arg1&lt;&lt; &quot; neither <a class="el" href="vector__tools__point__gradient__0_8txt.html#aef5058968290d0a16ef792424d0e1ba2">owned</a> <a class="el" href="chunk__sparsity__pattern__0_8txt.html#a31362234916f6aac38d1392e801099d6">nor</a> ghost <a class="el" href="data__postprocessor__0_8txt.html#a232fd208d0a301873073f51d8474883a">on</a> proc &quot;&lt;&lt; arg2&lt;&lt; &quot;.&quot;)</td></tr>
<tr class="separator:a77df9bf9b64a44fbb6ad03b0c8f17515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56ebf907bcd8ef8506a7ded78ed9db70"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a56ebf907bcd8ef8506a7ded78ed9db70">DeclException3</a> (<a class="el" href="group__Exceptions.html#ga293b358739542847d88c8cd447f9adc7">ExcGhostIndexArrayHasWrongSize</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>,&lt;&lt; &quot;The <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> ghost <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> <a class="el" href="matrix__free_2dof__info__0_8txt.html#a597165203ae66b8aa2d96f3bd238b626">array</a> (&quot;&lt;&lt; arg1&lt;&lt; &quot;) must <a class="el" href="grid_2manifold__0_8txt.html#a9dc1c289073d97c27ef2fd7d201521c5">either</a> equal <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> <a class="el" href="generators__0_8txt.html#a52d07c1744d923546e9cafc255f70465">number</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> ghost <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> &quot;&lt;&lt; &quot;<a class="el" href="base_2partitioner__0_8txt.html#a936b2264a337bdb80dd12b8f90f72767">partitioner</a> (&quot;&lt;&lt; arg2&lt;&lt; &quot;) or <a class="el" href="tria__iterator__0_8txt.html#ae2c744f7850c09a43eafeafedf8e2619">be</a> equal <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="error__estimator__0_8txt.html#a4ec80ded5cb4f47bcabf0a970c68075b">to</a> <a class="el" href="vector__tools__constraints__0_8txt.html#a5bb8955c98135fbb60012ceeee4b7839">a</a> <a class="el" href="petsc__matrix__base__0_8txt.html#a91d0bc46add3efe5a167829805522d28">more</a> comprehensive <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a>&quot;&lt;&lt; &quot;<a class="el" href="histogram__0_8txt.html#a1f28b62a413a3352bc54e62ef004750e">set</a> <a class="el" href="function__restriction__0_8txt.html#a79f2798b238440d7e1841d2cf4711885">which</a> contains &quot;&lt;&lt; arg3&lt;&lt; &quot; elements <a class="el" href="chunk__sparse__matrix__0_8txt.html#aae7ed603ea40c1e6a20bb18bab713802">for</a> <a class="el" href="data__postprocessor__0_8txt.html#a600bd43d5bd41af065e85ec3e40fed92">this</a> partitioner.&quot;)</td></tr>
<tr class="separator:a56ebf907bcd8ef8506a7ded78ed9db70"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:gaf6b2aa39da7267d2daceec0d03af4b79"><td class="memItemLeft" align="right" valign="top"><a class="el" href="sparsity__0_8txt.html#a9e8da5812fd9a4b6f626664964de293c">static</a> ::<a class="el" href="classExceptionBase.html">ExceptionBase</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Exceptions.html#gaf6b2aa39da7267d2daceec0d03af4b79">ExcIndexNotPresent</a> (<a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> arg1, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> arg2)</td></tr>
<tr class="separator:gaf6b2aa39da7267d2daceec0d03af4b79"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga293b358739542847d88c8cd447f9adc7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="sparsity__0_8txt.html#a9e8da5812fd9a4b6f626664964de293c">static</a> ::<a class="el" href="classExceptionBase.html">ExceptionBase</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__Exceptions.html#ga293b358739542847d88c8cd447f9adc7">ExcGhostIndexArrayHasWrongSize</a> (unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> arg1, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> arg2, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> arg3)</td></tr>
<tr class="separator:ga293b358739542847d88c8cd447f9adc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:a7fcae5500056427795b8ed84b5a4c102"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a7fcae5500056427795b8ed84b5a4c102">initialize_import_indices_plain_dev</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a7fcae5500056427795b8ed84b5a4c102"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fcae5500056427795b8ed84b5a4c102"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a7fcae5500056427795b8ed84b5a4c102">initialize_import_indices_plain_dev</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a7fcae5500056427795b8ed84b5a4c102"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fcae5500056427795b8ed84b5a4c102"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a7fcae5500056427795b8ed84b5a4c102">initialize_import_indices_plain_dev</a> () <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a></td></tr>
<tr class="separator:a7fcae5500056427795b8ed84b5a4c102"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a85a845b1a3a1a35329cd57858dd2f2d3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a85a845b1a3a1a35329cd57858dd2f2d3">global_size</a></td></tr>
<tr class="separator:a85a845b1a3a1a35329cd57858dd2f2d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8f254459fe6567b5af38251183195d2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classIndexSet.html">IndexSet</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ae8f254459fe6567b5af38251183195d2">locally_owned_range_data</a></td></tr>
<tr class="separator:ae8f254459fe6567b5af38251183195d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12bdc30aa3e8e4bfb06d44f75e1fd4cb"><td class="memItemLeft" align="right" valign="top">std::pair&lt; <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a12bdc30aa3e8e4bfb06d44f75e1fd4cb">local_range_data</a></td></tr>
<tr class="separator:a12bdc30aa3e8e4bfb06d44f75e1fd4cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2bb56a6841a8bdd7a4cae72c475ccb0c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classIndexSet.html">IndexSet</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a2bb56a6841a8bdd7a4cae72c475ccb0c">ghost_indices_data</a></td></tr>
<tr class="separator:a2bb56a6841a8bdd7a4cae72c475ccb0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a081b8efe1732c2d9d1270a96f09a0649"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a081b8efe1732c2d9d1270a96f09a0649">n_ghost_indices_data</a></td></tr>
<tr class="separator:a081b8efe1732c2d9d1270a96f09a0649"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5057fe3b10bb594c40186eb04867da1f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5057fe3b10bb594c40186eb04867da1f">ghost_targets_data</a></td></tr>
<tr class="separator:a5057fe3b10bb594c40186eb04867da1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae42fc9926ca45956f0f04a63c1a78ef2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ae42fc9926ca45956f0f04a63c1a78ef2">import_indices_data</a></td></tr>
<tr class="separator:ae42fc9926ca45956f0f04a63c1a78ef2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af06ca101e89a75949b170d2a974bc134"><td class="memItemLeft" align="right" valign="top"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; std::unique_ptr&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>[], void(*)(unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> *)&gt;, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af06ca101e89a75949b170d2a974bc134">import_indices_plain_dev</a></td></tr>
<tr class="separator:af06ca101e89a75949b170d2a974bc134"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c703b3ffe07bcd100c18150ba4905f5"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a9c703b3ffe07bcd100c18150ba4905f5">n_import_indices_data</a></td></tr>
<tr class="separator:a9c703b3ffe07bcd100c18150ba4905f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87957a3a9a52461f35e1f0d4e0b408fa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a87957a3a9a52461f35e1f0d4e0b408fa">import_targets_data</a></td></tr>
<tr class="separator:a87957a3a9a52461f35e1f0d4e0b408fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0ee2c8587e16577e3714a38340c1650"><td class="memItemLeft" align="right" valign="top"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa0ee2c8587e16577e3714a38340c1650">import_indices_chunks_by_rank_data</a></td></tr>
<tr class="separator:aa0ee2c8587e16577e3714a38340c1650"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a315cff6dd3f734cacb37d4841c2eafb2"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a315cff6dd3f734cacb37d4841c2eafb2">n_ghost_indices_in_larger_set</a></td></tr>
<tr class="separator:a315cff6dd3f734cacb37d4841c2eafb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc19ad6f939ea9ebb7019f9ed29bf253"><td class="memItemLeft" align="right" valign="top"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#afc19ad6f939ea9ebb7019f9ed29bf253">ghost_indices_subset_chunks_by_rank_data</a></td></tr>
<tr class="separator:afc19ad6f939ea9ebb7019f9ed29bf253"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8abdd13ff6bb523def59c1286c6c2bb9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8abdd13ff6bb523def59c1286c6c2bb9">ghost_indices_subset_data</a></td></tr>
<tr class="separator:a8abdd13ff6bb523def59c1286c6c2bb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44b1f9588ac9b0726e0220c28956ac71"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a44b1f9588ac9b0726e0220c28956ac71">my_pid</a></td></tr>
<tr class="separator:a44b1f9588ac9b0726e0220c28956ac71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5108af9f395f821b0bb6ae2edf827ba7"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5108af9f395f821b0bb6ae2edf827ba7">n_procs</a></td></tr>
<tr class="separator:a5108af9f395f821b0bb6ae2edf827ba7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00c7935cfbc45bf05e54b804302d20af"><td class="memItemLeft" align="right" valign="top">MPI_Comm&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a00c7935cfbc45bf05e54b804302d20af">communicator</a></td></tr>
<tr class="separator:a00c7935cfbc45bf05e54b804302d20af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bd49ebeaff5cb40ec119a6d47152946"><td class="memItemLeft" align="right" valign="top"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a3bd49ebeaff5cb40ec119a6d47152946">have_ghost_indices</a></td></tr>
<tr class="separator:a3bd49ebeaff5cb40ec119a6d47152946"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This class defines a model for the partitioning of a vector (or, in fact, any linear data structure) among processors using <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. The partitioner stores the global vector size and the locally owned range as a half-open interval [ <code>lower</code>, <code>upper</code>) on each process. Furthermore, it includes a structure for the point-to-point communication patterns. It allows the inclusion of ghost indices (i.e. indices that a current processor needs to have access to, but are owned by another process) through an <a class="el" href="classIndexSet.html">IndexSet</a>. In addition, it also stores the other processors' ghost indices belonging to the current processor (see <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af669a7aadb35f85a4e2edc21e50da374">import_targets()</a>), which are the indices where other processors might require information from. In a sense, these import indices form the dual of the ghost indices. This information is gathered once when constructing the partitioner, which obviates subsequent global communication steps when exchanging data. The figure below gives an example of index space \([0,74)\) being split into four parts that are each owned by one <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> process: </p><div class="image">
<img src="partitioner.png" alt=""/>
<div class="caption">
The first row (above the thick black line) shows which process owns which elements. Below it, the next four lines indicate which elements of the overall array each processor wants to know about</div></div>
<ul>
<li>this is generally a superset of the locally owned elements, with the difference being what are called "ghost elements". To understand the remaining pieces of the figure (and this class), remember that in <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>, you can't just ask another process for data. (That's not quite true: There are mechanisms in newer <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> standards for this, but as a general rule it's true.) Rather, if you need information, you need to send another process a message, the other process needs to expect the message and respond as appropriate with a message of its own. In practice, it is therefore easier and faster if each process willalready* know what it will be asked and, at the appropriate time, just send that data. The remaining lines of information set up this kind of scheme. To this end, note that process 0 will want to know about five elements it does not own itself: those with indices 20, 21 (owned by process 1); and 40, 41, 43 (owned by process 2). Similar information can be obtained from the following lines. To satisfy this need for knowledge, it would therefore be quite useful if process 1 stored that, at the appropriate time, it will have to send elements 20, 21 to process 0. Similarly, if you go through lines 2-4 below the thick black line, you will see that process 0 should know that it will need to send elements 1, 2, 13, 18, 19 to process 1; 18, 19 to process 2; and elements 1, 2, 13 to process 3. These are called "import indices" because other processes will want to import them. Instead of storing these indices as a set, it is often useful to use half-open index sets instead, and so the import indices listed above form the following collection of sets: <code>[1,3)</code>, <code>[13,14)</code>, <code>[18,20)</code>, <code>[18,20)</code>, <code>[1,3)</code>, <code>[13,14)</code>. This is how the import indices are shown in the figure above. We now only have to know which of these half-open sets are to be sent to whom. This is done in the line above it where we list the "import targets" (i.e., the target processes for an import operations): Process 1 will receive 5 elements (which are comprised of the first three half-open target index sets), process 2 will receive 2 indices (the fourth half-open interval), and process 3 will receive 3 indices (the remaining two half-open intervals). This information is encoded as the pairs <code>{1,5}</code>, <code>{2,2}</code>, <code>{3,3}</code> as the import targets. Similar considerations can be made for what processes 1, 2, and 3 will have to send out. Finally, when receiving information, it is useful to know how many indices each process will receive from whom since then one can already pre-allocate buffers of the right size. This is listed in the last line under "ghost targets": Process 0 will receive two elements from process 1 (namely those with indices 20, 21), and three from process 2 (namely those with indices 40, 41, 43). This is encoded as pairs <code>{1,2}</code> and <code>{2,3}</code>. Again, similar considerations can be made for what processes 1, 2, and 3 should expect, and what is then shown in their respective columns. The main purpose of this class is to set up these data structures knowing only which process owns which elements, and for which additional ghost elements each process needs knowledge. <h4>Local and global numbering</h4>
</li>
</ul>
<p>The partitioner includes a mechanism for converting global to local and local to global indices. Internally, this class stores vector elements using the convention as follows: The local range is associated with local indices [0, <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a>), and ghost indices are stored consecutively in [<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a>, <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>). The ghost indices are sorted according to their global index. </p><h4>Parallel data exchange</h4>
<p>This class also handles the ghost data exchange for partitioned arrays of objects</p>
<ul>
<li>i.e., if a separate class stores the locally owned elements on each process, then this class facilitates the importation of those elements that are locally needed as ghosts but stored elsewhere. An example of where this class is used is the <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html">LinearAlgebra::distributed::Vector</a> class. The data exchange happens through four functions: <ul>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> is used for initiating an export operation that sends data from the locally owned data field, passed as an array, to the ghost data arrays of other processes (according to the ghost indices stored in the present class). This call starts non-blocking <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> send communication routines, but does not wait for the routines to finish. Thus, the user may not write into the respective positions of the underlying arrays as the data might still be needed by <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </li>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> finalizes the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> data exchange started in <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> and signals that the data in the arrays may be used for further processing or modified as appropriate. </li>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> is used for initiating an import operation that sends data from a ghost data field, passed as an array, to the locally owned array according to the ghost indices stored in the present class. A <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> flag can be passed to decide on how to combine the data in the ghost field with the data at the owner, since both relate to the same data entry. In assembly, this is usually an add-to operation where contributions from all processes to a locally owned element need to be added up. This call starts non-blocking <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication routines, but does not wait for the routines to finish. Thus, the user may not write into the respective positions of the underlying arrays as the data might still be needed by <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </li>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> finalizes the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> data exchange started in <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> and signals that the data in the arrays may be used for further processing or modified as appropriate. </li>
</ul>
The <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication routines are point-to-point communication patterns. <h4>Sending only selected ghost data</h4>
</li>
</ul>
<p>This partitioner class operates on a fixed set of ghost indices and must always be compatible with the ghost indices inside the array whose partitioning it represents. In some cases, one only wants to send around some of the ghost indices present in a vector, but without creating a copy of the vector with a suitable index set</p>
<ul>
<li>think e.g. of local time stepping where different regions of a vector might be exchanged at different stages of a time step slice. This class supports that case by the following model: A vector is first created with the full ghosted index set. Then, a second <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> instance is created that sets ghost indices with a tighter index set as ghosts, but specifying the larger index set as the second argument to the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a> call. When data is exchanged, the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> detect this case and only send the selected indices, taken from the full array of ghost entries.</li>
</ul>
<p>This class defines a model for the partitioning of a vector (or, in fact, any linear data structure) among processors using <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>.</p>
<p>The partitioner stores the global vector size and the locally owned range as a half-open interval [<code>lower</code>, <code>upper</code>) on each process. Furthermore, it includes a structure for the point-to-point communication patterns. It allows the inclusion of ghost indices (i.e. indices that a current processor needs to have access to, but are owned by another process) through an <a class="el" href="classIndexSet.html">IndexSet</a>. In addition, it also stores the other processors' ghost indices belonging to the current processor (see <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af669a7aadb35f85a4e2edc21e50da374">import_targets()</a>), which are the indices where other processors might require information from. In a sense, these import indices form the dual of the ghost indices. This information is gathered once when constructing the partitioner, which obviates subsequent global communication steps when exchanging data.</p>
<p>The figure below gives an example of index space \([0,74)\) being split into four parts that are each owned by one <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> process: </p><div class="image">
<img src="partitioner.png" alt=""/>
</div>
<p> The first row (above the thick black line) shows which process owns which elements. Below it, the next four lines indicate which elements of the overall array each processor wants to know about &ndash; this is generally a superset of the locally owned elements, with the difference being what are called "ghost elements".</p>
<p>To understand the remaining pieces of the figure (and this class), remember that in <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>, you can't just ask another process for data. (That's not quite true: There are mechanisms in newer <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> standards for this, but as a general rule it's true.) Rather, if you need information, you need to send another process a message, the other process needs to expect the message and respond as appropriate with a message of its own. In practice, it is therefore easier and faster if each process will <em>already</em> know what it will be asked and, at the appropriate time, just send that data. The remaining lines of information set up this kind of scheme.</p>
<p>To this end, note that process 0 will want to know about five elements it does not own itself: those with indices 20, 21 (owned by process 1); and 40, 41, 43 (owned by process 2). Similar information can be obtained from the following lines. To satisfy this need for knowledge, it would therefore be quite useful if process 1 stored that, at the appropriate time, it will have to send elements 20, 21 to process 0. Similarly, if you go through lines 2-4 below the thick black line, you will see that process 0 should know that it will need to send elements 1, 2, 13, 18, 19 to process 1; 18, 19 to process 2; and elements 1, 2, 13 to process 3. These are called "import indices" because other processes will want to import them. Instead of storing these indices as a set, it is often useful to use half-open index sets instead, and so the import indices listed above form the following collection of sets: <code>[1,3)</code>, <code>[13,14)</code>, <code>[18,20)</code>, <code>[18,20)</code>, <code>[1,3)</code>, <code>[13,14)</code>. This is how the import indices are shown in the figure above. We now only have to know which of these half-open sets are to be sent to whom. This is done in the line above it where we list the "import targets" (i.e., the target processes for an import operations): Process 1 will receive 5 elements (which are comprised of the first three half-open target index sets), process 2 will receive 2 indices (the fourth half-open interval), and process 3 will receive 3 indices (the remaining two half-open intervals). This information is encoded as the pairs <code>{1,5}</code>, <code>{2,2}</code>, <code>{3,3}</code> as the import targets. Similar considerations can be made for what processes 1, 2, and 3 will have to send out.</p>
<p>Finally, when receiving information, it is useful to know how many indices each process will receive from whom since then one can already pre-allocate buffers of the right size. This is listed in the last line under "ghost targets": Process 0 will receive two elements from process 1 (namely those with indices 20, 21), and three from process 2 (namely those with indices 40, 41, 43). This is encoded as pairs <code>{1,2}</code> and <code>{2,3}</code>. Again, similar considerations can be made for what processes 1, 2, and 3 should expect, and what is then shown in their respective columns.</p>
<p>The main purpose of this class is to set up these data structures knowing only which process owns which elements, and for which additional ghost elements each process needs knowledge.</p>
<h4>Local and global numbering</h4>
<p>The partitioner includes a mechanism for converting global to local and local to global indices. Internally, this class stores vector elements using the convention as follows: The local range is associated with local indices [0, <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a>), and ghost indices are stored consecutively in [<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a>, <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>). The ghost indices are sorted according to their global index.</p>
<h4>Parallel data exchange</h4>
<p>This class also handles the ghost data exchange for partitioned arrays of objects &ndash; i.e., if a separate class stores the locally owned elements on each process, then this class facilitates the importation of those elements that are locally needed as ghosts but stored elsewhere. An example of where this class is used is the <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html">LinearAlgebra::distributed::Vector</a> class.</p>
<p>The data exchange happens through four functions: </p><ul>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> is used for initiating an export operation that sends data from the locally owned data field, passed as an array, to the ghost data arrays of other processes (according to the ghost indices stored in the present class). This call starts non-blocking <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> send communication routines, but does not wait for the routines to finish. Thus, the user may not write into the respective positions of the underlying arrays as the data might still be needed by <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </li>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> finalizes the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> data exchange started in <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> and signals that the data in the arrays may be used for further processing or modified as appropriate. </li>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> is used for initiating an import operation that sends data from a ghost data field, passed as an array, to the locally owned array according to the ghost indices stored in the present class. A <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a> flag can be passed to decide on how to combine the data in the ghost field with the data at the owner, since both relate to the same data entry. In assembly, this is usually an add-to operation where contributions from all processes to a locally owned element need to be added up. This call starts non-blocking <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication routines, but does not wait for the routines to finish. Thus, the user may not write into the respective positions of the underlying arrays as the data might still be needed by <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </li>
<li>
<a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> finalizes the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> data exchange started in <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> and signals that the data in the arrays may be used for further processing or modified as appropriate. </li>
</ul>
<p>The <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication routines are point-to-point communication patterns.</p>
<h4>Sending only selected ghost data</h4>
<p>This partitioner class operates on a fixed set of ghost indices and must always be compatible with the ghost indices inside the array whose partitioning it represents. In some cases, one only wants to send around some of the ghost indices present in a vector, but without creating a copy of the vector with a suitable index set - think e.g. of local time stepping where different regions of a vector might be exchanged at different stages of a time step slice. This class supports that case by the following model: A vector is first created with the full ghosted index set. Then, a second <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> instance is created that sets ghost indices with a tighter index set as ghosts, but specifying the larger index set as the second argument to the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a> call. When data is exchanged, the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> detect this case and only send the selected indices, taken from the full array of ghost entries. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00052">52</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ad9658977e422b669a966673692d8cd7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad9658977e422b669a966673692d8cd7e">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[1/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Default constructor. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00026">26</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a809df85f8965a4cf27ec7e171d250043"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a809df85f8965a4cf27ec7e171d250043">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[2/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>size</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with size argument. Creates an MPI_COMM_SELF structure where there is no real parallel layout. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00041">41</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a26d6f941603139d1701cc85d82e7ce99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a26d6f941603139d1701cc85d82e7ce99">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[3/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>local_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>ghost_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor that takes the number of locally-owned degrees of freedom <code>local_size</code> and the number of ghost degrees of freedom <code>ghost_size</code>. The local index range is translated to global indices in an ascending and one-to-one fashion, i.e., the indices of process \(p\) sit exactly between the indices of the processes \(p-1\) and \(p+1\) , respectively. </p><dl class="section note"><dt>Note</dt><dd>Setting the <code>ghost_size</code> variable to an appropriate value provides memory space for the ghost data in a vector's memory allocation as and allows access to it via local_element(). However, the associated global indices must be handled externally in this case. </dd></dl>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00061">61</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a1e1d676591853dc94e1466c577e1f7ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e1d676591853dc94e1466c577e1f7ee">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[4/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>ghost_indices_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with index set arguments. This constructor creates a distributed layout based on a given communicators, an <a class="el" href="classIndexSet.html">IndexSet</a> describing the locally owned range and another one for describing ghost indices that are owned by other processors, but that we need to have read or write access to. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00097">97</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a556204a8a9aa00b96f283b7330846322"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a556204a8a9aa00b96f283b7330846322">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[5/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with one index set argument. This constructor creates a distributed layout based on a given communicator, and an <a class="el" href="classIndexSet.html">IndexSet</a> describing the locally owned range. It allows to set the ghost indices at a later time. Apart from this, it is similar to the other constructor with two index sets. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00116">116</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="ad9658977e422b669a966673692d8cd7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad9658977e422b669a966673692d8cd7e">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[6/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Default constructor. </p>

</div>
</div>
<a id="a809df85f8965a4cf27ec7e171d250043"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a809df85f8965a4cf27ec7e171d250043">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[7/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>size</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with size argument. Creates an MPI_COMM_SELF structure where there is no real parallel layout. </p>

</div>
</div>
<a id="a26d6f941603139d1701cc85d82e7ce99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a26d6f941603139d1701cc85d82e7ce99">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[8/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>local_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>ghost_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor that takes the number of locally-owned degrees of freedom <code>local_size</code> and the number of ghost degrees of freedom <code>ghost_size</code>.</p>
<p>The local index range is translated to global indices in an ascending and one-to-one fashion, i.e., the indices of process \(p\) sit exactly between the indices of the processes \(p-1\) and \(p+1\), respectively.</p>
<dl class="section note"><dt>Note</dt><dd>Setting the <code>ghost_size</code> variable to an appropriate value provides memory space for the ghost data in a vector's memory allocation as and allows access to it via local_element(). However, the associated global indices must be handled externally in this case. </dd></dl>

</div>
</div>
<a id="a1e1d676591853dc94e1466c577e1f7ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e1d676591853dc94e1466c577e1f7ee">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[9/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>ghost_indices_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with index set arguments. This constructor creates a distributed layout based on a given communicators, an <a class="el" href="classIndexSet.html">IndexSet</a> describing the locally owned range and another one for describing ghost indices that are owned by other processors, but that we need to have read or write access to. </p>

</div>
</div>
<a id="a556204a8a9aa00b96f283b7330846322"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a556204a8a9aa00b96f283b7330846322">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[10/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with one index set argument. This constructor creates a distributed layout based on a given communicator, and an <a class="el" href="classIndexSet.html">IndexSet</a> describing the locally owned range. It allows to set the ghost indices at a later time. Apart from this, it is similar to the other constructor with two index sets. </p>

</div>
</div>
<a id="ad9658977e422b669a966673692d8cd7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad9658977e422b669a966673692d8cd7e">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[11/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Default constructor. </p>

</div>
</div>
<a id="a809df85f8965a4cf27ec7e171d250043"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a809df85f8965a4cf27ec7e171d250043">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[12/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>size</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with size argument. Creates an MPI_COMM_SELF structure where there is no real parallel layout. </p>

</div>
</div>
<a id="a26d6f941603139d1701cc85d82e7ce99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a26d6f941603139d1701cc85d82e7ce99">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[13/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>local_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>ghost_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor that takes the number of locally-owned degrees of freedom <code>local_size</code> and the number of ghost degrees of freedom <code>ghost_size</code>. The local index range is translated to global indices in an ascending and one-to-one fashion, i.e., the indices of process \(p\) sit exactly between the indices of the processes \(p-1\) and \(p+1\) , respectively. </p><dl class="section note"><dt>Note</dt><dd>Setting the <code>ghost_size</code> variable to an appropriate value provides memory space for the ghost data in a vector's memory allocation as and allows access to it via local_element(). However, the associated global indices must be handled externally in this case. </dd></dl>

</div>
</div>
<a id="a1e1d676591853dc94e1466c577e1f7ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e1d676591853dc94e1466c577e1f7ee">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[14/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>ghost_indices_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with index set arguments. This constructor creates a distributed layout based on a given communicators, an <a class="el" href="classIndexSet.html">IndexSet</a> describing the locally owned range and another one for describing ghost indices that are owned by other processors, but that we need to have read or write access to. </p>

</div>
</div>
<a id="a556204a8a9aa00b96f283b7330846322"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a556204a8a9aa00b96f283b7330846322">&#9670;&nbsp;</a></span>Partitioner() <span class="overload">[15/15]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::Partitioner </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Constructor with one index set argument. This constructor creates a distributed layout based on a given communicator, and an <a class="el" href="classIndexSet.html">IndexSet</a> describing the locally owned range. It allows to set the ghost indices at a later time. Apart from this, it is similar to the other constructor with two index sets. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a895bdd6d93c5bf296c53b39dc3b2248d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a895bdd6d93c5bf296c53b39dc3b2248d">&#9670;&nbsp;</a></span>reinit() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::reinit </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>vector_space_vector_index_set</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>read_write_vector_index_set</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Reinitialize the communication pattern. The first argument <code>vector_space_vector_index_set</code> is the index set associated to a VectorSpaceVector object. The second argument <code>read_write_vector_index_set</code> is the index set associated to a ReadWriteVector object. </p>

<p>Implements <a class="el" href="classUtilities_1_1MPI_1_1CommunicationPatternBase.html#a257cc0c37d054a30f5d83a1bee444c73">Utilities::MPI::CommunicationPatternBase</a>.</p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00134">134</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a209816de3a347481b172efc7b2afa11e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a209816de3a347481b172efc7b2afa11e">&#9670;&nbsp;</a></span>set_owned_indices() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::set_owned_indices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Set the locally owned indices. Used in the constructor. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00147">147</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="aa05cff1b3f359e104d4d533e0d245f0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa05cff1b3f359e104d4d533e0d245f0f">&#9670;&nbsp;</a></span>set_ghost_indices() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::set_ghost_indices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>ghost_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>larger_ghost_index_set</em> = <code><a class="el" href="classIndexSet.html">IndexSet</a>()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Set the ghost indices after the constructor has been called. The optional parameter <code>larger_ghost_index_set</code> allows defining an indirect addressing into a larger set of ghost indices. This setup is useful if a distributed vector is based on that larger ghost index set but only a tighter subset should be communicated according to <code>ghost_indices</code>. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00188">188</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="ad3b457f661fec81683f5893a252ee8f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3b457f661fec81683f5893a252ee8f3">&#9670;&nbsp;</a></span>size() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> Utilities::MPI::Partitioner::size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the global size. </p>

</div>
</div>
<a id="a40d257bdf99e2ce1edceaaab997a6dcb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40d257bdf99e2ce1edceaaab997a6dcb">&#9670;&nbsp;</a></span>local_size() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::local_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of locally owned indices, i.e., <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.second minus <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.first. The returned numbers need to add up to the total number of indices when summed over all processes </p><dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000009">Deprecated:</a></b></dt><dd>Use the more clearly named function <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> instead.</dd></dl>

</div>
</div>
<a id="a8b4a475abc0b200583fd897a0869b7af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b4a475abc0b200583fd897a0869b7af">&#9670;&nbsp;</a></span>locally_owned_size() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::locally_owned_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of locally owned indices, i.e., <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.second minus <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.first. The returned numbers need to add up to the total number of indices when summed over all processes </p>

</div>
</div>
<a id="ad8b23309278c2d8994b4d42bae05c4aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad8b23309278c2d8994b4d42bae05c4aa">&#9670;&nbsp;</a></span>locally_owned_range() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a>&amp; Utilities::MPI::Partitioner::locally_owned_range </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return an <a class="el" href="classIndexSet.html">IndexSet</a> representation of the local range. This class only supports contiguous local ranges, so the <a class="el" href="classIndexSet.html">IndexSet</a> actually only consists of one single range of data, and is equivalent to the result of <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>. </p>

</div>
</div>
<a id="af5b55ec94360152e50fa10ad39fadf0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5b55ec94360152e50fa10ad39fadf0d">&#9670;&nbsp;</a></span>local_range() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt;<a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&gt; Utilities::MPI::Partitioner::local_range </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the local range. The returned pair consists of the index of the first element and the index of the element one past the last locally owned one. </p>

</div>
</div>
<a id="a158e25d33cc3477b873b4281b7bc222a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a158e25d33cc3477b873b4281b7bc222a">&#9670;&nbsp;</a></span>in_local_range() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::in_local_range </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return true if the given global index is in the local range of this processor. </p>

</div>
</div>
<a id="a11316c010d3d51912cdfe1939651ad72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11316c010d3d51912cdfe1939651ad72">&#9670;&nbsp;</a></span>global_to_local() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::global_to_local </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the local index corresponding to the given global index. If the given global index is neither locally owned nor a ghost, an exception is thrown. Note that the returned local index for locally owned indices will be between 0 and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a></p>
<ul>
<li>1, and the local index for ghosts is between <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a></li>
<li>1. </li>
</ul>

</div>
</div>
<a id="a8bef6ce5fdcdc556e35d2f9afd9a3e64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8bef6ce5fdcdc556e35d2f9afd9a3e64">&#9670;&nbsp;</a></span>local_to_global() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> Utilities::MPI::Partitioner::local_to_global </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>local_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the global index corresponding to the given local index. Note that the local index for locally owned indices must be between 0 and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a></p>
<ul>
<li>1, and the local index for ghosts must be between <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a></li>
<li>1. </li>
</ul>

</div>
</div>
<a id="ae5d416287d1d4286044e45cdf8f2dc34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5d416287d1d4286044e45cdf8f2dc34">&#9670;&nbsp;</a></span>is_ghost_entry() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_ghost_entry </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return whether the given global index is a ghost index on the present processor. Returns false for indices that are owned locally and for indices not present at all. </p>

</div>
</div>
<a id="aff4396480641e9e88a8bef38a54b7f32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff4396480641e9e88a8bef38a54b7f32">&#9670;&nbsp;</a></span>ghost_indices() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a>&amp; Utilities::MPI::Partitioner::ghost_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return an <a class="el" href="classIndexSet.html">IndexSet</a> representation of all ghost indices. </p>

</div>
</div>
<a id="a32ffda295e9a5b81ae40359c592a31d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32ffda295e9a5b81ae40359c592a31d9">&#9670;&nbsp;</a></span>n_ghost_indices() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_ghost_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of ghost indices. Same as <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices()</a>.<a class="el" href="table__0_8txt.html#ab0c207fc9a63cc7861178ab4e76b2da9">n_elements()</a>, but cached for simpler access. </p>

</div>
</div>
<a id="a50ad28f00d8ed112756a3b34c5f4a02c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50ad28f00d8ed112756a3b34c5f4a02c">&#9670;&nbsp;</a></span>ghost_indices_within_larger_ghost_set() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::ghost_indices_within_larger_ghost_set </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>In case the partitioner was built to define ghost indices as a subset of indices in a larger set of ghosts, this function returns the numbering in terms of ranges within that set. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a>, but tailored to be iterated over. In case the partitioner did not take a second set of ghost indices into account, this subset is simply defined as the half-open interval <code>[0, <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>)</code> . </p>

</div>
</div>
<a id="a0712b38533b13a65285a2d73bb43ce4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0712b38533b13a65285a2d73bb43ce4c">&#9670;&nbsp;</a></span>ghost_targets() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::ghost_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a list of processors (first entry) and the number of ghost degrees of freedom owned by that processor (second entry). The sum of the latter over all processors equals <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>. </p>

</div>
</div>
<a id="a30aa27640e582dd380694c6904c53796"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30aa27640e582dd380694c6904c53796">&#9670;&nbsp;</a></span>import_indices() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::import_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a vector of ranges of local indices that we are importing during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a>, i.e., others' ghosts that belong to the local range. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a>, but tailored to be iterated over, and some indices may be duplicated. The returned pairs consists of the index of the first element and the index of the element one past the last one in a range. </p>

</div>
</div>
<a id="abf1656017a302e6e2a3ad84625ac63d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf1656017a302e6e2a3ad84625ac63d8">&#9670;&nbsp;</a></span>n_import_indices() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_import_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Number of import indices, i.e., indices that are ghosts on other processors and we will receive data from. </p>

</div>
</div>
<a id="af669a7aadb35f85a4e2edc21e50da374"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af669a7aadb35f85a4e2edc21e50da374">&#9670;&nbsp;</a></span>import_targets() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::import_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a list of processors (first entry) and the number of degrees of freedom imported from it during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a> operation (second entry) for all the processors that data is obtained from, i.e., locally owned indices that are ghosts on other processors. </p><dl class="section note"><dt>Note</dt><dd>The returned vector only contains those processor id's for which the second entry is non-zero. </dd></dl>

</div>
</div>
<a id="aec126befa3eaa12723033cf3a2c44373"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec126befa3eaa12723033cf3a2c44373">&#9670;&nbsp;</a></span>is_compatible() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_compatible </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;&#160;</td>
          <td class="paramname"><em>part</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Check whether the given partitioner is compatible with the current partitioner. Two partitioners are compatible if they have the same local sizes and the same ghost indices. They do not necessarily need to correspond to the same data that is stored based on these partioner objects. This is a local operation only, i.e., if only some processors decide that the partitioning is not compatible, only these processors will return <code>false</code>, whereas the other processors will return <code>true</code>. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00470">470</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a1c331ade4bbd7571a3741fd2747d1f1d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c331ade4bbd7571a3741fd2747d1f1d">&#9670;&nbsp;</a></span>is_globally_compatible() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_globally_compatible </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;&#160;</td>
          <td class="paramname"><em>part</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Check whether the given partitioner is compatible with the current partitioner. Two partitioners are compatible if they have the same local size and the same ghost indices. They do not necessarily need to correspond to the same data that is stored based on these partioner objects. As opposed to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible()</a>, this method checks for compatibility among all processors and the method only returns <code>true</code> if the partitioner is the same on all processors. In other words, it does a global "and" operation over the results returned by <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible()</a> on all involved processes. This method performs global communication, so make sure to use it only in a context where all processors call it the same number of times. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00497">497</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a528645b3631f18c7f84304a85511a54b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a528645b3631f18c7f84304a85511a54b">&#9670;&nbsp;</a></span>this_mpi_process() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::this_mpi_process </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> ID of the calling processor. Cached to have simple access. </p>

</div>
</div>
<a id="a74d37fa18c73e1277afb996827080a4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74d37fa18c73e1277afb996827080a4e">&#9670;&nbsp;</a></span>n_mpi_processes() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_mpi_processes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the total number of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> processor participating in the given partitioner. Cached to have simple access. </p>

</div>
</div>
<a id="acdd62432c1d0bdec701b79528dab3ef9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdd62432c1d0bdec701b79528dab3ef9">&#9670;&nbsp;</a></span>get_mpi_communicator() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm&amp; Utilities::MPI::Partitioner::get_mpi_communicator </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Return the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator underlying the partitioner object. </p>

<p>Implements <a class="el" href="classUtilities_1_1MPI_1_1CommunicationPatternBase.html#a678401c284fdbbaa7a896794c417b091">Utilities::MPI::CommunicationPatternBase</a>.</p>

</div>
</div>
<a id="af353fd142ec460dce6e2b3ddf29b1697"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af353fd142ec460dce6e2b3ddf29b1697">&#9670;&nbsp;</a></span>ghost_indices_initialized() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::ghost_indices_initialized </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return whether ghost indices have been explicitly added as a <code>ghost_indices</code> argument. Only true if a <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a895bdd6d93c5bf296c53b39dc3b2248d">reinit()</a> call or constructor provided that argument. </p>

</div>
</div>
<a id="a5138501f56f373ab880ecfb2a8ed876b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5138501f56f373ab880ecfb2a8ed876b">&#9670;&nbsp;</a></span>export_to_ghosted_array_start() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::export_to_ghosted_array_start </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>communication_channel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Start the exportation of the data in a locally owned array to the range described by the ghost indices of this class. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">communication_channel</td><td>Sets an offset to the MPI_Isend and MPI_Irecv calls that avoids interference with other ongoing <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> calls on different entries. Typically handled within the blocks of a block vector. Any value less than 200 is a valid value.</td></tr>
    <tr><td class="paramname">locally_owned_array</td><td>The array of data from which the data is extracted and sent to the ghost entries on a remote processor.</td></tr>
    <tr><td class="paramname">temporary_storage</td><td>A temporary storage array of length <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices()</a> that is used to hold the packed data from the <code>locally_owned_array</code> to be sent. Note that this array must not be touched until the respective <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call has been made because the model uses non-blocking communication. </td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array that will receive the exported data, i.e., the entries that a remote processor sent to the calling process. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. In case only selected indices are sent, no guarantee is made regarding the entries that do not get set. Some of them might be used to organize the transfer and later reset to zero, so make sure you do not use them in computations. </td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that will be finalized in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878">LinearAlgebra::distributed::Vector::update_ghost_values()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab3d760ded3110fb5e4d60d1202147bf0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3d760ded3110fb5e4d60d1202147bf0">&#9670;&nbsp;</a></span>export_to_ghosted_array_finish() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::export_to_ghosted_array_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Finish the exportation of the data in a locally owned array to the range described by the ghost indices of this class. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ghost_array</td><td>The array that will receive the exported data started in the <code><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a></code>. This must be the same array as passed to that function, otherwise the behavior is undefined.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that were started in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> call. This must be the same array as passed to that function, otherwise <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> will likely throw an error. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878">LinearAlgebra::distributed::Vector::update_ghost_values()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aca3a9b8e1840bf9539e6335817f1a8fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca3a9b8e1840bf9539e6335817f1a8fa">&#9670;&nbsp;</a></span>import_from_ghosted_array_start() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::import_from_ghosted_array_start </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a>&#160;</td>
          <td class="paramname"><em>vector_operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>communication_channel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Start importing the data on an array indexed by the ghost indices of this class that is later accumulated into a locally owned array with <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a>.</p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector_operation</td><td>Defines how the data sent to the owner should be combined with the existing entries, e.g., added into. </td></tr>
    <tr><td class="paramname">communication_channel</td><td>Sets an offset to the MPI_Isend and MPI_Irecv calls that avoids interference with other ongoing <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> calls on different entries. Typically handled within the blocks of a block vector. Any value less than 200 is a valid value.</td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array of ghost data that is sent to a remote owner of the respective index in a vector. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. This or the subsequent <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> function, the order is implementation-dependent, will set all data entries behind <code>ghost_array</code> to zero.</td></tr>
    <tr><td class="paramname">temporary_storage</td><td>A temporary storage array of length <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices()</a> that is used to hold the packed data from <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication that will later be written into the locally owned array. Note that this array must not be touched until the respective <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> call has been made because the model uses non-blocking communication.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that will be finalized in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a8a204103e550697467d933388b732bda">LinearAlgebra::distributed::Vector::compress()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a699b46b2256bcb38119b5faac1b242cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a699b46b2256bcb38119b5faac1b242cd">&#9670;&nbsp;</a></span>import_from_ghosted_array_finish() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::import_from_ghosted_array_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a>&#160;</td>
          <td class="paramname"><em>vector_operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Finish importing the data from an array indexed by the ghost indices of this class into a specified locally owned array, combining the results according to the given input <code>vector_operation</code>. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector_operation</td><td>Defines how the data sent to the owner should be combined with the existing entries, e.g., added into. </td></tr>
    <tr><td class="paramname">temporary_storage</td><td>The same array given to the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> call that contains the packed data from <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication. In thus function, it is combined at the corresponding entries described by the ghost relations according to <code>vector_operation</code>.</td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array of ghost data that is sent to a remote owner of the respective index in a vector. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. This function will set all data entries behind <code>ghost_array</code> to zero for the implementation-dependent cases when it was not already done in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> call. </td></tr>
    <tr><td class="paramname">locally_owned_storage</td><td>The array of data where the resulting data sent by remote processes to the calling process will be accumulated into.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that have been initiated in the import_to_ghosted_array_finish() call. This must be the same array as passed to that function, otherwise <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> will likely throw an error. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a8a204103e550697467d933388b732bda">LinearAlgebra::distributed::Vector::compress()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a0f154243f694679910f605359a739fa1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f154243f694679910f605359a739fa1">&#9670;&nbsp;</a></span>memory_consumption() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::size_t Utilities::MPI::Partitioner::memory_consumption </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Compute the memory consumption of this structure. </p>

<p class="definition">Definition at line <a class="el" href="partitioner_8cc_source.html#l00506">506</a> of file <a class="el" href="partitioner_8cc_source.html">partitioner.cc</a>.</p>

</div>
</div>
<a id="a7fcae5500056427795b8ed84b5a4c102"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fcae5500056427795b8ed84b5a4c102">&#9670;&nbsp;</a></span>initialize_import_indices_plain_dev() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::initialize_import_indices_plain_dev </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Initialize import_indices_plain_dev from import_indices_data. This function is only used when using CUDA-aware <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </p>

</div>
</div>
<a id="a44313c9910bc19d27bfbccde2bf051a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44313c9910bc19d27bfbccde2bf051a2">&#9670;&nbsp;</a></span>reinit() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> void Utilities::MPI::Partitioner::reinit </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>vector_space_vector_index_set</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>read_write_vector_index_set</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Reinitialize the communication pattern. The first argument <code>vector_space_vector_index_set</code> is the index set associated to a VectorSpaceVector object. The second argument <code>read_write_vector_index_set</code> is the index set associated to a ReadWriteVector object. </p>

<p>Implements <a class="el" href="classUtilities_1_1MPI_1_1CommunicationPatternBase.html#a257cc0c37d054a30f5d83a1bee444c73">Utilities::MPI::CommunicationPatternBase</a>.</p>

</div>
</div>
<a id="a209816de3a347481b172efc7b2afa11e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a209816de3a347481b172efc7b2afa11e">&#9670;&nbsp;</a></span>set_owned_indices() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::set_owned_indices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Set the locally owned indices. Used in the constructor. </p>

</div>
</div>
<a id="aa05cff1b3f359e104d4d533e0d245f0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa05cff1b3f359e104d4d533e0d245f0f">&#9670;&nbsp;</a></span>set_ghost_indices() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::set_ghost_indices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>ghost_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>larger_ghost_index_set</em> = <code><a class="el" href="classIndexSet.html">IndexSet</a>()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Set the ghost indices after the constructor has been called.</p>
<p>The optional parameter <code>larger_ghost_index_set</code> allows defining an indirect addressing into a larger set of ghost indices. This setup is useful if a distributed vector is based on that larger ghost index set but only a tighter subset should be communicated according to <code>ghost_indices</code>. </p>

</div>
</div>
<a id="ad3b457f661fec81683f5893a252ee8f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3b457f661fec81683f5893a252ee8f3">&#9670;&nbsp;</a></span>size() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> Utilities::MPI::Partitioner::size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the global size. </p>

</div>
</div>
<a id="a40d257bdf99e2ce1edceaaab997a6dcb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40d257bdf99e2ce1edceaaab997a6dcb">&#9670;&nbsp;</a></span>local_size() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::local_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of locally owned indices, i.e., <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.second minus <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.first. The returned numbers need to add up to the total number of indices when summed over all processes</p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000104">Deprecated:</a></b></dt><dd>Use the more clearly named function <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> instead. </dd></dl>

</div>
</div>
<a id="a8b4a475abc0b200583fd897a0869b7af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b4a475abc0b200583fd897a0869b7af">&#9670;&nbsp;</a></span>locally_owned_size() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::locally_owned_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of locally owned indices, i.e., <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.second minus <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.first. The returned numbers need to add up to the total number of indices when summed over all processes </p>

</div>
</div>
<a id="ad8b23309278c2d8994b4d42bae05c4aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad8b23309278c2d8994b4d42bae05c4aa">&#9670;&nbsp;</a></span>locally_owned_range() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a>&amp; Utilities::MPI::Partitioner::locally_owned_range </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return an <a class="el" href="classIndexSet.html">IndexSet</a> representation of the local range. This class only supports contiguous local ranges, so the <a class="el" href="classIndexSet.html">IndexSet</a> actually only consists of one single range of data, and is equivalent to the result of <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>. </p>

</div>
</div>
<a id="af5b55ec94360152e50fa10ad39fadf0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5b55ec94360152e50fa10ad39fadf0d">&#9670;&nbsp;</a></span>local_range() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt;<a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&gt; Utilities::MPI::Partitioner::local_range </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the local range. The returned pair consists of the index of the first element and the index of the element one past the last locally owned one. </p>

</div>
</div>
<a id="a158e25d33cc3477b873b4281b7bc222a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a158e25d33cc3477b873b4281b7bc222a">&#9670;&nbsp;</a></span>in_local_range() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::in_local_range </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return true if the given global index is in the local range of this processor. </p>

</div>
</div>
<a id="a11316c010d3d51912cdfe1939651ad72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11316c010d3d51912cdfe1939651ad72">&#9670;&nbsp;</a></span>global_to_local() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::global_to_local </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the local index corresponding to the given global index. If the given global index is neither locally owned nor a ghost, an exception is thrown.</p>
<p>Note that the returned local index for locally owned indices will be between 0 and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> - 1, and the local index for ghosts is between <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> - 1. </p>

</div>
</div>
<a id="a8bef6ce5fdcdc556e35d2f9afd9a3e64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8bef6ce5fdcdc556e35d2f9afd9a3e64">&#9670;&nbsp;</a></span>local_to_global() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> Utilities::MPI::Partitioner::local_to_global </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>local_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the global index corresponding to the given local index.</p>
<p>Note that the local index for locally owned indices must be between 0 and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> - 1, and the local index for ghosts must be between <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> - 1. </p>

</div>
</div>
<a id="ae5d416287d1d4286044e45cdf8f2dc34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5d416287d1d4286044e45cdf8f2dc34">&#9670;&nbsp;</a></span>is_ghost_entry() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_ghost_entry </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return whether the given global index is a ghost index on the present processor. Returns false for indices that are owned locally and for indices not present at all. </p>

</div>
</div>
<a id="aff4396480641e9e88a8bef38a54b7f32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff4396480641e9e88a8bef38a54b7f32">&#9670;&nbsp;</a></span>ghost_indices() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a>&amp; Utilities::MPI::Partitioner::ghost_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return an <a class="el" href="classIndexSet.html">IndexSet</a> representation of all ghost indices. </p>

</div>
</div>
<a id="a32ffda295e9a5b81ae40359c592a31d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32ffda295e9a5b81ae40359c592a31d9">&#9670;&nbsp;</a></span>n_ghost_indices() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_ghost_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of ghost indices. Same as <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices()</a>.<a class="el" href="table__0_8txt.html#ab0c207fc9a63cc7861178ab4e76b2da9">n_elements()</a>, but cached for simpler access. </p>

</div>
</div>
<a id="a50ad28f00d8ed112756a3b34c5f4a02c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50ad28f00d8ed112756a3b34c5f4a02c">&#9670;&nbsp;</a></span>ghost_indices_within_larger_ghost_set() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::ghost_indices_within_larger_ghost_set </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>In case the partitioner was built to define ghost indices as a subset of indices in a larger set of ghosts, this function returns the numbering in terms of ranges within that set. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a>, but tailored to be iterated over.</p>
<p>In case the partitioner did not take a second set of ghost indices into account, this subset is simply defined as the half-open interval <code>[0, <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>)</code>. </p>

</div>
</div>
<a id="a0712b38533b13a65285a2d73bb43ce4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0712b38533b13a65285a2d73bb43ce4c">&#9670;&nbsp;</a></span>ghost_targets() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::ghost_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a list of processors (first entry) and the number of ghost degrees of freedom owned by that processor (second entry). The sum of the latter over all processors equals <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>. </p>

</div>
</div>
<a id="a30aa27640e582dd380694c6904c53796"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30aa27640e582dd380694c6904c53796">&#9670;&nbsp;</a></span>import_indices() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::import_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a vector of ranges of local indices that we are importing during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a>, i.e., others' ghosts that belong to the local range. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a>, but tailored to be iterated over, and some indices may be duplicated. The returned pairs consists of the index of the first element and the index of the element one past the last one in a range. </p>

</div>
</div>
<a id="abf1656017a302e6e2a3ad84625ac63d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf1656017a302e6e2a3ad84625ac63d8">&#9670;&nbsp;</a></span>n_import_indices() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_import_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Number of import indices, i.e., indices that are ghosts on other processors and we will receive data from. </p>

</div>
</div>
<a id="af669a7aadb35f85a4e2edc21e50da374"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af669a7aadb35f85a4e2edc21e50da374">&#9670;&nbsp;</a></span>import_targets() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::import_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a list of processors (first entry) and the number of degrees of freedom imported from it during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a> operation (second entry) for all the processors that data is obtained from, i.e., locally owned indices that are ghosts on other processors.</p>
<dl class="section note"><dt>Note</dt><dd>The returned vector only contains those processor id's for which the second entry is non-zero. </dd></dl>

</div>
</div>
<a id="aec126befa3eaa12723033cf3a2c44373"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec126befa3eaa12723033cf3a2c44373">&#9670;&nbsp;</a></span>is_compatible() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_compatible </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;&#160;</td>
          <td class="paramname"><em>part</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Check whether the given partitioner is compatible with the current partitioner. Two partitioners are compatible if they have the same local sizes and the same ghost indices. They do not necessarily need to correspond to the same data that is stored based on these partioner objects. This is a local operation only, i.e., if only some processors decide that the partitioning is not compatible, only these processors will return <code>false</code>, whereas the other processors will return <code>true</code>. </p>

</div>
</div>
<a id="a1c331ade4bbd7571a3741fd2747d1f1d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c331ade4bbd7571a3741fd2747d1f1d">&#9670;&nbsp;</a></span>is_globally_compatible() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_globally_compatible </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;&#160;</td>
          <td class="paramname"><em>part</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Check whether the given partitioner is compatible with the current partitioner. Two partitioners are compatible if they have the same local size and the same ghost indices. They do not necessarily need to correspond to the same data that is stored based on these partioner objects. As opposed to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible()</a>, this method checks for compatibility among all processors and the method only returns <code>true</code> if the partitioner is the same on all processors. In other words, it does a global "and" operation over the results returned by <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible()</a> on all involved processes.</p>
<p>This method performs global communication, so make sure to use it only in a context where all processors call it the same number of times. </p>

</div>
</div>
<a id="a528645b3631f18c7f84304a85511a54b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a528645b3631f18c7f84304a85511a54b">&#9670;&nbsp;</a></span>this_mpi_process() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::this_mpi_process </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> ID of the calling processor. Cached to have simple access. </p>

</div>
</div>
<a id="a74d37fa18c73e1277afb996827080a4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74d37fa18c73e1277afb996827080a4e">&#9670;&nbsp;</a></span>n_mpi_processes() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_mpi_processes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the total number of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> processor participating in the given partitioner. Cached to have simple access. </p>

</div>
</div>
<a id="acdd62432c1d0bdec701b79528dab3ef9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdd62432c1d0bdec701b79528dab3ef9">&#9670;&nbsp;</a></span>get_mpi_communicator() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm&amp; Utilities::MPI::Partitioner::get_mpi_communicator </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Return the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator underlying the partitioner object. </p>

<p>Implements <a class="el" href="classUtilities_1_1MPI_1_1CommunicationPatternBase.html#a678401c284fdbbaa7a896794c417b091">Utilities::MPI::CommunicationPatternBase</a>.</p>

</div>
</div>
<a id="af353fd142ec460dce6e2b3ddf29b1697"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af353fd142ec460dce6e2b3ddf29b1697">&#9670;&nbsp;</a></span>ghost_indices_initialized() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::ghost_indices_initialized </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return whether ghost indices have been explicitly added as a <code>ghost_indices</code> argument. Only true if a <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a895bdd6d93c5bf296c53b39dc3b2248d">reinit()</a> call or constructor provided that argument. </p>

</div>
</div>
<a id="a5138501f56f373ab880ecfb2a8ed876b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5138501f56f373ab880ecfb2a8ed876b">&#9670;&nbsp;</a></span>export_to_ghosted_array_start() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::export_to_ghosted_array_start </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>communication_channel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Start the exportation of the data in a locally owned array to the range described by the ghost indices of this class.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">communication_channel</td><td>Sets an offset to the MPI_Isend and MPI_Irecv calls that avoids interference with other ongoing <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> calls on different entries. Typically handled within the blocks of a block vector. Any value less than 200 is a valid value.</td></tr>
    <tr><td class="paramname">locally_owned_array</td><td>The array of data from which the data is extracted and sent to the ghost entries on a remote processor.</td></tr>
    <tr><td class="paramname">temporary_storage</td><td>A temporary storage array of length <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices()</a> that is used to hold the packed data from the <code>locally_owned_array</code> to be sent. Note that this array must not be touched until the respective <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call has been made because the model uses non-blocking communication.</td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array that will receive the exported data, i.e., the entries that a remote processor sent to the calling process. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. In case only selected indices are sent, no guarantee is made regarding the entries that do not get set. Some of them might be used to organize the transfer and later reset to zero, so make sure you do not use them in computations.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that will be finalized in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call.</td></tr>
  </table>
  </dd>
</dl>
<p>This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878">LinearAlgebra::distributed::Vector::update_ghost_values()</a>. </p>

</div>
</div>
<a id="ab3d760ded3110fb5e4d60d1202147bf0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3d760ded3110fb5e4d60d1202147bf0">&#9670;&nbsp;</a></span>export_to_ghosted_array_finish() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::export_to_ghosted_array_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Finish the exportation of the data in a locally owned array to the range described by the ghost indices of this class.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ghost_array</td><td>The array that will receive the exported data started in the <code><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a></code>. This must be the same array as passed to that function, otherwise the behavior is undefined.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that were started in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> call. This must be the same array as passed to that function, otherwise <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> will likely throw an error.</td></tr>
  </table>
  </dd>
</dl>
<p>This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878">LinearAlgebra::distributed::Vector::update_ghost_values()</a>. </p>

</div>
</div>
<a id="aca3a9b8e1840bf9539e6335817f1a8fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca3a9b8e1840bf9539e6335817f1a8fa">&#9670;&nbsp;</a></span>import_from_ghosted_array_start() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::import_from_ghosted_array_start </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a>&#160;</td>
          <td class="paramname"><em>vector_operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>communication_channel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Start importing the data on an array indexed by the ghost indices of this class that is later accumulated into a locally owned array with <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector_operation</td><td>Defines how the data sent to the owner should be combined with the existing entries, e.g., added into.</td></tr>
    <tr><td class="paramname">communication_channel</td><td>Sets an offset to the MPI_Isend and MPI_Irecv calls that avoids interference with other ongoing <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> calls on different entries. Typically handled within the blocks of a block vector. Any value less than 200 is a valid value.</td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array of ghost data that is sent to a remote owner of the respective index in a vector. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. This or the subsequent <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> function, the order is implementation-dependent, will set all data entries behind <code>ghost_array</code> to zero.</td></tr>
    <tr><td class="paramname">temporary_storage</td><td>A temporary storage array of length <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices()</a> that is used to hold the packed data from <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication that will later be written into the locally owned array. Note that this array must not be touched until the respective <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> call has been made because the model uses non-blocking communication.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that will be finalized in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call.</td></tr>
  </table>
  </dd>
</dl>
<p>This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a8a204103e550697467d933388b732bda">LinearAlgebra::distributed::Vector::compress()</a>. </p>

</div>
</div>
<a id="a699b46b2256bcb38119b5faac1b242cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a699b46b2256bcb38119b5faac1b242cd">&#9670;&nbsp;</a></span>import_from_ghosted_array_finish() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::import_from_ghosted_array_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a>&#160;</td>
          <td class="paramname"><em>vector_operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Finish importing the data from an array indexed by the ghost indices of this class into a specified locally owned array, combining the results according to the given input <code>vector_operation</code>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector_operation</td><td>Defines how the data sent to the owner should be combined with the existing entries, e.g., added into.</td></tr>
    <tr><td class="paramname">temporary_storage</td><td>The same array given to the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> call that contains the packed data from <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication. In thus function, it is combined at the corresponding entries described by the ghost relations according to <code>vector_operation</code>.</td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array of ghost data that is sent to a remote owner of the respective index in a vector. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. This function will set all data entries behind <code>ghost_array</code> to zero for the implementation-dependent cases when it was not already done in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> call.</td></tr>
    <tr><td class="paramname">locally_owned_storage</td><td>The array of data where the resulting data sent by remote processes to the calling process will be accumulated into.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that have been initiated in the import_to_ghosted_array_finish() call. This must be the same array as passed to that function, otherwise <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> will likely throw an error.</td></tr>
  </table>
  </dd>
</dl>
<p>This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a8a204103e550697467d933388b732bda">LinearAlgebra::distributed::Vector::compress()</a>. </p>

</div>
</div>
<a id="a0f154243f694679910f605359a739fa1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f154243f694679910f605359a739fa1">&#9670;&nbsp;</a></span>memory_consumption() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::size_t Utilities::MPI::Partitioner::memory_consumption </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Compute the memory consumption of this structure. </p>

</div>
</div>
<a id="a77df9bf9b64a44fbb6ad03b0c8f17515"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77df9bf9b64a44fbb6ad03b0c8f17515">&#9670;&nbsp;</a></span>DeclException2() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::DeclException2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__Exceptions.html#gaf6b2aa39da7267d2daceec0d03af4b79">ExcIndexNotPresent</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&lt;&lt; &quot;Global <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> &quot;&lt;&lt; arg1&lt;&lt; &quot; neither <a class="el" href="vector__tools__point__gradient__0_8txt.html#aef5058968290d0a16ef792424d0e1ba2">owned</a> <a class="el" href="chunk__sparsity__pattern__0_8txt.html#a31362234916f6aac38d1392e801099d6">nor</a> ghost <a class="el" href="data__postprocessor__0_8txt.html#a232fd208d0a301873073f51d8474883a">on</a> proc &quot;&lt;&lt; arg2&lt;&lt; &quot;.&quot;&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Exception </p>

</div>
</div>
<a id="a56ebf907bcd8ef8506a7ded78ed9db70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56ebf907bcd8ef8506a7ded78ed9db70">&#9670;&nbsp;</a></span>DeclException3() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::DeclException3 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__Exceptions.html#ga293b358739542847d88c8cd447f9adc7">ExcGhostIndexArrayHasWrongSize</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&lt;&lt; &quot;The <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> ghost <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> <a class="el" href="matrix__free_2dof__info__0_8txt.html#a597165203ae66b8aa2d96f3bd238b626">array</a> (&quot;&lt;&lt; arg1&lt;&lt; &quot;) must <a class="el" href="grid_2manifold__0_8txt.html#a9dc1c289073d97c27ef2fd7d201521c5">either</a> equal <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> <a class="el" href="generators__0_8txt.html#a52d07c1744d923546e9cafc255f70465">number</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> ghost <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> &quot;&lt;&lt; &quot;<a class="el" href="base_2partitioner__0_8txt.html#a936b2264a337bdb80dd12b8f90f72767">partitioner</a> (&quot;&lt;&lt; arg2&lt;&lt; &quot;) or <a class="el" href="tria__iterator__0_8txt.html#ae2c744f7850c09a43eafeafedf8e2619">be</a> equal <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="error__estimator__0_8txt.html#a4ec80ded5cb4f47bcabf0a970c68075b">to</a> <a class="el" href="vector__tools__constraints__0_8txt.html#a5bb8955c98135fbb60012ceeee4b7839">a</a> <a class="el" href="petsc__matrix__base__0_8txt.html#a91d0bc46add3efe5a167829805522d28">more</a> comprehensive <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a>&quot;&lt;&lt; &quot;<a class="el" href="histogram__0_8txt.html#a1f28b62a413a3352bc54e62ef004750e">set</a> <a class="el" href="function__restriction__0_8txt.html#a79f2798b238440d7e1841d2cf4711885">which</a> contains &quot;&lt;&lt; arg3&lt;&lt; &quot; elements <a class="el" href="chunk__sparse__matrix__0_8txt.html#aae7ed603ea40c1e6a20bb18bab713802">for</a> <a class="el" href="data__postprocessor__0_8txt.html#a600bd43d5bd41af065e85ec3e40fed92">this</a> partitioner.&quot;&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Exception </p>

</div>
</div>
<a id="a7fcae5500056427795b8ed84b5a4c102"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fcae5500056427795b8ed84b5a4c102">&#9670;&nbsp;</a></span>initialize_import_indices_plain_dev() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::initialize_import_indices_plain_dev </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Initialize import_indices_plain_dev from import_indices_data. This function is only used when using CUDA-aware <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </p>

</div>
</div>
<a id="a44313c9910bc19d27bfbccde2bf051a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44313c9910bc19d27bfbccde2bf051a2">&#9670;&nbsp;</a></span>reinit() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> void Utilities::MPI::Partitioner::reinit </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>vector_space_vector_index_set</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>read_write_vector_index_set</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm &amp;&#160;</td>
          <td class="paramname"><em>communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Reinitialize the communication pattern. The first argument <code>vector_space_vector_index_set</code> is the index set associated to a VectorSpaceVector object. The second argument <code>read_write_vector_index_set</code> is the index set associated to a ReadWriteVector object. </p>

<p>Implements <a class="el" href="classUtilities_1_1MPI_1_1CommunicationPatternBase.html#a257cc0c37d054a30f5d83a1bee444c73">Utilities::MPI::CommunicationPatternBase</a>.</p>

</div>
</div>
<a id="a209816de3a347481b172efc7b2afa11e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a209816de3a347481b172efc7b2afa11e">&#9670;&nbsp;</a></span>set_owned_indices() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::set_owned_indices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_indices</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Set the locally owned indices. Used in the constructor. </p>

</div>
</div>
<a id="aa05cff1b3f359e104d4d533e0d245f0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa05cff1b3f359e104d4d533e0d245f0f">&#9670;&nbsp;</a></span>set_ghost_indices() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::set_ghost_indices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>ghost_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>larger_ghost_index_set</em> = <code><a class="el" href="classIndexSet.html">IndexSet</a>()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Set the ghost indices after the constructor has been called. The optional parameter <code>larger_ghost_index_set</code> allows defining an indirect addressing into a larger set of ghost indices. This setup is useful if a distributed vector is based on that larger ghost index set but only a tighter subset should be communicated according to <code>ghost_indices</code>. </p>

</div>
</div>
<a id="ad3b457f661fec81683f5893a252ee8f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3b457f661fec81683f5893a252ee8f3">&#9670;&nbsp;</a></span>size() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> Utilities::MPI::Partitioner::size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the global size. </p>

</div>
</div>
<a id="a40d257bdf99e2ce1edceaaab997a6dcb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40d257bdf99e2ce1edceaaab997a6dcb">&#9670;&nbsp;</a></span>local_size() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::local_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of locally owned indices, i.e., <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.second minus <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.first. The returned numbers need to add up to the total number of indices when summed over all processes </p><dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000203">Deprecated:</a></b></dt><dd>Use the more clearly named function <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> instead.</dd></dl>

</div>
</div>
<a id="a8b4a475abc0b200583fd897a0869b7af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b4a475abc0b200583fd897a0869b7af">&#9670;&nbsp;</a></span>locally_owned_size() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::locally_owned_size </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of locally owned indices, i.e., <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.second minus <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>.first. The returned numbers need to add up to the total number of indices when summed over all processes </p>

</div>
</div>
<a id="ad8b23309278c2d8994b4d42bae05c4aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad8b23309278c2d8994b4d42bae05c4aa">&#9670;&nbsp;</a></span>locally_owned_range() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a>&amp; Utilities::MPI::Partitioner::locally_owned_range </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return an <a class="el" href="classIndexSet.html">IndexSet</a> representation of the local range. This class only supports contiguous local ranges, so the <a class="el" href="classIndexSet.html">IndexSet</a> actually only consists of one single range of data, and is equivalent to the result of <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#af5b55ec94360152e50fa10ad39fadf0d">local_range()</a>. </p>

</div>
</div>
<a id="af5b55ec94360152e50fa10ad39fadf0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5b55ec94360152e50fa10ad39fadf0d">&#9670;&nbsp;</a></span>local_range() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt;<a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&gt; Utilities::MPI::Partitioner::local_range </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the local range. The returned pair consists of the index of the first element and the index of the element one past the last locally owned one. </p>

</div>
</div>
<a id="a158e25d33cc3477b873b4281b7bc222a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a158e25d33cc3477b873b4281b7bc222a">&#9670;&nbsp;</a></span>in_local_range() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::in_local_range </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return true if the given global index is in the local range of this processor. </p>

</div>
</div>
<a id="a11316c010d3d51912cdfe1939651ad72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11316c010d3d51912cdfe1939651ad72">&#9670;&nbsp;</a></span>global_to_local() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::global_to_local </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the local index corresponding to the given global index. If the given global index is neither locally owned nor a ghost, an exception is thrown. Note that the returned local index for locally owned indices will be between 0 and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a></p>
<ul>
<li>1, and the local index for ghosts is between <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a></li>
<li>1. </li>
</ul>

</div>
</div>
<a id="a8bef6ce5fdcdc556e35d2f9afd9a3e64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8bef6ce5fdcdc556e35d2f9afd9a3e64">&#9670;&nbsp;</a></span>local_to_global() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> Utilities::MPI::Partitioner::local_to_global </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>local_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the global index corresponding to the given local index. Note that the local index for locally owned indices must be between 0 and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a></p>
<ul>
<li>1, and the local index for ghosts must be between <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> and <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a8b4a475abc0b200583fd897a0869b7af">locally_owned_size()</a> + <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a></li>
<li>1. </li>
</ul>

</div>
</div>
<a id="ae5d416287d1d4286044e45cdf8f2dc34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5d416287d1d4286044e45cdf8f2dc34">&#9670;&nbsp;</a></span>is_ghost_entry() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_ghost_entry </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname"><em>global_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return whether the given global index is a ghost index on the present processor. Returns false for indices that are owned locally and for indices not present at all. </p>

</div>
</div>
<a id="aff4396480641e9e88a8bef38a54b7f32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff4396480641e9e88a8bef38a54b7f32">&#9670;&nbsp;</a></span>ghost_indices() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classIndexSet.html">IndexSet</a>&amp; Utilities::MPI::Partitioner::ghost_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return an <a class="el" href="classIndexSet.html">IndexSet</a> representation of all ghost indices. </p>

</div>
</div>
<a id="a32ffda295e9a5b81ae40359c592a31d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32ffda295e9a5b81ae40359c592a31d9">&#9670;&nbsp;</a></span>n_ghost_indices() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_ghost_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of ghost indices. Same as <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aff4396480641e9e88a8bef38a54b7f32">ghost_indices()</a>.<a class="el" href="table__0_8txt.html#ab0c207fc9a63cc7861178ab4e76b2da9">n_elements()</a>, but cached for simpler access. </p>

</div>
</div>
<a id="a50ad28f00d8ed112756a3b34c5f4a02c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50ad28f00d8ed112756a3b34c5f4a02c">&#9670;&nbsp;</a></span>ghost_indices_within_larger_ghost_set() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::ghost_indices_within_larger_ghost_set </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>In case the partitioner was built to define ghost indices as a subset of indices in a larger set of ghosts, this function returns the numbering in terms of ranges within that set. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a>, but tailored to be iterated over. In case the partitioner did not take a second set of ghost indices into account, this subset is simply defined as the half-open interval <code>[0, <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>)</code> . </p>

</div>
</div>
<a id="a0712b38533b13a65285a2d73bb43ce4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0712b38533b13a65285a2d73bb43ce4c">&#9670;&nbsp;</a></span>ghost_targets() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::ghost_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a list of processors (first entry) and the number of ghost degrees of freedom owned by that processor (second entry). The sum of the latter over all processors equals <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a>. </p>

</div>
</div>
<a id="a30aa27640e582dd380694c6904c53796"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30aa27640e582dd380694c6904c53796">&#9670;&nbsp;</a></span>import_indices() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::import_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a vector of ranges of local indices that we are importing during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a>, i.e., others' ghosts that belong to the local range. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a>, but tailored to be iterated over, and some indices may be duplicated. The returned pairs consists of the index of the first element and the index of the element one past the last one in a range. </p>

</div>
</div>
<a id="abf1656017a302e6e2a3ad84625ac63d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf1656017a302e6e2a3ad84625ac63d8">&#9670;&nbsp;</a></span>n_import_indices() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_import_indices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Number of import indices, i.e., indices that are ghosts on other processors and we will receive data from. </p>

</div>
</div>
<a id="af669a7aadb35f85a4e2edc21e50da374"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af669a7aadb35f85a4e2edc21e50da374">&#9670;&nbsp;</a></span>import_targets() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt;std::pair&lt;unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&gt; &gt;&amp; Utilities::MPI::Partitioner::import_targets </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a list of processors (first entry) and the number of degrees of freedom imported from it during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a> operation (second entry) for all the processors that data is obtained from, i.e., locally owned indices that are ghosts on other processors. </p><dl class="section note"><dt>Note</dt><dd>The returned vector only contains those processor id's for which the second entry is non-zero. </dd></dl>

</div>
</div>
<a id="aec126befa3eaa12723033cf3a2c44373"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec126befa3eaa12723033cf3a2c44373">&#9670;&nbsp;</a></span>is_compatible() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_compatible </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;&#160;</td>
          <td class="paramname"><em>part</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Check whether the given partitioner is compatible with the current partitioner. Two partitioners are compatible if they have the same local sizes and the same ghost indices. They do not necessarily need to correspond to the same data that is stored based on these partioner objects. This is a local operation only, i.e., if only some processors decide that the partitioning is not compatible, only these processors will return <code>false</code>, whereas the other processors will return <code>true</code>. </p>

</div>
</div>
<a id="a1c331ade4bbd7571a3741fd2747d1f1d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c331ade4bbd7571a3741fd2747d1f1d">&#9670;&nbsp;</a></span>is_globally_compatible() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::is_globally_compatible </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a> &amp;&#160;</td>
          <td class="paramname"><em>part</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Check whether the given partitioner is compatible with the current partitioner. Two partitioners are compatible if they have the same local size and the same ghost indices. They do not necessarily need to correspond to the same data that is stored based on these partioner objects. As opposed to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible()</a>, this method checks for compatibility among all processors and the method only returns <code>true</code> if the partitioner is the same on all processors. In other words, it does a global "and" operation over the results returned by <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aec126befa3eaa12723033cf3a2c44373">is_compatible()</a> on all involved processes. This method performs global communication, so make sure to use it only in a context where all processors call it the same number of times. </p>

</div>
</div>
<a id="a528645b3631f18c7f84304a85511a54b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a528645b3631f18c7f84304a85511a54b">&#9670;&nbsp;</a></span>this_mpi_process() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::this_mpi_process </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> ID of the calling processor. Cached to have simple access. </p>

</div>
</div>
<a id="a74d37fa18c73e1277afb996827080a4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74d37fa18c73e1277afb996827080a4e">&#9670;&nbsp;</a></span>n_mpi_processes() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_mpi_processes </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the total number of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> processor participating in the given partitioner. Cached to have simple access. </p>

</div>
</div>
<a id="acdd62432c1d0bdec701b79528dab3ef9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdd62432c1d0bdec701b79528dab3ef9">&#9670;&nbsp;</a></span>get_mpi_communicator() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="time__dependent__0_8txt.html#aec4741ed233852c8c3d33ac036f9de89">virtual</a> <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> MPI_Comm&amp; Utilities::MPI::Partitioner::get_mpi_communicator </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Return the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator underlying the partitioner object. </p>

<p>Implements <a class="el" href="classUtilities_1_1MPI_1_1CommunicationPatternBase.html#a678401c284fdbbaa7a896794c417b091">Utilities::MPI::CommunicationPatternBase</a>.</p>

</div>
</div>
<a id="af353fd142ec460dce6e2b3ddf29b1697"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af353fd142ec460dce6e2b3ddf29b1697">&#9670;&nbsp;</a></span>ghost_indices_initialized() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::ghost_indices_initialized </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return whether ghost indices have been explicitly added as a <code>ghost_indices</code> argument. Only true if a <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a895bdd6d93c5bf296c53b39dc3b2248d">reinit()</a> call or constructor provided that argument. </p>

</div>
</div>
<a id="a5138501f56f373ab880ecfb2a8ed876b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5138501f56f373ab880ecfb2a8ed876b">&#9670;&nbsp;</a></span>export_to_ghosted_array_start() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::export_to_ghosted_array_start </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>communication_channel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Start the exportation of the data in a locally owned array to the range described by the ghost indices of this class. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">communication_channel</td><td>Sets an offset to the MPI_Isend and MPI_Irecv calls that avoids interference with other ongoing <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> calls on different entries. Typically handled within the blocks of a block vector. Any value less than 200 is a valid value.</td></tr>
    <tr><td class="paramname">locally_owned_array</td><td>The array of data from which the data is extracted and sent to the ghost entries on a remote processor.</td></tr>
    <tr><td class="paramname">temporary_storage</td><td>A temporary storage array of length <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices()</a> that is used to hold the packed data from the <code>locally_owned_array</code> to be sent. Note that this array must not be touched until the respective <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call has been made because the model uses non-blocking communication. </td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array that will receive the exported data, i.e., the entries that a remote processor sent to the calling process. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. In case only selected indices are sent, no guarantee is made regarding the entries that do not get set. Some of them might be used to organize the transfer and later reset to zero, so make sure you do not use them in computations. </td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that will be finalized in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878">LinearAlgebra::distributed::Vector::update_ghost_values()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab3d760ded3110fb5e4d60d1202147bf0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3d760ded3110fb5e4d60d1202147bf0">&#9670;&nbsp;</a></span>export_to_ghosted_array_finish() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::export_to_ghosted_array_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Finish the exportation of the data in a locally owned array to the range described by the ghost indices of this class. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ghost_array</td><td>The array that will receive the exported data started in the <code><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a></code>. This must be the same array as passed to that function, otherwise the behavior is undefined.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that were started in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a5138501f56f373ab880ecfb2a8ed876b">export_to_ghosted_array_start()</a> call. This must be the same array as passed to that function, otherwise <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> will likely throw an error. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878">LinearAlgebra::distributed::Vector::update_ghost_values()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aca3a9b8e1840bf9539e6335817f1a8fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca3a9b8e1840bf9539e6335817f1a8fa">&#9670;&nbsp;</a></span>import_from_ghosted_array_start() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::import_from_ghosted_array_start </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a>&#160;</td>
          <td class="paramname"><em>vector_operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname"><em>communication_channel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Start importing the data on an array indexed by the ghost indices of this class that is later accumulated into a locally owned array with <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a>.</p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector_operation</td><td>Defines how the data sent to the owner should be combined with the existing entries, e.g., added into. </td></tr>
    <tr><td class="paramname">communication_channel</td><td>Sets an offset to the MPI_Isend and MPI_Irecv calls that avoids interference with other ongoing <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> calls on different entries. Typically handled within the blocks of a block vector. Any value less than 200 is a valid value.</td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array of ghost data that is sent to a remote owner of the respective index in a vector. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. This or the subsequent <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> function, the order is implementation-dependent, will set all data entries behind <code>ghost_array</code> to zero.</td></tr>
    <tr><td class="paramname">temporary_storage</td><td>A temporary storage array of length <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#abf1656017a302e6e2a3ad84625ac63d8">n_import_indices()</a> that is used to hold the packed data from <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication that will later be written into the locally owned array. Note that this array must not be touched until the respective <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a699b46b2256bcb38119b5faac1b242cd">import_from_ghosted_array_finish()</a> call has been made because the model uses non-blocking communication.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that will be finalized in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ab3d760ded3110fb5e4d60d1202147bf0">export_to_ghosted_array_finish()</a> call. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a8a204103e550697467d933388b732bda">LinearAlgebra::distributed::Vector::compress()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a699b46b2256bcb38119b5faac1b242cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a699b46b2256bcb38119b5faac1b242cd">&#9670;&nbsp;</a></span>import_from_ghosted_array_finish() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number , typename MemorySpaceType  = MemorySpace::Host&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::import_from_ghosted_array_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964c">VectorOperation::values</a>&#160;</td>
          <td class="paramname"><em>vector_operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>temporary_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>locally_owned_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="coding__conventions__0_8txt.html#ad54c4de985d6d1b46aaf6ae96ae8d3a1">const</a> <a class="el" href="classArrayView.html">ArrayView</a>&lt; Number, MemorySpaceType &gt; &amp;&#160;</td>
          <td class="paramname"><em>ghost_array</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; <a class="el" href="classMPI__Request.html">MPI_Request</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>requests</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Finish importing the data from an array indexed by the ghost indices of this class into a specified locally owned array, combining the results according to the given input <code>vector_operation</code>. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vector_operation</td><td>Defines how the data sent to the owner should be combined with the existing entries, e.g., added into. </td></tr>
    <tr><td class="paramname">temporary_storage</td><td>The same array given to the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> call that contains the packed data from <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communication. In thus function, it is combined at the corresponding entries described by the ghost relations according to <code>vector_operation</code>.</td></tr>
    <tr><td class="paramname">ghost_array</td><td>The array of ghost data that is sent to a remote owner of the respective index in a vector. Its size must either be <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#a32ffda295e9a5b81ae40359c592a31d9">n_ghost_indices()</a> or equal the number of ghost indices in the larger index set that was given as second argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. This function will set all data entries behind <code>ghost_array</code> to zero for the implementation-dependent cases when it was not already done in the <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aca3a9b8e1840bf9539e6335817f1a8fa">import_from_ghosted_array_start()</a> call. </td></tr>
    <tr><td class="paramname">locally_owned_storage</td><td>The array of data where the resulting data sent by remote processes to the calling process will be accumulated into.</td></tr>
    <tr><td class="paramname">requests</td><td>The list of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> requests for the ongoing non-blocking communication that have been initiated in the import_to_ghosted_array_finish() call. This must be the same array as passed to that function, otherwise <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> will likely throw an error. This functionality is used in <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html#a8a204103e550697467d933388b732bda">LinearAlgebra::distributed::Vector::compress()</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a0f154243f694679910f605359a739fa1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f154243f694679910f605359a739fa1">&#9670;&nbsp;</a></span>memory_consumption() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::size_t Utilities::MPI::Partitioner::memory_consumption </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Compute the memory consumption of this structure. </p>

</div>
</div>
<a id="a77df9bf9b64a44fbb6ad03b0c8f17515"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77df9bf9b64a44fbb6ad03b0c8f17515">&#9670;&nbsp;</a></span>DeclException2() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::DeclException2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__Exceptions.html#gaf6b2aa39da7267d2daceec0d03af4b79">ExcIndexNotPresent</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&lt;&lt; &quot;Global <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> &quot;&lt;&lt; arg1&lt;&lt; &quot; neither <a class="el" href="vector__tools__point__gradient__0_8txt.html#aef5058968290d0a16ef792424d0e1ba2">owned</a> <a class="el" href="chunk__sparsity__pattern__0_8txt.html#a31362234916f6aac38d1392e801099d6">nor</a> ghost <a class="el" href="data__postprocessor__0_8txt.html#a232fd208d0a301873073f51d8474883a">on</a> proc &quot;&lt;&lt; arg2&lt;&lt; &quot;.&quot;&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Exception </p>

</div>
</div>
<a id="a56ebf907bcd8ef8506a7ded78ed9db70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56ebf907bcd8ef8506a7ded78ed9db70">&#9670;&nbsp;</a></span>DeclException3() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Utilities::MPI::Partitioner::DeclException3 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__Exceptions.html#ga293b358739542847d88c8cd447f9adc7">ExcGhostIndexArrayHasWrongSize</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&lt;&lt; &quot;The <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> ghost <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a> <a class="el" href="matrix__free_2dof__info__0_8txt.html#a597165203ae66b8aa2d96f3bd238b626">array</a> (&quot;&lt;&lt; arg1&lt;&lt; &quot;) must <a class="el" href="grid_2manifold__0_8txt.html#a9dc1c289073d97c27ef2fd7d201521c5">either</a> equal <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> <a class="el" href="generators__0_8txt.html#a52d07c1744d923546e9cafc255f70465">number</a> <a class="el" href="copy__data__0_8txt.html#ad2652187ccefa4786a264b05b284b040">of</a> ghost <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="vector__tools__project__0_8txt.html#a0f636bbf8ef44dc0f3b278cf16adb0a7">the</a> &quot;&lt;&lt; &quot;<a class="el" href="base_2partitioner__0_8txt.html#a936b2264a337bdb80dd12b8f90f72767">partitioner</a> (&quot;&lt;&lt; arg2&lt;&lt; &quot;) or <a class="el" href="tria__iterator__0_8txt.html#ae2c744f7850c09a43eafeafedf8e2619">be</a> equal <a class="el" href="tria__description__0_8txt.html#a11901ff80013804497fa645646431eae">in</a> <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#ad3b457f661fec81683f5893a252ee8f3">size</a> <a class="el" href="error__estimator__0_8txt.html#a4ec80ded5cb4f47bcabf0a970c68075b">to</a> <a class="el" href="vector__tools__constraints__0_8txt.html#a5bb8955c98135fbb60012ceeee4b7839">a</a> <a class="el" href="petsc__matrix__base__0_8txt.html#a91d0bc46add3efe5a167829805522d28">more</a> comprehensive <a class="el" href="scalapack__0_8txt.html#abc6ecee32660d1fa6d6157325220179a">index</a>&quot;&lt;&lt; &quot;<a class="el" href="histogram__0_8txt.html#a1f28b62a413a3352bc54e62ef004750e">set</a> <a class="el" href="function__restriction__0_8txt.html#a79f2798b238440d7e1841d2cf4711885">which</a> contains &quot;&lt;&lt; arg3&lt;&lt; &quot; elements <a class="el" href="chunk__sparse__matrix__0_8txt.html#aae7ed603ea40c1e6a20bb18bab713802">for</a> <a class="el" href="data__postprocessor__0_8txt.html#a600bd43d5bd41af065e85ec3e40fed92">this</a> partitioner.&quot;&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Exception </p>

</div>
</div>
<a id="a7fcae5500056427795b8ed84b5a4c102"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fcae5500056427795b8ed84b5a4c102">&#9670;&nbsp;</a></span>initialize_import_indices_plain_dev() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::Partitioner::initialize_import_indices_plain_dev </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Initialize import_indices_plain_dev from import_indices_data. This function is only used when using CUDA-aware <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a85a845b1a3a1a35329cd57858dd2f2d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85a845b1a3a1a35329cd57858dd2f2d3">&#9670;&nbsp;</a></span>global_size</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> Utilities::MPI::Partitioner::global_size</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The global size of the vector over all processors </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00553">553</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="ae8f254459fe6567b5af38251183195d2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8f254459fe6567b5af38251183195d2">&#9670;&nbsp;</a></span>locally_owned_range_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classIndexSet.html">IndexSet</a> Utilities::MPI::Partitioner::locally_owned_range_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The range of the vector that is stored locally. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00559">559</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a12bdc30aa3e8e4bfb06d44f75e1fd4cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12bdc30aa3e8e4bfb06d44f75e1fd4cb">&#9670;&nbsp;</a></span>local_range_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt; <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a>, <a class="el" href="namespacetypes.html#a3bf9e493f1aab00b04933b81856144c4">types::global_dof_index</a> &gt; Utilities::MPI::Partitioner::local_range_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The range of the vector that is stored locally. Extracted from locally_owned_range for performance reasons. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00567">567</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a2bb56a6841a8bdd7a4cae72c475ccb0c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2bb56a6841a8bdd7a4cae72c475ccb0c">&#9670;&nbsp;</a></span>ghost_indices_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classIndexSet.html">IndexSet</a> Utilities::MPI::Partitioner::ghost_indices_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The set of indices to which we need to have read access but that are not locally owned </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00574">574</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a081b8efe1732c2d9d1270a96f09a0649"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a081b8efe1732c2d9d1270a96f09a0649">&#9670;&nbsp;</a></span>n_ghost_indices_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_ghost_indices_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>A variable caching the number of ghost indices. It would be expensive to use <code>ghost_indices.n_elements()</code> to compute this. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00581">581</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a5057fe3b10bb594c40186eb04867da1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5057fe3b10bb594c40186eb04867da1f">&#9670;&nbsp;</a></span>ghost_targets_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; Utilities::MPI::Partitioner::ghost_targets_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>An array that contains information which processors my ghost indices belong to and how many those indices are </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00588">588</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="ae42fc9926ca45956f0f04a63c1a78ef2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae42fc9926ca45956f0f04a63c1a78ef2">&#9670;&nbsp;</a></span>import_indices_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; Utilities::MPI::Partitioner::import_indices_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The set of (local) indices that we are importing during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a>, i.e., others' ghosts that belong to the local range. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a>, but tailored to be iterated over, and some indices may be duplicates. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00597">597</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="af06ca101e89a75949b170d2a974bc134"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af06ca101e89a75949b170d2a974bc134">&#9670;&nbsp;</a></span>import_indices_plain_dev</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; std::unique_ptr&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>[], void(*)(unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> *)&gt;, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; Utilities::MPI::Partitioner::import_indices_plain_dev</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">mutable</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The set of (local) indices that we are importing during <a class="el" href="namespaceUtilities.html#a6155277fd058eddb1504f9562cb1c04d">compress()</a>, i.e., others' ghosts that belong to the local range. The data stored is the same than in import_indices_data but the data is expanded in plain arrays. This variable is only used when using CUDA-aware <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00613">613</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a9c703b3ffe07bcd100c18150ba4905f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c703b3ffe07bcd100c18150ba4905f5">&#9670;&nbsp;</a></span>n_import_indices_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_import_indices_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>A variable caching the number of ghost indices. It would be expensive to compute it by iterating over the import indices and accumulate them. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00621">621</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a87957a3a9a52461f35e1f0d4e0b408fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87957a3a9a52461f35e1f0d4e0b408fa">&#9670;&nbsp;</a></span>import_targets_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; Utilities::MPI::Partitioner::import_targets_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The set of processors and length of data field which send us their ghost data </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00628">628</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="aa0ee2c8587e16577e3714a38340c1650"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0ee2c8587e16577e3714a38340c1650">&#9670;&nbsp;</a></span>import_indices_chunks_by_rank_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; Utilities::MPI::Partitioner::import_indices_chunks_by_rank_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>An array that caches the number of chunks in the import indices per <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> rank. The length is import_indices_data.size()+1. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00635">635</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a315cff6dd3f734cacb37d4841c2eafb2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a315cff6dd3f734cacb37d4841c2eafb2">&#9670;&nbsp;</a></span>n_ghost_indices_in_larger_set</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_ghost_indices_in_larger_set</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>A variable caching the number of ghost indices in a larger set of indices given by the optional argument to <a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html#aa05cff1b3f359e104d4d533e0d245f0f">set_ghost_indices()</a>. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00642">642</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="afc19ad6f939ea9ebb7019f9ed29bf253"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc19ad6f939ea9ebb7019f9ed29bf253">&#9670;&nbsp;</a></span>ghost_indices_subset_chunks_by_rank_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; Utilities::MPI::Partitioner::ghost_indices_subset_chunks_by_rank_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>An array that caches the number of chunks in the import indices per <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> rank. The length is ghost_indices_subset_data.size()+1. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00649">649</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a8abdd13ff6bb523def59c1286c6c2bb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8abdd13ff6bb523def59c1286c6c2bb9">&#9670;&nbsp;</a></span>ghost_indices_subset_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="kinsol__0_8txt.html#ab19f5518dcad7cebd9aa51c8bc219a22">std::vector</a>&lt; std::pair&lt; unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a>, unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> &gt; &gt; Utilities::MPI::Partitioner::ghost_indices_subset_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The set of indices that appear for an <a class="el" href="classIndexSet.html">IndexSet</a> that is a subset of a larger set. Similar structure as in an <a class="el" href="classIndexSet.html">IndexSet</a> within all ghost indices, but tailored to be iterated over. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00658">658</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a44b1f9588ac9b0726e0220c28956ac71"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44b1f9588ac9b0726e0220c28956ac71">&#9670;&nbsp;</a></span>my_pid</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::my_pid</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The ID of the current processor in the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> network </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00664">664</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a5108af9f395f821b0bb6ae2edf827ba7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5108af9f395f821b0bb6ae2edf827ba7">&#9670;&nbsp;</a></span>n_procs</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="matrix__free__0_8txt.html#afdb878b17ab7df395a1435ac49d661fc">int</a> Utilities::MPI::Partitioner::n_procs</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The total number of processors active in the problem </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00670">670</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a00c7935cfbc45bf05e54b804302d20af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00c7935cfbc45bf05e54b804302d20af">&#9670;&nbsp;</a></span>communicator</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">MPI_Comm Utilities::MPI::Partitioner::communicator</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>The <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator involved in the problem </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00676">676</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<a id="a3bd49ebeaff5cb40ec119a6d47152946"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3bd49ebeaff5cb40ec119a6d47152946">&#9670;&nbsp;</a></span>have_ghost_indices</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="hdf5__0_8txt.html#ab2d1d1742a4bbf5eb3519d1b615183fe">bool</a> Utilities::MPI::Partitioner::have_ghost_indices</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>A variable storing whether the ghost indices have been explicitly set. </p>

<p class="definition">Definition at line <a class="el" href="base_2partitioner_8h_source.html#l00683">683</a> of file <a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/deal.II/base/<a class="el" href="base_2partitioner_8h_source.html">partitioner.h</a></li>
<li>source/base/<a class="el" href="partitioner_8cc_source.html">partitioner.cc</a></li>
</ul>
</div><!-- contents -->
<!-- HTML footer for doxygen 1.8.17-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
