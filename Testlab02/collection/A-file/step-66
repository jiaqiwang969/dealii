examples/step-66/doc/intro.dox
<br>

<i>
This program was contributed by Fabian Castelli.

A version of this code was presented and discussed in
@cite castelli2021numerical
G.F. Castelli: Numerical Investigation of Cahn-Hilliard-Type Phase-Field
Models for Battery Active Particles, PhD thesis, Karlsruhe Institute of
Technology (KIT), 2021. (To be published)

Fabian Castelli acknowledges financial support by the German Research
Foundation (DFG) through the Research Training Group 2218 SiMET -- Simulation
of mechano-electro-thermal processes in lithium-ion batteries, project number
281041241.

Finally Fabian Castelli would like to thank Timo Heister for the encouragement
and advice in writing this tutorial.
</i>


<a name="Intro"></a>
<h1>Introduction</h1>

The aim of this tutorial program is to demonstrate how to solve a nonlinear
problem using Newton's method within the matrix-free framework. This tutorial
combines several techniques already introduced in step-15, step-16, step-37,
step-48 and others.


<h3>Problem formulation</h3>
On the unit circle $\Omega = \bigl\{ x \in \mathbb{R}^2 : \|x\| \leq 1 \bigr\}$
we consider the following nonlinear elliptic boundary value problem subject to a
homogeneous Dirichlet boundary condition: Find a function
$u\colon\Omega\to\mathbb{R}$ such that it holds:
@f{align*}
    - \Delta u &= \exp(u) & \quad & \text{in } \Omega,\\
             u &= 0       & \quad & \text{on } \partial\Omega.
@f}
This problem is also called the <i>Gelfand problem</i> and is a typical example
for problems from combustion theory, see for example
@cite bebernes1989mathematical.


<h3>Discretization with finite elements</h3>
As usual, we first derive the weak formulation for this problem by multiplying
with a smooth test function $v\colon\Omega\to\mathbb{R}$ respecting the
boundary condition and integrating over the domain $\Omega$. Integration by
parts and putting the term from the right hand side to the left yields the weak
formulation: Find a function $u\colon\Omega\to\mathbb{R}$ such that for all
test functions $v$ it holds:
@f{align*}{
 \int_\Omega \nabla v \cdot \nabla u \,\mathrm{d}x
 -
 \int_\Omega v \exp(u) \,\mathrm{d}x
 =
 0.
@f}

Choosing the Lagrangian finite element space $V_h \dealcoloneq
\bigl\{ v \in C(\overline{\Omega}) : v|_Q \in \mathbb{Q}_p \text{ for all }
Q \in \mathcal{T}_h \bigr\} \cap H_0^1(\Omega)$, which directly incorporates
the homogeneous Dirichlet boundary condition, we can define a basis
$\{\varphi_i\}_{i=1,\dots,N}$ and thus it suffices to test only with those
basis functions. So the discrete problem reads as follows: Find $u_h\in V_h$
such that for all $i=1,\dots,N$ it holds:
@f{align*}{
 F(u_h)
 \dealcoloneq
 \int_\Omega \nabla \varphi_i \cdot \nabla u_h \,\mathrm{d}x
 -
 \int_\Omega \varphi_i \exp(u_h) \,\mathrm{d}x \stackrel{!}{=} 0.
@f}
As each finite element function is a linear combination of the basis functions
$\{\varphi_i\}_{i=1,\dots,N}$, we can identify the finite element solution by
a vector from $\mathbb{R}^N$ consisting of the unknown values in each degree of
freedom (DOF). Thus, we define the nonlinear function
$F\colon\mathbb{R}^N\to\mathbb{R}^N$ representing the discrete nonlinear
problem.

To solve this nonlinear problem we use Newton's method. So given an
initial guess $u_h^0\in V_h$, which already fulfills the Dirichlet boundary
condition, we determine a sequence of Newton steps $\bigl( u_h^n \bigr)_n$ by
successively applying the following scheme:
@f{align*}{
 &\text{Solve for } s_h^n\in V_h: \quad & F'(u_h^n)[s_h^n] &= -F(u_h^n),\\
 &\text{Update: }                       & u_h^{n+1} &= u_h^n + s_h^n.
@f}
So in each Newton step we have to solve a linear problem $A\,x = b$, where the
system matrix $A$ is represented by the Jacobian
$F'(u_h^n)[\,\cdot\,]\colon\mathbb{R}^N\to\mathbb{R}^N$ and the right hand side
$b$ by the negative residual $-F(u_h^n)$. The solution vector $x$ is in that
case the Newton update of the $n$-th Newton step. Note, that we assume an
initial guess $u_h^0$, which already fulfills the Dirichlet boundary conditions
of the problem formulation (in fact this could also be an inhomogeneous
Dirichlet boundary condition) and thus the Newton updates $s_h$ satisfy a
homogeneous Dirichlet condition.

Until now we only tested with the basis functions, however, we can also
represent any function of $V_h$ as linear combination of basis functions. More
mathematically this means, that every element of $V_h$ can be
identified with a vector $U\in\mathbb{R}^N$ via the representation formula:
$u_h = \sum_{i=1}^N U_i \varphi_i$. So using this we can give an expression for
the discrete Jacobian and the residual:
@f{align*}{
 A_{i,j} = \bigl( F'(u_h^n) \bigr)_{i,j}
 &=
 \int_\Omega \nabla\varphi_i \cdot \nabla \varphi_j \,\mathrm{d} x
 -
 \int_\Omega \varphi_i \, \exp( u_h ) \varphi_j \,\mathrm{d} x,\\
 b_{i} = \bigl( F(u_h^n) \bigr)_{i}
 &=
 \int_\Omega \nabla\varphi_i \cdot \nabla u_h^n \,\mathrm{d} x
 -
 \int_\Omega \varphi_i \, \exp( u_h^n ) \,\mathrm{d} x.
@f}
Compared to step-15 we could also have formed the Frech{\'e}t derivative of the
nonlinear function corresponding to the strong formulation of the problem and
discretized it afterwards. However, in the end we would get the same set of
discrete equations.


<h3>Numerical linear algebra</h3>
Note, how the system matrix, actually the Jacobian, depends on the previous
Newton step $A = F'(u^n)$. Hence we need to tell the function that computes
the system matrix about the solution at the last Newton step. In an
implementation with a classical <code>assemble_system()</code> function we
would gather this information from the last Newton step during assembly by the
use of the member functions FEValuesBase::get_function_values() and
FEValuesBase::get_function_gradients(). The <code>assemble_system()</code>
function would then looks like:
@code
template <int dim>
void GelfandProblem<dim>::assemble_system()
{
  system_matrix = 0;
  system_rhs    = 0;

  const QGauss<dim> quadrature_formula(fe.degree + 1);
  FEValues<dim>     fe_values(fe,
                          quadrature_formula,
                          update_values | update_gradients | update_JxW_values);

  const unsigned int n_q_points    = fe_values.n_quadrature_points;
  const unsigned int dofs_per_cell = fe_values.dofs_per_cell;

  FullMatrix<double>                   cell_matrix(dofs_per_cell);
  Vector<double>                       cell_rhs(dofs_per_cell);
  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);

  std::vector<Tensor<1, dim>> newton_step_gradients(n_q_points);
  std::vector<double>         newton_step_values(n_q_points);


  for (const auto &cell : dof_handler.active_cell_iterators())
    {
      cell_matrix = 0.0;
      cell_rhs    = 0.0;

      fe_values.reinit(cell);

      fe_values.get_function_values(solution, newton_step_values);
      fe_values.get_function_gradients(solution, newton_step_gradients);

      for (unsigned int q = 0; q < n_q_points; ++q)
        {
          const double nonlinearity = std::exp(newton_step_values[q]);
          const double dx           = fe_values.JxW(q);

          for (unsigned int i = 0; i < dofs_per_cell; ++i)
            {
              const double         phi_i      = fe_values.shape_value(i, q);
              const Tensor<1, dim> grad_phi_i = fe_values.shape_grad(i, q);

              for (unsigned int j = 0; j < dofs_per_cell; ++j)
                {
                  const double         phi_j      = fe_values.shape_value(j, q);
                  const Tensor<1, dim> grad_phi_j = fe_values.shape_grad(j, q);

                  cell_matrix(i, j) +=
                    (grad_phi_i * grad_phi_j - phi_i * nonlinearity * phi_j) *
                    dx;
                }

              cell_rhs(i) += (-grad_phi_i * newton_step_gradients[q] +
                              phi_i * newton_step_values[q]) *
                             dx;
            }
        }

      cell->get_dof_indices(local_dof_indices);

      constraints.distribute_local_to_global(
        cell_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);
    }
}
@endcode

Since we want to solve this problem without storing a matrix, we need to tell
the matrix-free operator this information before we use it. Therefore in the
derived class <code>JacobianOperator</code> we will implement a function
called <code>evaluate_newton_step</code>, which will process the information of
the last Newton step prior to the usage of the matrix-vector implementation.
Furthermore we want to use a geometric multigrid (GMG) preconditioner for the
linear solver, so in order to apply the multilevel operators we need to pass the
last Newton step also to these operators. This is kind of a tricky task, since
the vector containing the last Newton step has to be interpolated to all levels
of the triangulation. In the code this task will be done by the function
MGTransferMatrixFree::interpolate_to_mg(). Note, a fundamental difference to
the previous cases, where we set up and used a geometric multigrid
preconditioner, is the fact, that we can reuse the MGTransferMatrixFree object
for the computation of all Newton steps. So we can save some work here by
defining a class variable and using an already set up MGTransferMatrixFree
object <code>mg_transfer</code> that was initialized in the
<code>setup_system()</code> function.
@code
template <int dim, int fe_degree>
void GelfandProblem<dim, fe_degree>::compute_update()
{
  TimerOutput::Scope t(computing_timer, "compute update");

  solution.update_ghost_values();

  system_matrix.evaluate_newton_step(solution);

  mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);


  // Set up options for the multilevel preconditioner
  // ...

  for (unsigned int level = 0; level < triangulation.n_global_levels(); ++level)
    {
      mg_matrices[level].evaluate_newton_step(mg_solution[level]);
    }

  // Define the actual preconditioner
  // ...

  // Solve the linear system
  // ...
}
@endcode

The function evaluating the nonlinearity works basically in the same way as the
function <code>evaluate_coefficient</code> from step-37 evaluating a coefficient
function. The idea is to use an FEEvaluation object to evaluate the Newton step
and store the expression in a table for all cells and all quadrature points:
@code
template <int dim, int fe_degree, typename number>
void JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(
  const LinearAlgebra::distributed::Vector<number> &newton_step)
{
  const unsigned int n_cells = this->data->n_cell_batches();

  FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi(*this->data);

  nonlinear_values.reinit(n_cells, phi.n_q_points);

  for (unsigned int cell = 0; cell < n_cells; ++cell)
    {
      phi.reinit(cell);
      phi.read_dof_values_plain(newton_step);
      phi.evaluate(EvaluationFlags::values);

      for (unsigned int q = 0; q < phi.n_q_points; ++q)
        {
          nonlinear_values(cell, q) = std::exp(phi.get_value(q));
        }
    }
}
@endcode


<h3>Triangulation</h3>
As said in step-37 the matrix-free method gets more efficient if we choose a
higher order finite element space. Since we want to solve the problem on the
$d$-dimensional unit ball, it would be good to have an appropriate boundary
approximation to overcome convergence issues. For this reason we use an
isoparametric approach with the MappingQGeneric class to recover the smooth
boundary as well as the mapping for inner cells. In addition, to get a good
triangulation in total we make use of the TransfiniteInterpolationManifold.


examples/step-66/doc/results.dox
<h1>Results</h1>

The aim of this tutorial step was to demonstrate the solution of a nonlinear
PDE with the matrix-free framework.



<h3>Program output</h3>
Running the program on two processes in release mode via
@code
cmake . && make release && make && mpirun -n 2 ./step-66
@endcode
gives the following output on the console
@code
================================================================================
START DATE: 2021/5/18, TIME: 16:25:48
--------------------------------------------------------------------------------
Running with 2 MPI processes
Vectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2
Finite element space: FE_Q<2>(4)
================================================================================
--------------------------------------------------------------------------------
Cycle 0
--------------------------------------------------------------------------------
Set up system...
   Triangulation: 20 cells
   DoFHandler:    337 DoFs

Solve using Newton's method...
   Nstep 1, errf = 0.00380835, errx = 3.61904, it = 7
   Nstep 2, errf = 3.80167e-06, errx = 0.104353, it = 6
   Nstep 3, errf = 3.97939e-12, errx = 0.00010511, it = 4
   Nstep 4, errf = 2.28859e-13, errx = 1.07726e-10, it = 1
Convergence step 4 value 2.28859e-13 (used wall time: 0.0096409 s)

Time for setup+solve (CPU/Wall) 0.015617/0.0156447 s

Output results...
  H1 seminorm: 0.773426



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |    0.0286s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assemble right hand side        |         4 |  9.71e-05s |      0.34% |
| compute residual                |         4 |  0.000137s |      0.48% |
| compute update                  |         4 |   0.00901s |        32% |
| make grid                       |         1 |   0.00954s |        33% |
| setup system                    |         1 |   0.00585s |        20% |
| solve                           |         1 |   0.00966s |        34% |
+---------------------------------+-----------+------------+------------+

.
.
.

--------------------------------------------------------------------------------
Cycle 6
--------------------------------------------------------------------------------
Set up system...
   Triangulation: 81920 cells
   DoFHandler:    1311745 DoFs

Solve using Newton's method...
   Nstep 1, errf = 5.90478e-05, errx = 231.427, it = 9
   Nstep 2, errf = 5.89991e-08, errx = 6.67102, it = 6
   Nstep 3, errf = 4.28813e-13, errx = 0.0067188, it = 4
Convergence step 3 value 4.28813e-13 (used wall time: 4.82953 s)

Time for setup+solve (CPU/Wall) 6.25094/6.37174 s

Output results...
  H1 seminorm: 0.773426



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      9.04s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assemble right hand side        |         3 |    0.0827s |      0.91% |
| compute residual                |         3 |    0.0909s |         1% |
| compute update                  |         3 |      4.65s |        51% |
| setup system                    |         1 |      1.54s |        17% |
| solve                           |         1 |      4.83s |        53% |
+---------------------------------+-----------+------------+------------+

================================================================================
START DATE: 2021/5/18, TIME: 16:26:00
--------------------------------------------------------------------------------
Running with 2 MPI processes
Vectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2
Finite element space: FE_Q<3>(4)
================================================================================

.
.
.

--------------------------------------------------------------------------------
Cycle 5
--------------------------------------------------------------------------------
Set up system...
   Triangulation: 229376 cells
   DoFHandler:    14729857 DoFs

Solve using Newton's method...
   Nstep 1, errf = 6.30096e-06, errx = 481.74, it = 8
   Nstep 2, errf = 4.25607e-10, errx = 4.14315, it = 6
   Nstep 3, errf = 7.29563e-13, errx = 0.000321775, it = 2
Convergence step 3 value 7.29563e-13 (used wall time: 133.793 s)

Time for setup+solve (CPU/Wall) 226.809/232.615 s

Output results...
  H1 seminorm: 0.588667



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |       390s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assemble right hand side        |         3 |      2.06s |      0.53% |
| compute residual                |         3 |      2.46s |      0.63% |
| compute update                  |         3 |       129s |        33% |
| setup system                    |         1 |      98.8s |        25% |
| solve                           |         1 |       134s |        34% |
+---------------------------------+-----------+------------+------------+
@endcode

We show the solution for the two- and three-dimensional problem in the
following figure.

<div class="twocolumn" style="width: 80%; text-align: center;">
  <div>
    <img src = "https://www.dealii.org/images/steps/developer/step-66.solution-2d.png"
     alt     = "Solution of the two-dimensional Gelfand problem."
     width   = "100%">
  </div>
  <div>
    <img src = "https://www.dealii.org/images/steps/developer/step-66.solution-3d.png"
     alt     = "Solution of the three-dimensional Gelfand problem."
     width   = "100%">
  </div>
</div>



<h3>Newton solver</h3>
In the program output above we find some interesting information about the
Newton iterations. The terminal output in each refinement cycle presents
detailed diagnostics of the Newton method, which show first of all the number
of Newton steps and for each step the norm of the residual $\|F(u_h^{n+1})\|$,
the norm of the Newton update $\|s_h^n\|$, and the number of CG iterations
<code>it</code>.

We observe that for all cases the Newton method converges in approximately
three to four steps, which shows the quadratic convergence of the Newton method
with a full step length $\alpha = 1$. However, be aware that for a badly chosen
initial guess $u_h^0$, the Newton method will also diverge quadratically.
Usually if you do not have an appropriate initial guess, you try a few damped
Newton steps with a reduced step length $\alpha < 1$ until the Newton step is
again in the quadratic convergence domain. This damping and relaxation of the
Newton step length truly requires a more sophisticated implementation of the
Newton method, which we designate to you as a possible extension of the
tutorial.

Furthermore, we see that the number of CG iterations is approximately constant
with successive mesh refinements and an increasing number of DoFs. This is of
course due to the geometric multigrid preconditioner and similar to the
observations made in other tutorials that use this method, e.g., step-16 and
step-37. Just to give an example, in the three-dimensional case after five
refinements, we have approximately 14.7 million distributed DoFs with
fourth-order Lagrangian finite elements, but the number of CG iterations is
still less than ten.

In addition, there is one more very useful optimization that we applied and
that should be mentioned here. In the <code>compute_update()</code> function we
explicitly reset the vector holding the Newton update before passing it as the
output vector to the solver. In that case we use a starting value of zero for
the CG method, which is more suitable than the previous Newton update, the
actual content of the <code>newton_update</code> before resetting, and thus
reduces the number of CG iterations by a few steps.



<h3>Possibilities for extensions</h3>
A couple of possible extensions are available concerning minor updates fo the
present code as well as a deeper numerical investigation of the Gelfand problem.

<h4>More sophisticated Newton iteration</h4>
Beside a step size controlled version of the Newton iteration as mentioned
already in step-15, one could also implement a more flexible stopping criterion
for the Newton iteration. For example one could replace the fixed tolerances
for the residual <code>TOLf</code> and for the Newton updated <code>TOLx</code>
and implement a mixed error control with a given absolute and relative
tolerance, such that the Newton iteration exists with success as, e.g.,
@f{align*}{
  \|F(u_h^{n+1})\| \leq \texttt{RelTol} \|u_h^{n+1}\| + \texttt{AbsTol}.
@f}
For more advanced applications with many nonlinear systems to solve, for
example at each time step for a time-dependent problem, it turns out that it is
not necessary to set up and assemble the Jacobian anew at every single Newton
step or even for each time step. Instead, the existing Jacobian from a previous
step can be used for the Newton iteration. The Jacobian is then only rebuilt
if, for example, the Newton iteration converges too slowly. Such an idea yields
a <a href="https://en.wikipedia.org/wiki/Quasi-Newton_method">quasi-Newton
method</a>. Admittedly, when using the matrix-free framework, the assembly of
the Jacobian is omitted anyway, but with in this way one can try to optimize
the reassembly of the geometric multigrid preconditioner. Remember that each
time the solution from the old Newton step must be distributed to all levels
and the mutligrid preconditioner must be reinitialized.

<h4>Parallel scalability and thread parallelism</h4>
In the results section of step-37 and others, the parallel scalability of the
matrix-free framework on a large number of processors has already been
demonstrated very impressively. In the nonlinear case we consider here, we note
that one of the bottlenecks could become the transfer and evaluation of the
matrix-free Jacobi operator and its multistage operators in the previous Newton
step, since we need to transfer the old solution at all stages in each step. A
first parallel scalability analysis in @cite castelli2021numerical shows quite
good strong scalability when the problem size is large enough. However, a more
detailed analysis needs to be performed for reliable results. Moreover, the
problem has been solved only with MPI so far, without using the possibilities
of shared memory parallelization with threads. Therefore, for this example, you
could try hybrid parallelization with MPI and threads, such as described in
step-48.

<h4>Comparison to matrix-based methods</h4>
Analogously to step-50 and the mentioned possible extension of step-75, you can
convince yourself which method is faster.

<h4>Eigenvalue problem</h4>
One can consider the corresponding eigenvalue problem, which is called Bratu
problem. For example, if we define a fixed eigenvalue $\lambda\in[0,6]$, we can
compute the corresponding discrete eigenfunction. You will notice that the
number of Newton steps will increase with increasing $\lambda$. To reduce the
number of Newton steps you can use the following trick: start from a certain
$\lambda$, compute the eigenfunction, increase $\lambda=\lambda +
\delta_\lambda$, and then use the previous solution as an initial guess for the
Newton iteration. In the end you can plot the $H^1(\Omega)$-norm over the
eigenvalue $\lambda \mapsto \|u_h\|_{H^1(\Omega)}$. What do you observe for
further increasing $\lambda>7$?


