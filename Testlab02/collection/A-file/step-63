examples/step-63/doc/intro.dox
<br>

<i>This program was contributed by Thomas C. Clevenger and Timo Heister.

The creation of this tutorial was partially supported by NSF Award
DMS-1522191, DMS-1901529, OAC-1835452, by the Computational
Infrastructure in Geodynamics initiative (CIG), through the NSF under
Award EAR-0949446 and EAR-1550901 and The University of California -
Davis.
</i>

@dealiiTutorialDOI{10.5281/zenodo.3382899,https://zenodo.org/badge/DOI/10.5281/zenodo.3382899.svg}

<a name="Intro"></a>
<h1>Introduction</h1>

This program solves an advection-diffusion problem using a geometric multigrid
(GMG) preconditioner. The basics of this preconditioner are discussed in step-16;
here we discuss the necessary changes needed for a non-symmetric
PDE. Additionally, we introduce the idea of block smoothing (as compared to
point smoothing in step-16), and examine the effects of DoF renumbering for
additive and multiplicative smoothers.

<h3>Equation</h3>
The advection-diffusion equation is given by
@f{align*}{
-\varepsilon \Delta u + \boldsymbol{\beta}\cdot \nabla u & = f &
\text{ in } \Omega\\
u &= g & \text{ on } \partial\Omega
@f}
where $\varepsilon>0$, $\boldsymbol{\beta}$ is the <i>advection
direction</i>, and $f$ is a source. A few notes:

1. If $\boldsymbol{\beta}=\boldsymbol{0}$, this is the Laplace equation solved in step-16
(and many other places).

2. If $\varepsilon=0$ then this is the stationary advection equation solved in
step-9.

3. One can define a dimensionless number for this problem, called the
<i>Peclet number</i>: $\mathcal{P} \dealcoloneq \frac{\|\boldsymbol{\beta}\|
L}{\varepsilon}$, where $L$ is the length scale of the domain. It
characterizes the kind of equation we are
considering: If $\mathcal{P}>1$, we say the problem is
<i>advection-dominated</i>, else if $\mathcal{P}<1$ we will say the problem is
<i>diffusion-dominated</i>.

For the discussion in this tutorial we will be concerned with
advection-dominated flow. This is the complicated case: We know that
for diffusion-dominated problems, the standard Galerkin method works
just fine, and we also know that simple multigrid methods such as
those defined in step-16 are very efficient. On the other hand, for
advection-dominated problems, the standard Galerkin approach leads to
oscillatory and unstable discretizations, and simple solvers are often
not very efficient. This tutorial program is therefore intended to
address both of these issues.


<h4>Streamline diffusion</h4>

Using the standard Galerkin finite element method, for suitable test
functions $v_h$, a discrete weak form of the PDE would read
@f{align*}{
a(u_h,v_h) = F(v_h)
@f}
where
@f{align*}{
a(u_h,v_h) &= (\varepsilon \nabla v_h,\, \nabla u_h) +
(v_h,\,\boldsymbol{\beta}\cdot \nabla u_h),\\
F(v_h) &= (v_h,\,f).
@f}

Unfortunately, one typically gets oscillatory solutions with this
approach. Indeed, the following error estimate can be shown for this
formulation:
@f{align*}{
\|\nabla (u-u_h)\| \leq (1+\mathcal{P}) \inf_{v_h} \|\nabla (u-v_h)\|.
@f}
The infimum on the right can be estimated as follows if the exact
solution is sufficiently smooth:
@f{align*}{
  \inf_{v_h} \|\nabla (u-v_h)\|.
  \le
  \|\nabla (u-I_h u)\|
  \le
  h^k
  C
  \|\nabla^k u)\|
@f}
where $k$ is the polynomial degree of the finite elements used. As a
consequence, we obtain the estimate
@f{align*}{
\|\nabla (u-u_h)\|
\leq (1+\mathcal{P}) C h^k
  \|\nabla^k u)\|.
@f}
In other words, the numerical solution will converge. On the other hand,
given the definition of $\mathcal{P}$ above, we have to expect poor
numerical solutions with a large error when $\varepsilon \ll
\|\boldsymbol{\beta}\| L$, i.e., if the problem has only a small
amount of diffusion.

To combat this, we will consider the new weak form
@f{align*}{
a(u_h,\,v_h) + \sum_K (-\varepsilon \Delta u_h +
\boldsymbol{\beta}\cdot \nabla u_h-f,\,\delta_K
\boldsymbol{\beta}\cdot \nabla v_h)_K = F(v_h)
@f}
where the sum is done over all cells $K$ with the inner product taken
for each cell, and $\delta_K$ is a cell-wise constant
stabilization parameter defined in
@cite john2006discontinuity.

Essentially, adding in the
discrete strong form residual enhances the coercivity of the bilinear
form $a(\cdot,\cdot)$ which increases the stability of the discrete
solution. This method is commonly referred to as <i>streamline
diffusion</i> or <i>SUPG</i> (streamline upwind/Petrov-Galerkin).


<h3>Smoothers</h3>

One of the goals of this tutorial is to expand from using a simple
(point-wise) Gauss-Seidel (SOR) smoother that is used in step-16
(class PreconditionSOR) on each level of the multigrid hierarchy.
The term "point-wise" is traditionally used in solvers to indicate that one
solves at one "grid point" at a time; for scalar problems, this means
to use a solver that updates one unknown of the linear
system at a time, keeping all of the others fixed; one would then
iterate over all unknowns in the problem and, once done, start over again
from the first unknown until these "sweeps" converge. Jacobi,
Gauss-Seidel, and SOR iterations can all be interpreted in this way.
In the context of multigrid, one does not think of these methods as
"solvers", but as "smoothers". As such, one is not interested in
actually solving the linear system. It is enough to remove the high-frequency
part of the residual for the multigrid method to work, because that allows
restricting the solution to a coarser mesh.  Therefore, one only does a few,
fixed number of "sweeps" over all unknowns. In the code in this
tutorial this is controlled by the "Smoothing steps" parameter.

But these methods are known to converge rather slowly when used as
solvers. While as multigrid smoothers, they are surprisingly good,
they can also be improved upon. In particular, we consider
"cell-based" smoothers here as well. These methods solve for all
unknowns on a cell at once, keeping all other unknowns fixed; they
then move on to the next cell, and so on and so forth. One can think
of them as "block" versions of Jacobi, Gauss-Seidel, or SOR, but
because degrees of freedom are shared among multiple cells, these
blocks overlap and the methods are in fact
best be explained within the framework of additive and multiplicative
Schwarz methods.

In contrast to step-16, our test problem contains an advective
term. Especially with a small diffusion constant $\varepsilon$, information is
transported along streamlines in the given advection direction. This means
that smoothers are likely to be more effective if they allow information to
travel in downstream direction within a single smoother
application. If we want to solve one unknown (or block of unknowns) at
a time in the order in which these unknowns (or blocks) are
enumerated, then this information propagation property
requires reordering degrees of freedom or cells (for the cell-based smoothers)
accordingly so that the ones further upstream are treated earlier
(have lower indices) and those further downstream are treated later
(have larger indices). The influence of the ordering will be visible
in the results section.

Let us now briefly define the smoothers used in this tutorial.
For a more detailed introduction, we refer to
@cite KanschatNotesIterative and the books @cite smith2004domain and @cite toselli2006domain.
A Schwarz
preconditioner requires a decomposition
@f{align*}{
V = \sum_{j=1}^J V_j
@f}
of our finite element space $V$. Each subproblem $V_j$ also has a Ritz
projection $P_j: V \rightarrow V_j$ based on the bilinear form
$a(\cdot,\cdot)$. This projection induces a local operator $A_j$ for each
subproblem $V_j$. If $\Pi_j:V\rightarrow V_j$ is the orthogonal projector onto
$V_j$, one can show $A_jP_j=\Pi_j^TA$.

With this we can define an <i>additive Schwarz preconditioner</i> for the
operator $A$ as
@f{align*}{
 B^{-1} = \sum_{j=1}^J P_j A^{-1} = \sum_{j=1}^J A_j^{-1} \Pi_j^T.
@f}
In other words, we project our solution into each subproblem, apply the
inverse of the subproblem $A_j$, and sum the contributions up over all $j$.

Note that one can interpret the point-wise (one unknown at a time)
Jacobi method as an additive
Schwarz method by defining a subproblem $V_j$ for each degree of
freedom. Then, $A_j^{-1}$ becomes a multiplication with the inverse of a
diagonal entry of $A$.

For the "Block Jacobi" method used in this tutorial, we define a subproblem
$V_j$ for each cell of the mesh on the current level. Note that we use a
continuous finite element, so these blocks are overlapping, as degrees of
freedom on an interface between two cells belong to both subproblems. The
logic for the Schwarz operator operating on the subproblems (in deal.II they
are called "blocks") is implemented in the class RelaxationBlock. The "Block
Jacobi" method is implemented in the class RelaxationBlockJacobi. Many
aspects of the class (for example how the blocks are defined and how to invert
the local subproblems $A_j$) can be configured in the smoother data, see
RelaxationBlock::AdditionalData and DoFTools::make_cell_patches() for details.

So far, we discussed additive smoothers where the updates can be applied
independently and there is no information flowing within a single smoother
application. A <i>multiplicative Schwarz preconditioner</i> addresses this
and is defined by
@f{align*}{
 B^{-1} = \left( I- \prod_{j=1}^J \left(I-P_j\right) \right) A^{-1}.
@f}
In contrast to above, the updates on the subproblems $V_j$ are applied
sequentially. This means that the update obtained when inverting the
subproblem $A_j$ is immediately used in $A_{j+1}$. This becomes
visible when writing out the project:
@f{align*}{
 B^{-1}
 =
 \left(
   I
   -
   \left(I-P_1\right)\left(I-P_2\right)\cdots\left(I-P_J\right)
 \right)
 A^{-1}
 =
   A^{-1}
   -
   \left[ \left(I-P_1\right)
   \left[ \left(I-P_2\right)\cdots
     \left[\left(I-P_J\right) A^{-1}\right] \cdots \right] \right]
@f}

When defining the sub-spaces $V_j$ as whole blocks of degrees of
freedom, this method is implemented in the class RelaxationBlockSOR and used when you
select "Block SOR" in this tutorial. The class RelaxationBlockSOR is also
derived from RelaxationBlock. As such, both additive and multiplicative
Schwarz methods are implemented in a unified framework.

Finally, let us note that the standard Gauss-Seidel (or SOR) method can be
seen as a multiplicative Schwarz method with a subproblem for each DoF.


<h3>Test problem</h3>

We will be considering the following test problem: $\Omega =
[-1,\,1]\times[-1,\,1]\backslash B_{0.3}(0)$, i.e., a square
with a circle of radius 0.3 centered at the
origin removed. In addition, we use $\varepsilon=0.005$, $\boldsymbol{\beta} =
[-\sin(\pi/6),\,\cos(\pi/6)]$, $f=0$, and Dirichlet boundary values
@f{align*}{
g = \left\{\begin{array}{ll} 1 & \text{if } x=-1 \text{ or } y=-1,\,x\geq 0.5 \\
0 & \text{otherwise} \end{array}\right.
@f}

The following figures depict the solutions with (left) and without
(right) streamline diffusion. Without streamline diffusion we see large
oscillations around the boundary layer, demonstrating the instability
of the standard Galerkin finite element method for this problem.

<table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-63-solution.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-63-solution-no-sd.png" alt="">
    </td>
  </tr>
</table>


examples/step-63/doc/results.dox
<h1>Results</h1>

<h3> GMRES Iteration Numbers </h3>

The major advantage for GMG is that it is an $\mathcal{O}(n)$ method,
that is, the complexity of the problem increases linearly with the
problem size. To show then that the linear solver presented in this
tutorial is in fact $\mathcal{O}(n)$, all one needs to do is show that
the iteration counts for the GMRES solve stay roughly constant as we
refine the mesh.

Each of the following tables gives the GMRES iteration counts to reduce the
initial residual by a factor of $10^8$. We selected a sufficient number of smoothing steps
(based on the method) to get iteration numbers independent of mesh size. As
can be seen from the tables below, the method is indeed $\mathcal{O}(n)$.

<h4> DoF/Cell Renumbering </h4>

The point-wise smoothers ("Jacobi" and "SOR") get applied in the order the
DoFs are numbered on each level. We can influence this using the
DoFRenumbering namespace. The block smoothers are applied based on the
ordering we set in `setup_smoother()`. We can visualize this numbering. The
following pictures show the cell numbering of the active cells in downstream,
random, and upstream numbering (left to right):

<img src="https://www.dealii.org/images/steps/developer/step-63-cell-order.png" alt="">

Let us start with the additive smoothers. The following table shows
the number of iterations necessary to obtain convergence from GMRES:

<table align="center" class="doxtable">
<tr>
  <th></th>
  <th></th>
  <th colspan="1">$Q_1$</th>
  <th colspan="7">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">Jacobi (6)</th>
  <th></th>
  <th colspan="3">Block Jacobi (3)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
</tr>
<tr>
  <th>Cells</th>
  <th></th>
  <th>DoFs</th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
  <th></th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
</tr>
<tr>
  <th>32</th>
  <th></th>
  <th>48</th>
  <td>3</th>
  <td>3</th>
  <td>3</th>
  <th></th>
  <td>3</th>
  <td>3</th>
  <td>3</th>
</tr>
<tr>
  <th>128</th>
  <th></th>
  <th>160</th>
  <td>6</th>
  <td>6</th>
  <td>6</th>
  <th></th>
  <td>6</th>
  <td>6</th>
  <td>6</th>
</tr>
<tr>
  <th>512</th>
  <th></th>
  <th>576</th>
  <td>11</th>
  <td>11</th>
  <td>11</th>
  <th></th>
  <td>9</th>
  <td>9</th>
  <td>9</th>
</tr>
<tr>
  <th>2048</th>
  <th></th>
  <th>2176</th>
  <td>15</th>
  <td>15</th>
  <td>15</th>
  <th></th>
  <td>13</th>
  <td>13</th>
  <td>13</th>
</tr>
<tr>
  <th>8192</th>
  <th></th>
  <th>8448</th>
  <td>18</th>
  <td>18</th>
  <td>18</th>
  <th></th>
  <td>15</th>
  <td>15</th>
  <td>15</th>
</tr>
<tr>
  <th>32768</th>
  <th></th>
  <th>33280</th>
  <td>20</th>
  <td>20</th>
  <td>20</th>
  <th></th>
  <td>16</th>
  <td>16</th>
  <td>16</th>
</tr>
<tr>
  <th>131072</th>
  <th></th>
  <th>132096</th>
  <td>20</th>
  <td>20</th>
  <td>20</th>
  <th></th>
  <td>16</th>
  <td>16</th>
  <td>16</th>
</tr>
</table>

We see that renumbering the
DoFs/cells has no effect on convergence speed. This is because these
smoothers compute operations on each DoF (point-smoother) or cell
(block-smoother) independently and add up the results. Since we can
define these smoothers as an application of a sum of matrices, and
matrix addition is commutative, the order at which we sum the
different components will not affect the end result.

On the other hand, the situation is different for multiplicative smoothers:

<table align="center" class="doxtable">
<tr>
  <th></th>
  <th></th>
  <th colspan="1">$Q_1$</th>
  <th colspan="7">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">SOR (3)</th>
  <th></th>
  <th colspan="3">Block SOR (1)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
</tr>
<tr>
  <th>Cells</th>
  <th></th>
  <th>DoFs</th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
  <th></th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
</tr>
<tr>
  <th>32</th>
  <th></th>
  <th>48</th>
  <td>2</th>
  <td>2</th>
  <td>3</th>
  <th></th>
  <td>2</th>
  <td>2</th>
  <td>3</th>
</tr>
<tr>
  <th>128</th>
  <th></th>
  <th>160</th>
  <td>5</th>
  <td>5</th>
  <td>7</th>
  <th></th>
  <td>5</th>
  <td>5</th>
  <td>7</th>
</tr>
<tr>
  <th>512</th>
  <th></th>
  <th>576</th>
  <td>7</th>
  <td>9</th>
  <td>11</th>
  <th></th>
  <td>7</th>
  <td>7</th>
  <td>12</th>
</tr>
<tr>
  <th>2048</th>
  <th></th>
  <th>2176</th>
  <td>10</th>
  <td>12</th>
  <td>15</th>
  <th></th>
  <td>8</th>
  <td>10</th>
  <td>17</th>
</tr>
<tr>
  <th>8192</th>
  <th></th>
  <th>8448</th>
  <td>11</th>
  <td>15</th>
  <td>19</th>
  <th></th>
  <td>10</th>
  <td>11</th>
  <td>20</th>
</tr>
<tr>
  <th>32768</th>
  <th></th>
  <th>33280</th>
  <td>12</th>
  <td>16</th>
  <td>20</th>
  <th></th>
  <td>10</th>
  <td>12</th>
  <td>21</th>
</tr>
<tr>
  <th>131072</th>
  <th></th>
  <th>132096</th>
  <td>12</th>
  <td>16</th>
  <td>19</th>
  <th></th>
  <td>11</th>
  <td>12</th>
  <td>21</th>
</tr>
</table>

Here, we can speed up
convergence by renumbering the DoFs/cells in the advection direction,
and similarly, we can slow down convergence if we do the renumbering
in the opposite direction. This is because advection-dominated
problems have a directional flow of information (in the advection
direction) which, given the right renumbering of DoFs/cells,
multiplicative methods are able to capture.

This feature of multiplicative methods is, however, dependent on the
value of $\varepsilon$. As we increase $\varepsilon$ and the problem
becomes more diffusion-dominated, we have a more uniform propagation
of information over the mesh and there is a diminished advantage for
renumbering in the advection direction. On the opposite end, in the
extreme case of $\varepsilon=0$ (advection-only), we have a 1st-order
PDE and multiplicative methods with the right renumbering become
effective solvers: A correct downstream numbering may lead to methods
that require only a single iteration because information can be
propagated from the inflow boundary downstream, with no information
transport in the opposite direction. (Note, however, that in the case
of $\varepsilon=0$, special care must be taken for the boundary
conditions in this case).


<h4> %Point vs. block smoothers </h4>

We will limit the results to runs using the downstream
renumbering. Here is a cross comparison of all four smoothers for both
$Q_1$ and $Q_3$ elements:

<table align="center" class="doxtable">
<tr>
  <th></th>
  <td></th>
  <th colspan="1">$Q_1$</th>
  <th colspan="4">Smoother (smoothing steps)</th>
  <th></th>
  <th colspan="1">$Q_3$</th>
  <th colspan="4">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th colspan="1">Cells</th>
  <td></th>
  <th colspan="1">DoFs</th>
  <th colspan="1">Jacobi (6)</th>
  <th colspan="1">Block Jacobi (3)</th>
  <th colspan="1">SOR (3)</th>
  <th colspan="1">Block SOR (1)</th>
  <th></th>
  <th colspan="1">DoFs</th>
  <th colspan="1">Jacobi (6)</th>
  <th colspan="1">Block Jacobi (3)</th>
  <th colspan="1">SOR (3)</th>
  <th colspan="1">Block SOR (1)</th>
</tr>
<tr>
  <th>32</th>
  <td></th>
  <th>48</th>
  <td>3</th>
  <td>3</th>
  <td>2</th>
  <td>2</th>
  <td></th>
  <th>336</th>
  <td>15</th>
  <td>14</th>
  <td>15</th>
  <td>6</th>
</tr>
<tr>
  <th>128</th>
  <td></th>
  <th>160</th>
  <td>6</th>
  <td>6</th>
  <td>5</th>
  <td>5</th>
  <td></th>
  <th>1248</th>
  <td>23</th>
  <td>18</th>
  <td>21</th>
  <td>9</th>
</tr>
<tr>
  <th>512</th>
  <td></th>
  <th>576</th>
  <td>11</th>
  <td>9</th>
  <td>7</th>
  <td>7</th>
  <td></th>
  <th>4800</th>
  <td>29</th>
  <td>21</th>
  <td>28</th>
  <td>9</th>
</tr>
<tr>
  <th>2048</th>
  <td></th>
  <th>2176</th>
  <td>15</th>
  <td>13</th>
  <td>10</th>
  <td>8</th>
  <td></th>
  <th>18816</th>
  <td>33</th>
  <td>22</th>
  <td>32</th>
  <td>9</th>
</tr>
<tr>
  <th>8192</th>
  <td></th>
  <th>8448</th>
  <td>18</th>
  <td>15</th>
  <td>11</th>
  <td>10</th>
  <td></th>
  <th>74496</th>
  <td>35</th>
  <td>22</th>
  <td>34</th>
  <td>10</th>
</tr>
<tr>
  <th>32768</th>
  <td></th>
  <th>33280</th>
  <td>20</th>
  <td>16</th>
  <td>12</th>
  <td>10</th>
  <td></th>
</tr>
<tr>
  <th>131072</th>
  <td></th>
  <th>132096</th>
  <td>20</th>
  <td>16</th>
  <td>12</th>
  <td>11</th>
  <td></th>
</tr>
</table>

We see that for $Q_1$, both multiplicative smoothers require a smaller
combination of smoothing steps and iteration counts than either
additive smoother. However, when we increase the degree to a $Q_3$
element, there is a clear advantage for the block smoothers in terms
of the number of smoothing steps and iterations required to
solve. Specifically, the block SOR smoother gives constant iteration
counts over the degree, and the block Jacobi smoother only sees about
a 38% increase in iterations compared to 75% and 183% for Jacobi and
SOR respectively.

<h3> Cost </h3>

Iteration counts do not tell the full story in the optimality of a one
smoother over another. Obviously we must examine the cost of an
iteration. Block smoothers here are at a disadvantage as they are
having to construct and invert a cell matrix for each cell. Here is a
comparison of solve times for a $Q_3$ element with 74,496 DoFs:

<table align="center" class="doxtable">
<tr>
  <th colspan="1">$Q_3$</th>
  <th colspan="4">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th colspan="1">DoFs</th>
  <th colspan="1">Jacobi (6)</th>
  <th colspan="1">Block Jacobi (3)</th>
  <th colspan="1">SOR (3)</th>
  <th colspan="1">Block SOR (1)</th>
</tr>
<tr>
  <th>74496</th>
  <td>0.68s</th>
  <td>5.82s</th>
  <td>1.18s</th>
  <td>1.02s</th>
</tr>
</table>

The smoother that requires the most iterations (Jacobi) actually takes
the shortest time (roughly 2/3 the time of the next fastest
method). This is because all that is required to apply a Jacobi
smoothing step is multiplication by a diagonal matrix which is very
cheap. On the other hand, while SOR requires over 3x more iterations
(each with 3x more smoothing steps) than block SOR, the times are
roughly equivalent, implying that a smoothing step of block SOR is
roughly 9x slower than a smoothing step of SOR. Lastly, block Jacobi
is almost 6x more expensive than block SOR, which intuitively makes
sense from the fact that 1 step of each method has the same cost
(inverting the cell matrices and either adding or multiply them
together), and block Jacobi has 3 times the number of smoothing steps per
iteration with 2 times the iterations.


<h3> Additional points </h3>

There are a few more important points to mention:

<ol>
<li> For a mesh distributed in parallel, multiplicative methods cannot
be executed over the entire domain. This is because they operate one
cell at a time, and downstream cells can only be handled once upstream
cells have already been done. This is fine on a single processor: The
processor just goes through the list of cells one after the
other. However, in parallel, it would imply that some processors are
idle because upstream processors have not finished doing the work on
cells upstream from the ones owned by the current processor. Once the
upstream processors are done, the downstream ones can start, but by
that time the upstream processors have no work left. In other words,
most of the time during these smoother steps, most processors are in
fact idle. This is not how one obtains good parallel scalability!

One can use a hybrid method where
a multiplicative smoother is applied on each subdomain, but as you
increase the number of subdomains, the method approaches the behavior
of an additive method. This is a major disadvantage to these methods.
</li>

<li> Current research into block smoothers suggest that soon we will be
able to compute the inverse of the cell matrices much cheaper than
what is currently being done inside deal.II. This research is based on
the fast diagonalization method (dating back to the 1960s) and has
been used in the spectral community for around 20 years (see, e.g., <a
href="https://doi.org/10.1007/s10915-004-4787-3"> Hybrid
Multigrid/Schwarz Algorithms for the Spectral Element Method by Lottes
and Fischer</a>). There are currently efforts to generalize these
methods to DG and make them more robust. Also, it seems that one
should be able to take advantage of matrix-free implementations and
the fact that, in the interior of the domain, cell matrices tend to
look very similar, allowing fewer matrix inverse computations.
</li>
</ol>

Combining 1. and 2. gives a good reason for expecting that a method
like block Jacobi could become very powerful in the future, even
though currently for these examples it is quite slow.


<h3> Possibilities for extensions </h3>

<h4> Constant iterations for Q<sub>5</sub> </h4>

Change the number of smoothing steps and the smoother relaxation
parameter (set in <code>Smoother::AdditionalData()</code> inside
<code>create_smoother()</code>, only necessary for point smoothers) so
that we maintain a constant number of iterations for a $Q_5$ element.

<h4> Effectiveness of renumbering for changing epsilon </h4>

Increase/decrease the parameter "Epsilon" in the `.prm` files of the
multiplicative methods and observe for which values renumbering no
longer influences convergence speed.

<h4> Mesh adaptivity </h4>

The code is set up to work correctly with an adaptively refined mesh (the
interface matrices are created and set). Devise a suitable refinement
criterium or try the KellyErrorEstimator class.


