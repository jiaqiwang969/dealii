examples/step-33/doc/intro.dox
<br>

<i>
This program was written for fun by David Neckels (NCAR) while working
at Sandia (on the Wyoming Express bus to and from Corrales each day).
The main purpose was to better understand Euler flow.
The code solves the basic Euler equations of gas dynamics, by using a
fully implicit Newton iteration (inspired by Sandia's Aria code).  The
code may be configured by an input file to run different simulations
on different meshes, with differing boundary conditions.
<br>
The original code and documentation was later slightly modified by Wolfgang
Bangerth to make it more modular and allow replacing the parts that are
specific to the Euler equations by other hyperbolic conservation laws without
too much trouble.
</i>

@note The program uses the <a
href="http://trilinos.org">Trilinos</a> linear solvers (these can be found
in Trilinos in the Aztec/Amesos packages) and an automatic
differentiation package, Sacado, also part of Trilinos. deal.II must
be configured to use Trilinos. Refer to the <a
href="../../readme.html#trilinos">ReadMe</a> file for instructions how to
do this.

@note While this program demonstrates the use of automatic differentiation
well, it does not express the state of the art in Euler equation solvers.
There are much faster and more accurate method for this equation, and
you should take a look at step-67 and step-69 to see how this equation
can be solved more efficiently.



<a name="Intro"></a> <h1>Introduction</h1>

<h3>Euler flow</h3>

The equations that describe the movement of a compressible, inviscid
gas (the so-called Euler equations of gas dynamics) are
a basic system of conservation laws. In spatial dimension $d$ they read
@f[
\partial_t \mathbf{w} + \nabla \cdot \mathbf{F}(\mathbf{w}) =
\mathbf{G}(\mathbf w),
@f]
with the solution $\mathbf{w}=(\rho v_1,\ldots,\rho v_d,\rho,
E)^{\top}$ consisting of $\rho$ the fluid density, ${\mathbf v}=(v_1,\ldots v_d)^T$ the
flow velocity (and thus $\rho\mathbf v$ being the linear momentum
density), and
$E$ the energy density of the gas. We interpret the equations above as
$\partial_t \mathbf{w}_i + \nabla \cdot \mathbf{F}_i(\mathbf{w}) = \mathbf
G_i(\mathbf w)$, $i=1,\ldots,dim+2$.

For the Euler equations, the flux matrix $\mathbf F$ (or system of flux functions)
is defined as (shown here for the case $d=3$)
@f{eqnarray*}
  \mathbf F(\mathbf w)
  =
  \left(
  \begin{array}{ccc}
    \rho v_1^2+p & \rho v_2v_1  & \rho v_3v_1 \\
    \rho v_1v_2  & \rho v_2^2+p & \rho v_3v_2 \\
    \rho v_1v_3  & \rho v_2v_3  & \rho v_3^2+p \\
    \rho v_1 & \rho v_2 & \rho v_3 \\
    (E+p) v_1 & (E+p) v_2 & (E+p) v_3
  \end{array}
  \right),
@f}
and we will choose as particular right hand side forcing only the effects of
gravity, described by
@f{eqnarray*}
  \mathbf G(\mathbf w)
  =
  \left(
  \begin{array}{c}
    g_1\rho \\
    g_2\rho \\
    g_3\rho \\
    0 \\
    \rho \mathbf g \cdot \mathbf v
  \end{array}
  \right),
@f}
where $\mathbf g=(g_1,g_2,g_3)^T$ denotes the gravity vector.
With this, the entire system of equations reads:
@f{eqnarray*}
  \partial_t (\rho v_i) + \sum_{s=1}^d \frac{\partial(\rho v_i v_s +
  \delta_{is} p)}{\partial x_s} &=& g_i \rho, \qquad i=1,\dots,d, \\
  \partial_t \rho + \sum_{s=1}^d \frac{\partial(\rho v_s)}{\partial x_s} &=& 0,  \\
  \partial_t E + \sum_{s=1}^d \frac{\partial((E+p)v_s)}{\partial x_s} &=&
  \rho \mathbf g \cdot \mathbf v.
@f}
These equations describe, respectively, the conservation of momentum,
mass, and energy.
The system is closed by a relation that defines the pressure: $p =
(\gamma -1)(E-\frac{1}{2} \rho |\mathbf v|^2)$. For the constituents
of air (mainly nitrogen and oxygen) and other diatomic gases, the ratio of
specific heats is $\gamma=1.4$.

This problem obviously falls into the class of vector-valued
problems. A general overview of how to deal with these problems in
deal.II can be found in the @ref vector_valued module.

<h3>Discretization</h3>

Discretization happens in the usual way, taking into account that this
is a hyperbolic problem in the same style as the simple one discussed
in step-12:
We choose a finite element space $V_h$, and integrate our conservation law against
our (vector-valued) test function $\mathbf{z} \in V_h$.  We then integrate by parts and approximate the
boundary flux with a <i> numerical </i> flux $\mathbf{H}$,
@f{eqnarray*}
&&\int_{\Omega} (\partial_t \mathbf{w}, \mathbf{z}) + (\nabla \cdot \mathbf{F}(\mathbf{w}), \mathbf{z}) \\
&\approx &\int_{\Omega} (\partial_t \mathbf{w}, \mathbf{z}) - (\mathbf{F}(\mathbf{w}), \nabla \mathbf{z}) + h^{\eta}(\nabla \mathbf{w} , \nabla \mathbf{z}) + \int_{\partial \Omega} (\mathbf{H}(\mathbf{w}^+, \mathbf{w}^-, \mathbf{n}), \mathbf{z}^+),
@f}
where a superscript $+$ denotes the interior trace of a function, and $-$ represents the outer trace.
The diffusion term $h^{\eta}(\nabla \mathbf{w} , \nabla \mathbf{z})$ is introduced strictly for stability,
 where $h$ is the mesh size and $\eta$ is a parameter prescribing how
 much diffusion to add.

On the boundary, we have to say what the outer trace $\mathbf{w}^-$ is.
Depending on the boundary condition, we prescribe either of the following:
<ul>
<li> Inflow boundary: $\mathbf{w}^-$ is prescribed to be the desired value.
<li> Supersonic outflow boundary: $\mathbf{w}^- = \mathbf{w}^+$
<li> Subsonic outflow boundary: $\mathbf{w}^- = \mathbf{w}^+$ except that the energy variable
is modified to support a prescribed pressure $p_o$, i.e.
$\mathbf{w}^- =(\rho^+, \rho v_1^+, \dots, \rho v_d^+, p_o/(\gamma -1) + 0.5 \rho |\mathbf{v}^+|^2)$
<li> Reflective boundary: we set $\mathbf{w}^-$ so that $(\mathbf{v}^+ + \mathbf{v}^-) \cdot \mathbf{n} = 0$ and
$\rho^- = \rho^+,E^-=E^+$.
</ul>

More information on these issues can be found, for example, in Ralf
Hartmann's PhD thesis ("Adaptive Finite Element Methods for the
Compressible Euler Equations", PhD thesis, University of Heidelberg, 2002).

We use a time stepping scheme to substitute the time derivative in the
above equations. For simplicity, we define $ \mathbf{B}({\mathbf{w}_{n}})(\mathbf z) $ as the spatial residual at time step $n$ :

@f{eqnarray*}
 \mathbf{B}(\mathbf{w}_{n})(\mathbf z)  &=&
- \int_{\Omega} \left(\mathbf{F}(\mathbf{w}_n),
\nabla\mathbf{z}\right) +  h^{\eta}(\nabla \mathbf{w}_n , \nabla \mathbf{z}) \\
&& +
\int_{\partial \Omega} \left(\mathbf{H}(\mathbf{w}_n^+,
\mathbf{w}^-(\mathbf{w}_n^+), \mathbf{n}), \mathbf{z}\right)
-
\int_{\Omega} \left(\mathbf{G}(\mathbf{w}_n),
\mathbf{z}\right) .
@f}

At each time step, our full discretization is thus
that the residual applied to any test
function $\mathbf z$ equals zero:
@f{eqnarray*}
R(\mathbf{W}_{n+1})(\mathbf z) &=&
\int_{\Omega} \left(\frac{{\mathbf w}_{n+1} - \mathbf{w}_n}{\delta t},
\mathbf{z}\right)+
\theta \mathbf{B}({\mathbf{w}}_{n+1}) +  (1-\theta) \mathbf{B}({\mathbf w}_{n}) \\
&=& 0
@f}
where $ \theta \in [0,1] $ and
$\mathbf{w}_i = \sum_k \mathbf{W}_i^k \mathbf{\phi}_k$. Choosing
$\theta=0$ results in the explicit (forward) Euler scheme, $\theta=1$
in the stable implicit (backward) Euler scheme, and $\theta=\frac 12$
in the Crank-Nicolson scheme.

In the implementation below, we choose the Lax-Friedrichs flux for the
function $\mathbf H$, i.e.  $\mathbf{H}(\mathbf{a},\mathbf{b},\mathbf{n}) =
\frac{1}{2}(\mathbf{F}(\mathbf{a})\cdot \mathbf{n} +
\mathbf{F}(\mathbf{b})\cdot \mathbf{n} + \alpha (\mathbf{a} - \mathbf{b}))$,
where $\alpha$ is either a fixed number specified in the input file, or where
$\alpha$ is a mesh dependent value. In the latter case, it is chosen as
$\frac{h}{2\delta T}$ with $h$ the diameter of the face to which the flux is
applied, and $\delta T$ the current time step.

With these choices, equating the residual to zero results in a
nonlinear system of equations $R(\mathbf{W}_{n+1})=0$. We solve this nonlinear system by a
Newton iteration (in the same way as explained in step-15), i.e. by iterating
@f{eqnarray*}
R'(\mathbf{W}^k_{n+1},\delta \mathbf{W}_{n+1}^k)(\mathbf z) & = & -
R(\mathbf{W}^{k}_{n+1})(\mathbf z) \qquad \qquad \forall \mathbf z\in V_h \\
\mathbf{W}^{k+1}_{n+1} &=& \mathbf{W}^k_{n+1} + \delta \mathbf{W}^k_{n+1},
@f}
until $|R(\mathbf{W}^k_{n+1})|$ (the residual) is sufficiently small. By
testing with the nodal basis of a finite element space instead of all
$\mathbf z$, we arrive at a linear system for $\delta \mathbf W$:
@f{eqnarray*}
\mathbf R'(\mathbf{W}^k_{n+1})\delta \mathbf{W}^k_{n+1} & = & -
\mathbf R(\mathbf{W}^{k}_{n+1}).
@f}
This linear system is, in general, neither symmetric nor has any
particular definiteness properties. We will either use a direct solver
or Trilinos' GMRES implementation to solve it. As will become apparent from
the <a href="#Results">results shown below</a>, this fully implicit iteration
converges very rapidly (typically in 3 steps) and with the quadratic
convergence order expected from a Newton method.


<h3> Automatic differentiation </h3>

Since computing the Jacobian matrix $\mathbf R'(\mathbf W^k)$ is a
terrible beast, we use an automatic differentiation package, Sacado,
to do this.  Sacado is a package within the <a
href="http://trilinos.org" target="_top">Trilinos</a> framework
and offers a C++ template class <code>Sacado::Fad::DFad</code>
(<code>Fad</code> standing for "forward automatic
differentiation") that supports basic arithmetic operators and
functions such as <code> sqrt, sin, cos, pow, </code> etc. In order to
use this feature, one declares a collection of variables of this type
and then denotes some of this collection as degrees of freedom, the rest of
the variables being functions of the independent variables.  These
variables are used in an algorithm, and as the variables are used,
their sensitivities with respect to the degrees of freedom are
continuously updated.

One can imagine that for the full Jacobian matrix as a whole,
this could be prohibitively expensive: the number of independent variables are
the $\mathbf W^k$, the dependent variables the elements of the vector $\mathbf
R(\mathbf W^k)$. Both of these vectors can easily have tens of thousands of
elements or more.  However, it is important to note that not all elements of
$\mathbf R$ depend on all elements of $\mathbf W^k$: in fact, an entry in
$\mathbf R$ only depends on an element of $\mathbf W^k$ if the two
corresponding shape functions overlap and couple in the weak form.

Specifically, it is wise to define a minimum set of
independent AD variables that the residual on the current cell may possibly
depend on: on every element, we define those variables as
independent that correspond to the degrees of freedom defined on this
cell (or, if we have to compute jump terms between cells, that
correspond to degrees of freedom defined on either of the two adjacent
cells), and the dependent variables are the elements of the local
residual vector. Not doing this, i.e. defining <i>all</i> elements of
$\mathbf W^k$ as independent, will result a very expensive computation
of a lot of zeros: the elements of the local residual vector are
independent of almost all elements of the solution vector, and
consequently their derivatives are zero; however, trying to compute
these zeros can easily take 90% or more of the compute time of the
entire program, as shown in an experiment inadvertently made by a student a few
years after this program was first written.


Coming back to the question of computing the Jacobian automatically:
The author has used this approach side by side with a hand coded Jacobian for
the incompressible Navier-Stokes problem and found the Sacado approach to be
just as fast as using a hand coded Jacobian, but infinitely simpler and less
error prone: Since using the auto-differentiation requires only that one code
the residual $R(\mathbf{W})$, ensuring code correctness and maintaining code
becomes tremendously more simple -- the Jacobian matrix $\mathbf R'$ is
computed by essentially the same code that also computes the residual $\mathbf
R$.

All this said, here's a very simple example showing how Sacado can be
used:

@code
#include <Sacado.hpp>
#include <iostream>

using fad_double = Sacado::Fad::DFad<double>;

main() {

  fad_double a,b,c;

  a = 1; b = 2;

  a.diff(0,2);  // Set a to be dof 0, in a 2-dof system.

  b.diff(1,2);  // Set b to be dof 1, in a 2-dof system.

  c = 2*a+cos(a*b);

  double *derivs = &c.fastAccessDx(0); // Access derivatives

  std::cout << "dc/da = " << derivs[0] << ", dc/db=" << derivs[1] << std::endl;

}
@endcode

The output are the derivatives $\frac{\partial c(a,b)}{\partial a},
\frac{\partial c(a,b)}{\partial b}$ of $c(a,b)=2a+\cos(ab)$ at $a=1,b=2$.

It should be noted that Sacado provides more auto-differentiation capabilities than the small subset
used in this program.  However, understanding the example above is
enough to understand the use of Sacado in this Euler flow program.

<h3> Trilinos solvers </h3>
The program uses either the Aztec iterative solvers, or the Amesos
sparse direct solver, both provided by
the Trilinos package.  This package is inherently designed to be used in a parallel program, however,
it may be used in serial just as easily, as is done here.  The Epetra package is the basic
vector/matrix library upon which the solvers are built.  This very powerful package can be used
to describe the parallel distribution of a vector, and to define sparse matrices that operate
on these vectors.  Please view the commented code for more details on how these solvers are used
within the example.

<h3> Adaptivity </h3>
The example uses an ad hoc refinement indicator that shows some usefulness in shock-type problems, and
in the downhill flow example included.  We refine according to the squared gradient of the density.
Hanging nodes are handled by computing the numerical flux across cells that are of differing
refinement levels, rather than using the AffineConstraints class as in
all other tutorial programs so far.  In this way, the example combines
the continuous and DG methodologies. It also simplifies the generation
of the Jacobian because we do not have to track constrained degrees of
freedom through the automatic differentiation used to compute it.

@note Whereas this program was written in 2008, we were unaware of any
publication that would actually have used this approach. However, a
more recent paper by A. Dedner, R. Kl&ouml;fkorn, and M. Kr&auml;nkel
("Continuous Finite-Elements on Non-Conforming Grids Using
Discontinuous Galerkin Stabilization", Proceedings of Finite Volumes
for Complex Applications VII - Methods and Theoretical Aspects,
Springer, 2014) comes close.

Further, we enforce a maximum number of refinement levels to keep refinement under check.  It is the
author's experience that for adaptivity for a time dependent problem, refinement can easily lead the simulation to
a screeching halt, because of time step restrictions if the mesh
becomes too fine in any part of the domain, if care is not taken.  The amount of refinement is
limited in the example by letting the user specify the
maximum level of refinement that will be present anywhere in the mesh.  In this way, refinement
tends not to slow the simulation to a halt.  This, of course, is purely a heuristic strategy, and
if the author's advisor heard about it, the author would likely be exiled forever from the finite
 element error estimation community.

<h3>Input deck, initial and boundary conditions</h3>

We use an input file deck to drive the simulation.  In this way, we can alter the boundary conditions
and other important properties of the simulation without having to recompile.  For more information on
the format, look at the <a href="#Results">results section</a>, where we
describe an example input file in more detail.

In previous example programs, we have usually hard-coded the initial
and boundary conditions. In this program, we instead use the
expression parser class FunctionParser so that we can specify a
generic expression in the input file and have it parsed at run time &mdash;
this way, we can change initial conditions without the need to
recompile the program. Consequently, no classes named
InitialConditions or BoundaryConditions will be declared in the
program below.


<h3>Implementation</h3>

The implementation of this program is split into three essential parts:
<ul>
  <li>The <code>EulerEquations</code> class that encapsulates everything that
  completely describes the specifics of the Euler equations. This includes the
  flux matrix $\mathbf F(\mathbf W)$, the numerical flux $\mathbf F(\mathbf
  W^+,\mathbf W^-,\mathbf n)$, the right hand side $\mathbf G(\mathbf W)$,
  boundary conditions, refinement indicators, postprocessing the output, and
  similar things that require knowledge of the meaning of the individual
  components of the solution vectors and the equations.

  <li>A namespace that deals with everything that has to do with run-time
  parameters.

  <li>The <code>ConservationLaw</code> class that deals with time stepping,
  outer nonlinear and inner linear solves, assembling the linear systems, and
  the top-level logic that drives all this.
</ul>

The reason for this approach is that it separates the various concerns in a
program: the <code>ConservationLaw</code> is written in such a way that it
would be relatively straightforward to adapt it to a different set of
equations: One would simply re-implement the members of the
<code>EulerEquations</code> class for some other hyperbolic equation, or
augment the existing equations by additional ones (for example by advecting
additional variables, or by adding chemistry, etc). Such modifications,
however, would not affect the time stepping, or the nonlinear solvers if
correctly done, and consequently nothing in the <code>ConservationLaw</code>
would have to be modified.

Similarly, if we wanted to improve on the linear or nonlinear solvers, or on
the time stepping scheme (as hinted at the end of the <a
href="#Results">results section</a>), then this would not require changes in
the <code>EulerEquations</code> at all.


examples/step-33/doc/results.dox
<a name="Results"></a>
<h1>Results</h1>

We run the problem with the mesh <code>slide.inp</code> (this file is in the
same directory as the source code for this program) and the following input
deck (available as <code>input.prm</code> in the same directory):
@verbatim
# Listing of Parameters
# ---------------------

# The input grid
set mesh = slide.inp

# Stabilization parameter
set diffusion power = 2.0

# --------------------------------------------------
# Boundary conditions
# We may specify boundary conditions for up to MAX_BD boundaries.
# Your .inp file should have these boundaries designated.
subsection boundary_1
  set no penetration = true # reflective boundary condition
end

subsection boundary_2
  # outflow boundary
  # set w_2 = pressure
  # set w_2 value = 1.5 - y
end

subsection boundary_3
  set no penetration = true # reflective
  # set w_3 = pressure
  # set w_3 value = 1.0
end

subsection boundary_4
  set no penetration = true #reflective
end

# --------------------------------------------------
# Initial Conditions
# We set the initial conditions of the conservative variables.  These lines
# are passed to the expression parsing function.  You should use x,y,z for
# the coordinate variables.

subsection initial condition
  set w_0 value = 0
  set w_1 value = 0
  set w_2 value = 10*(x<-0.7)*(y> 0.3)*(y< 0.45) + (1-(x<-0.7)*(y> 0.3)*(y< 0.45))*1.0
  set w_3 value = (1.5-(1.0*1.0*y))/0.4
end

# --------------------------------------------------
# Time stepping control
subsection time stepping
  set final time = 10.0 # simulation end time
  set time step  = 0.02 # simulation time step
  set theta scheme value = 0.5
end

subsection linear solver
  set output         = quiet
  set method         = gmres
  set ilut fill      = 1.5
  set ilut drop tolerance = 1e-6
  set ilut absolute tolerance = 1e-6
  set ilut relative tolerance = 1.0
end

# --------------------------------------------------
# Output frequency and kind
subsection output
  set step           = 0.01
  set schlieren plot = true
end

# --------------------------------------------------
# Refinement control
subsection refinement
  set refinement = true # none only other option
  set shock value = 1.5
  set shock levels = 1 # how many levels of refinement to allow
end

# --------------------------------------------------
# Flux parameters
subsection flux
 set stab = constant
 #set stab value = 1.0
end
@endverbatim

When we run the program, we get the following kind of output:
@verbatim
...
T=0.14
   Number of active cells:       1807
   Number of degrees of freedom: 7696

   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   7.015e-03        0008        3.39e-13
   2.150e-05        0008        1.56e-15
   2.628e-09        0008        5.09e-20
   5.243e-16        (converged)

T=0.16
   Number of active cells:       1807
   Number of degrees of freedom: 7696

   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   7.145e-03        0008        3.80e-13
   2.548e-05        0008        7.20e-16
   4.063e-09        0008        2.49e-19
   5.970e-16        (converged)

T=0.18
   Number of active cells:       1807
   Number of degrees of freedom: 7696

   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   7.395e-03        0008        6.69e-13
   2.867e-05        0008        1.33e-15
   4.091e-09        0008        3.35e-19
   5.617e-16        (converged)
...
@endverbatim

This output reports the progress of the Newton iterations and the time
stepping. Note that our implementation of the Newton iteration indeed shows
the expected quadratic convergence order: the norm of the nonlinear residual
in each step is roughly the norm of the previous step squared. This leads to
the very rapid convergence we can see here. This holds until
times up to $t=1.9$ at which time the nonlinear iteration reports a
lack of convergence:
@verbatim
...

T=1.88
   Number of active cells:       2119
   Number of degrees of freedom: 9096

   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   2.251e-01        0012        9.78e-12
   5.698e-03        0012        2.04e-13
   3.896e-05        0012        1.48e-15
   3.915e-09        0012        1.94e-19
   8.800e-16        (converged)

T=1.9
   Number of active cells:       2140
   Number of degrees of freedom: 9184

   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   2.320e-01        0013        3.94e-12
   1.235e-01        0016        6.62e-12
   8.494e-02        0016        6.05e-12
   1.199e+01        0026        5.72e-10
   1.198e+03        0002        1.20e+03
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan


----------------------------------------------------
Exception on processing:

--------------------------------------------------------
An error occurred in line <2476> of file <\step-33.cc> in function
    void Step33::ConservationLaw<dim>::run() [with int dim = 2]
The violated condition was:
    nonlin_iter <= 10
The name and call sequence of the exception was:
    ExcMessage ("No convergence in nonlinear solver")
Additional Information:
No convergence in nonlinear solver
--------------------------------------------------------

Aborting!
----------------------------------------------------
@endverbatim

We may find out the cause and possible remedies by looking at the animation of the solution.

The result of running these computations is a bunch of output files that we
can pass to our visualization program of choice. When we collate them into a
movie, the results of last several time steps looks like this:

<img src="https://www.dealii.org/images/steps/developer/step-33.oscillation.gif " alt="" height="300">

As we see, when the heavy mass of fluid hits the left bottom corner,
some oscillation occurs and lead to the divergence of the iteration. A lazy solution to
this issue is add more viscosity. If we set the diffusion power $\eta = 1.5$ instead of $2.0$,
the simulation would be able to survive this crisis. Then, the result looks like this:


<img src="https://www.dealii.org/images/steps/developer/step-33.slide.ed2.gif " alt="" height="300">

The heavy mass of fluid is drawn down the slope by gravity, where
it collides with the ski lodge and is flung into the air!  Hopefully everyone
escapes! And also, we can see the boundary between heavy mass and light mass blur quickly
due to the artificial viscosity.

We can also visualize the evolution of the adaptively refined grid:

<img src="https://www.dealii.org/images/steps/developer/step-33.slide.adapt.ed2.gif " alt="" height="300">

The adaptivity follows and precedes the flow pattern, based on the heuristic
refinement scheme discussed above.




<a name="extensions"></a>
<h3>Possibilities for extensions</h3>

<h4>Stabilization</h4>

The numerical scheme we have chosen is not particularly
stable when the artificial viscosity is small while is too diffusive when
the artificial viscosity is large. Furthermore, it is known there are more
advanced techniques to stabilize the solution, for example streamline
diffusion, least-squares stabilization terms, entropy viscosity.



<h4>Better linear solvers</h4>

While the Newton method as a nonlinear solver appears to work very
well if the time step is small enough, the linear solver can be
improved. For example, in the current scheme whenever we use an
iterative solver, an ILU is computed anew for each Newton step;
likewise, for the direct solver, an LU decomposition of the Newton
matrix is computed in each step. This is obviously wasteful: from one
Newton step to another, and probably also between time steps, the
Newton matrix does not radically change: an ILU or a sparse LU
decomposition for one Newton step is probably still a very good
preconditioner for the next Newton or time step. Avoiding the
recomputation would therefore be a good way to reduce the amount of
compute time.

One could drive this a step further: since close to convergence the
Newton matrix changes only a little bit, one may be able to define a
quasi-Newton scheme where we only re-compute the residual (i.e. the
right hand side vector) in each Newton iteration, and re-use the
Newton matrix. The resulting scheme will likely not be of quadratic
convergence order, and we have to expect to do a few more nonlinear
iterations; however, given that we don't have to spend the time to
build the Newton matrix each time, the resulting scheme may well be
faster.


<h4>Cache the explicit part of residual</h4>

The residual calculated in ConservationLaw::assemble_cell_term function
reads
   $R_i = \left(\frac{\mathbf{w}^{k}_{n+1} - \mathbf{w}_n}{\delta t}
    , \mathbf{z}_i \right)_K  +
      \theta \mathbf{B}({\mathbf{w}^{k}_{n+1}})(\mathbf{z}_i)_K +
      (1-\theta) \mathbf{B}({\mathbf{w}_{n}}) (\mathbf{z}_i)_K $
This means that we calculate the spatial residual twice at one Newton
iteration step: once respect to the current solution $\mathbf{w}^{k}_{n+1}$
and once more respect to the last time step solution $\mathbf{w}_{n}$ which
remains the same during all Newton iterations through one timestep.
Cache up the explicit part of residual
 $ \mathbf{B}({\mathbf{w}_{n}}) (\mathbf{z}_i)_K$
during Newton iteration will save lots of labor.


<h4>Other conservation laws</h4>

Finally, as a direction beyond the immediate solution of the Euler
equations, this program tries very hard to separate the implementation
of everything that is specific to the Euler equations into one class
(the <code>EulerEquation</code> class), and everything that is
specific to assembling the matrices and vectors, nonlinear and linear
solvers, and the general top-level logic into another (the
<code>ConservationLaw</code> class).

By replacing the definitions of flux matrices and numerical fluxes in
this class, as well as the various other parts defined there, it
should be possible to apply the <code>ConservationLaw</code> class to
other hyperbolic conservation laws as well.


