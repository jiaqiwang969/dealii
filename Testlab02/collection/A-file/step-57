examples/step-57/doc/intro.dox
<br>

<i>This program was contributed by Liang Zhao and Timo Heister.

This material is based upon work partially supported by National Science
Foundation grant DMS1522191 and the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation under
Award No. EAR-0949446 and The University of California-Davis.
</i>

@dealiiTutorialDOI{10.5281/zenodo.484156,https://zenodo.org/badge/DOI/10.5281/zenodo.484156.svg}

<a name="Intro"></a>
<h1>Introduction</h1>

<h3> Navier Stokes Equations </h3>

In this tutorial we show how to solve the incompressible Navier
Stokes equations (NSE) with Newton's method. The flow we consider here
is assumed to be steady. In a domain $\Omega \subset
\mathbb{R}^{d}$, $d=2,3$, with a piecewise smooth boundary
$\partial \Omega$, and a given force field $\textbf{f}$, we seek
a velocity field $\textbf{u}$ and a pressure field $\textbf{p}$
satisfying
@f{eqnarray*}
- \nu \Delta\textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f}\\
- \nabla \cdot \textbf{u} &=& 0.
@f}

Unlike the Stokes equations as discussed in step-22, the NSE are a
nonlinear system of equations because of the convective term $(\textbf{u} \cdot
\nabla)\textbf{u}$. The first step of computing a numerical solution
is to linearize the system and this will be done using Newton's method. A
time-dependent problem is discussed in step-35, where the system is linearized
using the solution from the last time step and no nonlinear
solve is necessary.

<h3> Linearization of Navier-Stokes Equations </h3>

We define a nonlinear function whose root is a solution to the NSE by
@f{eqnarray*}
F(\mathbf{u}, p) =
  \begin{pmatrix}
    - \nu \Delta\mathbf{u} + (\mathbf{u} \cdot \nabla)\mathbf{u} + \nabla p - \mathbf{f} \\
    - \nabla \cdot \mathbf{u}
  \end{pmatrix}.
@f}

Assuming the initial guess is good enough to
guarantee the convergence of Newton's iteration and denoting
$\textbf{x} = (\textbf{u}, p)$, Newton's iteration on a vector function
can be defined as
@f{eqnarray*}
  \textbf{x}^{k+1} = \textbf{x}^{k} - (\nabla F(\textbf{x}^{k}))^{-1} F(\textbf{x}^{k}),
@f}

where $\textbf{x}^{k+1}$ is the approximate solution in step $k+1$,
$\textbf{x}^{k}$ represents the solution from the previous step, and $\nabla
F(\textbf{x}^{k})$ is the Jacobian matrix evaluated at
$\textbf{x}^{k}$.
A similar iteration can be found in step-15.

The Newton iteration formula implies the new
solution is obtained by adding an update term to the old solution. Instead
of evaluating the Jacobian matrix and taking its inverse, we consider
the update term as a whole, that is
@f{eqnarray*}
  \delta \textbf{x}^{k} = - (\nabla F(\textbf{x}^{k}))^{-1} F(\textbf{x}^{k}),
@f}

where $\textbf{x}^{k+1}=\textbf{x}^{k}+\delta \textbf{x}^{k}$.

We can find the update term by solving the system
@f{eqnarray*}
  \nabla F(\textbf{x}^{k}) \delta \textbf{x}^{k} = -F(\textbf{x}^{k}).
@f}

Here, the left of the previous equation represents the
directional gradient of $F(\textbf{x})$ along $\delta
\textbf{x}^{k}$ at $\textbf{x}^{k}$. By definition, the directional gradient is given by
@f{eqnarray*}
  & &\nabla F(\mathbf{u}^{k}, p^{k}) (\delta \mathbf{u}^{k}, \delta p^{k}) \\
  \\
  &=& \lim_{\epsilon \to 0} \frac{1}{\epsilon}
      \left(
        F(\mathbf{u}^{k} + \epsilon \delta \mathbf{u}^{k},
          p^{k} + \epsilon \nabla \delta p^{k})
      - F(\mathbf{u}^{k}, p^{k})
      \right)\\
  \\
  &=& \lim_{\epsilon \to 0} \frac{1}{\epsilon}
      \begin{pmatrix}
        - \epsilon \nu \Delta \delta \mathbf{u}^{k}
        + \epsilon \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
        + \epsilon \delta \mathbf{u}^{k} \cdot \nabla \mathbf{u}^{k}
        + \epsilon^{2} \delta \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
        + \epsilon \nabla \delta p^{k}\\
        - \epsilon \nabla \cdot \delta \mathbf{u}^{k}
      \end{pmatrix} \\
  \\
  &=& \begin{pmatrix}
        - \nu \Delta \delta \mathbf{u}^{k}
        + \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
        + \delta \mathbf{u}^{k} \cdot \nabla \mathbf{u}^{k}
        + \nabla \delta p^{k}\\
        - \nabla \cdot \delta \mathbf{u}^{k}
      \end{pmatrix}.
@f}

Therefore, we arrive at the linearized system:
@f{eqnarray*}
   -\nu \Delta \delta \mathbf{u}^{k}
  + \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
  + \delta \mathbf{u}^{k} \cdot \nabla \mathbf{u}^{k}
  + \nabla \delta p^{k}
  = -F(\mathbf{x}^k), \\
   -\nabla \cdot\delta \mathbf{u}^{k}
  = \nabla \cdot \mathbf{u}^{k},
@f}

where $\textbf{u}^k$ and $p^k$ are the solutions from the
previous iteration. Additionally, the
right hand side of the second equation is not zero since the discrete
solution is not exactly divergence free (divergence free for the continuous
solution). The right hand side here acts as a correction which leads the
discrete solution of the velocity to be divergence free along Newton's
iteration. In this linear system, the only unknowns are the
update terms $\delta \textbf{u}^{k}$ and $\delta p^{k}$, and we can use a
similar strategy to the one used in step-22 (and derive the weak form in the
same way).

Now, Newton's iteration can be used to solve for the update terms:

<ol>
  <li>Initialization: Initial guess $u_0$ and $p_0$, tolerance $\tau$;</li>
  <li>Linear solve to compute update term $\delta\textbf{u}^{k}$ and
      $\delta p^k$;</li>
  <li>Update the approximation:
      $\textbf{u}^{k+1} = \textbf{u}^{k} + \delta\textbf{u}^{k}$ and
      $p^{k+1} = p^{k} + \delta p^{k}$;</li>
  <li>Check residual norm: $E^{k+1} = \|F(\mathbf{u}^{k+1}, p^{k+1})\|$:
      <ul>
        <li>If $E^{k+1} \leq \tau$, STOP.</li>
        <li>If $E^{k+1} > \tau$, back to step 2.</li>
      </ul></li>
</ol>

<h3> Finding an Initial Guess </h3>

The initial guess needs to be close enough to the solution for Newton's method
to converge; hence, finding a good starting value is crucial to the nonlinear
solver.

When the viscosity $\nu$ is large, a good initial guess can be obtained
by solving the Stokes equation with viscosity $\nu$. While problem dependent,
this works for $\nu \geq 1/400$ for the test problem considered here.

However, the convective term $(\mathbf{u}\cdot\nabla)\mathbf{u}$ will be
dominant if the viscosity is small, like $1/7500$ in test case 2.  In this
situation, we use a continuation method to set up a series of auxiliary NSEs with
viscosity approaching the one in the target NSE. Correspondingly, we create a
sequence $\{\nu_{i}\}$ with $\nu_{n}= \nu$, and accept that the solutions to
two NSE with viscosity $\nu_{i}$ and $\nu_{i+1}$ are close if $|\nu_{i} -
\nu_{i+1}|$ is small.  Then we use the solution to the NSE with viscosity
$\nu_{i}$ as the initial guess of the NSE with $\nu_{i+1}$. This can be thought of
as a staircase from the Stokes equations to the NSE we want to solve.

That is, we first solve a Stokes problem
@f{eqnarray*}
  -\nu_{1} \Delta \textbf{u} + \nabla p &=& \textbf{f}\\
  -\nabla \cdot \textbf{u} &=& 0
@f}

to get the initial guess for
@f{eqnarray*}
  -\nu_{1} \Delta \textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f},\\
  -\nabla \cdot \textbf{u} &=& 0,
@f}

which also acts as the initial guess of the continuation method.
Here $\nu_{1}$ is relatively large so that the solution to the Stokes problem with viscosity $\nu_{1}$
can be used as an initial guess for the NSE in Newton's iteration.

Then the solution to
@f{eqnarray*}
  -\nu_{i} \Delta \textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f},\\
  -\nabla \cdot \textbf{u} &=& 0.
@f}

acts as the initial guess for
@f{eqnarray*}
  -\nu_{i+1} \Delta \textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f},\\
  -\nabla \cdot \textbf{u} &=& 0.
@f}

This process is repeated with a sequence of viscosities $\{\nu_i\}$ that is
determined experimentally so that the final solution can used as a starting
guess for the Newton iteration.

<h3>The %Solver and Preconditioner </h3>

At each step of Newton's iteration, the problem results in solving a
saddle point systems of the form
@f{eqnarray*}
    \begin{pmatrix}
      A & B^{T} \\
      B & 0
    \end{pmatrix}
    \begin{pmatrix}
      U \\
      P
    \end{pmatrix}
    =
    \begin{pmatrix}
      F \\
      0
    \end{pmatrix}.
@f}

This system matrix has the same block structure as the one in step-22. However,
the matrix $A$ at the top left corner is not symmetric because of the nonlinear term.
Instead of solving the above system, we can solve the equivalent system
@f{eqnarray*}
    \begin{pmatrix}
      A + \gamma B^TW^{-1}B & B^{T} \\
      B & 0
    \end{pmatrix}
    \begin{pmatrix}
      U \\
      P
    \end{pmatrix}
    =
    \begin{pmatrix}
      F \\
      0
    \end{pmatrix}
@f}

with a parameter $\gamma$ and an invertible matrix $W$. Here
$\gamma B^TW^{-1}B$ is the Augmented Lagrangian term; see [1] for details.

Denoting the system matrix of the new system by $G$ and the right-hand
side by $b$, we solve it iteratively with right preconditioning
$P^{-1}$ as $GP^{-1}y = b$, where
@f{eqnarray*}
P^{-1} =
  \begin{pmatrix}
    \tilde{A} & B^T \\
    0         & \tilde{S}
  \end{pmatrix}^{-1}
@f}

with $\tilde{A} = A + \gamma B^TW^{-1}B$ and $\tilde{S}$ is the
corresponding Schur complement $\tilde{S} = B^T \tilde{A}^{-1} B$. We
let $W = M_p$ where $M_p$ is the pressure mass matrix, then
$\tilde{S}^{-1}$ can be approximated by
@f{eqnarray*}
\tilde{S}^{-1} \approx -(\nu+\gamma)M_p^{-1}.
@f}

See [1] for details.

We decompose $P^{-1}$ as
@f{eqnarray*}
P^{-1} =
  \begin{pmatrix}
    \tilde{A}^{-1} & 0 \\
    0              & I
  \end{pmatrix}
  \begin{pmatrix}
    I & -B^T \\
    0 & I
  \end{pmatrix}
  \begin{pmatrix}
    I & 0 \\
    0 & \tilde{S}^{-1}
  \end{pmatrix}.
@f}

Here two inexact solvers will be needed for $\tilde{A}^{-1}$ and
$\tilde{S}^{-1}$, respectively (see [1]). Since the pressure mass
matrix is symmetric and positive definite,
CG with ILU as a preconditioner is appropriate to use for $\tilde{S}^{-1}$. For simplicity, we use
the direct solver UMFPACK for $\tilde{A}^{-1}$. The last ingredient is a sparse
matrix-vector product with $B^T$. Instead of computing the matrix product
in the augmented Lagrangian term in $\tilde{A}$, we assemble Grad-Div stabilization
$(\nabla \cdot \phi _{i}, \nabla \cdot \phi _{j}) \approx (B^T
M_p^{-1}B)_{ij}$, as explained in [2].

<h3> Test Case </h3>

We use the lid driven cavity flow as our test case; see [3] for details.
The computational domain is the unit square and the right-hand side is
$f=0$. The boundary condition is
@f{eqnarray*}
  (u(x, y), v(x,y)) &=& (1,0) \qquad\qquad \textrm{if}\ y = 1 \\
  (u(x, y), v(x,y)) &=& (0,0) \qquad\qquad \textrm{otherwise}.
@f}

When solving this problem, the error consists of the nonlinear error (from
Newton's iteration) and the discretization error (dependent on mesh size). The
nonlinear part decreases with each Newton iteration and the discretization error
reduces with mesh refinement. In this example, the solution from the coarse
mesh is transferred to successively finer meshes and used as an initial
guess. Therefore, the nonlinear error is always brought below the tolerance of
Newton's iteration and the discretization error is reduced with each mesh
refinement.

Inside the loop, we involve three solvers: one for $\tilde{A}^{-1}$,
one for $M_p^{-1}$ and one for $Gx=b$. The first two
solvers are invoked in the preconditioner and the outer solver gives us
the update term. Overall convergence is controlled by the nonlinear residual;
as Newton's method does not require an exact Jacobian, we employ FGMRES with a
relative tolerance of only 1e-4 for the outer linear solver. In fact,
we use the truncated Newton solve for this system.
As described in step-22, the inner linear solves are also not required
to be done very accurately. Here we use CG with a relative
tolerance of 1e-6 for the pressure mass matrix. As expected, we still see convergence
of the nonlinear residual down to 1e-14. Also, we use a simple line
search algorithm for globalization of the Newton method.

The cavity reference values for $\mathrm{Re}=400$ and $\mathrm{Re}=7500$ are
from [4] and [5], respectively, where $\mathrm{Re}$ is the Reynolds number and
can be located at [8]. Here the viscosity is defined by $1/\mathrm{Re}$.
Even though we can still find a solution for $\mathrm{Re}=10000$ and the
references contain results for comparison, we limit our discussion here to
$\mathrm{Re}=7500$. This is because the solution is no longer stationary
starting around $\mathrm{Re}=8000$ but instead becomes periodic, see [7] for
details.

<h3> References </h3>
<ol>

  <li>  An Augmented Lagrangian-Based Approach to the Oseen Problem, M. Benzi and M. Olshanskii, SIAM J. SCI. COMPUT. 2006
  <li>  Efficient augmented Lagrangian-type preconditioning for the Oseen problem using Grad-Div stabilization, Timo Heister and Gerd Rapin
  <li>  http://www.cfd-online.com/Wiki/Lid-driven_cavity_problem
  <li>  High-Re solution for incompressible flow using the Navier-Stokes Equations and a Multigrid Method, U. Ghia, K. N. Ghia, and C. T. Shin
  <li>  Numerical solutions of 2-D steady incompressible driven cavity flow at high Reynolds numbers, E. Erturk, T.C. Corke and C. Gokcol
  <li> Implicit Weighted ENO Schemes for the Three-Dimensional Incompressible Navier-Stokes Equations, Yang et al, 1998
  <li> The 2D lid-driven cavity problem revisited, C. Bruneau and M. Saad, 2006
  <li> https://en.wikipedia.org/wiki/Reynolds_number
</ol>


examples/step-57/doc/results.dox
<h1>Results</h1>

Now we use the method we discussed above to solve Navier Stokes equations with
viscosity $1/400$ and $1/7500$.

<h3> Test case 1: Low Reynolds Number </h3>

In the first test case the viscosity is set to be $1/400$. As we discussed in the
introduction, the initial guess is the solution to the corresponding Stokes
problem. In the following table, the residuals at each Newton's iteration on
every mesh is shown. The data in the table shows that Newton's iteration
converges quadratically.

<table align="center" class="doxtable">
<tr>
    <th>$\mathrm{Re}=400$</th>
    <th colspan="2">Mesh0</th>
    <th colspan="2">Mesh1</th>
    <th colspan="2">Mesh2</th>
    <th colspan="2">Mesh3</th>
    <th colspan="2">Mesh4</th>
</tr>
<tr>
    <th>Newton iter   </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
</tr>
<tr>
  <td>1</td>
  <td>3.7112e-03</td>
  <td>5</td>
  <td>6.4189e-03</td>
  <td>3</td>
  <td>2.4338e-03</td>
  <td>3</td>
  <td>1.0570e-03</td>
  <td>3</td>
  <td>4.9499e-04</td>
  <td>3</td>
</tr>
<tr>
  <td>2</td>
  <td>7.0849e-04</td>
  <td>5</td>
  <td>9.9458e-04</td>
  <td>5</td>
  <td>1.1409e-04</td>
  <td>6</td>
  <td>1.3544e-05</td>
  <td>6</td>
  <td>1.4171e-06</td>
  <td>6</td>
</tr>
<tr>
  <td>3</td>
  <td>1.9980e-05</td>
  <td>5</td>
  <td>4.5007e-05</td>
  <td>5</td>
  <td>2.9020e-08</td>
  <td>5</td>
  <td>4.4021e-10</td>
  <td>6</td>
  <td>6.3435e-11</td>
  <td>6</td>
</tr>
<tr>
  <td>4</td>
  <td>2.3165e-09</td>
  <td>6</td>
  <td>1.6891e-07</td>
  <td>5</td>
  <td>1.2338e-14</td>
  <td>7</td>
  <td>1.8506e-14</td>
  <td>8</td>
  <td>8.8563e-15</td>
  <td>8</td>
</tr>
<tr>
  <td>5</td>
  <td>1.2585e-13</td>
  <td>7</td>
  <td>1.4520e-11</td>
  <td>6</td>
  <td>1.9044e-13</td>
  <td>8</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>6</td>
  <td></td>
  <td></td>
  <td>1.3998e-15</td>
  <td>8</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
</table>






The following figures show the sequence of generated grids. For the case
of $\mathrm{Re}=400$, the initial guess is obtained by solving Stokes on an
$8 \times 8$ mesh, and the mesh is refined adaptively. Between meshes, the
solution from the coarse mesh is interpolated to the fine mesh to be used as an
initial guess.

<table align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh0.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh1.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh2.png" width="232px" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh3.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh4.png" width="232px" alt="">
    </td>
  </tr>
</table>

This picture is the graphical streamline result of lid-driven cavity with
$\mathrm{Re}=400$.
<img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Streamline.png" alt="">

Then the solution is compared with a reference solution
from [4] and the reference solution data can be found in the file "ref_2d_ghia_u.txt".

<img src="https://www.dealii.org/images/steps/developer/step-57.compare-Re400.svg" style="width:50%" alt="">

<h3> Test case 2: High Reynolds Number </h3>

Newton's iteration requires a good initial guess. However, the nonlinear term
dominates when the Reynolds number is large, so that the solution to the Stokes
equations may be far away from the exact solution. If the Stokes solution acts
as the initial guess, the convergence will be lost. The following picture
shows that the nonlinear iteration gets stuck and the residual no longer decreases
in further iterations.

<img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_loss_convergence.svg" style="width:50%" alt="">

The initial guess, therefore, has to be obtained via a continuation method
which has been discussed in the introduction. Here the step size in the continuation method, that is $|\nu_{i}-\nu_{i+1}|$, is 2000 and the initial
mesh is of size $32 \times 32$. After obtaining an initial guess, the mesh is
refined as in the previous test case. The following picture shows that at each
refinement Newton's iteration has quadratic convergence. 52 steps of Newton's
iterations are executed for solving this test case.

<img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_get_convergence.svg" style="width:50%" alt="">

We also show the residual from each step of Newton's iteration on every
mesh. The quadratic convergence is clearly visible in the table.

<table align="center" class="doxtable">
  <tr>
    <th>$\mathrm{Re}=7500$</th>
    <th colspan="2">Mesh0</th>
    <th colspan="2">Mesh1</th>
    <th colspan="2">Mesh2</th>
    <th colspan="2">Mesh3</th>
    <th colspan="2">Mesh4</th>
  </tr>
  <tr>
    <th>Newton iter   </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
  </tr>
<tr>
  <td>1</td>
  <td>1.8922e-06</td>
  <td>6</td>
  <td>4.2506e-03</td>
  <td>3</td>
  <td>1.4299e-03</td>
  <td>3</td>
  <td>4.8793e-04</td>
  <td>2</td>
  <td>1.8998e-04</td>
  <td>2</td>
</tr>
<tr>
  <td>2</td>
  <td>3.1644e-09</td>
  <td>8</td>
  <td>1.3732e-03</td>
  <td>7</td>
  <td>4.1506e-04</td>
  <td>7</td>
  <td>9.1119e-05</td>
  <td>8</td>
  <td>1.3555e-05</td>
  <td>8</td>
</tr>
<tr>
  <td>3</td>
  <td>1.7611e-14</td>
  <td>9</td>
  <td>2.1946e-04</td>
  <td>6</td>
  <td>1.7881e-05</td>
  <td>6</td>
  <td>5.2678e-07</td>
  <td>7</td>
  <td>9.3739e-09</td>
  <td>7</td>
</tr>
<tr>
  <td>4</td>
  <td></td>
  <td></td>
  <td>8.8269e-06</td>
  <td>6</td>
  <td>6.8210e-09</td>
  <td>7</td>
  <td>2.2770e-11</td>
  <td>8</td>
  <td>1.2588e-13</td>
  <td>9</td>
</tr>
<tr>
  <td>5</td>
  <td></td>
  <td></td>
  <td>1.2974e-07</td>
  <td>7</td>
  <td>1.2515e-13</td>
  <td>9</td>
  <td>1.7801e-14</td>
  <td>1</td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>6</td>
  <td></td>
  <td></td>
  <td>4.4352e-11</td>
  <td>7</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>7</td>
  <td></td>
  <td></td>
  <td>6.2863e-15</td>
  <td>9</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
</table>






The sequence of generated grids looks like this:
<table align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh0.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh1.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh2.png" width="232px" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh3.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh4.png" width="232px" alt="">
    </td>
  </tr>
</table>
We compare our solution with reference solution from [5].
<img src="https://www.dealii.org/images/steps/developer/step-57.compare-Re7500.svg" style="width:50%" alt="">
The following picture presents the graphical result.
<img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Streamline.png" alt="">

Furthermore, the error consists of the nonlinear error,
which decreases as we perform Newton iterations, and the discretization error,
which depends on the mesh size. That is why we have to refine the
mesh and repeat Newton's iteration on the next finer mesh. From the table above, we can
see that the residual (nonlinear error) is below 1e-12 on each mesh, but the
following picture shows us the difference between solutions on subsequently finer
meshes.

<img src="https://www.dealii.org/images/steps/developer/step-57.converge-Re7500.svg" style="width:50%" alt="">

<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Compare to other solvers</h4>

It is easy to compare the currently implemented linear solver to just using
UMFPACK for the whole linear system. You need to remove the nullspace
containing the constant pressures and it is done in step-56. More interesting
is the comparison to other state of the art preconditioners like PCD. It turns
out that the preconditioner here is very competitive, as can be seen in the
paper [2].

The following table shows the timing results between our iterative approach
(FGMRES) compared to a direct solver (UMFPACK) for the whole system
with viscosity set to 1/400. Even though we use the same direct solver for
the velocity block in the iterative solver, it is considerably faster and
consumes less memory. This will be even more pronounced in 3d.

<table align="center" class="doxtable">
<tr>
  <th>Refinement Cycle</th>
  <th>DoFs</th>
  <th>Iterative: Total/s (Setup/s)</th>
  <th>Direct: Total/s (Setup/s)</th>
</tr>
<tr>
  <td>5</td>
  <td>9539</td>
  <td>0.10 (0.06)</td>
  <td>0.13 (0.12)</td>
</tr>
<tr>
  <td>6</td>
  <td>37507</td>
  <td>0.58 (0.37)</td>
  <td>1.03 (0.97)</td>
</tr>
<tr>
  <td>7</td>
  <td>148739</td>
  <td>3.59 (2.73)</td>
  <td>7.78 (7.53)</td>
</tr>
<tr>
  <td>8</td>
  <td>592387</td>
  <td>29.17 (24.94)</td>
  <td>(>4GB RAM)</td>
</tr>
</table>


<h4>3d computations</h4>

The code is set up to also run in 3d. Of course the reference values are
different, see [6] for example. High resolution computations are not doable
with this example as is, because a direct solver for the velocity block does
not work well in 3d. Rather, a parallel solver based on algebraic or geometric
multigrid is needed. See below.

<h4>Parallelization</h4>

For larger computations, especially in 3d, it is necessary to implement MPI
parallel solvers and preconditioners. A good starting point would be step-55,
which uses algebraic multigrid for the velocity block for the Stokes
equations. Another option would be to take a look at the list of codes
in the <a href="https://www.dealii.org/code-gallery.html">deal.II code
gallery</a>, which already contains parallel Navier-Stokes solvers.


