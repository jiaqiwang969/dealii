examples/step-1/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

<h3> About the tutorial </h3>

由于这是第一个教程程序，让我们首先评论一下这个教程和deal.II的其他文档应该如何工作。deal.II的文档基本上有三个不同的层次。

- 该教程。这是一个程序集，展示了deal.II在实践中的应用。它通常不在单个参数的层面上讨论单个函数，而是希望给出事物如何共同工作的大画面。换句话说，它讨论的是 "概念"：什么是deal.II的构件，它们如何在有限元程序中一起使用。

- 该手册。这是deal.II中每一个类和每一个（成员）函数的文档。例如，如果你点击本页顶部的 "主页 "或 "类 "选项卡，你就可以看到。在这里你可以查到 Triangulation::create_triangulation_compatibility 的第二个参数是什么意思，这只是一个略显晦涩的例子。当你知道你要做什么，但忘记了函数到底是怎么命名的，它的参数是什么，或者它的返回值是什么时，你就需要这种级别的文档。请注意，当你读完教程并点击任何一个类或函数名称时，你也会进入手册，也就是说，当你需要对某个函数或类进行更详细的描述时，教程包含了大量进入手册的链接。另一方面，手册并不是学习deal.II的好地方，因为它只给你一个微观的观点，而没有告诉你一个函数是如何融入大局的。

- 模块。这些是一起工作或具有相关功能的类和函数组。如果你点击本页顶部的 "模块 "标签，你就会进入一个列出许多此类组的页面。每个模块都讨论了这些类的基本原理；例如， @ref Sparsity 模块讨论了与存储矩阵的稀疏模式有关的各种不同问题。这就是中级水平的文档：它们给你一个特定领域的概述。例如，当你想知道存在哪些有限元类时，你会看一下 @ref fe 模块。当然，这些模块也与手册（有时也与教程）有交叉链接；如果你点击一个类的名字，比如说三角法，如果你想了解更多关于这个类的背景，也会在类名的右上方得到一个指向这个类所属模块的链接。

让我们回到教程中来，因为你正在看的是它的第一个程序（或 "步骤"）。每个教程的程序都被细分为以下几个部分。<ol>  <li>  <b>Introduction:</b> 这是讨论程序的作用，包括数学模型，以及与以前的教程程序相比有哪些新的编程技术。     <li>  <b>The commented program:</b> 广泛地记录了源代码的清单。在这里，我们经常记录个别行或代码块，并讨论它们做什么，如何做，以及为什么。评论中经常提到介绍，也就是说，你必须先了解<i>what</i>程序想要达到的目标（介绍中讨论的目标），然后才能了解<i>how</i>它想要达到的目标。     <li>  <b>Results:</b> 程序的输出，包括注释和解释。这一部分也经常有一个小节，给出如何在不同方向上扩展程序的建议；在早期的程序中，这是为了给你提供小实验的方向，旨在使你熟悉deal.II，而在后来的程序中，更多的是关于如何使用更高级的数值技术。     <li>  <b>The plain program:</b> 剥去所有注释的源代码。如果你想看到代码的 "全貌"，这很有用，因为程序的注释版本中间有很多文字，往往很难在屏幕上一次看到单个函数的全部代码。   </ol> 

教程不仅意味着是静态文档，而且你应该玩玩它们。为此，进入 <code>example/step-1</code> 目录（或任何你感兴趣的教程的编号），然后输入

@code
  cmake .
  make
  make run
@endcode

第一条命令设置了描述本教程程序所依赖的包含文件、如何编译以及如何运行的文件。这条命令应该也能找到已安装的deal.II库，这些库是在你按照<a href="../../readme.html" target="body">README</a>文件中描述的方式编译和安装一切时产生的。如果这个命令不能找到deal.II库，那么你需要用命令提供安装的路径

@code
  cmake -DDEAL_II_DIR=/path/to/installed/deal.II .
@endcode

而不是。

上述命令中的第二条将源代码编译成可执行文件，而最后一条则是执行它（严格来说，如果可执行文件还不存在， <code>make run</code> 也会编译代码，所以如果你想的话，你可以跳过第二条命令）。这就是运行代码和产生输出所需的全部内容，在教程程序的 "结果 "部分讨论。这个顺序需要在你想玩的所有教程目录中重复。

当学习这个库时，你需要玩玩它，看看会发生什么。为此，用你喜欢的编辑器打开 <code>example/step-1/step-1.cc</code> 的源文件，并以某种方式进行修改，保存它并按上述方式运行它。在这个程序的结果部分的末尾给出了一些可能的修改建议，在那里我们还提供了一些其他有用信息的链接。




<h3> Video lectures on tutorial programs </h3>

在关于deal.II和计算科学的<a
href="http://www.math.colostate.edu/~bangerth/videos.html">Wolfgang
Bangerth video lectures</a>中也讨论和演示了这个和其他几个教程程序。特别是，你可以看到他为运行这个和其他程序所执行的步骤，你会对可以用来处理deal.II的工具有一个更好的了解。特别是，第2和第4讲概述了deal.II和任何有限元代码的构建模块。(  @dealiiVideoLectureSeeAlso{2,4}) 

如果你还不熟悉使用Linux和在命令行上运行东西，你可能会有兴趣观看讲座2.9和2.91。(  @dealiiVideoLectureSeeAlso{2.9,2.91}) These give overviews over the command 行和关于编译程序时发生的事情，分别。

请注意，deal.II正在积极开发，在开发过程中，我们偶尔会对这些视频讲座中仍然引用的函数或类进行重新命名或废弃。  例如，视频讲座5中的步骤1代码使用了一个HyperShellBoundary类，后来被SphericalManifold类取代。此外，从deal.II 9.0版本开始， GridGenerator::hyper_shell() 现在自动将SphericalManifold附加到Triangulation上。否则，讲座材料的其余部分都是相关的。

<h3> What this program does </h3>

让我们回到步骤1，即当前的程序。在这第一个例子中，我们实际上并没有做很多事情，而是展示了两种技术：生成三角形对象的语法是什么，以及所有单元格上简单循环的一些元素。我们创建了两个网格，一个是有规律地细化的正方形（不是很刺激，但对于一些问题来说是常见的起始网格），还有一个是更多的几何尝试：一个环形域，向内边缘细化。通过这些，你将了解到每一个有限元程序都必须有的三样东西。一个用于网格的Triangulation类型的对象；对GridGenerator函数的调用以生成网格；以及涉及迭代器的所有单元的循环（迭代器是指针的泛化，在C++标准库中经常使用；在deal.II的背景下， @ref Iterators 模块谈到了它们）。

该程序在其他方面足够小，不需要大量的介绍。

 @dealiiVideoLecture{5,6} 




<h3> About scientific computing in general </h3>

如果你正在阅读这个教程程序，很可能你有兴趣继续使用deal.II来完成你自己的项目。因此，你即将开始一个使用大规模科学计算库的编程练习。除非你已经是大规模编程方法的资深用户，否则这对你来说可能是一个新的领域；伴随着所有的新规则，比如你将不得不处理别人写的代码，你可能不得不考虑记录自己的代码，因为你可能在一年后不记得它到底在做什么（或者因为别人也会使用它），或者想出一些方法来测试你的程序是否在做正确的事情。这些都不是我们通常训练数学家、工程师或科学家的东西，但当你开始编写超过几百行的软件时，这些就很重要了。请记住。制作软件并不等同于仅仅编写代码。

为了使你在这一旅程中生活得更轻松，让我们指出一些资源，这些资源在你开始任何大规模的编程之前是值得浏览的。

- 在<a href="https://github.com/dealii/dealii/wiki/Frequently-Asked-Questions">
  deal.II FAQ</a>中，有大量关于deal.II特定方面问题的答案，但也有一些更普遍的问题，如 "我如何调试科学计算代码？"或 "我能否训练自己写出错误更少的代码？"。

- 你将从成为一个更好的程序员中受益。为此，一个很好的资源是Steve McConnell的[Code Complete](https://en.wikipedia.org/wiki/Code_Complete)  @cite CodeComplete  。这本书已经有几年的历史了，最后一版是在2004年出版的，但它作为良好的编程实践指南的吸引力丝毫不减，一些主要的开发者把它作为他们研究小组每一代成员的集体阅读项目。

- <a href="http://software-carpentry.org/">Software Carpentry project</a>，提供了处理软件的许多重要主题的介绍，如版本控制、make文件、测试等。它是专门为科学家和工程师编写的，而不是为计算机科学家编写的，并以简短的、实用的课程为重点。

- <a href="https://bssw.io/">Better Scientific Software
  project</a>有大量的资源（和有趣的博文），涵盖了编写科学软件的许多方面。

- <a href="https://ideas-productivity.org/">IDEAS
  project</a>也有关于软件开发的资源，特别是用于并行计算。在该网站的 "活动 "部分有录制的教程和网络研讨会，涉及许多有趣的主题。

- 一篇关于<a href="http://arxiv.org/abs/1210.0530">Best
  Practices for Scientific Computing</a>的文章，介绍了许多方法，通过这些方法，你可以确保你是一个高效的程序员，写出的程序可以正常工作。

作为一个一般性建议。如果你期望在未来花几天时间来编写软件，请帮你自己的忙，学习能够使你的生活更有效率的工具，特别是调试器和集成开发环境。(  @dealiiVideoLectureSeeAlso{7,8,8.01,25})  你会发现，通过提高工作效率，你很快就会把学习这些工具的时间拿回来几倍!上面提到的几个视频讲座展示了如何使用集成开发环境或调试器等工具。


examples/step-1/doc/results.dox



<h1>Results</h1>

运行该程序会产生两个网格的图形（grid-1.svg和grid-2.svg）。你可以用大多数网络浏览器打开它们--在最简单的情况下，只要在文件系统资源管理器中打开当前目录，然后点击文件。如果你喜欢在命令行上工作，你可以用该文件调用你的网络浏览器。`firefox grid-1.svg`，`google-chrome grid-1.svg`，或者任何你的浏览器的名字。如果你这样做，这两个网格应该是这样的。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-1.grid-1-r9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-1.grid-2-r9.2.png" alt="">
    </td>
  </tr>
</table> 

左边那个，嗯，不是很刺激。右边的是&mdash；至少是&mdash；非传统的。这些图片对每个单元的 "细化水平 "进行了颜色编码。一个粗略的网格单元要被细分多少次才能得到给定的单元。在左图中，这是无聊的，因为网格被全局细化了若干次，也就是说，<i>every</i>单元被细化的次数相同。

(虽然第二个网状结构完全是人为捏造的，当然在应用中也不太实用，但令大家惊讶的是，它已经进入了文献：见  @cite Mu05  。显然，它至少对某些事情是有好处的）。)




<h3> Possibilities for extensions </h3>

<h4> Different adaptive refinement strategies </h4>

这个程序显然没有太多的功能，但特别是 <code>second_grid</code> 函数有一堆你可以玩弄它的地方。例如，你可以修改我们决定细化哪些单元格的标准。一个例子是把条件改成这样。

@code
      for (auto &cell: triangulation.active_cell_iterators())
        if (cell->center()[1] > 0)
          cell->set_refine_flag ();
@endcode

这将细化所有单元中心的 $y$ 坐标大于零的单元（我们通过解除引用 <code>cell</code> 迭代器调用的 <code>TriaAccessor::center</code> 函数返回一个Point<2>对象；下标 <code>[0]</code> 将得到 $x$ 坐标，下标 <code>[1]</code> 得到 $y$  坐标）。通过查看TriaAccessor提供的函数，你也可以使用更复杂的标准进行细化。

一般来说，你能用`cell->something()`形式的操作做什么，在文档中有点困难，因为`cell`不是一个指针，而是一个迭代器。你可以在单元格上调用的函数可以在`TriaAccessor'类的文档中找到（它的函数也可以在单元格的面或更普遍的、出现在三角形中的各种几何对象上调用），以及`CellAccessor'（它增加了一些专门针对*单元格的函数）。

对整个迭代器概念的更彻底的描述可以在 @ref Iterators 文档模块中找到。




<h4> Different geometries </h4>

另一种可能性是生成完全不同几何形状的网格。虽然对于复杂的几何体来说，使用网格生成器获得的网格是没有办法的，但是有大量的几何体，deal.II可以使用GridGenerator命名空间的函数来创建网格。许多这样的几何体（如本例程序中使用的几何体）包含有弯曲面的单元：换句话说，我们希望放置在边界上的新顶点位于一个圆上。deal.II通过Manifold类（以及从它继承的类）处理复杂的几何体；尤其是GridGenerator中对应于非笛卡尔网格的函数（如 GridGenerator::hyper_shell 或 GridGenerator::truncated_cone) 将一个Manifold对象附加到三角网格中应该是曲线的部分（分别为SphericalManifold和CylindricalManifold），并在应该是平面的部分使用另一个Manifold（FlatManifold）。关于这些类的设计理念和接口的描述，请参见Manifold的文档或 @ref manifold "manifold模块"。看看它们提供了什么，看看如何在这样的程序中使用它们。

我们还在第49步中讨论了其他各种创建和操作网格的方法（并描述了附加Manifolds的过程）。




<h4> Comments about programming and debugging </h4>

最后，我们对用deal.II修改或编写程序做一个总体的评论。当你开始使用教程程序或你自己的应用程序时，你会发现错误会发生：你的程序会包含一些代码，这些代码要么是立即中止程序，要么是一些简单地导致错误结果的bug。无论哪种情况，你都会发现知道如何使用调试器是非常有帮助的：你可能会通过把调试输出放到你的程序中，编译它，然后运行它来应付一段时间，但最终用调试器寻找错误会更快，更方便，更可靠，因为你不必总是重新编译程序，而且你可以检查变量的值和它们的变化。

与其推迟学习如何使用调试器，直到你真的看不到任何其他方法来发现一个错误，这里是我们将在这个项目中提供的一个建议：尽快学习如何使用调试器。这将是很好的时间投资。( 从顶层的<a
href="http://www.dealii.org/">deal.II webpage</a>链接到的 @dealiiVideoLectureSeeAlso{25}) The deal.II Frequently Asked 问题（FAQ）页面也提供了大量关于调试deal.II程序的提示。




<h4> More about graphical output </h4>

在你的论文或出版物中包含网格往往是有用的。为此，按细化级别对单元格进行颜色编码，并在每个单元格上打印单元格号，可能不是很有用。但这并不意味着一定要这样做 -- GridOut类允许为每种可能的输出格式设置标志（参见GridOutFlags命名空间中的类），以控制网格的具体绘制方式。当然，你也可以选择其他的输出文件格式，如VTK或VTU；这对三维网格特别有用，因为二维格式如SVG并不特别有用，因为它固定了三维物体的特定视角。因此，你可能想探索GridOut类中的其他选项。


examples/step-10/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>


这是一个相当短的例子，只显示了使用高阶映射的一些方面。我们所说的 <em> 映射 </em> 是指单元格（即单位线、正方形或立方体）与现实空间中的单元格之间的转换。在前面所有的例子中，我们都隐含地使用了线性或d-线性映射；你根本不会注意到这一点，因为如果你不做任何特别的事情，这就是发生的情况。然而，如果你的域有弯曲的边界，在有些情况下，边界的片状线性逼近（即通过直线段）是不够的，你希望你的计算域也是一个使用弯曲边界的真实域的逼近。如果边界近似使用分片的二次抛物线来近似真实边界，那么我们说这是二次或 $Q_2$ 的近似。如果我们使用成片的立体多项式的图形，那么这是一个 $Q_3$ 的近似，以此类推。




对于某些微分方程，已知如果精确域的边界是弯曲的，那么边界的片状线性近似，即 $Q_1$ 映射，是不够的。例如，使用 $C^1$ 元素的偏谐方程，或具有弯曲反射边界的域上的气体动力学的欧拉方程。在这些情况下，有必要使用高阶映射来计算积分。如果我们不使用这样的高阶映射，那么边界的逼近顺序将主导整个数值方案的收敛顺序，而不考虑域的内部离散化的收敛顺序。




我们没有用这些更复杂的例子来证明高阶映射的使用，而是只做了一个简单的计算：用两种不同的方法计算 $\pi=3.141592653589793238462643\ldots$ 的值。




第一种方法使用单位半径的圆的三角形近似，并在其上积分一个单位幅度的常数函数（ $f = 1$ ）。当然，如果领域是精确的单位圆，那么面积将是 $\pi$ ，但由于我们只使用片状多项式段的近似，我们积分的面积值并不完全是 $\pi$  。然而，众所周知，当我们细化三角形时， $Q_p$ 映射以 $h^{p+1}$ 的阶数逼近边界，其中 $h$ 是网格大小。我们将检查圆的计算面积值，以及它们在不同映射的网格细化下向 $\pi$ 收敛的情况。我们还将发现一种收敛行为，这种行为一开始是令人惊讶的，但有一个很好的解释。




第二种方法与此类似，但这次不使用三角形单位圆的面积，而是使用其周长。   $\pi$ 然后用周长的一半来近似，因为我们选择半径等于1。




 @note  本教程实质上展示了如何为积分选择一个特定的映射，方法是将一个特定的几何体附加到三角形上（例如在步骤1中已经完成），然后将一个映射参数传递给FEValues类，该类用于deal.II中的所有积分。我们选择的几何体是一个圆，deal.II已经有一个可以使用的类（SphericalManifold）。如果你想定义你自己的几何体，例如，因为它很复杂，不能用deal.II中已有的类来描述，你会想通过步骤53来阅读。


examples/step-10/doc/results.dox



<h1>Results</h1>


该程序执行两个任务，第一个是生成映射域的可视化，第二个是通过所述的两种方法计算π。让我们先看一下生成的图形。它们是以Gnuplot格式生成的，可以用以下命令查看

@code
set style data lines
set size ratio -1
unset key
unset xtics
unset ytics
plot [-1:1][-1:1] "ball_0_mapping_q_1.dat" lw 4 lt rgb "black"
@endcode

或使用其他文件名之一。第二行确保生成的输出的长宽比实际上是1:1，也就是说，一个圆在你的屏幕上被画成一个圆，而不是一个椭圆。第三行关闭了图形中的键，因为那只会打印信息（文件名），而这些信息现在并不那么重要。同样地，第四行和第五行关闭了刻度线。然后生成具有特定线宽（"lw"，这里设置为4）和线型（"lt"，这里选择线应使用RGB颜色 "黑色"）的图。

下表显示了 $Q_1$ 、 $Q_2$ 和 $Q_3$ 映射的三角计算域，为原始粗网格（左）和一次均匀细化网格（右）。

<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_ball_0_q1.svg" alt="磁盘的五单元离散化。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_ball_1_q1.svg" alt="磁盘的20单元离散化（即。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_ball_0_q2.svg" alt="五格离散化的圆盘，边缘为二次方。边界与实际的圆几乎没有区别。" width="400" height="400" > </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_ball_1_q2.svg" alt="带有二次方边缘的20个单元离散化。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_ball_0_q3.svg" alt="带有三次方边缘的圆的五单元离散化。边界与实际的圆几乎没有区别。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_ball_1_q3.svg" alt="具有立方体边缘的20单元离散化。" width="400" height="400"> </div> </div>

这些图片显示了高阶映射的明显优势：它们在相当粗的网格上也能相当好地接近真实边界。为了进一步证明这一点，这里是使用 $Q_2$ 和 $Q_3$ 映射的粗网格的右上角四分之一圈的一部分，其中红色虚线标志着实际的圆。

<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_exact_vs_interpolate_q2.svg" alt="二次离散化的特写。二次插值和实际圆之间的距离很小。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_10_exact_vs_interpolate_q3.svg" alt="立方离散化的特写。立体插值和实际圆之间的距离非常小。" width="400" height="400"> </div> </div> </div>

很明显，二次映射很好地接近了边界，而对于三次映射来说，对于粗略的网格来说，近似域和真实域之间的差异已经很难看到了。你还可以看到，映射只在三角形的外部边界有一些变化。在内部，所有的线条仍然是由线性函数表示的，这就导致了只在边界的单元上进行额外的计算。因此，高阶映射通常不会比低阶映射明显地慢，因为额外的计算只在所有单元格的一个小子集上执行。




该程序的第二个目的是计算π的值，以达到良好的准确性。这是程序的这一部分的输出。

@code
Output of grids into gnuplot files:
===================================
Refinement level: 0
Degree = 1
Degree = 2
Degree = 3


Refinement level: 1
Degree = 1
Degree = 2
Degree = 3


Computation of Pi by the area:
==============================
Degree = 1
cells      eval.pi            error
    5 1.9999999999999993 1.1416e+00    -
   20 2.8284271247461890 3.1317e-01 1.87
   80 3.0614674589207174 8.0125e-02 1.97
  320 3.1214451522580511 2.0148e-02 1.99
 1280 3.1365484905459380 5.0442e-03 2.00
 5120 3.1403311569547516 1.2615e-03 2.00


Degree = 2
cells      eval.pi            error
    5 3.1045694996615860 3.7023e-02    -
   20 3.1391475703122267 2.4451e-03 3.92
   80 3.1414377167038290 1.5494e-04 3.98
  320 3.1415829366419006 9.7169e-06 4.00
 1280 3.1415920457576898 6.0783e-07 4.00
 5120 3.1415926155921117 3.7998e-08 4.00


Degree = 3
cells      eval.pi            error
    5 3.1410033851499288 5.8927e-04    -
   20 3.1415830393583839 9.6142e-06 5.94
   80 3.1415925017363797 1.5185e-07 5.98
  320 3.1415926512106696 2.3791e-09 6.00
 1280 3.1415926535525927 3.7200e-11 6.00
 5120 3.1415926535892100 5.8302e-13 6.00


Degree = 4
cells      eval.pi            error
    5 3.1415871927401131 5.4608e-06    -
   20 3.1415926314742428 2.2116e-08 7.95
   80 3.1415926535026202 8.7173e-11 7.99
  320 3.1415926535894498 3.4350e-13 7.99
 1280 3.1415926535897896 3.4671e-15 6.63
 5120 3.1415926535897909 2.4009e-15 0.53


Computation of Pi by the perimeter:
===================================
Degree = 1
cells      eval.pi            error
    5 2.8284271247461898 3.1317e-01    -
   20 3.0614674589207178 8.0125e-02 1.97
   80 3.1214451522580520 2.0148e-02 1.99
  320 3.1365484905459389 5.0442e-03 2.00
 1280 3.1403311569547525 1.2615e-03 2.00
 5120 3.1412772509327724 3.1540e-04 2.00


Degree = 2
cells      eval.pi            error
    5 3.1248930668550594 1.6700e-02    -
   20 3.1404050605605449 1.1876e-03 3.81
   80 3.1415157631807009 7.6890e-05 3.95
  320 3.1415878042798613 4.8493e-06 3.99
 1280 3.1415923498174534 3.0377e-07 4.00
 5120 3.1415926345931995 1.8997e-08 4.00


Degree = 3
cells      eval.pi            error
    5 3.1414940401456048 9.8613e-05    -
   20 3.1415913432549156 1.3103e-06 6.23
   80 3.1415926341726910 1.9417e-08 6.08
  320 3.1415926532906897 2.9910e-10 6.02
 1280 3.1415926535851355 4.6578e-12 6.00
 5120 3.1415926535897190 7.4216e-14 5.97


Degree = 4
cells      eval.pi            error
    5 3.1415921029432572 5.5065e-07     -
   20 3.1415926513737595 2.2160e-09  7.96
   80 3.1415926535810712 8.7222e-12  7.99
  320 3.1415926535897576 3.5525e-14  7.94
 1280 3.1415926535897936 4.6729e-16  6.25
 5120 3.1415926535897918 1.4929e-15 -1.68
@endcode






从输出的一个直接观察结果是，在所有情况下，数值都迅速收敛到 $\pi=3.141592653589793238462643$ 的真实值。请注意，对于 $Q_4$ 的映射，我们已经进入了四舍五入误差的制度，收敛率趋于平缓，这已经是相当多的了。然而，也请注意，对于 $Q_1$ 映射，即使在最细的网格上，精度也明显比 $Q_3$ 映射的粗网格上要差得多!




输出的最后一列显示了收敛顺序，以网格宽度的幂为单位  $h$  。在介绍中，我们曾说过  $Q_p$  映射的收敛顺序应该是  $h^{p+1}$  。然而，在所示的例子中，顺序是 $h^{2p}$  !这个起初令人惊讶的事实可以用 $Q_p$ 映射的特性来解释。在<i>p</i>阶时，它使用的支持点是基于<i>p</i>+1点的Gauss-Lobatto正交规则，以这样的方式选择支持点，使正交规则在2<i>p</i>阶时收敛。尽管这些点在这里只用于插值<i>p</i>阶多项式，但我们在数值评估积分时得到了超收敛效应，导致观察到的高阶收敛。这种效应在下面的出版物中也有详细讨论。A. Bonito, A. Demlow, and J. Owen:"拉普拉斯-贝特拉米算子的特征值和特征函数的有限元近似的先验误差估计"，提交，2018年）。)


examples/step-11/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

我们要考虑的问题是只带诺伊曼边界条件的拉普拉斯问题的解决方案。

@f{eqnarray*}


  -\Delta u &=& f \qquad \mathrm{in}\ \Omega,
  \\
  \partial_n u &=& g \qquad \mathrm{on}\ \partial\Omega.


@f}

众所周知，如果这个问题要有一个解决方案，那么力需要满足兼容性条件

@f[
  \int_\Omega f\; dx + \int_{\partial\Omega} g\; ds = 0.


@f]

我们将考虑这样的特殊情况： $\Omega$ 是围绕原点的半径为1的圆，而 $f=-2$  ， $g=1$  。这种选择满足了兼容性条件。

兼容性条件允许上述方程的解，但它仍然保留了一个模糊性：因为只有解的导数出现在方程中，解只确定到一个常数。出于这个原因，我们必须为数字解提出另一个条件，以固定这个常数。

对于这一点，有多种可能性。<ol>  <li>  将离散化的一个节点固定为零或任何其他固定值。   这相当于一个附加条件  $u_h(x_0)=0$  。虽然这是常见的做法，但不一定是个好主意，因为我们知道拉普拉斯方程的解只在  $H^1$  中，这不允许定义点值，因为它不是连续函数的子集。因此，即使固定一个节点对离散函数来说是允许的，但对连续函数来说是不允许的，在数值解的这一点上，人们常常可以看到由此产生的错误尖峰。

 <li>  将域上的均值固定为零或任何其他值。这在连续水平上是允许的，因为 $H^1(\Omega)\subset L^1(\Omega)$ 由Sobolev不等式决定，因此在离散水平上也是允许的，因为我们那里只考虑 $H^1$ 的子集。

 <li>  将域的边界上的均值固定为零或任何其他值。这在连续水平上也是允许的，因为 $H^{1/2}(\partial\Omega)\subset L^1(\partial\Omega)$  ，同样由Sobolev的不等式。   </ol>  我们将选择最后一种可能性，因为我们想用它来演示另一种技术。

虽然这描述了要解决的问题，但我们仍然要弄清楚如何实现它。基本上，除了额外的均值约束，我们已经多次解决了这个问题，使用的是迪里希特边界值，我们只需要放弃对迪里希特边界节点的处理。高阶映射的使用也是相当琐碎的，我们会在使用它的各个地方进行解释；在几乎所有可以想象的情况下，你只会把描述映射的对象视为一个黑盒子，你不需要担心，因为它们的唯一用途似乎是被传递到库的深处，在那里函数知道如何处理它们（即在 <code>FEValues</code> 类及其后代）。

这个程序中的棘手之处在于对均值约束的使用。幸运的是，库中有一个知道如何处理这种约束的类，我们已经经常使用它了，没有提到它的通用性。请注意，如果我们假设边界节点沿边界的间隔是相等的，那么均值约束

@f[
  \int_{\partial \Omega} u(x) \; ds = 0


@f]

可写为

@f[
  \sum_{i\in\partial\Omega_h} u_i = 0,


@f]

其中总和应贯穿位于计算域边界上的所有自由度指数。让我们用 $i_0$ 表示边界上数字最小的指数（或任何其他方便选择的指数），那么这个约束也可以用以下方式表示

@f[
  u_{i_0} = \sum_{i\in\partial\Omega_h\backslash i_0} -u_i.


@f]

幸运的是，这正是AffineConstraints类所设计的约束形式。请注意，我们在之前的几个例子中使用了这个类来表示悬空节点的约束，它也有这种形式：在这里，中间的顶点应具有相邻顶点的平均值。一般来说，AffineConstraints类被设计用来处理以下形式的仿生约束

@f[
  CU = b


@f]

其中 $C$ 表示一个矩阵， $b$ 表示一个向量， $U$ 是节点值的向量。在这种情况下，由于 $C$ 代表一个同质约束， $b$ 是零向量。

在这个例子中，沿边界的平均值允许这样的表示， $C$ 是一个只有一行的矩阵（即只有一个约束条件）。在实现中，我们将创建一个AffineConstraints对象，添加一个参考第一个边界节点 $i_0$ 的约束（即给矩阵添加另一行），并插入所有其他节点贡献的权重，在这个例子中刚好是 $-1$  。

稍后，我们将使用这个对象来消除线性方程组中的第一个边界节点，将其还原为一个没有常数偏移值的解。实施过程中的一个问题是，这个节点的明确消除会导致矩阵中出现一些额外的元素，我们事先不知道这些元素的位置，也不知道矩阵的每一行中会有多少额外的条目。我们将展示我们如何使用一个中间对象来解决这个问题。

但现在开始实施解决这个问题的方案......


examples/step-11/doc/results.dox



<h1>Results</h1>

这是该程序的输出结果。

@code
Using mapping with degree 1:
============================
cells  |u|_1    error
    5 0.680402 0.572912
   20 1.088141 0.165173
   80 1.210142 0.043172
  320 1.242375 0.010939
 1280 1.250569 0.002745
 5120 1.252627 0.000687


Using mapping with degree 2:
============================
cells  |u|_1    error
    5 1.177062 0.076252
   20 1.228978 0.024336
   80 1.245175 0.008139
  320 1.250881 0.002433
 1280 1.252646 0.000668
 5120 1.253139 0.000175


Using mapping with degree 3:
============================
cells  |u|_1    error
    5 1.193493 0.059821
   20 1.229825 0.023489
   80 1.245221 0.008094
  320 1.250884 0.002430
 1280 1.252646 0.000668
 5120 1.253139 0.000175
@endcode

正如我们所期望的，每个不同的映射的收敛顺序显然是与网格大小成二次方的。不过 <em> 有趣的是，双线性映射（即1度）的误差比高阶映射的误差大三倍以上；因此在这种情况下，使用高阶映射显然是有利的，不是因为它提高了收敛顺序，而只是为了减少收敛顺序前的常数。另一方面，除了在非常粗的网格上，使用立方体映射只能进一步改善结果，幅度微乎其微。

我们还可以通过使用例如ParaView来可视化底层网格。下面的图片显示了不同映射度的初始网格。

 <img src="https://www.dealii.org/images/steps/developer/step-11.cycle_0.png" alt=""> 

显然，当我们从线性映射到二次映射时，这种影响是最明显的。这也反映在上表中给出的误差值中。从二次方到三次方的效果没有那么明显，但由于对圆形边界的描述更加准确，所以还是很明显的。

接下来，让我们看看三次全局细化后的网格

 <img src="https://www.dealii.org/images/steps/developer/step-11.cycle_3.png" alt=""> 

在这里，差异就不那么明显了，特别是对于高阶映射。事实上，在这个细化水平上，表格中报告的误差值在二度和三度的映射之间基本上是相同的。


examples/step-12/doc/intro.dox

 <br> 

<i> Note: A variant called step-12b of this tutorial exists, using
MeshWorker and LocalIntegrators instead of assembling matrices using
FEInterfaceValues as is done in this tutorial.
</i>

<a name="Intro"></a>

<h1>An example of an advection problem using the Discountinuous Galerkin method</h1>

<h3>Overview</h3>

本例专门介绍了 <em> 非连续Galerkin方法 </em> ，简称为DG方法。它包括以下内容。<ol>  <li>  用DG方法对线性平流方程进行离散化。     <li>  使用FEInterfaceValues组装跳跃项和单元间界面上的其他表达式。     <li>  使用 MeshWorker::mesh_loop().   </ol>  组合系统矩阵。

这个项目特别关注的是DG方法的循环。这些被证明是特别复杂的，主要是因为对于面的条件，我们必须分别区分边界、规则的内部面和有悬挂节点的内部面的情况。 MeshWorker::mesh_loop() 处理了单元和面迭代的复杂性，并允许为不同的单元和面项指定 "工作者"。面条款本身的整合，包括对自适应细化面的整合，是通过FEInterfaceValues类完成的。

<h3>The equation</h3>

本例中解决的模型问题是线性平流方程

@f[
  \nabla\cdot \left({\mathbf \beta} u\right)=0 \qquad\mbox{in }\Omega,


@f]

受制于边界条件

@f[
u=g\quad\mbox{on }\Gamma_-,


@f]

在域的边界 $\Gamma=\partial\Omega$ 的流入部分 $\Gamma_-$ 。  这里， ${\mathbf \beta}={\mathbf \beta}({\bf x})$ 表示一个矢量场， $u$ 是（标量）解函数， $g$ 是边界值函数。

@f[
\Gamma_- \dealcoloneq \{{\bf x}\in\Gamma, {\mathbf \beta}({\bf x})\cdot{\bf n}({\bf x})<0\}


@f]

表示域边界的流入部分， ${\bf n}$ 表示边界的单位外向法线 $\Gamma$  。这个方程是本教程第9步中已经考虑过的平流方程的保守版本。


在每个单元格 $T$ 上，我们从左边乘以一个测试函数 $v_h$ ，并通过部分整合得到。

@f[
  \left( v_h, \nabla \cdot (\beta u_h) \right)_T
= -(\nabla v_h, \beta u_h) + \int_\Gamma v_h u_h \beta \cdot n


@f]

当对所有单元 $T$ 求和时，边界积分是在所有内部和外部面进行的，因此，有三种情况。<ol>  <li>  流入的外部边界（我们用给定的 $g$ 代替 $u_h$ ）。     $\int_{\Gamma_-} v_h g \beta \cdot n$   <li>  流出的外部边界。     $\int_{\Gamma_+} v_h u_h \beta \cdot n$   <li> 内面（两边的积分变成了跳跃，我们使用上风速度）。     $\int_F [v_h] u_h^{\text{upwind}} \beta \cdot n$   </ol> 。

这里，跳跃被定义为 $[v] = v^+ - v^-$ ，其中上标指的是面的左（'+'）和右（'-'）值。如果 $\beta \cdot n>0$ ，上风值 $u^{\text{upwind}}$ 被定义为 $u^+$ ，否则为 $u^-$ 。

因此，依赖网格的弱形式为：。

@f[
\sum_{T\in \mathbb T_h} -\bigl(\nabla \phi_i,{\mathbf \beta}\cdot \phi_j \bigr)_T +
\sum_{F\in\mathbb F_h^i} \bigl< [\phi_i], \phi_j^{upwind} \beta\cdot \mathbf n\bigr>_{F} +
\bigl<\phi_i, \phi_j \beta\cdot \mathbf n\bigr>_{\Gamma_+}
= -\bigl<\phi_i, g \beta\cdot\mathbf n\bigr>_{\Gamma_-}.


@f]

这里， $\mathbb T_h$ 是三角形的所有活动单元的集合， $\mathbb F_h^i$ 是所有活动内部面的集合。这种公式被称为上风非连续Galerkin方法。

为了实现这种双线性形式，我们需要用通常的方法计算单元项（第一个和）来实现单元上的积分，用FEInterfaceValues计算界面项（第二个和），以及边界项（另外两个项）。所有这些的求和是通过 MeshWorker::mesh_loop(). 完成的。




<h3>The test problem</h3>

我们在 $\Omega=[0,1]^2$ 上求解平流方程， ${\mathbf \beta}=\frac{1}{|x|}(-x_2, x_1)$ 代表一个圆形的逆时针流场， $g=1$ 代表 ${\bf x}\in\Gamma_-^1 := [0,0.5]\times\{0\}$ ， $g=0$ 代表 ${\bf x}\in
\Gamma_-\setminus \Gamma_-^1$  。

我们通过估计每个单元的梯度规范，自适应地细化网格，在一连串的网格上求解。在每个网格上求解后，我们以vtk格式输出解决方案，并计算解决方案的 $L^\infty$ 准则。由于精确解是0或1，我们可以用它来衡量数值解的过冲程度。


examples/step-12/doc/results.dox



<h1>Results</h1>


这个程序的输出包括控制台输出和vtk格式的解决方案。

@code
Cycle 0
  Number of active cells:       64
  Number of degrees of freedom: 256
  Solver converged in 4 iterations.
  Writing solution to <solution-0.vtk>
  L-infinity norm: 1.09057
Cycle 1
  Number of active cells:       112
  Number of degrees of freedom: 448
  Solver converged in 9 iterations.
  Writing solution to <solution-1.vtk>
  L-infinity norm: 1.10402
Cycle 2
  Number of active cells:       214
  Number of degrees of freedom: 856
  Solver converged in 16 iterations.
  Writing solution to <solution-2.vtk>
  L-infinity norm: 1.09813
Cycle 3
  Number of active cells:       415
  Number of degrees of freedom: 1660
  Solver converged in 26 iterations.
  Writing solution to <solution-3.vtk>
  L-infinity norm: 1.09579
Cycle 4
  Number of active cells:       796
  Number of degrees of freedom: 3184
  Solver converged in 44 iterations.
  Writing solution to <solution-4.vtk>
  L-infinity norm: 1.09612
Cycle 5
  Number of active cells:       1561
  Number of degrees of freedom: 6244
  Solver converged in 81 iterations.
  Writing solution to <solution-5.vtk>
@endcode



我们展示了初始网格的解决方案，以及经过两个和五个自适应细化步骤后的网格。

 <img src="https://www.dealii.org/images/steps/developer/step-12.sol-0.png" alt="">   <img src="https://www.dealii.org/images/steps/developer/step-12.sol-2.png" alt="">   <img src="https://www.dealii.org/images/steps/developer/step-12.sol-5.png" alt=""> 。

最后我们展示一个3D计算的图。

 <img src="https://www.dealii.org/images/steps/developer/step-12.sol-5-3d.png" alt=""> 


<a name="dg-vs-cg"></a>

<h3>Why use discontinuous elements</h3>

在这个程序中，我们使用了不连续的元素。这是一个合理的问题，为什么不简单地使用正常的、连续的元素呢？当然，对于每个有数值方法背景的人来说，答案是显而易见的：连续Galerkin（cG）方法对于输运方程是不稳定的，除非特别添加稳定项。然而，DG方法<i>is</i>则是稳定的。用目前的程序来说明这一点并不十分困难；事实上，只需要做以下的小修改就可以了。

- 将该元素改为FE_Q，而不是FE_DGQ。

- 以与步骤6完全相同的方式增加对悬挂节点约束的处理。

- 我们需要一个不同的求解器；步骤29中的直接求解器是一个方便的选择。一个有经验的deal.II用户将能够在10分钟内完成这一工作。

虽然上面显示了二维解决方案，在界面上含有一些小的尖峰，但是在网格细化的情况下，这些尖峰的高度是稳定的，当使用连续元素时，结果看起来有很大不同。

 <table align="center">
  <tr>
    <td valign="top">
      0 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-12.cg.sol-0.png" alt="">
    </td>
    <td valign="top">
      1 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-12.cg.sol-1.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      2 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-12.cg.sol-2.png" alt="">
    </td>
    <td valign="top">
      3 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-12.cg.sol-3.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      4 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-12.cg.sol-4.png" alt="">
    </td>
    <td valign="top">
      5 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-12.cg.sol-5.png" alt="">
    </td>
  </tr>
</table> 

在细化迭代5中，图像不能再以合理的方式绘制成三维图。因此我们展示了一个范围为 $[-1,2]$ 的彩色图（当然，精确解的解值位于 $[0,1]$ ）。在任何情况下，很明显，连续Galerkin解表现出振荡行为，随着网格的细化越来越差。

如果出于某种原因想使用连续元素，有很多策略可以稳定cG方法。讨论这些方法超出了本教程程序的范围；例如，感兴趣的读者可以看看步骤31。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

鉴于在这种情况下确切的解是已知的，进一步扩展的一个有趣的途径是确认这个程序的收敛顺序。在目前的情况下，解是非光滑的，因此我们不能期望得到特别高的收敛阶，即使我们使用高阶元素。但是，即使解<i>is</i>光滑，方程也不是椭圆的，因此，我们应该得到等于最优插值估计的收敛阶，这一点并不明显（例如，我们通过使用二次元会得到 $h^3$ 在 $L^2$ 准则下的收敛）。

事实上，对于双曲方程来说，理论预测常常表明，我们所能希望的最好结果是比插值估计值低二分之一的阶。例如，对于流线扩散法（此处用于稳定传输方程解的DG法的替代方法），可以证明对于度数为 $p$ 的元素，在任意网格上的收敛阶为 $p+\frac 12$ 。虽然在均匀细化的网格上观察到的顺序经常是 $p+1$ ，但人们可以构建所谓的彼得森网格，在这些网格上实际上达到了更差的理论约束。这应该是比较容易验证的，例如使用 VectorTools::integrate_difference 函数。

一个不同的方向是观察运输问题的解决经常有不连续性，因此，我们<i>bisect</i>在每个坐标方向上的每个单元的网格可能不是最佳的。相反，一个更好的策略是只在平行于不连续的方向上切割单元。这被称为<i>anisotropic mesh refinement</i>，是步骤30的主题。


examples/step-12b/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

这是第16步的一个变体，唯一的变化是我们使用MeshWorker框架和预制的LocalIntegrator辅助类，而不是使用FEInterfaceValues来组装面的术语。

关于这个框架在实践中如何使用的细节，将作为本教程计划的一部分加以解释。

<h3>The testcase</h3>

我们在这里解决的问题与步骤12中的问题相同。


examples/step-12b/doc/results.dox



<h1>Results</h1>


这个程序的输出与步骤16非常相似，我们在此不重复输出。

我们展示了初始网格的解决方案，以及经过两个和五个自适应细化步骤后的网格。

 <img src="https://www.dealii.org/images/steps/developer/step-12.sol-0.png" alt="">   <img src="https://www.dealii.org/images/steps/developer/step-12.sol-2.png" alt="">   <img src="https://www.dealii.org/images/steps/developer/step-12.sol-5.png" alt=""> 。


然后，我们再次展示了最终的网格（经过5个细化步骤）和解决方案，这一次，我们使用了更漂亮的3D渲染（使用 DataOutBase::write_vtk 函数和基于VTK的VisIt可视化程序获得），更好地显示了细化网格上跳跃的尖锐性以及解决方案沿界面的过度和不足。

 <img src="https://www.dealii.org/images/steps/developer/step-12.grid-5.png" alt="">   <img src="https://www.dealii.org/images/steps/developer/step-12.3d-solution.png" alt=""> 。


最后我们展示一个3D计算的图。

 <img src="https://www.dealii.org/images/steps/developer/step-12.sol-5-3d.png" alt=""> 


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

关于进一步扩展的想法，请参见步骤12。


examples/step-13/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

<h3>Background and purpose</h3>


在这个例子程序中，我们将不太关注描述如何使用deal.II及其设施的新方法，而是介绍编写模块化和可扩展有限元程序的方法。其主要原因是现代研究软件的规模和复杂性：实现现代误差估计概念和自适应求解方法的应用程序往往变得相当大。例如，当这个程序是在2002年写的时候，deal.II的主要作者的三个最大的应用程序，在写这个例子程序的时候。<ol>  <li>  一个用非连续加尔金有限元法求解守恒双曲方程的程序。33,775行代码；  <li>  一个参数估计程序。28,980行代码；  <li>  一个波浪方程求解器：21,020行代码。   </ol> 

这个库本身--不包括示例程序和测试套件--在2002年春天有略多于15万行的代码。当然，现在已经大了好几倍了）。)这些应用程序的规模是一个人，甚至是一个有经验的程序员，所能处理的边缘。




上面的数字相当清楚地说明了一件事：没有被分解成较小的、大部分独立的片段的单体程序是没有办法生存的，因为即使是作者也会很快失去对程序不同部分之间各种依赖关系的概述。只有数据封装，例如使用面向对象的编程方法，以及通过定义小而固定的接口来实现模块化，才能帮助构建数据流和相互依赖。如果一个以上的人在开发一个程序，这也是一个绝对的先决条件，因为否则的话，混乱会很快出现，因为如果一个开发人员需要知道另一个人是否改变了不同模块的内部结构，如果它们没有被干净地分开的话。




在前面的例子中，你已经看到了库本身是如何被分成几个复合体的，每个复合体都建立在底层复合体之上，但相对独立于其他复合体。<ol>  <li>  三角形类复合物，以及相关的迭代器类； <li>  有限元类； <li>  DoFHandler类复合物，以及相关的迭代器，建立在三角形和有限元类之上； <li>  实现单元和实数单元间映射的类； <li>  FEValues类复合物，建立在有限元和映射之上。   </ol>  除了这些，还有大量的小类，当然还有以下的 "工具 "模块。<ol>  <li>  以各种图形格式输出；  <li>  线性代数类。   </ol>  这些复数也可以在deal.II手册网站的首页上以流程图的形式找到。




这个程序的目标是给出一个例子，说明一个相对简单的有限元程序的结构，使我们最终得到一组尽可能相互独立的模块。这使得我们可以在一端改变程序，而不必担心另一端的程序会被破坏，只要我们不触及两端交流的接口。当然，C++中的接口是抽象基类的声明。




在这里，我们将（再次）实现一个拉普拉斯求解器，尽管与之前的例子程序相比有一些不同。<ol>  <li>  实现数值求解方程过程的类不再负责驱动 "求解-估计误差-再求解 "的过程，而是将其委托给外部函数。这首先允许在更大的范围内将其作为一个构件，在这里拉普拉斯方程的解可能只是其中的一部分（例如，在非线性问题中，拉普拉斯方程可能要在每个非线性步骤中解决）。它还允许围绕该类建立一个框架，允许使用其他方程的求解器（但具有相同的外部接口），以备对不同类型的偏微分方程评估一些技术。   <li>  它将评估计算出的解的过程分割成一组单独的类。原因是，人们通常对偏微分方程的解本身不感兴趣，而是对它的某些方面感兴趣。例如，人们可能希望在弹性计算中计算某一边界的牵引力，或者在某一位置的接收器上计算地震波的信号。有时，人们可能对这些方面中的几个方面感兴趣。由于解的评估是通常不影响解的过程，我们把它拆成一个单独的模块，以便独立于解算器类的开发来开发这种评估过滤器。   <li>  将实现网格细化的类与计算解的类分开。   <li>  将我们要介绍的测试案例的描述与程序的其他部分分开。   <li>  使用WorkStream设施对线性系统的装配进行并行化。这是在 @ref threads "多处理器访问共享内存的并行计算 "文档模块中可以找到的广泛描述。该实现基本上遵循步骤9中已经描述过的内容。   </ol> 




该程序所做的事情并不新鲜。事实上，这更像是以前程序的混合体，从以前的例子中拆解了各种部分和功能。读者应该关注的是它们在这个程序中的安排方式，即程序中使用的软件设计技术，以达到实现所需数学方法的目的。然而，我们必须强调，软件设计在某种程度上也是一个主观的问题：不同的人有不同的编程背景，对编程的 "正确 "风格有不同的看法；因此，这个程序只表达了作者认为有用的做法，如果你对所选择的方式感到不舒服，不一定要采用这种风格来编写成功的数值软件。不过，它应该作为一个案例研究，用启发读者的想法来达到理想的目的。




一旦你完成了这个程序，你会注意到它的结构已经有些复杂了。然而，它只有大约850行代码，没有注释。在真正的应用程序中，当然会有注释和类文件，这将使其达到1200行。然而，与上面列出的应用程序相比，这仍然是很小的，因为它们的规模是它们的20到25倍。对于这么大的程序，从一开始就进行适当的设计是不可缺少的。否则，一旦它变得过于庞大而无法管理，就必须在其生命中的某一时刻重新设计它。




尽管如此，上面列出的三个程序都经历了重大的修改，甚至是重写。例如，波浪程序，在它还明显较小的时候，曾经被完全撕成了碎片，只是为了以更模块化的形式再次组装。那时，已经不可能在不影响代码的旧部分的情况下增加功能了（代码的主要问题是数据流：在时间依赖的应用中，主要的问题是什么时候把数据存储到磁盘，什么时候再重新加载；如果这不是以一种有组织的方式进行的，那么你最终会发现数据释放得太早，加载得太晚，或者根本没有释放）。尽管本例程序因此吸取了几年的经验，但它的设计肯定不是没有缺陷的，特别是可能不适合目标不同的应用。它应该作为一个灵感，让你以模块化的方式编写自己的应用程序，以避免过于紧密耦合的代码的陷阱。




<h3>What the program does</h3>


程序实际做什么甚至不是这个程序的重点，程序的结构更重要。然而，用几句话来描述就是：求解给定右手边的拉普拉斯方程，使其解为函数  $u(x,t)=\exp(x+\sin(10y+5x^2))$  。计算的目标是得到解在点 $x_0=(0.5,0.5)$ 处的值，并比较我们在两种细化标准下解决这个值的准确性，即全局细化和通过Kelly等人的误差指标细化，我们已经在以前的例子中使用过。




像往常一样，这些结果将在本文件的相应部分进行讨论。在这样做的过程中，我们将发现一个关于两个细化标准的相对性能的略微令人恼火的观察。在以后的例子程序中，在这个程序的基础上，我们将设计一个不同的方法，希望它能比这里讨论的技术表现更好。




现在，所有的理论和传闻背景都说了这么多。了解一个项目的最好方法是看它，所以它就在这里。


examples/step-13/doc/results.dox



<h1>Results</h1>




这个程序的结果并不那么有趣--毕竟它的目的不是为了演示一些新的数学思想，也不是为了演示如何用deal.II编程，而是为了利用我们在前面的例子中所开发的材料，形成一些演示以模块化和可扩展的方式建立现代有限元软件的方法。




尽管如此，我们当然会展示程序的结果。最感兴趣的是点值计算，为此我们实现了相应的评估类。该程序的结果（即输出）看起来如下。

@code
Running tests with "global" refinement criterion:


-------------------------------------------------
Refinement cycle: 0 1 2 3 4 5 6
DoFs  u(x_0)
   25 1.2868
   81 1.6945
  289 1.4658
 1089 1.5679
 4225 1.5882
16641 1.5932
66049 1.5945


Running tests with "kelly" refinement criterion:


------------------------------------------------
Refinement cycle: 0 1 2 3 4 5 6 7 8 9 10 11
DoFs  u(x_0)
   25 1.2868
   47 0.8775
   89 1.5365
  165 1.2974
  316 1.6442
  589 1.5221
 1093 1.5724
 2042 1.5627
 3766 1.5916
 7124 1.5876
13111 1.5942
24838 1.5932
@endcode




这里令人惊讶的是，精确的数值是1.59491554...，而且计算该解显然出奇的复杂，甚至只达到百分之一的精度，尽管该解是平滑的（事实上是无限常可微）。这种平滑性显示在程序生成的图形输出中，这里是粗网格和凯利细化指标的前9个细化步骤。


 <table width="80%" align="center">
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-0.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-1.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-2.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-3.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-4.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-5.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-6.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-7.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-8.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-13.solution-kelly-9.png" alt="">
    </td>
  </tr>
</table> 


当我们已经在观看图片时，这是第八个网格，从顶部看。


 <img src="https://www.dealii.org/images/steps/developer/step-13.grid-kelly-8.png" alt=""> 


然而，我们还没有完成对点值计算的评估。事实上，将两个细化标准的误差 $e=|u(x_0)-u_h(x_0)|$ 绘制成图，可以得到下面的图片。


 <img src="https://www.dealii.org/images/steps/developer/step-13.error.png" alt=""> 





这幅图 <em> 令人不安的是，自适应网格细化不仅没有像人们通常期望的那样比全局细化好，甚至明显更差，因为它的收敛是不规则的，在使用后续网格的值时，阻止了所有的外推技术!另一方面，全局细化提供了一个完美的 $1/N$ 或 $h^{-2}$ 收敛历史，并提供了各种机会，甚至可以通过外推法来改善点值。因此，在这个例子中，全局网格细化必须被认为是优越的!这更令人惊讶，因为评估点不是在左边的某个地方，那里的网格是粗糙的，而是在右边，自适应细化也应该细化评估点周围的网格。




因此，我们以一个问题来结束对这个例子程序的讨论。

<p align="center"> <strong>  <em>  如果适应性不比全局细化好，那么它有什么问题？ </em>  </strong>





 <em>  在这个例子的结尾处进行练习。 </em>  有一个简单的原因导致适应性网格解决方案的不良和不规则行为。通过观察每个步骤中评估点周围的网格，可以很简单地找到这个原因--这个数据在程序的输出文件中。因此，一个练习是修改网格细化程序，使问题（一旦你注意到它）得以避免。第二个练习是检查结果是否比全局细化要好，如果是的话，是否能达到更好的收敛顺序（就自由度数而言），或者只达到一个更好的常数。




(  <em>  对于没有耐心的人来说，非常简短的回答。 </em> 在误差较大的步骤中，网格在评估点上是不规则的，即一些相邻的单元有悬空的节点；这破坏了一些超级近似的效果，而全局细化的网格可以从中受益。答案2：这个快速黑客

@code
  bool refinement_indicated = false;
  for (const auto &cell : triangulation.active_cell_iterators())
    for (const auto v : cell->vertex_indices())
	  if (cell->vertex(v) == Point<dim>(.5,.5))
	    {
	      cell->clear_coarsen_flag();
	      refinement_indicated |= cell->refine_flag_set();
	    }
  if (refinement_indicated)
    for (const auto &cell : triangulation.active_cell_iterators())
      for (const auto v : cell->vertex_indices())
	    if (cell->vertex(v) == Point<dim>(.5,.5))
	      cell->set_refine_flag ();
@endcode

在执行细化之前，在Kelly细化类的细化函数中，将改善结果（练习：代码是怎么做的？不过，行为仍然是不规则的，所以不可能有关于收敛顺序的结果）。)


examples/step-14/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

<h3>The maths</h3>

Rolf Rannacher教授的海德堡小组，deal.II库的三位最初的作者在他们的博士期间和部分之后都属于该小组，自90年代中期以来一直从事有限元离散的适应性和误差估计的研究。其主要成就是开发了任意函数的误差估计，以及用于计算的最佳网格细化。

我们不会太详细地讨论这些概念的推导，但会在本例程序中实现主要思想。对于一般概念的彻底介绍，我们参考Becker和Rannacher的开创性工作 @cite BR95 ， @cite BR96r ，以及同一作者在Acta Numerica @cite BR01 上的概述文章；前者介绍了拉普拉斯方程的误差估计和一般函数输出的适应性概念，而后者给出了这些概念在大量其他更复杂方程中的应用例子。关于个别类型方程的应用，也可参见Becker  @cite Bec95  ,  @cite Bec98  , Kanschat  @cite Kan96  ,  @cite FK97  , Suttmeier  @cite Sut96  的出版物。] ,  @cite RS97  ,  @cite RS98c  ,  @cite RS99  , 班格特  @cite BR99b  ,  @cite Ban00w  ,  @cite BR01a  ,  @cite Ban02  , 和哈特曼  @cite Har02  ,  @cite HH01  ,  @cite HH01b  。所有这些工作，从Becker和Rannacher的原始介绍到对特定方程的个别贡献，后来都被Bangerth和Rannacher总结成一本书，涵盖所有这些主题，见  @cite BR03  。


其基本思想如下：在应用中，人们通常对解本身不感兴趣，而是对它的某些方面感兴趣。例如，在流动问题的模拟中，人们可能想知道浸在流体中的物体的升力或阻力；我们想知道的是这个量的最佳精度，而描述方程的其余解是否得到很好的解决并不是主要兴趣。同样，在弹性方面，人们可能想知道某些点的应力值，以猜测关节的最大负荷值是否安全，例如。或者，在辐射传输问题中，平均通量强度是有意义的。

在刚才列举的所有情况中，我们感兴趣的是解的函数 $J(u)$ 的评估，而不是各地的 $u$ 的值。由于精确的解决方案 $u$ 是不可用的，只有它的数字近似值 $u_h$ ，所以询问计算值 $J(u_h)$ 是否在精确值 $J(u)$ 的一定范围内是明智的，也就是说，我们要约束与这个函数有关的误差， $J(u)-J(u_h)$ 。

为了简化论述，我们假设感兴趣的量 $J$ 以及方程都是线性的，我们将特别展示具有同质Dirichlet边界条件的拉普拉斯方程的推导，尽管这一概念更为普遍。对于这种一般情况，我们参考上面列出的参考文献。  我们的目标是获得误差的界限，  $J(e)=J(u)-J(u_h)$  。为此，让我们用 $z$ 表示对偶问题的解，定义如下。

@f[
  a(\varphi,z) = J(\varphi) \qquad \forall \varphi,


@f]

其中 $a(\cdot,\cdot)$ 是与微分方程相关的双线性形式，测试函数从相应的解空间中选择。然后，以特殊的检验函数 $\varphi=e$ 作为误差，我们有

@f[
  J(e) = a(e,z)


@f]

根据加尔金正交性，我们可以将其改写为

@f[
  J(e) = a(e,z-\varphi_h)


@f]

其中 $\varphi_h$ 可以用我们认为方便的任何方式从离散测试空间中选择。

具体来说，对于拉普拉斯方程来说，其误差特性为

@f[
  J(e) = (\nabla e, \nabla(z-\varphi_h)).


@f]

因为我们不仅要用这个公式来计算误差，而且还要细化网格，所以我们需要将上面的表达式改写为单元格之和，每个单元格的贡献可以作为这个单元格的误差指标。因此，我们将标量产品分成每个单元的条款，并对每个单元进行分项积分。

@f{eqnarray*}
  J(e)
  &=&
  \sum_K (\nabla (u-u_h), \nabla (z-\varphi_h))_K
  \\
  &=&
  \sum_K (-\Delta (u-u_h), z-\varphi_h)_K
  + (\partial_n (u-u_h), z-z_h)_{\partial K}.


@f}

接下来我们使用 $-\Delta u=f$ ，对于拉普拉斯方程的解来说，该解足够平滑， $\partial_n u$ 几乎在任何地方都是连续的--因此在一个单元上涉及 $\partial_n u$ 的项与它的邻居上的项相抵消，其中法向量的符号相反。(不过 $\partial_n u_h$ 的情况并非如此。)在域的边界，没有可以抵消这个项的邻接单元，权重 $z-\varphi_h$ 可以选择为零，而整个项就消失了。

因此，我们有

@f{eqnarray*}
  J(e)
  &=&
  \sum_K (f+\Delta u_h, z-\varphi_h)_K


  - (\partial_n u_h, z-\varphi_h)_{\partial K\backslash \partial\Omega}.


@f}

在最后一步，注意当取 $u_h$ 的法向导数时，我们指的是从单元格的这一边取的这个量的值（对于通常的拉格朗日元素，导数不是跨边连续的）。然后我们重写上述公式，将单元格 $K$ 的一半边缘积分与相邻单元格 $K'$ 交换，得到

@f{eqnarray*}
  J(e)
  &=&
  \sum_K (f+\Delta u_h, z-\varphi_h)_K


  - \frac 12 (\partial_n u_h|_K + \partial_{n'} u_h|_{K'},
              z-\varphi_h)_{\partial K\backslash \partial\Omega}.


@f}

利用对于相邻单元格上的法向量，我们有 $n'=-n$ ，我们定义法向导数的跳跃为

@f[
  [\partial_n u_h] \dealcoloneq \partial_n u_h|_K + \partial_{n'} u_h|_{K'}
  =
  \partial_n u_h|_K - \partial_n u_h|_{K'},


@f]

并在将离散函数 $\varphi_h$ 设置为对偶解的点插值后得到最终形式， $\varphi_h=I_h z$ ，现在它仍然是任意的。

@f{eqnarray*}
  J(e)
  &=&
  \sum_K (f+\Delta u_h, z-I_h z)_K


  - \frac 12 ([\partial_n u_h],
              z-I_h z)_{\partial K\backslash \partial\Omega}.


@f}



借此，我们得到了关于任意（线性）函数的有限元离散化误差的精确表示  $J(\cdot)$  。其结构是残差估计的加权形式，因为 $f+\Delta u_h$ 和 $[\partial_n u_h]$ 都是在精确解上消失的单元和边缘残差，而 $z-I_h z$ 是表示某个单元上的残差对于给定函数的评估有多重要的权重。此外，它是一个面向单元的量，所以我们可以把它作为一个网格细化的标准。问题是：如何评估它？毕竟，评估需要了解对偶解 $z$ ，它带有我们想要知道的最准确的数量的信息。

在一些非常特殊的情况下，这个对偶解是已知的。例如，如果函数 $J(\cdot)$ 是点评估， $J(\varphi)=\varphi(x_0)$ ，那么对偶解必须满足

@f[


  -\Delta z = \delta(x-x_0),


@f]

右手边是狄拉克三角函数，对偶解是关于点 $x_0$ 的格林函数。对于简单的几何形状，这个函数是分析上已知的，我们可以把它插入误差表示公式中。

然而，我们不想把自己限制在这种特殊情况下。相反，我们将以数值方式计算对偶解，并通过一些数值获得的 $\tilde z$ 来近似 $z$ 。我们注意到，使用与原始解 $u_h$ 相同的方法来计算这个近似值 $\tilde z$ 是不够的，因为这样 $\tilde z-I_h \tilde z=0$ 和整体误差估计值将为零。相反，近似值 $\tilde z$ 必须来自一个比原始有限元空间更大的空间。有多种方法可以获得这样的近似值（见所引用的文献），我们将选择用高阶有限元空间来计算它。虽然这肯定不是最有效的方法，但它很简单，因为我们已经有了所有需要做的事情，而且还可以进行简单的实验。对于更有效的方法，再次参考给定的文献，特别是  @cite BR95  ,  @cite BR03  。

至此，我们结束了对这个程序的数学方面的讨论，转而讨论实际的实施。




 @note 如果你只关心计算误差的话，上面有两个步骤似乎没有必要：即(i)从 $z$ 中减去 $\phi_h$ ，以及(ii)将积分拆成单元格之和，并对每个单元格进行积分。事实上，这两个步骤根本没有改变 $J(e)$ ，因为在用 $\tilde z$ 替换 $z$ 之前，我们只考虑上面的相同点。换句话说，如果你只关心<i>estimating the global error</i> $J(e)$ ，那么这些步骤就没有必要。另一方面，如果你想把误差估计值也作为网格中每个单元的细化标准，那么就有必要(i)把估计值分解成单元的总和，(ii)以这样的方式按摩公式，使每个单元的贡献都与局部误差有关。(虽然上面的扭曲没有改变<i>sum</i> $J(e)$ 的值，但它们改变了我们为每个单元 $K$ 计算的值) 。为此，我们想把一切都写成 "残差乘以双重权重 "的形式，其中 "残差 "是随着近似度变得 $u_h$ 越来越好而归于零的东西。例如， $\partial_n
u_h$ 这个量不是残差，因为它只是收敛到精确解的梯度的（法线分量）。另一方面， $[\partial_n u_h]$ 是一个残差，因为它收敛于 $[\partial_n
u]=0$  。我们在制定 $J(e)$ 的最终形式时采取的所有步骤，实际上都是为了使最终公式变成一种形式，即当离散解 $u_h$ 收敛到 $u$ 时，每个项都收敛为零。这样就可以把每个单元的贡献看作是一个 "误差指标"，也会收敛为零--因为它应该随着网格的细化而收敛。




<h3>The software</h3>

第14步的例子程序在很大程度上建立在第13步程序中已经使用的技术上。它对上面解释的双重加权残差估计器的实现是通过派生出第二个类，正确地称为 <code>DualSolver</code>, from the <code>Solver</code> 基类，并有一个类(  <code>WeightedResidual</code> )将两者再次连接起来，控制原始和双重问题的解决，然后用两者来计算网格细化的误差指标。

这个程序延续了上一个例子的模块化概念，通过一个抽象的基类来实现双重功能，描述感兴趣的数量，并提供两个不同的功能来实现这个接口。因此，增加一个不同的兴趣量是很简单的。

其中一个更根本的区别是对数据的处理。一个常见的情况是，你开发了一个解决某个方程的程序，并用不同的右手边、不同的域、不同的系数和边界值等来测试它。通常情况下，这些都必须匹配，这样才能知道确切的解决方案，或者它们的组合根本就有意义。

我们将演示如何以一种简单而又非常灵活的方式实现这一目标。我们将把属于某个设置的所有东西放到一个类中，并围绕它提供一个小的C++砂浆，这样整个设置（域、系数、右手边等）就可以通过只改变 <em> 中的某个 </em> 地方来交换。

再进一步，我们还将所有描述程序如何工作的其他参数集中在一个地方，如有限元的顺序、最大自由度数、对计算出的解应执行的评估对象等等。这使得程序的配置更加简单，我们将在后面的程序中展示如何使用一个库类来处理通过读取输入文件来设置这些参数。总的来说，我们的目的是要减少程序中想要改变某些参数时可能需要查找的地方，因为在实践中发现，随着程序的发展，人们会忘记它们的位置。此外，把所有描述程序在某次运行中的选项放到一个文件中（可以和结果一起存储），比在程序中的某个地方设置各种标志更有助于结果的可重复性，因为在下次改变这个地方后，它们的准确值就会被遗忘。

不幸的是，这个程序已经变得相当长了。虽然这无疑降低了它作为一个示例程序的作用，但我们认为它是一个很好的起点，可以为其他类型的问题开发一个程序，涉及不同于这里处理的拉普拉斯方程的方程。此外，它显示了我们可以向你展示的关于我们的后验误差估计方法的一切，它的结构应该使你能够简单地调整这个方法以适应其他问题、其他函数、其他几何形状、系数等等。

作者认为，就数学的复杂性和添加扩展的简单性而言，本程序是他在范例程序中的杰作。如果你使用这个程序作为你自己程序的基础，我们希望你能在出版物中说明这一事实以及示例程序的作者Wolfgang Bangerth的名字，因为你的程序有相当一部分是由示例程序组成的。


examples/step-14/doc/results.dox



<h1>Results</h1>

<h3>Point values</h3>


这个程序提供了很多玩耍的可能性。因此，我们只能展示在这个程序的帮助下可以获得的所有可能结果的一小部分。然而，我们鼓励你通过改变主程序中的设置来尝试。在这里，我们先简单地让它运行，不做任何修改。

@code
Refinement cycle: 0
   Number of degrees of freedom=72
   Point value=0.03243
   Estimated error=0.000702385
Refinement cycle: 1
   Number of degrees of freedom=67
   Point value=0.0324827
   Estimated error=0.000888953
Refinement cycle: 2
   Number of degrees of freedom=130
   Point value=0.0329619
   Estimated error=0.000454606
Refinement cycle: 3
   Number of degrees of freedom=307
   Point value=0.0331934
   Estimated error=0.000241254
Refinement cycle: 4
   Number of degrees of freedom=718
   Point value=0.0333675
   Estimated error=7.4912e-05
Refinement cycle: 5
   Number of degrees of freedom=1665
   Point value=0.0334083
   Estimated error=3.69111e-05
Refinement cycle: 6
   Number of degrees of freedom=3975
   Point value=0.033431
   Estimated error=1.54218e-05
Refinement cycle: 7
   Number of degrees of freedom=8934
   Point value=0.0334406
   Estimated error=6.28359e-06
Refinement cycle: 8
   Number of degrees of freedom=21799
   Point value=0.0334444
@endcode




首先让我们看看这个程序实际计算的结果。在第七个网格上，原始和双重数值解看起来是这样的（使用的颜色方案旨在唤起科罗拉多州白雪皑皑的山峰，这个程序的原作者现在称之为家）。   <table align="center">
  <tr>
    <td width="50%">
      <img src="https://www.dealii.org/images/steps/developer/step-14.point-value.solution-7.9.2.png" alt="">
    </td>
    <td width="50%">
      <img src="https://www.dealii.org/images/steps/developer/step-14.point-value.solution-7-dual.9.2.png" alt="">
    </td>
  </tr>
</table> 显然，左下角的区域对于右上角的点值评估是如此不重要，以至于网格在那里完全没有被细化，尽管解在该单元的内角有奇异点由于右手边和领域的对称性，解决方案实际上应该是在右上角的所有四个角落，但是涉及到对偶解决方案的网格细化标准选择了不同的细化方式--因为我们说过，我们真正关心的只是右上角某个地方的单一函数值。




下面是一些在细化周期0、2、4（顶行）和5、7、8（底行）中产生的网格。

 <table width="80%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.grid-0.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.grid-2.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.grid-4.9.2.png" alt="" width="100%"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.grid-5.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.grid-7.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.grid-8.9.2.png" alt="" width="100%"></td>
  </tr>
</table> 

请注意解决角部奇异点和解决评估点周围的奇异点之间的微妙相互作用。手工生成这样的网格是相当困难的，因为这将涉及到定量地判断四个角的奇异点应该被解决多少，并设置与评估点附近的权重。




程序会打印出这个数量的点值和估计的误差。通过推断，我们可以猜测出精确的数值接近0.0334473，正负0.0000001（注意，我们从只有22000个（原始）自由度中得到近6个有效数字。这个数字不能单独从函数值中得到，但我使用了误差估计器大部分是精确的假设，并将计算值加上估计误差进行外推，得到真实值的近似值。用更多自由度的计算表明，这个假设确实是有效的。




从计算结果中，我们可以生成两个图表：一个显示点值中误差 $J(u)-J(u_h)$ （将外推值视为正确）的收敛性，以及我们将计算值 $J(u_h)$ 和估计误差eta相加得到的值（如果误差估计器 $eta$ 是精确的，那么值 $J(u_h)+\eta$ 将等于精确的点值，并且这个量的误差将总是零；然而，由于误差估计器只是对真实误差的一个-好的-近似值，我们只能通过这个来减少误差的大小）。)在这张图中，我们还指出了复杂度 ${\cal O}(1/N)$ ，以表明网格细化在这种情况下的作用是最佳的。第二张图比较了真实误差和估计误差，显示两者实际上是非常接近的，即使对于点值这样一个复杂的数量。


 <table width="80%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.error.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-value.error-estimation.png" alt="" width="100%"></td>
  </tr>
</table> 




<h3>Comparing refinement criteria</h3>


由于我们在使用由对偶加权误差估计器驱动的网格细化时接受了相当多的努力（用于解决对偶问题，以及评估误差表示），因此值得询问这种努力是否成功。为此，我们首先比较不同的网格细化标准所达到的误差水平。要产生这些数据，只需改变主程序中的网格细化准则变量的值。结果是这样的（对于Kelly指标中的权重，我们选择了 $1/(r^2+0.1^2)$ 这个函数，其中 $r$ 是到评估点的距离；可以证明，如果我们忽略边界的影响，这就是最佳权重）。

 <img src="https://www.dealii.org/images/steps/developer/step-14.point-value.error-comparison.png" alt=""> 




检查这些数字，我们看到对于全局细化，误差与 $O(1/(sqrt(N) log(N)))$ 成正比，而对于双重估计器 $O(1/N)$  。一般来说，我们看到双重加权误差估计器比其他细化指标要好，至少在与那些具有类似规则行为的指标相比时是如此。凯利指标产生的误差较小，但在画面上的跳动相当不规则，误差有时也会改变符号。因此，它的行为不允许将结果推断到更大的N值。此外，如果我们相信双重加权误差估计器的误差估计值，可以通过将估计的误差加入到计算值中来改善结果。因此在可靠性方面，加权估计器比凯利指标更好，尽管后者有时会产生较小的误差。




<h3>Evaluation of point stresses</h3>


除了评估某一点上的解的值，程序还提供了评估某一点上的X-导数的可能性，并且还可以为此定制网格细化的方法。要让程序计算这些量，只需将主函数中出现的两个 <code>PointValueEvaluation</code> 替换为 <code>PointXDerivativeEvaluation</code> ，然后让程序运行。

@code
Refinement cycle: 0
   Number of degrees of freedom=72
   Point x-derivative=-0.0719397
   Estimated error=-0.0126173
Refinement cycle: 1
   Number of degrees of freedom=61
   Point x-derivative=-0.0707956
   Estimated error=-0.00774316
Refinement cycle: 2
   Number of degrees of freedom=131
   Point x-derivative=-0.0568671
   Estimated error=-0.00313426
Refinement cycle: 3
   Number of degrees of freedom=247
   Point x-derivative=-0.053033
   Estimated error=-0.00136114
Refinement cycle: 4
   Number of degrees of freedom=532
   Point x-derivative=-0.0526429
   Estimated error=-0.000558868
Refinement cycle: 5
   Number of degrees of freedom=1267
   Point x-derivative=-0.0526955
   Estimated error=-0.000220116
Refinement cycle: 6
   Number of degrees of freedom=2864
   Point x-derivative=-0.0527495
   Estimated error=-9.46731e-05
Refinement cycle: 7
   Number of degrees of freedom=6409
   Point x-derivative=-0.052785
   Estimated error=-4.21543e-05
Refinement cycle: 8
   Number of degrees of freedom=14183
   Point x-derivative=-0.0528028
   Estimated error=-2.04241e-05
Refinement cycle: 9
   Number of degrees of freedom=29902
   Point x-derivative=-0.052814
@endcode






解决方案看起来与之前大致相同（准确的解决方案当然是 <em> 与 </em> 相同，只是网格发生了一点变化），但现在的对偶解决方案是不同的。评估点周围的特写显示了这一点。   <table align="center">
  <tr>
    <td width="50%">
      <img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.solution-7-dual.png" alt="">
    </td>
    <td width="50%">
      <img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.solution-7-dual-close-up.png" alt="">
    </td>
</table> 这次，细化周期0、5、6、7、8和9的网格是这样的。

 <table align="center" width="80%">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.grid-0.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.grid-5.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.grid-6.9.2.png" alt="" width="100%"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.grid-7.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.grid-8.9.2.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.grid-9.9.2.png" alt="" width="100%"></td>
  </tr>
</table> 

请注意，与我们在点评估中获得的网格相比，这些网格是不对称的。这是由于域和原始解可能是围绕对角线对称的，但 $x$ -导数不是，后者进入了细化标准。




然后，有趣的是，将感兴趣的量的实际计算值（即在某一点的解决方案的X导数）与参考值-0.0528223...正负0.0000005进行比较。我们通过在更细的网格上计算得到这个参考值，经过一些更细的网格细化，大约有13万个单元。回顾一下，如果在最佳情况下，误差是 $O(1/N)$ ，那么采用多十倍的单元格的网格，我们的结果就会多出一个数字。




在下图的左边部分，你再次看到误差向这个外推值的收敛，而在右边你看到真实和估计误差的比较。

 <table width="80%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.error.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.point-derivative.error-estimation.png" alt="" width="100%"></td>
  </tr>
</table> 

在初始阶段，真实的误差改变了它的符号，估计的误差又与它很好地匹配。还请注意，当使用估计误差来修正 $J(u_h)$ 的计算值时，误差有了极大的改善。




<h3>step-13 revisited</h3>


如果我们不选择 <code>Exercise_2_3</code> 的数据集，而是在主函数中选择 <code>CurvedRidges</code> ，并选择 $(0.5,0.5)$ 作为评价点，那么我们就可以重新进行前面的例子程序的计算，以比较在双重加权误差估计器帮助下得到的结果是否比之前的结果更好。




首先，分别用点评估和导数评估细化标准得到的9个自适应细化周期后的网格看起来是这样的。

 <table width="80%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.step-13.point-value.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.step-13.point-derivative.png" alt="" width="100%"></td>
  </tr>
</table> 

在网格中仍然可以看到解的特征，但是由于解是光滑的，对偶解的奇异点完全主导了网格细化准则，并导致网格强烈集中。第七次细化步骤后的解看起来像下面这样。

 <table width="40%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-14.step-13.solution-7.9.2.png" alt="" width="100%"></td>
  </tr>
</table> 

显然，在某些地方的解是比较差的，但是网格细化过程中应该注意到这些地方对计算点值并不重要。





下一步是将新的（基于二重性的）网格细化标准与旧的标准进行比较。这些是结果。

 <img src="https://www.dealii.org/images/steps/developer/step-14.step-13.error-comparison.png" alt=""> 




其结果是，嗯，有点混合。首先，Kelly指标因其不稳定的行为而失去了资格，多次改变了误差的符号，而且在网格细化下误差越来越大。双重加权误差估计器的误差呈单调下降，比加权凯利和全局细化要好，但幅度没有预期的那么大。在这里，这是由于全局细化可以利用评估点周围网格的规则结构，从而导致点误差的收敛顺序更好。然而，如果我们有一个不是局部矩形的网格，例如因为我们必须近似弯曲的边界，或者如果系数不是恒定的，那么全局细化网格的这种优势就会消失，而基于对偶性的估计器的良好性能将保持不变。







<h3>Conclusions and outlook</h3>


这里的结果并没有太明显地表明双加权误差估计方法在网格细化方面比其他网格细化标准（如Kelly指标）更有优势。这是由于所显示的应用相对简单的缘故。如果你还不相信这种方法确实有优势，请你浏览一下引言中提到的文献，其中提供了大量的例子，双加权方法可以将必要的数值工作减少几个数量级，使之成为计算某些数量的合理精度的唯一途径。




除了你可能对其作为网格细化标准提出的反对意见外，考虑到对可能想要计算的量的误差的准确认识是非常有用的，因为我们可以在对精度满意的时候停止计算。使用更传统的方法，很难得到任意量的精确估计，也许除了能量准则的误差，我们将不能保证我们计算的结果满足对其准确性的任何要求。另外，正如对点值和导数的评价所显示的那样，误差估计可以用来推断结果，在我们想知道的量上产生更高的精度。




抛开这些数学上的考虑，我们试图以模块化的方式编写程序，这样实现另一个测试案例，或另一个评估和双重功能就很简单。我们鼓励你把这个程序作为你自己实验的基础，并且玩一玩。


examples/step-15/doc/intro.dox

 <br> 

<i>
This program grew out of a student project by Sven Wetterauer at the
University of Heidelberg, Germany. Most of the work for this program
is by him.
</i> <br>  。


<a name="Intro"></a>

<h1>Introduction</h1>

<h3>Foreword</h3>

这个程序涉及到一个非线性椭圆偏微分方程的例子，即[最小表面方程](https://en.wikipedia.org/wiki/Minimal_surface)。你可以想象这个方程的解来描述一个肥皂膜所跨越的表面，这个肥皂膜被一个封闭的金属环所包围。我们想象金属丝不只是一个平面的环，实际上是弯曲的。肥皂膜的表面张力将使该表面变成最小表面。最小表面方程的解描述了这个形状，电线的垂直位移是一个边界条件。为了简单起见，我们在此假定表面可以写成图形 $u=u(x,y)$ ，尽管很明显，构建这样的情况并不难，即钢丝弯曲的方式使得表面只能局部构建成图形，而不能整体构建。

因为这个方程是非线性的，所以我们不能直接解决它。相反，我们必须使用牛顿的方法来迭代计算解决方案。

 @dealiiVideoLecture{31.5,31.55,31.6}  （  @dealiiVideoLectureSeeAlso{31.65,31.7})  ）。




<h3>Classical formulation</h3>

在经典的意义上，该问题以如下形式给出。


  @f{align*}


    -\nabla \cdot \left( \frac{1}{\sqrt{1+|\nabla u|^{2}}}\nabla u \right) &= 0 \qquad
    \qquad &&\textrm{in} ~ \Omega
    \\
    u&=g \qquad\qquad &&\textrm{on} ~ \partial \Omega.
  @f}



 $\Omega$ 是我们将导线的位置投影到 $x-y$ 空间得到的域。在这个例子中，我们选择 $\Omega$ 作为单位盘。

如上所述，我们用牛顿方法解决这个方程，在这个方法中，我们从 $(n-1)$ 个方程计算出 $n$ 个近似解，并使用阻尼参数 $\alpha^n$ 来获得更好的全局收敛行为。   @f{align*}
    F'(u^{n},\delta u^{n})&=- F(u^{n})
    \\
    u^{n+1}&=u^{n}+\alpha^n \delta u^{n}
  @f}

与@f[
    F(u) \dealcoloneq -\nabla \cdot \left( \frac{1}{\sqrt{1+|\nabla u|^{2}}}\nabla u \right)
  @f]

而 $F'(u,\delta u)$ 是F在 $\delta u$ 方向的导数。

@f[
  F'(u,\delta u)=\lim \limits_{\epsilon \rightarrow 0}{\frac{F(u+\epsilon \delta u)-
  F(u)}{\epsilon}}.


@f]



通过寻找 $F'(u,\delta u)$ 是什么，我们发现我们必须在每一个牛顿步骤中解决一个线性椭圆PDE， $\delta u^n$ 是的解。

  @f[


  - \nabla \cdot \left( \frac{1}{\left(1+|\nabla u^{n}|^{2}\right)^{\frac{1}{2}}}\nabla
  \delta u^{n} \right) +
  \nabla \cdot \left( \frac{\nabla u^{n} \cdot
  \nabla \delta u^{n}}{\left(1+|\nabla u^{n}|^{2}\right)^{\frac{3}{2}}} \nabla u^{n}
  \right)  =


  -\left( - \nabla \cdot \left( \frac{1}{\left(1+|\nabla u^{n}|^{2}\right)^{\frac{1}{2}}}
  \nabla u^{n} \right) \right)
  @f]



为了解决最小表面方程，我们必须重复解决这个方程，每一个牛顿步骤一次。为了解决这个问题，我们必须看一下这个问题的边界条件。假设 $u^{n}$ 已经有了正确的边界值，那么牛顿更新 $\delta u^{n}$ 的边界条件应该为零，这样才能在加入两者之后有正确的边界条件。  在第一个牛顿步骤中，我们从解 $u^{0}\equiv 0$ 开始，牛顿更新仍然要向解 $u^{1}$ 传递正确的边界条件。


综上所述，我们必须在第一步用边界条件 $\delta
u^{0}=g$ 解决上述PDE，并在接下来的所有步骤中用 $\delta u^{n}=0$ 解决。

 @note  在某种意义上，人们可能会说，如果程序已经实现了 $F(u)$ ，那么还必须实现 $F'(u,\delta)$ 就是重复的。像往常一样，重复会诱发错误，我们希望能避免它。虽然我们在这个程序中没有探讨这个问题，但我们将在下面的<a
  href="#extensions">Possibilities for extensions</a>部分的结尾处，特别是在步骤72中再来讨论这个问题。




<h3>Weak formulation of the problem</h3>

从上面的强表述开始，我们通过将PDE的两边都乘以一个检验函数 $\varphi$ 并对两边进行部分积分，得到弱表述。   @f[
  \left( \nabla \varphi , \frac{1}{\left(1+|\nabla u^{n}|^{2}\right)^{\frac{1}{2}}}\nabla
  \delta u^{n} \right)-\left(\nabla \varphi ,\frac{\nabla u^{n} \cdot \nabla
  \delta u^{n}}{\left(1+|\nabla u^{n}|^{2}\right)^{\frac{3}{2}}}\nabla u^{n}  \right)
  = -\left(\nabla \varphi , \frac{1}{\left(1+|\nabla u^{n}|^{2}\right)^{\frac{1}{2}}} \nabla u^{n}
   \right).
  @f]

这里的解 $\delta u^{n}$ 是 $H^{1}(\Omega)$ 中的一个函数，受制于上面讨论的边界条件。将这一空间还原为具有基数 $\left\{
\varphi_{0},\dots , \varphi_{N-1}\right\}$ 的有限维空间，我们可以写出该解。

@f[
  \delta u^{n}=\sum_{j=0}^{N-1} \delta U_{j} \varphi_{j}.


@f]



使用基函数作为测试函数并定义 $a_{n} \dealcoloneq \frac{1}
{\sqrt{1+|\nabla u^{n}|^{2}}}$ ，我们可以重写弱的表述。

@f[
  \sum_{j=0}^{N-1}\left[ \left( \nabla \varphi_{i} , a_{n} \nabla \varphi_{j} \right) -
  \left(\nabla u^{n}\cdot \nabla \varphi_{i} , a_{n}^{3} \nabla u^{n} \cdot \nabla
  \varphi_{j} \right) \right] \cdot \delta U_{j}=-\left( \nabla \varphi_{i} , a_{n}
  \nabla u^{n}\right) \qquad \forall i=0,\dots ,N-1,


@f]



其中解  $\delta u^{n}$  是由系数  $\delta U^{n}_{j}$  给出的。这个线性方程组可以改写为。

@f[
  A^{n}\; \delta U^{n}=b^{n},


@f]



其中，矩阵 $A^{n}$ 的条目由以下方式给出。

@f[
  A^{n}_{ij} \dealcoloneq \left( \nabla \varphi_{i} , a_{n} \nabla \varphi_{j} \right) -
  \left(\nabla u^{n}\cdot \nabla \varphi_{i} , a_{n}^{3} \nabla u^{n} \cdot \nabla
  \varphi_{j} \right),


@f]



而右手边 $b^{n}$ 由以下公式给出。

@f[
  b^{n}_{i} \dealcoloneq -\left( \nabla \varphi_{i} , a_{n} \nabla u^{n}\right).


@f]






<h3> Questions about the appropriate solver </h3>

与上述牛顿步骤相对应的矩阵可以重新表述，以更好地显示其结构。稍微重写一下，我们可以得到它的形式是

@f[
  A_{ij}
  =
  \left(
    \nabla \varphi_i,
    B
    \nabla \varphi_j
  \right),


@f]

其中矩阵 $B$ （在 $d$ 空间维度中的大小为 $d \times d$ ）由以下表达式给出。

@f[
  B
  =
  a_n \left\{
   \mathbf I


   -
   a_n^2 [\nabla u_n] \otimes [\nabla u_n]
  \right\}
  =
  a_n \left\{
   \mathbf I


   -
  \frac{\nabla u_n}{\sqrt{1+|\nabla u^{n}|^{2}}} \otimes
  \frac{\nabla u_n}{\sqrt{1+|\nabla u^{n}|^{2}}}
  \right\}.


@f]

从这个表达式来看，显然 $B$ 是对称的，所以 $A$ 也是对称的。另一方面， $B$ 也是正定的，这使 $A$ 也具有同样的属性。这可以通过注意到向量 $v_1 =
\frac{\nabla u^n}{|\nabla u^n|}$ 是 $B$ 的特征向量，其特征值为 $\lambda_1=a_n \left(1-\frac{|\nabla u^n|^2}{1+|\nabla u^n|^2}\right) > 0$ ，而所有与 $v_1$ 相互垂直的向量 $v_2\ldots v_d$ 都是特征向量，其特征值为 $a_n$  。由于所有的特征值都是正的， $B$ 是正定的， $A$ 也是正定的。因此我们可以使用CG方法来解决牛顿步骤。矩阵 $A$ 是对称和正定的这一事实不应该令人惊讶。它是由取一个能量函数的导数而产生的算子的结果：最小表面方程只是最小化了一些非二次能量。因此，牛顿矩阵，作为标量能量的二阶导数矩阵，必须是对称的，因为与 $i$ th和 $j$ th自由度有关的导数显然应该相减。同样，如果能量函数是凸的，那么第二导数的矩阵必须是正定的，上面的直接计算只是重申了这一点。)

然而，值得注意的是，在 $\nabla u$ 变大的问题上，正定性会退化。换句话说，如果我们简单地将所有边界值乘以2，那么一阶 $u$ 和 $\nabla u$ 也将被乘以2，但结果是 $B$ 的最小特征值将变小，矩阵将变得更加涣散。更具体地说，对于 $|\nabla u^n|\rightarrow\infty$ ，我们有 $\lambda_1 \propto a_n \frac{1}{|\nabla u^n|^2}$ 而 $\lambda_2\ldots \lambda_d=a_n$ ；因此， $B$ 的条件数，也就是 $A$ 的条件数的一个乘法因子，会像 ${\cal O}(|\nabla u^n|^2)$ 那样增长）。用目前的程序很容易验证，确实将目前程序中使用的边界值乘以越来越大的数值，导致问题最终不再能用我们这里使用的简单预设条件的CG方法解决。




<h3> Choice of step length and globalization </h3>

如上所述，牛顿方法的工作原理是计算一个方向 $\delta u^n$ ，然后以一个步长 $0 < \alpha^n \le 1$ 执行更新 $u^{n+1} = u^{n}+\alpha^n
\delta u^{n}$  。一个常见的现象是，对于强非线性模型，如果我们总是选择 $\alpha^n=1$ ，牛顿方法就不会收敛，除非我们从一个足够接近非线性问题的解 $u$ 的初始猜测 $u^0$ 开始。在实践中，我们并不总是有这样的初始猜测，因此采取完整的牛顿步骤（即使用 $\alpha=1$ ）往往是行不通的。

因此，一个常见的策略是，当迭代 $u^n$ 离解 $u$ 还很远时，在前几步使用较小的步长，随着我们越来越接近，使用较大的 $\alpha^n$ 值，直到最后我们可以开始使用全步 $\alpha^n=1$ ，因为我们已经足够接近解。当然，问题是如何选择 $\alpha^n$ 。基本上有两种广泛使用的方法：直线搜索和信任区域方法。

在这个程序中，我们总是简单地选择步长等于0.1。这确保了在手头的测试案例中，我们确实得到了收敛，尽管很明显，由于没有最终恢复到全步长，我们放弃了使牛顿方法如此吸引人的快速、二次收敛性。很明显，如果这个程序是为了解决更多的现实问题，我们最终必须解决这个问题。我们将在<a href="#Results">results section</a>中对这个问题进行更多的评论，并在第77步中使用一个更好的方法。




<h3> Summary of the algorithm and testcase </h3>

总的来说，我们这里的程序在许多方面与step-6并无不同。主类的布局基本上是相同的。另一方面， <code>run()</code> 函数中的驱动算法是不同的，工作原理如下。<ol>  <li>  从函数 $u^{0}\equiv 0$ 开始，以这样的方式修改它，使 $u^0$ 的值沿边界等于正确的边界值 $g$ （这发生在 <code>MinimalSurfaceProblem::set_boundary_values</code> ）。设 $n=0$  .   </li> 

 <li>  通过解决 $A^{n}\;\delta
  U^{n}=b^{n}$ 系统和 $\delta u^{n}=0$ 上的边界条件，计算牛顿更新。   </li> 

 <li>  计算一个步长  $\alpha^n$  。在这个程序中，我们总是设置  $\alpha^n=0.1$  。为了便于以后的扩展，这发生在一个自己的函数中，即 <code>MinimalSurfaceProblem::determine_step_length</code>  中。 (总是选择 $\alpha^n=0.1$ 的策略当然不是最优的--我们应该选择一个对给定搜索方向有效的步长--但这需要做一些工作来实现。最后，我们把这类事情留给外部软件包：step-77就是这样做的）。)   </li> 

 <li>  解的新近似值由  $u^{n+1}=u^{n}+\alpha^n \delta u^{n}$  给出。   </li> 

 <li>  如果 $n$ 是5的倍数，则细化网格，将解 $u^{n+1}$ 转移到新的网格中，并设置 $u^{n+1}$ 的值，以便沿边界有 $u^{n+1}|_{\partial\Gamma}=g$ （同样在 <code>MinimalSurfaceProblem::set_boundary_values</code> ）。请注意，这并不是自动保证的，即使在网格细化之前我们已经有了 $u^{n+1}|_{\partial\Gamma}=g$ ，因为网格细化会在网格中增加新的节点，当我们把旧的解决方案带到新的网格时，必须把旧的解决方案插值到新的节点。我们通过插值选择的数值可能接近于精确的边界条件，但一般来说，并不是正确的数值。   </li> 

 <li>  设置 $n\leftarrow n+1$ 并转到步骤2。   </li>   </ol> 。

我们解决的测试案例选择如下。我们寻求在单位盘 $\Omega=\{\mathbf x: \|\mathbf
x\|<1\}\subset {\mathbb R}^2$ 上找到最小曲面的解决方案，其中曲面沿边界达到 $u(x,y)|{\partial\Omega} = g(x,y) \dealcoloneq \sin(2 \pi (x+y))$ 的数值。


examples/step-15/doc/results.dox



<h1>Results</h1>


程序的输出看起来如下。

@code
Mesh refinement step 0
  Initial residual: 1.53143
  Residual: 1.08746
  Residual: 0.966748
  Residual: 0.859602
  Residual: 0.766462
  Residual: 0.685475


Mesh refinement step 1
  Initial residual: 0.868959
  Residual: 0.762125
  Residual: 0.677792
  Residual: 0.605762
  Residual: 0.542748
  Residual: 0.48704


Mesh refinement step 2
  Initial residual: 0.426445
  Residual: 0.382731
  Residual: 0.343865
  Residual: 0.30918
  Residual: 0.278147
  Residual: 0.250327


Mesh refinement step 3
  Initial residual: 0.282026
  Residual: 0.253146
  Residual: 0.227414
  Residual: 0.20441
  Residual: 0.183803
  Residual: 0.165319


Mesh refinement step 4
  Initial residual: 0.154404
  Residual: 0.138723
  Residual: 0.124694
  Residual: 0.112124
  Residual: 0.100847
  Residual: 0.0907222


....
@endcode



很明显，该方案会收敛，即使不是非常快。我们将在下面讨论加速该方法的策略。

我们可以在每一组五次牛顿迭代之后，即在我们近似解决方案的每一个网格上，直观地看到解决方案。这就产生了以下一组图像。

<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step_15_solution_1.png" alt="带等高线的零周期后的解决方案。" width="230" height="273"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_15_solution_2.png" alt="带等高线的一个周期后的解决方案。" width="230" height="273"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_15_solution_3.png" alt="带轮廓线的两个周期后的解决方案。" width="230" height="273"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_15_solution_4.png" alt="带轮廓线的三个周期后的解决方案。" width="230" height="273"> </div> <div>

可以清楚地看到，每次细化后的解决方案都能使表面最小化。解决方案收敛于人们想象中的肥皂泡，它位于一个像边界一样弯曲的线环内。同样可以看出，每次细化后，边界是如何被平滑化的。在粗略的网格上，边界看起来并不像正弦，而网格越细越像。

网格主要是在边界附近被细化，在那里解的增加或减少很强烈，而在域的内部则被粗化，在那里没有什么有趣的事情发生，因为解没有什么变化。这里显示的是第九个解和网格。

<div class="onecolumn" style="width: 60%"> <div> <img src="https://www.dealii.org/images/steps/developer/step_15_solution_9.png" alt="第九个周期的网格和解决方案与等高线。" width="507" height="507"> </div> </div>




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

该程序显示了一个非线性、静止问题的求解器的基本结构。然而，它的收敛速度不是特别快，这是有原因的。

- 该程序总是采取0.1的步长。这就排除了牛顿方法通常选择的快速、二次收敛。

- 它没有将非线性迭代与网格细化迭代联系起来。

很明显，一个更好的方案必须解决这两点。我们将在下文中讨论它们。




<h4> Step length control </h4>

牛顿方法有两个众所周知的特性。

- 它可能不会从任意选择的起点收敛。相反，一个起点必须足够接近解决方案以保证收敛。然而，我们可以通过使用 <i>step length</i> 0<  $\alpha^n\le
  1$  的阻尼迭代来扩大牛顿方法的收敛区域。

- 如果(i)步长选择为 $\alpha^n=1$ ，并且(ii)事实上在选择步长的情况下，它表现出快速收敛的二次方阶。

这两个观察的结果是，一个成功的策略是为初始迭代选择 $\alpha^n<1$ ，直到迭代已经足够接近，允许以全步长收敛，这时我们要切换到 $\alpha^n=1$  。问题是如何以自动方式选择 $\alpha^n$ ，以满足这些标准。

我们不想在这里回顾关于这个主题的文献，只是简单地提到有两种基本的方法来解决这个问题：回溯线搜索和信任区域方法。前者更广泛地用于偏微分方程，基本上是这样做的。

- 计算一个搜索方向

- 看看 $u^n + \alpha^n\;\delta u^n$ 与 $\alpha^n=1$ 产生的残差是否比 $u^n$ 单独产生的残差 "大大减少"。

- 如果是这样，那么就采取  $\alpha^n=1$  。

- 如果不是，用  $\alpha^n=2/3$  试试残差是否 "大大缩小"。

- 如果是这样，则取 $\alpha^n=2/3$  。

- 如果不是，用 $\alpha^n=(2/3)^2$ 试试残差是否 "大大缩小"。

- 等等。当然，除了上面选择的 $2/3,
(2/3)^2, \ldots$ ，我们还可以选择其他因素 $r, r^2, \ldots$ ，用于 $0<r<1$  。很明显，"回溯 "一词的来源是：我们尝试一个长的步骤，但如果不成功，我们就尝试一个更短的步骤，越来越短的步骤，等等。函数 <code>determine_step_length()</code> 的编写方式正是为了支持这种用例。

我们是否接受一个特定的步长 $\alpha^n$ 取决于我们如何定义 "大大小于"。有很多方法，但不详细介绍，我们只说最常见的是使用沃尔夫和阿米约-戈尔德斯坦条件。对于这些，人们可以证明如下。

- 总有一个步长 $\alpha^n$ 可以满足条件，也就是说，只要问题是凸的，迭代就不会卡住。

- 如果我们足够接近解决方案，那么条件允许 $\alpha^n=1$  ，从而实现二次收敛。

我们在此不再赘述，而是将这种算法的实现作为一个练习。然而，我们注意到，如果实施得当，大多数合理的非线性问题可以在5到15次牛顿迭代中得到解决，达到工程精度&mdash；比我们目前版本的程序所需要的次数要少得多，这是一个普遍现象。

关于包括回溯在内的全局化方法的更多细节，例如可以在  @cite GNS08  和  @cite NW99  找到。

然而，非常值得一提的是，在实践中，高效非线性求解器的实现与高效有限元方法的实现一样复杂。我们不应该试图通过自己实现所有的必要步骤来重新发明车轮。在 LineMinimization::line_search() 函数中已经有了大量的拼图，可以用来实现这一目的。但是，相反，就像在deal.II等库上构建有限元求解器一样，人们应该在[SUNDIALS](https://computing.llnl.gov/projects/sundials)等库上构建非线性求解器。事实上，deal.II有与SUNDIALS的接口，特别是通过 SUNDIALS::KINSOL 类与它的非线性求解器子包KINSOL的接口。将目前的问题建立在该接口上并不十分困难--事实上，这正是step-77所做的。




<h4> Integrating mesh refinement and nonlinear and linear solvers </h4>

我们目前在每个网格上正好做了5次迭代。但这是最优的吗？人们可以提出以下问题。

- 也许在初始网格上做更多的迭代是值得的，因为那里的计算很便宜。

- 另一方面，我们不希望在每个网格上做太多的迭代：是的，我们可以在每个网格上将残差驱动到零，但这只意味着非线性迭代误差远远小于离散化误差。

- 我们应该用更高还是更低的精度来解决每个牛顿步骤中的线性系统？

最终，这归结为我们需要将当前网格上的离散化误差与我们希望在特定网格上通过牛顿迭代实现的非线性残差，以及我们希望在每个牛顿迭代中通过CG方法实现的线性迭代结合起来。

如何做到这一点，同样不是完全微不足道的，我们再次将其作为未来的练习。




<h4> Using automatic differentiation to compute the Jacobian matrix </h4>

正如介绍中所概述的，当解决一个形式为@f[
    F(u) \dealcoloneq


    -\nabla \cdot \left( \frac{1}{\sqrt{1+|\nabla u|^{2}}}\nabla u \right)
    = 0
  @f]的非线性问题时

我们使用牛顿迭代，要求我们反复解决线性偏微分方程@f{align*}
    F'(u^{n},\delta u^{n}) &=- F(u^{n})
  @f}。

这样，我们就可以计算出更新@f{align*}
    u^{n+1}&=u^{n}+\alpha^n \delta u^{n}
  @f}。

与牛顿步骤的解 $\delta u^{n}$ 。对于这里的问题，我们可以用手计算导数 $F'(u,\delta u)$ ，得到@f[
  F'(u,\delta u)
  =


  - \nabla \cdot \left( \frac{1}{\left(1+|\nabla u|^{2}\right)^{\frac{1}{2}}}\nabla
  \delta u \right) +
  \nabla \cdot \left( \frac{\nabla u \cdot
  \nabla \delta u}{\left(1+|\nabla u|^{2}\right)^{\frac{3}{2}}} \nabla u
  \right).
  @f] 。

但这已经是一个相当大的表达方式了，无论是推导还是实现都很麻烦。在某种意义上，它也是重复的。如果我们在代码的某个地方实现了 $F(u)$ 是什么，那么 $F'(u,\delta u)$ 就不是一个独立的信息，而是至少在原则上计算机应该能够自己推断出来的东西。如果这真的能发生，那不是很好吗？也就是说，如果我们真的只需要实现 $F(u)$ ，而 $F'(u,\delta u)$ 是以某种方式隐含完成的，那不是很好吗？这实际上是可能的，并以 "自动微分 "的名义运行。步骤-71讨论了这个概念的一般术语，步骤-72说明了如何在实践中应用于我们在这里考虑的问题。


examples/step-16/doc/intro.dox

 <br> 

<i> Note: A variant called step-16b of this tutorial exists, that uses
MeshWorker and LocalIntegrators instead of assembling matrices manually as it
is done in this tutorial.
</i>

<a name="Intro"></a>

<h1>Introduction</h1>


这个例子展示了deal.II中多级函数的基本用法。它几乎解决了与步骤6中使用的相同的问题，但展示了使用多网格作为预处理程序时必须提供的东西。特别是，这要求我们定义一个层次结构，提供从一个层次到下一个层次以及返回的转移算子，并在每个层次上提供拉普拉斯算子的表示。

为了使微分方程系统和块状预处理程序具有足够的灵活性，在启动多级方法之前必须创建一些不同的对象，尽管大部分需要做的事情都是由deal.II本身提供。这些对象是

  - 网格之间的对象处理转移；我们使用MGTransferPrebuilt类来处理这个问题，它几乎完成了库内的所有工作。

  - 解算器的最粗层次；在这里，我们使用MGCoarseGridHouseholder。

  - 所有其他级别的平滑器，在我们的例子中，这将是使用SOR作为基本方法的 mg::SmootherRelaxation 类。

  - 和 mg::Matrix, 一个具有特殊水平乘法的类，也就是说，我们基本上每个网格水平存储一个矩阵并允许与之相乘。

这些对象中的大多数只需要在实际求解线性系统的函数中使用。在这里，这些对象被组合到一个多网格类型的对象中，其中包含V型循环的实现，它又被预设条件器PreconditionMG使用，准备插入LAC库的线性求解器中。

这里实现的自适应细化网格的多网格方法遵循 @ref mg_paper "多网格论文 "中的大纲，该论文在deal.II中描述了底层实现，也介绍了很多术语。首先，我们必须区分层次网格，即与粗网格有相同细化距离的单元，以及由层次中的活动单元组成的叶子网格（在较早的工作中，我们将其称为全局网格，但这个术语被过度使用）。最重要的是，叶子网格与最细层次上的层次网格不完全相同。下面的图片显示了我们认为的 "层次网"。

<p align="center">  @image html "multigrid.png" ""   </p>  。

这个网格中的精细层次只包括定义在精细单元上的自由度，但不延伸到领域中未被精细化的那部分。虽然这保证了整体的努力增长为 ${\cal O}(N)$ 的最佳多网格复杂度所必需的，但它导致了在定义平滑的地方和对定义在各个层次上的算子提出什么边界条件时的问题，如果层次边界不是外部边界。这些问题将在上面引用的文章中详细讨论。

<h3>The testcase</h3>

我们在这里解决的问题与第6步类似，主要有两个不同点：第一，多网格预处理程序，显然。我们还改变了系数的不连续性，使局部装配器看起来不会比必要的更复杂。


examples/step-16/doc/results.dox



<h1>Results</h1>

在最细的网格上，解决方案看起来像这样。

<p align="center">  <img src="https://www.dealii.org/images/steps/developer/step-16.solution.png" alt="">   </p>  。

更重要的是，我们想看看多网格方法是否真的改善了求解器的性能。因此，这里是文本输出。

<p>周期0 活动单元数：80 自由度数：89（按级别：8，25，89） CG迭代数。8

周期1 活动单元数：158 自由度数：183（按级别：8，25，89，138） CG迭代次数。9

周期2 活动单元数：302 自由度数：352（按级别：8、25、89、223、160） CG迭代次数。10

周期3 活动单元数：578 自由度数：649（按级别：8、25、89、231、494、66） CG迭代次数。10

第四周期 活跃单元数：1100 自由度数：1218（按级别：8、25、89、274、764、417、126） CG迭代次数。10

周期5 活动单元数：2096 自由度数：2317（按级别：8、25、89、304、779、1214、817） CG迭代次数。11

第6周期 活跃单元数：3986 自由度数：4366（按级别：8，25，89，337，836，2270，897，1617） CG迭代数。10

周期7 活动单元数：7574 自由度数：8350（按级别：8、25、89、337、1086、2835、2268、1789、3217） CG迭代次数。11 </pre>

这几乎是完美的多重网格性能：线性残差在10个迭代步骤中被减少了12个数量级，而且结果几乎与网格大小无关。这显然部分是由于所解决的问题的简单性质，但它显示了多梯度方法的力量。




<h3> Possibilities for extensions </h3>


我们鼓励你生成solve()调用的时间并与步骤6进行比较。你会看到多网格方法在粗网格上有相当大的开销，但由于其最佳的复杂性，它在细网格上总是胜过其他方法。

仔细检查这个程序的性能就会发现，它主要是由矩阵-向量操作主导的。step-37展示了一种通过使用无矩阵方法来避免这种情况的方法。

另一个途径是使用代数多网格方法。这里使用的几何多栅方法在实现上有时会有点尴尬，因为它需要所有这些额外的数据结构，如果程序要在%parallel的机器上通过MPI耦合运行，就会变得更加困难，例如。在这种情况下，如果能使用一个黑盒预处理程序，就会更简单，该程序使用某种多栅层次结构以获得良好的性能，但可以自己计算出水平矩阵和类似的东西。代数多栅方法正是这样做的，我们将在步骤31中使用它们来解决斯托克斯问题，在步骤32和步骤40中使用它们来解决平行变化。也就是说，在步骤50中可以找到这个例子程序的MPI并行版本。

最后，人们可能要考虑如何将几何多网格用于其他类型的问题，特别是 @ref vector_valued "矢量值问题"。这是step-56的主题，我们将这里的技术用于斯托克斯方程。


examples/step-16b/doc/intro.dox

 <br> 

<a name="Intro"></a>

<h1>Introduction</h1>

这是第16步的一个变体，唯一的变化是我们使用MeshWorker框架和预制的LocalIntegrator辅助类，而不是手动组装矩阵。

关于这个框架在实践中如何使用的细节，将作为本教程计划的一部分加以解释。

<h3>The testcase</h3>

我们在这里解决的问题与步骤16中的问题相同。


examples/step-16b/doc/results.dox



<h1>Results</h1>

如同第16步，在最细的网格上，解决方案看起来是这样的。

<p align="center">  <img src="https://www.dealii.org/images/steps/developer/step-16.solution.png" alt="">   </p>  。

与step-16相比，输出的格式略有不同，但在功能上是一样的，显示了相同的收敛特性。<p>  DEAL::Cycle  0 DEAL:: 活动单元数：20 DEAL:: 自由度数：25（通过级别：8，25）  DEAL:cg::Starting  值 0.510691  DEAL:cg::Convergence  步骤6 值 4.59193e-14  DEAL::Cycle  1 DEAL:: 活动单元数：44 DEAL:: 自由度数：55（按级别：8，25，45）  DEAL:cg::Starting  值 0.440678  DEAL:cg::Convergence  步骤8值 1.99419e-13  DEAL::Cycle  2 DEAL:: 活动单元数：86 DEAL:: 自由度数：105（按级别：8，25，69，49）  DEAL:cg::Starting  值 0.371855  DEAL:cg::Convergence  步骤 9 值 1.13984e-13  DEAL::Cycle 3 DEAL:: 活动单元数：170 DEAL:: 自由度数：200（按级别：8，25，77，174）  DEAL:cg::Starting  值 0.318967  DEAL:cg::Convergence  步骤 9 值 2.62112e-13  DEAL::Cycle  4 DEAL:: 活动单元数：332 DEAL:: 自由度数：388（按级别：8, 25, 86, 231, 204）  DEAL:cg::Starting  值 0.276534  DEAL:cg::Convergence  步骤10值 1.69562e-13  DEAL::Cycle  5 DEAL:: 活动单元数：632 DEAL:: 自由度数：714（按级别：8, 25, 89, 231, 514, 141）  DEAL:cg::Starting  值 0.215300  DEAL:cg::Convergence  步骤10值 6.47463e-13  DEAL::Cycle  6 DEAL:: 活动单元数：1202 DEAL:: 自由度数：1332（按级别：8, 25, 89, 282, 771, 435, 257）  DEAL:cg::Starting  值 0.175848  DEAL:cg::Convergence  第10步值 1.80664e-13  DEAL::Cycle  7 DEAL:: 活动单元数：2288 DEAL:: 自由度数：2511（按级别：8、25、89、318、779、1420、829、30）  DEAL:cg::Starting  值 0.136724  DEAL:cg::Convergence  第11步值 9.73331e-14 </pre>


examples/step-17/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

<h3>Overview</h3>

这个程序没有引入任何新的数学思想；事实上，它所做的只是做与step-8已经做的完全相同的计算，但它以一种不同的方式来做：我们没有使用deal.II自己的线性代数类，而是在deal.II提供的类之上建立一切，这些类包裹着<a
href="http://www.mcs.anl.gov/petsc/" target="_top">PETSc</a>库的线性代数实现。由于PETSc允许将矩阵和向量分布在MPI网络中的几台计算机上，因此产生的代码甚至能够以%并行方式解决问题。如果你不知道PETSc是什么，那么这将是一个快速浏览其主页的好时机。

作为这个程序的先决条件，你需要安装PETSc，如果你想在一个集群上以%并行方式运行，你还需要<a
href="http://www-users.cs.umn.edu/~karypis/metis/index.html"
target="_top">METIS</a>来划分网格。在<a
href="../../readme.html" target="body">README</a>文件中描述了deal.II和这两个附加库的安装。

现在，关于细节：如前所述，该程序不计算任何新的东西，所以对有限元类等的使用与以前完全相同。与以前的程序不同的是，我们用几乎所有的类 <code>Vector</code> and <code>SparseMatrix</code> 代替了它们的近似值 <code>PETScWrappers::MPI::Vector</code> 和 <code>PETScWrappers::MPI::SparseMatrix</code> ，它们存储数据的方式使MPI网络中的每个处理器只存储矩阵或矢量的一部分。更具体地说，每个处理器将只存储与它 "拥有 "的自由度相对应的矩阵的那些行。对于向量，它们要么只存储与处理器拥有的自由度相对应的元素（这是右手边所需要的），要么也存储一些额外的元素，以确保每个处理器都能访问处理器拥有的单元（所谓 @ref GlossLocallyActiveDof "本地活动的自由度"）或邻近单元（所谓 @ref GlossLocallyRelevantDof "本地相关自由度"）上的解组件。

来自PETScWrapper命名空间的类所提供的接口与deal.II线性代数类的接口非常相似，但它们不是自己实现这一功能，而是简单地传递给它们相应的PETSc函数。因此，包装器只是用来给PETSc一个更现代的、面向对象的接口，并使PETSc和deal.II对象的使用尽可能地互换。使用PETSc的主要意义在于它可以在%并行状态下运行。我们将利用这一点，将域划分为与MPI网络中的进程一样多的块（"子域"）。同时，PETSc还提供了假的MPI存根，所以如果PETSc的配置中没有MPI，你可以在一台机器上运行这个程序。




<h3>Parallelizing software with MPI</h3>

开发软件以通过MPI在%parallel中运行，需要改变一下思维方式，因为我们通常必须分割所有的数据结构，使每个处理器只存储整个问题的一部分。因此，你通常不能在每个处理器上访问一个解决方案向量的所有组成部分 -- 每个处理器可能根本没有足够的内存来容纳整个解决方案向量。由于数据被分割或 "分布 "在各个处理器上，我们把MPI使用的编程模型称为 "分布式内存计算"（与 "共享内存计算 "相反，后者意味着多个处理器可以访问一个内存空间中的所有数据，例如，当一台机器的多个核心在一个共同任务上工作时）。分布式内存计算的一些基本原理在 @ref distributed "使用分布式内存的多处理器并行计算 "文档模块中讨论，该模块本身是 @ref Parallel "并行计算 "模块的一个子模块。

一般来说，为了真正能够扩展到大量的处理器，我们需要在可用的处理器之间分割出<i>every</i>数据结构，其大小随着整个问题的大小而扩展。关于程序 "扩展 "的定义，见 @ref GlossParallelScaling "本词汇表条目"）。这包括，例如，三角形、矩阵和所有全局向量（解决方案，右手边）。如果不拆分所有这些对象，其中一个对象将被复制到所有的处理器上，如果问题大小（和可用的处理器数量）变得很大，最终会简单地变得太大。另一方面，在每个处理器上保留大小与整个问题大小无关的对象是完全可以的。例如，可执行文件的每个副本将创建自己的有限元对象，或者我们在汇编中使用的局部矩阵）。)

在当前的程序中（以及相关的第18步），我们不会走得这么远，而是对MPI的使用做一个比较温和的介绍。更具体地说，我们要并行化的数据结构只有矩阵和向量。然而，我们并没有拆分Triangulation和DoFHandler类：每个进程仍然拥有这些对象的完整副本，而且所有进程都拥有其他进程所拥有的确切副本。然后，我们只需在每个处理器上的三角形的每个副本中，标记哪个处理器拥有哪些单元。这个过程被称为将网格 "分割 "为 @ref GlossSubdomainId "子域"。

对于较大的问题，必须在每个处理器上存储<i>entire</i>网格，显然会产生一个瓶颈。分割网格是稍微的，虽然没有多复杂（从用户的角度来看，虽然它<i>much</i>下更复杂）来实现，我们将展示如何在step-40和其他一些程序中这样做。在讨论这个程序的某个功能如何工作的过程中，我们会多次评论它不会扩展到大型问题，以及为什么不会。所有这些问题都将在第18步，特别是第40步中得到解决，它可以扩展到非常多的进程。

从哲学上讲，MPI的运作方式如下。你通常通过以下方式运行一个程序

@code
  mpirun -np 32 ./step-17
@endcode

这意味着在（比如）32个处理器上运行它。如果你是在一个集群系统上，你通常需要<i>schedule</i>程序在32个处理器可用时运行；这将在你的集群的文档中描述。但是在系统内部，每当这些处理器可用时，通常会执行上述相同的调用）。)这样做的目的是，MPI系统将启动32个<i>copies</i>的 <code>step-17</code> 的可执行文件。(这些正在运行的可执行文件中的每一个的MPI术语是，你有32个 @ref GlossMPIProcess "MPI进程"。)这可能发生在不同的机器上，甚至不能从对方的内存空间中读取，也可能发生在同一台机器上，但最终的结果是一样的：这32个副本中的每一个都将以操作系统分配给它的一些内存运行，而且它不能直接读取其他31个副本的内存。为了在一个共同的任务中进行协作，这32个副本就必须<i>communicate</i>相互协作。MPI是<i>Message Passing Interface</i>的缩写，通过允许程序<i>send messages</i>来实现这一点。你可以把它看作是邮件服务：你可以把一封写给特定地址的信放入邮件，它将被送达。但这是你能控制事物的程度。如果你想让收信人对信的内容做些什么，例如把你想要的数据从那边返回给你，那么需要发生两件事。(i)接收方需要实际去检查他们的邮箱里是否有东西，(ii)如果有的话，做出适当的反应，比如说发送数据回来。如果你等待这个返回信息，但原来的接收者却心不在焉，没有注意，那么你就不走运了：你只需要等待，直到你在那边的请求将被解决。在某些情况下，错误会导致原始接收者永远不检查你的邮件，在这种情况下，你将永远等待--这被称为<i>deadlock</i>。(  @dealiiVideoLectureSeeAlso{39,41,41.25,41.5}) 

在实践中，人们通常不在发送和接收单个消息的层面上编程，而是使用更高层次的操作。例如，在程序中，我们将使用函数调用，从每个处理器获取一个数字，将它们全部相加，然后将总和返回给所有处理器。在内部，这是用单个消息实现的，但对用户来说，这是透明的。我们称这种操作为<i>collectives</i>，因为<i>all</i>处理器参与其中。集合体允许我们编写程序，其中不是每个可执行文件的副本都在做完全不同的事情（这将是难以置信的编程难度），但实质上所有副本都在为自己做同样的事情（尽管是在不同的数据上），通过相同的代码块运行；然后他们通过集合体进行数据通信；然后再回到为自己做事情，通过相同的数据块运行。这是能够编写程序的关键部分，也是确保程序能够在任何数量的处理器上运行的关键部分，因为我们不需要为每个参与的处理器编写不同的代码。

这并不是说程序从来都是以不同的处理器在其可执行文件的副本中运行不同的代码块的方式来编写的。程序内部也经常以其他方式而不是通过集合体进行通信。但是在实践中，%并行有限元代码几乎总是遵循这样的方案：程序的每个副本在同一时间运行相同的代码块，中间穿插着所有处理器相互交流的阶段）。)

在现实中，即使是调用MPI集体函数的水平也太低了。相反，下面的程序根本不会包含对MPI的任何直接调用，而只包含对deal.II的用户隐藏这种通信的函数。这样做的好处是，你不需要学习MPI的细节和相当复杂的函数调用。也就是说，你确实必须理解上文所述的MPI背后的一般哲学。




<h3>What this program does</h3>

然后，这个程序演示的技术是。

- 如何使用PETSc封装类；这在本程序的主类的声明中已经可以看到，  <code>ElasticProblem</code>  。

- 如何将网格划分为子域；这发生在 <code>ElasticProblem::setup_system()</code> 函数。

- 如何对运行在MPI网络上的作业进行并行化操作；在这里，这是在很多地方都要注意的，最明显的是在 <code>ElasticProblem::assemble_system()</code> 函数中。

- 如何处理只存储向量项子集的向量，对于这些向量，我们必须确保它们在当前处理器上存储我们需要的东西。例如见 <code>ElasticProblem::solve()</code> and <code>ElasticProblem::refine_grid()</code> 函数。

- 如何处理同时在多个处理器上运行的程序的状态输出。这是通过程序中的 <code>pcout</code> 变量完成的，在构造函数中初始化。

由于这一切只能用实际的代码来证明，让我们直接进入代码，不再多说。


examples/step-17/doc/results.dox



<h1>Results</h1>


如果上述程序在单处理器机器上编译和运行，它产生的结果应该与我们已经通过步骤8得到的结果非常相似。然而，如果我们在多核机器或计算机集群上运行它，就会变得更加有趣。运行MPI程序的最基本方法是使用一个命令行，如

@code
  mpirun -np 32 ./step-17
@endcode

以32个处理器运行step-17可执行文件。

如果你在一个集群上工作，那么中间通常有一个步骤，你需要设置一个作业脚本，并将该脚本提交给调度器。只要调度器能够为你的工作分配32个未使用的处理器，它就会执行这个脚本。如何编写这样的作业脚本因集群而异，你应该找到你的集群的文档来看看如何做。在我的系统上，我必须使用 <code>qsub</code> 这个命令，加上一大堆的选项来并行运行一个作业）。)

无论是直接还是通过调度器，如果你在8个处理器上运行这个程序，你应该得到如下输出。

@code
Cycle 0:
   Number of active cells:       64
   Number of degrees of freedom: 162 (by partition: 22+22+20+20+18+16+20+24)
   Solver converged in 23 iterations.
Cycle 1:
   Number of active cells:       124
   Number of degrees of freedom: 302 (by partition: 38+42+36+34+44+44+36+28)
   Solver converged in 35 iterations.
Cycle 2:
   Number of active cells:       238
   Number of degrees of freedom: 570 (by partition: 68+80+66+74+58+68+78+78)
   Solver converged in 46 iterations.
Cycle 3:
   Number of active cells:       454
   Number of degrees of freedom: 1046 (by partition: 120+134+124+130+154+138+122+124)
   Solver converged in 55 iterations.
Cycle 4:
   Number of active cells:       868
   Number of degrees of freedom: 1926 (by partition: 232+276+214+248+230+224+234+268)
   Solver converged in 77 iterations.
Cycle 5:
   Number of active cells:       1654
   Number of degrees of freedom: 3550 (by partition: 418+466+432+470+442+474+424+424)
   Solver converged in 93 iterations.
Cycle 6:
   Number of active cells:       3136
   Number of degrees of freedom: 6702 (by partition: 838+796+828+892+866+798+878+806)
   Solver converged in 127 iterations.
Cycle 7:
   Number of active cells:       5962
   Number of degrees of freedom: 12446 (by partition: 1586+1484+1652+1552+1556+1576+1560+1480)
   Solver converged in 158 iterations.
Cycle 8:
   Number of active cells:       11320
   Number of degrees of freedom: 23586 (by partition: 2988+2924+2890+2868+2864+3042+2932+3078)
   Solver converged in 225 iterations.
Cycle 9:
   Number of active cells:       21424
   Number of degrees of freedom: 43986 (by partition: 5470+5376+5642+5450+5630+5470+5416+5532)
   Solver converged in 282 iterations.
Cycle 10:
   Number of active cells:       40696
   Number of degrees of freedom: 83754 (by partition: 10660+10606+10364+10258+10354+10322+10586+10604)
   Solver converged in 392 iterations.
Cycle 11:
   Number of active cells:       76978
   Number of degrees of freedom: 156490 (by partition: 19516+20148+19390+19390+19336+19450+19730+19530)
   Solver converged in 509 iterations.
Cycle 12:
   Number of active cells:       146206
   Number of degrees of freedom: 297994 (by partition: 37462+37780+37000+37060+37232+37328+36860+37272)
   Solver converged in 705 iterations.
Cycle 13:
   Number of active cells:       276184
   Number of degrees of freedom: 558766 (by partition: 69206+69404+69882+71266+70348+69616+69796+69248)
   Solver converged in 945 iterations.
Cycle 14:
   Number of active cells:       523000
   Number of degrees of freedom: 1060258 (by partition: 132928+132296+131626+132172+132170+133588+132252+133226)
   Solver converged in 1282 iterations.
Cycle 15:
   Number of active cells:       987394
   Number of degrees of freedom: 1994226 (by partition: 253276+249068+247430+248402+248496+251380+248272+247902)
   Solver converged in 1760 iterations.
Cycle 16:
   Number of active cells:       1867477
   Number of degrees of freedom: 3771884 (by partition: 468452+474204+470818+470884+469960+
471186+470686+475694)
   Solver converged in 2251 iterations.
@endcode

(这次运行比examples/目录中的代码多用了几个细化周期。该运行还使用了2004年的METIS版本，产生了不同的分区；因此，你今天得到的数字略有不同）。)

可以看出，我们可以很容易地达到近400万个未知数。事实上，这段代码在8个进程中的运行时间不到7分钟，直到（包括）第14个周期，14分钟包括倒数第二步。(这些数字与该代码最初编写的时间有关，即2004年。)虽然我失去了最后一步的时间信息，但你会明白的。所有这些都是在通过运行 <code>make release</code> 启用发布模式之后，并且由于上述程序注释中所述的原因，关闭了图形输出的生成。(  @dealiiVideoLectureSeeAlso{18})  我做的最大的2D计算大约有710万个未知数，在32个进程上完成。花了大约40分钟。毫不奇怪，一个人能够走多远的限制因素是他有多少内存，因为每个进程都必须持有整个网格和DoFHandler对象，尽管矩阵和向量被分割开来。对于7.1M的计算，每个未知数的内存消耗约为600字节，这并不坏，但我们必须考虑到这是针对每个未知数的，无论我们是否在本地存储矩阵和向量条目。




下面是在程序的第12个周期中产生的一些输出，即大约有30万个未知数。

 <table align="center" style="width:80%">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-17.12-ux.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-17.12-uy.png" alt="" width="100%"></td>
  </tr>
</table> 

正如人们所希望的那样，这里显示的X位移（左）和Y位移（右）与我们在第8步中已经看到的密切相关。正如第22步所示，我们也可以制作一个位移场的矢量图，而不是把它绘制成两个独立的标量场。不过，可能更有趣的是，在这一步看一下网格和分区。

 <table align="center" width="80%">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-17.12-grid.png" alt="" width="100%"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-17.12-partition.png" alt="" width="100%"></td>
  </tr>
</table> 

同样，网格（左边）显示了与之前看到的相同的细化模式。右图显示了8个过程中的域的划分，每个过程用不同的颜色表示。图片显示，在网格单元较小的地方，子域较小，考虑到分区算法试图平衡每个子域的单元数，这一事实是需要预期的；这种平衡在上图所示的输出中也很容易识别，每个子域的度数大致相同。




值得注意的是，如果我们用不同的进程数来运行同一个程序，我们可能会得到稍微不同的输出：不同的网格，不同的未知数和迭代收敛的次数。其原因是，虽然矩阵和右手边是相同的，与使用的进程数无关，但预处理程序不是：它对每个处理器的 <em>  矩阵块分别执行ILU(0)  </em>  。因此，随着进程数的增加，它作为预处理程序的有效性会降低，这使得迭代次数增加。由于不同的预处理程序会导致计算出的解有细微的变化，这将导致细化时标记的网格单元略有不同，在后续步骤中的差异也更大。不过，解决方案看起来总是非常相似的。




最后，这里是3D模拟的一些结果。你可以通过改变以下内容来重复这些结果

@code
        ElasticProblem<2> elastic_problem;
@endcode

至

@code
        ElasticProblem<3> elastic_problem;
@endcode

在主函数中。如果你再并行运行该程序，你会得到与此类似的东西（这是针对一个有16个进程的工作）。

@code
Cycle 0:
   Number of active cells:       512
   Number of degrees of freedom: 2187 (by partition: 114+156+150+114+114+210+105+102+120+120+96+123+141+183+156+183)
   Solver converged in 27 iterations.
Cycle 1:
   Number of active cells:       1604
   Number of degrees of freedom: 6549 (by partition: 393+291+342+354+414+417+570+366+444+288+543+525+345+387+489+381)
   Solver converged in 42 iterations.
Cycle 2:
   Number of active cells:       4992
   Number of degrees of freedom: 19167 (by partition: 1428+1266+1095+1005+1455+1257+1410+1041+1320+1380+1080+1050+963+1005+1188+1224)
   Solver converged in 65 iterations.
Cycle 3:
   Number of active cells:       15485
   Number of degrees of freedom: 56760 (by partition: 3099+3714+3384+3147+4332+3858+3615+3117+3027+3888+3942+3276+4149+3519+3030+3663)
   Solver converged in 96 iterations.
Cycle 4:
   Number of active cells:       48014
   Number of degrees of freedom: 168762 (by partition: 11043+10752+9846+10752+9918+10584+10545+11433+12393+11289+10488+9885+10056+9771+11031+8976)
   Solver converged in 132 iterations.
Cycle 5:
   Number of active cells:       148828
   Number of degrees of freedom: 492303 (by partition: 31359+30588+34638+32244+30984+28902+33297+31569+29778+29694+28482+28032+32283+30702+31491+28260)
   Solver converged in 179 iterations.
Cycle 6:
   Number of active cells:       461392
   Number of degrees of freedom: 1497951 (by partition: 103587+100827+97611+93726+93429+88074+95892+88296+96882+93000+87864+90915+92232+86931+98091+90594)
   Solver converged in 261 iterations.
@endcode






最后一步，达到150万个未知数，在8台双处理器机器（2003年可用的那种）上进行16个进程，需要大约55分钟。这个工作产生的图形输出相当大（第5周期已经打印了大约82MB的数据），所以我们要显示第4周期的输出。

 <table width="80%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-17.4-3d-partition.png" width="100%" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-17.4-3d-ux.png" alt="" width="100%"></td>
  </tr>
</table> 




左图显示的是将立方体划分为16个过程，而右图显示的是沿两个切面通过立方体的X位移。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

该程序在每个处理器上都保留一份三角形和DoFHandler对象的完整副本。它还创建了解决方案矢量的完整副本，并且只在一个处理器上创建输出。就并行化而言，所有这些显然是瓶颈。

在内部，在deal.II中，将分层和非结构化三角计算中使用的数据结构并行化是一个难点，我们又花了几年时间才实现了这一点。step-40教程程序和 @ref distributed 文档模块谈到了如何做这些步骤，以及从应用的角度来看需要什么。当前程序的一个明显的扩展是使用这个功能将计算完全分布到比这里使用的更多的处理器。


examples/step-18/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>


这个教程程序是我们已经在步骤8和步骤17中开始的弹性问题系列中的另一个。它将其扩展到两个不同的方向：首先，它用拉格朗日网格运动方法解决了大变形的准静态但与时间相关的弹性问题。其次，它又展示了一些使用PETSc的线性代数的%并行处理来解决此类问题的技术。除此之外，我们还展示了如何解决step-17的两个主要瓶颈中的一个，即我们只从一个进程中产生图形输出，而这在更多的进程和大问题上的扩展性非常差。另一个瓶颈，即每个处理器都必须持有整个网格和DoFHandler，将在第40步中解决）。最后，我们还展示了许多以前的程序中未曾展示过的各种改进和技术。

如同前面的第17步，只要你安装了PETSc，程序在单机上的运行也是一样的。关于如何告诉deal.II你的系统上安装了PETSc的信息可以在deal.II的README文件中找到，该文件可以从你安装的deal.II的<a href="../../index.html">main
documentation page</a>中链接到，或者在<a href="http://www.dealii.org/">the
deal.II webpage</a>上。




<h3>Quasistatic elastic deformation</h3>

<h4>Motivation of the model</h4>

一般来说，随时间变化的小弹性变形是由弹性波方程描述的

@f[
  \rho \frac{\partial^2 \mathbf{u}}{\partial t^2}
  + c \frac{\partial \mathbf{u}}{\partial t}


  - \textrm{div}\  ( C \varepsilon(\mathbf{u})) = \mathbf{f}
  \qquad
  \textrm{in}\ \Omega,


@f]

其中 $\mathbf{u}=\mathbf{u} (\mathbf{x},t)$ 是身体的变形， $\rho$ 和 $c$ 是密度和衰减系数，以及 $\mathbf{f}$ 外力。此外，初始条件

@f[
  \mathbf{u}(\cdot, 0) = \mathbf{u}_0(\cdot)
  \qquad
  \textrm{on}\ \Omega,


@f]

和Dirichlet（位移）或Neumann（牵引）边界条件，需要指定一个唯一的解决方案。

@f{eqnarray*}
  \mathbf{u}(\mathbf{x},t) &=& \mathbf{d}(\mathbf{x},t)
  \qquad
  \textrm{on}\ \Gamma_D\subset\partial\Omega,
  \\
  \mathbf{n} \ C \varepsilon(\mathbf{u}(\mathbf{x},t)) &=& \mathbf{b}(\mathbf{x},t)
  \qquad
  \textrm{on}\ \Gamma_N=\partial\Omega\backslash\Gamma_D.


@f}

在上述公式中， $\varepsilon(\mathbf{u})= \frac 12 (\nabla \mathbf{u} + \nabla
\mathbf{u}^T)$ 是位移的对称梯度，也称为 <em> 应变 </em>  。   $C$ 是一个等级为4的张量，称为 <em> 应力-应变张量 </em> （<a
  href="https://en.wikipedia.org/wiki/Hooke%27s_law#Hooke's_law_for_continuous_media"><em>compliance
  tensor</em></a>的逆向）。]），它包含了材料弹性强度的知识；它的对称性特性确保它将秩为2的对称张量（&ldquo;矩阵&rdquo;的维数 $d$ ，其中 $d$ 是空间维数）映射到相同秩的对称张量上。我们将在下面更多地评论应变和应力张量的作用。现在只需要说，我们将术语 $\textrm{div}\  ( C \varepsilon(\mathbf{u}))$ 解释为具有分量 $\frac \partial{\partial x_j} C_{ijkl} \varepsilon(\mathbf{u})_{kl}$ 的向量，其中对指数 $j,k,l$ 的求和是隐含的。

这个方程的准静态极限的动机如下：身体的每个小扰动，例如边界条件或强迫函数的变化，将导致身体配置的相应变化。一般来说，这将是以波的形式从扰动的位置辐射出去。由于阻尼项的存在，这些波将在例如 $\tau$ 的时间尺度上被衰减。现在，假设所有外部强制力的变化发生在比 $\tau$ 大得多的时间尺度上。在这种情况下，变化的动态性质并不重要：我们可以认为身体总是处于静态平衡状态，也就是说，我们可以假设在任何时候，身体都满足于

@f{eqnarray*}


  - \textrm{div}\  ( C \varepsilon(\mathbf{u})) &=& \mathbf{f}(\mathbf{x},t)
  \qquad
  \textrm{in}\ \Omega,
  \\
  \mathbf{u}(\mathbf{x},t) &=& \mathbf{d}(\mathbf{x},t)
  \qquad
  \textrm{on}\ \Gamma_D,
  \\
  \mathbf{n} \ C \varepsilon(\mathbf{u}(\mathbf{x},t)) &=& \mathbf{b}(\mathbf{x},t)
  \qquad
  \textrm{on}\ \Gamma_N.


@f}

请注意，微分方程不再包含任何时间导数 -- 所有的时间依赖性都是通过边界条件和可能的时间变化的力函数引入的  $\mathbf{f}(\mathbf{x},t)$  。因此，配置的变化可以被认为是瞬时静止的。对此的另一种看法是， $t$ 并不是真正的时间变量，而只是一个支配问题演变的类似时间的参数。

虽然这些方程足以描述小的变形，但计算大的变形就有点复杂了，一般来说，会导致非线性方程，如步骤-44中处理的那些。在下文中，让我们考虑在模拟变形成为<i>large</i>的问题时，人们会采用的一些工具。

 @note 我们下面要考虑的模型并不是建立在任何在数学上合理的基础上：我们将考虑一个模型，在这个模型中，我们产生一个小的变形，通过这个变形使身体的物理坐标变形，然后再考虑下一个加载步骤，作为一个线性问题。这并不一致，因为线性的假设意味着变形是无限小的，所以在解决下一个线性问题之前，在我们的网格顶点周围移动一个有限的量是不一致的做法。因此，我们应该注意到，在文献中找不到下面讨论的方程，这并不奇怪。<b>The model considered here has
little to do with reality!</b>另一方面，我们所考虑的实现技术正是人们在实现<i>real</i>模型时需要使用的，我们将在步骤-44中看到。


为了回到定义我们的 "人工 "模型，让我们首先引入一个张量的应力变量 $\sigma$ ，并以应力为基础写出微分方程。

@f{eqnarray*}


  - \textrm{div}\  \sigma &=& \mathbf{f}(\mathbf{x},t)
  \qquad
  \textrm{in}\ \Omega(t),
  \\
  \mathbf{u}(\mathbf{x},t) &=& \mathbf{d}(\mathbf{x},t)
  \qquad
  \textrm{on}\ \Gamma_D\subset\partial\Omega(t),
  \\
  \mathbf{n} \ C \varepsilon(\mathbf{u}(\mathbf{x},t)) &=& \mathbf{b}(\mathbf{x},t)
  \qquad
  \textrm{on}\ \Gamma_N=\partial\Omega(t)\backslash\Gamma_D.


@f}

注意这些方程是在一个随时间变化的域 $\Omega(t)$ 上提出的，边界根据边界上各点的位移 $\mathbf{u}(\mathbf{x},t)$ 而移动。为了完成这个系统，我们必须指定应力和应变之间的增量关系，如下所示。<a name="step_18.stress-strain"></a>

@f[
  \dot\sigma = C \varepsilon (\dot{\mathbf{u}}),
  \qquad
  \qquad
  \textrm{[stress-strain]}


@f]

其中点表示一个时间导数。应力 $\sigma$ 和应变 $\varepsilon(\mathbf{u})$ 都是等级2的对称张量。




<h4>Time discretization</h4>

在数值上，该系统的求解方法如下：首先，我们使用后向欧拉方案对时间部分进行离散化。这导致了时间步长的离散平衡力  $n$  。

@f[


  -\textrm{div}\  \sigma^n = f^n,


@f]

其中

@f[
  \sigma^n = \sigma^{n-1} + C \varepsilon (\Delta \mathbf{u}^n),


@f]

和  $\Delta \mathbf{u}^n$  时间步长的增量位移  $n$  。此外，我们必须指定初始数据  $\mathbf{u}(\cdot,0)=\mathbf{u}_0$  。这样一来，如果我们想求解位移增量，我们必须求解以下系统。

@f{align*}


  - \textrm{div}\   C \varepsilon(\Delta\mathbf{u}^n) &= \mathbf{f} + \textrm{div}\  \sigma^{n-1}
  \qquad
  &&\textrm{in}\ \Omega(t_{n-1}),
  \\
  \Delta \mathbf{u}^n(\mathbf{x},t) &= \mathbf{d}(\mathbf{x},t_n) - \mathbf{d}(\mathbf{x},t_{n-1})
  \qquad
  &&\textrm{on}\ \Gamma_D\subset\partial\Omega(t_{n-1}),
  \\
  \mathbf{n} \ C \varepsilon(\Delta \mathbf{u}^n(\mathbf{x},t)) &= \mathbf{b}(\mathbf{x},t_n)-\mathbf{b}(\mathbf{x},t_{n-1})
  \qquad
  &&\textrm{on}\ \Gamma_N=\partial\Omega(t_{n-1})\backslash\Gamma_D.


@f}

这组方程的弱形式，像往常一样是有限元公式的基础，其内容如下：找到 $\Delta \mathbf{u}^n \in
\{v\in H^1(\Omega(t_{n-1}))^d: v|_{\Gamma_D}=\mathbf{d}(\cdot,t_n) - \mathbf{d}(\cdot,t_{n-1})\}$ ，使<a name="step_18.linear-system"></a>这样的方程。

@f{align*}
  (C \varepsilon(\Delta\mathbf{u}^n), \varepsilon(\varphi) )_{\Omega(t_{n-1})}
  &=
  (\mathbf{f}, \varphi)_{\Omega(t_{n-1})}


  -(\sigma^{n-1},\varepsilon(\varphi))_{\Omega(t_{n-1})}
  \\
  &\qquad
  +(\mathbf{b}(\mathbf{x},t_n)-\mathbf{b}(\mathbf{x},t_{n-1}), \varphi)_{\Gamma_N}
  +(\sigma^{n-1} \mathbf{n}, \varphi)_{\Gamma_N}
  \\
  &\qquad\qquad
  \forall \varphi \in \{\mathbf{v}\in H^1(\Omega(t_{n-1}))^d: \mathbf{v}|_{\Gamma_D}=0\}.


@f}

利用 $\sigma^{n-1} \mathbf{n}
            = [C \varepsilon(\mathbf{u}^{n-1})] \mathbf{n}
            = \mathbf{b}(\mathbf x, t_{n-1})$ ，这些方程可以简化为

@f{align*}
  (C \varepsilon(\Delta\mathbf{u}^n), \varepsilon(\varphi) )_{\Omega(t_{n-1})}
  &=
  (\mathbf{f}, \varphi)_{\Omega(t_{n-1})}


  -(\sigma^{n-1},\varepsilon(\varphi))_{\Omega(t_{n-1})}
  +(\mathbf{b}(\mathbf{x},t_n),t_{n-1}), \varphi)_{\Gamma_N}
  \\
  &\qquad\qquad
  \forall \varphi \in \{\mathbf{v}\in H^1(\Omega(t_{n-1}))^d: \mathbf{v}|_{\Gamma_D}=0\}.
  \qquad
  \qquad
  \textrm{[linear-system]}


@f}



我们注意到，为了简单起见，在程序中我们总是假设没有边界力，即 $\mathbf{b} = 0$ ，并且身体的变形仅由身体力 $\mathbf{f}$ 和规定的边界位移 $\mathbf{d}$ 驱动。还值得注意的是，当通过部分积分时，我们会得到形式为 $(C \varepsilon(\Delta\mathbf{u}^n), \nabla \varphi
)_{\Omega(t_{n-1})}$ 的条款，但我们用涉及对称梯度的条款 $\varepsilon(\varphi)$ 而不是 $\nabla\varphi$ 来取代它们。由于 $C$ 的对称性，这两个项在数学上是等价的，但对称版本避免了可能出现的四舍五入错误，使得到的矩阵略显非对称性。

在时间步长 $n$ 的系统，要在旧域 $\Omega(t_{n-1})$ 上求解，其形式完全是一个静止的弹性问题，因此与我们在以前的例子程序中已经实现的类似。因此，除了说我们再次使用最低阶连续有限元之外，我们将不对空间离散化进行评论。

但也有不同之处。<ol>  <li>  我们必须在每个时间步骤之后移动（更新）网格，以便能够在新的领域上解决下一个时间步骤。

    <li> 我们需要知道 $\sigma^{n-1}$ 来计算下一个增量位移，也就是说，我们需要在时间步骤结束时计算它，以确保它可以用于下一个时间步骤。从本质上讲，应力变量是我们了解体的变形历史的窗口。   </ol>  这两个操作在程序中的 <code>move_mesh</code> 和 <code>update_quadrature_point_history</code> 函数中完成。移动网格只是一个技术问题，而更新应力则要复杂一些，将在下一节讨论。




<h4>Updating the stress variable</h4>

如上所述，在计算时间步长 $n+1$ 时，我们需要有应力变量 $\sigma^n$ ，我们可以用<a name="step_18.stress-update"></a>来计算它。

@f[
  \sigma^n = \sigma^{n-1} + C \varepsilon (\Delta \mathbf{u}^n).
  \qquad
  \qquad
  \textrm{[stress-update]}


@f]

尽管这个方程表面上很简单，但有两个问题我们需要讨论。第一个问题是关于我们存储 $\sigma^n$ 的方式：即使我们使用最低阶有限元计算增量更新 $\Delta\mathbf{u}^n$ ，那么其对称梯度 $\varepsilon(\Delta\mathbf{u}^n)$ 一般来说仍然是一个不容易描述的函数。特别是，它不是一个片状常数函数，在一般的网格上（单元不是平行于坐标轴的矩形）或非恒定应力-应变张量 $C$ ，它甚至不是一个双线性或三线性函数。因此，如何在计算机程序中存储 $\sigma^n$ 是先验的。

要决定这一点，我们必须看它被用在什么地方。我们需要应力的唯一地方是在术语 $(\sigma^{n-1},\varepsilon(\varphi))_{\Omega(t_{n-1})}$ 中。在实践中，我们当然会用数值正交来代替这个项。

@f[
  (\sigma^{n-1},\varepsilon(\varphi))_{\Omega(t_{n-1})}
  =
  \sum_{K\subset {T}}
  (\sigma^{n-1},\varepsilon(\varphi))_K
  \approx
  \sum_{K\subset {T}}
  \sum_q
  w_q \ \sigma^{n-1}(\mathbf{x}_q) : \varepsilon(\varphi(\mathbf{x}_q),


@f]

其中 $w_q$ 是正交权重， $\mathbf{x}_q$ 是单元格 $K$ 上的正交点。这应该表明，我们真正需要的不是应力 $\sigma^{n-1}$ 本身，而只是所有单元上的正交点的应力值。然而，这是一个更简单的任务：我们只需要提供一个数据结构，能够为所有单元上的每个正交点（或者，由于我们是并行计算，目前的MPI进程拥有的所有单元的所有正交点&ldquo;rdquo;）容纳一个等级为2的对称张量。在每个时间步骤结束时，我们只需评估 $\varepsilon(\Delta \mathbf{u}^n(\mathbf{x}_q))$ ，将其乘以应力-应变张量 $C$ ，并使用该结果来更新正交点 $q$ 的应力 $\sigma^n(\mathbf{x}_q)$ 。

第二个复杂的问题在我们上面选择的符号中并不明显。这是由于我们在域 $\Omega(t_{n-1})$ 上计算 $\Delta u^n$ ，然后用这个位移增量来更新应力，同时移动网格节点，以达到 $\Omega(t_n)$ ，在此基础上计算下一个增量。在这种情况下，我们必须确定的是，移动网格不仅涉及到节点的移动，还涉及到应力变量的相应变化：更新的应力是一个相对于旧域中材料的坐标系而定义的变量，必须转移到新域中。其原因可以理解为：在局部，增量变形 $\Delta\mathbf{u}$ 可以分解为三个部分，线性平移（点附近的位移增量场的常数部分），扩张分量（位移场梯度中具有非零发散的那部分），以及旋转。材料的线性平移并不影响冻结在其中的应力--应力值只是沿着平移。扩张或压缩的变化产生相应的应力更新。然而，旋转分量不一定会引起非零的应力更新（想想，在2d中，例如 $\Delta\mathbf{u}=(y, -x)^T$  ，与 $\varepsilon(\Delta
\mathbf{u})=0$  的情况）。尽管如此，如果材料在某个方向上被预应力，那么这个方向将随着材料的旋转而旋转。  为此，我们必须定义一个旋转矩阵 $R(\Delta \mathbf{u}^n)$ ，描述在每一个点上由于位移增量而产生的旋转。不难看出， $R$ 对 $\Delta \mathbf{u}^n$ 的实际依赖只能是通过位移的卷曲，而不是位移本身或其全部梯度（如上所述，增量的常数分量描述平移，其发散描述扩张模式，而卷曲描述旋转模式）。由于 $R$ 的确切形式很麻烦，我们只在程序代码中说明，并注意到应力变量的正确更新公式是<a name="step_18.stress-update+rot"></a> 。

@f[
  \sigma^n
  =
  R(\Delta \mathbf{u}^n)^T
  [\sigma^{n-1} + C \varepsilon (\Delta \mathbf{u}^n)]
  R(\Delta \mathbf{u}^n).
  \qquad
  \qquad
  \textrm{[stress-update+rot]}


@f]



应力更新和旋转都是在示例程序的函数 <code>update_quadrature_point_history</code> 中实现的。




<h3>Parallel graphical output</h3>

在步骤17中，就运行时间而言，平行计算的主要瓶颈是只有第一个处理器产生整个领域的输出。由于生成图形输出是很昂贵的，所以当涉及到更多数量的处理器时，这并不能很好地扩展。我们将在这里解决这个问题。关于程序 "扩展 "的定义，见 @ref GlossParallelScaling "本词汇表条目"）。

基本上，我们需要做的是让每个进程为它所拥有的那个单元子集产生图形输出，将它们写进单独的文件，并有办法同时显示某个时间步长的所有文件。这样，代码在每个时间步长的每个进程产生一个 <code>.vtu</code> 文件。两个常见的VTK文件查看器ParaView和Viscit都支持一次打开一个以上的 <code>.vtu</code> 文件。为了简化挑选正确文件的过程，并允许在时间上移动，两者都支持记录文件，以引用特定时间步长的所有文件。遗憾的是，记录文件在VisIt和Paraview之间有不同的格式，所以我们把两种格式都写出来。

代码将生成文件 <code>solution-TTTT.NNN.vtu</code> ，其中 <code>TTTT</code> 是时间步数（从1开始）， <code>NNN</code> 是进程等级（从0开始）。这些文件包含时间段和处理器的本地所有单元。文件 <code>solution-TTTT.visit</code> 是时间段的访问记录 <code>TTTT</code>, while <code>solution-TTTT.pvtu</code> 对ParaView也是如此。(较新版本的VisIt实际上也可以读取 <code>.pvtu</code> 文件，但输出两种记录文件也无妨。)最后， <code>solution.pvd</code> 文件是只有ParaView支持的特殊记录，它引用所有的时间步骤。所以在ParaView中，只需要打开solution.pvd，而在VisIt中需要选择所有的.visit文件组，才能达到同样的效果。




<h3>A triangulation with automatic partitioning</h3>

在第17步中，我们使用了一个在每个处理器上简单复制的常规三角形，以及一个相应的DoFHandler。两者都不知道它们是在%并行环境下使用的--它们只是完整地存在于每个处理器上，我们认为这最终会成为一个主要的内存瓶颈。

我们在这里不解决这个问题（我们将在第40步中解决），但使情况稍微自动化一些。在第17步中，我们创建了三角形，然后手动 "分区"，也就是说，我们给每个单元分配了 @ref GlossSubdomainId "子域ID"，以表明哪个 @ref GlossMPIProcess "MPI进程""拥有 "该单元。在这里，我们使用了一个类 parallel::shared::Triangulation ，它至少自动完成了这一部分：每当你创建或完善这样一个三角图时，它都会自动在所有参与的进程之间进行划分（它知道这些进程，因为你必须告诉它在构建三角图时连接这些进程的 @ref GlossMPICommunicator "MPI通信器"）。否则， parallel::shared::Triangulation 看起来，就所有的实际目的而言，就像一个普通的Triangulation对象。

使用这个类的便利性不仅来自于能够避免手动调用 GridTools::partition(). ，相反，DoFHandler类现在也知道你想在并行环境下使用它，并且默认情况下会自动列举自由度，使进程0拥有的所有DoF先于进程1拥有的所有DoF，等等。换句话说，你也可以避免对 DoFRenumbering::subdomain_wise(). 的调用。

还有其他好处。例如，由于三角计算知道它生活在一个%parallel universe中，它也知道它 "拥有 "某些单元（即那些子域id等于其MPI等级的单元；以前，三角计算只存储这些子域id，但没有办法使它们有意义）。因此，在汇编函数中，你可以测试一个单元是否 "本地拥有"（即由当前进程拥有，见 @ref GlossLocallyOwnedCell ），当你在所有单元上循环时，使用以下语法

@code
  if (cell->is_locally_owned())
@endcode

这种知识延伸到建立在这种三角形上的DoFHandler对象，然后它可以通过 DoFHandler::compute_n_locally_owned_dofs_per_processor() 和 DoFTools::extract_locally_relevant_dofs(). 等调用来识别哪些自由度是本地拥有的（见 @ref GlossLocallyOwnedDof ）。最后，DataOut类也知道如何处理这种三角形，并将简单地跳过在非本地拥有的单元上生成图形输出。

当然，正如在第17步的讨论中多次指出的那样，在每个进程上保持整个三角形将无法扩展：大型问题可能根本无法再适合每个进程的内存，即使我们有足够多的进程在合理的时间内解决它们。在这种情况下， parallel::shared::Triangulation 不再是一个合理的计算基础，我们将在步骤40中展示如何使用 parallel::distributed::Triangulation 类来解决这个问题，即让每个进程只存储一个<i>part</i>的三角图。




<h3>Overall structure of the program</h3>

程序的整体结构可以从 <code>run()</code> 函数中推断出来，该函数首先在第一个时间步骤中调用 <code>do_initial_timestep()</code> ，然后在所有后续时间步骤中调用 <code>do_timestep()</code> 。这些函数之间的区别仅仅在于，在第一个时间步骤中，我们从一个粗略的网格开始，在其上求解，自适应地细化网格，然后在新的网格上以干净的状态重新开始。这个过程给了我们一个更好的起始网格，尽管我们当然应该在迭代过程中不断调整网格--这个程序中没有这样做，但是下面会有评论。

这两个处理时间步骤的函数的共同部分是在本网格上的以下操作序列。   <ul>   <li>   <code>assemble_system ()</code> [via <code>solve_timestep ()</code>  ] 。   这第一个函数也是最有趣的一个。它组装了对应于方程<a href="#step_18.linear-system">[linear-system]</a>离散化版本的线性系统。这导致了一个系统矩阵 $A_{ij} = \sum_K
  A^K_{ij}$ ，由每个单元 $K$ 上的局部贡献组成，其条目为@f[
    A^K_{ij} = (C \varepsilon(\varphi_j), \varepsilon(\varphi_i))_K;
  @f] 。

  在实践中， $A^K$ 是根据公式@f[
    A^K_{ij} = \sum_q w_q [\varepsilon(\varphi_i(\mathbf{x}_q)) : C :
                           \varepsilon(\varphi_j(\mathbf{x}_q))],
  @f]使用数值正交计算出来的。

  与正交点 $\mathbf{x}_q$ 和权重 $w_q$  。我们之前在步骤8和步骤17中建立了这些贡献，但在这两种情况下，我们都是通过使用等级4张量 $C$ 的组成知识，以及考虑应变张量的单个元素 $\varepsilon(\varphi_i),\varepsilon(\varphi_j)$ ，相当笨拙地完成的。这其实并不方便，特别是如果我们想考虑比各向同性的情况更复杂的弹性模型，而 $C$ 有方便的形式  $C_{ijkl}  = \lambda \delta_{ij} \delta_{kl} + \mu (\delta_{ik} \delta_{jl}
  + \delta_{il} \delta_{jk})$  。虽然我们在本程序中没有使用比这更复杂的形式，但我们还是希望以一种容易实现的方式来编写它。因此，很自然地要引入代表等级为2（用于应变和应力）和4（用于应力-应变张量 $C$ ）的对称张量的类。幸运的是，deal.II提供了这些： <code>SymmetricTensor<rank,dim></code> 类模板提供了等级 <code>rank</code> （需要是偶数）和维度 <code>dim</code> 的这类张量的完整实现。

  然后我们需要的是两件事：一种创建应力-应变等级4张量 $C$ 的方法，以及从形状函数 $\varphi_i$ 的梯度在给定单元上的正交点 $\mathbf{x}_q$ 创建一个等级2的对称张量（应变张量）。在这个例子程序的执行顶部，你会发现这样的函数。第一个， <code>get_stress_strain_tensor</code>  ，需要两个参数，对应于Lam&eacute; 常数 $\lambda$ 和 $\mu$ ，并返回对应于这些常数的各向同性的应力应变张量（在程序中，我们将选择对应于钢的常数）；用一个计算各向异性的张量的函数来代替这个函数是很简单的，或者考虑到晶体对称性，比如说。第二个， <code>get_strain</code> takes an object of type <code>FEValues</code> 和指数 $i$ 和 $q$ ，返回对称梯度，即应变，对应于形状函数 $\varphi_i(\mathbf{x}_q)$ ，在 <code>FEValues</code> 对象最后被重新初始化的单元上评估。

  鉴于此， <code>assemble_system</code> 的最内部循环以下列优雅的方式计算对矩阵的局部贡献（变量 <code>stress_strain_tensor</code> ，对应于张量 $C$ ，之前已经用上述第一个函数的结果初始化了）。   @code
for (unsigned int i=0; i<dofs_per_cell; ++i)
  for (unsigned int j=0; j<dofs_per_cell; ++j)
    for (unsigned int q_point=0; q_point<n_q_points;
         ++q_point)
      {
        const SymmetricTensor<2,dim>
          eps_phi_i = get_strain (fe_values, i, q_point),
          eps_phi_j = get_strain (fe_values, j, q_point);


        cell_matrix(i,j)
          += (eps_phi_i * stress_strain_tensor * eps_phi_j *
              fe_values.JxW (q_point));
      }
  @endcode

  值得注意的是这段代码的表现力，并将其与我们在以前的例子中为弹性问题所经历的复杂情况进行比较。公平地说，在写这些以前的例子时，SymmetricTensor类模板还不存在）。为了简单起见， <code>operator*</code> 在这里规定了偶数等级的对称张量之间的（双重求和）积。

  组建本地捐款@f{eqnarray*}
      f^K_i &=&
      (\mathbf{f}, \varphi_i)_K -(\sigma^{n-1},\varepsilon(\varphi_i))_K
      \\
      &\approx&
      \sum_q
      w_q \left\{
        \mathbf{f}(\mathbf{x}_q) \cdot \varphi_i(\mathbf{x}_q) -
        \sigma^{n-1}_q : \varepsilon(\varphi_i(\mathbf{x}_q))
      \right\}
  @f}

  到<a href="#step_18.linear-system">[linear-system]</a>的右手边同样是直接的（注意，我们在这里不考虑任何边界牵引 $\mathbf{b}$ ）。请记住，我们只需要在单元格的正交点上存储旧的应力。在程序中，我们将提供一个变量 <code>local_quadrature_points_data</code> ，允许访问每个正交点的应力 $\sigma^{n-1}_q$ 。有了这个，右手边的代码看起来就像这样，同样相当优雅。   @code
for (unsigned int i=0; i<dofs_per_cell; ++i)
  {
    const unsigned int
      component_i = fe.system_to_component_index(i).first;


    for (unsigned int q_point=0; q_point<n_q_points; ++q_point)
      {
        const SymmetricTensor<2,dim> &old_stress
          = local_quadrature_points_data[q_point].old_stress;


        cell_rhs(i) += (body_force_values[q_point](component_i) *
                        fe_values.shape_value (i,q_point)


                        -
                        old_stress *
                        get_strain (fe_values,i,q_point)) *
                       fe_values.JxW (q_point);
      }
  }
  @endcode

  请注意，在乘法 $\mathbf{f}(\mathbf{x}_q) \cdot \varphi_i(\mathbf{x}_q)$ 中，我们利用了这样一个事实：对于所选的有限元素， $\varphi_i$ 中只有一个向量分量（即 <code>component_i</code> ）是非零的，因此我们也只需要考虑 $\mathbf{f}(\mathbf{x}_q)$ 的一个分量。

  这基本上结束了我们在这个函数中提出的新材料。它后来必须处理边界条件以及悬挂节点约束，但这与我们以前在其他程序中已经要做的事情相类似。

 <li>   <code>solve_linear_problem ()</code> [via <code>solve_timestep ()</code>  ] 。   与前一个函数不同，这个函数其实并不有趣，因为它做的是以前所有教程程序中的类似函数--用CG方法求解线性系统，使用不完整的LU分解作为预处理程序（在%并行情况下，它分别使用每个处理器块的ILU）。它与第17步几乎没有变化。

 <li>   <code>update_quadrature_point_history ()</code>  [通过 <code>solve_timestep ()</code>  ] 。基于之前计算的位移场 $\Delta \mathbf{u}^n$ ，我们根据<a href="#step_18.stress-update">[stress-update]</a>和<a href="#step_18.stress-update+rot">[stress-update+rot]</a>更新所有正交点的应力值，包括坐标系的旋转。

 <li>   <code>move_mesh ()</code>  ：给定之前计算的解决方案，在这个函数中，我们通过移动每个顶点的位移矢量场来实现网格的变形。

 <li>   <code>output_results ()</code>  : 这个函数只是根据我们上面所说的输出解决方案，也就是说，每个处理器只对自己的那部分域计算输出。除了解决方案，我们还计算了每个单元上所有正交点平均的应力的规范。   </ul> 

有了这个代码的一般结构，我们只需要定义我们要解决的情况。在本程序中，我们选择模拟一个垂直圆柱体的准静态变形，其底部边界是固定的，顶部边界以规定的垂直速度被推倒。然而，顶层边界的水平速度没有被指定--我们可以把这种情况想象成一块油性良好的板从顶部推到圆柱体上，圆柱体顶层边界上的点被允许沿着板的表面水平滑动，但被板强迫向下移动。圆柱体的内部和外部边界是自由的，不受任何规定的偏转或牵引的影响。此外，重力作用于身体。

程序文本将揭示更多关于如何实现这种情况，而结果部分将显示这种模拟产生的位移模式。


examples/step-18/doc/results.dox



<h1>Results</h1>


如果使用调试模式，运行该程序需要很长时间；在我的i7台式机上需要大约11分钟。幸运的是，经过优化编译的版本要快得多；在同一台机器上用<tt>make release</tt>命令重新编译后，程序只需要大约1.5分钟，这个时间要合理得多。


如果运行，该程序会打印出以下输出，解释它在这段时间内做了什么。

@verbatim
\$ time make run
[ 66%] Built target \step-18
[100%] Run \step-18 with Release configuration
Timestep 1 at time 1
  Cycle 0:
    Number of active cells:       3712 (by partition: 3712)
    Number of degrees of freedom: 17226 (by partition: 17226)
    Assembling system... norm of rhs is 1.88062e+10
    Solver converged in 103 iterations.
    Updating quadrature point data...
  Cycle 1:
    Number of active cells:       12812 (by partition: 12812)
    Number of degrees of freedom: 51738 (by partition: 51738)
    Assembling system... norm of rhs is 1.86145e+10
    Solver converged in 121 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 2 at time 2
    Assembling system... norm of rhs is 1.84169e+10
    Solver converged in 122 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 3 at time 3
    Assembling system... norm of rhs is 1.82355e+10
    Solver converged in 122 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 4 at time 4
    Assembling system... norm of rhs is 1.80728e+10
    Solver converged in 117 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 5 at time 5
    Assembling system... norm of rhs is 1.79318e+10
    Solver converged in 116 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 6 at time 6
    Assembling system... norm of rhs is 1.78171e+10
    Solver converged in 115 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 7 at time 7
    Assembling system... norm of rhs is 1.7737e+10
    Solver converged in 112 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 8 at time 8
    Assembling system... norm of rhs is 1.77127e+10
    Solver converged in 111 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 9 at time 9
    Assembling system... norm of rhs is 1.78207e+10
    Solver converged in 113 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 10 at time 10
    Assembling system... norm of rhs is 1.83544e+10
    Solver converged in 115 iterations.
    Updating quadrature point data...
    Moving mesh...


[100%] Built target run
make run  176.82s user 0.15s system 198% cpu 1:28.94 total
@endverbatim

换句话说，它是在12,000个单元和大约52,000个未知数的情况下进行计算。不是很多，但对于一个耦合的三维问题来说，足以让计算机忙上一阵子。在一天结束的时候，这就是我们的输出。

@verbatim
\$ ls -l *vtu *visit


-rw-r--r-- 1 drwells users 1706059 Feb 13 19:36 solution-0010.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:36 solution-0010.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:36 solution-0010.visit


-rw-r--r-- 1 drwells users 1707907 Feb 13 19:36 solution-0009.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:36 solution-0009.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:36 solution-0009.visit


-rw-r--r-- 1 drwells users 1703771 Feb 13 19:35 solution-0008.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:35 solution-0008.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:35 solution-0008.visit


-rw-r--r-- 1 drwells users 1693671 Feb 13 19:35 solution-0007.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:35 solution-0007.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:35 solution-0007.visit


-rw-r--r-- 1 drwells users 1681847 Feb 13 19:35 solution-0006.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:35 solution-0006.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:35 solution-0006.visit


-rw-r--r-- 1 drwells users 1670115 Feb 13 19:35 solution-0005.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:35 solution-0005.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:35 solution-0005.visit


-rw-r--r-- 1 drwells users 1658559 Feb 13 19:35 solution-0004.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:35 solution-0004.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:35 solution-0004.visit


-rw-r--r-- 1 drwells users 1639983 Feb 13 19:35 solution-0003.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:35 solution-0003.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:35 solution-0003.visit


-rw-r--r-- 1 drwells users 1625851 Feb 13 19:35 solution-0002.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:35 solution-0002.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:35 solution-0002.visit


-rw-r--r-- 1 drwells users 1616035 Feb 13 19:34 solution-0001.000.vtu


-rw-r--r-- 1 drwells users     761 Feb 13 19:34 solution-0001.pvtu


-rw-r--r-- 1 drwells users      33 Feb 13 19:34 solution-0001.visit
@endverbatim




如果我们用VisIt或Paraview将这些文件可视化，我们就能看到我们的强制压缩对圆柱体造成的灾难的全貌（图像中的颜色编码了材料中的应力规范）。


<div class="threecolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.sequential-0002.0000.png" alt="Time = 2" width="400"> </div> <div class="text" align="center"> Time = 2 </div> <div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.sequential-0005.0000.png" alt="时间=5" width="400"> </div> <div class="text" align="center"> 时间=5 </div> </div> <div class="father"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.sequential-0007.0000.png" alt="时间=7" width="400"> </div> <div class="text" align="center">时间=7 </div> </div> </div>


<div class="threecolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.sequential-0008.0000.png" alt="Time = 8" width="400"> </div> <div class="text" align="center"> 时间 = 8 </div> </div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.sequential-0009.0000.png" alt="时间=9" width="400"> </div> <div class="text" align="center"> 时间=9 </div> </div> <div class="father"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.sequential-0010.0000.png" alt="Time = 10" width="400"> </div> <div class="text" align="center"> Time = 10 </div> </div> </div>


可以清楚地看到，当我们不断压缩圆柱体时，它开始在完全约束的底面附近弯曲，并在大约8个时间单位后，以方位对称的方式弯曲。


虽然这个结果对于对称几何和加载来说似乎是合理的，但计算是否完全收敛还有待确定。为了确定是否收敛，我们再次运行程序，在开始时再进行一次全局细化，并将时间步长减半。这在单机上会花费很长的时间，所以我们使用了一个合适的工作站，在16个处理器上并行运行。现在输出的开头看起来像这样。

@verbatim
Timestep 1 at time 0.5
  Cycle 0:
    Number of active cells:       29696 (by partition: 1808+1802+1894+1881+1870+1840+1884+1810+1876+1818+1870+1884+1854+1903+1816+1886)
    Number of degrees of freedom: 113100 (by partition: 6936+6930+7305+7116+7326+6869+7331+6786+7193+6829+7093+7162+6920+7280+6843+7181)
    Assembling system... norm of rhs is 1.10765e+10
    Solver converged in 209 iterations.
    Updating quadrature point data...
  Cycle 1:
    Number of active cells:       102034 (by partition: 6387+6202+6421+6341+6408+6201+6428+6428+6385+6294+6506+6244+6417+6527+6299+6546)
    Number of degrees of freedom: 359337 (by partition: 23255+21308+24774+24019+22304+21415+22430+22184+22298+21796+22396+21592+22325+22553+21977+22711)
    Assembling system... norm of rhs is 1.35759e+10
    Solver converged in 268 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 2 at time 1
    Assembling system... norm of rhs is 1.34674e+10
    Solver converged in 267 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 3 at time 1.5
    Assembling system... norm of rhs is 1.33607e+10
    Solver converged in 265 iterations.
    Updating quadrature point data...
    Moving mesh...


Timestep 4 at time 2
    Assembling system... norm of rhs is 1.32558e+10
    Solver converged in 263 iterations.
    Updating quadrature point data...
    Moving mesh...


[...]


Timestep 20 at time 10
    Assembling system... norm of rhs is 1.47755e+10
    Solver converged in 425 iterations.
    Updating quadrature point data...
    Moving mesh...
@endverbatim

考虑到我们是在三维空间中，这是一个相当好的未知数的数量。这个程序的输出是每个时间步骤的16个文件。

@verbatim
\$ ls -l solution-0001*


-rw-r--r-- 1 wellsd2 user 761065 Feb 13 21:09 solution-0001.000.vtu


-rw-r--r-- 1 wellsd2 user 759277 Feb 13 21:09 solution-0001.001.vtu


-rw-r--r-- 1 wellsd2 user 761217 Feb 13 21:09 solution-0001.002.vtu


-rw-r--r-- 1 wellsd2 user 761605 Feb 13 21:09 solution-0001.003.vtu


-rw-r--r-- 1 wellsd2 user 756917 Feb 13 21:09 solution-0001.004.vtu


-rw-r--r-- 1 wellsd2 user 752669 Feb 13 21:09 solution-0001.005.vtu


-rw-r--r-- 1 wellsd2 user 735217 Feb 13 21:09 solution-0001.006.vtu


-rw-r--r-- 1 wellsd2 user 750065 Feb 13 21:09 solution-0001.007.vtu


-rw-r--r-- 1 wellsd2 user 760273 Feb 13 21:09 solution-0001.008.vtu


-rw-r--r-- 1 wellsd2 user 777265 Feb 13 21:09 solution-0001.009.vtu


-rw-r--r-- 1 wellsd2 user 772469 Feb 13 21:09 solution-0001.010.vtu


-rw-r--r-- 1 wellsd2 user 760833 Feb 13 21:09 solution-0001.011.vtu


-rw-r--r-- 1 wellsd2 user 782241 Feb 13 21:09 solution-0001.012.vtu


-rw-r--r-- 1 wellsd2 user 748905 Feb 13 21:09 solution-0001.013.vtu


-rw-r--r-- 1 wellsd2 user 738413 Feb 13 21:09 solution-0001.014.vtu


-rw-r--r-- 1 wellsd2 user 762133 Feb 13 21:09 solution-0001.015.vtu


-rw-r--r-- 1 wellsd2 user   1421 Feb 13 21:09 solution-0001.pvtu


-rw-r--r-- 1 wellsd2 user    364 Feb 13 21:09 solution-0001.visit
@endverbatim




这里首先是我们计算的网格，以及16个处理器的分区。


<div class="twocolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-000mesh.png" alt="Discretization" width="400"> </div> <div class="text" align="center"> Discretization </div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-0002.p.png" alt="Parallel partitioning" width="400"> </div> <div class="text" align="center"> Parallel partitioning</div> </div> </div>


最后，这里是与我们之前展示的更小的顺序情况相同的输出。

<div class="threecolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-0002.s.png" alt="Time = 2" width="400"> </div> <div class="text" align="center"> 时间 = 2 </div> </div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-0005.s.png" alt="时间=5" width="400"> </div> <div class="text" align="center"> 时间=5 </div> </div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-0007.s.png" alt="Time = 7" width="400"> </div> <div class="text" align="center"> Time = 7 </div> </div> </div>


<div class="threecolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-0008.s.png" alt="Time = 8" width="400"> </div> <div class="text" align="center"> 时间 = 8 </div> </div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-0009.s.png" alt="Time = 9" width="400"> </div> <div class="text" align="center"> Time = 9 </div> </div> <div class="father"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-18.parallel-0010.s.png" alt="Time = 10" width="400"> </div> <div class="text" align="center"> Time = 10 </div> </div> </div>


和以前一样，我们观察到，在高轴向压缩时，圆柱体开始弯曲，但这一次最终是在自己身上塌陷。与我们的第一次运行相反，在模拟结束时，变形模式变得不对称（中心隆起向侧面偏转）。该模型显然没有规定这一点（我们所有的力和边界偏转都是对称的），但这种效果可能在物理上是正确的：在现实中，身体材料属性的小不均匀性会导致它向一侧弯曲以逃避强制力；在数值模拟中，小的扰动，如数值舍入或迭代求解器对线性系统的不精确求解，也会产生同样的效果。在自适应计算中，另一个典型的不对称来源是每一步只细化一定的单元，这可能导致不对称的网格，即使原来的粗网格是对称的。


如果将其与之前的运行相比较，结果在质和量上都有不同。因此，以前的计算肯定没有收敛，尽管我们不能肯定地说现在的计算有什么问题。我们需要一个更精细的计算来找出答案。然而，这一点可能是没有意义的：详细看一下最后一张图片，很明显，不仅我们选择的线性小变形模型是完全不够的，而且对于一个现实的模拟，我们还需要确保身体在变形过程中不相交（如果我们继续压缩圆柱体，我们会观察到一些自我相交）。如果没有这样的表述，我们就不能指望任何东西都有物理意义，即使它能产生漂亮的图片!




<h3>Possibilities for extensions</h3>

这个程序并没有真正解决一个在实践中有很多应用的方程：基于纯弹性规律的准静态材料变形几乎是无聊的。然而，该程序可以作为更有趣的实验的起点，而这确实是编写该程序的最初动机。这里有一些建议，说明这个程序缺少什么，以及它可以在什么方向上进行扩展。

<h5>Plasticity models</h5>

最明显的扩展是使用一个更现实的材料模型来处理大规模的静态变形。这方面的自然选择是塑性，其中应力和应变之间的非线性关系取代了方程<a href="#step_18.stress-strain">[stress-strain]</a>。塑性模型的编程通常相当复杂，因为应力-应变关系通常是非平滑的。可以认为材料只能承受一个最大的应力（屈服应力），之后它就会开始&ldquo;流动&rdquo;。这方面的数学描述可以以变分不等式的形式给出，也可以将其视为弹性能量的最小化

@f[
  E(\mathbf{u}) =
  (\varepsilon(\mathbf{u}), C\varepsilon(\mathbf{u}))_{\Omega}


  - (\mathbf{f}, \mathbf{u})_{\Omega} - (\mathbf{b}, \mathbf{u})_{\Gamma_N},


@f]

受制于约束条件

@f[
  f(\sigma(\mathbf{u})) \le 0


@f]

对应力的影响。这种扩展使得在每个时间步长中要解决的问题是非线性的，所以我们需要在每个时间步长中的另一个循环。

在不进一步了解这个模型的细节的情况下，我们可以参考Simo和Hughes关于&ldquo;计算非弹性&rdquo;的优秀书籍，以全面了解解决塑性模型的计算策略。另外，在S. Commend, A. Truty, and Th. Zimmermann的文章中，对塑性的算法做了简单而简洁的描述。Zimmermann;  @cite CTZ04  。




<h5>Stabilization issues</h5>

我们选择的公式，即对位移矢量的所有分量使用分片（双，三）线性元素，并将应力视为依赖于位移的变量，对于大多数材料是合适的。然而，对于不可压缩或几乎不可压缩的材料，这种所谓的基于位移的公式变得不稳定，并表现出虚假的模式。虽然流体通常不是弹性的（在大多数情况下，应力取决于速度梯度，而不是位移梯度，但也有例外，如电流变流体），但也有少数固体是几乎不可压缩的，如橡胶。另一种情况是，许多塑性模型最终让材料变得不可压缩，尽管这不在本方案的范围之内。

不可压缩性是由泊松比来表征的

@f[
  \nu = \frac{\lambda}{2(\lambda+\mu)},


@f]

其中 $\lambda,\mu$ 是材料的Lam&eacute; 常数。物理约束表明 $-1\le \nu\le \frac 12$ （该条件也来自于数学稳定性考虑）。如果 $\nu$ 接近 $\frac 12$ ，则材料变得不可压缩。在这种情况下，纯粹的基于位移的公式不再适合于解决这类问题，必须采用稳定化技术以获得稳定和准确的解决方案。上面引用的书和论文给出了如何做到这一点的指示，但在这个问题上也有大量的文献；在H.-Y. Duan和Q. Lin的论文的参考文献中可以找到一个获得该主题概述的良好开端。H.-Y. Duan and Q. Lin;  @cite DL05  。




<h5>Refinement during timesteps</h5>

在目前的形式下，程序只对初始网格进行若干次细化，然后就不再进行细化。对于任何一种现实的模拟，我们都希望将其扩展到每隔几步就对网格进行细化和粗化。事实上，这并不难做到，但如果你愿意的话，可以留待将来的教程程序或作为练习。

我们必须克服的主要复杂问题是，我们必须将存储在旧网格单元的正交点中的数据转移到新网格中，最好是通过某种投影方案。这方面的一般方法是这样的。

- 开始时，数据只在各个单元的正交点上可用，而不是作为一个到处定义的有限元场。

- 所以让我们找到一个<i>is</i>处处定义的有限元场，这样我们以后就可以把它插到新网格的正交点上。一般来说，要找到一个与正交点中的数值完全匹配的连续有限元场是很困难的，因为这些场的自由度数与正交点的数量不匹配，这个全局场的节点值要么是过定的，要么是欠定的。但是找到一个与正交点数值相匹配的不连续场通常不是很困难；例如，如果你有一个QGauss(2)正交公式（即2d中每个单元4个点，3d中8个点），那么就可以使用FE_DGQ(1)类型的有限元，即双/三线性函数，因为这些函数在2d中每个单元有4个自由度，在3d中有8个自由度。

- 有一些函数可以使这种从单个点到全局场的转换更简单。如果你使用QGauss(2)正交公式，下面这段伪代码应该会有所帮助。请注意，下面的投影矩阵的乘法需要一个标量分量的向量，也就是说，我们一次只能将一组标量从正交点转换成自由度，反之亦然。所以我们需要分别存储每个应力分量，这需要 <code>dim*dim</code> 个向量。我们将把这组向量存储在一个二维数组中，以便于用读出应力张量的方式来读出分量。   因此，我们将对每个单元的应力分量进行循环，并将这些值存储在全局历史域中。(前缀 <code>history_</code> 表示我们的工作与正交点中定义的历史变量有关。)   @code
    FE_DGQ<dim>     history_fe (1);
    DoFHandler<dim> history_dof_handler (triangulation);
    history_dof_handler.distribute_dofs (history_fe);


    std::vector< std::vector< Vector<double> > >
                 history_field (dim, std::vector< Vector<double> >(dim)),
                 local_history_values_at_qpoints (dim, std::vector< Vector<double> >(dim)),
                 local_history_fe_values (dim, std::vector< Vector<double> >(dim));


    for (unsigned int i=0; i<dim; i++)
      for (unsigned int j=0; j<dim; j++)
      {
        history_field[i][j].reinit(history_dof_handler.n_dofs());
        local_history_values_at_qpoints[i][j].reinit(quadrature.size());
        local_history_fe_values[i][j].reinit(history_fe.n_dofs_per_cell());
      }


    FullMatrix<double> qpoint_to_dof_matrix (history_fe.dofs_per_cell,
                                             quadrature.size());
    FETools::compute_projection_from_quadrature_points_matrix
              (history_fe,
               quadrature, quadrature,
               qpoint_to_dof_matrix);


    typename DoFHandler<dim>::active_cell_iterator cell = dof_handler.begin_active(),
                                                   endc = dof_handler.end(),
                                                   dg_cell = history_dof_handler.begin_active();


    for (; cell!=endc; ++cell, ++dg_cell)
      {


        PointHistory<dim> *local_quadrature_points_history
          = reinterpret_cast<PointHistory<dim> *>(cell->user_pointer());


        Assert (local_quadrature_points_history >= &quadrature_point_history.front(),
                ExcInternalError());
        Assert (local_quadrature_points_history < &quadrature_point_history.back(),
                ExcInternalError());


        for (unsigned int i=0; i<dim; i++)
          for (unsigned int j=0; j<dim; j++)
          {
            for (unsigned int q=0; q<quadrature.size(); ++q)
              local_history_values_at_qpoints[i][j](q)
                = local_quadrature_points_history[q].old_stress[i][j];


            qpoint_to_dof_matrix.vmult (local_history_fe_values[i][j],
                                        local_history_values_at_qpoints[i][j]);


            dg_cell->set_dof_values (local_history_fe_values[i][j],
                                     history_field[i][j]);
          }
      }
  @endcode



- 现在我们有了一个全局场，我们可以像往常一样使用SolutionTransfer类来细化网格并转移history_field向量。这将把所有的东西从旧的网格插值到新的网格。

- 在最后一步，我们必须将数据从现在插值的全局场返回到新网格上的正交点。下面的代码将做到这一点。   @code
    FullMatrix<double> dof_to_qpoint_matrix (quadrature.size(),
                                             history_fe.n_dofs_per_cell());
    FETools::compute_interpolation_to_quadrature_points_matrix
              (history_fe,
               quadrature,
               dof_to_qpoint_matrix);


    typename DoFHandler<dim>::active_cell_iterator cell = dof_handler.begin_active(),
                                                   endc = dof_handler.end(),
                                                   dg_cell = history_dof_handler.begin_active();


    for (; cell != endc; ++cell, ++dg_cell)
    {
      PointHistory<dim> *local_quadrature_points_history
       = reinterpret_cast<PointHistory<dim> *>(cell->user_pointer());


      Assert (local_quadrature_points_history >= &quadrature_point_history.front(),
              ExcInternalError());
      Assert (local_quadrature_points_history < &quadrature_point_history.back(),
              ExcInternalError());


      for (unsigned int i=0; i<dim; i++)
        for (unsigned int j=0; j<dim; j++)
        {
          dg_cell->get_dof_values (history_field[i][j],
                                   local_history_fe_values[i][j]);


          dof_to_qpoint_matrix.vmult (local_history_values_at_qpoints[i][j],
                                      local_history_fe_values[i][j]);


          for (unsigned int q=0; q<quadrature.size(); ++q)
            local_quadrature_points_history[q].old_stress[i][j]
              = local_history_values_at_qpoints[i][j](q);
      }
  @endcode



一旦我们并行运行程序，情况就变得有点复杂了，因为那时每个进程只为它在旧网格上拥有的单元存储这些数据。也就是说，如果你在正交点转移到全局向量之后，使用 <code>history_field</code> 的并行向量就可以做到这一点。




<h5>Ensuring mesh regularity</h5>

目前，程序没有尝试确保一个单元在时间步数结束时移动其顶点后，仍然具有有效的几何形状（即它的雅各布行列式是正的，并且在任何地方都远离零的界限）。事实上，设置边界值和强迫项并不难，这样就可以很快得到扭曲和倒置的单元。当然，在某些大变形的情况下，这在有限网格的情况下是不可避免的，但在其他一些情况下，通过适当的网格细化和/或减少时间步长，这应该是可以避免的。这个程序没有做到这一点，但是一个更复杂的版本肯定应该采用某种启发式方法来定义哪些单元的变形量是可以接受的，哪些是不可以的。


examples/step-19/doc/intro.dox



 <br> 

<i>
This program was contributed by Wolfgang Bangerth, Rene Gassmoeller, and Peter Munch.


Wolfgang Bangerth acknowledges support through NSF
awards DMS-1821210, EAR-1550901, and OAC-1835673.
</i>

 @note  deal.II中存在对粒子的支持，这主要是由于Rene Gassmoeller的最初努力。如果你在自己的工作中使用粒子功能，请引用出版物 @cite GLHPW2018 来确认这项工作。

<a name="Intro"></a>

<h1>Introduction</h1>

一般来说，有限元方法，特别是deal.II，是为了解决偏微分方程而发明的--换句话说，是为了解决[连续体力学](https://en.wikipedia.org/wiki/Continuum_mechanics)问题。另一方面，有时人们想解决的问题是，跟踪单个物体（"粒子"）以及它们的位置如何演变是有用的。如果这只是导致一组常微分方程，例如，如果你想跟踪太阳系中行星随时间变化的位置，那么deal.II显然不是你合适的工具。另一方面，如果这种演变是由于与偏微分方程的解的相互作用，或者有一个网格来确定哪些粒子与其他粒子相互作用（如在[平滑粒子流体力学（SPH）](https://en.wikipedia.org/wiki/Smoothed-particle_hydrodynamics)方法中），那么deal.II对你有支持。

我们在这里要考虑的情况是带电粒子如何在电场中移动。作为动力，我们将考虑[阴极射线]（https://en.wikipedia.org/wiki/Cathode_ray）。由一块被加热的带负电的金属（"阴极"）发出的电子，然后被电场加速到带正电的电极（"阳极"）。阳极通常是环形的，这样大部分电子可以以电子束的形式飞过孔。在过去，它们可能会照亮由[阴极射线管](https://en.wikipedia.org/wiki/Cathode-ray_tube)制成的电视的屏幕。今天，电子束反而在[X射线机](https://en.wikipedia.org/wiki/X-ray_tube)、[电子束光刻](https://en.wikipedia.org/wiki/Electron-beam_lithography)、[电子束焊接](https://en.wikipedia.org/wiki/Electron-beam_welding)和其他一些领域发挥了作用。

然后我们要考虑的方程如下。首先，我们需要描述电场。通过注意到电势 $V$ 满足方程，这是最容易完成的。

@f[


  -\epsilon_0 \Delta V = \rho


@f]

其中 $\epsilon_0$ 是真空的介电常数，而 $\rho$ 是电荷密度。这是由我们将选择的边界条件所增强的，如下所示。

@f{align*}{
  V &= -V_0 && \text{on}\; \Gamma_\text{cathode}\subset\partial\Omega \\
  V &= +V_0 && \text{on}\; \Gamma_\text{anode}\subset\partial\Omega \\
  \epsilon\frac{\partial V}{\partial n} &= 0
   && \text{on}\; \partial\Omega\setminus\Gamma_\text{cathode}\setminus\Gamma_\text{anode}.


@f}

换句话说，我们在两个电极上规定电压 $+V_0$ 和 $-V_0$ ，在其他地方规定绝缘（诺伊曼）边界条件。由于粒子的动力学纯粹是由于电场 $\mathbf E=\nabla V$ ，我们也可以在两个电极上规定 $2V_0$ 和 $0$ --所有重要的是两个电极的电压差。

考虑到这个电势 $V$ 和电场 $\mathbf E=\nabla V$ ，我们可以用微分方程来描述 $i$ 这个粒子的轨迹

@f[
  m {\ddot {\mathbf x}}_i = e\mathbf E,


@f]

其中 $m,e$ 是每个粒子的质量和电荷。在实践中，将其写成位置 $\mathbf x$ 和速度 $\mathbf v$ 的一阶微分方程系统很方便。

@f{align*}{
  {\dot {\mathbf v}}_i &= \frac{e\mathbf E}{m}, \\
  {\dot {\mathbf x}}_i &= {\mathbf v}_i.


@f}

我们将用来处理粒子的deal.II类， Particles::ParticleHandler, 以一种方式存储粒子，因此位置 $\mathbf x_i$ 是 Particles::ParticleHandler 数据结构的一部分。它存储的粒子是按它们所在的单元分类的，因此需要知道每个粒子的位置）。另一方面，速度 $\mathbf v_i$ 与 Particles::ParticleHandler 无关，因此我们将把它存储为每个粒子的 "属性"，并在每个时间步长中更新。属性也可以用来存储我们可能关心的关于每个粒子的任何其他数量：它的电荷，或者如果它们大于一个电子，它的颜色、质量、在空间的位置、化学成分等等。

要完成这个模型，还有两件事要讨论。粒子从哪里开始以及电荷密度 $\rho$ 是什么。

首先，在历史上，阴极射线使用非常大的电场将电子从金属中拉出来。这只产生一个相对较小的电流。我们可以通过加热阴极来做得更好：在这种情况下，统计学上的一部分电子有足够的热能来离开金属；然后电场只要足够强，就可以把它们从宿主的吸引中拉出来。我们将以下列方式对此进行建模。如果（i）电场指向远离电极，即如果 $\mathbf E \cdot \mathbf n < 0$ ，其中 $\mathbf n$ 是指向域外（进入电极）的面的法向量，以及（ii）电场超过一个阈值 $|\mathbf E|\ge E_\text{threshold}$ ，我们将创建一个新粒子。这肯定不是真正发生的足够精确的模型，但对于我们目前的教程程序来说已经足够好了。

第二，原则上我们必须通过以下方式建立电荷密度模型

@f[
  \rho(\mathbf x) = \sum_i e\delta(\mathbf x-\mathbf x_i).


@f]



 @note 现在的问题是，在现实中，一台老式电视中的阴极射线管产生的电流大约为几毫安培。在粒子加速器的更高能量的光束中，电流可能只有几纳安培。但一个安培是每秒流动的 $6\times 10^{18}$ 个电子。现在，正如你将在结果部分看到的，我们实际上只模拟了几微秒（ $10^{-5}$ 秒），但这仍然导致非常非常多的电子 -- 远远超过我们希望用像目前这样小的程序来模拟。因此，让我们假设每个粒子代表 $N$ 个电子。那么粒子的质量和电荷也是 $Nm$ 和 $Ne$ ，我们要解决的方程式是

@f[
  (Nm) {\ddot {\mathbf x}}_i = (Ne)\mathbf E,


@f]

当然，这与上述情况完全相同。另一方面，这些电子 "团块 "的电荷密度由以下公式给出

@f[
  \rho(\mathbf x) = \sum_i (Ne)\delta(\mathbf x-\mathbf x_i).


@f]

我们将在程序中实现这种形式，其中 $N$ 在程序中被选得相当大，以确保粒子实际影响电场。这在实践中可能并不现实。在大多数情况下，没有足够的电子来实际影响整个电场。但现实主义不是我们的目标）。)




 @note  人们可能会问，为什么电场（或者说，电势）的方程没有时间导数，而电子位置的方程却有。从本质上讲，这是一个建模假设。我们假设粒子移动得很慢，以至于在任何时候电场都处于平衡状态。这就是说，换句话说，电子的速度远远小于光速。换句话说，我们可以用电极电压来重新表述  $V_0$  ：由于每伏特的电动势都会使电子加速约600公里/秒（忽略相对论效应），要求  $|\mathbf v_i\|\ll c$  等于说  $2V_0 \ll 500 \text{V}$  。在这个假设下（以及电子总数很小的假设），我们也可以忽略移动电荷产生的磁场，否则也会影响电子的运动。




<h3>Time discretization</h3>

上面概述的方程形成了一组耦合微分方程。让我们再次把它们集中在一起，以明确这一点。

@f{align*}{


  -\epsilon_0 \Delta V &= \sum_i e\delta(\mathbf x-\mathbf x_i)
  \\
  {\dot {\mathbf x}}_i &= {\mathbf v}_i,
  \\
  {\dot {\mathbf v}}_i &= \frac{e\mathbf E}{m} = \frac{e\mathbf \nabla V}{m}.


@f}

由于电势对粒子位置的依赖性很强，我们不想将其作为一个耦合系统来求解，而是采用一种解耦的方法，首先求解每个时间步长的电势，然后再求解粒子的位置。这与我们在第21步、第31步和第32步（仅举几例）所做的工作的精神是一样的，都可以在第58步讨论的算子分割方法的背景下加以理解。

因此，如果我们用大指数 $n$ 表示时间步长，并且如果我们对ODE使用简单的时间离散化，那么这意味着我们必须在每个时间步长中解决以下方程组。

@f{align*}{


  -\epsilon_0 \Delta V^{(n)} &= \sum_i e\delta(\mathbf x-\mathbf x_i^{(n-1)})
  \\
  \frac{{\mathbf v}_i^{(n)}-{\mathbf v}_i^{(n-1)}}{\Delta t} &= \frac{e\nabla V^{(n)}}{m}
  \\
  \frac{{\mathbf x}_i^{(n)}-{\mathbf x}_i^{(n-1)}}{\Delta t} &= {\mathbf v}_i^{(n)}.


@f}

当然还有许多更好的方法来做时间离散化（例如简单的[跃迁方案](https://en.wikipedia.org/wiki/Leapfrog_integration)），但这不是本教程程序的重点，因此我们将满足于这里的内容。不过，我们将在本程序的<a href="#extensions">possibilities for extensions</a>部分对这个难题的一个部分进行评论）。

还有一个问题是我们应该如何选择时间步长  $\Delta t$  。这里的限制是， Particles::ParticleHandler 类需要跟踪每个粒子在哪个单元中。如果我们平行运行计算（比如，在step-70中），这尤其是一个问题，因为在这种情况下，每个进程只存储它拥有的那些单元，再加上一层 "幽灵单元"。这在这里并不重要，但一般来说，我们应该确保在每个时间步长中，一个粒子只从一个单元移动到它的任何一个近邻（面、边或顶点的邻居）。如果我们能确保这一点，那么 Particles::ParticleHandler 就能保证能够找出粒子最后在哪个单元。为了做到这一点，一个有用的经验法则是，我们应该选择时间步长，使所有粒子的预期移动距离小于一个细胞的直径。

@f[
  \Delta t \le \frac{h_i}{\|\mathbf v_i\|} \qquad\qquad \forall i,


@f]

或等价的

@f[
  \Delta t \le \min_i \frac{h_i}{\|\mathbf v_i\|}.


@f]

这里， $h_i$ 是粒子 $i$ 所在的单元格最短边的长度--本质上是对单元格大小的衡量。

另一方面，一个粒子可能已经在一个单元的边界上，而邻近的单元可能已经进一步细化。因此，那么穿过那个*邻近*单元的时间实际上将是上述数量的一半，这表明

@f[
  \Delta t \le \min_i \frac{\tfrac 12 h_i}{\|\mathbf v_i\|}.


@f]



但即使这样也是不够的。上面的公式在每次更新粒子位置时使用的是

@f[
\frac{{\mathbf x}_i^{(n)}-{\mathbf x}_i^{(n-1)}}{\Delta t} = {\mathbf v}_i^{(n)},


@f]

也就是说，使用当前的*速度 ${\mathbf v}_i^{n}$ 。但是当我们需要选择 $\Delta t$ 时，我们还没有当前的速度 -- 也就是在我们更新了潜能 $V^{(n)}$ 之后，但在我们将速度从 ${\mathbf v}_i^{(n-1)}$ 更新到 ${\mathbf v}_i^{(n)}$ 之前。我们有的只是  ${\mathbf v}_i^{(n-1)}$  。所以我们需要一个额外的安全系数来实现我们的最终选择。

@f[
  \Delta t^{(n)} =
  c_\text{safety} \min_i \frac{\tfrac 12 h_i}{\|\mathbf v_i^{(n-1)}\|}.


@f]

 $c_\text{safety}$ 应该有多大？这取决于与 $\|\mathbf v_i^{(n)}\|$ 相比， $\|\mathbf v_i^{(n-1)}\|$ 可能被低估了多少，而这实际上是很容易评估的。如果沿途遇到的电场大致恒定，那么在一个时间步长中产生的速度为零的粒子，在每个连续的时间步长中大致会获得相等的速度增量。因此， $\|\mathbf v_i^{(n-1)}\|$ 和 $\|\mathbf v_i^{(n)}\|$ 之间的最大差异将是一个系数。因此，我们将选择 $c_\text{safety}=0.5$  。

我们应该考虑的只有另外一种情况。在第一个时间步骤中会发生什么？在那里，任何要被移动的粒子刚刚被创造出来，但它们的速度是零。所以我们不知道我们应该为它们选择什么速度。当然，在所有其他时间步骤中，也有刚刚被创造出来的粒子，但一般来说，具有最高速度的粒子限制了时间步骤的大小，因此新创造出来的具有零速度的粒子并不重要。但是如果我们**只有这样的粒子？

在这种情况下，我们可以使用以下近似值。如果一个粒子从 $\mathbf v^{(0)}=0$ 开始，那么更新公式告诉我们

@f[
  {\mathbf v}_i^{(1)} = \frac{e\nabla V^{(1)}}{m} \Delta t,


@f]

因此

@f[
    \frac{{\mathbf x}_i^{(1)}-{\mathbf x}_i^{(0)}}{\Delta t} = {\mathbf v}_i^{(1)},


@f]

我们可以把它写成

@f[
    {\mathbf x}_i^{(1)} - {\mathbf x}_i^{(0)} = \frac{e\nabla V^{(1)}}{m} \Delta t^2.


@f]

不想让一个粒子移动超过 $\frac 12 h_i$ ，那么就意味着我们应该选择时间步长为

@f[
  \Delta t
  \le
  \min_i
  \sqrt{ \frac{h_i m}{e \|\nabla V^{(1)}\| }}.


@f]

使用关于相邻单元可能小2倍的相同论点，然后得出时间步长为0的最终公式。

@f[
  \Delta t
  =
  \min_i
  \sqrt{ \frac{\frac 12 h_i m}{e \|\nabla V^{(1)}\| } }.


@f]



严格来说，我们必须在每个粒子的位置评估电势 $V^{(1)}$ ，但一个足够好的近似值是使用各自单元顶点的最大值。为什么是顶点而不是中点？因为拉普拉斯方程的解的梯度，即电场，在位于单元顶点的角落奇点上是最大的）。)这样做的好处是，我们可以很好地利用FEValues功能，只要各单元的正交点相同，就可以循环使用预计算的材料。

我们总是可以运行这种方案来估计 $\mathbf v_i^{(n-1)}$ 和 $\mathbf v_i^{(n)}$ 之间的差异，但它依赖于评估每个单元的电场 $\mathbf E$ ，这很昂贵。因此，我们将把这种方法限制在第一个时间步骤上。




<h3>Spatial discretization</h3>

在讨论了时间离散化之后，对空间离散化的讨论将很简短：我们使用二次有限元，即空间 $Q_2$  ，来近似计算电动势 $V$  。在初始时间步骤中，网格被调整了几次。如果你读过第6步，所有这些都是完全标准的，而且实现起来也没有规定任何形式的惊喜。




<h3>Dealing with particles programmatically</h3>

实际上，在deal.II中，添加和移动粒子并不十分困难。要添加一个粒子，本程序的`create_particles()`函数只需使用以下形式的代码片段。

@code
  Particles::Particle<dim> new_particle;
  new_particle.set_location(location);
  new_particle.set_reference_location
      (mapping.transform_real_to_unit_cell(cell, location));
  new_particle.set_id(n_current_particles);


  particle_handler.insert_particle(new_particle, cell);
@endcode

换句话说，它与在 `std::set` 或 `std::map`: 中插入一个对象没有什么不同。 创建对象，设置其属性（这里是当前位置、其参考单元位置和其id）并调用`insert_particle`。唯一可能令人惊讶的是参考位置。为了评估诸如  $\nabla V(\mathbf x_i)$  的东西，有必要在位置  $\mathbf x_i$  评估有限元场。但这需要在参考单元 $\hat{\mathbf x}_i$ 上的点评估有限元形状函数。为了使之有效，每个粒子不仅要存储它的位置和它所在的单元，还要存储该点在单元参考坐标系中对应的位置。

这样，更新粒子的位置就不再困难了。我们只需要调用

@code
  particle->set_location(new_location);
@endcode

我们在`move_particles()`函数中这样做。唯一的区别是，我们必须告诉 Particles::ParticleHandler 类也要找到该位置所对应的单元（而且，在并行计算时，哪个进程拥有该单元）。出于效率的考虑，这在更新所有粒子的位置后最容易完成，并通过 Particles::ParticleHandler::sort_particles_into_subdomains_and_cells() 函数实现。

当然，有些时候，粒子可能会离开有关的域。在这种情况下， Particles::ParticleHandler::sort_particles_into_subdomains_and_cells() 不能找到周围的单元，而只是简单地删除该粒子。但是，跟踪以这种方式丢失的粒子的数量往往是有用的，为此， Particles::ParticleHandler 类提供了一个可以附加的 "信号"。我们在主类的构造函数中展示了如何做到这一点，以计算每个时间步骤中损失了多少粒子。具体来说，这种工作方式是， Particles::ParticleHandler 类有一个 "信号"，人们可以附加一个函数，只要信号被触发就会执行。在这里，这看起来如下。

@code
    particle_handler.signals.particle_lost.connect(
      [this](const typename Particles::ParticleIterator<dim> &        particle,
             const typename Triangulation<dim>::active_cell_iterator &cell)
      {
        this->track_lost_particle(particle, cell);
      });
@endcode

这有点拗口，但实际情况是这样的。我们声明了一个 "捕获"`this`指针的lambda函数（这样我们就可以在lambda函数中访问周围对象的成员函数），它需要两个参数。

- 指的是已经 "丢失 "的粒子。

- 它最后所在的单元格的引用。这个lambda函数然后简单地用这些参数调用 `CathodeRaySimulator::track_lost_particle` 函数。当我们把这个lambda函数附加到信号上时， Particles::ParticleHandler::sort_particles_into_subdomains_and_cells() 函数将为每个找不到新家的粒子触发信号。这让我们有机会记录下粒子的位置，并记录下关于它的统计数据。




 @note  在这个教程程序中，我们通过手工插入粒子，并在我们根据包括静电问题的解决的条件专门选择的位置插入粒子。但在其他情况下，人们主要希望将粒子作为被动对象使用，例如，追踪和可视化流体流动问题的流场。在这些情况下， Particles::Generators 命名空间中有许多函数可以自动生成粒子。例如，这个命名空间中的一个函数也被用于step-70教程程序中。




<h3>The test case</h3>

这里的测试案例并不意味着是对阴极射线管的真实描述，但它具有正确的一般特征，而且在任何情况下，重点只是演示如何实现使用粒子的deal.II代码。

下图显示了我们要使用的几何图形。

<p align="center"> <img src="https://www.dealii.org/images/steps/developer/step-19.geometry.png" alt="本程序中使用的几何图形" width="600">  </p> 

在这幅图中，边界上用红色和蓝色标记的部分是阴极，保持在一个电动势 $V=-V_0$ 。阴极的红色部分是被加热的部分，导致电子离开金属，然后被电场加速（也显示了一些电场线）。边界的绿色部分是阳极，保持在 $V=+V_0$ 。边界的其余部分满足诺伊曼边界条件。

这种设置模仿了真实的设备。重心角导致电势 $V$ ，其导数（电场 $\mathbf E$ ）有一个奇点--换句话说，它在角的附近变得非常大，允许它把电子从金属中扯出来。这些电子然后被加速推向（绿色）阳极，阳极中间有一个孔，电子可以通过这个孔逃离设备并飞到屏幕上，在那里它们激发 "荧光粉"，然后发出我们从这些老式电视屏幕上看到的光。阴极的非加热部分不受电子发射的影响--在代码中，我们将其标记为电子管的 "聚焦元件"，因为它的负电压会排斥电子，并确保它们不只是垂直于边界从阴极的加热部分飞走，而是事实上将它们的路径弯曲到右边的阳极。

图中的电场线也说明了电场分别连接着负极和正极。电子经历的加速力是沿着这些场线的。最后，图片显示了计算中使用的网格，说明在重租角的顶端以及边界条件改变的所有地方都有奇异点；这些奇异点是可见的，因为网格在这些地方被细化。

实际的利益是要弄清楚从阴极发射的电子中有哪一部分真正通过了阳极上的孔--那些只是反弹到阳极本身的电子除了将电转化为热之外，实际上并没有什么用处。因此，在`track_lost_particle()`函数中（为每个离开域的粒子调用，见上文），我们将估计它可能离开域的位置并在输出中报告。




 @note 值得重申的是，这里使用的几何图形，以及事实上这个程序的任何其他方面，都不是为了代表任何半点现实的东西。教程是我们教授deal.II如何工作的工具，我们经常使用我们有某种直觉的情况，因为这有助于我们解释程序的输出，但这就是我们打算让程序除了作为教学工具之外做任何有用的事情的程度。


examples/step-19/doc/results.dox



<h1>Results</h1>

当这个程序运行时，它产生的输出看起来如下。``时间步数1 场自由度：4989 仿真中的粒子总数：20 这个时间步数损失的粒子数：0

  现在在t=2.12647e-07，dt=2.12647e-07。

时间步数2 场自由度：4989 仿真中的粒子总数：24 本时间步数损失的粒子数：0

  现在在t=4.14362e-07，dt=2.01715e-07。

时间步数3 场自由度：4989 仿真中的粒子总数：28 本时间步数损失的粒子数：0

  现在在t=5.96019e-07，dt=1.81657e-07。

时间步数4 场自由度：4989 仿真中的粒子总数。  32 这个时间步长损失的粒子数：0

  现在在t=7.42634e-07，dt=1.46614e-07。


...


  时间步数1000场自由度：4989模拟中的粒子总数。  44 这个时间步长损失的粒子数：6 通过阳极损失的粒子的比例。0.0601266

  现在在t=4.93276e-05，dt=4.87463e-08。

时间步数1001场自由度：4989模拟中的粒子总数。  44 这个时间步长损失的粒子数：0 通过阳极损失的粒子的分数。0.0601266

  现在在t=4.93759e-05，dt=4.82873e-08。


...


时间步数2091场自由度：4989模拟中的粒子总数。  44 这个时间步长损失的粒子数：0 通过阳极损失的粒子的比例。0.0503338

  现在在t=9.99237e-05，dt=4.26254e-08。

时间步数2092场自由度：4989模拟中的粒子总数。  44 这个时间步长损失的粒子数：0 通过阳极损失的粒子的分数。0.0503338

  现在在t=9.99661e-05，dt=4.24442e-08。

时间步数2093场自由度：4989模拟中的粒子总数。  44 这个时间步长损失的粒子数：2 通过阳极损失的粒子的比例。0.050308

  现在在t=0.0001，dt=3.38577e-08。```

随机选取几个时间步长，我们可以用电场的流线和电子的点的形式来可视化解决方案。<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-19.solution.0000.png" alt="时间步骤0（t=0秒）的解决方案。" width="500">  <br>  时间步骤0（t=0秒）的解决方案。       <br>  </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-19.solution.1400.png" alt="时间步骤1400（t=0.000068秒）的解决方案。" width="500">  <br>  时间步骤1400（t=0.000068秒）的解决方案。       <br>  </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-19.solution.0700.png" alt="时间步骤700（t=0.000035秒）的解决方案。" width="500">  <br>  在时间步骤700（t=0.000035秒）的解决方案。       <br>  </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-19.solution.2092.png" alt="时间步骤2092（t=0.0001秒）的解决方案。" width="500">  <br>  时间步骤2092（t=0.0001秒）的解决方案。       <br>  </div> </div>

也就是说，更合适的方式是通过创建一个视频，展示这些电子是如何运动的，以及电场是如何随着它们的运动而变化的，从而将这个程序的结果可视化。

@htmlonly
<p align="center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/HwUtE7xuteE"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly



在这里你可以看到边界的 "焦点元素 "是如何用其负电压排斥电子，并确保它们不会垂直于阴极飞走（就像它们在其轨迹的初始部分那样）。它还显示了电场线如何随着时间的推移而移动，以回应飞过的电荷--换句话说，粒子对电场的反馈，而电场本身驱动着电子的运动。

这部电影表明，电子是以 "成串 "或 "爆裂 "的方式移动的。这种表象的一个因素是电影是如何创建的，是一个伪影。电影的每一帧都对应着一个时间步长，但时间步长是不同的。更具体地说，穿过最小单元的最快粒子决定了时间步长（见介绍中的讨论），因此，每当一个（快速）粒子穿过域的右边缘的小单元时，时间步长都很小；一旦粒子离开域，时间步长又会变长。通过绘制屏幕输出中显示的时间步长，可以很容易地看到这种减速-加速的效果。

然而，这其中的第二部分是真实的。模拟在开始时创造了一大群粒子，而在大约第300个时间步长后，粒子数量就减少了。这可能是因为模拟中的粒子带有负电荷。它们降低了（同样带负电的电极）的电场强度，因此减少了阴极上的点的数量，在这些点上，电场强度超过了将电子从电极中吸引出来所需的阈值。


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4> Avoiding a performance bottleneck with particles </h4>

`assemble_system()`、`move_particles()`和`update_timestep_size()`函数都调用 Particles::ParticleHandler::particles_in_cell() 和 Particles::ParticleHandler::n_particles_in_cell() ，查询位于当前单元上的粒子信息。虽然这很方便，但也很低效。为了理解为什么会这样，我们需要知道粒子是如何存储在 Particles::ParticleHandler: 中的，即在一个数据结构中，粒子是以某种线性方式按它们所在的单元进行排序的。因此，为了找到与给定单元相关的粒子，这些函数需要搜索给定单元上的第一个（也可能是最后一个）粒子--这种努力需要花费 ${\cal O}(\log N)$ 次操作，其中 $N$ 是粒子的数量。但这是在每个单元上重复的；假设对于大型计算来说，单元和粒子的数量大致成正比，那么这些函数调用的累积成本是 ${\cal O}(N \log N)$ ，因此大于我们应该对程序的所有部分进行的 ${\cal O}(N)$ 成本。

不过，我们可以使之更便宜。首先，我们可以先调用 Particles::ParticleHandler::n_particles_in_cell(), 而不是 Particles::ParticleHandler::particles_in_cell() ，然后通过计算当前单元上的最后一个粒子到第一个粒子的距离来计算单元上的粒子数。

@code
  const typename Particles::ParticleHandler<dim, spacedim>::particle_iterator_range
    particles_in_cell = particle_handler.particles_in_cell(cell);
  const unsigned int
    n_particles_in_cell = std::distance (particles_in_cell.begin(),
                                         particles_in_cell.end());
@endcode

其中第一个调用当然还是 ${\cal O}(\log N)$ ，但至少第二个调用只需要与当前单元上的粒子数成比例的计算时间，因此，当累积到所有单元时，其成本为 ${\cal O}(N)$ 。

但我们甚至可以通过一些适当的算法设计来摆脱这些调用中的第一个。这是因为粒子的排列方式与单元格相同，因此我们可以在单元格上移动时直接走动它们。下面的算法纲要就是这样做的。

@code
  auto begin_particle_on_cell = particle_handler.begin();
  for (const auto &cell : dof_handler.active_cell_iterators())
    {
      unsigned int n_particles_on_cell = 0;
      auto end_particle_on_cell = begin_particle_on_cell;
      while (end_particle_on_cell->get_surrounding_cell(triangulation)
             == cell)
        {
          ++n_particles_on_cell;
          ++end_particle_on_cell;
        }


      ...now operate on the range of particles from begin_particle_on_cell
         to end_particle_on_cell, all of which are known to be on the current
         cell...;


      // Move the begin iterator forward so that it points to the first
      // particle on the next cell
      begin_particle_on_cell = end_particle_on_cell;
    }
@endcode



在这段代码中，我们对每个单元都精确地接触了一次，而且我们从来不需要在大数据结构中搜索每个单元上的第一个或最后一个粒子。因此，该算法总共花费了 ${\cal O}(N)$ 来完成对所有粒子和所有单元的扫瞄。

对这个程序中存在这个问题的所有三个函数实施这个方案并不十分困难。




<h4> More statistics about electrons </h4>

该程序已经计算出了通过阳极上的孔离开该领域的电子的比例。但人们可能还对其他数量感兴趣。例如，这些粒子的平均速度。从每个粒子的属性中获得其速度并不是很困难，就像我们在`move_particles()`函数中所做的那样，并从中计算出统计数据。




<h4> A better-synchronized visualization </h4>

如上所述，视频的不同帧之间有不同的时间差，因为我们为每个时间步长创建输出。一个更好的创建电影的方法是在固定的时间间隔内生成一个新的输出文件，不管每个这样的点之间有多少时间步长。




<h4> A better time integrator </h4>

我们在这个程序中考虑的问题是一个耦合的、多物理学的问题。但是我们解决它的方法是首先计算（电）势场，然后更新粒子位置。这就是所谓的 "算子分割法"，我们将在第58步中更详细地研究这一概念。

虽然要想出一个不涉及将问题分割成PDE部分和粒子部分的方法是很尴尬的，但人们*可以*（而且可能应该！）想出一个更好的方法来更新粒子的位置。具体来说，我们用来更新粒子位置的方程是

@f{align*}{
  \frac{{\mathbf v}_i^{(n)}-{\mathbf v}_i^{(n-1)}}{\Delta t} &= \frac{e\nabla V^{(n)}}{m}
  \\
  \frac{{\mathbf x}_i^{(n)}-{\mathbf x}_i^{(n-1)}}{\Delta t} &= {\mathbf v}_i^{(n)}.


@f}

这相当于一个简单的正向欧拉时间离散化--一种在时间步长上具有一阶精度的方法 $\Delta t$ ，我们知道我们应该避免，因为我们可以做得更好。相反，我们可能想考虑一种方案，如[跃迁方案](https://en.wikipedia.org/wiki/Leapfrog_integration)或更普遍的[折衷积分器](https://en.wikipedia.org/wiki/Symplectic_integrator)，如[Verlet方案](https://en.wikipedia.org/wiki/Verlet_integration)。




<h4> Parallelization </h4>

在写这篇文章时，在作者的一台笔记本电脑上，在发布模式下，该程序的运行时间约为3.5分钟。这是可以接受的。但是，如果我们想让模拟变成三维的呢？如果我们想在任何时候都不使用最多约100个粒子（如这里使用的参数），而是使用100,000个？如果我们需要一个更细的网格？

在这些情况下，人们不只是想在单个处理器上运行程序，实际上是在尽可能多的处理器上运行。这就要求对PDE的解决方案以及粒子进行并行化。在实践中，虽然有大量的挑战要使其高效和良好地扩展，但这些挑战都在deal.II本身中得到了解决。例如，第40步显示了如何将有限元部分并行化，第70步显示了如何将粒子部分也并行化。


examples/step-2/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{9} 

在前面的例子中，我们已经创建了一个网格，现在我们展示如何在这个网格上定义自由度。在这个例子中，我们将使用最低阶（ $Q_1$ ）的有限元，自由度与网格的顶点相关联。以后的例子将展示更高阶的元素，自由度不一定与顶点相关，但可以与边、面或单元相关。

术语 "自由度 "在有限元界通常用来表示两个略有不同但相关的事情。首先是我们希望将有限元解表示为形状函数的线性组合，形式为 $u_h(\mathbf x) = \sum_{j=0}^{N-1} U_j \varphi_j(\mathbf
x)$  。这里， $U_j$ 是一个膨胀系数的向量。因为我们还不知道它们的值（我们将计算它们作为线性或非线性系统的解），它们被称为 "未知数 "或 "自由度"。该术语的第二个含义可以解释如下。对有限元问题的数学描述通常是说，我们正在寻找一个满足某些方程组的有限维函数 $u_h \in V_h$ （例如， $a(u_h,\varphi_h)=(f,\varphi_h)$ 为所有测试函数 $\varphi_h\in
V_h$ ）。换句话说，我们在这里说的是，解决方案需要位于某个空间  $V_h$  中。然而，为了在计算机上实际解决这个问题，我们需要选择这个空间的一个基；这就是我们在上面用系数 $U_j$ 对 $u_h(\mathbf x)$ 进行展开的形状函数 $\varphi_j(\mathbf x)$ 的集合。当然，空间 $V_h$ 的基数有很多，但我们将特别选择由传统上在网格单元上局部定义的有限元函数描述的基数。在这种情况下描述 "自由度 "需要我们简单地 <i>enumerate</i> 空间的基函数  $V_h$  。对于 $Q_1$ 元素，这意味着简单地以某种方式列举网格的顶点，但对于高阶元素，还必须列举与网格的边、面或单元内部相关的形状函数。换句话说，自由度的枚举是完全独立于我们用于顶点的索引的。提供这种列举 $V_h$ 的基础函数的类被称为DoFHandler。

在网格上定义自由度（简称 "DoF"）是一个相当简单的任务，因为这个库为你做了所有的工作。基本上，你所要做的就是创建一个有限元对象（从deal.II已有的众多有限元类中选取，例如参见 @ref fe 文档），并通过 DoFHandler::distribute_dofs 函数将其交给DoFHandler对象（"分配DoF "是我们用来描述上文讨论的<i>enumerating</i>基函数过程的术语）。DoFHandler是一个知道哪些自由度住在哪里的类，也就是说，它可以回答 "全局有多少自由度 "和 "在这个单元上，给我住在这里的形状函数的全局索引 "这样的问题。当你决定你的系统矩阵应该有多大时，以及当把单个单元的贡献复制到全局矩阵时，你需要这种信息。

<h3> Sparsity </h3>

然后，下一步将是利用这个有限元和网格计算与特定微分方程对应的矩阵和右手。我们将为第三步程序保留这一步骤，而是谈论有限元程序的一个实际问题，即有限元矩阵总是非常稀疏的：这些矩阵中的几乎所有条目都是零。

更准确地说，如果一个矩阵中的非零项<i>per row</i>的数量与整个自由度的数量无关，我们就说该矩阵是稀疏的。例如，拉普拉斯方程的有限差分近似的简单5点模版导致了一个稀疏矩阵，因为每行的非零条目数是5，因此与矩阵的总大小无关。对于更复杂的问题--比如说步骤22的斯托克斯问题--特别是在三维中，每行的条目数可能是几百个。但重要的一点是，这个数字与问题的总体大小无关：如果你细化网格，每行未知数的最大数量保持不变。

与使用泰勒扩展和匹配系数来逼近偏微分方程的解，或使用傅里叶基相比，稀疏性是有限元方法的一个突出特点。

在实践中，正是由于矩阵的稀疏性，使我们能够解决有数百万或数十亿未知数的问题。为了理解这一点，请注意，一个有 $N$ 行的矩阵，每个非零项的数量都有固定的上限，需要 ${\cal O}(N)$ 个内存位置来存储，而矩阵-向量乘法也只需要 ${\cal O}(N)$ 次操作。因此，如果我们有一个线性求解器，只需要固定数量的矩阵向量乘法就能得出这个矩阵的线性系统的解，那么我们就会有一个能以最佳复杂度找到所有 $N$ 未知数的值的求解器，也就是说，总共只需要 ${\cal O}(N)$ 次操作。很明显，如果矩阵不是稀疏的，这是不可能的（因为那样的话，矩阵中的条目数必须是 ${\cal O}(N^s)$ 与一些 $s>1$ ，做固定数量的矩阵-向量乘积将需要 ${\cal O}(N^s)$ 次操作），但这也需要非常专业的求解器，如多网格方法，以满足求解只需要固定数量的矩阵-向量乘法的要求。我们将在本教程的剩余程序中经常研究使用什么求解器的问题。

稀疏性是由以下事实产生的：有限元形状函数是在单个单元上定义的<i>locally</i>，而不是全局的，并且双线性形式中的局部微分算子只对支持度重叠的形状函数进行耦合。一个函数的 "支持 "是指它的非零区域。对于有限元方法，形状函数的支持通常是指与它所定义的顶点、边或面相邻的单元。)换句话说，自由度 $i$ 和 $j$ 如果不是定义在同一个单元上，就不会重叠，因此，矩阵条目 $A_{ij}$ 将为零。  (在某些情况下，如非连续加尔金法，形状函数也可以通过面积分连接到相邻的单元。但是有限元方法一般不会将形状函数与定义了该函数的单元的近邻相联系）。)




<h3> How degrees of freedom are enumerated </h3>

默认情况下，DoFHandler类以一种相当随机的方式枚举网格上的自由度；因此，稀疏度模式也没有为任何特定的目的进行优化。为了说明这一点，下面的代码将演示一个简单的方法来输出对应于DoFHandler的 "稀疏模式"，即一个对象代表了在网格上离散偏微分方程时可能建立的矩阵的所有潜在非零元素及其DoFHandler。这种缺乏结构的疏散模式将从我们下面展示的图片中显现出来。

对于大多数应用和算法来说，自由度的确切编号方式并不重要。例如，我们用来解决线性系统的共轭梯度方法并不关心。另一方面，有些算法确实关心：特别是一些预处理程序，如SSOR，如果它们能以特定的顺序走过自由度，就能更好地工作，如果我们能以这样的方式排序，使SSOR能以这样的顺序从零到 $N$ 迭代它们，那就太好了。其他的例子包括计算不完整的LU或Cholesky分解，或者如果我们关心矩阵的块状结构（见步骤20的例子）。因此，deal.II在命名空间DoFRenumbering中有一些算法可以以特定的方式重新列举自由度。重新编号可以被认为是选择了一个不同的、经排列的有限元空间的基础。因此，这种重新编号所产生的稀疏模式和矩阵与我们没有明确的重新编号所得到的相比，也只是行和列的排列组合。

在下面的程序中，我们将使用Cuthill和McKee的算法来完成。我们将在<a href="#Results">results section</a>中展示原始自由度列举和下面重新编号的版本的稀疏模式。


examples/step-2/doc/results.dox



<h1>Results</h1>

该程序运行后，产生了两个稀疏模式。我们可以通过在网络浏览器中打开 <code>.svg</code> 文件来可视化它们。

结果是这样的（每一个点都表示一个可能为非零的条目；当然，这个条目是否真的为零取决于所考虑的方程，但矩阵中的指示位置告诉我们，在离散化局部，即微分方程时，哪些形状函数可以，哪些不可以耦合）。   <table style="width:60%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-2.sparsity-1.svg" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-2.sparsity-2.svg" alt=""></td>
  </tr>
</table> 

左图中的不同区域，由线条中的扭结和左边和上面的单点表示，代表了三角法不同细化层次上的自由度。  从右图中可以看出，重新编号后，稀疏模式在矩阵的主对角线附近的聚类情况要好得多。虽然这可能不明显，但两张图片中非零项的数量当然是一样的。




<h3> Possibilities for extensions </h3>

就像第1步一样，你可能想在程序中玩一下，熟悉一下deal.II。例如，在 <code>distribute_dofs</code> 函数中，我们使用线性有限元（FE_Q对象的参数 "1 "就是如此）。探索一下如果你使用高阶元素，例如立方或五元元素（使用3和5作为各自的参数），稀疏模式会有什么变化。

你也可以通过细化网格来探索稀疏性模式的变化。你会发现，不仅矩阵的大小会发生变化，其带宽（矩阵中离对角线最远的那些非零元素与对角线的距离）也会发生变化，不过带宽与大小的比例通常会缩小，也就是说，矩阵在对角线周围聚集得更多。

实验的另一个想法是尝试DoFRenumbering命名空间中除Cuthill-McKee之外的其他重新编号策略，看看它们如何影响稀疏性模式。

你也可以使用<a
href="http://www.gnuplot.info/">GNUPLOT</a>（较简单的可视化程序之一；也许不是最容易使用的，因为它是命令行驱动的，但在所有Linux和其他类似Unix的系统上也是普遍可用的）通过改变 <code>print_svg()</code> to <code>print_gnuplot()</code> in <code>distribute_dofs()</code> and <code>renumber_dofs()</code> 来使输出可视化。

@code
examples/\step-2> gnuplot


        G N U P L O T
        Version 3.7 patchlevel 3
        last modified Thu Dec 12 13:00:00 GMT 2002
        System: Linux 2.6.11.4-21.10-default


        Copyright(C) 1986 - 1993, 1998 - 2002
        Thomas Williams, Colin Kelley and many others


        Type `help` to access the on-line reference manual
        The gnuplot FAQ is available from
        http://www.gnuplot.info/gnuplot-faq.html


        Send comments and requests for help to <info-gnuplot@dartmouth.edu>
        Send bugs, suggestions and mods to <bug-gnuplot@dartmouth.edu>



Terminal type set to 'x11'
gnuplot> set style data points
gnuplot> plot "sparsity_pattern.1"
@endcode



另一个基于<a href="http://www.gnuplot.info/">GNUPLOT</a>的做法是尝试打印出带有支撑点位置和编号的网格。为此，你需要包含GridOut和MappingQ1的头文件。这方面的代码是。

@code
  std::ofstream out("gnuplot.gpl");
  out << "plot '-' using 1:2 with lines, "
      << "'-' with labels point pt 2 offset 1,1"
      << std::endl;
  GridOut().write_gnuplot (triangulation, out);
  out << "e" << std::endl;
  const int dim = 2;
  std::map<types::global_dof_index, Point<dim> > support_points;
  DoFTools::map_dofs_to_support_points (MappingQ1<dim>(),
                                        dof_handler,
                                        support_points);
  DoFTools::write_gnuplot_dof_support_point_info(out,
                                                 support_points);
  out << "e" << std::endl;
@endcode

在我们运行该代码后，我们得到了一个名为gnuplot.gpl的文件。要查看这个文件，我们可以在命令行中运行以下代码。

@code
gnuplot -p gnuplot.gpl
@endcode.有了这个，你会得到一个类似于 @image html support_point_dofs1.png 的图片，这取决于你正在看的网格。更多信息，见 DoFTools::write_gnuplot_dof_support_point_info. 。


examples/step-20/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{19,20,21} 

这个程序致力于两个方面：使用混合有限元--特别是Raviart-Thomas元--以及使用块状矩阵来定义求解器、预处理器和使用系统矩阵的子结构的嵌套版本。我们要解决的方程仍然是泊松方程，虽然有一个矩阵值的系数。

@f{eqnarray*}


  -\nabla \cdot K({\mathbf x}) \nabla p &=& f \qquad {\textrm{in}\ } \Omega, \\
  p &=& g \qquad {\textrm{on}\ }\partial\Omega.


@f}

 $K({\mathbf x})$ 被假定为均匀正定，即有 $\alpha>0$ ，使得 $K(x)$ 的特征值 $\lambda_i({\mathbf x})$ 满足 $\lambda_i({\mathbf x})\ge \alpha$  。使用符号 $p$ 而不是通常的 $u$ 作为解变量将在下一节中变得清晰。

在讨论了方程和我们要用来解决它的公式之后，这个介绍将包括块状矩阵和向量的使用，求解器和预处理器的定义，以及最后我们要解决的实际测试案例。

我们将在第21步中扩展这个教程程序，不仅要解决混合拉普拉斯方程，还要增加另一个描述两种流体混合物运输的方程。

这里所涉及的方程属于矢量值问题的范畴。这个主题的顶层概述可以在 @ref vector_valued 模块中找到。




<h3>The equations</h3>

在上述形式中，泊松方程（即具有非零右手边的拉普拉斯方程）通常被认为是流体在多孔介质中流动的良好模型方程。当然，人们通常通过<a href="https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equations">Navier-Stokes
equations</a>来模拟流体流动，或者，如果流体速度很慢或粘度很大，则通过<a href="https://en.wikipedia.org/wiki/Stokes_flow">Stokes
equations</a>（我们在步骤22中涉及）。在这两个模型中，第一个模型的作用力是惯性和粘性摩擦力，而在第二个模型中，只有粘性摩擦力--即一个流体粒子对附近的粒子施加的力。如果你在一个大的领域里有自由流动，例如管道、河流或空气中，这是很合适的。另一方面，如果流体被限制在孔隙中，那么孔壁对流体施加的摩擦力变得越来越重要，而内部粘性摩擦力变得越来越不重要。如果这两种效应都很重要，那么建立模型首先会导致<a href="https://en.wikipedia.org/wiki/Darcy%27s_law#Brinkman_form_of_Darcy's_law">Brinkman
model</a>，而在非常小的孔隙的限制下会导致<a href="https://en.wikipedia.org/wiki/Darcy%27s_law">Darcy equations</a>。后者只是泊松方程或拉普拉斯方程的不同名称，其内涵是人们想应用它的领域：多孔介质中的缓慢流动。本质上，它说速度与驱动流体通过多孔介质的负压梯度成正比。

达西方程对驱动流动的这种压力进行建模。由于解变量是压力，我们在这里使用 $p$ 这个名字，而不是更常用于偏微分方程解的 $u$ 这个名字）。这种拉普拉斯方程观点的典型应用是为地下水流建模，或者为油藏中的碳氢化合物流动建模。在这些应用中， $K$ 是渗透性张量，即衡量土壤或岩石基质对流体流动的阻力大小。

在上述应用中，数值方案的一个理想特征是它应该是局部保守的，也就是说，无论什么东西流入一个单元，也会从该单元流出（或者如果源不为零，则差值等于每个单元的源项的积分）。然而，事实证明，拉普拉斯方程的通常离散化（如步骤3、步骤4或步骤6中使用的那些）并不满足这一特性。但是，人们可以通过选择问题的不同表述和有限元空间的特定组合来实现这一点。




<h3>Formulation, weak form, and discrete problem</h3>

为此，我们首先引入了第二个变量，称为速度，  ${\mathbf u}=-K\nabla p$  。根据其定义，速度是压力梯度的负方向的一个矢量，乘以渗透性张量。如果渗透率张量与单位矩阵成正比，这个方程就很容易理解和直观：渗透率越高，速度越高；速度与压力梯度成正比，从高压区到低压区（因此是负号）。

有了这第二个变量，就可以找到拉普拉斯方程的另一个版本，称为<i>mixed formulation</i>。

@f{eqnarray*}
  K^{-1} {\mathbf u} + \nabla p &=& 0 \qquad {\textrm{in}\ } \Omega, \\


  -{\textrm{div}}\ {\mathbf u} &=& -f \qquad {\textrm{in}\ }\Omega, \\
  p &=& g \qquad {\textrm{on}\ } \partial\Omega.


@f}

这里，我们将定义速度的方程 ${\mathbf
u}$ 乘以 $K^{-1}$ ，因为这使得方程组是对称的：其中一个方程有梯度，第二个方程有负发散，这两个当然是彼此相邻的，结果是一个对称的双线性形式，因此在 $K$ 是对称张量的共同假设下，是一个对称的系统矩阵。

这个问题的弱表述是通过将两个方程与测试函数相乘，并对一些项进行分项积分来找到的。

@f{eqnarray*}
  A(\{{\mathbf u},p\},\{{\mathbf v},q\}) = F(\{{\mathbf v},q\}),


@f}

其中

@f{eqnarray*}
  A(\{{\mathbf u},p\},\{{\mathbf v},q\})
  &=&
  ({\mathbf v}, K^{-1}{\mathbf u})_\Omega - ({\textrm{div}}\ {\mathbf v}, p)_\Omega


  - (q,{\textrm{div}}\ {\mathbf u})_\Omega
  \\
  F(\{{\mathbf v},q\}) &=& -(g,{\mathbf v}\cdot {\mathbf n})_{\partial\Omega} - (f,q)_\Omega.


@f}

这里， ${\mathbf n}$ 是边界处的外向法向量。请注意，在这个公式中，原问题的迪里希特边界值被纳入到弱形式中。

为了得到良好的解决，我们必须在空间 $H({\textrm{div}})=\{{\mathbf w}\in L^2(\Omega)^d:\ {\textrm{div}}\ {\mathbf w}\in L^2\}$ 中寻找 $\mathbf u$ 、 $\mathbf v$ 和 $L^2$ 的解和检验函数。几乎每一本关于有限元理论的书都说过一个众所周知的事实，如果选择离散的有限元空间来逼近 ${\mathbf u},p$ 是不恰当的，那么产生的离散问题是不稳定的，离散的解将不会收敛到精确的解。这里考虑的问题的一些细节--属于 "鞍点问题 "的范畴

--可以在维基百科上找到<a
href="https://en.wikipedia.org/wiki/Ladyzhenskaya%E2%80%93Babu%C5%A1ka%E2%80%93Brezzi_condition">Ladyzhenskaya-Babuska-Brezzi
(LBB) condition</a>的页面）。)

为了克服这个问题，已经为 ${\mathbf u},p$ 开发了一些不同的有限元对，导致了稳定的离散问题。其中一个对子是对速度 ${\mathbf u}$ 使用Raviart-Thomas空间，对压力 $p$ 使用类 $DQ(k)$ 的不连续元素。关于这些空间的细节，我们特别参考Brezzi和Fortin的关于混合有限元方法的书，但许多其他关于有限元理论的书，例如Brenner和Scott的经典书，也说明了相关结果。在任何情况下，在适当选择函数空间的情况下，离散的表述如下。找到 ${\mathbf
u}_h,p_h$ ，以便

@f{eqnarray*}
  A(\{{\mathbf u}_h,p_h\},\{{\mathbf v}_h,q_h\}) = F(\{{\mathbf v}_h,q_h\})
  \qquad\qquad \forall {\mathbf v}_h,q_h.


@f}




在继续之前，让我们简单地停顿一下，说明上面的函数空间的选择为我们提供了所需的局部守恒特性。特别是，由于压力空间由不连续的片断多项式组成，我们可以选择测试函数 $q$ 作为在任何给定单元 $K$ 上等于1，其他地方为0的函数。如果我们也到处选择 ${\mathbf v}=0$ （记住，上面的弱式对<i>all</i>离散测试函数 $q,v$ 必须成立），那么把这些测试函数的选择放入上面的弱式中，特别意味着

@f{eqnarray*}


  - (1,{\textrm{div}}\ {\mathbf u}_h)_K
  =


  -(1,f)_K,


@f}

当然，我们可以将其以更明确的形式写为

@f{eqnarray*}
  \int_K {\textrm{div}}\ {\mathbf u}_h
 =
  \int_K f.


@f}

应用发散定理的结果是，对于每个单元 ${\mathbf
u}_h$ 的选择， $K$ 必须满足以下关系

@f{eqnarray*}
  \int_{\partial K} {\mathbf u}_h\cdot{\mathbf n}
  =
  \int_K f.


@f}

如果你现在记得 ${\mathbf u}$ 是速度，那么左边的积分正好是穿过单元格边界的（离散）通量 $K$  。那么声明是，通量必须等于对 $K$ 内的源的积分。特别是，如果没有源（即 $f=0$ 在 $K$ 中），那么声明是<i>total</i>通量为零，也就是说，任何流入一个单元的东西都必须通过单元边界的其他部分流出。这就是我们所说的<i>local conservation</i>，因为它对每个细胞都是成立的。

另一方面，通常的连续 $Q_k$ 元素在用于压力时不会产生这种性质（例如，我们在步骤-43中所做的），因为我们不能选择一个离散的测试函数 $q_h$ ，在单元 $K$ 上为1，其他地方为0：它将是不连续的，因此不在有限元空间内。严格来说，我们只能说上面的证明对连续元素不起作用。这些元素是否仍然可能导致局部守恒是一个不同的问题，因为人们可以认为不同的证明可能仍然有效；然而，在现实中，这个属性确实不成立）。)




<h3>Assembling the linear system</h3>

deal.II库（当然）实现了任意阶的Raviart-Thomas元素 $RT(k)$ ，以及不连续元素 $DG(k)$  。如果我们暂时忘记它们的特殊属性，那么我们就必须解决一个离散的问题

@f{eqnarray*}
  A(x_h,w_h) = F(w_h),


@f}

的双线性形式和右手边，以及 $x_h=\{{\mathbf u}_h,p_h\}$  ,  $w_h=\{{\mathbf v}_h,q_h\}$  。 $x_h$ 和 $w_h$ 都来自空间 $X_h=RT(k)\times DQ(k)$ ，其中 $RT(k)$ 本身就是一个 $dim$ 维函数的空间，以适应流速为矢量值的事实。那么必要的问题是：我们如何在程序中做到这一点？

矢量值元素已经在以前的教程程序中讨论过了，第一次是在步骤8中详细讨论。那里的主要区别是，矢量值空间 $V_h$ 的所有分量都是统一的：位移矢量的 $dim$ 分量都是相等的，来自同一个函数空间。因此，我们可以做的是将 $V_h$ 建立为 $dim$ 乘以通常的 $Q(1)$ 有限元空间的外积，并以此确保我们所有的形状函数只有一个非零矢量分量。因此，我们在步骤8中所做的不是处理矢量值的形状函数，而是查看（标量）唯一的非零分量，并使用 <code>fe.system_to_component_index(i).first</code> 调用来计算这实际上是哪个分量。

这对Raviart-Thomas元素不起作用：由于它们的构造满足空间 $H({\textrm{div}})$ 的某些规则性属性， $RT(k)$ 的形状函数通常在其所有矢量分量中都是不为零。由于这个原因，如果应用 <code>fe.system_to_component_index(i).first</code> 来确定形状函数 $i$ 的唯一非零分量，就会产生一个例外。我们真正需要做的是在 <em> 中获得一个形状函数的所有 </em> 向量分量。在deal.II的字典中，我们称这样的有限元为 <em> 非原始 </em> ，而那些标量的有限元或者每个矢量值的形状函数只在一个矢量分量中不为零的有限元被称为 <em>  原始 </em> 。

那么，对于非原始元素，我们要怎么做呢？为了弄清楚这个问题，让我们回到教程程序中，几乎是最开始的时候。在那里，我们了解到我们使用 <code>FEValues</code> 类来确定正交点的形状函数的值和梯度。例如，我们会调用  <code>fe_values.shape_value(i,q_point)</code>  来获得  <code>i</code>  第三个形状函数在编号为  <code>q_point</code>  的正交点的值。后来，在step-8和其他教程程序中，我们了解到这个函数调用也适用于矢量值的形状函数（原始有限元），它返回形状函数  <code>i</code>  在正交点  <code>q_point</code>  的唯一非零分量的值。

对于非原始形状函数，这显然是行不通的：形状函数 <code>i</code> 没有单一的非零向量分量，因此调用 <code>fe_values.shape_value(i,q_point)</code> 也就没有什么意义。然而，deal.II提供了第二个函数调用， <code>fe_values.shape_value_component(i,q_point,comp)</code> ，返回正交点 <code>comp</code>th vector component of shape function  <code>i</code> 的值 <code>q_point</code>, where <code>comp</code> 是一个介于零和当前有限元的矢量分量数量之间的索引；例如，我们将用于描述速度和压力的元素将有 $dim+1$ 分量。值得注意的是，这个函数调用也可用于原始形状函数：它将简单地对除一个分量外的所有分量返回零；对于非原始形状函数，它一般会对不止一个分量返回非零值。

我们现在可以尝试用矢量分量来重写上面的双线性形式。例如，在2d中，第一项可以这样改写（注意， $u_0=x_0, u_1=x_1, p=x_2$ ）。

@f{eqnarray*}
  ({\mathbf u}_h^i, K^{-1}{\mathbf u}_h^j)
  =
  &\left((x_h^i)_0, K^{-1}_{00} (x_h^j)_0\right) +
   \left((x_h^i)_0, K^{-1}_{01} (x_h^j)_1\right) + \\
  &\left((x_h^i)_1, K^{-1}_{10} (x_h^j)_0\right) +
   \left((x_h^i)_1, K^{-1}_{11} (x_h^j)_1\right).


@f}

如果我们实现了这一点，我们会得到这样的代码。

@code
  for (unsigned int q=0; q<n_q_points; ++q)
    for (unsigned int i=0; i<dofs_per_cell; ++i)
      for (unsigned int j=0; j<dofs_per_cell; ++j)
        local_matrix(i,j) += (k_inverse_values[q][0][0] *
                              fe_values.shape_value_component(i,q,0) *
                              fe_values.shape_value_component(j,q,0)
                              +
                              k_inverse_values[q][0][1] *
                              fe_values.shape_value_component(i,q,0) *
                              fe_values.shape_value_component(j,q,1)
                              +
                              k_inverse_values[q][1][0] *
                              fe_values.shape_value_component(i,q,1) *
                              fe_values.shape_value_component(j,q,0)
                              +
                              k_inverse_values[q][1][1] *
                              fe_values.shape_value_component(i,q,1) *
                              fe_values.shape_value_component(j,q,1)
                             ) *
                             fe_values.JxW(q);
@endcode



这充其量是繁琐的，容易出错的，而且不是独立的维度。有一些明显的方法可以使事情与维度无关，但最终，代码根本不漂亮。如果我们能够简单地提取形状函数 ${\mathbf u}$ 和 $p$ 的分量，那就更好了。在程序中，我们以如下方式进行。

@code
  const FEValuesExtractors::Vector velocities (0);
  const FEValuesExtractors::Scalar pressure (dim);


  ...


  for (unsigned int q=0; q<n_q_points; ++q)
    for (unsigned int i=0; i<dofs_per_cell; ++i)
      for (unsigned int j=0; j<dofs_per_cell; ++j)
        local_matrix(i,j) += (fe_values[velocities].value (i, q) *
                              k_inverse_values[q] *
                              fe_values[velocities].value (j, q)


                              -
                              fe_values[velocities].divergence (i, q) *
                              fe_values[pressure].value (j, q)


                              -
                              fe_values[pressure].value (i, q) *
                              fe_values[velocities].divergence (j, q)) *
                              fe_values.JxW(q);
@endcode



事实上，这不仅是双线性形式的第一项，而且是整个事情（不包括边界贡献）。

这段代码的作用是，给定一个 <code>fe_values</code> 对象，提取形状函数 <code>i</code> 在正交点 <code>q</code> 的第一个 $dim$ 分量的值，也就是该形状函数的速度部分。换句话说，如果我们把形状函数 $x_h^i$ 写成元组 $\{{\mathbf u}_h^i,p_h^i\}$ ，那么该函数返回这个元组的速度部分。请注意，速度当然是一个 <code>dim</code> 维的张量，函数返回一个相应的对象。同样地，在我们用压力提取器下标的地方，我们提取标量压力分量。整个机制在 @ref vector_valued 模块中有更详细的描述。

在实践中，如果我们在每个最外层的循环中只评估一次形状函数、它们的梯度和发散，并存储结果，我们可以做得更好一些，因为这样可以节省一些重复的计算（通过提前计算所有相关的量，然后只在实际的循环中插入结果，甚至可以节省更多的重复操作，关于这种方法的实现见步骤22）。最后的结果是这样的，在每个空间维度上都是如此。

@code
  for (const auto &cell : dof_handler.active_cell_iterators())
    {
      fe_values.reinit (cell);
      local_matrix = 0;
      local_rhs = 0;


      right_hand_side.value_list (fe_values.get_quadrature_points(),
                                  rhs_values);
      k_inverse.value_list (fe_values.get_quadrature_points(),
                            k_inverse_values);


      for (unsigned int q=0; q<n_q_points; ++q)
        for (unsigned int i=0; i<dofs_per_cell; ++i)
          {
            const Tensor<1,dim> phi_i_u     = fe_values[velocities].value (i, q);
            const double        div_phi_i_u = fe_values[velocities].divergence (i, q);
            const double        phi_i_p     = fe_values[pressure].value (i, q);


            for (unsigned int j=0; j<dofs_per_cell; ++j)
              {
                const Tensor<1,dim> phi_j_u     = fe_values[velocities].value (j, q);
                const double        div_phi_j_u = fe_values[velocities].divergence (j, q);
                const double        phi_j_p     = fe_values[pressure].value (j, q);


                local_matrix(i,j) += (phi_i_u * k_inverse_values[q] * phi_j_u


                                      - div_phi_i_u * phi_j_p


                                      - phi_i_p * div_phi_j_u) *
                                     fe_values.JxW(q);
              }


            local_rhs(i) += -phi_i_p *
                            rhs_values[q] *
                            fe_values.JxW(q);
          }
@endcode



这非常类似于我们最初写下的双线性形式和右手边的形式。

有一个最后的项我们必须注意：右手边包含项 $(g,{\mathbf v}\cdot {\mathbf n})_{\partial\Omega}$ ，构成压力边界条件的弱执行。我们已经在步骤7中看到了如何处理面积分：本质上与域积分完全相同，只是我们必须使用FEFaceValues类而不是 <code>FEValues</code> 。为了计算边界项，我们只需在所有的边界面上进行循环并在那里进行积分。该机制的工作方式与上述相同，即提取器类也对FEFaceValues对象工作。

@code
        for (const auto &face : cell->face_iterators())
          if (face->at_boundary())
            {
              fe_face_values.reinit(cell, face);


              pressure_boundary_values.value_list(
                fe_face_values.get_quadrature_points(), boundary_values);


              for (unsigned int q = 0; q < n_face_q_points; ++q)
                for (unsigned int i = 0; i < dofs_per_cell; ++i)
                  local_rhs(i) += -(fe_face_values[velocities].value(i, q) *
                                    fe_face_values.normal_vector(q) *
                                    boundary_values[q] *
                                    fe_face_values.JxW(q));
@endcode



在本程序的源代码中，你会发现与上面完全相同的代码。因此，我们在下文中不做过多评论。




<h3>Linear solvers and preconditioners</h3>

在组装好线性系统后，我们就面临着解决它的任务。这里的问题是，矩阵拥有两个不理想的特性。

- 它是<a href="https://en.wikipedia.org/wiki/Definiteness_of_a_matrix">indefinite</a>，也就是说，它有正负两个特征值。   我们不想在这里证明这个属性，但要注意，对于所有形式为 $\left(\begin{array}{cc} M & B \\ B^T & 0 \end{array}\right)$ 的矩阵，如这里的 $M$ 是正定的矩阵，这都是真的。

- 矩阵的右下方有一个零块（在双线性形式中没有将压力 $p$ 与压力测试函数 $q$ 耦合的项）。

至少它是对称的，但是上面的第一个问题仍然意味着共轭梯度法是行不通的，因为它只适用于矩阵是对称和正定的问题。我们将不得不求助于其他迭代求解器，如MinRes、SymmLQ或GMRES，它们可以处理不确定的系统。然而，下一个问题立即浮现。由于零块，对角线上有零，通常的 "简单 "预处理程序（Jacobi、SSOR）都不能工作，因为它们需要除以对角线上的元素。

对于我们期望用这个程序运行的矩阵大小来说，迄今为止最简单的方法是直接使用一个直接求解器（特别是与deal.II捆绑的SparseDirectUMFPACK类）。Step-29走的就是这条路线，它表明只需3、4行代码就可以完成<i>any</i>线性系统的求解。

但是，这是一个教程。我们教的是如何做事情。因此，在下文中，我们将介绍一些可用于类似这种情况的技术。也就是说，我们将考虑线性系统不是由一个大矩阵和向量组成的，而是要将矩阵分解为<i>blocks</i>，这些矩阵对应于系统中出现的各个运算符。我们注意到，所产生的求解器并不是最优的--有更好的方法来有效地计算该系统，例如在步骤22的结果部分所解释的方法，或者我们在步骤43中用于类似于当前问题的方法。在这里，我们的目标只是介绍新的求解技术以及如何在交易中实现它们。




<h4>Solving using the Schur complement</h4>

鉴于使用上述标准求解器和预处理器的困难，让我们再看一下矩阵。如果我们对自由度进行排序，使所有的速度变量排在所有的压力变量之前，那么我们可以将线性系统 $Ax=b$ 细分为以下几个块。

@f{eqnarray*}
  \left(\begin{array}{cc}
    M & B \\ B^T & 0
  \end{array}\right)
  \left(\begin{array}{cc}
    U \\ P
  \end{array}\right)
  =
  \left(\begin{array}{cc}
    F \\ G
  \end{array}\right),


@f}

其中 $U,P$ 分别是速度和压力自由度的值， $M$ 是速度空间上的质量矩阵， $B^T$ 对应于负发散算子， $B$ 是其转置，对应于梯度。

通过区块消除法，我们就可以按以下方式对这个系统重新排序（用系统的第一行乘以 $B^TM^{-1}$ ，然后用第二行减去）。

@f{eqnarray*}
  B^TM^{-1}B P &=& B^TM^{-1} F - G, \\
  MU &=& F - BP.


@f}

这里，矩阵 $S=B^TM^{-1}B$ （称为 $A$ 的<a href="https://en.wikipedia.org/wiki/Schur_complement">Schur complement</a>）显然是对称的，由于 $M$ 的正定性和 $B$ 具有全列秩， $S$ 也是正定的。

因此，如果我们能计算出 $S$ ，我们就可以对其应用共轭梯度法。然而，计算 $S$ 是昂贵的，因为它需要我们计算（可能很大的）矩阵 $M$ 的逆；而且 $S$ 实际上也是一个完整的矩阵，因为即使 $M$ 是稀疏的，它的逆 $M^{-1}$ 通常是一个密集的矩阵。另一方面，CG算法并不要求我们真正拥有 $S$ 的表示：只需与它形成矩阵-向量乘积即可。我们可以利用矩阵乘积是关联的这一事实，分步进行（也就是说，我们可以通过设置括号来使乘积的计算更加方便）。为了计算 $Sv=(B^TM^{-1}B)v=B^T(M^{-1}(Bv))$ ，我们<ol>  <li> 计算 $w = B v$ ； <li> 解 $My = w$ 为 $y=M^{-1}w$ ，使用CG方法应用于正定和对称质量矩阵 $M$ ； <li> 计算 $z=B^Ty$ ，得到 $z=Sv$  。   </ol>  注意我们如何从右到左评估表达式 $B^TM^{-1}Bv$ 以避免矩阵-矩阵乘积；这样，我们所要做的就是评估矩阵-向量乘积。

在下文中，我们将不得不想出表示矩阵 $S$ 的方法，以便它可以用于共轭梯度求解器，以及定义我们可以预设涉及 $S$ 的线性系统解决方案的方法，并处理与矩阵 $M$ 的线性系统求解（上述第二步骤）。

 @note  这个考虑的关键点是要认识到，为了实现CG或GMRES这样的迭代求解器，我们实际上从来不需要矩阵的实际<i>elements</i>!所需要的只是我们能够形成矩阵-向量乘积。对于预处理程序也是如此。在deal.II中，我们对这一要求进行了编码，只要求给予求解器类的矩阵和预处理器有一个 <code>vmult()</code> 成员函数来做矩阵-向量乘积。一个类如何选择实现这个函数对求解器来说并不重要。因此，类可以通过，例如，做一连串的乘积和线性求解来实现它，正如上面所讨论的。




<h4>The LinearOperator framework in deal.II</h4>

deal.II包括支持以一种非常普遍的方式来描述这种线性操作。这是由LinearOperator类完成的，与 @ref ConceptMatrixType "MatrixType概念 "一样，它定义了<i>applying</i>对矢量进行线性操作的最小接口。

@code
    std::function<void(Range &, const Domain &)> vmult;
    std::function<void(Range &, const Domain &)> vmult_add;
    std::function<void(Domain &, const Range &)> Tvmult;
    std::function<void(Domain &, const Range &)> Tvmult_add;
@endcode

然而，LinearOperator和普通矩阵的关键区别在于，LinearOperator不允许对底层对象进行任何进一步的访问。你能用LinearOperator做的就是把它的 "动作 "应用到一个向量上。我们借此机会介绍一下LinearOperator的概念，因为它是一个非常有用的工具，可以让你以非常直观的方式构造复杂的求解器和预处理器。

作为第一个例子，让我们构建一个代表  $M^{-1}$  的 LinearOperator 对象。这意味着每当这个运算符的 <code>vmult()</code> 函数被调用时，它必须解决一个线性系统。这就要求我们指定一个解算器（和相应的）前置条件。假设 <code>M</code> 是对系统矩阵左上块的引用，我们可以写出。

@code
    const auto op_M = linear_operator(M);


    PreconditionJacobi<SparseMatrix<double>> preconditioner_M;
    preconditioner_M.initialize(M);


    ReductionControl reduction_control_M(2000, 1.0e-18, 1.0e-10);
    SolverCG<Vector<double>>    solver_M(reduction_control_M);


    const auto op_M_inv = inverse_operator(op_M, solver_M, preconditioner_M);
@endcode

我们没有使用SolverControl，而是在这里使用ReductionControl类，当达到绝对公差（我们选择 $10^{-18}$ ）或者当残差减少了某个系数（这里是 $10^{-10}$ ）时，它就会停止迭代。相反，SolverControl类只检查绝对公差。在我们的案例中，我们必须使用ReductionControl来解决一个小问题。我们将送入 <code>op_M_inv</code> 的右手边基本上是由残差形成的，随着外部迭代的进行，残差的规范自然会大大减少。这使得绝对公差的控制非常容易出错。

我们现在有一个LinearOperator  <code>op_M_inv</code> ，我们可以用它来构造更复杂的运算符，如Schur补码  $S$  。假设 <code>B</code> 是对右上角区块的引用，构造一个LinearOperator  <code>op_S</code> 只需两行即可。

@code
    const auto op_B = linear_operator(B);
    const auto op_S = transpose_operator(op_B) * op_M_inv * op_B;
@endcode

在这里，三个LinearOperator对象的乘法产生了一个复合对象 <code>op_S</code> whose <code>vmult()</code> ，该函数首先应用 $B$ ，然后是 $M^{-1}$ （即用 $M$ 解方程），最后是 $B^T$ 到任何指定的输入矢量。在这个意义上， <code>op_S.vmult()</code> 类似于以下代码。

@code
    B.vmult (tmp1, src); // multiply with the top right block: B
    solver_M(M, tmp2, tmp1, preconditioner_M); // multiply with M^-1
    B.Tvmult (dst, tmp2); // multiply with the bottom left block: B^T
@endcode

(  <code>tmp1</code> and <code>tmp2</code> 是两个临时向量)。这种方法背后的关键点是，我们实际上从未创建一个矩阵的内积。相反，每当我们要用 <code>op_S</code> 进行矩阵向量乘法时，我们只需按上述顺序运行所有单独的 <code>vmult</code> 操作。

 @note 我们可以通过实现一个专门的类 <code>SchurComplement</code> ，提供一个合适的 <code>vmult()</code> 函数，来实现创建一个 "类似矩阵 "的对象的相同目标。跳过一些细节，这可能看起来像下面这样。

@code
class SchurComplement
{
  public:


  // ...


  void SchurComplement::vmult (Vector<double>       &dst,
                               const Vector<double> &src) const
  {
    B.vmult (tmp1, src);
    solver_M(M, tmp2, tmp1, preconditioner_M);
    B.Tvmult (dst, tmp2);
  }
};
@endcode

尽管这两种方法完全等同，但LinearOperator类比这种手工方法有很大的优势。它提供了所谓的［<i><a href="https://en.wikipedia.org/wiki/Syntactic_sugar">syntactic sugar</a>］［<a href="https://en.wikipedia.org/wiki/Syntactic_sugar">syntactic sugar</a></i>］。在数学上，我们认为 $S$ 是复合矩阵 $S=B^TM^{-1}B$ ，LinearOperator类允许你或多或少地逐字写出这一点。

@code
const auto op_M_inv = inverse_operator(op_M, solver_M, preconditioner_M);
const auto op_S = transpose_operator(op_B) * op_M_inv * op_B;
@endcode

另一方面，人工方法掩盖了这一事实。

现在我们要做的就是形成定义 $P$ 和 $U$ 的两个方程的右手边，然后分别用舒尔补码矩阵和质量矩阵来解决它们。例如，第一个方程的右手边为 $B^TM^{-1}F-G$  。这可以通过以下方式实现。

@code
    Vector<double> schur_rhs (P.size());
    Vector<double> tmp (U.size());
    op_M_inv.vmult (tmp, F);
    transpose_operator(op_B).vmult (schur_rhs, tmp);
    schur_rhs -= G;
@endcode

同样，这是一个完全有效的方法，但是deal.II要求我们手动调整最终向量和临时向量的大小，而且每一个操作都要占用一个新的行，这让我们很难阅读。这就是线性运算符框架中的第二个类可以将帮助我们的地方。与LinearOperator的精神类似，一个PackagedOperation存储了一个 "计算"。

@code
    std::function<void(Range &)> apply;
    std::function<void(Range &)> apply_add;
@endcode

该类允许<a href="https://en.wikipedia.org/wiki/Lazy_evaluation">lazy evaluation</a>涉及向量和线性运算符的表达式。这是通过存储计算表达式来实现的，只有当对象被转换为向量对象，或者 PackagedOperation::apply() （或 PackagedOperation::apply_add()) 被手动调用时才执行计算。假设 <code>F</code> and <code>G</code> 是右手边的两个向量，我们可以简单地写。

@code
    const auto schur_rhs = transpose_operator(op_B) * op_M_inv * F - G;
@endcode

这里， <code>schur_rhs</code> 是一个打包操作，<i>records</i>是我们指定的计算。它不会立即创建一个带有实际结果的向量。

有了这些先决条件，解决 $P$ 和 $U$ 的问题就是创建另一个解算器和反演。

@code
    SolverControl solver_control_S(2000, 1.e-12);
    SolverCG<Vector<double>>    solver_S(solver_control_S);
    PreconditionIdentity preconditioner_S;


    const auto op_S_inv = inverse_operator(op_S, solver_S, preconditioner_S);


    P = op_S_inv * schur_rhs;
    U = op_M_inv * (F - op_B * P);
@endcode



 @note  我们在这个例子中手工开发的功能在库中已经是现成的。看看schur_complement(), condense_schur_rhs(), and postprocess_schur_solution()。




<h4>A preconditioner for the Schur complement</h4>

有人可能会问，如果我们有一个Schur补数的预处理程序，是否会有帮助  $S=B^TM^{-1}B$  。一般来说，答案是：当然。问题是，我们对这个舒尔补码矩阵一无所知。我们不知道它的条目，我们所知道的只是它的作用。另一方面，我们必须认识到，我们的求解器是昂贵的，因为在每次迭代中，我们必须与舒尔补矩阵做一次矩阵-向量乘积，这意味着我们必须在每次迭代中对质量矩阵做一次反转。

对这样一个矩阵的预处理有不同的方法。一个极端是使用便宜的东西，因此对每次迭代的工作没有实际影响。另一个极端是使用本身非常昂贵的预处理程序，但作为回报，它确实降低了用 $S$ 求解所需的迭代次数。

我们将按照第二种方法进行尝试，既是为了提高程序的性能，也是为了展示一些技术。为此，让我们回顾一下，理想的预处理程序当然是 $S^{-1}$ ，但这是无法实现的。然而，如何

@f{eqnarray*}
  \tilde S^{-1} = [B^T ({\textrm{diag}\ }M)^{-1}B]^{-1}


@f}

作为一个预处理程序？这就意味着，每次我们要做一个预处理步骤时，实际上都要用 $\tilde S$ 来解。起初，这看起来几乎和立即用 $S$ 求解一样昂贵。然而，请注意，在内迭代中，我们不必计算 $M^{-1}$ ，而只需计算其对角线的逆值，这很便宜。

值得庆幸的是，LinearOperator框架使得这一点非常容易写出来。我们之前已经对 <code>preconditioner_M</code> 矩阵使用了雅可比预处理程序（ $M$ ）。所以剩下的就是写出近似的舒尔补码应该是什么样子。

@code
    const auto op_aS =
      transpose_operator(op_B) * linear_operator(preconditioner_M) * op_B;
@endcode

注意这个运算符的不同之处在于，它只是做了一次雅可比扫频（即与对角线的逆数相乘），而不是与整个 $M^{-1}$ 相乘。]的定义：它是与 $M$ 的对角线的倒数相乘；换句话说，对向量 $x$ 的 $({\textrm{diag}\ }M)^{-1}x$ 操作正是PreconditionJacobi所做的）。)

有了这些，我们几乎已经完成了预处理程序：它应该是近似Schur补码的逆。我们再次通过使用inverse_operator()函数创建一个线性算子来实现这一点。然而这一次我们想为CG求解器选择一个相对较小的容忍度（即反转 <code>op_aS</code> ）。理由是 <code>op_aS</code> is only coarse approximation to <code>op_S</code> ，所以我们实际上不需要完全反转它。然而，这产生了一个微妙的问题： <code>preconditioner_S</code> 将被用于最后的外层CG迭代以创建一个正交基础。但为了使其发挥作用，每次调用都必须是精确的线性操作。我们通过使用IterationNumberControl来确保这一点，它允许我们将执行的CG迭代次数固定为一个固定的小数字（在我们的例子中为30）。

@code
    IterationNumberControl iteration_number_control_aS(30, 1.e-18);
    SolverCG<Vector<double>>           solver_aS(iteration_number_control_aS);
    PreconditionIdentity preconditioner_aS;
    const auto preconditioner_S =
      inverse_operator(op_aS, solver_aS, preconditioner_aS);
@endcode



就这样吧!

很明显，应用这个近似Schur补数的逆运算是一个非常昂贵的预处理程序，几乎和反转Schur补数本身一样昂贵。我们可以期望它能大大减少Schur补数所需的外部迭代次数。事实上，它确实如此：在使用0阶元素的7次细化网格的典型运行中，外部迭代次数从592次下降到39次。另一方面，我们现在必须应用一个非常昂贵的预处理程序25次。因此，更好的衡量标准只是程序的运行时间：在目前的笔记本电脑上（截至2019年1月），对于这个测试案例，它从3.57秒下降到2.05秒。这似乎并不令人印象深刻，但在更细的网格和更高阶的元素上，节省的时间变得更加明显了。例如，一个7倍细化的网格和使用2阶元素（相当于约40万个自由度）产生了1134次到83次的外部迭代的改进，运行时间从168秒到40秒。虽然不是惊天动地，但意义重大。




<h3>Definition of the test case</h3>

在这个教程程序中，我们将求解上述混合公式中的拉普拉斯方程。由于我们想在程序中监测解的收敛性，我们选择右手边、边界条件和系数，以便恢复我们已知的解函数。特别是，我们选择压力解

@f{eqnarray*}
  p = -\left(\frac \alpha 2 xy^2 + \beta x - \frac \alpha 6 x^3\right),


@f}

而对于系数，为了简单起见，我们选择单位矩阵 $K_{ij}=\delta_{ij}$ 。因此，确切的速度满足于

@f{eqnarray*}
  {\mathbf u} =
  \left(\begin{array}{cc}
    \frac \alpha 2 y^2 + \beta - \frac \alpha 2 x^2 \\
    \alpha xy
  \end{array}\right).


@f}

选择这个解决方案是因为它完全没有发散，使得它成为不可压缩流体流动的一个现实的测试案例。因此，右手边等于 $f=0$ ，作为边界值，我们必须选择 $g=p|_{\partial\Omega}$ 。

对于本程序中的计算，我们选择  $\alpha=0.3,\beta=1$  。你可以在<a name="#Results">results section
below</a>中找到结果的解决方案，在注释的程序之后。


examples/step-20/doc/results.dox



<h1>Results</h1>

<h3>Output of the program and graphical visualization</h3>


如果我们按原样运行程序，对于我们使用的 $32\times 32$ 网格，我们得到这样的输出（因为我们使用片状常数，所以总共有1024个单元，1024个压力自由度，2112个速度，因为Raviart-Thomas元素定义了每个面的一个自由度，有 $1024 + 32 = 1056$ 个面与 $x$  -轴平行，有同样数量的面与 $y$  -轴平行）。

@verbatim
\$ make run
[ 66%] Built target \step-20
Scanning dependencies of target run
[100%] Run \step-20 with Release configuration
Number of active cells: 1024
Total number of cells: 1365
Number of degrees of freedom: 3136 (2112+1024)
24 CG Schur complement iterations to obtain convergence.
Errors: ||e_p||_L2 = 0.0445032,   ||e_u||_L2 = 0.010826
[100%] Built target run
@endverbatim



当然，迭代次数如此之少的事实是由于我们开发的良好（但昂贵！）的预处理程序。为了获得对解决方案的信心，让我们看一下它。下面三张图片显示了（从左到右）X-速度、Y-速度和压力。

 <table style="width:60%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-20.u_new.jpg" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-20.v_new.jpg" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-20.p_new.jpg" width="400" alt=""></td>
  </tr>
</table> 




让我们从压力开始：它在左边是最高的，在右边是最低的，所以流动将是从左到右。此外，虽然在图中几乎看不出来，但我们选择的压力场是这样的：从左到右的流动首先是向中心流动，然后再向外流动。因此，X-速度必须增加以使流动通过狭窄的部分，这一点在左图中很容易看到。中间的图像表示在域的左端有Y方向的内流，而在域的右端有Y方向的外流。




作为补充说明，请注意左图中的x-速度在x方向上是连续的，而y-速度在y方向上是连续的。其他方向上的流场是不连续的。这非常明显地反映了Raviart-Thomas元素的连续性特性，事实上，它只在空间H(div)而不是在空间 $H^1$ 。最后，压力场是完全不连续的，但鉴于我们选择了 <code>FE_DGQ(0)</code> 作为该解分量的有限元，这不应该令人惊讶。




<h3>Convergence</h3>


该程序提供了两个明显的玩耍和观察收敛的地方：使用的有限元的程度（传递给 <code>MixedLaplaceProblem</code> class from <code>main()</code> 的构造器），和细化水平（在 <code>MixedLaplaceProblem::make_grid_and_dofs</code> 中确定）。人们可以做的是改变这些值，观察后来在程序运行过程中计算出的误差。




如果这样做，就会发现压力变量中 $L_2$ 的错误有如下模式。   <table align="center" class="doxtable">
  <tr>
    <th></th>
    <th colspan="3" align="center">Finite element order</th>
  </tr>
  <tr>
    <th>Refinement level</th>
    <th>0</th>
    <th>1</th>
    <th>2</th>
  </tr>
  <tr>
    <th>0</th>  <td>1.45344</td>  <td>0.0831743</td>  <td>0.0235186</td>
  </tr>
  <tr>
    <th>1</th>  <td>0.715099</td>  <td>0.0245341</td>  <td>0.00293983</td>
  </tr>
  <tr>
    <th>2</th>  <td>0.356383</td>  <td>0.0063458</td>  <td>0.000367478</td>
  </tr>
  <tr>
    <th>3</th>  <td>0.178055</td>  <td>0.00159944</td>  <td>4.59349e-05</td>
  </tr>
  <tr>
    <th>4</th>  <td>0.0890105</td>  <td>0.000400669</td>  <td>5.74184e-06</td>
  </tr>
  <tr>
    <th>5</th>  <td>0.0445032</td>  <td>0.000100218</td>  <td>7.17799e-07</td>
  </tr>
  <tr>
    <th>6</th>  <td>0.0222513</td>  <td>2.50576e-05</td>  <td>9.0164e-08</td>
  </tr>
  <tr>
    <th></th>  <th>$O(h)$</th>  <th>$O(h^2)$</th>  <th>$O(h^3)$</th>
  </tr>
</table> 

理论上预期的收敛顺序很好地反映在表中最后一行所显示的实验观察结果中。




我们可以用速度变量的 $L_2$ 误差做同样的实验。   <table align="center" class="doxtable">
  <tr>
    <th></th>
    <th colspan="3" align="center">Finite element order</th>
  </tr>
  <tr>
    <th>Refinement level</th>
    <th>0</th>
    <th>1</th>
    <th>2</th>
  </tr>
  <tr>
    <th>0</th> <td>0.367423</td> <td>0.127657</td> <td>5.10388e-14</td>
  </tr>
  <tr>
    <th>1</th> <td>0.175891</td> <td>0.0319142</td> <td>9.04414e-15</td>
  </tr>
  <tr>
    <th>2</th> <td>0.0869402</td> <td>0.00797856</td> <td>1.23723e-14</td>
  </tr>
  <tr>
    <th>3</th> <td>0.0433435</td> <td>0.00199464</td> <td>1.86345e-07</td>
  </tr>
  <tr>
    <th>4</th> <td>0.0216559</td> <td>0.00049866</td> <td>2.72566e-07</td>
  </tr>
  <tr>
    <th>5</th> <td>0.010826</td> <td>0.000124664</td> <td>3.57141e-07</td>
  </tr>
  <tr>
    <th>6</th> <td>0.00541274</td> <td>3.1166e-05</td> <td>4.46124e-07</td>
  </tr>
  <tr>
    <th></th>  <td>$O(h)$</td>  <td>$O(h^2)$</td>  <td>$O(h^3)$</td>
  </tr>
</table>  这里关于收敛顺序的结果是一样的。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>More realistic permeability fields</h4>

用于地下水或油藏模拟的现实流动计算不会使用恒定的渗透率。下面是改变这种情况的第一个相当简单的方法：我们使用一个渗透率，它在远离中心流线的地方迅速衰减，直到达到一个背景值0.001。这是为了模仿流体在砂岩中的行为：在大部分领域中，砂岩是均匀的，虽然对流体有渗透性，但不是过分的渗透；在另一块石头上，石头沿着一条线裂开了，或者说断层了，流体沿着这条大裂缝更容易流动。下面是我们如何实现这样的东西。

@code
template <int dim>
void
KInverse<dim>::value_list (const std::vector<Point<dim> > &points,
                           std::vector<Tensor<2,dim> >    &values) const
{
  Assert (points.size() == values.size(),
	  ExcDimensionMismatch (points.size(), values.size()));


  for (unsigned int p=0; p<points.size(); ++p)
    {
      values[p].clear ();


      const double distance_to_flowline
        = std::fabs(points[p][1]-0.2*std::sin(10*points[p][0]));


      const double permeability = std::max(std::exp(-(distance_to_flowline*
                                                      distance_to_flowline)
                                                    / (0.1 * 0.1)),
                                           0.001);


      for (unsigned int d=0; d<dim; ++d)
	values[p][d][d] = 1./permeability;
    }
}
@endcode

记住，该函数返回渗透率张量的逆值。




通过一个明显更高的网格分辨率，我们可以直观地看到这一点，这里有x-和y-速度。

 <table style="width:60%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-20.u-wiggle.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-20.v-wiggle.png" alt=""></td>
  </tr>
</table> 

很明显，流体基本上只沿着中线流动，而不是其他地方。




另一种可能性是使用一个随机的渗透率场。实现这一点的一个简单方法是在领域周围分散一些中心，然后使用一个渗透率场，这个渗透率场是这些中心的（负）指数之和。然后，流动将试图从一个高渗透率的中心跳到下一个中心。这是描述随机介质的一种完全不科学的尝试，但实现这种行为的一种可能性是这样的。

@code
template <int dim>
class KInverse : public TensorFunction<2,dim>
{
  public:
    KInverse ();


    virtual void value_list (const std::vector<Point<dim> > &points,
			     std::vector<Tensor<2,dim> >    &values) const;


  private:
    std::vector<Point<dim> > centers;
};



template <int dim>
KInverse<dim>::KInverse ()
{
  const unsigned int N = 40;
  centers.resize (N);
  for (unsigned int i=0; i<N; ++i)
    for (unsigned int d=0; d<dim; ++d)
      centers[i][d] = 2.*rand()/RAND_MAX-1;
}



template <int dim>
void
KInverse<dim>::value_list (const std::vector<Point<dim> > &points,
                           std::vector<Tensor<2,dim> >    &values) const
{
  Assert (points.size() == values.size(),
	  ExcDimensionMismatch (points.size(), values.size()));


  for (unsigned int p=0; p<points.size(); ++p)
    {
      values[p].clear ();


      double permeability = 0;
      for (unsigned int i=0; i<centers.size(); ++i)
        permeability += std::exp(-(points[p] - centers[i]).norm_square() / (0.1 * 0.1));


      const double normalized_permeability
        = std::max(permeability, 0.005);


      for (unsigned int d=0; d<dim; ++d)
	values[p][d][d] = 1./normalized_permeability;
    }
}
@endcode



这个张量的对角线元素的片状常数插值（即 <code>normalized_permeability</code> ）看起来如下。

 <img src="https://www.dealii.org/images/steps/developer/step-20.k-random.png" alt=""> 


有了这样一个渗透率场，我们将得到如下的x-velocities和压力。

 <table style="width:60%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-20.u-random.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-20.p-random.png" alt=""></td>
  </tr>
</table> 

我们将在步骤21和步骤43中再次使用这些渗透率场。




<h4>Better linear solvers</h4>

正如介绍中提到的，这里使用的Schur补码求解器并不是可以想象的最好的（也不打算成为一个特别好的）。更好的解算器可以在文献中找到，并且可以使用这里介绍的相同的块矩阵技术来构建。我们将在第22步中再次讨论这个主题，在这里我们首先为斯托克斯方程建立一个Schur补数求解器，然后在<a
href="step_22.html#improved-solver">Improved Solvers</a>部分讨论基于整体求解系统但基于单个块的预处理的更好方法。我们还将在第43步中再来讨论这个问题。


examples/step-21/doc/intro.dox

［<a name="Intro"></a>］ ［<h1>Introduction</h1>］

这个项目是由德克萨斯A&amp;M大学的李艳的一个学生项目发展而来的。这个项目的大部分工作都是由她完成的。

在这个项目中，我们提出了一个针对多孔介质中两相流动问题的数值模拟。这个问题包括一个椭圆方程和一个非线性的、随时间变化的传输方程。因此，这也是第一个时间相关的教程程序（除了有点奇怪的时间相关的 @ref step_18 "step-18"）。

这里涉及的方程是步骤20中已经涉及的材料的延伸。特别是，它们属于矢量值问题的范畴。这个主题的顶层概述可以在 @ref vector_valued 模块中找到。




<h3>The two phase flow problem</h3>

多孔介质中两相流动的建模对于环境修复和石油及地下水库的管理都很重要。涉及两相流动的实际情况包括非水相液体在含水层中的分散，或混合液体（如油和水）在储层中的联合运动。仿真模型如果要提供真实的预测，就必须准确地考虑到这些影响。

为了推导出管理方程，考虑储层中的两相流动 $\Omega$ ，假设流体的运动由粘性效应主导；即我们忽略了重力、压缩性和毛细压力的影响。孔隙率将被认为是恒定的。我们将使用下标 $w$ 和 $o$ 来表示两相中的任何一个变量，即水和油的简称。然而，方程的推导对其他流体对也是适用的。

两相中每一相的分子移动的速度由达西定律决定，该定律指出速度与压力梯度成正比。

@f{eqnarray*}
  \mathbf{u}_{j}
  =


  -\frac{k_{rj}(S)}{\mu_{j}} \mathbf{K} \cdot \nabla p


@f}

其中 $\mathbf{u}_{j}$ 是相 $j=o,w$ 的速度， $K$ 是渗透率张量， $k_{rj}$ 是相 $j$ 的相对渗透率， $p$ 是压力， $\mu_{j}$ 是相 $j$ 的粘性。最后， $S$ 是饱和度（体积分数），即一个数值在0和1之间的函数，表示流体混合物的组成。一般来说，系数 $K, k_{rj}, \mu$ 可能是空间上的变量，在下文中我们将始终把它们作为非常数函数。

我们将达西定律与各相的质量守恒声明结合起来。

@f[
  \textrm{div}\ \mathbf{u}_{j} = q_j,


@f]

每个相都有一个源项。通过对两相求和，我们可以用所谓的压力方程来表达治理方程。

@f{eqnarray*}


- \nabla \cdot (\mathbf{K}\lambda(S) \nabla p)= q.


@f}

这里， $q$ 是和源项，而

@f[
  \lambda(S) = \frac{k_{rw}(S)}{\mu_{w}}+\frac{k_{ro}(S)}{\mu_{o}}


@f]

是总的流动性。

到目前为止，这看起来是一个普通的静止的、类似泊松的方程，我们可以用前几个教程的技术马上解决（例如，看一下步骤6，非常类似的东西）。然而，我们还没有说到饱和度，这当然会随着流体的移动而改变。

方程的第二部分是对饱和度的动态描述，即两种流体的相对浓度如何随时间变化。置换流体（水）的饱和度方程由以下守恒定律给出。

@f{eqnarray*}
  S_{t} + \nabla \cdot (F(S) \mathbf{u}) = q_{w},


@f}

这可以通过使用前一个方程中发散算子的乘积规则来重写。

@f{eqnarray*}
  S_{t} + F(S) \left[\nabla \cdot \mathbf{u}\right]
        + \mathbf{u} \cdot \left[ \nabla F(S)\right]
  = S_{t} + F(S) q + \mathbf{u} \cdot \nabla F(S) = q_{w}.


@f}

这里， $q=\nabla\cdot \mathbf{u}$ 是上面介绍的总流入量， $q_{w}$ 是置换流体（水）的流速。这两者与分流量 $F(S)$ 的关系如下。

@f[
  q_{w} = F(S) q,


@f]

其中分数流通常通过（启发式）表达式进行参数化

@f[
  F(S)
  =
  \frac{k_{rw}(S)/\mu_{w}}{k_{rw}(S)/\mu_{w} + k_{ro}(S)/\mu_{o}}.


@f]

将所有这些放在一起，可以得到以下形式的饱和度方程，即平流式。

@f{eqnarray*}
  S_{t} + \mathbf{u} \cdot \nabla F(S) = 0,


@f}

其中 $\mathbf u$ 是总速度

@f[
  \mathbf{u} =
  \mathbf{u}_{o} + \mathbf{u}_{w} = -\lambda(S) \mathbf{K}\cdot\nabla p.


@f]

注意，平流方程包含术语 $\mathbf{u} \cdot \nabla
F(S)$ 而不是 $\mathbf{u} \cdot \nabla S$ ，以表明饱和度不是简单地沿途传送；相反，由于两相以不同的速度移动，即使在平流坐标系中，饱和度实际上也可以改变。为了看到这一点，重写 $\mathbf{u} \cdot \nabla F(S)
= \mathbf{u} F'(S) \cdot \nabla S$ ，观察到具有饱和度 $S$ 的相的<i>actual</i>传输速度是 $\mathbf u F'(S)$ ，而另一相的传输速度是 $\mathbf u (1-F'(S))$  。  因此， $F(S)$ 通常被称为<i>fractional flow</i>。

综上所述，我们得到的是以下两个方程式。

@f{eqnarray*}


  - \nabla \cdot (\mathbf{K}\lambda(S) \nabla p) &=& q
  \qquad \textrm{in}\ \Omega\times[0,T],
  \\
  S_{t} + \mathbf{u} \cdot \nabla F(S) &=& 0
  \qquad \textrm{in}\ \Omega\times[0,T].


@f}

这里， $p=p(\mathbf x, t), S=S(\mathbf x, t)$ 现在是随时间变化的函数：虽然在每个时间瞬间，流场与压力处于平衡状态（即我们忽略了动态加速），但饱和度随着流动而运输，因此随时间变化，反过来又通过第一个方程对 $S$ 的依赖性影响流场。

这组方程有一个奇特的特点：两个方程中的一个有时间导数，另一个没有。这与压力和速度通过瞬时约束耦合的特点相对应，而饱和度在有限的时间尺度上演变。

这样的方程组被称为微分代数方程（DAE），因为其中一个方程是微分方程，另一个不是（至少不是相对于时间变量），因此是一个 "代数 "方程。这个符号来自常微分方程领域，在这个领域中，所有没有关于时间变量的导数的东西都必然是一个代数方程）。这类方程包含相当知名的情况：例如，与时间相关的斯托克斯和纳维-斯托克斯方程（其中代数约束是流场的发散， $\textrm{div}\ \mathbf u$ ，必须为零）以及与时间相关的麦克斯韦方程（这里，代数约束是电位移场的发散等于电荷密度， $\textrm{div}\ \mathbf D = \rho$  ，磁通密度的发散为零。   $\textrm{div}\ \mathbf
B = 0$ ）；即使是Step-18的准静态模型也属于这个类别。我们将看到，这两个方程的不同特征将告知我们这两个方程的离散化策略。




<h3>Time discretization</h3>

在储层模拟界，通常是通过回到一阶混合公式来解决上面得出的方程。为此，我们重新引入总速度 $\mathbf u$ ，并将方程写成以下形式。

@f{eqnarray*}
  \mathbf{u}+\mathbf{K}\lambda(S) \nabla p&=&0 \\
  \nabla \cdot\mathbf{u} &=& q \\
  S_{t} + \mathbf{u} \cdot \nabla F(S) &=& 0.


@f}

这种表述方式还有一个好处，即我们不必将出现在传输方程中的总速度 $\mathbf u$ 表示为压力的函数，而是可以将其作为主变量。鉴于前两个方程的鞍点结构以及它们与我们在第20步中介绍的混合拉普拉斯公式的相似性，我们将再次使用混合离散化，这并不奇怪。

但是，让我们先把这个问题推迟一下。我们处理这些方程的第一件事是考虑时间离散化。在储层模拟中，有一个相当标准的算法，我们将在这里使用。它首先使用隐式方程解决压力问题，然后使用显式时间步进方案解决饱和问题。该算法被称为IMplicit Pressure Explicit Saturation（隐式压力显式饱和），很早以前就被提出：Sheldon等人在1959年提出，Stone和Gardner在1961年提出（J.W.Sheldon, B. Zondek and W. T. Cardwell:<i>One-dimensional, incompressible, non-capillary, two-phase
fluid flow in a porous medium</i>, Trans.SPE AIME, 216 (1959), pp. 290-296; H. L. Stone and A. O. Gardner Jr: <i>Analysis of gas-cap or dissolved-gas
reservoirs</i>, Trans.SPE AIME, 222 (1961), pp. 92-104)。在一个稍加修改的形式中，这个算法可以写成如下：对于每一个时间步长，解决

@f{eqnarray*}
  \mathbf{u}^{n+1}+\mathbf{K}\lambda(S^n) \nabla p^{n+1}&=&0 \\
  \nabla \cdot\mathbf{u}^{n+1} &=& q^{n+1} \\
  \frac {S^{n+1}-S^n}{\triangle t} + \mathbf{u}^{n+1} \cdot \nabla F(S^n) &=& 0,


@f}

其中 $\triangle t$ 是一个时间步长。请注意我们是如何解决隐式压力-速度系统的，它只取决于先前计算的饱和度 $S^n$ ，然后对 $S^{n+1}$ 做一个显式时间步长，它只取决于先前已知的 $S^n$ 和刚刚计算的 $\mathbf{u}^{n+1}$ 。这样一来，我们就不必像使用全隐式方法那样，对系统的非线性进行迭代。从更现代的角度来看，这应该被看作是一种 "算子分割 "方法。

然后我们可以将问题以弱的形式陈述如下，用测试函数 $\mathbf v$ 、 $\phi$ 和 $\sigma$ 乘以每个方程，并通过部分整合条款。

@f{eqnarray*}
  \left((\mathbf{K}\lambda(S^n))^{-1} \mathbf{u}^{n+1},\mathbf v\right)_\Omega -
  (p^{n+1}, \nabla\cdot\mathbf v)_\Omega &=&


  - (p^{n+1}, \mathbf v)_{\partial\Omega}
  \\
  (\nabla \cdot\mathbf{u}^{n+1}, \phi)_\Omega &=& (q^{n+1},\phi)_\Omega


@f}

注意，在第一项中，我们必须规定边界 $p^{n+1}$ 上的压力 $\partial\Omega$ 作为我们问题的边界值。   $\mathbf n$ 表示对 $\partial K$ 的单位外向法向量，如常。

对于饱和度方程，我们通过部分积分后得到

@f{eqnarray*}
  (S^{n+1}, \sigma)_\Omega


  -
  \triangle t
  \sum_K
  \left\{
  \left(F(S^n), \nabla \cdot (\mathbf{u}^{n+1} \sigma)\right)_K


  -
  \left(F(S^n) (\mathbf n \cdot \mathbf{u}^{n+1}, \sigma\right)_{\partial K}
  \right\}
  &=&
  (S^n,\sigma)_\Omega.


@f}

利用 $\nabla \cdot \mathbf{u}^{n+1}=q^{n+1}$ 这一事实，我们可以重写细胞项，得到如下方程。

@f{eqnarray*}
  (S^{n+1}, \sigma)_\Omega


  -
  \triangle t
  \sum_K
  \left\{
  \left(F(S^n) \mathbf{u}^{n+1}, \nabla \sigma\right)_K


  -
  \left(F(S^n) (\mathbf n \cdot \mathbf{u}^{n+1}), \sigma\right)_{\partial K}
  \right\}
  &=&
  (S^n,\sigma)_\Omega +
  \triangle t \sum_K  \left(F(S^n) q^{n+1}, \sigma\right)_K.


@f}

我们引入了一个DiscreteTime类型的对象，以便在代码中保持对时间和时间步长的当前值的跟踪。这个类封装了许多关于调整时间步长和在指定的最终时间停止的复杂情况。




<h3>Space discretization</h3>

在每个时间步长中，我们再对速度和压力应用 @ref step_20 "step-20 "的混合有限方法。为了得到良好的解决，我们对 $\mathbf{u}$ 选择Raviart-Thomas空间 $RT_{k}$ ，对 $p$ 选择 $DGQ_{k}$ 类的不连续元素。对于饱和度，我们也将选择 $DGQ_{k}$ 空间。

由于我们有不连续的空间，我们必须考虑如何评估细胞之间界面上的项，因为不连续的函数在那里没有真正定义。特别是，我们必须给饱和度方程左边的最后一个项赋予一个意义。为此，让我们定义，我们要在以下意义上评估它。

@f{eqnarray*}
  &&\left(F(S^n) (\mathbf n \cdot \mathbf{u}^{n+1}), \sigma\right)_{\partial K}
  \\
  &&\qquad =
  \left(F(S^n_+) (\mathbf n \cdot \mathbf{u}^{n+1}_+), \sigma\right)_{\partial K_+}
  +
  \left(F(S^n_-) (\mathbf n \cdot \mathbf{u}^{n+1}_-), \sigma\right)_{\partial K_-},


@f}

其中 $\partial K_{-} \dealcoloneq \{x\in \partial K, \mathbf{u}(x) \cdot \mathbf{n}<0\}$ 表示流入边界， $\partial K_{+} \dealcoloneq \{\partial K \setminus
\partial K_{-}\}$ 是边界的流出部分。数量 $S_+,\mathbf{u}_+$ 对应于当前单元上的这些变量值，而 $S_-,\mathbf{u}_-$ （需要在 $K$ 边界的流入部分）是取自邻近单元的数量。关于非连续元素技术和通量评估的更多背景，也可以在步骤12和步骤12b中找到。




<h3>Linear solvers</h3>

这个程序中使用的线性求解器是对步骤20中使用的线性求解器的直接扩展（但没有LinearOperator）。从本质上讲，我们只需将一切从两个解元扩展到三个解元。如果我们使用上面提到的离散空间，并将形状函数放入双线性形式中，我们得出以下线性系统，以解决时间步长 $n+1$  。

@f[
\left(
\begin{array}{ccc}
M^u(S^{n}) & B^{T}& 0\\
B &    0 & 0\\
\triangle t\; H &    0& M^S
\end{array}
\right)
\left(
\begin{array}{c}
\mathbf{U}^{n+1} \\ P^{n+1} \\ S^{n+1}
\end{array}
\right)
=
\left(
\begin{array}{c}
0 \\ F_2 \\ F_3
\end{array}
\right)


@f]

其中各个矩阵和向量的定义如下：使用形状函数 $\mathbf v_i$ （类型为Raviart Thomas $RT_k$ ）定义速度，使用 $\phi_i$ （类型为 $DGQ_k$  ）定义压力和饱和度。

@f{eqnarray*}
M^u(S^n)_{ij} &=&
\left((\mathbf{K}\lambda(S^n))^{-1} \mathbf{v}_i,\mathbf
v_j\right)_\Omega,
\\
B_{ij} &=&


-(\nabla \cdot \mathbf v_j, \phi_i)_\Omega,
\\
H_{ij} &=&


  -
  \sum_K
  \left\{
  \left(F(S^n) \mathbf v_i, \nabla \phi_j)\right)_K


  -
  \left(F(S^n_+) (\mathbf n \cdot (\mathbf v_i)_+), \phi_j\right)_{\partial K_+}


  -
  \left(F(S^n_-) (\mathbf n \cdot (\mathbf v_i)_-), \phi_j\right)_{\partial K_-},
  \right\}
\\
M^S_{ij} &=&
(\phi_i, \phi_j)_\Omega,
\\
(F_2)_i &=&


-(q^{n+1},\phi_i)_\Omega,
\\
(F_3)_i &=&
(S^n,\phi_i)_\Omega +\triangle t \sum_K  \left(F(S^n) q^{n+1}, \phi_i\right)_K.


@f}



 @note  由于历史原因，与第20步相比，矩阵 $B$ 和 $B^T$ 的作用在本程序中被还原了。换句话说，这里 $B$ 指的是发散， $B^T$ 指的是梯度算子，而在第20步中则是相反。

上面的系统出现了一个复杂的问题。由于矩阵 $H_{ij}$ 隐含地依赖于 $\mathbf u^{n+1}$ （需要速度来确定细胞边界 $\partial K$ 的哪些部分是流入或流出的部分），我们只能在解决了速度问题之后才能组装这个矩阵。

然后，求解方案包括以下步骤。<ol>  <li>  使用步骤20中介绍的Schur补足技术求解压力 $p^{n+1}$ 。

    <li>  求解速度 $\mathbf u^{n+1}$ ，也是在步骤20中讨论的。

    <li>  计算项 $F_3-\triangle t\; H \mathbf u^{n+1}$  ，使用刚刚计算的速度。

    <li>  求解饱和度  $S^{n+1}$  。   </ol> 

在这个方案中，我们实际上从未建立过矩阵 $H$ ，而是在我们准备好后生成第三个方程的右手边。

在程序中，我们使用一个变量 <code>solution</code> 来存储当前时间步骤的解决方案。在每一步结束时，我们将其内容，即其所有的三个块状成分，复制到变量 <code>old_solution</code> 中，以便在下一个时间步骤中使用。




<h3>Choosing a time step</h3>

在双曲输运方程中，像我们要解决的饱和方程的一般经验法则是，如果我们使用显式时间步长方案，那么我们应该使用一个时间步长，使粒子在一个时间步长内所能走的距离不大于一个细胞的直径。换句话说，在这里，我们应该选择

@f[
  \triangle t_{n+1} \le \frac h{|\mathbf{u}^{n+1}(\mathbf{x})|}.


@f]

幸运的是，我们处在一个可以做到这一点的位置：我们只需要当我们想集合饱和方程的右边时的时间步长，也就是在我们已经解出 $\mathbf{u}^{n+1}$ 之后。因此，在求解速度之后，我们要做的就是在域中的所有正交点上循环，确定速度的最大幅度。然后我们可以将饱和方程的时间步长设定为

@f[
  \triangle t_{n+1} = \frac {\min_K h_K}{\max_{\mathbf{x}}|\mathbf{u}^{n+1}(\mathbf{x})|}.


@f]



为什么要这样做呢？如果我们不这样做，那么我们就会发现很多地方的饱和度大于1或小于0，这一点很容易得到验证。请记住，饱和度对应于流体混合物中的水比例，因此在物理上必须在0和1之间）。另一方面，如果我们根据上面列出的标准选择时间步长，这种情况只会非常非常少地发生，事实上在整个程序运行中只有一次。然而，为了安全起见，我们在每个时间步长结束时运行一个函数 <code>project_back_saturation</code> ，如果饱和度已经超出了物理范围，则简单地将其投射回区间 $[0,1]$ 。这很有用，因为函数 $\lambda(S)$ 和 $F(S)$ 并不代表这个范围之外的任何物理现象，而且一旦我们有负的饱和度或大于1的饱和度，我们不应该期望程序做任何有用的事情。

请注意，我们在第23步和第24步中也会对时间步长有类似的限制，在这两步中我们要解决与时间有关的波浪方程，即另一个双曲问题。我们还将在下面的<a href="#extensions">possible
extensions to this program</a>一节中再来讨论时间步长的选择问题。




<h3>The test case</h3>

为了简单起见，本程序假定没有源头，  $q=0$  ，并且异质多孔介质是各向同性的  $\mathbf{K}(\mathbf{x}) =
k(\mathbf{x}) \mathbf{I}$  。其中第一个假设在油藏中是一个现实的假设：除了注水井和生产井之外，通常没有液体突然出现或消失的机制。第二个假设更难证明：在微观层面上，大多数岩石是各向同性的，因为它们是由相互连接的孔隙网络组成的。然而，这种微观尺度超出了今天计算机模拟的范围，我们不得不满足于模拟米级的东西。然而，在这个尺度上，流体运输通常是通过岩石中的裂缝网络，而不是通过孔隙发生的。然而，裂缝通常是由岩层中的外部应力场造成的（例如由构造断层造成的），因此裂缝是大致排列的。这就导致了这样一种情况：在平行于裂缝的方向上，渗透率往往比垂直于裂缝的方向大几个数量级。然而，在储层模拟中通常面临的一个问题是，建模者不知道裂缝的方向，因为油藏不容易被检查到。在这种情况下，唯一的解决办法是假设有效的、各向同性的渗透率。

无论怎样，这两个限制，即无源和各向同性，只要在程序中写上几行代码就能轻松解除。

接下来，为了简单起见，我们的数值模拟将在 $\Omega = [0,1]\times [0,1]$ 的单元格上进行，即 $t\in [0,T]$ 。我们的初始条件是 $S(\mathbf{x},0)=0$ ；在油藏图片中， $S$ 将表示水的饱和度，这意味着油藏一开始就含有纯油。请注意，我们不需要任何压力或速度的初始条件，因为这些方程不包含这些变量的时间导数。最后，我们施加以下压力边界条件。

@f[
  p(\mathbf{x},t)=1-x_1 \qquad \textrm{on}\ \partial\Omega.


@f]

由于压力和速度求解的是混合形式的泊松方程，所以施加的压力导致了速度的流场。另一方面，这个流场决定了边界的某一部分是流入还是流出，这很重要，因为我们必须在边界的流入部分施加饱和度的边界条件。

@f[
  \Gamma_{in}(t) = \{\mathbf{x}\in\partial\Omega:
                     \mathbf{n} \cdot \mathbf{u}(\mathbf{x},t) < 0\}.


@f]

在这个流入的边界上，我们施加以下的饱和值。

@f{eqnarray}
  S(\mathbf{x},t) = 1 & \textrm{on}\ \Gamma_{in}\cap\{x_1=0\},
  \\
  S(\mathbf{x},t) = 0 & \textrm{on}\ \Gamma_{in}\backslash \{x_1=0\}.


@f}

换句话说，我们有纯水在左边进入储层，而边界的其他部分与储层的未受干扰部分接触，只要这些边界上发生流入，纯油就会进入。

在我们的模拟中，我们选择总流动性为

@f[
  \lambda (S) = \frac{1.0}{\mu} S^2 +(1-S)^2


@f]

其中我们用 $\mu=0.2$ 表示粘度。此外，水的分流量由以下公式给出

@f[
  F(S)=\frac{S^2}{S^2+\mu (1-S)^2}


@f]



 @note  几年后在step-43中再来看这个测试案例，发现这个测试案例的设置有一个奇怪之处。为此，考虑我们可以将饱和度的平流方程改写为  $S_{t} + (\mathbf{u}
F'(S)) \cdot \nabla S = 0$  。现在，在初始时间，我们有 $S=0$ ，在给定的函数 $F(S)$ 的选择下，我们正好有 $F'(0)=0$ 。换句话说，在 $t=0$ 处，方程对所有 $\mathbf x$ 都还原为 $S_t=0$ ，所以饱和度在任何地方都是零，而且在任何地方都会保持零！这就是为什么在 $\mathbf x$ 处的饱和度为零。尽管 $\mathbf u$ 不一定是零：组合流体在移动，但我们选择的部分通量 $F(S)$ 是这样的：无穷小量的润湿流体也只以无穷小的速度移动（也就是说，它们粘附在介质上的程度比它们所嵌入的非润湿相要大）。也就是说，我们如何将这一点与润湿性液体从左边侵入，导致<a href="#Results">results section</a>中看到的流动模式的知识联系起来？这就是我们进入数学的地方。像我们在这里考虑的传输方程有无限多的解决方案，但其中只有一个是物理的：由所谓的粘性极限产生的解决方案，称为<a
href="http://en.wikipedia.org/wiki/Viscosity_solution">viscosity
solution</a>。事情是这样的，用不连续的元素，我们到达了这个粘性极限，因为使用数值通量在数值方案中引入了有限量的人工粘性。另一方面，在step-43中，我们在每个单元上使用与 $\|\mathbf u F'(S)\|$ 成比例的人工粘度，在初始时间是零。因此，那里的饱和度为零，并保持为零；然后我们得到的解是<i>one</i>的平流方程解，但如果不进一步改变，该方法不会收敛到粘性解。因此，我们将在该程序中使用一个不同的初始条件。


最后，回到测试案例的描述，我们将展示用 @ref step_20  "step-20 "的结果部分末尾介绍的两个渗透率函数计算的结果。   <ul>   <li>  一个函数，模拟一个蜿蜒穿过领域的单一裂缝。与step-20相类似，但考虑到我们这里的几何形状略有不同，我们用以下函数来描述。   @f[
    k(\mathbf x)
    =
    \max \left\{ e^{-\left(\frac{x_2-\frac 12 - 0.1\sin(10x_1)}{0.1}\right)^2}, 0.01 \right\}.
  @f]

  取最大值是必要的，以确保最大和最小渗透率之间的比率保持有界。如果我们不这样做，渗透率将跨越许多数量级。另一方面，最大和最小渗透率之间的比率是舒尔补矩阵的条件数的一个因素，如果太大，会导致我们的线性求解器不再正常收敛的问题。

    <li>  一个模拟某种随机介质的函数。在这里，我们选择@f{eqnarray*}
    k(\mathbf x)
    &=&
    \min \left\{ \max \left\{ \sum_{i=1}^N \sigma_i(\mathbf{x}), 0.01 \right\}, 4\right\},
    \\
    \sigma_i(\mathbf x)
    &=&
    e^{-\left(\frac{|\mathbf{x}-\mathbf{x}_i|}{0.05}\right)^2},
  @f}。

  其中中心 $\mathbf{x}_i$ 是域内 $N$ 随机选择的位置。这个函数模拟了一个领域，其中有 $N$ 个渗透率较高的中心（例如，岩石已经开裂）嵌入到一个更原始的、未受干扰的背景岩石矩阵中。请注意，在这里我们切断了上方和下方的渗透率函数，以确保有界的条件数。   </ul> 


examples/step-21/doc/results.dox



<h1>Results</h1>

这里介绍的代码并没有真正计算出网页上的结果。原因是，即使在一台好的电脑上，它也要运行一天以上。如果你想重现这些结果，在TwoPhaseFlowProblem的构造函数中把DiscreteTime对象的结束时间修改为`250`。

如果我们运行该程序，我们会得到以下这种输出。

@code
Number of active cells: 1024
Number of degrees of freedom: 4160 (2112+1024+1024)


Timestep 1
   22 CG Schur complement iterations for pressure.
   1 CG iterations for saturation.
   Now at t=0.0326742, dt=0.0326742.


Timestep 2
   17 CG Schur complement iterations for pressure.
   1 CG iterations for saturation.
   Now at t=0.0653816, dt=0.0327074.


Timestep 3
   17 CG Schur complement iterations for pressure.
   1 CG iterations for saturation.
   Now at t=0.0980651, dt=0.0326836.


...
@endcode

我们可以看到，时间步长从一开始就基本恒定，这表明域中的速度并不强烈依赖于饱和度的变化，尽管它们肯定是通过压力方程中的因子 $\lambda(S)$ 来决定的。

我们的第二个观察结果是，在第一和第二时间步之间，解决压力舒尔补足方程所需的CG迭代次数从22次下降到17次（事实上，在其余的计算中，它保持在17次左右）。原因其实很简单。在我们求解一个时间步长的压力之前，我们没有将 <code>solution</code> 变量重置为零。因此，在我们进入CG求解器时，压力（和其他变量）具有前一个时间步骤的值。由于速度和压力在计算过程中变化不大，前一个时间步骤的压力实际上是对这个时间步骤压力的一个很好的初始猜测。因此，一旦我们计算了一次压力，我们需要的迭代次数就会大大减少。

最后的观察是关于求解饱和度所需的迭代次数，也就是一次。这不应该让我们太惊讶：我们必须解决的矩阵是质量矩阵。然而，这是 $DGQ_0$ 元素的分片常数的质量矩阵，其中没有元素与相邻单元的自由度耦合。因此，该矩阵是一个对角线矩阵，很明显，我们应该能够在一次CG迭代中反转该矩阵。


说了这么多，这里有几个电影，显示了饱和度是如何随时间推移而发展的。首先，这是针对单一裂缝模型的，正如在 <code>SingleCurvingCrack::KInverse</code> 类中实现的那样。

 <img src="https://www.dealii.org/images/steps/developer/step-21.centerline.gif" alt=""> 

可以看出，富水流体主要是沿着域中间的高渗透区蜿蜒前行，而域的其他部分则大部分是不渗透的。这部电影和下一部电影是用 <code>n_refinement_steps=7</code> 生成的，导致 $128\times 128$ 的网格有大约16000个单元和大约66000个未知数。


第二部电影显示了 <code>RandomMedium::KInverse</code> 类的随机介质模型的饱和度，我们有随机分布的高渗透率中心，流体从这些区域中的一个跳到另一个。

 <img src="https://www.dealii.org/images/steps/developer/step-21.random2d.gif" alt=""> 


最后，这里是在三个空间维度上的相同情况，在一个具有 <code>n_refinement_steps=5</code> 的网格上，产生一个大约32000个单元和167000个自由度的网格。

 <img src="https://www.dealii.org/images/steps/developer/step-21.random3d.gif" alt=""> 

要重复这些计算，你所要做的就是改变行数

@code
      TwoPhaseFlowProblem<2> two_phase_flow_problem(0);
@endcode

在主函数中为

@code
      TwoPhaseFlowProblem<3> two_phase_flow_problem(0);
@endcode

可视化采用了云技术，每个单元的饱和度都由彩色但透明的云来表示。这样，人们也可以在一定程度上看到域的深处发生了什么。另一种可视化的方式是显示饱和度随时间变化的等值面。有一些技术可以透明地绘制等值面，这样就可以像洋葱的层次一样同时看到几个等值面。

那么，为什么我们不显示这样的等值面呢？问题在于等值面的计算方式：它们要求要可视化的场是连续的，所以等值面可以通过至少在单个细胞中遵循轮廓线来生成。然而，我们的饱和场是片状常数和不连续的。如果我们想为一个饱和度 $S=0.5$ 绘制一个等值面，那么在这个领域中就很可能没有一个点是真正达到饱和度的。如果我们必须在这种情况下定义等值面，我们将不得不采取细胞之间的界面，其中相邻的两个细胞之一的饱和度大于，另一个细胞的饱和度小于0.5。然而，大多数可视化程序似乎并不具备做这种转换的能力。


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

这个项目有许多可以改进的地方。下面列出了其中的三个。事实上，所有这些问题都在构成当前程序的延续的辅导程序中得到了解决：Step-43。




<h4>Solvers</h4>

目前，该程序并不是特别快：二维随机介质的计算在1000个左右的时间步长中花费了大约一天时间。相应的三维计算在800个时间步骤中几乎花了两天时间。没有比这更快的原因有两个方面。首先，我们在每个时间步骤中都要重建整个矩阵，尽管有些部分如 $B$ 、 $B^T$ 和 $M^S$ 块从未改变。

第二，我们可以在求解器和预处理器方面做得更好。目前，我们用CG方法解决Schur补数 $B^TM^u(S)^{-1}B$ ，使用 $[B^T (\textrm{diag}(M^u(S)))^{-1} B]^{-1}$ 作为预处理程序。应用这个预处理程序是很昂贵的，因为它涉及到每次解决一个线性系统。这可能适合于 @ref
step_20 的 "第20步"，在那里我们只需要解决整个问题一次。然而，在这里我们必须求解数百次，在这种情况下，值得考虑使用一种第一次设置起来比较昂贵，但以后应用起来比较便宜的预处理程序。

一种可能性是意识到我们用作预处理的矩阵， $B^T (\textrm{diag}(M^u(S)))^{-1} B$ 仍然是稀疏的，而且是对称的。如果看一下流场随时间的演变，我们还可以看到，虽然 $S$ 随时间变化很大，但压力几乎没有变化，因此 $B^T (\textrm{diag}(M^u(S)))^{-1} B \approx B^T (\textrm{diag}(M^u(S^0)))^{-1}
B$  。换句话说，第一个时间步骤的矩阵应该是一个很好的前提条件，也适用于所有后来的时间步骤。  通过一些反反复复的操作，实际上并不难得到一个SparseMatrix对象的表示。然后我们可以把它交给SparseMIC类，以形成一个稀疏的不完全Cholesky分解。形成这种分解是很昂贵的，但是我们只需要在第一个时间步骤中做一次，然后就可以在未来把它作为一个廉价的预处理程序。我们甚至可以通过使用SparseDirectUMFPACK类来做得更好，它不仅能产生一个不完整的，而且是一个完整的矩阵分解，这应该会产生一个更好的预处理程序。

最后，为什么使用近似值 $B^T (\textrm{diag}(M^u(S)))^{-1} B$ 来预设 $B^T M^u(S)^{-1} B$ ？后者的矩阵毕竟是压力空间上拉普拉斯算子的混合形式，我们对其使用线性元素。因此，我们可以在直接对应于拉普拉斯的非混合形式的一侧建立一个单独的矩阵 $A^p$ ，例如使用双线性形式 $(\mathbf{K}\lambda(S^n) \nabla
\varphi_i,\nabla\varphi_j)$  。然后我们可以形成这个非混合矩阵的不完全或完全分解，并将其作为混合形式的预处理。

使用这样的技术，可以合理地预期，求解过程将至少快一个数量级。




<h4>Time stepping</h4>

在介绍中，我们已经确定了时间步长的限制

@f[
  \triangle t_{n+1} \le \frac h{|\mathbf{u}^{n+1}(\mathbf{x})|}


@f]

必须是全局性的，即对所有的 $\mathbf x$ 。离散化后，我们通过选择以下方式来满足它

@f[
  \triangle t_{n+1} = \frac {\min_K h_K}{\max_{\mathbf{x}}|\mathbf{u}^{n+1}(\mathbf{x})|}.


@f]



这种对时间步长的限制有些烦人：我们把网格做得越细，时间步长就越小；换句话说，我们受到了两次惩罚：每个时间步长的求解成本更高，我们必须做更多的时间步长。

这一点特别令人讨厌，因为大部分的额外工作是用来解决方程的隐含部分，即压力-速度系统，而正是饱和度的双曲传输方程施加了时间步长的限制。

为了避免这个瓶颈，人们发明了一些方法。例如，他们可能每隔几步时间才重新计算压力-速度场（或者，如果你愿意，对压力/速度和饱和度方程使用不同的时间步长）。这就保持了对廉价显式部分的时间步长限制，而使隐式部分的求解不那么频繁。这个方向的实验当然是值得的；这种方法的一个起点是陈章新、桓冠仁和李宝岩的论文：<i>An improved IMPES method for
two-phase flow in porous media</i>，Transport in Porous Media，54（2004），第361&mdash；376页。当然也有很多其他关于这个主题的论文，但这篇论文前段时间刚好落在我们的桌上。




<h4>Adaptivity</h4>

适应性显然也会有帮助。看一下电影，我们可以清楚地看到，大部分的行动都局限于领域的一个相对较小的部分（这对饱和度来说特别明显，但对速度和压力也是如此）。因此，自适应性可望保持必要的低自由度数量，或者增加精确度。

另一方面，对于时间相关问题的自适应性也不是一件小事：我们必须每隔几个时间步数改变网格，而且每次改变网格时，我们都必须将目前的解决方案传送到下一个网格（SolutionTransfer类可以帮助解决这个问题）。这些并不是无法克服的障碍，但它们确实需要一些额外的编码，而且比我们认为值得打包到这个教程程序中的更多。


examples/step-22/doc/intro.dox

 <br> 

<i>This program was contributed by Martin Kronbichler and Wolfgang
Bangerth.
<br>
This material is based upon work partly supported by the National
Science Foundation under Award No. EAR-0426271 and The California Institute of
Technology. Any opinions, findings, and conclusions or recommendations
expressed in this publication are those of the author and do not
necessarily reflect the views of the National Science Foundation or of The
California Institute of Technology.
</i>




<a name="Intro"></a>

<h1>Introduction</h1>

这个程序处理斯托克斯方程组，其非维度形式如下。

@f{eqnarray*}


  -2\; \textrm{div}\; \varepsilon(\textbf{u}) + \nabla p &=& \textbf{f},
  \\


  -\textrm{div}\; \textbf{u} &=& 0,


@f}

其中 $\textbf u$ 表示流体的速度， $p$ 是其压力， $\textbf f$ 是外力， $\varepsilon(\textbf{u})= \nabla^s{\textbf{u}}= \frac 12 \left[
(\nabla \textbf{u}) + (\nabla \textbf{u})^T\right]$ 是对称梯度的第2级张量；它的分量定义是 $\varepsilon(\textbf{u})_{ij}=\frac
12\left(\frac{\partial u_i}{\partial x_j} + \frac{\partial u_j}{\partial x_i}\right)$  。

斯托克斯方程描述了缓慢移动的粘性流体的稳态运动，如蜂蜜、地幔中的岩石，或其他惯性不起作用的情况。如果流体的运动速度足够快，与粘性摩擦力相比，惯性力很重要，那么斯托克斯方程就不再有效；考虑到惯性效应，就会产生非线性纳维-斯托克斯方程。然而，在这个教程程序中，我们将重点关注更简单的斯托克斯系统。

请注意，在推导更一般的可压缩纳维-斯托克斯方程时，扩散被建模为应力张量的发散。

@f{eqnarray*}
  \tau = - \mu (2\varepsilon(\textbf{u}) - \frac{2}{3}\nabla \cdot \textbf{u} I),


@f}

其中 $\mu$ 是流体的粘度。有了 $\mu=1$ 的假设（假设粘度恒定，通过除以 $\mu$ 使方程非立体化），并假设不可压缩性（ $\textrm{div}\; \textbf{u}=0$ ），我们就可以得出上面的公式。

@f{eqnarray*}
  \textrm{div}\; \tau = -2\textrm{div}\;\varepsilon(\textbf{u}).


@f}

一个不同的公式使用拉普拉斯算子（ $-\triangle \textbf{u}$ ）而不是对称梯度。这里一个很大的区别是，速度的不同分量并不耦合。如果你假定解的额外规律性 $\textbf{u}$ （第二部分导数存在并且是连续的），这些公式是等同的。

@f{eqnarray*}
  \textrm{div}\; \tau
  = -2\textrm{div}\;\varepsilon(\textbf{u})
  = -\triangle \textbf{u} + \nabla \cdot (\nabla\textbf{u})^T
  = -\triangle \textbf{u}.


@f}

这是因为 $i$ 中的第1个条目 $\nabla \cdot (\nabla\textbf{u})^T$ 是由以下内容给出的。

@f{eqnarray*}
[\nabla \cdot (\nabla\textbf{u})^T]_i
= \sum_j \frac{\partial}{\partial x_j} [(\nabla\textbf{u})^T]_{i,j}
= \sum_j \frac{\partial}{\partial x_j} [(\nabla\textbf{u})]_{j,i}
= \sum_j \frac{\partial}{\partial x_j} \frac{\partial}{\partial x_i} \textbf{u}_j
= \sum_j \frac{\partial}{\partial x_i} \frac{\partial}{\partial x_j} \textbf{u}_j
= \frac{\partial}{\partial x_i} \textrm{div}\; \textbf{u}
= 0.


@f}

如果你不能假设上述的规律性，或者你的粘度不是一个常数，那么这个等价关系就不再成立。因此，我们决定在本教程中坚持使用物理上更准确的对称张量公式。


为了得到良好的解决，我们将不得不在方程中加入边界条件。一旦我们讨论方程的微弱形式，哪些边界条件在这里是容易做到的就会变得清晰。

这里所涉及的方程属于矢量值问题的范畴。这个主题的顶层概述可以在 @ref vector_valued 模块中找到。




<h3>Weak form</h3>

通过将其写成矢量形式，可以得到方程的弱形式为

@f{eqnarray*}
  \begin{pmatrix}
    {-2\; \textrm{div}\; \varepsilon(\textbf{u}) + \nabla p}
    \\
    {-\textrm{div}\; \textbf{u}}
  \end{pmatrix}
  =
  \begin{pmatrix}
  {\textbf{f}}
  \\
  0
  \end{pmatrix},


@f}

从左边开始与一个矢量值测试函数 $\phi = \begin{pmatrix}\textbf{v} \\ q\end{pmatrix}$ 形成点积，并在域 $\Omega$ 上进行积分，得到以下一组方程。

@f{eqnarray*}
  (\mathrm v,


   -2\; \textrm{div}\; \varepsilon(\textbf{u}) + \nabla p)_{\Omega}


  -
  (q,\textrm{div}\; \textbf{u})_{\Omega}
  =
  (\textbf{v}, \textbf{f})_\Omega,


@f}

这对所有的测试函数都必须成立  $\phi = \begin{pmatrix}\textbf{v}
\\ q\end{pmatrix}$  。

一般来说，一个好的经验法则是，如果一个人<i>can</i>减少公式中任何变量的导数，那么他<i>should</i>实际上是用部分积分来做。这是由<a
href="https://en.wikipedia.org/wiki/Partial_differential_equation">partial
differential equations</a>的理论引起的，特别是强和<a href="https://en.wikipedia.org/wiki/Weak_solution">weak
solutions</a>之间的区别）。我们已经为拉普拉斯方程做了这个工作，在那里我们对第二导数进行了分项积分，以获得在测试和试验函数上都只有一个导数的弱表述。

在当前情况下，我们对第二项进行分项积分。

@f{eqnarray*}
  (\textbf{v}, -2\; \textrm{div}\; \varepsilon(\textbf{u}))_{\Omega}


  - (\textrm{div}\; \textbf{v}, p)_{\Omega}
  + (\textbf{n}\cdot\textbf{v}, p)_{\partial\Omega}


  -
  (q,\textrm{div}\; \textbf{u})_{\Omega}
  =
  (\textbf{v}, \textbf{f})_\Omega.


@f}

同样地，我们对第一项进行分项积分，得到

@f{eqnarray*}
  (\nabla \textbf{v}, 2\; \varepsilon(\textbf{u}))_{\Omega}


  -
  (\textbf{n} \otimes \textbf{v}, 2\; \varepsilon(\textbf{u}))_{\partial\Omega}


  - (\textrm{div}\; \textbf{v}, p)_{\Omega}
  + (\textbf{n}\cdot\textbf{v}, p)_{\partial\Omega}


  -
  (q,\textrm{div}\; \textbf{u})_{\Omega}
  =
  (\textbf{v}, \textbf{f})_\Omega,


@f}

其中，两个张量值的量之间的标量乘积在此定义为

@f{eqnarray*}
  (\nabla \textbf{v}, 2\; \varepsilon(\textbf{u}))_{\Omega}
  =
  2 \int_\Omega \sum_{i,j=1}^d \frac{\partial v_j}{\partial x_i}
  \varepsilon(\textbf{u})_{ij} \ dx.


@f}

利用这一点，我们现在已经将对我们的变量的要求降低到 $\mathbf u,\mathbf v$ 的一阶导数，而对 $p,q$ 完全没有导数。

因为像 $\nabla\textbf{v}$ 这样的一般张量和 $\varepsilon(\textbf{u})$ 这样的对称张量之间的标量积等于两者的对称形式之间的标量积，我们也可以把上面的双线性形式写成如下。

@f{eqnarray*}
  (\varepsilon(\textbf{v}), 2\; \varepsilon(\textbf{u}))_{\Omega}


  -
  (\textbf{n} \otimes \textbf{v}, 2\; \varepsilon(\textbf{u}))_{\partial\Omega}


  - (\textrm{div}\; \textbf{v}, p)_{\Omega}
  + (\textbf{n}\cdot\textbf{v}, p)_{\partial\Omega}


  -
  (q,\textrm{div}\; \textbf{u})_{\Omega}
  =
  (\textbf{v}, \textbf{f})_\Omega,


@f}

我们将在下一节处理边界条款，但从域条款中已经可以看出

@f{eqnarray*}
  (\varepsilon(\textbf{v}), 2\; \varepsilon(\textbf{u}))_{\Omega}


  - (\textrm{div}\; \textbf{v}, p)_{\Omega}


  -
  (q,\textrm{div}\; \textbf{u})_{\Omega}


@f}

的双线性形式，斯托克斯方程产生一个对称的双线性形式，并因此产生一个对称的（如果是不确定的）系统矩阵。




<h3>Boundary conditions</h3>

 @dealiiVideoLecture{21.5}  （  @dealiiVideoLectureSeeAlso{21.55,21.6,21.65})  。

刚刚导出的弱形式立即为我们提供了施加边界条件的不同可能性。<ol>  <li>  迪里希特速度边界条件。在一个部分 $\Gamma_D\subset\partial\Omega$ ，我们可以对速度 $\textbf u$ 施加迪里希特条件。

    @f{eqnarray*}
        \textbf u = \textbf g_D \qquad\qquad \textrm{on}\ \Gamma_D.
    @f}

    因为测试函数 $\textbf{v}$ 来自解变量的切线空间，我们有 $\textbf{v}=0$ 对 $\Gamma_D$ ，因此有@f{eqnarray*}


      -(\textbf{n} \otimes \mathrm
        v, 2\; \varepsilon(\textbf{u}))_{\Gamma_D}
      +
      (\textbf{n}\cdot\textbf{v}, p)_{\Gamma_D}
      = 0.
    @f}。

    换句话说，像往常一样，强加的边界值并没有出现在弱形式中。

    值得注意的是，如果我们在整个边界上施加迪里希特边界值，那么压力就只能确定到一个常数。这方面的算法实现将使用类似于步骤11中的工具。

 <li>  诺伊曼型或自然边界条件。在边界的其余部分 $\Gamma_N=\partial\Omega\backslash\Gamma_D$ ，让我们把边界条款重新写成如下。     @f{eqnarray*}


      -(\textbf{n} \otimes \mathrm
        v, 2\; \varepsilon(\textbf{u}))_{\Gamma_N}
      +
      (\textbf{n}\cdot\textbf{v}, p)_{\Gamma_N}
      &=&
      \sum_{i,j=1}^d


      -(n_i v_j, 2\; \varepsilon(\textbf{u})_{ij})_{\Gamma_N}
      +
      \sum_{i=1}^d
      (n_i v_i, p)_{\Gamma_N}
      \\
      &=&
      \sum_{i,j=1}^d


      -(n_i v_j, 2\; \varepsilon(\textbf{u})_{ij})_{\Gamma_N}
      +
      \sum_{i,j=1}^d
      (n_i v_j, p \delta_{ij})_{\Gamma_N}
      \\
      &=&
      \sum_{i,j=1}^d
      (n_i v_j,p \delta_{ij} - 2\; \varepsilon(\textbf{u})_{ij})_{\Gamma_N}
      \\
      &=&
      (\textbf{n} \otimes \textbf{v},
      p \textbf{I} - 2\; \varepsilon(\textbf{u}))_{\Gamma_N}.
      \\
      &=&
      (\textbf{v},
       \textbf{n}\cdot [p \textbf{I} - 2\; \varepsilon(\textbf{u})])_{\Gamma_N}.
    @f}

    换句话说，在边界的诺伊曼部分，我们可以规定总应力的数值。     @f{eqnarray*}
      \textbf{n}\cdot [p \textbf{I} - 2\; \varepsilon(\textbf{u})]
      =
      \textbf g_N \qquad\qquad \textrm{on}\ \Gamma_N.
    @f}

    如果边界被细分为Dirichlet和Neumann部分  $\Gamma_D,\Gamma_N$  ，这就导致了以下弱形式。     @f{eqnarray*}
      (\varepsilon(\textbf{v}), 2\; \varepsilon(\textbf{u}))_{\Omega}


      - (\textrm{div}\; \textbf{v}, p)_{\Omega}


      -
      (q,\textrm{div}\; \textbf{u})_{\Omega}
      =
      (\textbf{v}, \textbf{f})_\Omega


      -
      (\textbf{v}, \textbf g_N)_{\Gamma_N}.
    @f}




 <li>  罗宾式边界条件。罗宾式边界条件是迪里切特和诺伊曼边界条件的混合物。它们将读作@f{eqnarray*}
      \textbf{n}\cdot [p \textbf{I} - 2\; \varepsilon(\textbf{u})]
      =
      \textbf S \textbf u \qquad\qquad \textrm{on}\ \Gamma_R,
    @f}。

    有一个等级2的张量（矩阵）  $\textbf S$  。相关的弱形式是@f{eqnarray*}
      (\varepsilon(\textbf{v}), 2\; \varepsilon(\textbf{u}))_{\Omega}


      - (\textrm{div}\; \textbf{v}, p)_{\Omega}


      -
      (q,\textrm{div}\; \textbf{u})_{\Omega}
      +
      (\textbf S \textbf u, \textbf{v})_{\Gamma_R}
      =
      (\textbf{v}, \textbf{f})_\Omega.
    @f} 。



 <li>  部分边界条件。可以通过只对速度的某些分量强制执行Dirichlet和Neumann边界条件来结合它们。例如，施加人工边界条件的一种方法是要求流动垂直于边界，即切向分量 $\textbf u_{\textbf t}=(\textbf
    1-\textbf n\otimes\textbf n)\textbf u$ 为零，从而约束速度的 <code>dim</code> -1分量。剩下的分量可以通过要求法向应力的法向分量为零来约束，产生以下一组边界条件。     @f{eqnarray*}
      \textbf u_{\textbf t} &=& 0,
      \\
      \textbf n \cdot \left(\textbf{n}\cdot [p \textbf{I} - 2\;
      \varepsilon(\textbf{u})] \right)
      &=&
      0.
    @f}



    另一种情况是当人们希望流动是<i>parallel</i>而不是垂直于边界时（在deal.II中， VectorTools::compute_no_normal_flux_constraints 函数可以为你这样做）。这种情况经常发生在自由边界的问题上（例如，在河流或湖泊的表面，如果流动的垂直力不足以使表面实际变形），或者如果边界对流体没有施加明显的摩擦力（例如，在地幔和地核的界面上，两种流体因密度不同而相遇，但它们的粘度都很小，不会对彼此产生很大的切向应力）。     在公式中，这意味着@f{eqnarray*}
      \textbf{n}\cdot\textbf u &=& 0,
      \\
      (\textbf 1-\textbf n\otimes\textbf n)
      \left(\textbf{n}\cdot [p \textbf{I} - 2\;
      \varepsilon(\textbf{u})] \right)
      &=&
      0,
    @f}

    第一个条件（需要强加）固定了速度的一个分量，第二个条件（将在弱形式下强制执行）固定了其余的两个分量。   </ol> 

尽管有这么多的可能性，我们在这个教程程序中只使用迪里希特和（同质）诺伊曼边界条件。




<h3>Discretization</h3>

如上所述，在 $\Gamma_D$ 和 $\Gamma_N$ 上有迪里希特和诺伊曼边界条件的方程的弱形式是这样的：找到 $\textbf u\in \textbf V_g = \{\varphi \in H^1(\Omega)^d: \varphi_{\Gamma_D}=\textbf
g_D\}, p\in Q=L^2(\Omega)$ ，以便

@f{eqnarray*}
  (\varepsilon(\textbf{v}), 2\; \varepsilon(\textbf{u}))_{\Omega}


  - (\textrm{div}\; \textbf{v}, p)_{\Omega}


  -
  (q,\textrm{div}\; \textbf{u})_{\Omega}
  =
  (\textbf{v}, \textbf{f})_\Omega


  -
  (\textbf{v}, \textbf g_N)_{\Gamma_N}


@f}

为所有测试函数  $\textbf{v}\in \textbf V_0 = \{\varphi \in H^1(\Omega)^d: \varphi_{\Gamma_D}=0\},q\in
Q$  。

这些方程代表一个对称的<a
href="https://en.wikipedia.org/wiki/Ladyzhenskaya%E2%80%93Babu%C5%A1ka%E2%80%93Brezzi_condition">saddle
point problem</a>。众所周知，那么只有当我们寻找解决方案的函数空间必须满足某些条件时，解决方案才会存在，这些条件通常被称为Babuska-Brezzi或Ladyzhenskaya-Babuska-Brezzi（LBB）条件。上面的连续函数空间满足这些条件。然而，当我们将方程离散化，用有限维空间中的有限元函数取代连续变量和检验函数 $\textbf V_{g,h}\subset \textbf V_g,
Q_h\subset Q$ 时，我们必须确保 $\textbf V_h,Q_h$ 也满足LBB条件。这与我们在第20步中要做的事情类似。

对于斯托克斯方程，有许多可能的选择来确保有限元空间与LBB条件兼容。一个简单而准确的选择是 $\textbf u_h\in Q_{p+1}^d,
p_h\in Q_p$ ，即对速度使用比压力高一阶的元素。

这就导致了以下的离散问题：找到 $\textbf u_h,p_h$ ，以便于

@f{eqnarray*}
  (\varepsilon(\textbf{v}_h), 2\; \varepsilon(\textbf u_h))_{\Omega}


  - (\textrm{div}\; \textbf{v}_h, p_h)_{\Omega}


  -
  (q_h,\textrm{div}\; \textbf{u}_h)_{\Omega}
  =
  (\textbf{v}_h, \textbf{f})_\Omega


  -
  (\textbf{v}_h, \textbf g_N)_{\Gamma_N}


@f}

为所有测试函数  $\textbf{v}_h, q_h$  。组装与此问题相关的线性系统遵循  @ref step_20  "步骤-20"、步骤-21中使用的相同路线，并在  @ref
vector_valued  模块中详细解释。




<h3>Linear solver and preconditioning issues</h3>

离散方程的微弱形式自然导致了以下速度场和压力场的节点值的线性系统。

@f{eqnarray*}
  \left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)
  \left(\begin{array}{c}
    U \\ P
  \end{array}\right)
  =
  \left(\begin{array}{c}
    F \\ G
  \end{array}\right),


@f}

与第20步和第21步一样，我们将通过形成舒尔补数来解决这个方程组，也就是说，我们将首先找到 $P$ 的解。

@f{eqnarray*}
  BA^{-1}B^T P &=& BA^{-1} F - G, \\


@f}

然后

@f{eqnarray*}
  AU &=& F - B^TP.


@f}

我们这样做的方式与我们在以前的这些教程程序中做的差不多，也就是说，我们再次使用相同的类 <code>SchurComplement</code> 和 <code>InverseMatrix</code> 。然而，有两个显著的区别。

<ol>  <li>  首先，在混合拉普拉斯方程中，我们必须处理如何对舒尔补数 $B^TM^{-1}B$ 进行预处理的问题，它在谱上等同于压力空间上的拉普拉斯算子（因为 $B$ 代表梯度算子， $B^T$ 代表其邻接算子 $-\textrm{div}$ ，而 $M$ 代表身份（直到材料参数 $K^{-1}$ 为止），因此 $B^TM^{-1}B$ 类似于 $-\textrm{div} \mathbf 1 \nabla = -\Delta$ ）。因此，对于小的网格尺寸来说，矩阵的条件很差，我们不得不为Schur补数提出一个精心设计的预处理方案。

 <li>  其次，每次我们与 $B^TM^{-1}B$ 相乘时，我们必须用质量矩阵 $M$ 来解决。然而，这并不特别困难，因为质量矩阵总是有很好的条件的，所以使用CG和一点点预处理就能简单地反转。  换句话说， </ol> 的内部求解器的预处理很简单，而 $B^TM^{-1}B$ 的外部求解器的预处理很复杂。

在这里，情况几乎完全相反。差异源于这样一个事实，即舒尔补码的核心矩阵不是来自身份算子，而是来自拉普拉斯算子的一个变体， $-\textrm{div} \nabla^s$ （其中 $\nabla^s$ 是对称梯度），作用于一个矢量场。在对这个问题的研究中，我们主要遵循D. Silvester和A. Wathen的论文。"稳定的斯托克斯系统的快速迭代解第二部分。使用一般块状先决条件"。(SIAM J. Numer.Anal., 31 (1994), pp. 1352-1367)，可在线查阅<a
href="http://siamdl.aip.org/getabs/servlet/GetabsServlet?prog=normal&id=SJNAAM000031000005001352000001&idtype=cvips&gifs=Yes" target="_top">here</a>。主要来说，舒尔补码的核心矩阵的差异有两个后果。

<ol>  <li>  首先，它使外部预处理变得简单：Schur补数对应于压力空间上的算子 $-\textrm{div} (-\textrm{div} \nabla^s)^{-1}
\nabla$ ；忘记我们处理的是对称梯度而不是常规梯度的事实，Schur补数类似于 $-\textrm{div} (-\textrm{div} \nabla)^{-1} \nabla =


-\textrm{div} (-\Delta)^{-1} \nabla$ ，即使在数学上不完全简明，在光谱上也等同于身份算子（一个启发式的论证是将算子换算成 $-\textrm{div}(-\Delta)^{-1} \nabla = -\textrm{div}\nabla(-\Delta)^{-1} =


-\Delta(-\Delta)^{-1} = \mathbf 1$ ）。事实证明，用CG方法直接解决这个Schur补数并不容易：在没有预处理的情况下，Schur补数矩阵的条件数取决于最大和最小单元的大小比，而且仍然需要50-100次CG迭代。然而，有一个简单的解决办法：用压力空间上的质量矩阵进行预处理，我们就可以减少到5-15次CG迭代，几乎不受网格结构的影响（看看这个程序的<a href="#Results">results section</a>，可以看到CG迭代的数量确实不会随着我们细化网格而改变）。

因此，除了我们已经有的东西之外，我们需要的是压力变量上的质量矩阵，我们将把它存储在一个单独的对象中。




 <li>  虽然与第20步讨论的混合拉普拉斯情况相比，外部预调节器变得简单了，但内部求解器的问题却变得更加复杂。在混合拉普拉斯离散化中，舒尔补数的形式为  $B^TM^{-1}B$  。因此，每当我们与舒尔补码相乘时，我们必须解决一个线性系统 $M_uz=y$ ；然而，这并不太复杂，因为压力空间上的质量矩阵 $M_u$ 是有条件的。


另一方面，对于我们这里考虑的斯托克斯方程，舒尔补码是 $BA^{-1}B^T$ ，其中矩阵 $A$ 与拉普拉斯算子有关（事实上，它是对应于双线性形式 $(\nabla^s \varphi_i, \nabla^s\varphi_j)$ 的矩阵）。因此，用 $A$ 求解要复杂得多：矩阵的条件很差，我们知道我们需要很多迭代，除非我们有一个非常好的预处理程序。更糟糕的是，我们每次与舒尔补码相乘时都要用 $A$ 求解，使用上述的预处理程序需要5-15次。

因为我们必须多次用 $A$ 求解，所以多花一次时间为这个矩阵创建一个好的预处理程序是值得的。所以我们要做的是：如果在2d中，我们使用终极预处理程序，即矩阵的直接稀疏LU分解。这是用SparseDirectUMFPACK类实现的，它使用UMFPACK直接求解器来计算分解。要使用它，你必须建立支持UMFPACK的deal.II（这是默认的）；参见<a href="../../readme.html#optional-software">ReadMe file</a>中的说明。有了它，内解器在一次迭代中就能收敛。

在2D中，我们可以做这种事情，因为即使是合理的大问题，也很少有超过100,000个未知数的，每行的非零项相对较少。此外，2D中矩阵的带宽是 ${\cal
O}(\sqrt{N})$ ，因此是中等的。对于这样的矩阵，稀疏因子可以在几秒钟内计算出来。作为参考，计算一个大小为 $N$ 、带宽为 $B$ 的矩阵的稀疏因子需要 ${\cal
O}(NB^2)$ 次操作。在2d中，这是 ${\cal O}(N^2)$ ；尽管这比例如组装线性系统的复杂度要高，后者需要 ${\cal
O}(N)$ ，但计算分解的常数非常小，直到我们达到非常大的未知数%，甚至更多，它才成为整个程序中的主导因素）。)

情况在3D中发生了变化，因为在那里我们很快就会有更多的未知数，而且矩阵的带宽（决定了稀疏LU因子中非零项的数量）是 ${\cal O}(N^{2/3})$ ，而且每行也有很多条目。这使得像UMFPACK这样的稀疏直接求解器的效率很低：只有在问题规模为10,000到100,000个未知数时，才能用合理的时间和内存资源计算稀疏分解。

在这种情况下，我们要做的是使用一个不完整的LU分解（ILU）作为预处理，而不是实际计算完整的LU因子。恰好，deal.II有一个类可以做到这一点。SparseILU。计算ILU所需要的时间只取决于稀疏矩阵中的非零项的数量（或者说我们愿意填入LU因子，如果这些非零项应该多于矩阵中的非零项），但与矩阵的带宽无关。因此，这也是一个可以有效地在三维中计算的操作。另一方面，根据定义，一个不完整的LU分解并不代表矩阵的精确逆  $A$  。因此，与稀疏直接求解器的预处理不同，用ILU进行预处理仍然需要一次以上的迭代。因此，当与舒尔补码相乘时，内解器将花费更多时间：这是一个不可避免的权衡。   </ol> 

在下面的程序中，我们将利用SparseILU和SparseDirectUMFPACK类具有非常相似的接口，可以互换使用的事实。我们所需要的是一个开关类，根据维度的不同，提供一个类型，即上述两个类中的任何一个。我们就是这样做的。

@code
template <int dim>
struct InnerPreconditioner;


template <>
struct InnerPreconditioner<2>
{
  using type = SparseDirectUMFPACK;
};


template <>
struct InnerPreconditioner<3>
{
  using type = SparseILU<double>;
};
@endcode



从这里开始，我们可以引用<code>typename  InnerPreconditioner@<dim@>::%type</code> 这个类型，并自动得到正确的预处理程序类。由于这两个类的接口相似，我们将能够在所有地方使用相同的语法来互换使用它们。




<h4> Is this how one should solve the Stokes equations? </h4>

上面的讨论显示了解决由斯托克斯方程产生的线性系统的*种方式，由于辅导程序是教学工具，这是有意义的。但这是解决这个方程组的**方式吗？

这个问题的答案是否定的。上面已经指出了这个方法的主要瓶颈，就是我们必须反复求解Schur补数内的 $A$ 线性系统，由于我们没有一个好的Schur补数的预处理程序，这些求解就不得不经常发生。一个更好的方法是使用块分解，这是基于Silvester和Wathen  @cite SW94 的观察，在 @cite elman2005 中有更详细的解释。下面在本程序的结果部分的a <a href="#block-schur">block Schur
complementation preconditioner</a>一节中讨论了这种替代方法的实现。




<h4> A note on the structure of the linear system </h4>

以上，我们已经声称线性系统的形式是

@f{eqnarray*}
  \left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)
  \left(\begin{array}{cc}
    U \\ P
  \end{array}\right)
  =
  \left(\begin{array}{cc}
    F \\ G
  \end{array}\right),


@f}

即，特别是在矩阵的右下方有一个零块。这样，我们就可以把舒尔补码写成 $S=B A^{-1} B^T$  。但这并不完全正确。

想一想，如果对某些压力变量有约束会怎样（见 @ref constraints "自由度的约束 "文件模块），例如因为我们使用自适应细化网格和连续压力有限元，所以会有悬挂节点。造成这种约束的另一个原因是压力的迪里希特边界条件。然后，AffineConstraints类，在将矩阵的局部贡献复制到全局线性系统时，会将对应于受限自由度的行和列清零，并在对角线上放一个正条目。为了简单起见，你可以认为这个条目是1，尽管实际上它是一个与其他矩阵条目相同数量级的值）。换句话说，右下角区块其实根本不是空的：它在对角线上有几个条目，每个受限的压力自由度都有一个，对我们要解决的线性系统的正确描述是，它的形式如下

@f{eqnarray*}
  \left(\begin{array}{cc}
    A & B^T \\ B & D_c
  \end{array}\right)
  \left(\begin{array}{cc}
    U \\ P
  \end{array}\right)
  =
  \left(\begin{array}{cc}
    F \\ G
  \end{array}\right),


@f}

其中 $D_c$ 是零矩阵，除了受限自由度的正对角线项。那么正确的舒尔补码实际上是矩阵 $S = B A^{-1} B^T - D_c $ ，而不是上面说的那个。

思考这个问题使我们，首先，意识到所得到的舒尔补数现在是不确定的，因为 $B A^{-1} B^T$ 是对称的和正定的，而 $D_c$ 是正半定的，从前者减去后者可能不再是正定的。这很烦人，因为我们不能再对这个真正的舒尔补数采用共轭梯度法。也就是说，我们可以在 AffineConstraints::distribute_local_to_global() 中通过简单地将*负*值放在受限压力变量的对角线上来解决这个问题--因为我们实际上只是放了一些非零的东西来确保结果矩阵不是奇异的；我们真的不关心那个条目是正还是负。因此，如果 $D_c$ 的对角线上的条目是负的，那么 $S$ 将再次成为一个对称的正定矩阵。

但是，其次，下面的代码实际上并没有做这些事。它很高兴地用错误的Schur补码 $S = B A^{-1} B^T$ 来解决线性系统，完全忽略了这个问题。为什么会这样呢？为了理解为什么会这样，回顾一下，当把局部贡献写入全局矩阵时， AffineConstraints::distribute_local_to_global() 把对应于受限自由度的行和列置零。这意味着 $B$ 有一些零行， $B^T$ 零列。因此，如果要乘出 $S$ 的条目是什么，就会发现它的所有受限压力自由度的行和列都是零，包括对角线上的一个零。 $D_c$ 的非零条目将正好适合于这些零对角线位置，并确保 $S$ 是可逆的。不这样做，严格来说，意味着 $S$ 仍然是单数。它在非约束压力自由度子集上是对称和正定的，而在约束压力上只是一个零矩阵。为什么共轭梯度法对这个矩阵有效？因为 AffineConstraints::distribute_local_to_global() 也确保了对应于矩阵这些零行的右手边条目*也是零，也就是说，右手边是兼容的。

这意味着无论这些受限压力自由度的解向量的值是多少，这些行的残差总是为零，如果考虑到CG算法的内部操作，就永远不会对解向量产生任何更新。换句话说，CG算法只是*忽略*这些行，尽管矩阵是单数。这只是因为这些自由度与线性系统的其他部分完全解耦（因为整个行和相应的列都是零）。在求解过程结束时，求解向量中的受限压力值仍然和我们开始调用求解器时一模一样；当我们在CG求解器完成后调用 AffineConstraints::distribute() 时，它们最终被正确的值所覆盖。

这个讨论的结果是，大矩阵的右下角块为零的假设有点简化，但仅仅按照这个假设，实际上并没有导致任何值得解决的实际问题。




<h3>The testcase</h3>

我们下面实现的域、右手边和边界条件与地球物理学中的一个问题有关：在那里，人们想计算大洋中裂缝下地球内部岩浆的流动场。裂缝是两个大陆板块非常缓慢地漂移开来的地方（每年最多几厘米），在地壳上留下一个裂缝，被下面的岩浆填充。在不试图完全现实的情况下，我们通过求解域 $\Omega=[-2,2]\times[0,1]\times[-1,0]$ 上的以下一组方程和边界条件来模拟这种情况。

@f{eqnarray*}


  -2\; \textrm{div}\; \varepsilon(\textbf{u}) + \nabla p &=& 0,
  \\


  -\textrm{div}\; \textbf{u} &=& 0,
  \\
  \mathbf u &=&   \left(\begin{array}{c}


    -1 \\ 0 \\0
  \end{array}\right)
  \qquad\qquad \textrm{at}\ z=0, x<0,
  \\
  \mathbf u &=&   \left(\begin{array}{c}
    +1 \\ 0 \\0
  \end{array}\right)
  \qquad\qquad \textrm{at}\ z=0, x>0,
  \\
  \mathbf u &=&   \left(\begin{array}{c}
    0 \\ 0 \\0
  \end{array}\right)
  \qquad\qquad \textrm{at}\ z=0, x=0,


@f}

并在其他地方使用自然边界条件 $\textbf{n}\cdot [p \textbf{I} - 2
\varepsilon(\textbf{u})] = 0$ 。换句话说，在顶面的左边部分，我们规定流体以速度 $-1$ 随大陆板向左移动，在顶面的右边部分向右移动，并在其他地方施加自然流动条件。如果我们在2d中，描述基本上是相同的，只是我们省略了上述所有矢量的第二部分。

正如在<a href="#Results">results section</a>中会变得很明显的那样，流场将从下面拉动材料，并将其移动到域的左右两端，这是预期的。速度边界条件的不连续性将在顶面中心产生一个压力奇点，将材料一直吸到顶面，以填补材料在此位置向外运动所留下的缺口。




<h3>Implementation</h3>

<h4>Using imhomogeneous constraints for implementing Dirichlet boundary conditions</h4>

在之前的所有教程程序中，我们仅仅使用AffineConstraints对象来处理悬挂节点约束（步骤11除外）。然而，这个类也可以用来实现Dirichlet边界条件，正如我们将在这个程序中展示的，通过固定一些节点值  $x_i = b_i$  。注意，这些是不均匀约束，我们要特别注意一些。我们要实现的方法是，首先通过调用AffineConstraints对象读入边界值

@code
  VectorTools::interpolate_boundary_values (dof_handler,
                                            1,
                                            BoundaryValues<dim>(),
                                            constraints);
@endcode



非常类似于我们之前制作边界节点列表的方式（注意，我们只在边界标志为1的边界上设置Dirichlet条件）。然后边界值的实际应用由AffineConstraints对象直接处理，没有任何额外的干扰。

然后我们可以像以前一样进行，即通过填充矩阵，然后在约束对象上调用一个浓缩函数，其形式为

@code
  constraints.condense (system_matrix, system_rhs);
@endcode



请注意，我们在系统矩阵和系统右侧同时调用，因为解决不均匀约束需要对矩阵条目和右侧的知识。但出于效率的考虑，我们选择了另一种策略：所有收集在AffineConstraints对象中的约束都可以在将本地数据写入全局矩阵的同时得到解决，方法是使用调用

@code
  constraints.distribute_local_to_global (local_matrix, local_rhs,
                                          local_dof_indices,
                                          system_matrix, system_rhs);
@endcode



这个技术在step-27教程程序中进一步讨论。我们在这里需要知道的是，这个函数同时做了三件事：它把局部数据写入全局矩阵和右手边，它分布了悬挂的节点约束，另外还实现了（不均匀的）迪里切特边界条件。这很好，不是吗？

我们可以得出结论，AffineConstraints类提供了一个替代使用 MatrixTools::apply_boundary_values 来实现Dirichlet边界条件的方法。


<a name="constraint-matrix">


<h4>Using AffineConstraints for increasing performance</h4><h4>Using AffineConstraints for increasing performance</h4>
</a> 。

通常，稀疏矩阵包含大量的元素，当我们要开始线性求解时，这些元素实际上是零。这样的元素是在我们消除约束条件或实现Dirichlet条件时引入的，我们通常会删除受约束行和列中的所有条目，即把它们设置为零。对于本教程程序中所考虑的三维应用，存在于稀疏模式中但并不真正包含任何信息的那部分元素，可以达到矩阵中元素总数的四分之一。请记住，矩阵-向量乘积或预处理程序对稀疏矩阵的所有元素（甚至那些为零的元素）进行操作，这是我们在这里要避免的低效率。

直接解决约束自由度的一个好处是，我们可以避免在我们的稀疏矩阵中出现大部分要为零的条目&mdash；在矩阵构建过程中，我们不需要约束的条目（与传统算法相反，传统算法是先填充矩阵，之后才解决约束）。这将在形成矩阵-向量乘积时节省内存和时间。我们要做的是将约束信息传递给生成稀疏模式的函数，然后设置一个<tt>false</tt>参数，指定我们不打算使用约束条目。

@code
  DoFTools::make_sparsity_pattern (dof_handler, sparsity_pattern,
                                   constraints, false);
@endcode

顺便说一下，这个函数也避免了对稀疏模式的<tt>condense()</tt>函数的调用。




<h4>Performance optimizations</h4>

下面开发的程序已经看到了很多的TLC。我们在分析工具（主要是<a
href="http://www.valgrind.org/">valgrind</a>的cachegrind和callgrind工具，以及用于可视化的KDE<a
href="http://kcachegrind.sourceforge.net/">KCachegrind</a>程序）下一遍又一遍地运行它，看看瓶颈在哪里。这已经得到了回报：通过这种努力，当考虑到细化周期0到3的运行时间时，程序的速度已经提高了大约4倍，将CPU指令的总体执行数量从869,574,060,348减少到199,853,005,625。对于更高的细化水平，收益可能更大，因为一些不是 ${\cal O}(N)$ 的算法被取消了。

基本上，目前程序中有两种算法不随自由度数量的增加而线性扩展：自由度的重新编号（即 ${\cal O}(N \log N)$  ，以及线性求解器（即 ${\cal O}(N^{4/3})$  ）。至于第一个，虽然自由度的重新排序可能不是线性扩展，但它是整个算法中不可缺少的部分，因为它极大地提高了稀疏ILU的质量，很容易弥补计算重新编号的时间；证明这一点的图表和时间显示在DoFRenumbering命名空间的文档中，也强调了下面选择的Cuthill-McKee重新排序算法。

至于线性求解器：如上所述，我们在这里的实现使用了Schur补码公式。这不一定是非常好的选择，但展示了deal.II中的各种重要技术。关于哪种求解器最好的问题，在本程序的<a
href="#improved-solver">section on improved solvers in the results part</a>中再次进行了讨论，同时还有显示备选求解器的代码和对其结果的比较。

除此以外，在这个程序的创建过程中，许多其他的算法也被测试和改进。例如，在建立稀疏性模式时，我们最初使用了一个（现在已经不存在了）BlockCompressedSparsityPattern对象，每次增加一个元素；然而，它的数据结构对于我们在3d中离散化所产生的每行大量的非零条目来说适应性很差，导致了一个二次方的行为。替换deal.II中的内部算法，一次设置许多元素，并使用BlockCompressedSimpleSparsityPattern（截至2015年初，它又被BlockDynamicSparsityPattern取代）作为一个更好的适应性数据结构，消除了这个瓶颈，代价是内存消耗略高。同样，SparseILU类中的分解步骤的实现也非常低效，已经被一个快10倍的步骤所取代。甚至SparseILU的vmult函数也得到了改进，节省了大约20%的时间。小的改进在这里和那里被应用。此外，AffineConstraints对象被用来消除稀疏矩阵中很多最终将为零的条目，见<a href="#constraint-matrix">the section on using advanced
features of the AffineConstraints class</a>。

这里显示了在3D的细化周期0到3中，CPU指令在程序中各个不同的地方花费了多少的概况。

 <img src="https://www.dealii.org/images/steps/developer/step-22.profile-3.png" alt=""> 

可以看出，在这个细化级别，大约四分之三的指令数花在实际求解上（左边的 SparseILU::vmult 调用，中间的 SparseMatrix::vmult 调用用于舒尔补码求解，另一个方框代表在求解<i>U</i>时与稀疏ILU和稀疏矩阵的乘法）。大约五分之一的指令数用于矩阵装配和稀疏ILU计算（右下角的方框），其余的用于其他方面。由于 SparseILU::vmult 调用中的浮点运算通常比矩阵装配中的许多逻辑运算和查表要长得多，矩阵装配所占用的运行时间的比例实际上大大低于指令的比例，这在我们在结果部分的比较中会变得很明显。

对于更高的细化水平，代表求解器的方框以及右上角源自重排算法的蓝色方框将以牺牲程序的其他部分为代价而增长，因为它们不是线性扩展。在这个中等细化水平（3168个单元和93176个自由度），线性求解器已经占了大约四分之三的指令，这是一个很好的迹象，说明这个程序中使用的大多数算法都是经过良好调整的，加快程序速度的主要改进很可能不是来自手工优化的个别方面，而是通过改变求解器的算法。我们将在下面的结果讨论中也讨论这一点。

最后一点，作为参考，下图也显示了在优化这个程序的早期阶段，配置文件的样子。

 <img src="https://www.dealii.org/images/steps/developer/step-22.profile-3.original.png" alt=""> 

如上所述，这个版本的运行时间大约是第一个配置文件的四倍，其中SparseILU分解占用了大约30%的指令数，而操作早期低效版本的DynamicSparsityPattern大约占10%。这两个瓶颈后来都被完全消除了。


examples/step-22/doc/results.dox

<a name="Results"></a>

<h1>Results</h1>

<h3>Output of the program and graphical visualization</h3>

<h4>2D calculations</h4>

在 <code>main</code> 函数中空间维度设置为2的情况下运行程序，会产生以下输出（在 "释放模式 "下， @dealiiVideoLectureSeeAlso{18}): ）。

@code
examples/\step-22> make run
Refinement cycle 0
   Number of active cells: 64
   Number of degrees of freedom: 679 (594+85)
   Assembling...
   Computing preconditioner...
   Solving...  11 outer CG Schur complement iterations for pressure


Refinement cycle 1
   Number of active cells: 160
   Number of degrees of freedom: 1683 (1482+201)
   Assembling...
   Computing preconditioner...
   Solving...  11 outer CG Schur complement iterations for pressure


Refinement cycle 2
   Number of active cells: 376
   Number of degrees of freedom: 3813 (3370+443)
   Assembling...
   Computing preconditioner...
   Solving...  11 outer CG Schur complement iterations for pressure


Refinement cycle 3
   Number of active cells: 880
   Number of degrees of freedom: 8723 (7722+1001)
   Assembling...
   Computing preconditioner...
   Solving...  11 outer CG Schur complement iterations for pressure


Refinement cycle 4
   Number of active cells: 2008
   Number of degrees of freedom: 19383 (17186+2197)
   Assembling...
   Computing preconditioner...
   Solving...  11 outer CG Schur complement iterations for pressure


Refinement cycle 5
   Number of active cells: 4288
   Number of degrees of freedom: 40855 (36250+4605)
   Assembling...
   Computing preconditioner...
   Solving...  11 outer CG Schur complement iterations for pressure
@endcode



上述整个计算在一台相当快的（以2015年的标准）机器上需要大约2秒。

我们立即看到的是，（外部）迭代的次数并没有随着我们细化网格而增加。这证实了介绍中的说法，即用质量矩阵对Schur补码进行预处理，确实可以得到一个与身份矩阵频谱等价的矩阵（即特征值上下受限，与网格大小或单元的相对大小无关）。换句话说，质量矩阵和Schur补码在光谱上是等价的。

在下面的图片中，我们展示了程序中前六个细化步骤的网格。  观察一下网格是如何在解迅速变化的区域被细化的。在上边界，我们的迪里希特边界条件在左半边是-1，右半边是1，所以在 $x=0$ 有一个突然的变化。同样地，在两个上角也有从Dirichlet到Neumann数据的变化，所以那里也需要细化。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.2d.mesh-0.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.2d.mesh-1.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.2d.mesh-2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.2d.mesh-3.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.2d.mesh-4.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.2d.mesh-5.png" alt="">
    </td>
  </tr>
</table> 

最后，下面是一个流场图。它显示了流体随着上层边界的移动而被来自下层的物质所取代。

 <img src="https://www.dealii.org/images/steps/developer/step-22.2d.solution.png" alt=""> 

该图使用了基于VTK的可视化程序的能力（在这种情况下是VisIt）来显示矢量数据；这是我们将使用中的有限元的速度分量声明为一组矢量分量，而不是本教程程序的 <code>StokesProblem@<dim@>::%output_results</code> 函数中的独立标量分量的结果。




<h4>3D calculations</h4>

在3D中，程序的屏幕输出看起来像这样。

@code
Refinement cycle 0
   Number of active cells: 32
   Number of degrees of freedom: 1356 (1275+81)
   Assembling...
   Computing preconditioner...
   Solving...  13 outer CG Schur complement iterations for pressure.


Refinement cycle 1
   Number of active cells: 144
   Number of degrees of freedom: 5088 (4827+261)
   Assembling...
   Computing preconditioner...
   Solving...  14 outer CG Schur complement iterations for pressure.


Refinement cycle 2
   Number of active cells: 704
   Number of degrees of freedom: 22406 (21351+1055)
   Assembling...
   Computing preconditioner...
   Solving...  14 outer CG Schur complement iterations for pressure.


Refinement cycle 3
   Number of active cells: 3168
   Number of degrees of freedom: 93176 (89043+4133)
   Assembling...
   Computing preconditioner...
   Solving...  15 outer CG Schur complement iterations for pressure.


Refinement cycle 4
   Number of active cells: 11456
   Number of degrees of freedom: 327808 (313659+14149)
   Assembling...
   Computing preconditioner...
   Solving...  15 outer CG Schur complement iterations for pressure.


Refinement cycle 5
   Number of active cells: 45056
   Number of degrees of freedom: 1254464 (1201371+53093)
   Assembling...
   Computing preconditioner...
   Solving...  14 outer CG Schur complement iterations for pressure.
@endcode



我们再次看到，随着我们对网格的细化，外迭代的次数并没有增加。然而，计算时间明显增加：对于上述每个迭代分别需要约0.14秒、0.63秒、4.8秒、35秒、2分33秒和13分12秒。这种运行时间的整体超线性（未知数的数量）增加是由于我们的内部求解器不是 ${\cal O}(N)$ ：一个简单的实验表明，随着我们不断细化网格，反演速度-速度块 $A$ 的ILU预处理的CG平均迭代次数会增加。

我们将解决如何可能改进我们的解算器<a
href="#improved-solver">below</a>的问题。

至于图形输出，在解决过程中产生的网格看起来如下。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d.mesh-0.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d.mesh-1.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d.mesh-2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d.mesh-3.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d.mesh-4.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d.mesh-5.png" alt="">
    </td>
  </tr>
</table> 

同样，它们基本上显示了由边界条件引入的奇异点的位置。计算出的矢量场构成了一个有趣的图形。

 <img src="https://www.dealii.org/images/steps/developer/step-22.3d.solution.png" alt=""> 

这里显示的等值线也是压力变量的等值线，显示了在不连续的速度边界条件下的奇异现象。




<h3>Sparsity pattern</h3>

正如在生成稀疏模式时解释的那样，在使用不完全LU分解等预处理程序时，必须牢记自由度的编号。使用刚度矩阵中的非零元素的分布可以最方便地看到这一点。

如果我们不对自由度的重新编号做任何特殊处理（即不使用 DoFRenumbering::Cuthill_McKee, ，而是使用 DoFRenumbering::component_wise 来确保自由度被适当地排序到矩阵和向量的相应块中），那么我们在二维的第一次自适应细化后得到以下图像。

 <img src="https://www.dealii.org/images/steps/developer/step-22.2d.sparsity-nor.png" alt=""> 

为了生成这样的图表，你必须在设置步骤的末尾插入一段类似以下的代码。

@code
  {
    std::ofstream out ("sparsity_pattern.gpl");
    sparsity_pattern.print_gnuplot(out);
  }
@endcode



可以清楚地看到，非零项几乎分布在整个矩阵中。  这使得用ILU进行预处理的效率很低。ILU生成的高斯消除（LU分解）没有填充元素，这意味着更多的暂定填充元素的遗漏将导致完整分解的近似度降低。

因此，在这个程序中，我们选择了一种更高级的元件重新编号的方法。  用 DoFRenumbering::Cuthill_McKee 进行重新编号，并将元件分组为速度和压力，得到以下输出。

 <img src="https://www.dealii.org/images/steps/developer/step-22.2d.sparsity-ren.png" alt=""> 

很明显，情况有了很大的改善。现在大多数元素都集中在矩阵中（0,0）块的对角线周围。其他区块也可以看到类似的效果。在这种情况下，ILU分解将更接近于完全的LU分解，这就提高了预处理程序的质量。值得注意的是，稀疏直接求解器UMFPACK在实际生成稀疏LU分解之前会对方程进行一些内部重新编号；这个过程导致了与我们从Cuthill-McKee算法中得到的模式非常相似）。

最后，我们想仔细看看三维的稀疏模式。我们只显示了矩阵的(0,0)块，还是在一次自适应细化之后。除了矩阵大小增加的事实之外，还可以看到矩阵中多了很多条目。此外，即使是优化后的重新编号，也会有相当数量的暂定填充元素。这说明了为什么UMFPACK在三维中不是一个好的选择--完整的分解需要许多新的条目，最终无法放入物理内存（RAM）。

 <img src="https://www.dealii.org/images/steps/developer/step-22.3d.sparsity_uu-ren.png" alt=""> 




<h3>Possibilities for extensions</h3>

<a name="improved-solver">


<h4>Improved linear solver in 3D</h4><h4>Improved linear solver in 3D</h4>
</a> 。

我们在计算结果一节中看到，外迭代次数不取决于网格大小，从可扩展性的角度看，这是最佳的。然而，如上所述，这并不适用于整个求解器。在生成矩阵 $A$ 和质量矩阵 $M_p$ 的逆时，我们没有研究内部迭代的数量。当然，这在二维情况下是没有问题的，我们用直接求解器对 $A$ 进行预处理，逆矩阵结构的 <code>vmult</code> 操作将在一个单一的CG步骤中收敛，但这在三维情况下发生变化，我们只使用ILU预处理器。  在那里，反演 $A$ 所需的预处理CG步骤的数量随着网格的细化而增加，每个 <code>vmult</code> 操作平均涉及上述细化步骤中的大约14、23、36、59、75和101次内部CG迭代。(另一方面，应用反压力质量矩阵的迭代次数总是在5次左右，在二维和三维中都是如此)。  总而言之，大部分的工作都花在了用相同的矩阵 $A$ 反复解决线性系统上。让这看起来更糟糕的是，我们实际上反转了一个矩阵，其大小约为整个系统矩阵的95%，并代表了稀疏模式中85%的非零条目。因此，自然的问题是，在计算块状系统的解时，用矩阵 $A$ 解约15次的线性系统是否合理。

当然，答案是，我们可以用其他一些（大多数时候是更好的）方法来做。然而，必须指出的是，正如我们在早期教程中所看到的那样，眼前的这个不确定系统对线性代数的要求确实比标准椭圆问题高得多。如果与类似规模的椭圆问题相比，其改进仍然相当不令人满意。无论如何，我们将在下面介绍一些对线性求解器的改进，我们将在第31步程序中用额外的选项再次重新考虑这一讨论。

<a name="improved-ilu">


<h5>Better ILU decomposition by smart reordering</h5><h5>Better ILU decomposition by smart reordering</h5>
</a> 提高线性求解过程速度的第一个尝试是选择一个道夫重排序，使ILU更接近于全LU分解，这在代码中的注释中已经提到。DoFRenumbering命名空间比较了几种对斯托克斯方程的道夫重新编号的选择。关于计算时间的最佳结果是通过调用 DoFRenumbering::boost::king_ordering. 找到的，通过该程序，内部求解器需要的操作大大减少，例如，在第4周期对 $A$ 进行反演的内部CG迭代约62次，而标准Cuthill-McKee-算法的迭代约75次。另外，在第4周期，对于 <code>solve()</code> 的调用，计算时间从大约17分钟减少到11分钟。然而，King排序（以及一般由 DoFRenumbering::boost 命名空间提供的排序）有一个严重的缺点--它比构建中的交易版本使用更多的内存，因为它作用于抽象图而不是由三角化提供的几何图形。在目前的情况下，重新编号需要大约5倍的内存，这就产生了一个不可行的算法，在3D的最后一个周期有120万未知数。

<h5>Better preconditioner for the inner CG solver</h5>另一个改善情况的想法是选择一个预处理程序，使(0,0)矩阵 $A$ 的CG在一个与网格无关的迭代次数中收敛，比如10到30次。我们在步骤16中已经看到了这样的候选方案：多网格。

<h5>Block Schur complement preconditioner</h5> <a name="block-schur"></a> 即使对 $A$ 有一个好的预处理程序，我们仍然需要反复求解同一个线性系统（虽然右手边不同），以使舒尔补码的求解趋于一致。我们这里要讨论的方法是如何将内部迭代和外部迭代结合起来。如果我们坚持计算舒尔补码，就没有其他的可能性了。

另一种方法是一次性攻击块状系统，并使用近似的Schur补码作为有效的预处理程序。其思路如下。如果我们找到一个块状预处理器 $P$ ，使矩阵

@f{eqnarray*}
  P^{-1}\left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)


@f}

是简单的，那么使用该预处理程序的迭代求解器将在几次迭代中收敛。使用舒尔补码 $S = B A^{-1} B^T$ ，我们发现

@f{eqnarray*}
  P^{-1}
  =
  \left(\begin{array}{cc}
    A^{-1} & 0 \\ S^{-1} B A^{-1} & -S^{-1}
  \end{array}\right)


@f}

似乎是个不错的选择，因为

@f{eqnarray*}
  P^{-1}\left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)
  =
  \left(\begin{array}{cc}
    A^{-1} & 0 \\ S^{-1} B A^{-1} & -S^{-1}
  \end{array}\right)\cdot \left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)
  =
  \left(\begin{array}{cc}
    I & A^{-1} B^T \\ 0 & I
  \end{array}\right).


@f}

这就是引言中提到的Silvester和Wathen的论文所采取的方法（不同的是Silvester和Wathen使用了右预处理）。在这种情况下，基于Krylov的迭代方法只有在应用 $A$ 和 $S$ 的精确求逆时才会一步收敛，因为所有的特征值都是1（而这种方法的迭代次数是由不同特征值的数量所决定的）。下面，我们将讨论如何为这个问题选择一个适当的求解器。首先，我们要仔细研究一下预处理程序的实现。

由于 $P$ 的目的只是作为一个预处理程序，我们将使用舒尔补码 $S$ 和矩阵 $A$ 的近似反向。因此，舒尔补集将由压力质量矩阵 $M_p$ 近似，我们使用 $A$ 的预处理器（周围没有反矩阵类）来近似 $A^{-1}$ 。

这里有一个实现块舒尔补码预处理的类。根据上面的推导，对块向量的 <code>vmult</code> 操作可以通过三个连续的操作来指定。

@code
template <class PreconditionerA, class PreconditionerMp>
class BlockSchurPreconditioner : public Subscriptor
{
  public:
    BlockSchurPreconditioner (const BlockSparseMatrix<double>         &S,
          const InverseMatrix<SparseMatrix<double>,PreconditionerMp>  &Mpinv,
          const PreconditionerA &Apreconditioner);


  void vmult (BlockVector<double>       &dst,
              const BlockVector<double> &src) const;


  private:
    const SmartPointer<const BlockSparseMatrix<double> > system_matrix;
    const SmartPointer<const InverseMatrix<SparseMatrix<double>,
                       PreconditionerMp > > m_inverse;
    const PreconditionerA &a_preconditioner;


    mutable Vector<double> tmp;


};


template <class PreconditionerA, class PreconditionerMp>
BlockSchurPreconditioner<PreconditionerA, PreconditionerMp>::BlockSchurPreconditioner(
          const BlockSparseMatrix<double>                            &S,
          const InverseMatrix<SparseMatrix<double>,PreconditionerMp> &Mpinv,
          const PreconditionerA &Apreconditioner
          )
                :
                system_matrix           (&S),
                m_inverse               (&Mpinv),
                a_preconditioner        (Apreconditioner),
                tmp                     (S.block(1,1).m())
{}


        // Now the interesting function, the multiplication of
        // the preconditioner with a BlockVector.
template <class PreconditionerA, class PreconditionerMp>
void BlockSchurPreconditioner<PreconditionerA, PreconditionerMp>::vmult (
                                     BlockVector<double>       &dst,
                                     const BlockVector<double> &src) const
{
        // Form u_new = A^{-1} u
  a_preconditioner.vmult (dst.block(0), src.block(0));
        // Form tmp = - B u_new + p
        // (<code>SparseMatrix::residual</code>
        // does precisely this)
  system_matrix->block(1,0).residual(tmp, dst.block(0), src.block(1));
        // Change sign in tmp
  tmp *= -1;
        // Multiply by approximate Schur complement
        // (i.e. a pressure mass matrix)
  m_inverse->vmult (dst.block(1), tmp);
}
@endcode



由于我们现在对整个区块系统采取行动，我们必须忍受一个缺点：我们需要对整个区块系统而不是较小的压力空间进行求解器迭代。

现在我们转向我们应该对块系统使用哪种求解器的问题。第一个观察结果是，所产生的预处理矩阵不能用CG求解，因为它既不是正定也不是对称的。

deal.II库实现了几个适合手头问题的求解器。一种选择是求解器 @ref SolverBicgstab "BiCGStab"，它被用于解决步骤9中的非对称平流问题。第二个选择，也就是我们要选择的，是 @ref SolverGMRES  "GMRES"（广义最小残差）。这两种方法都有其优点和缺点--在有些问题上，两种候选方法中的一种明显优于另一种，反之亦然。<a href="http://en.wikipedia.org/wiki/GMRES#Comparison_with_other_solvers">Wikipedia</a>关于GMRES方法的文章给出了一个比较的介绍。更全面和有根据的比较可以在J.W.Demmel的书中读到（Applied Numerical Linear Algebra, SIAM, 1997, section 6.6.6）。

对于我们用ILU预处理 $A$ 的具体问题，对于大的问题规模，我们当然需要在块系统上进行数百次迭代（我们不会打败CG！）。实际上，这不利于GMRES。在GMRES迭代过程中，Krylov向量的基础被陆续建立起来，并对这些向量进行一些操作。这个基础上的向量越多，需要的操作和内存就越多。操作的数量以 ${\cal O}(n + k^2)$ 的形式扩展，内存以 ${\cal O}(kn)$ 的形式扩展，其中 $k$ 是Krylov基础中的向量数量， $n$ 是（块）矩阵的大小。为了不让这些需求过度增长，deal.II将基的大小 $k$ 默认限制为30个向量。然后，重新建立基。这种GMRES方法的实现被称为GMRES(k)，默认为  $k=30$  。我们通过这一限制所获得的东西，即对操作和内存需求的约束，将被我们使用不完整的基础这一事实所补偿--这将增加所需的迭代次数。

另一方面，当需要多次迭代时，BiCGStab不会变慢（一次迭代只使用前面一个步骤的结果，而不是像GMRES那样使用所有的步骤）。除了BiCGStab由于需要两个矩阵-向量乘积（相比之下，CG或GMRES只需要一个），所以每一步的成本更高之外，还有一个主要原因使得BiCGStab不适合这个问题：预处理程序通过使用InverseMatrix类应用压力质量矩阵的逆。由于向量的逆矩阵应用只是以近似的方式进行（精确的逆太昂贵了），这也会影响求解器。在BiCGStab的情况下，由于这种扰动，Krylov向量将不会是正交的。虽然这对于少量的步骤（最多50步）来说是不关键的，但当这些扰动在迭代的粗放中增长到相当大的程度时，它就会破坏求解器的性能。

我们用BiCGStab做了一些实验，发现它在细化周期3之前比GMRES快（在3D中），但在周期4和5时变得非常慢（甚至比原来的Schur补码还慢），所以在这种情况下求解器是没有用的。为逆矩阵类选择一个更尖锐的容忍度（ <code>1e-10*src.l2_norm()</code> 而不是 <code>1e-6*src.l2_norm()</code> ）使BiCGStab在第4周期也表现良好，但没有改变在非常大的问题上的失败。

当然，GMRES也会受到近似求逆的影响，但它对正交性不那么敏感，而且对于大尺寸也能保持相对较好的性能，见下面的结果。

说到这里，我们转向用 $k=100$ 临时向量的GMRES实现求解器调用。

@code
      const SparseMatrix<double> &pressure_mass_matrix
        = preconditioner_matrix.block(1,1);
      SparseILU<double> pmass_preconditioner;
      pmass_preconditioner.initialize (pressure_mass_matrix,
        SparseILU<double>::AdditionalData());


      InverseMatrix<SparseMatrix<double>,SparseILU<double> >
        m_inverse (pressure_mass_matrix, pmass_preconditioner);


      BlockSchurPreconditioner<typename InnerPreconditioner<dim>::type,
                               SparseILU<double> >
        preconditioner (system_matrix, m_inverse, *A_preconditioner);


      SolverControl solver_control (system_matrix.m(),
                                    1e-6*system_rhs.l2_norm());
      GrowingVectorMemory<BlockVector<double> > vector_memory;
      SolverGMRES<BlockVector<double> >::AdditionalData gmres_data;
      gmres_data.max_n_tmp_vectors = 100;


      SolverGMRES<BlockVector<double> > gmres(solver_control, vector_memory,
                                              gmres_data);


      gmres.solve(system_matrix, solution, system_rhs,
                  preconditioner);


      constraints.distribute (solution);


      std::cout << " "
                << solver_control.last_step()
                << " block GMRES iterations";
@endcode



显然，人们需要添加include文件 @ref SolverGMRES "<lac/solver_gmres.h>"以使其运行。我们用BlockVector模板来调用求解器，以便使GMRES能够对块状向量和矩阵进行操作。还要注意的是，在我们将信息复制到另一个矩阵之后，我们需要将系统矩阵中的（1,1）块设置为零（我们将压力质量矩阵保存在那里，这不是问题的一部分）。

使用定时器类，我们收集了一些统计数据，将块状求解器的运行时间与上述问题实现中的运行时间进行比较。除了两个选项的解决方案，我们还检查了两个变体的解决方案是否接近（即这个求解器给出的解决方案确实与我们之前的解决方案相同），并计算矢量差的无穷大准则。

让我们先看看二维的结果。

@code
Refinement cycle 0
   Number of active cells: 64
   Number of degrees of freedom: 679 (594+85) [0.00162792 s]
   Assembling...  [0.00108981 s]
   Computing preconditioner... [0.0025959 s]
   Solving...
      Schur complement: 11 outer CG iterations for p  [0.00479603s ]
      Block Schur preconditioner: 12 GMRES iterations [0.00441718 s]
   l_infinity difference between solution vectors: 5.38258e-07


Refinement cycle 1
   Number of active cells: 160
   Number of degrees of freedom: 1683 (1482+201) [0.00345707 s]
   Assembling...  [0.00237417 s]
   Computing preconditioner... [0.00605702 s]
   Solving...
      Schur complement: 11 outer CG iterations for p  [0.0123992s ]
      Block Schur preconditioner: 12 GMRES iterations [0.011909 s]
   l_infinity difference between solution vectors: 1.74658e-05


Refinement cycle 2
   Number of active cells: 376
   Number of degrees of freedom: 3813 (3370+443) [0.00729299 s]
   Assembling...  [0.00529909 s]
   Computing preconditioner... [0.0167508 s]
   Solving...
      Schur complement: 11 outer CG iterations for p  [0.031672s ]
      Block Schur preconditioner: 12 GMRES iterations [0.029232 s]
   l_infinity difference between solution vectors: 7.81569e-06


Refinement cycle 3
   Number of active cells: 880
   Number of degrees of freedom: 8723 (7722+1001) [0.017709 s]
   Assembling...  [0.0126002 s]
   Computing preconditioner... [0.0435679 s]
   Solving...
      Schur complement: 11 outer CG iterations for p  [0.0971651s ]
      Block Schur preconditioner: 12 GMRES iterations [0.0992041 s]
   l_infinity difference between solution vectors: 1.87249e-05


Refinement cycle 4
   Number of active cells: 2008
   Number of degrees of freedom: 19383 (17186+2197) [0.039988 s]
   Assembling...  [0.028281 s]
   Computing preconditioner... [0.118314 s]
   Solving...
      Schur complement: 11 outer CG iterations for p  [0.252133s ]
      Block Schur preconditioner: 13 GMRES iterations [0.269125 s]
   l_infinity difference between solution vectors: 6.38657e-05


Refinement cycle 5
   Number of active cells: 4288
   Number of degrees of freedom: 40855 (36250+4605) [0.0880702 s]
   Assembling...  [0.0603511 s]
   Computing preconditioner... [0.278339 s]
   Solving...
      Schur complement: 11 outer CG iterations for p  [0.53846s ]
      Block Schur preconditioner: 13 GMRES iterations [0.578667 s]
   l_infinity difference between solution vectors: 0.000173363
@endcode



我们看到，块状舒尔补码预处理求解器和舒尔补码本身在求解时间上没有巨大差异。原因很简单：我们使用直接求解作为 $A$ 的预处理程序--所以我们不能指望通过避免内部迭代获得任何收益。我们看到，GMRES的迭代次数略有增加，但总的来说，这两种选择是相当相似的。

画面当然会发生三维变化。

@code
Refinement cycle 0
   Number of active cells: 32
   Number of degrees of freedom: 1356 (1275+81) [0.00845218 s]
   Assembling...  [0.019372 s]
   Computing preconditioner... [0.00712395 s]
   Solving...
      Schur complement: 13 outer CG iterations for p  [0.0320101s ]
      Block Schur preconditioner: 22 GMRES iterations [0.0048759 s]
   l_infinity difference between solution vectors: 2.15942e-05


Refinement cycle 1
   Number of active cells: 144
   Number of degrees of freedom: 5088 (4827+261) [0.0346942 s]
   Assembling...  [0.0857739 s]
   Computing preconditioner... [0.0465031 s]
   Solving...
      Schur complement: 14 outer CG iterations for p  [0.349258s ]
      Block Schur preconditioner: 35 GMRES iterations [0.048759 s]
   l_infinity difference between solution vectors: 1.77657e-05


Refinement cycle 2
   Number of active cells: 704
   Number of degrees of freedom: 22406 (21351+1055) [0.175669 s]
   Assembling...  [0.437447 s]
   Computing preconditioner... [0.286435 s]
   Solving...
      Schur complement: 14 outer CG iterations for p  [3.65519s ]
      Block Schur preconditioner: 63 GMRES iterations [0.497787 s]
   l_infinity difference between solution vectors: 5.08078e-05


Refinement cycle 3
   Number of active cells: 3168
   Number of degrees of freedom: 93176 (89043+4133) [0.790985 s]
   Assembling...  [1.97598 s]
   Computing preconditioner... [1.4325 s]
   Solving...
      Schur complement: 15 outer CG iterations for p  [29.9666s ]
      Block Schur preconditioner: 128 GMRES iterations [5.02645 s]
   l_infinity difference between solution vectors: 0.000119671


Refinement cycle 4
   Number of active cells: 11456
   Number of degrees of freedom: 327808 (313659+14149) [3.44995 s]
   Assembling...  [7.54772 s]
   Computing preconditioner... [5.46306 s]
   Solving...
      Schur complement: 15 outer CG iterations for p  [139.987s ]
      Block Schur preconditioner: 255 GMRES iterations [38.0946 s]
   l_infinity difference between solution vectors: 0.00020793


Refinement cycle 5
   Number of active cells: 45056
   Number of degrees of freedom: 1254464 (1201371+53093) [19.6795 s]
   Assembling...  [28.6586 s]
   Computing preconditioner... [22.401 s]
   Solving...
      Schur complement: 14 outer CG iterations for p  [796.767s ]
      Block Schur preconditioner: 524 GMRES iterations [355.597 s]
   l_infinity difference between solution vectors: 0.000501219
@endcode



在这里，块状预处理求解器明显优于Schur补数，但是网格点越多，优势就越小。这是因为GMRES(k)随着问题规模的扩大比CG更差，正如我们上面所讨论的。  尽管如此，对于中等规模的问题，3-6倍的改进是相当令人印象深刻的。




<h5>Combining the block preconditioner and multigrid</h5>这个问题的终极线性求解器可以想象为 $A$ 的最佳预处理器（如多网格）和上述的块状预处理器的组合，这就是步骤31和步骤32教程程序（我们使用代数多网格方法）和步骤56（我们使用几何多网格方法）中所采取的方法。




<h5>No block matrices and vectors</h5> 另一个可以考虑的可能性是不设置块状系统，而是一次性解决速度和压力系统。可以选择用UMFPACK直接求解（2D）或用ILU预处理的GMRES（3D）。这应该是很直接的尝试。




<h4>More interesting testcases</h4>

当然，这个程序也可以作为计算更有趣的情况下的流动的基础。编写这个程序的最初动机是希望它能成为一些地球物理流动问题的起点，例如大陆板块漂移分离的地方（例如洋中脊）下的岩浆运动。当然，在这种地方，几何形状比上面的例子更复杂，但要适应这种情况并不难。

例如，通过使用以下对边界值函数的修改

@code
template <int dim>
double
BoundaryValues<dim>::value (const Point<dim>  &p,
                            const unsigned int component) const
{
  Assert (component < this->n_components,
          ExcIndexRange (component, 0, this->n_components));


  const double x_offset = std::atan(p[1]*4)/3;


  if (component == 0)
    return (p[0] < x_offset ? -1 : (p[0] > x_offset ? 1 : 0));
  return 0;
}
@endcode

和以下方式生成网格作为域 $[-2,2]\times[-2,2]\times[-1,0]$ 。

@code
    std::vector<unsigned int> subdivisions (dim, 1);
    subdivisions[0] = 4;
    if (dim>2)
      subdivisions[1] = 4;


    const Point<dim> bottom_left = (dim == 2 ?
                                    Point<dim>(-2,-1) :
                                    Point<dim>(-2,-2,-1));
    const Point<dim> top_right   = (dim == 2 ?
                                    Point<dim>(2,0) :
                                    Point<dim>(2,2,0));


    GridGenerator::subdivided_hyper_rectangle (triangulation,
                                               subdivisions,
                                               bottom_left,
                                               top_right);
@endcode

那么我们就会得到断层线是弯曲的图像。   <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d-extension.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-22.3d-grid-extension.png" alt="">
    </td>
  </tr>
</table> 


examples/step-23/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{28} 

这是一系列教程程序中的第一个，它将最终涵盖 "真正的 "时间依赖问题，而不是步骤18中发现的略显奇怪的时间依赖形式或步骤21的DAE模型。特别是，这个程序介绍了有界域中的波浪方程。后来，第24步将考虑一个吸收边界条件的例子，以及 @ref
step_25 "第25步 "一种产生称为孤子的解的非线性波方程。

波浪方程的原型形式如下：找到满足以下条件的 $u(x,t), x\in\Omega, t\in[0,T]$ 。

@f{eqnarray*}
	\frac{\partial^2 u}{\partial t^2}


	-
	\Delta u &=& f
	\qquad
	\textrm{in}\ \Omega\times [0,T],
\\
	u(x,t) &=& g
	\qquad
	\textrm{on}\ \partial\Omega\times [0,T],
\\
	u(x,0) &=& u_0(x)
	\qquad
	\textrm{in}\ \Omega,
\\
	\frac{\partial u(x,0)}{\partial t} &=& u_1(x)
	\qquad
	\textrm{in}\ \Omega.


@f}

请注意，由于这是一个具有二阶时间导数的方程，我们需要提出两个初始条件，一个是值，一个是解的时间导数。

在物理上，该方程描述了弹性介质的运动。在二维空间中，我们可以考虑膜在受到力的作用下如何运动。上面的Dirichlet边界条件表明，膜被夹在边界的高度 $g(x,t)$ （这个高度可能也在移动&mdash；想想人们拿着毯子上下摇晃）。第一个初始条件等于膜的初始偏转，而第二个初始条件给出了其速度。例如，我们可以考虑用手指把膜推下去，然后在 $t=0$ 处让它离开（非零偏转但零初始速度），或者在 $t=0$ 处用锤子砸它（零偏转但非零速度）。这两种情况都会引起膜的运动。




<h3>Time discretization</h3>

<h4>Method of lines or Rothe's method?</h4>在数值分析界有一个长期的争论，即时间依赖方程的离散化是否应该首先离散时间变量，导致每个时间步长的静止PDE，然后用标准的有限元技术来解决（这被称为Rothe方法），或者是否应该首先离散空间变量，导致一个大型的常微分方程系统，然后用一个通常的ODE求解器来处理（这被称为线的方法）。

这两种方法都有优点和缺点。传统上，人们更倾向于线的方法，因为它允许使用非常发达的高阶ODE求解器，可用于由这种方法产生的相当刚性的ODE，包括步长控制和时间误差的估计。

另一方面，当使用高阶时间步长法时，罗特的方法变得很尴尬，因为这时人们必须写下一个PDE，将当前时间步长的解与前一个时间步长的解结合起来，而且可能还有更早的解，从而导致大量的条款。

由于这些原因，线条法在很长一段时间内都是人们的首选方法。然而，它有一个很大的缺点：如果我们先将空间变量离散化，导致一个大的ODE系统，我们必须一劳永逸地选择一个网格。如果我们愿意这样做，那么这就是一种合法的、可能是优越的方法。

另一方面，如果我们看的是波浪方程和其他许多与时间有关的问题，我们会发现，随着时间的推移，解的特征会发生变化。例如，对于波浪方程，我们可能有一个单一的波浪穿过域，在波浪的前后，解是平滑的，甚至是恒定的&mdash;自适应性对于这种情况确实很有用，但关键是我们需要细化网格的区域会随着时间步数的变化而变化!

如果我们打算这样做，即为每个时间步长（或一组时间步长）选择不同的网格，那么线段法就不再合适了：我们不是得到一个变量数等于有限元网格中未知数数量的ODE系统，而是未知数的数量一直在变化，这是标准ODE求解器肯定不准备处理的事实。另一方面，对于罗特方法，我们只是在每个时间步长得到一个PDE，我们可以选择独立于前一个时间步长所用的网格进行离散化；这种方法并非没有危险和困难，但至少是一个合理的、定义明确的程序。

由于所有这些原因，在本程序中，我们选择使用Rothe方法进行离散化，即我们首先在时间上进行离散化，然后在空间上离散化。我们实际上根本不会使用自适应网格，因为这涉及到大量的额外代码，但我们将在<a href="#Results">results section below</a>中对此作一些评论。




<h4>Rothe's method!</h4>

鉴于这些考虑，我们将这样做：让我们首先为这个二阶问题定义一个简单的时间步进方法，然后在第二步做空间离散化，即我们将遵循Rothe的方法。

对于第一步，让我们先绕一点路：为了离散化一个第二时间导数，我们可以直接离散化它，或者引入一个额外的变量，将系统转化为一阶系统。在许多情况下，这证明是等价的，但处理一阶系统往往更简单。为此，让我们引入

@f[
	v = \frac{\partial u}{\partial t},


@f]

并称这个变量为<i>velocity</i>，原因很明显。然后，我们可以将原来的波浪方程重新表述如下。

@f{eqnarray*}
	\frac{\partial u}{\partial t}


	-
	v
	&=& 0
	\qquad
	\textrm{in}\ \Omega\times [0,T],
\\
	\frac{\partial v}{\partial t}


	-
	\Delta u &=& f
	\qquad
	\textrm{in}\ \Omega\times [0,T],
\\
	u(x,t) &=& g
	\qquad
	\textrm{on}\ \partial\Omega\times [0,T],
\\
	u(x,0) &=& u_0(x)
	\qquad
	\textrm{in}\ \Omega,
\\
	v(x,0) &=& u_1(x)
	\qquad
	\textrm{in}\ \Omega.


@f}

这个公式的优点是它现在只包含两个变量的第一时间导数，对于它来说，写下时间步进方案很简单。请注意，我们起初没有 $v$ 的边界条件。然而，我们可以在边界上强制执行 $v=\frac{\partial
g}{\partial t}$ 。在数值例子中发现，这实际上是必要的：如果不这样做，解决方案看起来并不特别错误，但如果不执行这些边界条件，Crank-Nicolson方案并不保存能量。

有了这个公式，让我们引入以下时间离散化，其中上标 $n$ 表示一个时间步长， $k=t_n-t_{n-1}$ 是当前时间步长。

\f{eqnarray*}
  \frac{u^n - u^{n-1}}{k}


  - \left[\theta v^n + (1-\theta) v^{n-1}\right] &=& 0,
  \\
  \frac{v^n - v^{n-1}}{k}


  - \Delta\left[\theta u^n + (1-\theta) u^{n-1}\right]
  &=& \theta f^n + (1-\theta) f^{n-1}.
\f} 注意我们在这里引入了一个参数 $\theta$ 。例如，如果我们选择 $\theta=0$ ，第一个方程将简化为 $\frac{u^n - u^{n-1}}{k}  - v^{n-1} = 0$ ，这就是众所周知的正向或显式欧拉方法。另一方面，如果我们设定 $\theta=1$ ，那么我们将得到 $\frac{u^n - u^{n-1}}{k}  - v^n = 0$ ，这对应于后向或隐式欧拉方法。这两种方法都是一阶精确方法。它们实现起来很简单，但其实并不十分精确。

第三种情况是选择 $\theta=\frac 12$  。然后上面的第一个方程将变成 $\frac{u^n - u^{n-1}}{k}


- \frac 12 \left[v^n + v^{n-1}\right] = 0$  。这种方法被称为Crank-Nicolson方法，它的优点是二阶精确。此外，它还有一个很好的特性，即保留了溶液中的能量（从物理上讲，能量是膜中粒子的动能加上由于局部拉伸而存在的势能的总和；这个量在连续方程中是一个守恒量，但大多数时间步进方案在时间离散化后并不保留它）。由于 $v^n$ 也出现在 $u^n$ 的方程中，Crank-Nicolson方案也是隐式的。

在程序中，我们将把 $\theta$ 作为一个参数，这样就很容易发挥它的作用了。结果部分将显示一些比较不同方案的数字证据。

上面的方程（称为<i>semidiscretized</i>方程，因为我们只离散了时间，而没有离散空间），可以通过从第一个方程中消除 $v^n$ 和重新排列项来简化一下。然后我们得到

\f{eqnarray*}
  \left[ 1-k^2\theta^2\Delta \right] u^n &=&
  	 \left[ 1+k^2\theta(1-\theta)\Delta\right] u^{n-1} + k v^{n-1}
   	 + k^2\theta\left[\theta f^n + (1-\theta) f^{n-1}\right],\\
   v^n &=& v^{n-1} + k\Delta\left[ \theta u^n + (1-\theta) u^{n-1}\right]
   + k\left[\theta f^n + (1-\theta) f^{n-1}\right].
\f}在这种形式下，我们看到，如果我们得到了前一个时间段的解 $u^{n-1},v^{n-1}$ ，那么我们就可以分别求解变量 $u^n,v^n$ ，也就是一次一个。这很方便。此外，我们认识到第一个方程中的算子是正定的，而第二个方程看起来特别简单。




<h3>Space discretization</h3>

我们现在已经得出了将时间 $u^n(x)$ 的近似（半离散）解 $v^n(x)$ 及其时间导数 $t_n$ 与前一个时间步骤 $t_{n-1}$ 的解 $u^{n-1}(x),v^{n-1}(x)$ 相关的方程。下一步是使用通常的有限元方法将空间变量离散化。为此，我们将每个方程与一个测试函数相乘，在整个域上进行积分，并在必要时进行部分积分。这就导致了

\f{eqnarray*}
  (u^n,\varphi) + k^2\theta^2(\nabla u^n,\nabla \varphi) &=&
  (u^{n-1},\varphi) - k^2\theta(1-\theta)(\nabla u^{n-1},\nabla \varphi)
  +
  k(v^{n-1},\varphi)
  + k^2\theta
  \left[
  \theta (f^n,\varphi) + (1-\theta) (f^{n-1},\varphi)
  \right],
  \\
  (v^n,\varphi)
   &=&
   (v^{n-1},\varphi)


    -
    k\left[ \theta (\nabla u^n,\nabla\varphi) +
    (1-\theta) (\nabla u^{n-1},\nabla \varphi)\right]
  + k
  \left[
  \theta (f^n,\varphi) + (1-\theta) (f^{n-1},\varphi)
  \right].
\f}

然后习惯于近似 $u^n(x) \approx u^n_h(x) = \sum_i
U_i^n\phi_i^n(x)$  ，其中 $\phi_i^n(x)$  是用于离散化 $n$  -个时间步长的形状函数， $U_i^n$  是解决方案的未知结点值。同样地， $v^n(x) \approx
v^n_h(x) = \sum_i V_i^n\phi_i^n(x)$  。最后，我们有前一个时间步骤的解，  $u^{n-1}(x) \approx u^{n-1}_h(x) = \sum_i
U_i^{n-1}\phi_i^{n-1}(x)$  和  $v^{n-1}(x) \approx v^{n-1}_h(x) = \sum_i
V_i^{n-1}\phi_i^{n-1}(x)$  。请注意，由于在我们到达时间步骤 $n$ 时，前一个时间步骤的解已经被计算出来了，所以 $U^{n-1},V^{n-1}$ 是已知的。此外，注意上一步的解可能是在不同的网格上计算的，所以我们必须使用形状函数  $\phi^{n-1}_i(x)$  。

如果我们将这些扩展插入上述方程，并用本网的测试函数进行测试，我们得到以下线性系统。

\f{eqnarray*}
  (M^n + k^2\theta^2 A^n)U^n &=&
  M^{n,n-1}U^{n-1} - k^2\theta(1-\theta) A^{n,n-1}U^{n-1}
  +
  kM^{n,n-1}V^{n-1}
  + k^2\theta
  \left[
  \theta F^n + (1-\theta) F^{n-1}
  \right],
  \\
  M^nV^n
   &=&
   M^{n,n-1}V^{n-1}


    -
    k\left[ \theta A^n U^n +
    (1-\theta) A^{n,n-1} U^{n-1}\right]
   + k
  \left[
  \theta F^n + (1-\theta) F^{n-1}
  \right],
\f} 其中

@f{eqnarray*}
	M^n_{ij} &=& (\phi_i^n, \phi_j^n),
	\\
	A^n_{ij} &=& (\nabla\phi_i^n, \nabla\phi_j^n),
	\\
	M^{n,n-1}_{ij} &=& (\phi_i^n, \phi_j^{n-1}),
	\\
	A^{n,n-1}_{ij} &=& (\nabla\phi_i^n, \nabla\phi_j^{n-1}),
	\\
	F^n_{i} &=& (f^n,\phi_i^n),
	\\
	F^{n-1}_{i} &=& (f^{n-1},\phi_i^n).


@f}



如果我们解决这两个方程，我们可以将解决方案向前推进一步，并进入下一个时间步骤。

值得注意的是，如果我们在每个时间步长选择相同的网格（事实上我们将在下面的程序中这样做），那么我们在时间步长 $n$ 和 $n-1$ 上有相同的形状函数，即 $\phi^n_i=\phi_i^{n-1}=\phi_i$  。因此，我们得到  $M^n=M^{n,n-1}=M$  和  $A^n=A^{n,n-1}=A$  。另一方面，如果我们使用了不同的形状函数，那么我们将不得不计算包含定义在两个网格上的形状函数的积分。这是一个有些混乱的过程，我们在此省略，但在步骤28中会有一些详细的处理。

在这些条件下（即网格不发生变化），我们可以通过基本消除第二个线性系统的解来优化求解过程。我们将在 @ref step_25 "step-25 "程序的介绍中讨论这个问题。

<h3>Energy conservation</h3>

比较时间步进方案质量的一个方法是看数值近似是否保留了连续方程的守恒特性。对于波浪方程来说，自然要看的是能量。通过将波浪方程乘以 $u_t$ ，对 $\Omega$ 进行积分，并在必要时进行部分积分，我们发现

@f[
	\frac{d}{d t}
	\left[\frac 12 \int_\Omega \left(\frac{\partial u}{\partial
	t}\right)^2 + (\nabla u)^2 \; dx\right]
	=
	\int_\Omega f \frac{\partial u}{\partial t} \; dx
	+
	\int_{\partial\Omega} n\cdot\nabla u
	\frac{\partial g}{\partial t} \; dx.


@f]

因此，在没有体力和恒定边界值的情况下，我们得到的结果是

@f[
	E(t) = \frac 12 \int_\Omega \left(\frac{\partial u}{\partial
	t}\right)^2 + (\nabla u)^2 \; dx


@f]

是一个守恒量，即一个不随时间变化的量。我们将在每个时间步骤后计算这个量。很容易看出，如果我们用有限元近似值代替 $u$ ，用速度的有限元近似值代替 $\frac{\partial u}{\partial t}$ ，那么

@f[
	E(t_n) = \frac 12 \left<V^n, M^n V^n\right>
	+
	\frac 12 \left<U^n, A^n U^n\right>.


@f]

正如我们将在结果部分看到的，Crank-Nicolson方案确实保存了能量，而前向和后向Euler方案都没有。




<h3>Who are Courant, Friedrichs, and Lewy?</h3>

波浪方程的数值求解很麻烦，原因之一是显式时间离散化只有在时间步长足够小的情况下才稳定。特别是，它与空间网格宽度有耦合关系  $h$  。对于我们这里使用的最低阶离散化，其关系为

@f[
	k\le \frac hc


@f]

其中 $c$ 是波速，在我们对波浪方程的表述中，它已被归一。因此，除非我们使用带有 $\theta>0$ 的隐式方案，否则如果我们违反这一限制，我们的解在数值上是不稳定的。隐式方案在稳定性方面没有这个限制，但如果时间步长过大，它们就会变得不准确了。

这一条件是由库兰特、弗里德里希斯和卢伊首先认识到的；在1928年，远在计算机可用于数值计算之前！（这一结果出现在德语文章R.库兰特、K.弗里德里希斯和H.卢伊中。这个结果出现在德语文章R.Courant, K. Friedrichs and H. Lewy:<i>&Uuml;ber die partiellen
Differenzengleichungen der mathematischen Physik</i>, Mathematische Annalen, vol. 100, no. 1, pages 32-74, 1928.)这个关于时间步长的条件最常被称为<i>CFL</i>条件。直观地说，CFL条件说的是，时间步长不能大于一个波穿过一个单元的时间。

在程序中，我们将对正方形 $[-1,1]^2$ 均匀地细化七次，得到的网格尺寸为 $h=\frac 1{64}$  ，这就是我们设置的时间步长。我们在两个不同的地方分别设置时间步长和网格尺寸是很容易出错的：很容易再细化一次网格，却忘记同时调整时间步长。   @ref
step_24  "step-24 "显示了一个更好的方法来保持这些东西的同步。




<h3>The test case</h3>

尽管该程序具有处理非零初始和边界条件以及体力的所有钩子，但我们采取一个简单的案例，即领域是一个正方形 $[-1,1]^2$ ，并且

@f{eqnarray*}
	f &=& 0,
	\\
	u_0 &=& 0,
	\\
	u_1 &=& 0,
	\\
	g &=& \left\{\begin{matrix}\sin (4\pi t)
	&\qquad& \text{for }\ t\le \frac 12, x=-1, -\frac 13<y<\frac 13
	\\
	 0
	&&\text{otherwise}
	\end{matrix}
	\right.


@f}

这相当于一个最初处于静止状态、四周被夹住的膜，有人将夹住的边界的一部分上下挥动一次，从而将波射入领域。


examples/step-23/doc/results.dox



<h1>Results</h1>

当该程序运行时，它产生了以下输出。

@code
Number of active cells: 16384
Number of degrees of freedom: 16641


Time step 1 at t=0.015625
   u-equation: 8 CG iterations.
   v-equation: 22 CG iterations.
   Total energy: 1.17887
Time step 2 at t=0.03125
   u-equation: 8 CG iterations.
   v-equation: 20 CG iterations.
   Total energy: 2.9655
Time step 3 at t=0.046875
   u-equation: 8 CG iterations.
   v-equation: 21 CG iterations.
   Total energy: 4.33761
Time step 4 at t=0.0625
   u-equation: 7 CG iterations.
   v-equation: 21 CG iterations.
   Total energy: 5.35499
Time step 5 at t=0.078125
   u-equation: 7 CG iterations.
   v-equation: 21 CG iterations.
   Total energy: 6.18652
Time step 6 at t=0.09375
   u-equation: 7 CG iterations.
   v-equation: 20 CG iterations.
   Total energy: 6.6799


...


Time step 31 at t=0.484375
   u-equation: 7 CG iterations.
   v-equation: 20 CG iterations.
   Total energy: 21.9068
Time step 32 at t=0.5
   u-equation: 7 CG iterations.
   v-equation: 20 CG iterations.
   Total energy: 23.3394
Time step 33 at t=0.515625
   u-equation: 7 CG iterations.
   v-equation: 20 CG iterations.
   Total energy: 23.1019


...


Time step 319 at t=4.98438
   u-equation: 7 CG iterations.
   v-equation: 20 CG iterations.
   Total energy: 23.1019
Time step 320 at t=5
   u-equation: 7 CG iterations.
   v-equation: 20 CG iterations.
   Total energy: 23.1019
@endcode



我们立即看到的是，至少在 $t=\frac 12$ 之后，能量是一个常数（在此之前，边界源项 $g$ 是非零的，向系统注入能量）。

除了屏幕输出外，程序还将每个时间步骤的解写到输出文件中。如果我们对其进行充分处理，并将其粘贴到电影中，我们会得到以下结果。

 <img src="https://www.dealii.org/images/steps/developer/step-23.movie.gif" alt="Animation of the solution of step 23."> 

影片显示了所产生的波在域中移动并返回，在夹持的边界处被反射。一些数值噪声跟在波的后面，这是由于网格尺寸过大造成的假象，可以通过减小网格宽度和时间步长来减少。


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

如果你想探索一下，可以尝试以下一些东西。   <ul>   <li>  Varying  $\theta$  。这给出了不同的时间步进方案，其中一些是稳定的，而另一些则不是。看一看能量是如何演变的。

    <li>  不同的初始和边界条件，右手边。

    <li>  更复杂的域或更精细的网格。请记住，时间步长需要以网格宽度为界，所以改变网格也应该包括改变时间步长。我们将在第24步再来讨论这个问题。

    <li>  可变系数。在现实介质中，波速往往是可变的。特别是，现实介质中的 "真实 "波浪方程将读作@f[
     \rho(x) \frac{\partial^2 u}{\partial t^2}


     -
     \nabla \cdot
     a(x) \nabla u = f,
  @f]

  其中 $\rho(x)$ 是材料的密度， $a(x)$ 与刚度系数有关。那么波速就是  $c=\sqrt{a/\rho}$  。

  为了做出这样的改变，我们将不得不用可变系数来计算质量和拉普拉斯矩阵。幸运的是，这并不难：函数 MatrixCreator::create_laplace_matrix 和 MatrixCreator::create_mass_matrix 有额外的默认参数，可以用来向它们传递非恒定系数函数。因此，所需的变化相对较小。另一方面，必须再次注意确保时间步长在允许范围内。

    <li>  在代码内的注释中，我们讨论了这样一个事实：由于边界条件的原因，用于求解 $U^n$ 和 $V^n$ 的矩阵需要在每次都被重置，尽管实际内容没有变化。可以通过不消除线性系统中的列来避免复制，这可以通过在调用中附加一个 @p false 参数来实现。   @code
    MatrixTools::apply_boundary_values(boundary_values,
                                       matrix_u,
                                       solution_u,
                                       system_rhs,
                                       false);
  @endcode



    <li>  deal.II是一个支持自适应网格的库，如果这个程序支持每隔几步就改变网格，那当然很好。考虑到解决方案的结构&mdash; 一个穿越领域的波浪&mdash; 如果我们只在波浪目前所在的地方完善网格，而不是简单地在所有地方完善网格，这似乎是合适的。直观地看，我们应该能够通过这种方式节省大量的单元。虽然经过进一步的思考，我们意识到这只是在模拟的初始阶段。   一段时间后，对于波浪现象来说，域中充满了初始波的反射，向各个方向发展，充满了域中的每个角落。   在这一点上，一般来说，使用局部网格细化可以获得的好处不多）。)

  为了使自适应改变网格成为可能，基本上有两条路线。   "正确 "的方法是回到我们使用罗特方法得到的弱形式。例如，在每个时间步骤中要解决的两个方程中的第一个方程看起来是这样的。   \f{eqnarray*}
  (u^n,\varphi) + k^2\theta^2(\nabla u^n,\nabla \varphi) &=&
  (u^{n-1},\varphi) - k^2\theta(1-\theta)(\nabla u^{n-1},\nabla \varphi)
  +
  k(v^{n-1},\varphi)
  + k^2\theta
  \left[
  \theta (f^n,\varphi) + (1-\theta) (f^{n-1},\varphi)
  \right].
  \f} 现在，注意我们在网格 ${\mathbb T}^n$ 上求解 $u^n$ ，因此测试函数 $\varphi$ 也必须来自空间 $V_h^n$ 。正如在介绍中所讨论的，像 $(u^{n-1},\varphi)$ 这样的条款要求我们将上一步的解决方案（可能是在不同的网格 ${\mathbb T}^{n-1}$ 上计算的）与当前网格的测试函数进行整合，从而得到一个矩阵 $M^{n,n-1}$ 。这个整合不同网格的形状函数的过程，充其量是尴尬的。它是可以做到的，但是因为很难保证 ${\mathbb T}^{n-1}$ 和 ${\mathbb T}^{n}$ 最多只相差一个细化级别，所以我们必须递归匹配两个网格的单元。这样做是可行的，但它会导致冗长的、不完全明显的代码。

  第二种方法如下：每当我们改变网格时，我们只需使用SolutionTransfer类将旧网格上的最后一个时间步长的解内插到新网格上。换句话说，我们将解决\f{eqnarray*}
  (u^n,\varphi) + k^2\theta^2(\nabla u^n,\nabla \varphi) &=&
  (I^n u^{n-1},\varphi) - k^2\theta(1-\theta)(\nabla I^n u^{n-1},\nabla \varphi)
  +
  k(I^n v^{n-1},\varphi)
  + k^2\theta
  \left[
  \theta (f^n,\varphi) + (1-\theta) (f^{n-1},\varphi)
  \right],
  \f}，其中 $I^n$ 将一个给定的函数插值到网格 ${\mathbb T}^n$ ，而不是上面的方程。   这是一个更简单的方法，因为在每个时间步长中，我们不再需要担心 $u^{n-1},v^{n-1}$ 是在我们现在使用的同一个网格上计算的，还是在不同的网格上计算的。因此，代码的唯一变化是增加了一个计算误差的函数，为细化标记单元，设置SolutionTransfer对象，将解转移到新的网格上，并在新的网格上重建矩阵和右手向量。建立矩阵和右手边的函数以及求解器都不需要改变。

  虽然严格来说，这第二种方法在罗特框架中是不太正确的（它引入了一个额外的误差源，即插值），然而这几乎是每个人在解决时间相关方程时所做的事情。我们将在步骤31中使用这种方法，例如。   </ul> 


examples/step-24/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

这个项目是由德克萨斯A&amp;M大学的Xing Jin的一个学生项目发展而来。本程序的大部分工作是由她完成的。这个教程程序的部分工作得到了美国国家科学基金会DMS-0604778号拨款的资助。

该计划是一个旨在模拟热声断层成像的项目的一部分。在热声断层成像中，脉冲电磁能量被送入生物问题。组织吸收一些这种能量，组织中吸收能量最多的那些部分通过热弹性膨胀产生热声波。对于成像来说，人们利用不同种类的组织，最重要的是健康和病变组织，吸收不同数量的能量，因此以不同的速度膨胀。实验装置是测量这些源在组织表面产生的压力波的振幅，并试图重建源的分布，这对吸收器的分布有指示作用，因此对不同种类的组织有指示作用。这个项目的一部分是将模拟数据与实际测量进行比较，因此必须解决 "正向问题"，即描述压力波在组织中传播的波浪方程。因此，这个程序是 @ref
step_23 "step-23 "的延续，其中首次介绍了波浪方程。




<h3>The problem</h3>

在忽略热扩散的情况下，某个位置的温度可以表示为

@f[
\rho C_p \frac{\partial}{\partial t}T(t,\mathbf r) = H(t,\mathbf r)


@f]



这里 $\rho (\mathbf r) $ 是密度； $C_p (\mathbf r) $ 是比热； $\frac{\partial T}{\partial t}(t,\mathbf r)$ 是由于传递的微波能量引起的温升； $H(t,\mathbf r)$ 是加热函数，定义为由沉积的微波能量转化的每一时间和体积的热能。

让我们假设组织具有异质的介电特性，但具有同质的声学特性。在声学均质介质中的基本声学生成方程可以描述如下：如果 $u$ 是矢量值的位移，那么组织肯定通过加速度对压力的变化做出反应。

@f[
\rho \frac{\partial^2}{\partial t^2}u(t,\mathbf r) =


-\nabla p(t,\mathbf r).


@f]

此外，它因压力过大而收缩，并根据温度的变化而膨胀。

@f[
\nabla \cdot u(t,\mathbf r) = -\frac{p(t,\mathbf r)}{\rho c_0^2}+\beta T(t,\mathbf r) .


@f]

这里， $\beta$ 是一个热膨胀系数。

现在让我们假设，加热只发生在比波在组织中传播短得多的时间尺度上（即加热组织的微波脉冲的时间长度远短于波穿过领域的时间）。在这种情况下，加热率 $H(t,\mathbf r)$ 可以写成 $H(t,\mathbf r) = a(\mathbf
r)\delta(t)$ （其中 $a(\mathbf r)$ 是微波能量的吸收强度图， $\delta(t)$ 是狄拉克三角函数），与上述第一个方程一起将产生温度 $T(\mathbf r)$ 在时间 $t=0$ 的瞬时跳跃。利用这一假设，并将所有方程放在一起，我们可以将上述内容重写并合并为以下内容。

@f[
\Delta p-\frac{1}{c_0^2} \frac{\partial^2 p}{\partial t^2} = \lambda
a(\mathbf r)\frac{d\delta(t)}{dt}


@f]

其中 $\lambda = - \frac{\beta}{C_p}$  。

这个有点奇怪的方程，右边是狄拉克三角函数的导数，可以重写为一个初值问题，如下所示。

@f{eqnarray*}
\Delta \bar{p}- \frac{1}{c_0^2} \frac{\partial^2 \bar{p}}{\partial t^2} & = &
0 \\
\bar{p}(0,\mathbf r) &=& c_0^2 \lambda a(\mathbf r) = b(\mathbf r)  \\
\frac{\partial\bar{p}(0,\mathbf r)}{\partial t} &=& 0.


@f}

(在本引言的最后，作为附录给出了这种转化为初值问题的推导)。

在逆向问题中，人们希望恢复的是初始条件 $b(\mathbf r) = c_0^2 \lambda a(\mathbf r)$ ，因为它是微波能量的吸收强度图，因此可能是分辨健康和病变组织的指标。

在实际应用中，热声源相对于介质来说是非常小的。  因此，热声波的传播路径可以被近似为从源头到无限远。此外，检测器离源头只有有限的距离。我们只需要评估热声波通过检测器时的数值，尽管它们确实继续超出。因此，这是一个我们只对无限介质的一小部分感兴趣的问题，我们不希望某个地方产生的波在我们认为有趣的领域的边界上被反射。相反，我们希望只模拟包含在感兴趣的领域内的那部分波场，而碰到该领域边界的波则不受干扰地通过边界。换句话说，我们希望边界能吸收撞击它的任何波。

一般来说，这是一个困难的问题：好的吸收边界条件是非线性的和/或数值上非常昂贵。因此，我们选择了一个简单的一阶近似吸收边界条件，其内容为

@f[
\frac{\partial\bar{p}}{\partial\mathbf n} =


-\frac{1}{c_0} \frac{\partial\bar{p}}{\partial t}


@f]

这里， $\frac{\partial\bar{p}}{\partial\mathbf n}$ 是边界处的法向导数。应该指出的是，这不是一个特别好的边界条件，但它是少数几个合理简单的实现条件之一。




<h3>Weak form and discretization</h3>

如同步骤23，首先引入第二个变量，定义为压力势的导数。

@f[
v = \frac{\partial\bar{p}}{\partial t}


@f]



有了第二个变量，我们就可以将正向问题转化为两个独立的方程式。

@f{eqnarray*}
\bar{p}_{t} - v & = & 0 \\
\Delta\bar{p} - \frac{1}{c_0^2}\,v_{t} & = & f


@f}

具有初始条件。

@f{eqnarray*}
\bar{p}(0,\mathbf r) & = & b(r) \\
v(0,\mathbf r)=\bar{p}_t(0,\mathbf r) & = & 0.


@f}

注意，我们在这里引入了一个右手边 $f(t,\mathbf r)$ ，以显示如何在一般情况下推导这些公式，尽管在应用于热声问题时 $f=0$  。

然后，使用步骤23中介绍的一般 $\theta$ 方案，这个模型的半具体化、弱化版本是。

@f{eqnarray*}
\left(\frac{\bar{p}^n-\bar{p}^{n-1}}{k},\phi\right)_\Omega-
\left(\theta v^{n}+(1-\theta)v^{n-1},\phi\right)_\Omega & = & 0   \\


-\left(\nabla((\theta\bar{p}^n+(1-\theta)\bar{p}^{n-1})),\nabla\phi\right)_\Omega-
\frac{1}{c_0}\left(\frac{\bar{p}^n-\bar{p}^{n-1}}{k},\phi\right)_{\partial\Omega} -
\frac{1}{c_0^2}\left(\frac{v^n-v^{n-1}}{k},\phi\right)_\Omega & =
& \left(\theta f^{n}+(1-\theta)f^{n-1}, \phi\right)_\Omega,


@f}

其中 $\phi$ 是一个任意的测试函数，我们使用了吸收边界条件来进行部分积分：吸收边界条件通过使用以下方法被纳入到弱形式之中

@f[
\int_\Omega\varphi \, \Delta p\; dx =


-\int_\Omega\nabla \varphi \cdot \nabla p dx +
\int_{\partial\Omega}\varphi \frac{\partial p}{\partial {\mathbf n}}ds.


@f]



由此，我们通过引入有限数量的形状函数得到离散模型，并得到

@f{eqnarray*}
M\bar{p}^{n}-k \theta M v^n & = & M\bar{p}^{n-1}+k (1-\theta)Mv^{n-1},\\


(-c_0^2k \theta A-c_0 B)\bar{p}^n-Mv^{n} & = &
(c_0^2k(1-\theta)A-c_0B)\bar{p}^{n-1}-Mv^{n-1}+c_0^2k(\theta F^{n}+(1-\theta)F^{n-1}).


@f}

这里的矩阵 $M$ 和 $A$ 与步骤23相同，而边界质量矩阵

@f[
	B_{ij} = \left(\varphi_i,\varphi_j\right)_{\partial\Omega}


@f]

是使用吸收性边界条件的结果。

以上两个方程可以用矩阵形式重写，压力和它的导数是一个未知矢量。

@f[
\left(\begin{array}{cc}
 M         &       -k\theta M \\
c_0^2\,k\,\theta\,A+c_0\,B  &  M   \\
               \end{array} \right)\\
\left(\begin{array}{c}
 \bar{p}^{n}    \\
 \bar{v}^{n}
              \end{array}\right)=\\
\left(\begin{array}{l}
 G_1  \\
 G_2 -(\theta F^{n}+(1-\theta)F ^{n-1})c_{0}^{2}k \\
                \end{array}\right)


@f]



其中

@f[
\left(\begin{array}{c}
G_1 \\
G_2 \\
   \end{array} \right)=\\
\left(\begin{array}{l}
 M\bar{p}^{n-1}+k(1-\theta)Mv^{n-1}\\
 (-c_{0}^{2}k (1-\theta)A+c_0 B)\bar{p}^{n-1} +Mv^{n-1}
                \end{array}\right)


@f]



通过简单的转换，就可以得到压力势及其导数的两个方程，就像前面的教程程序一样。

@f{eqnarray*}
(M+(k\,\theta\,c_{0})^{2}A+c_0k\theta B)\bar{p}^{n} & = &
G_{1}+(k\, \theta)G_{2}-(c_0k)^2\theta (\theta F^{n}+(1-\theta)F^{n-1}) \\
Mv^n & = & -(c_0^2\,k\, \theta\, A+c_0B)\bar{p}^{n}+ G_2 -
c_0^2k(\theta F^{n}+(1-\theta)F^{n-1})


@f}






<h3>What the program does</h3>

与Step-23相比，本程序增加了对简单吸收边界条件的处理。此外，它还处理了从实际实验测量得到的数据。为此，我们需要在实验也评估了真实压力场的点上评估解决方案。我们将看到如何使用 VectorTools::point_value 函数在下文中进一步做到这一点。




<h3>Appendix: PDEs with Dirac delta functions as right hand side and their transformation to an initial value problem</h3>

在推导波浪方程的初值问题时，我们最初发现该方程有一个狄拉克三角函数的导数作为右手边。

@f[
\Delta p-\frac{1}{c_0^2} \frac{\partial^2 p}{\partial t^2} = \lambda
a(\mathbf r)\frac{d\delta(t)}{dt}.


@f]

为了看看如何将这个单一的方程转化为具有初始条件的PDE的通常陈述，让我们假设物理上相当合理的介质最初处于静止状态，即 $p(t,\mathbf
r)=\frac{\partial p(t,\mathbf r)}{\partial t}=0$ 为 $t<0$  。接下来，让我们对两边的时间形成不确定的积分。

@f[
\int^t \Delta p\; dt -\int^t \frac{1}{c_0^2} \frac{\partial^2 p}{\partial t^2}
\; dt
=
\int^t \lambda a(\mathbf r)\frac{d\delta(t)}{dt} \;dt.


@f]

这立即引出了一个说法

@f[
P(t,\mathbf r) - \frac{1}{c_0^2} \frac{\partial p}{\partial t}
=
\lambda a(\mathbf r) \delta(t),


@f]

其中 $P(t,\mathbf r)$ 是这样的： $\frac{dP(t,\mathbf r)}{dt}=\Delta
p$  。接下来，我们对 $t=-\epsilon$ 到 $t=+\epsilon$ 的时间进行（定）积分，以求得

@f[
\int_{-\epsilon}^{\epsilon} P(t,\mathbf r)\; dt


- \frac{1}{c_0^2} \left[ p(\epsilon,\mathbf r) - p(-\epsilon,\mathbf r) \right]
=
\int_{-\epsilon}^{\epsilon} \lambda a(\mathbf r) \delta(t) \; dt.


@f]

如果我们利用三角洲函数的属性，即 $\int_{-\epsilon}^{\epsilon}
\delta(t)\; dt = 1$ ，并假设 $P$ 是一个时间上的连续函数，我们发现当我们让 $\epsilon$ 归零时，我们发现

@f[


- \lim_{\epsilon\rightarrow 0}\frac{1}{c_0^2} \left[ p(\epsilon,\mathbf r) - p(-\epsilon,\mathbf r) \right]
=
\lambda a(\mathbf r).


@f]

换句话说，利用 $p(-\epsilon,\mathbf r)=0$ ，我们找回了初始条件

@f[
  \frac{1}{c_0^2} p(0,\mathbf r)
  =
  \lambda a(\mathbf r).


@f]

同时，我们知道，对于每一个 $t>0$ ，三角洲函数都是零，所以对于 $0<t<T$ ，我们得到的方程式是

@f[
\Delta p-\frac{1}{c_0^2} \frac{\partial^2 p}{\partial t^2} = 0.


@f]

因此，我们从原来有些奇怪的方程中得到了一个波浪方程和一个初始条件的表示。

最后，由于我们这里有一个带有两个时间导数的方程，我们仍然需要第二个初始条件。为此，让我们回到方程中去

@f[
\Delta p-\frac{1}{c_0^2} \frac{\partial^2 p}{\partial t^2} = \lambda
a(\mathbf r)\frac{d\delta(t)}{dt}.


@f]

并从 $t=-\epsilon$ 到 $t=+\epsilon$ 进行时间整合。这就导致了

@f[
P(\epsilon)-P(-\epsilon)


-\frac{1}{c_0^2} \left[\frac{\partial p(\epsilon)}{\partial t} -
                       \frac{\partial p(-\epsilon)}{\partial t}\right]
 = \lambda a(\mathbf r) \int_{-\epsilon}^{\epsilon}\frac{d\delta(t)}{dt} \; dt.


@f]

使用部分整合的形式

@f[
  \int_{-\epsilon}^{\epsilon}\varphi(t)\frac{d\delta(t)}{dt} \; dt
  =


  -\int_{-\epsilon}^{\epsilon}\frac{d\varphi(t)}{dt} \delta(t)\; dt


@f]

在这里我们使用 $\delta(\pm \epsilon)=0$ 并插入 $\varphi(t)=1$ ，我们看到事实上

@f[
  \int_{-\epsilon}^{\epsilon}\frac{d\delta(t)}{dt} \; dt
  =
  0.


@f]



现在，让 $\epsilon\rightarrow 0$  。假设 $P$ 是一个时间上的连续函数，我们看到

@f[
  P(\epsilon)-P(-\epsilon) \rightarrow 0,


@f]

因此

@f[
  \frac{\partial p(\epsilon)}{\partial t} -
                       \frac{\partial p(-\epsilon)}{\partial t}
		       \rightarrow 0.


@f]

然而，我们已经假设 $\frac{\partial p(-\epsilon)}{\partial t}=0$  。因此，我们得到的第二个初始条件是

@f[
  \frac{\partial p(0)}{\partial t} = 0,


@f]

完成方程组。


examples/step-24/doc/results.dox



<h1>Results</h1>

该程序将每个时间步骤的图形数据以及每个探测器位置的评估值都写入磁盘。然后我们将它们绘制成图。还收集了实验数据进行比较。目前，我们的实验只在二维空间通过圆形扫描单个探测器进行。这里的组织样本是 $X-Y$ 平面的薄片（ $Z=0$ ），我们假设其他 $Z$ 方向的信号不会对数据产生影响。因此，我们只需要将我们的实验数据与二维模拟数据进行比较。

<h3> One absorber </h3>

这部电影显示了由单个小吸收器产生的热声波在介质中传播（在我们的模拟中，我们假设介质是矿物油，其声速为1.437  $\frac{mm}{\mu s}$  ）。

 <img src="https://www.dealii.org/images/steps/developer/step-24.one_movie.gif" alt=""> 

对于单个吸收器，我们当然要相应地改变 <code>InitialValuesP</code> 类。

接下来，让我们比较一下实验和计算的结果。可视化使用了一种在地震学中长期使用的技术，即把每个探测器的数据全部绘制在一张图上。这样做的方法是将每个探测器的信号与前一个探测器相比偏移一点。例如，这里是前四个探测器的图（从下到上，时间从左到右为微秒），使用程序中使用的源设置，与目前只有一个源的情况相比，使事情更有趣。

 <img src="https://www.dealii.org/images/steps/developer/step-24.traces.png" alt=""> 

例如，可以看到的一点是，第二和第四个信号的到达时间在探测器数量较多的情况下（即最上面的探测器）会转移到较早的时间，但第一和第三信号则不然；这可以解释为这些信号的起源必须比前者更接近后一个探测器。

如果我们不仅将4个，而是将所有160个探测器堆叠在一张图中，单个线条就会变得模糊，但在它们运行在一起的地方，就会形成一种较深或较浅的灰度模式。  下面两张图显示了在以这种方式堆叠的探测器位置获得的结果。左图是由实验得到的，右图是模拟数据。在实验中，一个小的强吸收器被嵌入到较弱的吸收组织中。

 <table width="100%">
<tr>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-24.one.png" alt="">
</td>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-24.one_s.png" alt="">
</td>
</tr>
</table> 

很明显，在角度 $180^\circ$ 处，源的位置离探测器更近。在实验数据中可以看到的所有其他信号都是由于组织的其他部分也有弱的吸收体，这些吸收体环绕着中心的小强吸收体产生的信号。另一方面，在模拟数据中，我们只模拟了小的强吸收体。

在现实中，探测器的带宽有限。因此，通过探测器的热声波将被过滤掉。通过使用高通滤波器（在MATLAB中实现并针对本程序产生的数据文件运行），可以使模拟结果看起来更接近于实验数据。

 <img src="https://www.dealii.org/images/steps/developer/step-24.one_sf.png" alt=""> 

在我们的模拟中，我们看到主波后面的假信号是由数值伪影造成的。这个问题可以通过使用更细的网格来缓解，从而得到下面的图。

 <img src="https://www.dealii.org/images/steps/developer/step-24.one_s2.png" alt=""> 




<h3>Multiple absorbers</h3>

为了进一步验证该程序，我们还将展示多个吸收器的模拟结果。这与程序中实际实现的情况相对应。下面的影片显示了由多个吸收器产生的热声波在介质中的传播情况。

 <img src="https://www.dealii.org/images/steps/developer/step-24.multi_movie.gif" alt=""> 

实验数据和我们的模拟数据在以下两个图中进行了比较。   <table width="100%">
<tr>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-24.multi.png" alt="">
</td>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-24.multi_s.png" alt="">
</td>
</tr>
</table> 

请注意，在实验数据中，第一个信号（即最左边的暗线）来自于组织边界的吸收，因此首先到达检测器，比来自内部的任何信号都要早。这个信号在痕迹的末端也是微弱可见的，大约在30 $\mu s$ ，这表明信号穿过整个组织到达另一侧的探测器，在所有来自内部的信号到达它们之后。

和以前一样，通过应用符合探测器实际行为的带宽滤波器（左）和选择更细的网格（右），数值结果与实验结果更加匹配。

 <table width="100%">
<tr>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-24.multi_sf.png" alt="">
</td>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-24.multi_s2.png" alt="">
</td>
</tr>
</table> 

左图和右图的一个重要区别是，右图的曲线看起来没有那么多 "棱角"。角度来自于这样一个事实：虽然连续方程中的波在各个方向上的移动速度相同，但离散化后的情况并非如此：在那里，对角线上的波与平行于网格线的波的移动速度略有不同。这种各向异性导致波前不是完全的圆形（在堆积图中会产生正弦信号），而是在某些方向上凸出。更糟糕的是，我们使用的圆形网格（例如，见步骤6的粗略网格图）也不是各向同性的。最终的结果是，除非网格足够细，否则信号锋面不是正弦波的。右图在这方面要好得多，尽管仍然可以看到拖尾假波形式的伪影。


examples/step-25/doc/intro.dox

<a name="Intro"></a> <h1>Introduction</h1>。

这个程序是由德克萨斯A&amp;M大学的Ivan Christov的一个学生项目发展而来的。这个程序的大部分工作都是由他完成的。

这个程序的目标是解决1、2或3空间维度的正弦戈登孤子方程。解决这个方程的动机是对二维和三维解的性质知之甚少，尽管一维情况已经被广泛研究。

确切地说，正弦-戈登方程的名称是对所谓的克莱因-戈登方程的双关语，它是薛定谔方程的相对论版本，适用于非零质量的粒子。这种相似性不仅仅是表面的，正弦-戈登方程已经被证明可以模拟一些统一场现象，如亚原子粒子的相互作用（见，例如，Perring &amp; Skyrme in Nuclear %Physics <b>31</b>）和超导体结中的约瑟夫森（量子）效应（见，例如<a
href="http://en.wikipedia.org/wiki/Long_Josephson_junction">http://en.wikipedia.org/wiki/Long_Josephson_junction</a>）。此外，从数学的角度来看，由于正弦戈登方程是 "完全可积分的"，它是使用反散射变换等通常方法研究的候选者。因此，多年来，人们发现了许多有趣的孤波，甚至是静止的正弦戈登方程解。在这些解中，粒子对应于局部特征。关于正弦戈登方程、反散射变换和其他寻找分析性孤子方程的方法的更多信息，读者应参考以下关于该主题的 "经典 "参考资料。G. L. Lamb的<i>Elements of Soliton
Theory</i>（第5章，第2节）和G. B. Whitham的<i>Linear and
Nonlinear Waves</i>（第17章，10-13节）。

 @note  我们将在第58步中介绍量子力学中一个单独的非线性方程，即非线性Schr&ouml;dinger方程。

<h3>Statement of the problem</h3> 我们希望解决的正弦戈登初始边界值问题（IBVP）由以下方程组成。

\f{eqnarray*}
  u_{tt}-\Delta u &=& -\sin(u) \quad\mbox{for}\quad (x,t) \in \Omega \times (t_0,t_f],\\
  {\mathbf n} \cdot \nabla u &=& 0 \quad\mbox{for}\quad (x,t) \in \partial\Omega
           \times (t_0,t_f],\\
  u(x,t_0) &=& u_0(x).
\f} 这是一个非线性方程，类似于我们在步骤23和步骤24中讨论的波浪方程。我们选择执行零诺伊曼边界条件，以使波从我们的域的边界上反射出去。然而，应该注意的是，迪里希特边界条件对这个问题并不合适。尽管正弦戈登方程的解是局部的，但只有在 $x=\pm\infty$ 处指定（迪里希特）边界条件才有意义，否则要么不存在解，要么只存在微不足道的解 $u=0$ 。

然而，上述方程的形式对于数值离散化来说并不理想。如果我们要直接准确地离散二阶时间导数，那么我们将需要一个大的模板（即需要在内存中保留几个时间步长），这可能变得很昂贵。因此，与我们在步骤23和步骤24中所做的完全类似，我们将二阶（时间上）正弦-戈登方程拆分为两个一阶（时间上）方程系统，我们称之为拆分，或速度公式。为此，通过设置 $v = u_t$ ，很容易看到正弦-戈登方程等同于

\f{eqnarray*}
  u_t - v &=& 0,\\
  v_t - \Delta u &=& -\sin(u).
\f}

现在，我们可以使用 $\theta$ 方法对分裂公式进行时间离散，该方法的模板只有两个时间步长。通过选择 $\theta\in [0,1]$ ，后者的离散化允许我们从一系列的方案中进行选择。特别是，如果我们选择 $\theta=0$ 或 $\theta=1$ ，我们可以分别得到一阶精确的显式或隐式欧拉方法。另一个重要的选择是 $\theta=\frac{1}{2}$ ，它给出了二阶精确的Crank-Nicolson方案。因此，上标 $n$ 表示在 $n^{\mathrm{th}}$ 时间步长的变量值，即在 $t=t_n \dealcoloneq n k$ ，其中 $k$ 是（固定）时间步长。因此，时间分解的正弦-戈登方程的拆分表述为

\f{eqnarray*}
  \frac{u^n - u^{n-1}}{k} - \left[\theta v^n + (1-\theta) v^{n-1}\right] &=& 0,\\
  \frac{v^n - v^{n-1}}{k} - \Delta\left[\theta u^n + (1-\theta) u^{n-1}\right]
  &=& -\sin\left[\theta u^n + (1-\theta) u^{n-1}\right].
\f}

我们可以通过一点代数来简化后者。从第一个方程中排除 $v^n$ 并重新排列，我们可以得到

\f{eqnarray*}
  \left[ 1-k^2\theta^2\Delta \right] u^n &=&
         \left[ 1+k^2\theta(1-\theta)\Delta\right] u^{n-1} + k v^{n-1}


         - k^2\theta\sin\left[\theta u^n + (1-\theta) u^{n-1}\right],\\
   v^n &=& v^{n-1} + k\Delta\left[ \theta u^n + (1-\theta) u^{n-1}\right]


         - k\sin\left[ \theta u^n + (1-\theta) u^{n-1} \right].
\f}

在这一点上，我们似乎可以直接进行空间离散化的方程。虽然这对第二个方程（在 $v^n$ 中是线性的）来说是正确的，但这对所有的 $\theta$ 来说是不可行的，因为上面的第一个方程是非线性的。因此，必须实现一个非线性求解器，然后将方程在空间中离散化并求解。

为此，我们可以使用牛顿方法。给定非线性方程 $F(u^n) = 0$ ，我们对 $u^n$ 产生连续的近似值，如下。

\f{eqnarray*}
  \mbox{ Find } \delta u^n_l \mbox{ s.t. } F'(u^n_l)\delta u^n_l = -F(u^n_l)
  \mbox{, set }  u^n_{l+1} = u^n_l + \delta u^n_l.
\f} 迭代可以用旧的时间步长进行初始化，即 $u^n_0 = u^{n-1}$  ，最终会产生分裂公式的第一个方程的解（见上文）。对于这里所考虑的正弦-戈登方程的时间离散化，我们有

\f{eqnarray*}
  F(u^n_l) &=&  \left[ 1-k^2\theta^2\Delta \right] u^n_l -
                 \left[ 1+k^2\theta(1-\theta)\Delta\right] u^{n-1} - k v^{n-1}
                 + k^2\theta\sin\left[\theta u^n_l + (1-\theta) u^{n-1}\right],\\
  F'(u^n_l) &=& 1-k^2\theta^2\Delta + k^2\theta^2\cos\left[\theta u^n_l
                        + (1-\theta) u^{n-1}\right].
\f} 注意，虽然 $F(u^n_l)$ 是一个函数，但 $F'(u^n_l)$ 是一个运算符。

<h3>Weak formulation of the time-discretized equations</h3> 事后看来，我们选择解和检验空间都是 $H^1(\Omega)$  。因此，乘以测试函数 $\varphi$ 并进行积分，我们得到每个时间步长的分裂公式（包括第一个方程的非线性求解器）的以下变分（或弱）公式。

\f{eqnarray*}
  &\mbox{ Find}& \delta u^n_l \in H^1(\Omega) \mbox{ s.t. }
  \left( F'(u^n_l)\delta u^n_l, \varphi \right)_{\Omega}
  = -\left(F(u^n_l), \varphi \right)_{\Omega} \;\forall\varphi\in H^1(\Omega),
  \mbox{ set } u^n_{l+1} = u^n_l + \delta u^n_l,\; u^n_0 = u^{n-1}.\\
  &\mbox{ Find}& v^n \in H^1(\Omega) \mbox{ s.t. }
  \left( v^n, \varphi \right)_{\Omega} = \left( v^{n-1}, \varphi \right)_{\Omega}


         - k\theta\left( \nabla u^n, \nabla\varphi \right)_{\Omega}


         - k (1-\theta)\left( \nabla u^{n-1}, \nabla\varphi \right)_{\Omega}


         - k\left(\sin\left[ \theta u^n + (1-\theta) u^{n-1} \right],
         \varphi \right)_{\Omega} \;\forall\varphi\in H^1(\Omega).
\f}注意，我们在涉及拉普拉斯算子的所有项上使用了分项积分和零诺伊曼边界条件。此外， $F(\cdot)$ 和 $F'(\cdot)$ 如上定义， $(\cdot,\cdot)_{\Omega}$ 表示域 $\Omega$ 上通常的 $L^2$ 内积，即 $(f,g)_{\Omega} = \int_\Omega fg
\,\mathrm{d}x$  。最后，请注意，第一个方程实际上是一个迭代程序的定义，所以在每个时间步骤中，它被多次解决，直到满足停止标准。

<h3>Discretization of the weak formulation in space</h3>使用有限元方法，我们在空间中离散变量公式。为此，让 $V_h$ 成为一个具有节点基 $\{\varphi_1,\ldots,\varphi_N\}$ 的有限元空间（ $\mathrm{dim}\, V_h = N
< \infty$ ）。现在，我们可以用节点基来展开弱公式（见上文）中的所有函数。此后，我们将用大写字母表示一个函数的系数向量（在节点基中），用小写字母表示；例如， $u^n = \sum_{i=1}^N
U^n_i \varphi_i$  其中 $U^n \in {R}^N$  和 $u^n \in
H^1(\Omega)$  。因此，变量公式的有限维版本要求我们在每个时间步长中解决以下矩阵方程。

@f{eqnarray*}
  F_h'(U^{n,l})\delta U^{n,l} &=& -F_h(U^{n,l}), \qquad
        U^{n,l+1} = U^{n,l} + \delta U^{n,l}, \qquad U^{n,0} = U^{n-1}; \\
  MV^n &=& MV^{n-1} - k \theta AU^n -k (1-\theta) AU^{n-1} - k S(u^n,u^{n-1}).


@f}

以上，矩阵 $F_h'(\cdot)$ 和向量 $F_h(\cdot)$ 表示上面讨论的小工具的离散版本，即。

\f{eqnarray*}
  F_h(U^{n,l}) &=&  \left[ M+k^2\theta^2A \right] U^{n,l} -
                \left[ M-k^2\theta(1-\theta)A \right] U^{n-1} - k MV^{n-1}
                + k^2\theta S(u^n_l, u^{n-1}),\\
  F_h'(U^{n,l}) &=& M+k^2\theta^2A
                                + k^2\theta^2N(u^n_l,u^{n-1})
\f} 再次注意，上面的第一个矩阵方程实际上是迭代程序的定义，所以它被多次求解，直到满足停止标准。此外， $M$ 是质量矩阵，即 $M_{ij} = \left( \varphi_i,\varphi_j \right)_{\Omega}$  ， $A$ 是拉普拉斯矩阵，即 $A_{ij} = \left( \nabla \varphi_i, \nabla
\varphi_j \right)_{\Omega}$  ， $S$  是定义我们的辅助速度变量的方程中的非线性项，即 $S_j(f,g) = \left(
  \sin\left[ \theta f + (1-\theta) g\right], \varphi_j \right)_{\Omega}$  ， $N$  是 $F(\cdot)$  的雅各布矩阵中的非线性项，即 $N_{ij}(f,g) = \left( \cos\left[ \theta f + (1-\theta) g\right]\varphi_i,
  \varphi_j \right)_{\Omega}$  。

对于第一个方程，我们可以用什么解法？让我们来看看我们要反转的矩阵。

@f[
  (M+k^2\theta^2(A + N))_{ij} =
  \int_\Omega (1+k^2\theta^2 \cos \alpha)
  \varphi_i\varphi_j \; dx
  + k^2 \theta^2 \int_\Omega \nabla\varphi_i\nabla\varphi_j \; dx,


@f]

为一些 $\alpha$ ，取决于现在和以前的解决方案。首先，请注意，该矩阵是对称的。此外，如果时间步长 $k$ 足够小，即如果 $k\theta<1$ ，那么该矩阵也将是正定的。在下面的程序中，情况总是这样的，所以我们将使用共轭梯度法和SSOR法作为预处理。然而，我们应该记住，如果我们碰巧使用更大的时间步长，这将失败。幸运的是，在这种情况下，求解器将只是抛出一个异常，表明收敛失败，而不是默默地产生一个错误的结果。如果发生这种情况，那么我们可以简单地用能够处理不确定对称系统的方法取代CG方法。GMRES求解器通常是处理所有 "坏 "线性系统的标准方法，但它也是一个缓慢的方法。更好的方法可能是利用对称性的求解器，例如，SymmLQ，它也在deal.II中实现。

这个程序在步骤23和 @ref
step_24 "步骤24 "上使用了巧妙的优化。如果你仔细阅读上述公式，就会发现，速度 $V$ 只出现在与质量矩阵的乘积中。因此，在步骤23和步骤24中，我们有点浪费：在每个时间步骤中，我们会用质量矩阵求解一个线性系统，只是在下一个时间步骤中再次将该系统的解乘以 $M$ 。当然，这可以避免，我们在这个程序中也是这样做的。




<h3>The test case</h3>

正弦戈登方程有几个分析解，包括一维和二维的。特别是，该程序如是计算一个具有单一的类似激波的初始条件的问题的解。  这个解是由Leibbrandt在Phys.Rev.Lett.中给出的。\b 41(7)中给出，并在 <code>ExactSolution</code> 类中实现。

应该注意的是，严格来说，这个闭式解只适用于无限空间的初值问题（而不是这里考虑的诺伊曼初界值问题）。然而，鉴于我们施加了零诺依曼边界条件，我们期望我们的初始边界值问题的解将接近无限空间初始值问题的解，如果波在我们领域的边界上的反射没有发生。在实践中，情况当然不是这样的，但我们至少可以假设是这样的。

二维解决方案中的常数 $\vartheta$ 和 $\lambda$ 以及三维解决方案中的 $\vartheta$ 、 $\phi$ 和 $\tau$ 被称为B&auml;cklund变换参数。它们控制诸如扭结的方向和陡度。为了测试代码与精确解的对比，我们应该选择这些参数，使扭结与网格保持一致。

我们在 <code>ExactSolution</code> 类中实现的解决方案是这些。   <ul>   <li>  在1D中：@f[
  u(x,t) =


  -4 \arctan\left[
     \frac{m}{\sqrt{1-m^2}}
     \frac{\sin\left(\sqrt{1-m^2}t+c_2\right)}
     {\cosh\left(mx+c_1\right)}
     \right],
  @f] 。

  其中我们选择  $m=\frac 12, c_1=c_2=0$  。

  在一维中，已知有更多有趣的分析解决方案。他们中的许多人被列在http://mathworld.wolfram.com/Sine-GordonEquation.html。

    <li>  在2D：@f[
    u(x,y,t) = 4 \arctan \left[a_0 e^{s\xi}\right],
  @f] 。

  其中 $\xi$ 被定义为@f[
    \xi = x \cos\vartheta + \sin(\vartheta) (y\cosh\lambda + t\sinh \lambda),
  @f]。

  而在这里我们选择 $\vartheta=\frac \pi 4, \lambda=a_0=s=1$ 。

    <li>  在三维：@f[
    u(x,y,z,t) = 4 \arctan \left[c_0 e^{s\xi}\right],
  @f] 。

  其中 $\xi$ 被定义为@f[
    \xi = x \cos\vartheta + y \sin \vartheta \cos\phi +
          \sin \vartheta \sin\phi (z\cosh\tau + t\sinh \tau),
  @f]。

  而在这里，我们选择 $\vartheta=\phi=\frac{\pi}{4}, \tau=c_1=s=1$  。   </ul> 


由于这使得玩起来更容易，用于设置&mdash;惊喜！&mdash;我们模拟的初始值的 <code>InitialValues</code> 类只是查询了描述初始时值的精确解的类，而不是重复实现解函数的努力。


examples/step-25/doc/results.dox



<h1>Results</h1>显式欧拉时间步长方案（ $\theta=0$ ）对于我们希望解决的问题来说表现得很充分。不幸的是，由于稳定性问题，必须选择一个相当小的时间步长 ----  $k\sim h/10$ 似乎对我们进行的大多数模拟都有效。另一方面，Crank-Nicolson方案（ $\theta=\frac{1}{2}$ ）是无条件稳定的，而且（至少对于一维呼吸器的情况）我们可以选择大到 $25h$ 的时间步长而不对解决方案产生任何不良影响。隐式欧拉方案（ $\theta=1$ ）是 "指数阻尼 "的，所以它不是解决正弦戈登方程的好选择，因为它是保守的。然而， $\theta$ 方法提供的连续体中的一些阻尼方案对于消除边界效应引起的虚假振荡很有用。

在下面的模拟中，我们在一维的区间 $\Omega =
[-10,10]$ 和二维的正方形 $\Omega = [-10,10]\times [-10,10]$ 上解决正弦-戈登方程。在每种情况下，各自的网格被均匀地细化了6次，即 $h\sim
2^{-6}$  。

<h3>An (1+1)-d Solution</h3> 我们讨论的第一个例子是正弦-戈登方程的所谓一维（静止的）呼吸器解。正如介绍中提到的，呼吸器有如下闭合形式的表达。

\f[
u_{\mathrm{breather}}(x,t) = -4\arctan \left(\frac{m}{\sqrt{1-m^2}} \frac{\sin\left(\sqrt{1-m^2}t +c_2\right)}{\cosh(mx+c_1)} \right),
\f] 其中 $c_1$  ,  $c_2$  和  $m<1$  是常数。在下面的模拟中，我们选择了  $c_1=0$  ,  $c_2=0$  ,  $m=0.5$  。此外，我们知道呼吸器的振荡周期是 $2\pi\sqrt{1-m^2}$ ，因此我们选择 $t_0=-5.4414$ 和 $t_f=2.7207$ ，这样我们可以观察到解决方案的三次振荡。然后，取 $u_0(x) = u_{\mathrm{breather}}(x,t_0)$ 、 $\theta=0$ 和 $k=h/10$ ，程序计算出以下解。

 <img src="https://www.dealii.org/images/steps/developer/step-25.1d-breather.gif" alt="Animation of the 1D stationary breather."> 

虽然程序中没有显示如何做，但另一种可视化(1+1)-d解决方案的方法是使用DataOutStack类产生的输出；它允许 "堆叠 "单个时间步骤的解决方案，因此我们从一维时间相关的解决方案中得到二维时空图。这就产生了下面的时空图，而不是上面的动画。

 <img src="https://www.dealii.org/images/steps/developer/step-25.1d-breather_stp.png" alt="A space-time plot of the 1D stationary breather."> 

此外，由于呼吸器是正弦-戈登方程的分析解，我们可以用它来验证我们的代码，尽管我们必须假设我们选择的诺伊曼边界条件引入的误差与数值误差相比是很小的。在这种假设下，可以使用 VectorTools::integrate_difference 函数来计算数值解和本程序的 <code>ExactSolution</code> 类描述的函数之间的差异。对于上面两幅图所示的模拟，每个时间步长的有限元解的 $L^2$ 误差的规范保持在 $10^{-2}$ 的数量级。因此，我们可以得出结论，数值方法在程序中得到了正确的实现。




<h3>A few (2+1)D Solutions</h3>

在文献中可以找到的正弦戈登方程在(2+1)D中的唯一分析解是所谓的Kink孤波。它有以下的闭合式表达。   @f[
    u(x,y,t) = 4 \arctan \left[a_0 e^{s\xi}\right]
  @f]

与@f[
    \xi = x \cos\vartheta + \sin(\vartheta) (y\cosh\lambda + t\sinh \lambda)
  @f]

其中 $a_0$ 、 $\vartheta$ 和 $\lambda$ 为常数。在下面的模拟中，我们选择了 $a_0=\lambda=1$  。请注意，如果 $\vartheta=\pi$ 是静止的，那么它将是一个很好的解决方案，我们可以用它来验证二维的程序，因为没有发生域边界的反射。

下面显示的模拟是用 $u_0(x) = u_{\mathrm{kink}}(x,t_0)$ 、 $\theta=\frac{1}{2}$ 、 $k=20h$ 、 $t_0=1$ 和 $t_f=500$ 进行的。每个时间步长的有限元解的误差的 $L^2$ 准则保持在 $10^{-2}$ 的数量级上，表明该程序在二维和一维中都能正常工作。不幸的是，这个解决方案并不十分有趣，不过为了完整起见，我们还是在下面附上了它的快照。

 <img src="https://www.dealii.org/images/steps/developer/step-25.2d-kink.png" alt="Stationary 2D kink."> 

现在我们已经在一维和二维中验证了代码，我们转到一个分析解未知的问题。

为此，我们围绕 $z$ 轴旋转上面讨论的扭结解：我们让 $\vartheta=\frac{\pi}{4}$  .后者的结果是一个不与网格对齐的孤波，所以反射立即发生在域的边界。对于下面所示的模拟，我们采取了 $u_0(x)=u_{\mathrm{kink}}(x,t_0)$ 、 $\theta=\frac{2}{3}$ 、 $k=20h$ 、 $t_0=0$ 和 $t_f=20$  。此外，我们不得不选择 $\theta=\frac{2}{3}$ ，因为对于任何 $\theta\le\frac{1}{2}$ 的边界都会产生振荡，这可能是由于方案而不是方程造成的，因此选择 $\theta$ 的值，在时间步进方案的 "指数阻尼 "频谱中，确保这些振荡不会被产生。

 <img src="https://www.dealii.org/images/steps/developer/step-25.2d-angled_kink.gif" alt="Animation of a moving 2D kink, at 45 degrees to the axes of the grid, showing boundary effects."> 

正弦-戈登方程的另一个有趣的解决方案（不能通过分析获得）可以通过使用两个一维呼吸器来构建以下可分离的二维初始条件来产生。

\f[
  u_0(x) =
  u_{\mathrm{pseudobreather}}(x,t_0) =
  16\arctan \left(
    \frac{m}{\sqrt{1-m^2}}
    \frac{\sin\left(\sqrt{1-m^2}t_0\right)}{\cosh(mx_1)} \right)
  \arctan \left(
    \frac{m}{\sqrt{1-m^2}}
    \frac{\sin\left(\sqrt{1-m^2}t_0\right)}{\cosh(mx_2)} \right),
\f] 其中 $x=(x_1,x_2)\in{R}^2$  ,  $m=0.5<1$  与我们上面讨论的一维情况一样。在下面的模拟中，我们选择了 $\theta=\frac{1}{2}$ 、 $k=10h$ 、 $t_0=-5.4414$ 和 $t_f=2.7207$ 。解决方案是相当有趣的



 <img src="https://www.dealii.org/images/steps/developer/step-25.2d-pseudobreather.gif" alt="Animation of a 2D pseudobreather."> 


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

改变初始条件是有意义的。大多数选择不会导致保持局部的解决方案（在孤子界，这样的解决方案被称为 "静止的"，尽管解决方案确实随时间变化），而是导致方程的波状特征占主导地位的解决方案，并且波从局部初始条件的位置传播出去。例如，值得玩一玩 <code>InitialValues</code> 类，把对 <code>ExactSolution</code> 类的调用换成类似这样的函数。

@f[
  u_0(x,y) = \cos\left(\frac x2\right)\cos\left(\frac y2\right)


@f]

如果 $|x|,|y|\le \frac\pi 2$ ，和 $u_0(x,y)=0$ 在这个区域之外。

第二个方面是研究该方案是否是能量保持的。对于 @ref
step_23 "step-23 "中讨论的纯波方程，如果我们选择时间步进参数，使我们得到Crank-Nicolson方案，情况就是这样。我们可以在这里做类似的事情，注意到正弦-戈登解中的能量被定义为

@f[
  E(t) = \frac 12 \int_\Omega \left(\frac{\partial u}{\partial
  t}\right)^2
  + \left(\nabla u\right)^2 + 2 (1-\cos u) \; dx.


@f]

(我们在公式中使用 $1-\cos u$ 而不是 $-\cos u$ ，以确保对能量的所有贡献都是正的，从而使衰变的解在无界域上具有有限的能量。)

除此以外，还有两个明显的领域。

- 显然，自适应性（即时间自适应网格）会对这样的问题产生兴趣。它们的复杂性导致我们再次将其排除在本方案之外，尽管 @ref step_23 "step-23 "介绍中的一般评论仍然正确。

- 解决这个问题的更快方案。虽然今天的计算机已经足够快，可以在不长的时间内解决二维甚至三维静止的问题，但与时间相关的问题则是完全不同的一类问题。我们在步骤48中讨论了这个问题，我们展示了如何在不组装或倒置任何矩阵的情况下并行解决这个问题。


examples/step-26/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{29,30}  （  @dealiiVideoLectureSeeAlso{31.7})  。


这个程序实现了热方程

@f{align*}
  \frac{\partial u(\mathbf x, t)}{\partial t}


  -
  \Delta u(\mathbf x, t)
  &=
  f(\mathbf x, t),
  \qquad\qquad &&
  \forall \mathbf x \in \Omega, t\in (0,T),
  \\
  u(\mathbf x, 0) &= u_0(\mathbf x) &&
  \forall \mathbf x \in \Omega, \\
  \\
  u(\mathbf x, t) &= g(\mathbf x,t) &&
  \forall \mathbf x \in \partial\Omega, t \in (0,T).


@f}

从某种意义上说，这个方程比我们在前面的程序步骤23、步骤24、步骤25中讨论的方程，即波浪方程要简单。这是由于热方程随着时间的推移使解变得平滑，因此在许多方面更宽容。例如，当使用隐式时间步长方法时，我们实际上可以采取大的时间步长，我们对通过每隔几步适应网格而引入的小干扰的麻烦较小，等等。

我们在这里的目标将是使用theta-scheme解决上述方程，该方程在时间上离散，使用以下方法，我们希望 $u^n(\mathbf x)$ 在某个时间 $t_n$ 近似 $u(\mathbf x, t_n)$  。

@f{align*}
  \frac{u^n(\mathbf x)-u^{n-1}(\mathbf x)}{k_n}


  -
  \left[
  (1-\theta)\Delta u^{n-1}(\mathbf x)
  +
  \theta\Delta u^n(\mathbf x)
  \right]
  &=
  \left[
  (1-\theta)f(\mathbf x, t_{n-1})
  +
  \theta f(\mathbf x, t_n)
  \right].


@f}

这里， $k_n=t_n-t_{n-1}$ 是时间步长。Theta-scheme概括了显式欧拉（  $\theta=0$  ）、隐式欧拉（  $\theta=1$  ）和Crank-Nicolson（  $\theta=\frac 12$  ）时间离散。由于后者具有最高的收敛顺序，我们将在下面的程序中选择 $\theta=\frac 12$ ，但要使这个参数的操作保持简单。如果你对玩更高阶的方法感兴趣，可以看一下步骤52）。

鉴于这种时间离散化，空间离散化会像往常一样发生，通过与测试函数相乘，通过部分积分，然后将一切限制在一个有限维的子空间。在与 $k_n$ 相乘之后，这就产生了以下一组完全离散的方程。

@f{align*}
  M U^n-MU^{n-1}
  +
  k_n \left[
  (1-\theta)A U^{n-1}
  +
  \theta A U^n
  \right]
  &=
  k_n
  \left[
  (1-\theta)F^{n-1}
  +
  \theta F^n
  \right],


@f}

其中 $M$ 是质量矩阵， $A$ 是将拉普拉斯离散化后的刚度矩阵。将所有已知的量带到右手边，就得到了我们在每一步都要解决的线性系统。

@f{align*}
  (M
  +
  k_n \theta A) U^n
  &=
  MU^{n-1}


  -
  k_n
  (1-\theta)A U^{n-1}
  +
  k_n
  \left[
  (1-\theta)F^{n-1}
  +
  \theta F^n
  \right].


@f}

左手边的线性系统是对称和正定的，所以我们用共轭梯度法解决它应该没有问题。

如果我们在初始时间有一组节点系数 $U^0$ ，我们可以开始上面的迭代。在这里，我们采取的是将初始值 $u_0(\mathbf x)$ 插值到用于第一个时间步长的网格上得到的那些。我们还需要选择一个时间步长；在这里我们只选择固定的时间步长，但显然先进的模拟器会希望自适应地选择它。我们将在<a href="#Results">results section
below</a>中简要地回到这个问题。




<h3> Adapting meshes for time dependent problems </h3>

在前面几个程序中求解波浪方程及其变体时，我们保持了固定的网格。就像静止方程一样，我们可以很好地说明这不是最聪明的方法，通过调整网格可以节省大量资金。然而，与静止的情况相比，还有很大的困难。让我们依次来看看这些困难。

 <ul>   <li>  <i>Time step size and minimal mesh size</i> 。对于静止的问题，一般的做法是 "将网格做得越细越好"。对于有奇点的问题，这往往会导致我们在角落或界面上得到许多细化层次的情况。第一个使用自适应网格的教程，第6步，已经是一个案例的要点。

  然而，对于时间相关问题，我们通常需要选择与网格大小相关的时间步长。对于显式时间离散，这是显而易见的，因为我们需要遵守一个CFL条件，将时间步长与最小的网格尺寸联系起来。对于隐式时间离散，不存在这样的硬性限制，但在实践中，如果我们使网格尺寸变小，我们仍然希望使时间步长变小，因为我们通常有 $\|e\| \le {\cal O}(k^p + h^q)$ 形式的误差估计，其中 $p,q$ 分别是时间和空间离散的收敛阶。我们只有减少这两个项，才能使误差变小。理想情况下，这样的估计会建议选择 $k \propto h^{q/p}$  。因为，至少对于非光滑解的问题来说，误差通常集中在网格尺寸最小的单元中，所以我们必须确实选择 $k \propto h_{\text{min}}^{q/p}$  ，使用<i>smallest</i>网格尺寸。

  其结果是，在一个地方进一步细化网格不仅意味着略微增加自由度数量的适度额外努力，而且由于时间步长较小，必须更频繁地求解<i>global</i>线性系统的更大努力。

  在实践中，我们通常通过承认我们不能使时间步长任意地小，因此也不能使局部网格尺寸任意地小来处理这个问题。相反，我们设置了一个最大的细化水平，当我们标记单元进行细化时，我们只是不细化那些子单元会超过这个最大的细化水平。

  还有一个类似的问题是，我们将选择一个右手边，在不同的时间在领域的不同部分开启。为了避免在突然需要更细的网格的地方，被太粗的网格弄得措手不及，我们还将在程序中强制执行<i>minimal</i>的网格细化水平。

    <li>  <i>Test functions from different meshes</i>。让我们再次考虑我们在上面写下的半离散方程。   @f{align*}
    \frac{u^n(\mathbf x)-u^{n-1}(\mathbf x)}{k_n}


    -
    \left[
    (1-\theta)\Delta u^{n-1}(\mathbf x)
    +
    \theta\Delta u^n(\mathbf x)
    \right]
    &=
    \left[
    (1-\theta)f(\mathbf x, t_{n-1})
    +
    \theta f(\mathbf x, t_n)
    \right].
  @f}

  我们在这里可以把 $u^{n-1}$ 视为数据，因为它可能已经被计算过了。现在，让我们替换掉@f{align*}
    u^n(\mathbf x)\approx u_h^n(\mathbf x)
    =
    \sum_j U^n \varphi_j(\mathbf x),
  @f}。

  与测试函数 $\varphi_i(\mathbf x)$ 相乘，并在必要时按部分整合。在如上所述的过程中，这将产生@f{align*}
    \sum_j
    (M
    +
    k_n \theta A)_{ij} U^n_j
    &=
    (\varphi_i, u_h^{n-1})


    -
    k_n
    (1-\theta)(\nabla \varphi_i, \nabla u_h^{n-1})
    +
    k_n
    \left[
    (1-\theta)F^{n-1}
    +
    \theta F^n
    \right].
  @f}。

  现在想象一下，我们在时间步骤  $n-1$  和  $n$  之间改变了网格。那么问题来了，我们在 $u_h^n$ 和 $u^{n-1}$ 中使用的基函数是不同的！这与右边的项有关。这与右手边的项有关，其中第一个项我们可以更清楚地写成（第二个项遵循同样的模式）@f{align*}
    (\varphi_i, u_h^{n-1})
    =
    (\varphi_i^n, u_h^{n-1})
    =
    \sum_{j=1}^{N_{n-1}}
    (\varphi_i^n, \varphi_j^{n-1}) U^{n-1}_j,
    \qquad\qquad
    i=1\ldots N_n.
  @f}

  如果在这两个时间步骤中使用的网格是相同的，那么 $(\varphi_i^n, \varphi_j^{n-1})$ 就会形成一个方形的质量矩阵 $M_{ij}$  。然而，如果网格不一样，那么一般来说，矩阵是矩形的。更糟的是，甚至很难计算这些积分，因为如果我们在时间步长 $n$ 的网格单元上循环，那么我们需要在这些单元的正交点上评估 $\varphi_j^{n-1}$ ，但它们不一定对应于时间步长 $n-1$ 的网格单元，而且 $\varphi_j^{n-1}$ 不是通过这些单元定义的；如果我们想通过对网格 $n-1$ 的单元积分计算这些积分当然也是一样。

  在任何情况下，我们必须面对的情况是，我们需要整合定义在两个不同网格上的形状函数。这是可以做到的，事实上在步骤28中也有演示，但这个过程最多只能用 "笨拙 "一词来形容。

  在实践中，人们通常不希望这样做。相反，我们在每次调整网格的时候，通过从旧的网格插值到新的网格来避免整个情况。换句话说，我们不是解决上面的方程，而是解决@f{align*}
    \sum_j
    (M
    +
    k_n \theta A)_{ij} U^n_j
    &=
    (\varphi_i, I_h^n u_h^{n-1})


    -
    k_n
    (1-\theta)(\nabla \varphi_i, \nabla I_h^n u_h^{n-1})
    +
    k_n
    \left[
    (1-\theta)F^{n-1}
    +
    \theta F^n
    \right],
  @f}的问题

  其中 $I_h^n$ 是对时间步骤 $n$ 中使用的有限元空间的内插算子。这不是最佳的方法，因为它除了时间和空间离散化之外还引入了一个额外的误差，但这是一个务实的方法，使得做时间适应网格是可行的。   </ul> 




<h3> What could possibly go wrong? Verifying whether the code is correct </h3>

在实现有限元代码时，通常有许多事情会出错。特别是对于时间相关问题，以下是常见的错误来源。

- 时间积分，例如把涉及当前和前一个时间步骤的条款前面的系数弄错了（例如，把一个系数 $\theta$ 混为 $1-\theta$ ）。

- 处理右侧，例如忘记了 $k_n$ 或 $\theta$ 的系数。

- 对边界值处理不当，例如再次忘记了 $k_n$ 或 $\theta$ 的系数，或忘记了不仅对右手边而且对系统矩阵应用非零边界值。

一个不太常见的问题是把初始条件弄错了，因为通常只要输出第一个时间步长就能看出它是错的。在任何情况下，为了验证代码的正确性，有一个测试协议是很有帮助的，它允许我们分别验证这些组件中的每一个。这意味着

- 用非零初始条件但零右手边和边界值测试代码，并验证时间演化是否正确。

- 然后用零初始条件和边界值但非零的右手边进行测试，再次确保正确性。

- 最后，用零初始条件和右手边但非零边界值进行测试。

这听起来很复杂，但幸运的是，对于像这里的无系数（或常数系数）的线性偏微分方程，有一个相当标准的协议，它基于以下观察：如果你选择一个正方形 $[0,1]^2$ 作为你的领域（或者，稍加修改，一个矩形），那么精确解可以写成

@f{align*}
  u(x,y,t) = a(t) \sin(n_x \pi x) \sin(n_y \pi y)


@f}

有整数常数 $n_x,n_y$ ），如果只有初始条件、右手边和边界值也都是 $\sin(n_x \pi x) \sin(n_y \pi y)$ 的形式。这是由于函数 $\sin(n_x \pi x) \sin(n_y \pi y)$ 是拉普拉斯算子的特征函数，允许我们以分析方式计算时间因子 $a(t)$ 等东西，并因此与我们的数值结果进行比较。

作为一个例子，让我们考虑我们有 $u_0(x,y)=\sin(n_x \pi x) \sin(n_x \pi y)$ 和 $f(x,y,t)=0$ 的情况。通过上面对 $u(x,y,t)$ 的形式的主张（ansatz），我们可以得到

@f{align*}
  \left(\frac{\partial}{\partial t} -\Delta\right)
  u(x,y,t)
  &=
  \left(\frac{\partial}{\partial t} -\Delta\right)
  a(t) \sin(n_x \pi x) \sin(n_y \pi y)
  \\
  &=
  \left(a'(t) + (n_x^2+n_y^2)\pi^2 a(t) \right) \sin(n_x \pi x) \sin(n_y \pi y).


@f}

为了使其等于 $f(x,y,t)=0$ ，我们需要： 1.

@f{align*}
  a'(t) + (n_x^2+n_y^2)\pi^2 a(t) = 0


@f}

并由于初始条件， $a(0)=1$  。这个微分方程可以被整合，得到

@f{align*}
  a(t) = - e^{-(n_x^2+n_y^2)\pi^2 t}.


@f}

换句话说，如果初始条件是正弦的乘积，那么解的形状与正弦的乘积完全相同，它以已知的时间依赖性衰减到零。如果你有足够细的网格和足够小的时间步长，这一点是很容易测试的。

如果你把时间积分方案弄错了（例如，在各条款前面有错误的 $\theta$ 或 $k$ 的因子），通常会发生的情况是你没有得到正确的解的时间行为。仔细检查各种因素，直到你得到正确的行为。你可能还想验证一下，时间衰减率（例如，通过绘制固定点的解的值来确定）在你每次将时间步长或网格大小增加一倍或减少一半的时候，都不会增加。你知道这不是对边界条件或右手边的处理，因为这些都是零。

如果你已经如此验证了时间积分器的正确性，那么就拿右手边非零但初始条件为零的情况来说。   $u_0(x,y)=0$  和  $f(x,y,t)=\sin(n_x \pi x) \sin(n_x \pi y)$  。再来看看。

@f{align*}
  \left(\frac{\partial}{\partial t} -\Delta\right)
  u(x,y,t)
  &=
  \left(\frac{\partial}{\partial t} -\Delta\right)
  a(t) \sin(n_x \pi x) \sin(n_y \pi y)
  \\
  &=
  \left(a'(t) + (n_x^2+n_y^2)\pi^2 a(t) \right) \sin(n_x \pi x) \sin(n_y \pi y),


@f}

而要使其等于 $f(x,y,t)$ ，我们需要的是

@f{align*}
  a'(t) + (n_x^2+n_y^2)\pi^2 a(t) = 1


@f}

并由于初始条件， $a(0)=0$  。对这个方程进行时间积分，可以得到

@f{align*}
  a(t) = \frac{1}{(n_x^2+n_y^2)\pi^2} \left[ 1 - e^{-(n_x^2+n_y^2)\pi^2 t} \right].


@f}



同样，如果你在右手边的条款前面有 $\theta$ 或 $k$ 的错误因子，你将不会得到正确的解的时间行为，或者它将收敛到 $\frac{1}{(n_x^2+n_y^2)\pi^2}$ 以外的最大值。

一旦我们验证了使用这个方案的时间积分和右手处理是正确的，我们就可以继续验证我们的边界值是否正确，使用非常类似的方法。




<h3> The testcase </h3>

在一个简单的域上用一个简单的右手边求解热方程，几乎总是导致解非常无聊，因为它们很快就变得非常光滑，然后就不再有什么变化。相反，我们在这里用零迪里希特边界值和零初始条件在L形域上求解方程，但作为右手边我们选择

@f{align*}
  f(\mathbf x, t)
  =
  \left\{
  \begin{array}{ll}
    \chi_1(\mathbf x)
    & \text{if \(0\le t \le 0.2\tau\) or \(\tau\le t \le 1.2\tau\) or \(2\tau\le t
    \le 2.2\tau\), etc}
    \\
    \chi_2(\mathbf x)
    & \text{if \(0.5\le t \le 0.7\tau\) or \(1.5\tau\le t \le 1.7\tau\) or \(2.5\tau\le t
    \le 2.7\tau\), etc}
    \\
    0
    & \text{otherwise}
  \end{array}
  \right.


@f}

在这里。

@f{align*}
  \chi_1(\mathbf x) &=
  \left\{
  \begin{array}{ll}
    1
    & \text{if \(x>0.5\) and \(y>-0.5\)}
    \\
    0
    & \text{otherwise}
  \end{array}
  \right.
  \\
  \chi_2(\mathbf x) &=
  \left\{
  \begin{array}{ll}
    1
    & \text{if \(x>-0.5\) and \(y>0.5\)}
    \\
    0
    & \text{otherwise}
  \end{array}
  \right.


@f}

换句话说，在每一个长度为 $\tau$ 的周期中，右手边首先在域1中闪烁，然后完全关闭，然后在域2中打开，然后再次完全关闭。通过<a href="#Results">results
section</a>中显示的解决方案的小动画，这种模式可能是最好的观察。

如果你把热方程解释为寻找导电固体的空间和时间可变的温度分布，那么上面的测试案例相当于一个L形体，我们把边界保持在零温度，并在领域的两个部分交替加热。在加热的同时，这些地方的温度会上升，之后温度会扩散并再次减弱。这些初始条件的意义在于，它们为我们提供了一个在时间上（当源打开和关闭时）以及时间上（在再入角以及源作用区域的边缘和角落）都有奇点的解决方案。


examples/step-26/doc/results.dox



<h1>Results</h1>

正如许多教程一样，程序的实际输出并不重要，重要的是我们是如何到达那里的。尽管如此，它还是来了。

@code
===========================================
Number of active cells: 48
Number of degrees of freedom: 65


Time step 1 at t=0.002
     7 CG iterations.


===========================================
Number of active cells: 60
Number of degrees of freedom: 81



Time step 1 at t=0.002
     7 CG iterations.


===========================================
Number of active cells: 105
Number of degrees of freedom: 136



Time step 1 at t=0.002
     7 CG iterations.


[...]


Time step 249 at t=0.498
     13 CG iterations.
Time step 250 at t=0.5
     14 CG iterations.


===========================================
Number of active cells: 1803
Number of degrees of freedom: 2109
@endcode



也许更有意义的是解决方案的可视化和计算的网格。

 <img src="https://www.dealii.org/images/steps/developer/step-26.movie.gif" alt="Animation of the solution of step 26."> 

这部电影显示了两个信号源是如何开启和关闭的，以及网格对此的反应。很明显，现在的网格可能不是我们能想出的最好的。我们将在下一节再来讨论这个问题。


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

至少有两个方面可以大大改善这个程序：自适应时间步长和更好地选择网格。

<h4>Adaptive time stepping</h4>

由于选择了隐式时间步进方案，我们不受任何类似CFL的时间步进条件的约束。此外，由于在热力方程中发生变化的时间尺度不受细胞直径的约束（与波浪方程的情况不同，在波浪方程中我们有一个固定的信息传输速度，将时间尺度和空间尺度联系起来），我们可以随意选择时间步长。或者，最好是按照我们认为必要的准确性来选择它。

看一下解决方案，很明显，行动并不是随时间均匀发生的：在我们打开一个源的时候，很多东西都在发生变化，一旦一个源开启了一段时间，事情就变得不那么戏剧化了，而当两个源都关闭的时候，我们进入了一个漫长的下降阶段。在这些时候，我们肯定可以在不牺牲太多精确度的情况下，采用比以前更大的时间步长。

文献中有许多关于如何自适应地选择时间步长的建议。例如，可以从ODE求解器选择其时间步长的方式中学到很多。我们也可以从后验误差估计中得到启发，理想情况下，后验误差估计可以写成由对整体误差的时间和空间贡献组成。如果时间上的贡献太大，我们应该选择一个较小的时间步长。例如，这个方向的想法可以在deal.II的前主要开发者Ralf Hartmann的博士论文中找到，该论文由德国海德堡大学在2002年出版。




<h4>Better time stepping methods</h4>

我们在这里使用了一种比较简单的时间步进方法，即二阶时间的Crank-Nicolson方法。然而，更精确的方法如Runge-Kutta方法是可用的，并且应该使用，因为它们并不代表很多额外的努力。对于目前的程序来说，实现这一点并不困难，但在step-52中也给出了一个更系统的处理。




<h4>Better refinement criteria</h4>

如果你看一下上面电影中的网格，很明显，它们不是特别适合手头的任务。事实上，它们看起来相当随意。

有两个因素在起作用。首先，有一些岛屿，其中的单元已经被细化，但周围是未细化的单元（可能还有一些偶尔被粗化的岛屿）。这些并不可怕，因为它们大多数时候并不影响网格的近似质量，但是它们也没有帮助，因为它们的许多额外的自由度事实上受到悬挂节点约束的限制。也就是说，这很容易解决：Triangulation类在其构造函数中接受一个参数，表示 "网格平滑 "的程度。传递许多可能的标志之一，这将指示三角剖分细化一些额外的单元，或者不细化一些单元，这样得到的网格就不会有这些伪影。

第二个问题更为严重：网格似乎滞后于解。其根本原因是我们每隔五步才调整一次网格，而且在这些情况下只允许进行一次细化。每当一个源打开时，之前的解在这个区域是非常平滑的，因此网格也是相当粗糙的。这意味着在下一个时间步骤中，当我们细化网格时，我们会在这个区域多得到一个细化级别，五个时间步骤后再多一个级别，等等。但这还不够：首先，我们应该在一个源打开时立即进行细化（毕竟在当前情况下，我们至少知道右手边是什么），而且我们应该允许超过一个细化级别。当然，所有这些都可以用deal.II来完成，只是需要在如何使其发挥作用方面有一些算法上的思考!




<h4>Positivity preservation</h4>

为了提高你的模拟在时间上的准确性和分辨率，通常会减少时间步长  $k_n$  。如果你在这个特定的例子中开始玩弄时间步长，你会注意到，如果 $k_n$ 低于某个阈值，解决方案会变成部分负数。这不是我们所期望发生的（在自然界）。

为了从数学上了解这种行为，让我们考虑一个一般的、完全离散的问题。

@f{align*}
  A u^{n} = B u^{n-1}.


@f}

那么 $i$ th方程的一般形式为：。

@f{align*}
  a_{ii} u^{n}_i &= b_{ii} u^{n-1}_i +
  \sum\limits_{j \in S_i} \left( b_{ij} u^{n-1}_j - a_{ij} u^{n}_j \right),


@f}

其中 $S_i$ 是与DoF $i$ 耦合的自由度集合（即矩阵 $A$ 或矩阵 $B$ 在位置 $(i,j)$ 有一个非零条目）。如果所有系数都满足以下条件。

@f{align*}
  a_{ii} &> 0, & b_{ii} &\geq 0, & a_{ij} &\leq 0, & b_{ij} &\geq 0,
  &
  \forall j &\in S_i,


@f}

所有的解决方案 $u^{n}$ 都保持其与之前的解决方案 $u^{n-1}$ 的符号，因此也保持其与初始值 $u^0$ 的符号。关于正性保留的更多信息，请参见例如 <a href="http://bookstore.siam.org/cs14/">Kuzmin, H&auml;m&auml;l&auml;inen</a> 。

根据要解决的PDE和使用的时间积分方案，人们能够推导出时间步长的条件  $k_n$  。对于采用Crank-Nicolson方案的热方程，<a href="https://doi.org/10.2478/cmam-2010-0025">Schatz et. al.</a>已将其转化为下列方案。

@f{align*}
  (1 - \theta) k a_{ii} &\leq m_{ii},\qquad \forall i,
  &
  \theta k \left| a_{ij} \right| &\geq m_{ij},\qquad j \neq i,


@f}

其中 $M = m_{ij}$ 表示质量矩阵， $A = a_{ij}$ 表示刚度矩阵， $a_{ij} \leq 0$ 分别表示 $j \neq i$ 。有了 $a_{ij} \leq 0$ ，我们可以制定全局时间步长 $k$ 的界限如下。

@f{align*}
  k_{\text{max}} &= \frac{ 1 }{ 1 - \theta }
  \min\left( \frac{ m_{ii} }{ a_{ii} } \right),~ \forall i,
  &
  k_{\text{min}} &= \frac{ 1 }{ \theta  }
  \max\left( \frac{ m_{ij} }{ \left|a_{ij}\right| } \right),~ j \neq i.


@f}

换句话说，在Crank-Nicolson方案的情况下，时间步长受到<i>both a lower
and upper bound</i>的限制。这些约束应与CFL条件一起考虑，以确保所进行的模拟的重要性。

无法使时间步长达到我们想要的小，以获得更多的精度，而又不失去积极性属性，这是令人讨厌的。这就提出了一个问题：在这个特定的教程中，我们是否至少可以<i>compute</i>选择最小的时间步长来确保正性的保留。事实上，我们可以使用通过MatrixCreator函数创建的质量和刚度的SparseMatrix对象。通过SparseMatrixIterators遍历每个条目，我们可以检查对角线和非对角线条目，从而动态地设置一个合适的时间步长。对于二次元矩阵，对角线元素被存储为一行的第一个成员（见SparseMatrix文档）。下面是一个关于如何从 <code>mass_matrix</code> 中抓取感兴趣的条目的示范性代码片断。

@code
Assert (mass_matrix.m() == mass_matrix.n(), ExcNotQuadratic());
const unsigned int num_rows = mass_matrix.m();
double mass_matrix_min_diag    = std::numeric_limits<double>::max(),
       mass_matrix_max_offdiag = 0.;


SparseMatrixIterators::Iterator<double,true> row_it (&mass_matrix, 0);


for(unsigned int m = 0; m<num_rows; ++m)
{
  // check the diagonal element
  row_it = mass_matrix.begin(m);
  mass_matrix_min_diag = std::min(row_it->value(), mass_matrix_min_diag);
  ++row_it;


  // check the off-diagonal elements
  for(; row_it != mass_matrix.end(m); ++row_it)
    mass_matrix_max_offdiag = std::max(row_it->value(), mass_matrix_max_offdiag);
}
@endcode



利用这样计算出来的信息，我们可以通过上述公式来约束时间步长。


examples/step-27/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

这个教程程序试图展示如何使用 $hp$ -finite element方法与deal.II。它解决的是拉普拉斯方程，因此只建立在前几个教程程序的基础上，特别是步骤4的独立维度编程和步骤6的自适应网格细化。

Babu&scaron;ka和Guo在20世纪80年代初提出了 $hp$ -有限元方法，作为(i)网格细化（即减少有限元计算中的网格参数 $h$ ）或(ii)增加用于形状函数的多项式程度 $p$ 的替代方法。它是基于这样的观察：如果解足够光滑，增加形状函数的多项式程度可以减少近似误差。另一方面，众所周知，即使对于一般良好的椭圆问题，在边界附近、角落或系数不连续的地方也不能保证较高的规则度；因此，在这些地方不能通过增加多项式度来改善近似  $p$  ，而只能通过细化网格，即减少网格大小  $h$  。这些减少误差的不同手段导致了 $hp$ 有限元的概念，即在解足够光滑的地方，近似的有限元空间被调整为具有高多项式度 $p$ ，而在解缺乏规则性的地方，网格宽度 $h$ 被减少。在关于这种方法的第一篇论文中已经意识到， $hp$ -无限元素可以是一个强有力的工具，它可以保证误差不仅以自由度数的某个负数减少，而且实际上是以指数形式减少。

为了实现这个方法，我们需要一些高于一般有限元程序所需的东西，特别是高于我们在步骤6之前的教程程序中所介绍的东西。特别是，我们将不得不讨论以下几个方面。   <ul>   <li>  我们现在不是在所有单元上使用相同的有限元，而是要有一个有限元对象的集合，并将每个单元与这个集合中的一个对象相关联。 </li> 

    <li> 然后，自由度将不得不根据与该特定单元相关的有限元来分配给每个单元。约束条件必须以与悬挂节点相同的方式生成，但我们现在还必须处理两个相邻单元分配不同有限元的情况。 </li> 

    <li>  我们将需要能够集合单元和面对全局矩阵和右手向量的贡献。 </li> 

    <li> 在求解所得到的线性系统后，我们将想分析该解决方案。特别是，我们要计算误差指标，告诉我们是否应该细化一个给定的单元和/或是否应该增加对其使用的形状函数的多项式程度。 </li>   </ul> 。

我们将在本介绍的以下几个小节中讨论所有这些方面。这些任务中的大部分已经由deal.II提供的功能很好地支持了，我们只需要提供程序应该做什么的逻辑，而不是确切地说明这一切将如何发生，这不会让人感到很惊讶。

在deal.II中， $hp$ 的功能大部分被打包到hp-namespace中。这个命名空间提供了处理 $hp$ 分解、集合矩阵和向量以及其他任务的类。我们将在下文中进一步了解它们中的许多。此外，DoFTools和VectorTools命名空间中的大多数函数除了接受非 $hp$ 的对象外，还接受 $hp$ 的对象。许多 $hp$ 的实现也在 @ref hp 文档模块和那里的链接中讨论。

也许值得在这第一部分介绍的最后给出一个稍大的观点。   $hp$ -功能已经在许多不同的有限元软件包中实现（例如，见 @ref hp_paper "hp-paper "中引用的参考文献列表）。然而，总的来说，这些软件包大多只在(i)2d情况下和/或(ii)不连续的Galerkin方法中实现了它。后者是一个重要的简化，因为根据定义，不连续的有限元不要求单元之间的面的连续性，因此，当不同的多项式程度的有限元在一个共同的面相遇时，不需要特殊处理。相比之下，deal.II实现了最普遍的情况，即它允许1d、2d和3d的连续和不连续元素，并自动处理由此产生的复杂性。特别是，它可以处理不同程度的元素在一个面或边缘相遇时的约束（类似于悬挂节点约束）的计算。许多必要的算法和数据结构技术在 @ref hp_paper "hp-paper "中描述，供那些对这些细节感兴趣的人参考。

我们希望，提供这样一个通用的实现方式将有助于进一步探索 $hp$ -方法的潜力。




<h3>Finite element collections</h3>

现在再来看看如何在deal.II中使用 $hp$ -功能的细节。我们要处理的第一个方面是，现在我们不再只有一个用于所有单元的有限元，而是有许多不同的单元可以选择使用的元素。为此，deal.II引入了<i>finite element
collection</i>的概念，在 hp::FECollection. 类中实现。实质上，这样的集合就像 <code>std::vector@<FiniteElement@></code> 类型的对象，但多了一些小功能和内存管理，更适合手头的任务。正如我们以后所看到的，我们还将使用类似的正交集合，以及&mdash; 尽管我们在这里没有使用它们&mdash; 还有映射集合的概念。所有这些类都在 @ref hpcollection 概述中有所描述。

在这个教程程序中，我们将使用阶数为2到7（在2D中）或2到5（在3D中）的连续Lagrange元素。然后可以按以下方式创建所用元素的集合。

@code
  hp::FECollection<dim> fe_collection;
  for (unsigned int degree = 2; degree <= max_degree; ++degree)
    fe_collection.push_back(FE_Q<dim>(degree));
@endcode






<h3>The DoFHandler class in <i>hp</i><i>hp</i>-mode, associating cells with finite elements, and constraints</h3> 。

我们要考虑的下一个任务是如何处理我们要使用的有限元对象的列表。在之前的教程程序中，从第2步开始，我们已经看到DoFHandler类负责在网格（由三角形对象描述）和有限元之间建立联系，为网格的每个顶点、面、边和单元分配正确的自由度数。

这里的情况有点复杂，因为我们不只是有一个单一的有限元对象，而是可能想在不同的单元上使用不同的元素。因此，我们需要两样东西。(i) 一个能够处理这种情况的DoFHandler类的版本，以及(ii) 告诉DoFHandler在哪个单元上使用哪个元素的方法。

这两件事中的第一件是在DoFHandler类的<i>hp</i>模式下实现的：不是将其与一个三角形和一个有限元对象相关联，而是与一个三角形和一个有限元集合相关联。第二部分是通过在DoFHandler的所有单元上的循环来实现的，并为每个单元设置集合中的有限元的索引，该索引将被用于该单元。我们将集合中用于某个单元的有限元对象的索引称为该单元的<i>active FE
index</i>，以表明这是活跃在该单元上的有限元，而集合中的所有其他元素在该单元上是不活跃的。其大致内容是这样的。

@code
  DoFHandler<dim> dof_handler(triangulation);
  for (auto &cell: dof_handler.active_cell_iterators())
    cell->set_active_fe_index(...);
  dof_handler.distribute_dofs(fe_collection);
@endcode



调用 <code>set_active_fe_index()</code> 中的点表示我们以后必须有某种策略来决定在哪个单元格上使用哪个元素；我们以后会再来讨论这个。这里的重点是，这个代码片段的第一行和最后一行与非  $hp$  的情况几乎完全相同。

另一个复杂的情况是，这次我们不只是有来自局部网格细化的悬挂节点，我们还必须处理这样的情况：如果有两个具有不同活动有限元指数的单元在一个面上相遇（例如一个Q2和一个Q3单元），那么我们必须计算有限元场上的额外约束，以确保它是连续的。这在概念上与我们计算悬挂节点约束的方式非常相似，事实上，代码看起来也完全一样。

@code
  AffineConstraints<double> constraints;
  DoFTools::make_hanging_node_constraints(dof_handler, constraints);
@endcode

换句话说， DoFTools::make_hanging_node_constraints 不仅处理悬挂节点约束，而且同时处理 $hp$ -约束。




<h3>Assembling matrices and vectors with hp-objects</h3>

在这之后，我们必须为正确大小的线性系统设置矩阵和向量，并将它们组合起来。设置它们的方法与非 $hp$ 的情况完全相同。组装则需要更多的思考。

当然，主要的想法是不变的：我们必须在所有单元中循环，集合局部贡献，然后将它们复制到全局对象中。正如在第3步中详细讨论的那样，deal.II有一个FEValues类，它将有限元描述、映射和正交公式拉到一起，帮助评估形状函数的值和梯度，以及映射到单元实际位置的每个正交点的其他信息。每当我们转到一个新的单元时，我们就会重新初始化这个FEValues对象，从而要求它重新计算从一个单元到另一个单元的那部分信息。然后，它可以被用来总结本地对双线性形式和右手边的贡献。

在 $hp$ 有限元方法的背景下，我们必须处理这样一个事实：我们不在每个单元上使用相同的有限元对象。事实上，我们甚至不应该对所有单元使用相同的正交对象，而应该对使用高阶有限元的单元使用高阶正交公式。同样地，我们可能也想在这些单元上使用高阶映射。

为了方便这些考虑，deal.II有一个类 hp::FEValues ，可以做我们在当前背景下需要的事情。不同的是，它不是一个单一的有限元、正交公式和映射，而是这些对象的集合。它的使用非常类似于常规的FEValues类，也就是说，在所有单元中循环的有趣部分看起来像这样。

@code
  hp::FEValues<dim> hp_fe_values(mapping_collection,
                                 fe_collection,
                                 quadrature_collection,
                                 update_values | update_gradients |
                                 update_quadrature_points | update_JxW_values);


  for (const auto &cell : dof_handler.active_cell_iterators())
    {
      hp_fe_values.reinit(cell);


      const FEValues<dim> &fe_values = hp_fe_values.get_present_fe_values();


      ...  // assemble local contributions and copy them into global object
    }
@endcode



在这个教程程序中，我们将始终使用Q1映射，所以 hp::FEValues 结构的映射集合参数将被省略。在循环中，我们首先初始化当前单元的 hp::FEValues 对象。第二个、第三个和第四个参数表示我们希望在该单元上使用的正交、映射和有限元对象在各自集合中的索引。这些参数可以省略（在下面的程序中也是如此），在这种情况下， <code>cell-@>active_fe_index()</code> 被用于这个索引。之所以这样选择这些参数的顺序，是因为有时人们可能想从各自的集合中挑选不同的正交或映射对象，但几乎不可能从这个单元上使用的有限元中挑选不同的有限元，即索引与 <code>cell-@>active_fe_index()</code> 不同。因此，有限元集合的索引是最后一个默认参数，这样可以方便地省略它。

这个 <code>reinit</code> 调用的作用如下： hp::FEValues 类检查它之前是否已经为这个有限元、正交和映射对象的组合分配了一个非 $hp$ -FEValues对象。如果没有，它将分配一个。然后，它为当前单元重新初始化这个对象，之后，现在有一个FEValues对象可用于当前单元上选定的有限元、正交和映射。然后通过调用 <code>hp_fe_values.get_present_fe_values()</code> 获得对该对象的引用，并将以通常的方式用于集合本地贡献。




<h3>A simple indicator for hp-refinement and estimating smoothness</h3>

自适应有限元方法的核心之一是，我们用一个指标来检查计算出的解（后验），告诉我们哪些是误差最大的单元，然后再对它们进行细化。在其他许多教程程序中，我们使用KellyErrorEstimator类来获得一个单元上的误差大小的指示，尽管我们也在一些程序中讨论了更复杂的策略，最重要的是在步骤14。

在任何情况下，只要决定只是 "细化这个单元 "或 "不细化这个单元"，实际的细化步骤就不是特别具有挑战性。然而，在这里，我们有一个能够进行hp细化的代码，也就是说，每当我们检测到某个单元上的误差太大，我们突然有两个选择：我们可以通过把它分割成几个小单元来细化这个单元，或者我们可以增加在它上面使用的形状函数的多项式程度。我们如何知道哪个是更有希望的策略？回答这个问题是本文写作时 $hp$ -无限元研究的核心问题。

简而言之，这个问题目前在文献中似乎还没有解决。有许多或多或少复杂的方案来解决这个问题，但没有任何方案像KellyErrorEstimator那样被普遍接受为一个好的、即使不是最佳的误差指标。大多数建议采用这样的事实：只要解是局部光滑的，增加多项式的度数是有益的，而只要网格是粗糙的，就应该细化。然而，如何确定解的局部光滑度以及决定一个解何时光滑到允许增加 $p$ 的问题无疑是很大很重要的问题。

在下文中，我们提出了一个简单的解决方案的局部平滑性的估计方法。正如我们将在结果部分看到的，这个估计器有缺陷，特别是就有局部悬空节点的单元而言。因此，我们不打算把下面的想法作为问题的完整解决方案。相反，它是作为一个值得进一步研究和调查的想法来处理的。换句话说，我们不打算在关于一般问题的答案的争论中进入一个复杂的建议。然而，为了证明我们对 $hp$ -无限元素的方法，我们需要一个简单的指标，它确实产生一些有用的信息，能够驱动本教程程序将进行的简单计算。




<h4>The idea</h4>

我们在这里的方法很简单：对于一个函数 $u({\bf x})$ 来说，它是在单元格 $K$ 上的索博列夫空间 $H^s(K)$ 中，它必须满足条件

@f[
   \int_K |\nabla^s u({\bf x})|^2 \; d{\bf x} < \infty.


@f]

假设单元格 $K$ 不是退化的，即从单元格到单元格 $K$ 的映射足够规则，上述条件当然等同于

@f[
   \int_{\hat K} |\nabla^s \hat u(\hat{\bf x})|^2 \; d\hat{\bf x} < \infty\,,


@f]

其中 $\hat u(\hat{\bf x})$ 是映射回单元格 $\hat K$ 的函数 $u({\bf x})$  。从这里，我们可以做以下工作：首先，让我们定义 $\hat u$ 的傅里叶级数为

@f[
   \hat u(\hat{\bf x})
   = \sum_{\bf k} \hat U_{\bf k}\,e^{-i {\bf k}\cdot \hat{\bf x}},


@f]

傅里叶向量 ${\bf k}=(k_x,k_y)$ 在2d中， ${\bf k}=(k_x,k_y,k_z)$ 在3d中，等等，以及 $k_x,k_y,k_z=0,2\pi,4\pi,\ldots$  。扩张 $\hat U_{\bf k}$ 的系数可以用 $L^2$ 得到--指数基的正交性

@f[
\int_{\hat K} e^{-i {\bf m}\cdot \hat{\bf x}} e^{i {\bf n}\cdot \hat{\bf x}} d\hat{\bf x} = \delta_{\bf m \bf n},


@f]

导致以下表达式

@f[
   \hat U_{\bf k}
   = \int_{\hat K} e^{i {\bf k}\cdot \hat{\bf x}} \hat u(\hat{\bf x}) d\hat{\bf x} \,.


@f]

很明显，我们可以将 $H^s$ 的 $\hat u$ 准则写成

@f[
  \int_{\hat K} |\nabla^s \hat u(\hat{\bf x})|^2 \; d\hat{\bf x}
  =
  \int_{\hat K}
  \left|
    \sum_{\bf k} |{\bf k}|^s e^{-i{\bf k}\cdot \hat{\bf x}} \hat U_{\bf k}
  \right|^2 \; d\hat{\bf x}
  =
  \sum_{\bf k}
    |{\bf k}|^{2s}
    |\hat U_{\bf k}|^2.


@f]

换句话说，如果这个规范是有限的（即，对于 $\hat u(\hat{\bf x})$ 在 $H^s(\hat K)$ 中），我们需要

@f[
   |\hat U_{\bf k}| = {\cal O}\left(|{\bf k}|^{-\left(s+1/2+\frac{d-1}{2}+\epsilon\right)}\right).


@f]

换句话说：我们想要的规则性 $s$ 越高，傅里叶系数归零的速度就越快。如果你想知道额外的指数 $\frac{d-1}2$ 从何而来：我们想利用这样一个事实： $\sum_l a_l < \infty$ 如果序列 $a_l =
{\cal O}(l^{-1-\epsilon})$ 对于任何 $\epsilon>0$ 。问题是，我们在这里不仅有一个单一变量的求和，而且有位于 $d$ 维球内的 $2\pi$ 的所有整数倍的求和，因为我们有向量成分 $k_x, k_y,
\ldots$  。就像我们通过用整个直线上的积分代替总和来证明上面的序列 $a_l$ 收敛一样，我们可以用 $d$ -维空间上的积分来代替我们的 $d$ -维总和。现在我们必须注意到，在距离 $|{\bf k}|$ 和 $|{\bf k}|+d|{\bf k}|$ 之间，存在着多达一个常数的 $|{\bf k}|^{d-1}$ 模式，这与我们可以将体积元素 $dx\;dy$ 转化为 $2\pi r\; dr$ 的方式相同。因此，不再是 $|{\bf k}|^{2s}|\hat
U_{\bf k}|^2$ 必须衰变为 ${\cal O}(|{\bf k}|^{-1-\epsilon})$ ，而实际上是 $|{\bf k}|^{2s}|\hat U_{\bf k}|^2 |{\bf k}|^{d-1}$ 。指数的比较产生了结果。

我们可以把这个问题转过来。假设我们得到了一个未知平滑度的函数 $\hat u$ 。让我们计算它的傅里叶系数 $\hat U_{\bf k}$ ，看看它们衰减的速度。如果它们的衰减速度为

@f[
   |\hat U_{\bf k}| = {\cal O}(|{\bf k}|^{-\mu-\epsilon}),


@f]

因此，我们这里的函数是在 $H^{\mu-d/2}$ 。




<h4>What we have to do</h4>

那么，我们要做什么来估计 $u({\bf x})$ 在单元格 $K$ 上的局部光滑度呢？显然，第一步是计算我们解决方案的傅里叶系数。傅里叶级数是无限级数，我们通过只计算级数的前几项来简化我们的任务，例如， $|{\bf k}|\le 2\pi N$ 有一个截止点 $N$ 。让我们顺便说一下，我们希望选择 $N$ 足够大，这样我们至少可以捕获那些变化最大的形状函数的变化。另一方面，我们不应该把 $N$ 选得太大：显然，一个有限元函数，作为一个多项式，在任何给定的单元上都在 $C^\infty$ 中，所以系数将不得不在一个点上指数衰减；由于我们想估计这个多项式所近似的函数的平稳性，而不是多项式本身，我们需要为 $N$ 选择一个合理的截止点。无论怎样，计算这个数列并不特别困难：从定义上看

@f[
   \hat U_{\bf k}
   = \int_{\hat K} e^{i {\bf k}\cdot \hat{\bf x}} \hat u(\hat{\bf x}) d\hat{\bf x}


@f]

我们看到，我们可以计算系数 $\hat U_{\bf k}$ 为

@f[
   \hat U_{\bf k}
   =
   \sum_{i=0}^{\textrm{dofs per cell}}
   \left[\int_{\hat K} e^{i {\bf k}\cdot \hat{\bf x}} \hat \varphi_i(\hat{\bf x})
   d\hat{\bf x} \right] u_i,


@f]

其中 $u_i$ 是这个单元上 $i$ 个自由度的值。换句话说，我们可以把它写成一个矩阵-向量乘积

@f[
   \hat U_{\bf k}
   = {\cal F}_{{\bf k},j} u_j,


@f]

与矩阵

@f[
   {\cal F}_{{\bf k},j}
   =
   \int_{\hat K} e^{i {\bf k}\cdot \hat{\bf x}} \hat \varphi_j(\hat{\bf x}) d\hat{\bf x}.


@f]

对于给定数量的形状函数  $\varphi_j$  和傅里叶模式  $N$  ，这个矩阵很容易计算出来。因此，寻找系数 $\hat U_{\bf k}$ 是一个相当琐碎的工作。为了进一步简化我们的生活，我们将使用 FESeries::Fourier 类，它正是这样做的。

接下来的任务是，我们必须估计这些系数随 $|{\bf k}|$ 衰减的速度。问题是，当然，我们首先只有有限的这些系数。换句话说，我们能做的最好的事情是将一个函数 $\alpha |{\bf k}|^{-\mu}$ 拟合到我们的数据点 $\hat U_{\bf k}$ ，例如通过最小二乘法程序确定 $\alpha,\mu$ 。

@f[
   \min_{\alpha,\mu}
   \frac 12 \sum_{{\bf k}, |{\bf k}|\le N}
   \left( |\hat U_{\bf k}| - \alpha |{\bf k}|^{-\mu}\right)^2


@f]

然而，这样做的问题是，它导致了一个非线性问题，这是我们想避免的事实。另一方面，如果我们试图将我们的系数的对数与 $\alpha |{\bf k}|^{-\mu}$ 的对数相适应，我们可以将问题转化为一个更简单的问题，就像这样。

@f[
   \min_{\alpha,\mu}
   Q(\alpha,\mu) =
   \frac 12 \sum_{{\bf k}, |{\bf k}|\le N}
   \left( \ln |\hat U_{\bf k}| - \ln (\alpha |{\bf k}|^{-\mu})\right)^2.


@f]

利用关于对数的一般事实，我们可以看到，这就产生了一个问题

@f[
   \min_{\beta,\mu}
   Q(\beta,\mu) =
   \frac 12 \sum_{{\bf k}, |{\bf k}|\le N}
   \left( \ln |\hat U_{\bf k}| - \beta + \mu \ln |{\bf k}|\right)^2,


@f]

其中  $\beta=\ln \alpha$  。现在这是一个问题，对于这个问题，最优性条件  $\frac{\partial Q}{\partial\beta}=0,
\frac{\partial Q}{\partial\mu}=0$  , 在  $\beta,\mu$  中是线性的。我们可以把这些条件写成如下。

@f[
   \left(\begin{array}{cc}
   \sum_{{\bf k}, |{\bf k}|\le N} 1 &
   \sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}|
   \\
   \sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}| &
   \sum_{{\bf k}, |{\bf k}|\le N} (\ln |{\bf k}|)^2
   \end{array}\right)
   \left(\begin{array}{c}
   \beta \\ -\mu
   \end{array}\right)
   =
   \left(\begin{array}{c}
   \sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}|
   \\
   \sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}| \ln |{\bf k}|
   \end{array}\right)


@f]

这个线性系统很容易被倒置，从而得到

@f[
   \beta =
   \frac
   {
   \left(\sum_{{\bf k}, |{\bf k}|\le N} (\ln |{\bf k}|)^2\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}|\right)


   -
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}|\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}| \ln |{\bf k}| \right)
   }
   {
   \left(\sum_{{\bf k}, |{\bf k}|\le N} 1\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} (\ln |{\bf k}|)^2\right)


   -
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}|\right)^2
   }


@f]

和

@f[
   \mu =
   \frac
   {
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}|\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}|\right)


   -
   \left(\sum_{{\bf k}, |{\bf k}|\le N} 1\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}| \ln |{\bf k}| \right)
   }
   {
   \left(\sum_{{\bf k}, |{\bf k}|\le N} 1\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} (\ln |{\bf k}|)^2\right)


   -
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}|\right)^2
   }.


@f]



这无非是线性回归拟合，为了做到这一点，我们将使用 FESeries::linear_regression(). 虽然我们对 $\beta$ 的实际值不是特别感兴趣，但上面的公式给了我们一个计算指数 $\mu$ 的平均值，然后我们可以用来确定 $\hat u(\hat{\bf x})$ 与 $s=\mu-\frac d2$ 在一起。

上面概述的这些步骤适用于许多不同的场景，这促使我们在deal.II中引入了一个通用函数 SmoothnessEstimator::Fourier::coefficient_decay() ，该函数将本节描述的所有任务结合在一个简单的函数调用中。我们将在本程序的实现中使用它。




<h4>Compensating for anisotropy</h4>

在上面的公式中，我们已经得出了傅里叶系数 $\hat U_{\bf
k}$  。因为 ${\bf k}$ 是一个矢量，对于相同的绝对值 $|{\bf k}|$ ，我们会得到许多傅里叶系数 $\hat U_{{\bf k}}$ ，对应于不同方向的傅里叶变换。如果我们现在考虑一个像 $|x|y^2$ 这样的函数，那么我们会发现在 $x$ 方向有很多大的傅里叶系数，因为这个方向的函数是不平滑的，但在 $y$ 方向有快速衰减的傅里叶系数，因为那里的函数是平滑的。由此产生的问题是：如果我们简单地将我们的多项式衰减 $\alpha |{\bf k}|^\mu$ 与<i>all</i>的傅里叶系数拟合，我们将把它拟合成一个光滑度<i>averaged in all spatial directions</i>。这就是我们想要的吗？还是只考虑所有 ${\bf k}$ 中幅度最大的系数 $\hat U_{{\bf k}}$ ，本质上是想确定解在那个空间方向上的平滑度，在这个方向上解显得最粗糙？

人们也许可以为这两种情况争辩。如果deal.II有能力使用各向异性的有限元，即在不同的空间方向使用不同的多项式度数的有限元，那么这个问题将更有意义，因为它们能够更好地利用方向上的可变平滑度。唉，在编写这个教程程序时，这种能力并不存在。

无论怎样，由于我们只有同位素的有限元类，我们采取的观点是，我们应该将多项式的程度调整到最低的规则性，以保持低的数值努力。因此，不使用公式

@f[
   \mu =
   \frac
   {
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}|\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}|\right)


   -
   \left(\sum_{{\bf k}, |{\bf k}|\le N} 1\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |\hat U_{{\bf k}}| \ln |{\bf k}| \right)
   }
   {
   \left(\sum_{{\bf k}, |{\bf k}|\le N} 1\right)
   \left(\sum_{{\bf k}, |{\bf k}|\le N} (\ln |{\bf k}|)^2\right)


   -
   \left(\sum_{{\bf k}, |{\bf k}|\le N} \ln |{\bf k}|\right)^2
   }.


@f]

为了计算如上所示的 $\mu$ ，我们必须对所有的和稍作修改：不是对所有的傅里叶模式求和，而是只对那些傅里叶系数是所有 $\hat U_{{\bf k}}$ 中最大的、具有相同幅度的 $|{\bf k}|$ 求和，也就是说，上面的所有和必须由以下的和来代替。

@f[
  \sum_{{\bf k}, |{\bf k}|\le N}
  \longrightarrow
  \sum_{\begin{matrix}{{\bf k}, |{\bf k}|\le N} \\ {|\hat U_{{\bf k}}| \ge |\hat U_{{\bf k}'}|
  \ \textrm{for all}\ {\bf k}'\ \textrm{with}\ |{\bf k}'|=|{\bf k}|}\end{matrix}}.


@f]

这是我们将在计划中实施的形式。




<h4>Questions about cell sizes</h4>

有人可能会问，我们只在解的<i>reference cell</i>（而不是实数单元）上计算傅里叶变换，这是否是一个问题？毕竟，在变换过程中，我们将解决方案拉伸了一个系数 $\frac 1h$ ，从而使傅里叶频率移动了一个系数 $h$ 。这是一个特别值得关注的问题，因为我们可能有相邻的单元，其网格大小 $h$ 相差2倍，如果其中一个单元比另一个更精细。这个问题也是出于这样的考虑：正如我们在下面的结果部分所看到的，估计的解决方案的平滑度应该是一个或多或少的连续函数，但在网格大小跳跃的地方表现出跳跃。因此，我们似乎很自然地要问，我们是否必须对这种转换进行补偿。

简短的回答是 "不"。在上述过程中，我们试图找到系数 $\beta,\mu$ ，使条款的平方之和最小。

@f[
   \ln |\hat U_{{\bf k}}| - \beta + \mu \ln |{\bf k}|.


@f]

补偿变换意味着不试图拟合相对于傅里叶频率 ${\bf k}$ <i>on the unit
cell</i>的衰减 $|{\bf k}|^\mu$ ，而是拟合在参考单元<i>to the Fourier frequencies on the real cell $|\bf
k|h$</i>上计算的系数 $\hat U_{{\bf k}}$ ，其中 $h$ 是变换算子的规范（即类似单元直径的东西）。换句话说，我们将不得不最小化条款的平方之和

@f[
   \ln |\hat U_{{\bf k}}| - \beta + \mu \ln (|{\bf k}|h).


@f]

来代替。然而，利用对数的基本属性，这只是相当于最小化了

@f[
   \ln |\hat U_{{\bf k}}| - (\beta - \mu \ln h) + \mu \ln (|{\bf k}|).


@f]

换句话说，这个问题和原来的最小二乘法问题将产生相同的最佳拟合指数 $\mu$ ，尽管偏移量在一种情况下是 $\beta$ ，在另一种情况下是 $\beta-\mu \ln h$  。然而，由于我们对偏移量根本不感兴趣，而只对指数感兴趣，所以我们是否对傅里叶频率进行缩放以考虑网格大小的影响并不重要，在两种情况下估计的平滑度指数都是一样的。




<h3>Complications with linear systems for hp-discretizations</h3>

<h4>Creating the sparsity pattern</h4>

 $hp$ -方法的问题之一是，形状函数的高多项式程度与大量受限自由度一起导致矩阵的某些行有大量非零条目。同时，因为有些地方我们使用的是低多项式度，因此矩阵行的非零项相对较少。因此，为这些矩阵分配稀疏性模式是一个挑战：我们不能简单地从带宽的估计开始组装一个SparsityPattern，而不使用大量的额外内存。

我们为底层线性系统创建SparsityPattern的方式与我们用来执行约束的策略紧密相连。 deal.II支持以两种方式处理线性系统中的约束。<ol>  <li>  在不考虑约束条件的情况下组装矩阵，之后用 AffineConstraints::condense, 或 </li> 来应用约束条件  <li>  在我们用 AffineConstraints::distribute_local_to_global.</li>  </ol> 来组装系统时应用约束条件。然后系统矩阵使用从DynamicSparsityPattern复制过来的SparsityPattern。这个方法在步骤2中解释，并在大多数教程程序中使用。

早期的教程程序使用一阶或二阶有限元，因此去除与受限自由度相对应的稀疏模式中的条目不会对矩阵明确存储的零的总体数量产生很大影响。然而，由于多达三分之一的自由度在hp微分中可能受到约束（对于高阶元素，这些约束可以将一个自由度与多达10个或20个其他自由度相联系），值得考虑这些约束，因为所产生的矩阵将更加稀疏（因此，矩阵-向量乘积或因子化也将大大加快）。




<h4>Eliminating constrained degrees of freedom</h4>

 $hp$ 方法的第二个问题是，我们有如此多的受限自由度：通常有三分之一的自由度（在三维中）是受限的，因为它们要么属于有悬空节点的单元，要么位于与具有更高或更低多项式度的单元相邻的单元上。事实上，这并不比非 $hp$ 模式中受约束自由度的比例高多少，但不同的是，每个受约束的悬空节点不仅受制于相邻的两个自由度，而且还受制于更多的自由度。

事实证明，在步骤6中首先提出的在用 AffineConstraints::distribute_local_to_global 计算元素矩阵和向量时消除约束的策略，对于这种情况也是最有效的方法。另一种策略是首先建立没有约束的矩阵，然后 "浓缩 "掉有约束的自由度，这种策略要昂贵得多。事实证明，用这种低效率的算法建立稀疏模式至少需要 ${\cal O}(N \log N)$ 个未知数，而理想的有限元程序当然只有与未知数成线性的算法。对稀疏模式的创建以及矩阵的装配进行计时显示，步骤6中提出的算法（并在下面的代码中使用）确实更快。

在我们的程序中，我们也将把边界条件作为（可能是不均匀的）约束条件，并把矩阵的行和列也消除。为此我们要做的就是在设置阶段调用插值Dirichlet边界条件的函数，以便告诉AffineConstraints对象关于它们的情况，然后同时在矩阵和向量上做从局部到全局的数据转移。这正是我们在步骤6中所展示的。




<h3>The test case</h3>

我们要用这个程序解决的测试案例是我们在第14步中已经看过的一个案例的重考：我们要解决拉普拉斯方程

@f[


   -\Delta u = f


@f]

2d，与 $f=(x+1)(y+1)$ ，以及 $u$ 的零Dirichlet边界值。我们在域 $[-1,1]^2\backslash[-\frac 12,\frac 12]^2$ 上这样做，即一个中间有一个方孔的正方形。

当然，与第14步的不同之处在于，我们使用 $hp$ -无限元素来求解。这个测试案例是有意义的，因为它在洞的四角有重入角，在这些地方的解有奇异性。因此，我们期望解在域的内部是平滑的，而在奇点附近是粗糙的。希望我们的细化和光滑度指标能够看到这种行为，并在远离奇点的地方细化网格，同时提高多项式的度数。正如我们将在结果部分看到的，情况确实如此。


examples/step-27/doc/results.dox



<h1>Results</h1>

在这一节中，我们讨论了运行当前教程程序所产生的一些结果。更多的结果，特别是对三维计算的扩展和确定程序的各个部分需要多少计算时间，在 @ref hp_paper "hp-paper "中给出。

当运行时，这是该程序产生的结果。

@code
> make run
[ 66%] Built target step-27
[100%] Run step-27 with Release configuration
Cycle 0:
   Number of active cells      : 768
   Number of degrees of freedom: 3264
   Number of constraints       : 384
Cycle 1:
   Number of active cells      : 807
   Number of degrees of freedom: 4764
   Number of constraints       : 756
Cycle 2:
   Number of active cells      : 927
   Number of degrees of freedom: 8226
   Number of constraints       : 1856
Cycle 3:
   Number of active cells      : 978
   Number of degrees of freedom: 12146
   Number of constraints       : 2944
Cycle 4:
   Number of active cells      : 1104
   Number of degrees of freedom: 16892
   Number of constraints       : 3998
Cycle 5:
   Number of active cells      : 1149
   Number of degrees of freedom: 22078
   Number of constraints       : 5230
@endcode



我们从中了解到的第一件事是，受限自由度的数量是总自由度的20-25%，至少在后来的网格上，当我们有相对高阶的元素时（在三维中，受限自由度的比例可以达到30%）。事实上，这与非 $hp$ 分化的数量级相同。例如，在第6步程序的最后一步，我们有18353个自由度，其中4432个是受约束的。不同的是，在后一个程序中，每个受约束的悬挂节点只对相邻的两个自由度进行约束，而在 $hp$ -案例中，受约束的节点对许多自由度进行约束。还要注意的是，目前的程序在约束列表中还包括受迪里希特边界条件约束的节点。在第0周期中，所有的约束实际上都是因为边界条件。

也许更感兴趣的是看一下图形输出。首先，这是该问题的解决方案。

<img src="https://www.dealii.org/images/steps/developer/step-27-solution.png" alt="解决方案的立面图，显示出在内部（再入）角落附近缺乏规则性。" width="200" height="200">

其次，让我们看看生成网格的顺序。

<div class="threecolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.mesh-00.svg" alt="包含无适应性细化的再入角的三角图。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.mesh-01.svg" alt="包含有一级细化的再入角的三角图。新的单元格被放置在角落附近。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.mesh-02.svg" alt="包含具有两级细化的重入角的三角图。新的单元格被放置在角落附近。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.mesh-03.svg" alt="包含三层细化的重入角的三角图。新的单元格被放置在角落附近。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.mesh-04.svg" alt="含有四级细化的重入角的三角图。新的单元格被放置在角落附近。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.mesh-05.svg" alt="包含有五级细化的重入角的三角图。新的单元被放置在角附近。" width="200" height="200"> </div> </div> </div>

我们可以清楚地看到，在角部奇点附近的网格是如何被细化的，正如我们所期望的那样。更有趣的是，我们应该好奇地看看这些网格单元的有限元多项式的度数分布，其中最浅的颜色对应于度数2，最深的对应于度数7。

<div class="threecolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.fe_degree-00.svg" alt="初始网格，所有单元格只包含双二次函数。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.fe_degree-01.svg" alt="一次细化后的局部近似度描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.fe_degree-02.svg" alt="两次细化后的局部近似度描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.fe_degree-03.svg" alt="三次细化后的局部近似度描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.fe_degree-04.svg" alt="四次细化后的局部近似度描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.fe_degree-05.svg" alt="五次细化后的局部近似度描述。" width="200" height="200"> </div> </div>

虽然这肯定不是一个完美的安排，但它确实有一定的意义：我们在靠近边界和角落的地方使用低阶元素，那里的规则性很低。另一方面，在以下情况下使用高阶元素：(i) 误差一度相当大，即主要在角部奇点周围的一般区域和右上角解大的地方；(ii) 解是平滑的，即远离边界的地方。

这种多项式程度的安排当然是由我们的平滑度估计器得出的。这里是对解决方案的平滑度的估计，深色表示最不平滑，浅色表示最平滑的区域。

<div class="threecolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.smoothness-00.svg" alt="初始网格上每个单元的估计规则性。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.smoothness-01.svg" alt="经过一次细化后每个单元的估计规则性的描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.smoothness-02.svg" alt="经过两次细化后每个单元估计规则性的描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.smoothness-03.svg" alt="经过三次细化后每个单元格的估计规则性的描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.smoothness-04.svg" alt="经过四次细化后每个单元格的估计规则性的描述。" width="200" height="200"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-27.smoothness-05.svg" alt="经过五次细化后每个单元格的估计规则性的描述。" width="200" height="200"> </div> </div>

从这里可以得出的主要结论是，内角的规则性损失是一个高度局部的现象；它似乎只影响到与角本身相邻的单元，所以当我们细化网格时，黑色的颜色不再可见。除了角部，这一连串的图示意味着平滑度估计在某种程度上与网格细化无关，特别是当我们远离边界时。同样明显的是，平滑度估计值与解的实际尺寸无关（见上面的解的图片），这也是应该的。然而，更值得关注的一点是，人们在仔细观察后发现，我们的估计器高估了有悬空节点的单元格的解决方案的平滑度。这反过来又导致了这些区域的多项式度数更高，使有限元在单元上的分配出现偏差。

对于这种效果，我们目前还没有很好的解释。一种理论是，在有悬挂节点的单元上的数值解当然是受限制的，因此不能完全自由地探索函数空间以接近精确解。这种自由度的缺乏可能表现为在这些单元上产生具有抑制振荡的数值解，意味着更高的平滑度。估计器会捕捉到这个信号，估计的平滑度会高估实际值。然而，这个程序的作者目前还没有得到关于发生了什么的明确答案。

当然，更大的问题是如何避免这个问题。可能的做法包括不是在单个细胞上估计平滑度，而是在每个细胞周围的细胞集合体或斑块上估计平滑度。也可能为每个细胞找到简单的校正因子，这取决于它所拥有的受限自由度的数量。无论哪种情况，都有大量的机会来进一步研究寻找好的 $hp$ -精化标准。另一方面，目前方案的主要内容是在deal.II中演示使用 $hp$ -技术，这不受我们使用可能的次优细化标准的影响。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Different hp-decision strategies</h4>

本教程只演示了决定 $h$ -和 $p$ -适应的一个特殊策略。事实上，还有许多自动决定适应类型的方法，其中一些已经在deal.II中实现：  <ul>   <li>  <i>Fourier coefficient decay:</i> 这是本教程中目前实现的策略。有关该策略的更多信息，请参见 SmoothnessEstimator::Fourier 命名空间的一般文档。 </li> 

    <li>  <i>Legendre coefficient decay:</i> 这个策略与目前的策略很相似，但使用了Legendre级数扩展，而不是傅里叶级数：这个策略使用Legendre多项式，而不是正弦波作为基础函数。当然，由于我们在每个单元上使用有限维度的多项式来近似解，因此解在Legendre多项式中的扩展也是有限的，因此，当我们谈论这个扩展的 "衰减 "时，我们只能考虑这个扩展的有限多个非零系数，而不是用渐进的方式来思考。   但是，如果我们有足够多的这些系数，我们当然可以把这些系数的衰减看作是精确解的系数衰减的特征（一般来说，精确解不是多项式的，所以会有一个无限的Legendre扩展），考虑我们拥有的系数应该可以揭示一些关于精确解的特性。

  从傅里叶策略过渡到Legendre策略是非常简单的。   你只需要改变序列扩展类和相应的平滑度估计函数，使其成为适当命名空间 FESeries::Legendre 和 SmoothnessEstimator::Legendre. 的一部分，这个策略在step-75中使用。关于这个策略的理论背景，请参考 SmoothnessEstimator::Legendre 命名空间的一般文档，以及 @cite mavriplis1994hp 、 @cite eibner2007hp 和 @cite davydov2017hp  。 </li> 

    <li>  <i>Refinement history:</i> 最后一种策略与其他两种截然不同。在理论上，我们知道在改变函数空间离散化后，误差将如何收敛。用 $h$ -细化，解会以代数方式收敛，正如在步骤7中已经指出的。不过，如果解足够平滑，我们预计解将随着有限元的多项式程度的增加而指数级收敛。我们可以在下面的步骤中把对误差的正确预测与实际误差进行比较，看看我们对适应类型的选择是否合理。

  向这一策略的过渡要复杂一些。为此，我们需要一个纯 $h$ -或 $p$ -细化的初始化步骤，我们需要将预测的误差转移到适应的网格上。 hp::Refinement::predict_error() 函数的大量文档不仅描述了这种方法的理论细节，而且还介绍了如何在你的代码中实现这种策略的蓝图。欲了解更多信息，请参见  @cite melenk2001hp  。

  请注意，用这个特殊的函数，你无法预测时间依赖性问题的下一个时间步骤的误差。因此，这种策略不能不加思索地应用于这种类型的问题。另外，也可以使用下面的方法，这也适用于所有其他的策略：从每个时间步长的粗网格开始，不断细化，直到对结果满意，然后才进入下一个时间步长。 </li>   </ul> 。

试着在本教程中实施这些策略之一，观察结果的微妙变化。你会注意到，所有的策略都能够识别重心角附近的奇点，并在这些区域执行 $h$ -精简，而在体域中更倾向于 $p$ -精简。这些策略的详细比较见 @cite fehling2020  。




<h4>Parallel hp-adaptive finite elements</h4>

本教程中介绍的所有功能都已经适用于顺序和并行应用。不费吹灰之力就可以改成 parallel::shared::Triangulation 或 parallel::distributed::Triangulation 类。如果你觉得急于尝试，我们建议先阅读前者的第18步和后者的第40步，以进一步了解该主题的背景信息，然后再回到本教程来尝试你新获得的技能。

我们在第75步中更进一步：在这里，我们将hp-adapative和MatrixFree方法与 parallel::distributed::Triangulation 对象结合在一起。


examples/step-28/doc/intro.dox

 <br> 

<i>This program was contributed by Yaqi Wang and Wolfgang
Bangerth. Results from this program are used and discussed in the publication
"Three-dimensional h-adaptivity for the multigroup neutron diffusion
equations" by Yaqi Wang, Wolfgang Bangerth and Jean Ragusa. The paper's full
bibliographic details are as follows:


@code
@Article{WBR09,
  author  = {Yaqi Wang and Wolfgang Bangerth and Jean Ragusa},
  title   = {Three-dimensional h-adaptivity for the multigroup
             neutron diffusion equations},
  journal = {Progr. Nucl. Energy},
  year    = 2009,
  volume  = 51,
  pages   = {543--555}
}
@endcode@code
@Article{WBR09,
  author  = {Yaqi Wang and Wolfgang Bangerth and Jean Ragusa},
  title   = {Three-dimensional h-adaptivity for the multigroup
             neutron diffusion equations},
  journal = {Progr. Nucl. Energy},
  year    = 2009,
  volume  = 51,
  pages   = {543--555}
}
@endcode


The paper is available <a target="_top"
href="https://www.semanticscholar.org/paper/Three-dimensional-h-adaptivity-for-the-multigroup-Wang-Bangerth/900592e8e891d9b888d59a69ec58bf2bbda56b4b">here</a><a target="_top"
href="https://www.semanticscholar.org/paper/Three-dimensional-h-adaptivity-for-the-multigroup-Wang-Bangerth/900592e8e891d9b888d59a69ec58bf2bbda56b4b">here</a>.
</i>

 <br> 


<a name="Intro"></a> <h1>Introduction</h1> 在这个例子中，我们打算解决中子传输方程的多组扩散近似。基本上，看待这个问题的方式如下。在核反应堆中，中子以不同的能量飞驰，被吸收或散射，或开始一个新的裂变事件。如果从足够长的长度尺度来看，中子的运动可以被视为一个扩散过程。

对这一点的数学描述将把中子归入能级，并考虑每个能级或能量组中的中子通量的平衡方程。然后，散射、吸收和裂变事件将成为描述中子通量的扩散方程中的算子。假设我们有能量组 $g=1,\ldots,G$ ，按照惯例，我们假设能量最高的中子在1组，能量最低的中子在 $G$ 组。那么每组的中子通量满足以下公式。

@f{eqnarray*}
\frac 1{v_g}\frac{\partial \phi_g(x,t)}{\partial t}
&=&
\nabla \cdot(D_g(x) \nabla \phi_g(x,t))


-
\Sigma_{r,g}(x)\phi_g(x,t)
\\
&& \qquad
+
\chi_g\sum_{g'=1}^G\nu\Sigma_{f,g'}(x)\phi_{g'}(x,t)
+
\sum_{g'\ne g}\Sigma_{s,g'\to g}(x)\phi_{g'}(x,t)
+
s_{\mathrm{ext},g}(x,t)


@f}

通过适当的边界条件增强。这里， $v_g$ 是 $g$ 组内中子的速度。换句话说， $g$ 组中的中子通量的时间变化受以下过程支配。   <ul>   <li>  扩散  $\nabla \cdot(D_g(x) \nabla \phi_g(x,t))$  。这里， $D_g$ 是（空间上可变的）扩散系数。   <li>  吸收  $\Sigma_{r,g}(x)\phi_g(x,t)$  （注意是负号）。系数 $\Sigma_{r,g}$ 被称为<i>removal
  cross section</i>。   <li>  核裂变  $\chi_g\sum_{g'=1}^G\nu\Sigma_{f,g'}(x)\phi_{g'}(x,t)$  。   能量的中子 $g$ 的产生与能量的中子通量 $g'$ 乘以能量的中子 $\Sigma_{f,g'}$ 引起裂变事件的概率 $g'$ 乘以每个裂变事件中产生的中子数量 $\nu$ 乘以该事件中产生的中子具有能量的概率 $g$  。   $\nu\Sigma_{f,g'}$ 被称为<i>fission cross section</i>， $\chi_g$ 被称为<i>fission spectrum</i>。我们将把 $\chi_g\nu\Sigma_{f,g'}$ 这个词表示为程序中的<i>fission distribution cross
    section</i>。   <li> 能量为 $\sum_{g'\ne g}\Sigma_{s,g'\to g}(x)\phi_{g'}(x,t)$ 的中子的散射 $g'$ 产生能量为 $g$ 的中子 。   $\Sigma_{s,g'\to g}$ 被称为<i>scattering cross
    section</i>。弹性、群内散射 $g'=g$ 的情况也存在，但我们将其归入清除截面。 $g'<g$ 的情况被称为向下散射，因为中子在这样的事件中失去了能量。另一方面， $g'>g$ 对应于上散射：中子在散射事件中从其周围原子的热运动中获得能量；因此，上散射仅对动能已经与热动能处于同一等级（即在 $eV$ 以下范围）的中子是一个重要过程。   <li>  一个外源  $s_{\mathrm{ext},g}$  。   </ul> 

为了在反应堆分析中进行现实模拟，人们可能希望将中子能量的连续谱分成许多能量组，通常多达100个。然而，如果对某些类型的反应堆（例如压水反应堆，PWR）的中子能谱有足够的了解，那么只用2个能群就有可能获得满意的结果。

在本教程的程序中，我们提供的结构可以根据需要用尽可能多的能量组进行计算。然而，为了保持适度的计算时间，并避免将数百个系数列表，我们只提供上述两组模拟方程的系数，即  $g=1,2$  。然而，我们确实考虑了一个现实的情况，即假设系数不是恒定的，而是取决于以相当复杂的方式装配到反应堆燃料组件的材料（见下文）。




<h3>The eigenvalue problem</h3>

如果我们一次考虑所有的能量组，我们可以将上述方程写成以下算子形式。

@f{eqnarray*}
\frac 1v \frac{\partial \phi}{\partial t}
=


-L\phi
+
F\phi
+
X\phi
+
s_{\mathrm{ext}},


@f}

其中 $L,F,X$ 分别是沉降、裂变和散射算子。  这里的 $L$ 包括扩散和清除项。请注意， $L$ 是对称的，而 $F$ 和 $X$ 不是。

众所周知，如果算子 $-L+F+X$ 的所有特征值都是负的，这个方程就有一个稳定的解。这可以通过将方程乘以 $\phi$ 并在域上进行积分而很容易看出，从而导致

@f{eqnarray*}
  \frac 1{2v} \frac{\partial}{\partial t}  \|\phi\|^2 = ((-L+F+X)\phi,\phi).


@f}

稳定性意味着解决方案不会增长，也就是说，我们希望左手边的值小于零，如果右边算子的特征值都是负的，就会出现这种情况。由于显而易见的原因，如果核反应堆产生的中子通量呈指数增长，这不是很理想，所以特征值分析是核工程师的面包和主食。因此，该程序的要点是考虑特征值问题

@f{eqnarray*}
  (L-F-X) \phi = \lambda \phi,


@f}

其中我们要确保所有的特征值都是正的。请注意， $L$ ，即扩散算子加上吸收（去除），是正定的；因此，所有特征值为正的条件意味着我们要确保裂变和组间散射足够弱，不会使频谱转移到负值。

在核工程中，人们通常会关注特征值问题的一个稍微不同的表述。为此，我们不只是与 $\phi$ 相乘并整合，而是与 $\phi(L-X)^{-1}$ 相乘。然后我们得到以下演化方程。

@f{eqnarray*}
  \frac 1{2v} \frac{\partial}{\partial t}  \|\phi\|^2_{(L-X)^{-1}} = ((L-X)^{-1}(-L+F+X)\phi,\phi).


@f}

如果以下问题的特征值都是负的，那么稳定性就得到了保证。

@f{eqnarray*}
  (L-X)^{-1}(-L+F+X)\phi = \lambda_F \phi,


@f}

等同于特征值问题

@f{eqnarray*}
  (L-X)\phi = \frac 1{\lambda_F+1} F \phi.


@f}

核工程中的典型表述是将其写为

@f{eqnarray*}
  (L-X) \phi = \frac 1{k_{\mathrm{eff}}} F \phi,


@f}

其中 $k_{\mathrm{eff}}=\frac 1{\lambda^F+1}$  。直观地说， $k_{\mathrm{eff}}$ 是类似于每个典型时间尺度的中子的乘法系数，对于反应堆的稳定运行，它应该小于或等于1：如果它小于1，链式反应将消亡，而核弹等的 $k$ -特征值大于1。一个稳定的反应堆应该有 $k_{\mathrm{eff}}=1$  。

对于那些想知道在实践中如何才能做到这一点，而又不至于在不经意间变得稍大而引发核弹的人来说：首先，裂变过程发生在不同的时间尺度上。虽然大多数中子在裂变事件后很快就被释放出来，但少量的中子只有在裂变开始后经过几次进一步的衰变后，才会由子核释放出来，最长可达10-60秒。因此，如果一个人稍稍超过 $k_{\mathrm{eff}}=1$ ，就会有许多秒的反应时间，直到裂变中产生的所有中子重新进入裂变循环。然而，吸收中子的核反应堆中的控制棒--并因此减少 $k_{\mathrm{eff}}$ --被设计成最多在2秒内全部进入反应堆。

因此，如果 $k_{\mathrm{eff}}$ 在一段时间内大于1，正如不断增长的中子通量所显示的那样，人们有10-60秒的时间来调节核反应。调节可以通过持续监测中子通量来实现，必要时通过将吸收中子的控制棒移入或移出反应堆几毫米来增加或减少中子通量。在更大的范围内，冷却反应堆的水含有硼，一种良好的中子吸收剂。每隔几个小时，通过添加硼或稀释冷却剂来调整硼的浓度。

最后，一些吸收和散射反应有一些内置的稳定性；例如，较高的中子通量导致局部温度升高，这降低了水的密度，因此减少了散射体的数量，而这些散射体是在中子开始裂变事件本身之前将其从高能量调节到低能量所必需的。

在这个教程程序中，我们解决上述 $k$ -两个能量组的特征值问题，我们正在寻找最大的乘法因子 $k_{\mathrm{eff}}$  ，它与最小特征值的逆值加1成正比。为了解决特征值问题，我们一般使用<i>inverse power method</i>的修改版。该算法看起来像这样。

<ol>  <li>  用 $\phi_g^{(0)}$ 和 $k_{\mathrm{eff}}^{(0)}$ 初始化 $\phi_g$ 和 $k_{\mathrm{eff}}$ ，让 $n=1$  .

 <li>  通过@f{eqnarray*}
    s_f^{(n-1)}(x)
    =
    \frac{1}{k_{\mathrm{eff}}^{(n-1)}}
    \sum_{g'=1}^G\nu\Sigma_{f,g'}(x)\phi_{g'}^{(n-1)}(x).
  @f}定义所谓的<i>fission source</i>。



 <li>  利用@f{eqnarray*}


    -\nabla \cdot D_g\nabla \phi_g^{(n)}
    +
    \Sigma_{r,g}\phi_g^{(n)}
    =
    \chi_g s_f^{(n-1)}
    +
    \sum_{g'< g} \Sigma_{s,g'\to g} \phi_{g'}^{(n)}
    +
    \sum_{g'> g}\Sigma_{s,g'\to g}\phi_{g'}^{(n-1)}.
  @f}求解所有组通量 $\phi_g,g=1,\ldots,G$  。



 <li>  更新@f{eqnarray*}
    k_{\mathrm{eff}}^{(n)}
    =
    \sum_{g'=1}^G
    \int_{\Omega}\nu\Sigma_{f,g'}(x)
    \phi_{g'}^{(n)}(x)dx.
  @f} 。



 <li>  比较 $k_{\mathrm{eff}}^{(n)}$ 和 $k_{\mathrm{eff}}^{(n-1)}$  。   如果变化大于规定的公差，则设置  $n=n+1$  从步骤2开始重复迭代，否则结束迭代。   </ol> 

需要注意的是，在这个方案中，我们在每次幂迭代中并不完全求解群通量，而是考虑以前只计算  $\phi_{g'}^{(n)}$  的下散射事件  $g'<g$  。上散射仅通过使用旧的迭代器 $\phi_{g'}^{(n-1)}$ 来处理，实质上是假设散射算子是三角形的。这在物理上是有原因的，因为向上散射在中子散射中并不扮演太重要的角色。此外，实践表明，即使使用这种简化方法，反功率迭代也是稳定的。

还要注意的是，我们可以使用很多外推技术来加速上述的功率迭代。然而，这些都没有在这个例子中实现。




<h3>Meshes and mesh refinement</h3>

人们可能会想，在同一网格上求解各个能量组方程的解是否合适。这个问题可以归结为： $\phi_g$ 和 $\phi_{g'}$ 是否会有类似的光滑度特性？如果是这样的话，那么对两者使用相同的网格是合适的；一个典型的应用可能是化学燃烧，通常所有或大多数化学物种的浓度在火焰前沿快速变化。事实证明，通过观察本教程程序结果部分显示的图形就会发现，然而这里的情况并非如此：由于不同能量组的扩散系数不同，快中子（在小群数 $g$ 的仓中）有一个非常平滑的通量函数，而慢中子（在大群数的仓中）受当地材料特性的影响更大，如果像我们这里计算的情况一样，系数粗糙，则有一个相应的粗糙解决方案。因此，我们要使用不同的网格来计算每个能量组。

这有两个影响，我们将不得不考虑。首先，我们需要找到一种方法来单独细化这些网格。第二，为逆功率迭代组装源项，我们必须将定义在网格 $g'$ 上的解 $\phi_{g'}^{(n)}$ 与定义在网格 $g$ 上的形状函数进行整合，这将成为一项更为复杂的任务。




<h4>Mesh refinement</h4>

我们使用通常的范式：在一个给定的网格上求解，然后为每个网格的每个单元评估一个误差指标。因为它非常方便，我们再次使用Kelly, Gago, Zienkiewicz和Babuska的事后误差估计器，它通过整合每个单元面的解的梯度跳跃来接近每个单元的误差。利用这一点，我们得到指标

@f{eqnarray*}
\eta_{g,K}, \qquad g=1,2,\ldots,G,\qquad K\in{\cal T}_g,


@f}

其中 ${\cal T}_g$ 是用于解决 $\phi_g$ 的三角法。问题是该如何处理这个问题。其一，很明显，只细化那些误差指标最高的单元可能会导致不好的结果。为了理解这一点，必须认识到 $\eta_{g,K}$ 与 $\phi_g$ 的二阶导数成比例。换句话说，如果我们有两个能量组 $g=1,2$ ，它们的解同样平滑，但其中一个大了一万倍，例如，那么只有该网格的单元被细化，而小幅度的解的网格将保持粗糙。这可能不是人们想要的，因为我们可以认为解的两个部分同样重要。

因此，从本质上讲，我们必须用一个重要系数 $z_g$ 来衡量 $\eta_{g,K}$ ，这个系数表示将 $\phi_g$ 解决到任何特定的精度有多重要。这样的重要系数可以用二元性技术来计算（例如，见step-14教程程序，以及那里引用的Bangerth和Rannacher的书的参考）。然而，我们不会去那里，而只是假设所有的能量组都是同等重要的，因此将以解 $\phi_g$ 的最大值来规范 $\eta_{g,K}$ 组的误差指标 $g$  。然后我们对误差满足以下条件的单元进行细化

@f{eqnarray*}
  \frac{\eta_{g,K}}{\|\phi_g\|_\infty}
  >
  \alpha_1
  \displaystyle{\max_{\begin{matrix}1\le g\le G \\ K\in {\cal T}_g\end{matrix}}
    \frac{\eta_{g,K}}{\|\phi_g\|_\infty}}


@f}

和粗化的细胞，其中

@f{eqnarray*}
  \frac{\eta_{g,K}}{\|\phi_g\|_\infty}
  <
  \alpha_2
  \displaystyle{\max_{\begin{matrix}1\le g\le G \\ K\in {\cal T}_g\end{matrix}}
    \frac{\eta_{g,K}}{\|\phi_g\|_\infty}}.


@f}

我们在代码中选择了［ $\alpha_1=0.3$ ］和［ $\alpha_2=0.01$ ］。注意，这当然会导致不同能量组的不同网格。

上面的策略实质上意味着以下几点。如果对于能量组 $g$ 来说，有许多单元 $K\in {\cal T}_g$ 的误差很大，例如因为解决方案在整体上非常粗糙，那么许多单元将高于阈值。另一方面，如果有几个单元的误差较大，而许多单元的误差较小，例如因为除少数地方外，解决方案总体上相当平滑，那么只有少数有较大误差的单元将被细化。因此，该策略允许网格很好地跟踪相应的解决方案的全局平滑性属性。




<h4>Assembling terms on different meshes</h4>

如上所述，多组细化策略导致不同解的网格不同  $\phi_g$  。那么问题出在哪里呢？实质上是这样的：在特征值迭代的第3步中，我们要像往常一样通过与定义在网格上的测试函数 $\varphi_g^i$ 相乘来形成要计算的方程的弱形式 $\phi_g^{(n)}$ ；在这个过程中，我们要计算包含以下形式的项的右手向量。

@f{eqnarray*}
  F_i = \int_\Omega f(x) \varphi_g^i(x) \phi_{g'}(x) \ dx,


@f}

其中 $f(x)$ 是用于特征值方程右侧的系数函数 $\Sigma_{s,g'\to g}$ 或 $\nu\chi_g\Sigma_{f,g'}$ 中的一个。现在的困难是， $\phi_{g'}$ 是定义在能量组 $g'$ 的网格上，即它可以扩展为 $\phi_{g'}(x)=\sum_j\phi_{g'}^j \varphi_{g'}^j(x)$ ，基函数 $\varphi_{g'}^j(x)$ 定义在网格 $g'$ 。因此，对右边的贡献可以写成

@f{eqnarray*}
  F_i = \sum_j \left\{\int_\Omega f(x) \varphi_g^i(x) \varphi_{g'}^j(x)
  \ dx \right\} \phi_{g'}^j ,


@f}

另一方面，测试函数  $\varphi_g^i(x)$  是在网格  $g$  上定义的。这意味着我们不能将积分  $\Omega$  分割成网格  $g$  或  $g'$  上的积分，因为其他的基函数可能没有定义在这些单元上。

这个问题的解决方案在于， $g$ 和 $g'$ 的网格都是通过自适应细化从一个共同的粗略的网格中得到。因此，我们总能找到一组单元，我们用 ${\cal T}_g \cap
{\cal T}_{g'}$ 表示，它们满足以下条件。   <ul>   <li>  这些单元的联合覆盖了整个领域，并且  <li>  一个单元  $K \in {\cal T}_g \cap {\cal T}_{g'}$  在两个网格中至少有一个是活动的。   </ul>  构建这个集合的方法是，取粗略网格的每个单元，做以下步骤。(i) 如果该单元在 ${\cal T}_g$ 或 ${\cal T}_{g'}$ 上处于活动状态，则将该单元加入该集合；(ii) 否则，即如果该单元在两个网格上都有子节点，则对该单元的每个子节点进行步骤(i)。事实上，deal.II有一个函数 GridTools::get_finest_common_cells ，可以准确地计算出在两个网格中至少有一个处于活动状态的单元的集合。

有了这个，我们可以把上述积分写成如下。

@f{eqnarray*}
  F_i
  =
  \sum_{K \in {\cal T}_g \cap {\cal T}_{g'}}
  \sum_j \left\{\int_K f(x) \varphi_g^i(x) \varphi_{g'}^j(x)
  \ dx \right\} \phi_{g'}^j.


@f}

在代码中，我们在函数 <code>NeutronDiffusionProblem::assemble_rhs</code> 中计算右手边，其中（除其他外）我们在常见的最精炼的单元格集合上循环，对这些单元格的每一对调用函数 <code>NeutronDiffusionProblem::assemble_common_cell</code> 。

根据结构，现在有三种情况需要考虑。<ol>  <li>  单元 $K$ 在两个网格上都是有效的，也就是说，基函数 $\varphi_g^i$ 以及 $\varphi_{g'}^j$ 都是在 $K$ 上定义。   <li>  单元 $K$ 在网格 $g$ 上是有效的，但在 $g'$ 上不是，即 $\varphi_g^i$ 是在 $K$ 上定义的，而 $\varphi_{g'}^j$ 是在 $K$ 的子网格上定义的。   <li>  单元 $K$ 在网格 $g'$ 上是有效的，但在 $g$ 上不是，其结论与(ii)相反。   </ol> 

为了计算上面的右手边，我们就需要对这三种情况有不同的代码，如下所示。<ol>  <li>  如果单元 $K$ 在两个网格上都是活动的，那么我们可以直接评估积分。事实上，我们甚至不必理会基函数 $\varphi_{g'}$ ，因为我们所需要的只是 $\phi_{g'}$ 在正交点的值。我们可以使用 FEValues::get_function_values 函数来完成这个任务。这在 <code>NeutronDiffusionProblem::assemble_common_cell</code> 函数中直接完成。

 <li>  如果单元格  $K$  在网格  $g$  上是有效的，而不是  $g'$  ，那么基函数  $\varphi_{g'}^j$  只能定义在子单元  $K_c,0\le c<2^{\texttt{dim}}$  上，或者在这些子单元  $K$  上被精炼一次以上。

  让我们假设 $K$ 在网格 $g'$ 上只比在网格 $g$ 上多精炼一次。利用我们使用嵌入式有限元空间的事实，即一个网格上的每个基函数可以写成下一个细化网格上的基函数的线性组合，我们可以将 $\phi_g^i$ 对子单元 $K_c$ 的限制扩展为定义在该子单元上的基函数（即定义了基函数 $\varphi_{g'}^l$ 的单元上）。   @f{eqnarray*}
    \phi_g^i|_{K_c} = B_c^{il} \varphi_{g'}^l|_{K_c}.
  @f}

  在这里，以及在下文中，对出现两次的指数进行求和是隐含的。矩阵 $B_c$ 是将数据从一个单元格内插到其 $c$ 的子单元的矩阵。

  那么我们可以把单元格 $K$ 对右侧分量 $F_i$ 的贡献写成@f{eqnarray*}
    F_i|_K
    &=&
    \left\{ \int_K f(x) \varphi_g^i(x) \varphi_{g'}^j(x)
    \ dx \right\} \phi_{g'}^j
    \\
    &=&
    \left\{
    \sum_{0\le c<2^{\texttt{dim}}}
    B_c^{il} \int_{K_c} f(x) \varphi_{g'}^l(x) \varphi_{g'}^j(x)
    \ dx \right\} \phi_{g'}^j.
  @f} 。

  在矩阵符号中，这可以写成@f{eqnarray*}
    F_i|_K
    =
    \sum_{0\le c<2^{\texttt{dim}}}
    F_i|_{K_c},
    \qquad
    \qquad
    F_i|_{K_c} = B_c^{il} M_{K_c}^{lj}  \phi_{g'}^j
    = (B_c M_{K_c})^{ij} \phi_{g'}^j,
  @f}

  其中 $M_{K_c}^{lj}=\int_{K_c} f(x) \varphi_{g'}^l(x) \varphi_{g'}^j(x)$ 是单元格 $K$ 的子 $c$ 上的加权质量矩阵。

  下一个问题是，如果 $K$ 的一个子集 $K_c$ 没有被激活，会发生什么？然后，我们必须递归地应用这个过程，即我们必须将基础函数 $\varphi_g^i$ 插值到 $K$ 的子 $K_c$ 上，然后插值到该单元的子 $K_{cc'}$ 上，插值到该单元的子 $K_{cc'c''}$ 上，等等，直到我们找到一个活动单元。然后，我们必须将单元格 $K$ 的所有子代、孙代等的贡献相加，其贡献形式为@f{eqnarray*}
    F_i|_{K_{cc'}} = (B_cB_{c'} M_{K_{cc'}})^{ij}  \phi_{g'}^j,
  @f} 。

  或@f{eqnarray*}
    F_i|_{K_{cc'c''}} = (B_c B_{c'} B_{c''}M_{K_{cc'c''}})^{ij}
    \phi_{g'}^j,
  @f}

  等等。我们递归地做这个过程，即如果我们坐在单元格 $K$ 上，看到它在网格 $g'$ 上有孩子，那么我们就用一个身份矩阵调用一个函数 <code>assemble_case_2</code> ；该函数将把它的参数从左边乘以延长矩阵；如果该单元格还有孩子，它将用这个新矩阵调用自己，否则它将进行整合。

 <li>  最后一种情况是 $K$ 在网格 $g'$ 上是有效的，但在网格 $g$ 上不是。在这种情况下，我们必须用定义在单元格  $K$  上的基函数来表达基函数  $\varphi_{g'}^j$  ，而不是像以前那样用  $\varphi_g^i$  来表达。这当然是以完全相同的方式进行的。如果 $K$ 的子单元在网格 $g$ 上是活动的，那么就会导致表达式@f{eqnarray*}
    F_i|_K
    &=&
    \left\{ \int_K f(x) \varphi_g^i(x) \varphi_{g'}^j(x)
    \ dx \right\} \phi_{g'}^j
    \\
    &=&
    \left\{
    \sum_{0\le c<2^{\texttt{dim}}}
    \int_{K_c} f(x) \varphi_g^i(x) B_c^{jl} \varphi_{g}^l(x)
    \ dx \right\} \phi_{g'}^j.
  @f} 。

  在矩阵符号中，这个表达式现在读作@f{eqnarray*}
    F_i|_K
    =
    \sum_{0\le c<2^{\texttt{dim}}}
    F_i|_{K_c},
    \qquad
    \qquad
    F_i|_{K_c} = M_{K_c}^{il} B_c^{jl}  \phi_{g'}^j
    =
    (M_{K_c} B_c^T)^{ij} \phi_{g'}^j,
  @f} 。

  而相应地，对于单元格 $K$ 在网格 $g$ 上被精炼一次以上的情况：@f{eqnarray*}
    F_i|_{K_{cc'}} = (M_{K_{cc'}} B_{c'}^T B_c^T)^{ij}  \phi_{g'}^j,
  @f} 。

  或@f{eqnarray*}
    F_i|_{K_{cc'c''}} = (M_{K_{cc'c''}} B_{c''}^T B_{c'}^T B_c^T)^{ij}
    \phi_{g'}^j,
  @f}

  等。换句话说，这个过程与之前的工作方式完全相同，只是我们必须采取延长矩阵的转置，并需要从另一侧乘以质量矩阵。   </ol> 


情况（二）和（三）的表达式可以理解为将标量积 $(f \varphi_g^i, \varphi_{g'}^j)_K$ 中的左或右基函数反复插值到子单元上，然后在最后的单元上形成内积（质量矩阵）。为了使这些情况的对称性更加明显，我们可以这样写：对于情况（二），我们有

@f{eqnarray*}
  F_i|_{K_{cc'\cdots c^{(k)}}}
  = [B_c B_{c'} \cdots B_{c^{(k)}} M_{K_{cc'\cdots c^{(k)}}}]^{ij}
    \phi_{g'}^j,


@f}

而对于情况（三），我们得到

@f{eqnarray*}
  F_i|_{K_{cc'\cdots c^{(k)}}}
  = [(B_c B_{c'} \cdots B_{c^{(k)}} M_{K_{cc'\cdots c^{(k)}}})^T]^{ij}
    \phi_{g'}^j,


@f}






<h3>Description of the test case</h3>

一个核反应堆的堆芯是由不同类型的组件组成的。一个组件基本上是可以在反应堆内和外移动的最小单元，通常是矩形或方形。然而，组件并不是固定的单位，因为它们是由不同的燃料棒、控制棒和仪器元件组成的复杂晶格组装而成的，这些元件通过永久连接到燃料棒上的间隔件来保持彼此的位置。使事情更加复杂的是，在反应堆中同时使用不同种类的组件，这些组件在其组成的燃料棒的类型和排列上有所不同。

显然，组件的排列以及组件内燃料棒的排列都会影响反应堆内中子通量的分布（这一事实通过查看本方案结果部分中下面显示的解决方案就会很明显）。例如，燃料棒在铀235或钚239的富集程度上彼此不同。另一方面，控制棒具有零裂变，但散射和吸收截面不为零。

这整个安排将使描述或空间上的材料参数变得非常复杂。它不会变得更简单，但我们将做一个近似：我们将每个圆柱形棒和周围的水所居住的体积合并成二次横截面的体积，变成所谓的 "夹子单元"，用核数据库和中子光谱的知识获得这些单元的同质化材料数据。同质化使所有材料数据在带有新燃料的反应堆的求解域上成为片状常数。然后为一个点所在的四元组查询空间相关的材料参数，然后为这个四元组中的四元针单元查询。

在这个教程程序中，我们模拟了一个由 $4
\times 4$ 组件组成的反应堆的四分之一。我们使用对称性（Neumann）边界条件，将问题缩小到四分之一的领域，因此只模拟 $2\times 2$ 套组件。其中两个将是UO ${}_2$ 燃料，另外两个是MOX燃料。这些组件中的每一个都由不同成分的 $17\times 17$ 棒组成。因此，我们总共创造了一个 $34\times 34$ 棒子的晶格。为了使以后的事情更简单，我们通过创建一个 $34\times 34$ 单元的粗大网格来反映这一事实（尽管领域是一个正方形，我们通常会使用一个单元）。在deal.II中，每个单元都有一个 <code>material_id</code> ，可以用来将每个单元与一个特定的数字联系起来，识别这个单元的体积是由什么材料制成的；我们将使用这个材料ID来识别在这个测试案例中使用的8种不同的杆子中的哪一种组成了一个特定的单元。请注意，在网格细化后，单元格的子代会继承材料ID，这样即使在网格细化后也能简单地跟踪材料。

在结果部分显示的图像中，棒的排列将清晰可见。材料和两个能量组的横截面取自OECD/NEA的基准问题。详细的配置和材料数据在代码中给出。




<h3>What the program does (and how it does that)</h3>

作为对程序具体工作的粗略概述，这里是基本布局：从每个能量组相同的粗略网格开始，我们计算反特征值迭代以计算给定网格集上的 $k$ 特征值。当特征值的变化低于一定的容忍度时，我们停止这些迭代，然后写出每个能量组的网格和解，供图形程序检查。由于解决方案的网格是不同的，我们必须为每个能量组生成一个单独的输出文件，而不是能够将所有能量组的解决方案添加到同一个文件中。

在这之后，我们按照上面某一节的解释对每个网格的误差指标进行评估，并独立地对每个网格的单元进行细化和粗化。由于特征值迭代是相当昂贵的，我们不想在新的网格上重新开始；相反，我们使用SolutionTransfer类在网格细化时将前一个网格的解插到下一个网格。一个简单的实验会让你相信，这比我们省略这一步要省事得多。这样做之后，我们在下一组网格上继续进行特征值迭代。

该程序由一个参数文件控制，使用ParameterHandler类。我们将在本教程的结果部分展示一个参数文件。现在只需说它控制了所使用的有限元的多项式程度、能量组的数量（尽管目前实现的只是2组问题的系数）、停止反特征值迭代的容忍度以及我们要做的细化循环的数量。


examples/step-28/doc/results.dox



<h1>Results</h1>

我们可以用下面的输入文件运行该程序。

@code
# Listing of Parameters
# ---------------------
# Polynomial degree of the finite element to be used
set Finite element degree     = 2


# The number of energy different groups considered
set Number of energy groups   = 2


# Inner power iterations are stopped when the change in k_eff falls below this
# tolerance
set Power iteration tolerance = 1e-12


# Number of refinement cycles to be performed
set Refinement cycles         = 12
@endcode

这个程序的输出包括控制台输出，一个名为 "convergence_table "的文件，记录网格迭代的主要结果，以及vtu格式的图形输出。

控制台的输出看起来像这样。

@code
Cycle 0:
   Numbers of active cells:       1156 1156
   Numbers of degrees of freedom: 4761 4761


Iter number: 1 k_eff=319.375676634310 flux_ratio=6.836246075630 max_thermal=1.433899030144
Iter number: 2 k_eff=0.834072546055 flux_ratio=5.204601882144 max_thermal=0.004630925876
Iter number: 3 k_eff=0.862826188043 flux_ratio=4.645051765984 max_thermal=0.005380396338
...
Iter number:69 k_eff=0.906841960370 flux_ratio=4.384056022578 max_thermal=0.008466414246
Iter number:70 k_eff=0.906841960371 flux_ratio=4.384056022583 max_thermal=0.008466414246


   Cycle=0, n_dofs=9522,  k_eff=0.906841960371, time=7.623425000000



Cycle 1:
   Numbers of active cells:       1156 2380
   Numbers of degrees of freedom: 4761 10667


Iter number: 1 k_eff=0.906838267472 flux_ratio=4.385474405125 max_thermal=0.008463675976
...


Cycle 11:
   Numbers of active cells:       11749 47074
   Numbers of degrees of freedom: 50261 204523


Iter number: 1 k_eff=0.906798057750 flux_ratio=4.384878772166 max_thermal=0.008464822382
Iter number: 2 k_eff=0.906833008185 flux_ratio=4.384868138638 max_thermal=0.008465057191
...
Iter number:32 k_eff=0.906834736550 flux_ratio=4.384846081793 max_thermal=0.008465019607
Iter number:33 k_eff=0.906834736551 flux_ratio=4.384846081798 max_thermal=0.008465019607


   Cycle=11, n_dofs=254784,  k_eff=0.906834736551, time=238.593762000000
@endcode



我们看到动力迭代在第0周期后确实收敛得更快，这是因为用上一次网格迭代的解决方案进行了初始化。收敛表 "的内容是。

@code
0 4761 4761 0.906841960371 4.38405602258
1 4761 10667 0.906837901031 4.38548908776
2 4761 18805 0.906836075928 4.3854666475
3 6629 27301 0.90683550011 4.38540458087
4 12263 48095 0.906835001796 4.38538179873
5 17501 69297 0.906834858174 4.38485382341
6 19933 78605 0.90683482406 4.38485065879
7 23979 93275 0.906834787555 4.38484837926
8 30285 117017 0.906834761604 4.38484654495
9 40087 154355 0.906834746215 4.38484608319
10 45467 179469 0.906834740155 4.38484600505
11 50261 204523 0.906834736551 4.3848460818
@endcode

列的含义是：网格迭代次数，快速能量组的自由度数，热能组的自由度数，收敛的K效应和快速通量的最大值和热能的最大值之间的比率。

网格迭代#9时，快速和热能组的网格看起来如下。

 <img width="400" src="https://www.dealii.org/images/steps/developer/step-28.grid-0.9.order2.png" alt=""> &nbsp;  <img width="400" src="https://www.dealii.org/images/steps/developer/step-28.grid-1.9.order2.png" alt="">  。

我们看到，热组的网格比快组的网格要细得多。这些网格上的解决方案是：（注：通量被归一化，总裂变源等于1）。

 <img width="400" src="https://www.dealii.org/images/steps/developer/step-28.solution-0.9.order2.png" alt="">  &nbsp;  <img width="400" src="https://www.dealii.org/images/steps/developer/step-28.solution-1.9.order2.png" alt=""> 

然后我们绘制出多项式阶数等于1、2和3的收敛数据。

 <img src="https://www.dealii.org/images/steps/developer/step-28.convergence.png" alt=""> 

估计的 "精确的 "k-effective=0.906834721253，这只是从最后一次网格迭代的多项式阶数3减去2e-10。我们看到，h-adaptive计算提供了一个代数收敛性。多项式阶数越高，网格迭代收敛的速度越快。在我们的问题中，我们需要较少的DoFs数量来实现较高的多项式阶数下的相同精度。


examples/step-29/doc/intro.dox

 <br> 

<i>
This program was contributed by Moritz Allmaras at Texas A&amp;M
University. Some of the work on this tutorial program has been funded
by NSF under grant DMS-0604778.
</i>

<b>Note:</b> 为了运行这个程序，deal.II必须被配置为使用UMFPACK稀疏直接求解器。请参考<a
href="../../readme.html#umfpack">ReadMe</a>中的说明如何做到这一点。


<a name="Intro"></a>

<h1>Introduction</h1>


一个经常出现的问题是如何用deal.II解决涉及复值函数的问题。对于许多问题，与其直接使用复值有限元，不如将复值函数分成实部和虚部，并使用单独的标量有限元场来离散它们中的每一个，这样做往往更方便。基本上，这相当于把一个复值方程看作是两个实值方程的系统。这个简短的例子演示了如何在deal.II中通过使用 <code>FE_system</code> 对象来堆叠两个代表实部和虚部的有限元场来实现。(相反的方法，保持所有的复值，在另一个教程程序中演示：见步骤58)。当分成实部和虚部时，这里涉及的方程属于矢量值问题的范畴。这个主题的顶层概述可以在  @ref vector_valued  模块中找到。

除了这些讨论，我们还讨论了ParameterHandler类，它提供了一种方便的方法，在运行时从配置文件中读取参数，而不需要重新编译程序代码。




<h3>Problem setting</h3>

这个程序的最初目的是模拟由一个几何形状可变的换能器透镜产生的超声波的聚焦特性。最近在医学成像方面的应用，不仅将超声波用于成像，而且还能激发材料中的某些局部效应，如光学特性的变化，然后可以用其他成像技术来测量。这些方法的一个重要因素是能够将超声波的强度集中在材料的一个特定部分，最好是一个点，以便能够检查该特定位置的材料特性。

为了推导出这个问题的模型，我们把超声波看成是由波浪方程支配的压力波。

@f[
	\frac{\partial^2 U}{\partial t^2}	-	c^2 \Delta U = 0


@f]

其中 $c$ 是波速（为简单起见，我们假设为常数）， $U
= U(x,t),\;x \in \Omega,\;t\in\mathrm{R}$  。边界 $\Gamma=\partial\Omega$ 分为两部分 $\Gamma_1$ 和 $\Gamma_2=\Gamma\setminus\Gamma_1$ ，其中 $\Gamma_1$ 代表换能器透镜， $\Gamma_2$ 是吸收边界（也就是说，我们希望在 $\Gamma_2$ 上选择边界条件，使其模仿一个更大的域）。在 $\Gamma_1$ 上，换能器产生一个恒定频率 ${\omega}>0$ 和恒定振幅（我们在这里选择为1）的波。

@f[
U(x,t) = \cos{\omega t}, \qquad x\in \Gamma_1


@f]



如果没有其他（内部或边界）源，并且由于唯一的源具有频率 $\omega$ ，那么解决方案可以接受形式为 $U(x,t) = \textrm{Re}\left(u(x)\,e^{i\omega
t})\right)$ 的变量分离。复值函数 $u(x)$ 描述了频率为 ${\omega}$ 的波的振幅和相位（相对于源）的空间依赖性，其中振幅是我们感兴趣的量。通过将这种形式的解决方案插入波浪方程，我们看到，对于 $u$ ，我们有

@f{eqnarray*}


-\omega^2 u(x) - c^2\Delta u(x) &=& 0, \qquad x\in\Omega,\\
u(x) &=& 1,  \qquad x\in\Gamma_1.


@f}



为了在 $\Gamma_2$ 上找到模拟吸收边界的合适条件，考虑一个频率为 ${\omega}$ 的波在 $k\in {\mathrm{R}^2}$ 方向上行驶。为了使 $V$ 能够解决波浪方程， $|k|={\frac{\omega}{c}}$ 必须成立。假设这个波以直角击中 $x_0\in\Gamma_2$ 的边界，即 $n=\frac{k}{|k|}$ ， $n$ 表示 $\Omega$ 在 $x_0$ 的外单位法线。然后在 $x_0$ ，这个波满足方程式

@f[
c (n\cdot\nabla V) + \frac{\partial V}{\partial t} = (i\, c\, |k| - i\, \omega) V = 0.


@f]

因此，通过强制执行边界条件

@f[
c (n\cdot\nabla U) + \frac{\partial U}{\partial t} = 0, \qquad x\in\Gamma_2,


@f]

以直角撞击边界 $\Gamma_2$ 的波将被完全吸收。另一方面，那些没有以直角撞击边界的波场部分不满足这个条件，将其作为边界条件强制执行会产生部分反射，即只有部分波会通过边界，就像它不在这里一样，而剩下的部分波会被反射回域中。

如果我们愿意接受这一点作为吸收边界的充分近似，我们最终得出以下问题，对于 $u$  。

@f{eqnarray*}


-\omega^2 u - c^2\Delta u &=& 0, \qquad x\in\Omega,\\
c (n\cdot\nabla u) + i\,\omega\,u &=&0, \qquad x\in\Gamma_2,\\
u &=& 1,  \qquad x\in\Gamma_1.


@f}

这是一个亥姆霍兹方程（类似于步骤7中的方程，但这次有''坏符号''），在 $\Gamma_1$ 上有Dirichlet数据，在 $\Gamma_2$ 上有混合边界条件。由于 $\Gamma_2$ 上的条件，我们不能只是分别处理 $u$ 的实部和虚部方程。然而，我们可以把 $u$ 的PDE看作是 $u$ 的实部和虚部的两个PDE系统， $\Gamma_2$ 的边界条件代表系统中两个部分之间的耦合项。这是按以下思路进行的。让 $v=\textrm{Re}\;u,\; w=\textrm{Im}\;u$ ，然后在 $v$ 和 $w$ 方面，我们有以下系统。

@f{eqnarray*}
  \left.\begin{array}{ccc}


    -\omega^2 v - c^2\Delta v &=& 0 \quad\\


    -\omega^2 w - c^2\Delta w &=& 0 \quad
  \end{array}\right\} &\;& x\in\Omega,
	\\
  \left.\begin{array}{ccc}
    c (n\cdot\nabla v) - \omega\,w &=& 0 \quad\\
    c (n\cdot\nabla w) + \omega\,v &=& 0 \quad
  \end{array}\right\} &\;& x\in\Gamma_2,
	\\
	\left.\begin{array}{ccc}
    v &=& 1 \quad\\
    w &=& 0 \quad
  \end{array}\right\} &\;& x\in\Gamma_1.


@f}



对于 $\phi,\psi$ 与 $\phi|_{\Gamma_1}=\psi|_{\Gamma_1}=0$ 的测试函数，经过通常的乘法，在 $\Omega$ 上的积分和应用部分积分，我们得到弱的表述

@f{eqnarray*}


-\omega^2 \langle \phi, v \rangle_{\mathrm{L}^2(\Omega)}
+ c^2 \langle \nabla \phi, \nabla v \rangle_{\mathrm{L}^2(\Omega)}


- c \omega \langle \phi, w \rangle_{\mathrm{L}^2(\Gamma_2)} &=& 0, \\


-\omega^2 \langle \psi, w \rangle_{\mathrm{L}^2(\Omega)}
+ c^2 \langle \nabla \psi, \nabla w \rangle_{\mathrm{L}^2(\Omega)}
+ c \omega \langle \psi, v \rangle_{\mathrm{L}^2(\Gamma_2)} &=& 0.


@f}



我们选择有限元空间 $V_h$ 和 $W_h$ ，基数为 $\{\phi_j\}_{j=1}^n,
\{\psi_j\}_{j=1}^n$ ，寻找近似解

@f[
v_h = \sum_{j=1}^n \alpha_j \phi_j, \;\; w_h = \sum_{j=1}^n \beta_j \psi_j.


@f]

将其插入变异形式中，可以得到方程组

@f[
\renewcommand{\arraystretch}{2.0}
\left.\begin{array}{ccc}
\sum_{j=1}^n
\left(


-\omega^2 \langle \phi_i, \phi_j \rangle_{\mathrm{L}^2(\Omega)}
+ c^2 \langle \nabla \phi_i, \nabla \phi_j \rangle_{\mathrm{L}^2(\Omega)}
\right)
\alpha_j


- \left(
c\omega \langle \phi_i,\psi_j\rangle_{\mathrm{L}^2(\Gamma_2)}\right)\beta_j
&=& 0 \\
\sum_{j=1}^n
\left(


-\omega^2 \langle \psi_i, \psi_j \rangle_{\mathrm{L}^2(\Omega)}
+ c^2 \langle \nabla \psi_i, \nabla \psi_j \rangle_{\mathrm{L}^2(\Omega)}
\right)\beta_j
+ \left(
c\omega \langle
\psi_i,\phi_j\rangle_{\mathrm{L}^2(\Gamma_2)}
\right)\alpha_j
&=& 0
\end{array}\right\}\;\;\forall\; i =1,\ldots,n.


@f]

用矩阵符号表示。

@f[
\renewcommand{\arraystretch}{2.0}
\left(
\begin{array}{cc}


-\omega^2 \langle \phi_i, \phi_j \rangle_{\mathrm{L}^2(\Omega)}
+ c^2 \langle \nabla \phi_i, \nabla \phi_j \rangle_{\mathrm{L}^2(\Omega)}
& -c\omega \langle \phi_i,\psi_j\rangle_{\mathrm{L}^2(\Gamma_2)} \\
c\omega \langle \psi_i,\phi_j\rangle_{\mathrm{L}^2(\Gamma_2)}
& -\omega^2 \langle \psi_{i}, \psi_j \rangle_{\mathrm{L}^2(\Omega)}
+ c^2 \langle \nabla \psi_{i}, \nabla \psi_j  \rangle_{\mathrm{L}^2(\Omega)}
\end{array}
\right)
\left(
\begin{array}{c}
\alpha \\ \beta
\end{array}
\right)
=
\left(
\begin{array}{c}
0 \\ 0
\end{array}
\right)


@f]

(不要被这里的右手边为零所迷惑，那是因为我们还没有包括Dirichlet边界数据)。由于非对角线区块的交替符号，我们已经可以看到这个系统是非对称的，事实上它甚至是不确定的。当然，没有必要选择空间 $V_h$ 和 $W_h$ 是相同的。然而，我们期望解的实部和虚部具有类似的性质，因此在实现中确实会采取 $V_h=W_h$ ，并且也会对两个空间使用相同的基函数 $\phi_i = \psi_i$ 。使用不同符号的原因只是让我们能够区分 $v$ 和 $w$ 的形状函数，因为这种区分在实施中起着重要作用。




<h3>The test case</h3>

在计算中，我们将考虑波在单位方阵中的传播，超声由换能器透镜产生，透镜的形状是圆的一段，中心在 $(0.5, d)$ ，半径略大于 $d$ ；这种形状应该导致声波在圆中心的聚焦。改变 $d$ 会改变透镜的 "焦点"，并影响 $u$ 强度的空间分布，我们主要关注的是 $|u|=\sqrt{v^2+w^2}$ 的聚焦效果如何。

在下面的程序中，我们将使用实部和虚部分裂的公式来实现复值亥姆霍兹方程。我们还将讨论如何生成一个看起来像正方形并带有轻微隆起的模拟换能器的域（在 <code>UltrasoundProblem<dim>::make_grid()</code> 函数中），以及如何生成不仅包含解分量 $v$ 和 $w$ ，而且直接在输出文件中包含幅值 $\sqrt{v^2+w^2}$ 的图形输出（在 <code>UltrasoundProblem<dim>::output_results()</code> ）。最后，我们使用ParameterHandler类来轻松读取参数，如焦距 $d$ 、波速 $c$ 、频率 $\omega$ ，以及在运行时从输入文件中读取其他一些参数，而不是在源代码中固定这些参数，因为每次我们想改变参数时，都必须重新编译。


examples/step-29/doc/results.dox

<a name="Results"></a>

<h1>Results</h1>

当前程序从一个名为 <code>\step-29.prm</code> 的输入文件中读取其运行时参数，该文件看起来像这样。

@code
subsection Mesh & geometry parameters
  # Distance of the focal point of the lens to the x-axis
  set Focal distance        = 0.3


  # Number of global mesh refinement steps applied to initial coarse grid
  set Number of refinements = 5
end



subsection Physical constants
  # Wave speed
  set c     = 1.5e5


  # Frequency
  set omega = 3.0e7
end



subsection Output parameters
  # Name of the output file (without extension)
  set Output file   = solution


  # A name for the output format to be used
  set Output format = vtu
end
@endcode



可以看出，我们设置了 $d=0.3$  ，相当于换能器镜头的焦点在 $x=0.5$  ， $y=0.3$  。粗略的网格被细化了5次，结果是160x160个单元，输出结果以vtu格式写入。参数读取器可以理解更多的参数，特别是与输出的生成有关的参数，但是我们在这里不需要这些参数，因此坚持使用其默认值。

这是调试模式下程序的控制台输出。

@code
> make run
[ 66%] Built target step-29
[100%] Run step-29 with Debug configuration
Generating grid... done (0.820449s)
  Number of active cells:  25600
Setting up system... done (1.18392s)
  Number of degrees of freedom: 51842
Assembling system matrix... done (2.33291s)
Solving linear system... done (1.34837s)
Generating output... done (2.05782s)
[100%] Built target run
@endcode



(当然，如果你在本地运行该程序，执行时间会有所不同。)事实上，大部分时间花在组装系统矩阵和生成输出上是由于在调试模式下需要检查许多断言。在发布模式下，程序的这些部分运行得更快，而求解线性系统的速度几乎没有加快。

@code
> make run
[ 66%] Built target step-29
Scanning dependencies of target run
[100%] Run step-29 with Release configuration
DEAL::Generating grid... done (0.0144960s)
DEAL::  Number of active cells:  25600
DEAL::Setting up system... done (0.0356880s)
DEAL::  Number of degrees of freedom: 51842
DEAL::Assembling system matrix... done (0.0436570s)
DEAL::Solving linear system... done (1.54733s)
DEAL::Generating output... done (0.720528s)
[100%] Built target run
@endcode



程序的图形输出看起来如下。


 <table align="center" class="doxtable">
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-29.v.png" alt="v = Re(u)">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-29.w.png" alt="w = Im(u)">
    </td>
  </tr>
  <tr>
    <td colspan="2">
      <img src="https://www.dealii.org/images/steps/developer/step-29.intensity.png" alt="|u|">
    </td>
  </tr>
</table> 

前两张图片显示了 $u$ 的实部和虚部，而最后一张显示了强度 $|u|$ 。我们可以清楚地看到，强度集中在镜头的焦点周围（0.5，0.3），焦点在 $x$ -方向上相当尖锐，但在 $y$ -方向上更加模糊，这是聚焦镜头的几何形状、其有限孔径和问题的波性的结果。

因为五颜六色的图形总是很有趣，而且为了进一步强调聚焦效果，这里还有一组图片，强调了强度在 $x$ -方向上的实际聚焦效果。

 <table align="center" class="doxtable">
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-29.surface.png" alt="|u|">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-29.contours.png" alt="|u|">
    </td>
  </tr>
</table> 


最后，程序的结构使我们很容易确定程序的哪些部分可以随着网格的细化而很好地扩展，哪些部分不可以。下面是5、6、7次全局细化的运行时间。

@code
> make run
[ 66%] Built target step-29
[100%] Run step-29 with Release configuration
DEAL::Generating grid... done (0.0135260s)
DEAL::  Number of active cells:  25600
DEAL::Setting up system... done (0.0213910s)
DEAL::  Number of degrees of freedom: 51842
DEAL::Assembling system matrix... done (0.0414300s)
DEAL::Solving linear system... done (1.56621s)
DEAL::Generating output... done (0.729605s)
[100%] Built target run


> make run
[ 66%] Built target step-29
[100%] Run step-29 with Release configuration
DEAL::Generating grid... done (0.0668490s)
DEAL::  Number of active cells:  102400
DEAL::Setting up system... done (0.109694s)
DEAL::  Number of degrees of freedom: 206082
DEAL::Assembling system matrix... done (0.160784s)
DEAL::Solving linear system... done (7.86577s)
DEAL::Generating output... done (2.89320s)
[100%] Built target run


> make run
[ 66%] Built target step-29
[100%] Run step-29 with Release configuration
DEAL::Generating grid... done (0.293154s)
DEAL::  Number of active cells:  409600
DEAL::Setting up system... done (0.491301s)
DEAL::  Number of degrees of freedom: 821762
DEAL::Assembling system matrix... done (0.605386s)
DEAL::Solving linear system... done (45.1989s)
DEAL::Generating output... done (11.2292s)
[100%] Built target run
@endcode



每次我们细化一次网格，所以每一步的单元和自由度的数量大约是四倍。可以看出，生成网格、设置自由度、组装线性系统和生成输出的规模相当接近于线性，而求解线性系统的操作，自由度的数量每增加4倍，就需要8倍的时间，也就是说，它是 ${\cal O}(N^{3/2})$  。这可以解释为（使用最优排序）有限元矩阵的带宽是  $B={\cal O}(N^{(dim-1)/dim})$  ，而使用LU分解解决带状线性系统的努力是  ${\cal O}(BN)$  。这也解释了为什么该程序也能在3D中运行（在改变了 <code>UltrasoundProblem</code> 对象的维度后），但其扩展性很差，需要非常耐心才能完成对具有明显分辨率的网格上的线性系统的求解，尽管该程序的其他部分的扩展性非常好。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

这个程序的一个明显的可能的扩展是在3D中运行它&mdash；毕竟，我们周围的世界是三维的，而超声束在三维介质中传播。你可以通过简单地改变 <code>main()</code> 中主类的模板参数并运行它来尝试。但这不会让你走得很远：当然，如果你按照参数文件中的设置做5个全局细化步骤，就更不会了。你的内存会耗尽，因为网格（含 $(2^5)^3 \cdot 5^3=2^{15}\cdot 125 \approx 4\cdot 10^6$ 单元），特别是稀疏直接求解器会占用太多的内存。然而，如果你有时间的话，你可以用3个全局细化步骤来求解：在2011年初，直接求解大约需要半个小时。然而，你会注意到，这个解是完全错误的：网格大小根本不够小，不能准确地解决解的波浪，你可以在解的图中看到这一点。因此，在这种情况下，如果你不想在这个问题上扔一个更大的（估计是%并行的）机器，那么自适应性是必不可少的。


examples/step-3/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{10} 

<h3>The basic set up of finite element methods</h3>

这是第一个我们实际使用有限元来计算的例子。我们将解决一个简单的泊松方程，其边界值为零，但右手边非零。

@f{align*}


  -\Delta u &= f \qquad\qquad & \text{in}\ \Omega,
  \\
  u &= 0 \qquad\qquad & \text{on}\ \partial\Omega.


@f}

我们将在正方形 $\Omega=[-1,1]^2$ 上求解这个方程，你已经在步骤1和步骤2中学习了如何生成网格。在这个程序中，我们也将只考虑 $f(\mathbf x)=1$ 这个特殊情况，并在下一个教程程序中再来讨论如何实现更一般的情况，即步骤4。

如果你学过有限元方法的基本知识，你会记得我们需要采取的步骤，用有限维度的近似方法来近似解 $u$ 。具体来说，我们首先需要推导出上述方程的弱形式，通过将方程乘以测试函数 $\varphi$ <i>from the left</i>（我们将在下面回到从左而非从右相乘的原因）并在域 $\Omega$ 上积分得到。

@f{align*}


  -\int_\Omega \varphi \Delta u = \int_\Omega \varphi f.


@f}

这可以通过部件进行整合。

@f{align*}
  \int_\Omega \nabla\varphi \cdot \nabla u


  -
  \int_{\partial\Omega} \varphi \mathbf{n}\cdot \nabla u
   = \int_\Omega \varphi f.


@f}

测试函数 $\varphi$ 必须满足同样的边界条件（用数学术语来说：它需要来自我们寻求解决方案的集合的切线空间），因此在边界上 $\varphi=0$ ，因此我们正在寻找的弱形式为

@f{align*}
  (\nabla\varphi, \nabla u)
   = (\varphi, f),


@f}

其中我们使用了常用的符号  $(a,b)=\int_\Omega a\; b$  。然后，问题要求从适当的空间（这里是空间 $H^1$ ）中找出一个函数 $u$ ，对于该函数，这一声明对于所有测试函数 $\varphi$ 都是真的。

当然，在一般情况下，我们无法在计算机上找到这样的函数，而是寻求一个近似值 $u_h(\mathbf x)=\sum_j U_j \varphi_j(\mathbf
x)$  ，其中 $U_j$ 是我们需要确定的未知膨胀系数（这个问题的 "自由度"）， $\varphi_i(\mathbf x)$ 是我们将使用的有限元形状函数。为了定义这些形状函数，我们需要以下内容。

- 一个用来定义形状函数的网格。你已经看到如何在步骤1和步骤2中生成和操作描述网格的对象。

- 一个描述我们想在参考单元上使用的形状函数的有限元（在deal.II中总是单位间隔 $[0,1]$ 、单位正方形 $[0,1]^2$ 或单位立方体 $[0,1]^3$ ，取决于你在哪个空间维度工作）。在步骤2中，我们已经使用了FE_Q<2>类型的对象，它表示通常的拉格朗日元素，通过对支持点的插值来定义形状函数。最简单的是FE_Q<2>(1)，它使用1度的多项式。在2D中，这些通常被称为<i>bilinear</i>，因为它们在参考单元的两个坐标中都是线性的。(在1d中，它们是<i>linear</i>，在3d中是<i>tri-linear</i>；然而，在deal.II文档中，我们经常不做这种区分，而总是简单地称这些函数为 "线性"。)

- 一个DoFHandler对象，以有限元对象提供的参考单元描述为基础，枚举网格上的所有自由度。你也已经在步骤2中看到了如何做到这一点。

- 一个映射，告诉你如何从参考单元上的有限元类定义的形状函数中获得实数单元上的形状函数。默认情况下，除非你明确说明，否则deal.II将使用（双，三）线性映射，所以在大多数情况下，你不必担心这个步骤。

通过这些步骤，我们现在有一组函数 $\varphi_i$ ，我们可以定义离散问题的弱形式：找到一个函数 $u_h$ ，即找到上面提到的扩展系数 $U_j$ ，以便

@f{align*}
  (\nabla\varphi_i, \nabla u_h)
   = (\varphi_i, f),
   \qquad\qquad
   i=0\ldots N-1.


@f}

请注意，我们在此遵循惯例，即一切从零开始计算，这在C和C++中很常见。如果你插入表示法 $u_h(\mathbf x)=\sum_j U_j
\varphi_j(\mathbf x)$ ，这个方程可以重写为一个线性系统，然后观察到

@f{align*}{
  (\nabla\varphi_i, \nabla u_h)
  &= \left(\nabla\varphi_i, \nabla \Bigl[\sum_j U_j \varphi_j\Bigr]\right)
\\
  &= \sum_j \left(\nabla\varphi_i, \nabla \left[U_j \varphi_j\right]\right)
\\
  &= \sum_j \left(\nabla\varphi_i, \nabla \varphi_j \right) U_j.


@f}

有了这个，问题就成了。找到一个向量 $U$ ，以便

@f{align*}{
  A U = F,


@f}

其中矩阵 $A$ 和右手边 $F$ 定义为

@f{align*}
  A_{ij} &= (\nabla\varphi_i, \nabla \varphi_j),
  \\
  F_i &= (\varphi_i, f).


@f}






<h3> Should we multiply by a test function from the left or from the right? </h3>

在我们继续描述如何计算这些数量之前，请注意，如果我们从<i>right</i>乘以一个测试函数而不是从左边乘以原方程，那么我们将得到一个形式为的线性系统

@f{align*}
  U^T A = F^T


@f}

有一个行向量  $F^T$  。通过转置这个系统，这当然等同于解决了

@f{align*}
  A^T U = F


@f}

这里与上面的 $A=A^T$ 相同。但一般来说不是，为了避免任何形式的混淆，经验表明，只要养成从左边而不是从右边乘方程的习惯（正如数学文献中经常做的那样），就可以避免一类常见的错误，因为在比较理论和实现时，矩阵会自动正确，不需要转置。本教程的第一个例子见第9步，我们有一个非对称的双线性方程，对于这个方程，我们从右面还是从左面相乘是有区别的。




<h3> Computing the matrix and right hand side vector </h3>

现在我们知道我们需要什么（即：持有矩阵和向量的对象，以及计算 $A_{ij},F_i$ 的方法），我们可以看看需要什么来实现这一点。

-  $A$ 的对象是SparseMatrix类型，而 $U$ 和 $F$ 的对象则是Vector类型。我们将在下面的程序中看到哪些类是用来解决线性系统的。

- 我们需要一种方法来形成积分。在有限元方法中，最常见的是使用正交法，也就是说，积分被每个单元上的一组点的加权和所取代。也就是说，我们首先将 $\Omega$ 的积分分成所有单元的积分，@f{align*}
    A_{ij} &= (\nabla\varphi_i, \nabla \varphi_j)
    = \sum_{K \in {\mathbb T}} \int_K \nabla\varphi_i \cdot \nabla \varphi_j,
    \\
    F_i &= (\varphi_i, f)
    = \sum_{K \in {\mathbb T}} \int_K \varphi_i f,
  @f}

  然后用正交法对每个单元的贡献进行近似。   @f{align*}
    A^K_{ij} &=
    \int_K \nabla\varphi_i \cdot \nabla \varphi_j
    \approx
    \sum_q \nabla\varphi_i(\mathbf x^K_q) \cdot \nabla
    \varphi_j(\mathbf x^K_q) w_q^K,
    \\
    F^K_i &=
    \int_K \varphi_i f
    \approx
    \sum_q \varphi_i(\mathbf x^K_q) f(\mathbf x^K_q) w^K_q,
  @f}

  其中 $\mathbf x^K_q$ 是 $q$ 单元上的第三个正交点 $K$ ， $w^K_q$ 是 $q$ 的正交权。这样做需要有不同的部分，接下来我们将依次讨论它们。

- 首先，我们需要一种方法来描述正交点的位置  $\mathbf x_q^K$  和它们的权重  $w^K_q$  。它们通常以与形状函数相同的方式从参考单元映射出来，即隐含地使用MappingQ1类，或者，如果你明确地说，通过从Mapping派生的其他类之一。参考单元上的位置和权重由派生自正交基类的对象来描述。通常，人们选择一个正交公式（即一组点和权重），使正交正好等于矩阵中的积分；这可以实现，因为积分中的所有因子都是多项式，由高斯正交公式完成，在QGauss类中实现。

- 然后我们需要一些东西来帮助我们在 $K$ 单元上评估 $\varphi_i(\mathbf x^K_q)$ 。这就是FEValues类的作用：它需要一个有限元对象来描述参考单元上的 $\varphi$ ，一个正交对象来描述正交点和权重，以及一个映射对象（或隐含地采用MappingQ1类），并在位于 $K$ 的正交点上提供形状函数的值和导数，以及积分所需的各种其他信息。

FEValues确实是装配过程中的核心类。你可以这样看待它。FiniteElement和派生类描述了形状<i>functions</i>，即无限维度的对象：函数在每一点都有值。由于理论上的原因，我们需要这样做，因为我们想用函数的积分来进行分析。然而，对于计算机来说，这是一个非常困难的概念，因为它们一般只能处理有限的信息量，所以我们用正交点上的和来代替积分，我们通过使用定义在参考单元（正交对象）上的点映射（映射对象）到真实单元上的点来获得。实质上，我们将问题简化为我们只需要有限的信息，即形状函数值和导数、正交权重、法向量等，只需要在有限的点集合上。FEValues类就是将这三个部分结合在一起，并在一个特定的单元上提供这个有限的信息集  $K$  。当我们组装下面的线性系统时，你会看到它的作用。

值得注意的是，如果你只是在应用程序中自己创建这三个对象，并自己处理这些信息，那么所有这些也都可以实现。然而，这样做既不简单（FEValues类提供的正是你实际需要的信息），也不快：FEValues类经过高度优化，只在每个单元中计算你需要的特定信息；如果有任何东西可以从上一个单元中重复使用，那么它就会这样做，而且该类中有很多代码可以确保在有利的地方进行缓存。

这个介绍的最后一块是要提到，在得到一个线性系统后，要用迭代求解器进行求解，然后进行后处理：我们用DataOut类创建一个输出文件，然后可以用一个常见的可视化程序进行可视化。

 @note  前面对任何有限元实现的所有重要步骤的概述，在deal.II中也有对应的内容：该库可以自然地归纳为若干 "模块"，涵盖刚才概述的基本概念。你可以通过本页面顶部的标签访问这些模块。在<a href="index.html">front page of the deal.II manual</a>上也有对最基本的概念组的概述。




<h3>About the implementation</h3>

虽然这是你能用有限元方法解决的最简单的方程，但这个程序显示了大多数有限元程序的基本结构，也是几乎所有下面的程序基本上都会遵循的模板。具体来说，这个程序的主类看起来像这样。

@code
class Step3
{
  public:
    Step3 ();
    void run ();


  private:
    void make_grid ();
    void setup_system ();
    void assemble_system ();
    void solve ();
    void output_results () const;


    Triangulation<2>     triangulation;
    FE_Q<2>              fe;
    DoFHandler<2>        dof_handler;


    SparsityPattern      sparsity_pattern;
    SparseMatrix<double> system_matrix;
    Vector<double>       solution;
    Vector<double>       system_rhs;
};
@endcode



这遵循了<a
href="http://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming)">data
encapsulation</a>的面向对象编程口号，也就是说，我们尽力将这个类的几乎所有内部细节隐藏在外部无法访问的私有成员中。

让我们从成员变量开始。这些遵循我们在上面的要点中所概述的构建模块，即我们需要一个三角形和一个DoFHandler对象，以及一个描述我们想要使用的各种形状函数的有限元对象。第二组对象与线性代数有关：系统矩阵和右手边以及解向量，还有一个描述矩阵稀疏模式的对象。这就是这个类所需要的全部内容（也是任何静止PDE的求解器所需要的基本内容），并且需要在整个程序中存活。与此相反，我们在装配时需要的FEValues对象只在整个装配过程中需要，因此我们在进行装配的函数中把它作为一个局部对象来创建，并在结束时再次销毁它。

其次，让我们来看看成员函数。这些，也已经构成了几乎所有下面的教程程序都会使用的共同结构。   <ul>   <li>   <code>make_grid()</code>  : 这就是人们所说的<i>preprocessing function</i>。顾名思义，它设置了存储三角图的对象。在以后的例子中，它还可以处理边界条件、几何形状等。     <li>   <code>setup_system()</code>  : 这是一个函数，其中设置了解决问题所需的所有其他数据结构。特别是，它将初始化DoFHandler对象并正确确定与线性代数有关的各种对象的大小。这个函数通常与上面的预处理函数分开，因为在一个与时间相关的程序中，每当网格被自适应细化时（我们将在步骤6中看到如何做），它可能至少每隔几个时间步就会被调用。另一方面，在上面的预处理函数中，设置网格本身只在程序开始时进行一次，因此，它被分离成自己的函数。     <li>   <code>assemble_system()</code>  : 这就是计算矩阵和右手边的内容的地方，在上面的介绍中已经详细讨论过。由于对这个线性系统进行处理在概念上与计算其条目有很大不同，我们将其与以下函数分开。     <li>   <code>solve()</code>  : 这就是我们计算线性系统 $U$ 的解的函数。在当前的程序中，这是一个简单的任务，因为矩阵是如此简单，但只要问题不再那么微不足道，它就会成为程序规模的重要部分（例如，一旦你对库有了更多的了解，请参阅步骤20，步骤22，或步骤31）。     <li>   <code>output_results()</code>  : 最后，当你计算出一个解决方案后，你可能想用它做一些事情。例如，你可能想以可视化的格式输出它，或者你可能想计算你感兴趣的量：例如，热交换器中的热通量、机翼的空气摩擦系数、最大桥梁载荷，或者仅仅是某一点上的数值解的值。因此，这个函数是对你的解进行后处理的地方。   </ul> 所有这些都是由单一的公共函数（除构造函数外），即 <code>run()</code> 函数来支撑的。它是在创建这种类型的对象的地方被调用的，它是按正确顺序调用所有其他函数的函数。把这个操作封装到 <code>run()</code> 函数中，而不是从 <code>main()</code> 中调用所有其他函数，确保你可以改变这个类中的关注点分离的实现方式。例如，如果其中一个函数变得太大了，你可以把它分成两个，而你唯一需要关注的地方就是这个类中的变化，而不是其他地方。

如上所述，你会看到这种一般的结构&mdash；有时在函数名称的拼写上会有一些变化，但基本上是按照这种功能分离的顺序&mdash；在下面的许多教程程序中也是如此。




<h3> A note on types </h3>

deal.II通过命名空间 dealii::types. 中的别名定义了一些积分%类型（在前一句中，"积分 "一词被用作与名词 "整数 "相对应的<i>adjective</i>。它不应该与表示曲线或曲面下的面积或体积的<i>noun</i>"积分 "混淆起来。形容词 "积分 "在C++世界中被广泛使用，如 "积分类型"、"积分常数 "等。）特别是，在这个程序中，你会在几个地方看到 types::global_dof_index ：一个整数类型，用来表示自由度的<i>global</i>索引，即在定义在三角形之上的DoFHandler对象中特定自由度的索引（而不是特定单元中的特定自由度的索引）。对于当前的程序（以及几乎所有的教程程序），你将有几千个到几百万个全局未知数（而且，对于 $Q_1$ 元素，你将有4个<i>locally on each cell</i>的2D和8个3D）。因此，允许为全局DoF指数存储足够大的数字的数据类型是 <code>unsigned int</code> ，因为它允许存储0到略高于40亿的数字（在大多数系统中，整数是32位的）。事实上，这就是 types::global_dof_index 的作用。

那么，为什么不马上使用 <code>unsigned int</code> 呢？deal.II在7.3版本之前一直是这样做的。然而，deal.II支持非常大的计算（通过步骤40中讨论的框架），当分布在几千个处理器上时，可能有超过40亿个未知数。因此，有些情况下 <code>unsigned int</code> 不够大，我们需要一个64位的无符号积分类型。为了实现这一点，我们引入了 types::global_dof_index ，它默认被定义为<code>unsigned int</code>，而如果有必要，可以通过在配置过程中传递一个特定的标志，将其定义为<code>unsigned long long int</code>（见ReadMe文件）。

这涵盖了技术方面。但是还有一个文档的目的：在图书馆和建立在它之上的代码中，如果你看到一个地方使用数据类型 types::global_dof_index, ，你就会立即知道被引用的数量实际上是一个全局dof指数。如果我们只是使用 <code>unsigned int</code> （它也可能是一个局部索引，一个边界指示器，一个材料ID，等等），就不会有这样的意义了。立即知道一个变量指的是什么也有助于避免错误：如果你看到一个 types::global_dof_index 类型的对象被分配给 types::subdomain_id, 类型的变量，这很明显一定有一个错误，尽管它们都是用无符号整数表示，因此编译器不会抱怨。

在更实际的情况下，这种类型的存在意味着在装配过程中，我们创建一个 $4\times 4$ 矩阵（在2d中，使用 $Q_1$ 元素）来表示我们当前所在单元的贡献，然后我们需要将这个矩阵的元素添加到全局（系统）矩阵的相应元素中。为此，我们需要获得当前单元的局部自由度的全局指数，为此我们将始终使用下面这段代码。

@code
  cell->get_dof_indices (local_dof_indices);
@endcode

其中 <code>local_dof_indices</code> 被声明为

@code
  std::vector<types::global_dof_index> local_dof_indices (fe.n_dofs_per_cell());
@endcode

这个变量的名字可能有点名不副实--它代表 "在当前单元上局部定义的那些自由度的全局指数"--但持有这种信息的变量在整个库中普遍是这样命名的。

 @note   types::global_dof_index  并不是这个命名空间中定义的唯一类型。相反，有一整个系列，包括 types::subdomain_id,  types::boundary_id, 和 types::material_id. 所有这些都是整数数据类型的别名，但正如上面所解释的，它们被用于整个库，以便（i）变量的意图变得更容易辨别，以及（ii）如果有必要，可以将实际类型改为一个更大的类型，而不必翻阅整个库，找出 <code>unsigned int</code> 的特定使用是否对应于，例如，一个材料指标。


examples/step-3/doc/results.dox



<h1>Results</h1>

程序的输出看起来如下。

@code
Number of active cells: 1024
Number of degrees of freedom: 1089
DEAL:cg::Starting value 0.121094
DEAL:cg::Convergence step 48 value 5.33692e-13
@endcode



前两行是我们写给  <code>cout</code>  的内容。最后两行是CG求解器在没有我们的干预下生成的。前两行说明了迭代开始时的残差，而最后一行告诉我们求解器需要47次迭代才能使残差的规范值达到5.3e-13，即低于我们在 "solve "函数中设置的阈值1e-12。我们将在下一个程序中展示如何抑制这种输出，这种输出有时对调试很有用，但往往会使屏幕显示变得混乱。

除了上面显示的输出，该程序还生成了文件 <code>solution.vtk</code> ，该文件为VTK格式，被当今许多可视化程序广泛使用--包括两个重量级的<a href="https://www.llnl.gov/visit">VisIt</a>和<a href="https://www.paraview.org">Paraview</a>，是当今最常使用的程序。

使用VisIt，生成一张像这样的解决方案的图片并不是很困难。   <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-3.solution-3.png" alt="Visualization of the solution of step-3">
    </td>
  </tr>
</table>  它同时显示了解和网格，根据每一点的解的值提升到 $x$  -  $y$ 平面之上。当然，这里的解并不特别令人兴奋，但这是拉普拉斯方程所代表的内容和我们为这个程序选择的右手边 $f(\mathbf x)=1$ 的结果。拉普拉斯方程描述了（在许多其他用途中）受外部（也是垂直）力作用的膜的垂直变形。在目前的例子中，膜的边界被夹在一个没有垂直变化的方形框架上；因此，一个恒定的力密度将直观地导致膜简单地向上隆起--就像上图所示。

VisIt和Paraview都允许玩各种可视化的解决方案。几个视频讲座展示了如何使用这些程序。   @dealiiVideoLectureSeeAlso{11,32} 




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

如果你想用这个程序玩一玩，这里有几个建议。   </p> 

 <ul>   <li>  改变几何图形和网格。在程序中，我们通过使用 <code>GridGenerator::hyper_cube</code> 函数生成了一个方形域和网格。然而， <code>GridGenerator</code> 也有大量的其他函数。试试L形域，环形域，或其他你在那里找到的域。     </li> 

    <li>  改变边界条件。代码使用 Functions::ZeroFunction 函数来生成零边界条件。然而，你可能想用 <code>ConstantFunction&lt;2&gt;(1)</code> 而不是 <code>ZeroFunction&lt;2&gt;()</code> 尝试非零常数边界值，以获得单位Dirichlet边界值。在函数命名空间的文档中描述了更多的奇异函数，你可以选择一个来描述你的特定边界值。     </li> 

    <li>  修改边界条件的类型。目前，发生的情况是，我们在周围使用迪里希特边界值，因为默认情况是所有边界部分的边界指标为零，然后我们告诉 VectorTools::interpolate_boundary_values() 函数，在所有指标为零的边界部分上将边界值插值为零。    <p>  如果我们给边界的部分分配不同的指标，我们可以改变这种行为。例如，在调用 GridGenerator::hyper_cube(): @code
  triangulation.begin_active()->face(0)->set_boundary_id(1);
  @endcode后立即尝试这样做。



  这样做的目的是，首先要求三角剖分返回一个迭代器，指向第一个活动单元。当然，由于这是一个正方形的三角测量的粗略网格，此刻三角测量只有一个单元，而且它是活动的。接下来，我们要求单元格返回它的第一个面的迭代器，然后我们要求面将该面的边界指标重置为1。接下来的事情就是这样。当网格被细化时，子单元的面会继承其父母的边界指示器，也就是说，即使在最细的网格上，广场一侧的面的边界指示器为1。稍后，当我们要插值边界条件时， VectorTools::interpolate_boundary_values() 调用将只为那些边界指标为零的面产生边界值，而对那些具有不同边界指标的面则不予理会。这样做的目的是对前者施加Dirichlet边界条件，而对后者施加同质的Neumann条件（即解的法向导数为零，除非在变分等式的右侧添加额外的条款来处理潜在的非零Neumann条件）。如果你运行该程序，你会看到这一点。

  另一种改变边界指标的方法是根据面中心的笛卡尔坐标来标注边界。   例如，我们可以通过检查单元格中心的y坐标是否在-1和1的公差（这里是1e-12）范围内，将沿上下边界的所有单元格标记为边界指示器1。在调用 GridGenerator::hyper_cube(), 后，像以前一样立即尝试这样做。   @code
  for (auto &face : triangulation.active_face_iterators())
    if (std::fabs(face->center()(1) - (-1.0)) < 1e-12 ||
        std::fabs(face->center()(1) - (1.0)) < 1e-12)
      face->set_boundary_id(1);
  @endcode

  虽然这段代码比以前长了一些，但它对复杂的几何形状很有用，因为它不需要脸部标签的知识。

    <li> 最后一点的一个小变化是像上面那样设置不同的边界值，但随后为边界指标一使用不同的边界值函数。在实践中，你要做的是为边界指标一增加对 <code>interpolate_boundary_values</code> 的第二次调用。   @code
  VectorTools::interpolate_boundary_values(dof_handler,
					   1,
					   ConstantFunction<2>(1.),
					   boundary_values);
  @endcode

  如果你在这个函数的第一个调用之后立即进行这个调用，那么它将把边界指标为1的面的边界值内插到单位值，并将这些内插值与之前计算的边界指标为0的值合并。

    <li>  观察收敛情况。我们将只讨论第7步中规范的计算误差，但很容易检查计算在这里已经收敛了。例如，我们可以在一个点上评估解的值，并比较不同%的全局细化的值（全局细化的步骤数在上面的 <code>LaplaceProblem::make_grid</code> 中设定）。为了评估某个点的解决方案，例如在 $(\frac 13, \frac 13)$ ，我们可以在 <code>LaplaceProblem::output_results</code> 函数中加入以下代码。   @code
    std::cout << "Solution at (1/3,1/3): "
              << VectorTools::point_value(dof_handler, solution,
                                          Point<2>(1./3, 1./3))
              << std::endl;
  @endcode

  对于1到9个全局细化步骤，我们就会得到以下的点值序列。     <table align="center" class="doxtable">
    <tr> <th># of refinements</th> <th>$u_h(\frac 13,\frac13)$</th> </tr>
    <tr> <td>1</td> <td>0.166667</td> </tr>
    <tr> <td>2</td> <td>0.227381</td> </tr>
    <tr> <td>3</td> <td>0.237375</td> </tr>
    <tr> <td>4</td> <td>0.240435</td> </tr>
    <tr> <td>5</td> <td>0.241140</td> </tr>
    <tr> <td>6</td> <td>0.241324</td> </tr>
    <tr> <td>7</td> <td>0.241369</td> </tr>
    <tr> <td>8</td> <td>0.241380</td> </tr>
    <tr> <td>9</td> <td>0.241383</td> </tr>
  </table>  通过注意到每两个连续值之间的差异减少了大约4倍，我们可以猜测 "正确 "的值可能是 $u(\frac 13, \frac 13)\approx 0.241384$  。事实上，如果我们假设这是正确的值，我们可以证明上面的序列确实显示了 ${\cal
  O}(h^2)$ 的收敛&mdash；理论上，收敛顺序应该是 ${\cal O}(h^2 |\log h|)$ ，但是领域和网格的对称性可能导致了观察到的更好的收敛顺序。

  这方面的一个小变种是用二次元重复测试。你需要做的就是在构造函数中把有限元的多项式程度设置为2  <code>LaplaceProblem::LaplaceProblem</code>  。

    <li>  平均值的收敛。一个不同的方法是计算解的平均数，以了解解是否真的收敛了（收敛到什么程度&mdash；我们无法判断它是否真的是正确的值！）。为此，在 <code>LaplaceProblem::output_results</code> 中添加以下代码：@code
    std::cout << "Mean value: "
              << VectorTools::compute_mean_value (dof_handler,
						  QGauss<2>(fe.degree + 1),
						  solution,
						  0)
              << std::endl;
  @endcode

  该函数的文档解释了第二和第四个参数的含义，而第一和第三个参数应该是很明显的。再次做同样的研究，我们改变了全局细化步骤的数量，我们得到以下结果。     <table align="center" class="doxtable">
    <tr> <th># of refinements</th> <th>$\int_\Omega u_h(x)\; dx$</th> </tr>
    <tr> <td>0</td> <td>0.09375000</td> </tr>
    <tr> <td>1</td> <td>0.12790179</td> </tr>
    <tr> <td>2</td> <td>0.13733440</td> </tr>
    <tr> <td>3</td> <td>0.13976069</td> </tr>
    <tr> <td>4</td> <td>0.14037251</td> </tr>
    <tr> <td>5</td> <td>0.14052586</td> </tr>
    <tr> <td>6</td> <td>0.14056422</td> </tr>
    <tr> <td>7</td> <td>0.14057382</td> </tr>
    <tr> <td>8</td> <td>0.14057622</td> </tr>
  </table>  同样，两个相邻值之间的差异下降了约四倍，表明收敛为  ${\cal O}(h^2)$  。   </ul> 




<h3>Using %HDF5 to output the solution and additional data</h3>

%HDF5是一种常用的格式，可以被许多脚本语言（如R或Python）读取。让deal.II产生一些%HDF5文件并不困难，然后可以在外部脚本中使用，对该程序产生的一些数据进行后处理。这里有一些关于可能的想法。




<h4> Changing the output to .h5</h4>

为了充分利用自动化，我们首先需要为全局细化步骤的数量引入一个私有变量 <code>unsigned int n_refinement_steps </code> ，它将被用于输出文件名。在 <code>make_grid()</code> we then replace <code>triangulation.refine_global(5);</code> 中用

@code
n_refinement_steps = 5;
triangulation.refine_global(n_refinement_steps);
@endcode

deal.II库有两个不同的%HDF5绑定，一个在HDF5命名空间（用于对接通用数据文件），另一个在DataOut（专门用于为解决方案的可视化写文件）。尽管HDF5 deal.II绑定支持串行和MPI，但%HDF5 DataOut绑定只支持并行输出。由于这个原因，我们需要初始化一个只有一个处理器的MPI通信器。这可以通过添加以下代码来实现。

@code
int main(int argc, char* argv[])
{
  Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);
  ...
}
@endcode

接下来我们改变 `Step3::output_results()` 的输出例程，如DataOutBase命名空间文档中所述。

@code
const std::string filename_h5 = "solution_" + std::to_string(n_refinement_steps) + ".h5";
DataOutBase::DataOutFilterFlags flags(true, true);
DataOutBase::DataOutFilter data_filter(flags);
data_out.write_filtered_data(data_filter);
data_out.write_hdf5_parallel(data_filter, filename_h5, MPI_COMM_WORLD);
@endcode

然后，产生的文件可以被可视化，就像教程的原始版本产生的VTK文件一样；但是，由于%HDF5是一种更通用的文件格式，它也可以很容易地用脚本语言处理，用于其他目的。




<h4> Adding the point value and the mean (see extension above) into the .h5 file</h4>

在输出解决方案后，可以再次打开该文件以包括更多的数据集。  这使得我们可以将实验的所有必要信息保存在一个结果文件中，然后可以由一些后处理脚本来读取和处理。关于可能的输出选项，请看 HDF5::Group::write_dataset() 的进一步信息）。

为了实现这一点，我们首先将必要的头文件纳入我们的文件。

@code
#include <deal.II/base/hdf5.h>
@endcode

在我们的输出例程的末尾添加以下几行，将关于某一点的解的值，以及解的平均值的信息添加到我们的%HDF5文件中。

@code
HDF5::File data_file(filename_h5, HDF5::File::FileAccessMode::open, MPI_COMM_WORLD);
Vector<double> point_value(1);
point_value[0] = VectorTools::point_value(dof_handler, solution,
                                          Point<2>(1./3, 1./3));
data_file.write_dataset("point_value", point_value);
Vector<double> mean_value(1);
mean_value[0] = VectorTools::compute_mean_value(dof_handler,
                                                QGauss<2>(fe.degree + 1),
                                                solution, 0);
data_file.write_dataset("mean_value",mean_value);
@endcode






<h3> Using R and ggplot2 to generate plots</h3>

上述放入%HDF5文件的数据，然后可以从脚本语言中使用，进行进一步的后处理。在下文中，让我们展示一下，特别是如何用<a href="https://en.wikipedia.org/wiki/R_(programming_language)">R
programming language</a>这个在统计数据分析中广泛使用的语言来完成。(例如，类似的事情也可以在Python中完成。)如果你不熟悉R和ggplot2，你可以看看R的数据木工课程<a href="https://datacarpentry.org/R-ecology-lesson/index.html">here</a>。此外，由于大多数搜索引擎对 "R+主题 "这种形式的搜索很吃力，我们建议使用专门的服务<a
href="http://rseek.org">RSeek </a>来代替。

R和其他语言最突出的区别是，赋值运算符（`a = 5`）通常被写成`a <- 5`。由于后者被认为是标准的，我们将在我们的例子中也使用它。要在R语言中打开`.h5`文件，你必须安装<a href="https://bioconductor.org/packages/release/bioc/html/rhdf5.html">rhdf5</a>包，它是Bioconductor软件包的一部分。

首先，我们将包括所有必要的包，并看看我们文件中的数据是如何结构化的。

@code{.r}
library(rhdf5)     # library for handling HDF5 files
library(ggplot2)   # main plotting library
library(grDevices) # needed for output to PDF
library(viridis)   # contains good colormaps for sequential data


refinement <- 5
h5f <- H5Fopen(paste("solution_",refinement,".h5",sep=""))
print(h5f)
@endcode

这给出了以下输出

@code{.unparsed}
HDF5 FILE
   name /
filename


    name       otype  dclass     dim
0 cells       H5I_DATASET INTEGER  x 1024
1 mean_value  H5I_DATASET FLOAT   1
2 nodes       H5I_DATASET FLOAT    x 1089
3 point_value H5I_DATASET FLOAT   1
4 solution    H5I_DATASET FLOAT    x 1089
@endcode

数据集可以通过  <code>h5f\$name</code>  访问。函数  <code>dim(h5f\$cells)</code>  给我们提供了用于存储我们单元格的矩阵的尺寸。我们可以看到以下三个矩阵，以及我们添加的两个额外数据点。   <ul>   <li>   <code>cells</code>  ：一个4x1024的矩阵，存储每个单元的（C++）顶点指数  <li>   <code>nodes</code>  ：一个2x1089的矩阵，存储我们单元顶点的位置值（x，y）  <li>   <code>solution</code>  : 一个1x1089的矩阵，存储我们的解决方案在每个顶点的值  </ul>  现在我们可以使用这些数据来生成各种图表。用ggplot2作图通常分为两步。首先，数据需要被处理并添加到一个  <code>data.frame</code>  。之后，构建一个 <code>ggplot</code> 对象，并通过向其添加绘图元素来进行操作。

 <code>nodes</code> and <code>cells</code> 包含我们绘制网格所需的所有信息。下面的代码将所有的数据打包成一个数据框架，用于绘制我们的网格。

@code{.r}
# Counting in R starts at 1 instead of 0, so we need to increment all
# vertex indices by one:
cell_ids <- h5f$cells+1


# Store the x and y positions of each vertex in one big vector in a
# cell by cell fashion (every 4 entries belong to one cell):
cells_x <- h5f$nodes[1,][cell_ids]
cells_y <- h5f$nodes[2,][cell_ids]


# Construct a vector that stores the matching cell by cell grouping
# (1,1,1,1,2,2,2,2,...):
groups <- rep(1:ncol(cell_ids),each=4)


# Finally put everything into one dataframe:
meshdata <- data.frame(x = cells_x, y = cells_y, id = groups)
@endcode



有了完成的数据框架，我们就有了绘制网格所需的一切。

@code{.r}
pdf (paste("grid_",refinement,".pdf",sep=""),width = 5,height = 5) # Open new PDF file
plt <- ggplot(meshdata,aes(x=x,y=y,group=id))                      # Construction of our plot
                                                                   # object, at first only data


plt <- plt + geom_polygon(fill="white",colour="black")             # Actual plotting of the grid as polygons
plt <- plt + ggtitle(paste("grid at refinement level #",refinement))


print(plt)                                                         # Show the current state of the plot/add it to the pdf
dev.off()                                                          # Close PDF file
@endcode



这个文件的内容看起来如下（不是很令人兴奋，但你会明白的）。   <table width="60%" align="center">
  <tr>
   <td align="center">
     <img src="https://www.dealii.org/images/steps/developer/step-3.extensions.grid_5.png" alt="Grid after 5 refinement steps of step-3">
   </td>
  </tr>
</table> 

我们还可以将解决方案本身可视化，这看起来会更有趣。为了给我们的解决方案做一个二维伪色图，我们将使用  <code>geom_raster</code>  。这个函数需要一个结构化的网格，即在x和y方向上是均匀的。幸运的是，我们在这一点上的数据是以正确的方式结构化的。下面的代码将我们的曲面的伪彩色表示法绘制成一个新的PDF。

@code{.r}
pdf (paste("pseudocolor_",refinement,".pdf",sep=""),width = 5,height = 4.2) # Open new PDF file
colordata <- data.frame(x = h5f$nodes[1,],y = h5f$nodes[2,] , solution = h5f$solution[1,])
plt <- ggplot(colordata,aes(x=x,y=y,fill=solution))
plt <- plt + geom_raster(interpolate=TRUE)
plt <- plt + scale_fill_viridis()
plt <- plt + ggtitle(paste("solution at refinement level #",refinement))


print(plt)
dev.off()
H5Fclose(h5f) # Close the HDF5 file
@endcode

现在的情况是这样的。   <table width="60%" align="center">
 <tr>
   <td align="center">
     <img src="https://www.dealii.org/images/steps/developer/step-3.extensions.pseudocolor_5.png" alt="Solution after 5 refinement steps of step-3">
   </td>
 </tr>
</table> 

为了绘制收敛曲线，我们需要从1开始用不同的 <code>n_refinement_steps</code> 值多次重新运行C++代码。由于每个文件只包含一个数据点，我们需要对它们进行循环，并将结果串联成一个矢量。

@code{.r}
n_ref <- 8   # Maximum refinement level for which results are existing


# First we initiate all vectors with the results of the first level
h5f   <- H5Fopen("solution_1.h5")
dofs  <- dim(h5f$solution)[2]
mean  <- h5f$mean_value
point <- h5f$point_value
H5Fclose(h5f)


for (reflevel in 2:n_ref)
{
   h5f   <- H5Fopen(paste("solution_",reflevel,".h5",sep=""))
   dofs  <- c(dofs,dim(h5f\$solution)[2])
   mean  <- c(mean,h5f\$mean_value)
   point <- c(point,h5f\$point_value)
   H5Fclose(h5f)
}
@endcode

由于我们对数值本身不感兴趣，而是对与 "精确 "解决方案相比的误差感兴趣，我们将假设我们的最高细化水平是该解决方案，并从数据中省略它。

@code{.r}
# Calculate the error w.r.t. our maximum refinement step
mean_error  <- abs(mean[1:n_ref-1]-mean[n_ref])
point_error <- abs(point[1:n_ref-1]-point[n_ref])


# Remove the highest value from our DoF data
dofs     <- dofs[1:n_ref-1]
convdata <- data.frame(dofs = dofs, mean_value= mean_error, point_value = point_error)
@endcode

现在我们有所有的数据可以用来生成我们的图。在对数尺度上绘制误差往往是有用的，这在下面的代码中可以实现。

@code
pdf (paste("convergence.pdf",sep=""),width = 5,height = 4.2)
plt <- ggplot(convdata,mapping=aes(x = dofs, y = mean_value))
plt <- plt+geom_line()
plt <- plt+labs(x="#DoFs",y = "mean value error")
plt <- plt+scale_x_log10()+scale_y_log10()
print(plt)


plt <- ggplot(convdata,mapping=aes(x = dofs, y = point_value))
plt <- plt+geom_line()
plt <- plt+labs(x="#DoFs",y = "point value error")
plt <- plt+scale_x_log10()+scale_y_log10()
print(plt)


dev.off()
@endcode

这就产生了下面的图，显示了均值和所选点的解值的误差如何很好地收敛到零。   <table style="width:50%" align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-3.extensions.convergence_mean.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-3.extensions.convergence_point.png" alt=""></td>
  </tr>
</table> 


examples/step-30/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>




<h3>Overview</h3>

这个例子专门讨论 <em> 各向异性细化 </em> ，它扩展到局部细化的可能性。在大多数情况下，这是对step-12教程程序的修改，我们使用相同的DG方法处理线性输运方程。这个程序将涵盖以下主题。<ol>  <li>   <em>  各向异性细化  </em>  : 各向异性细化的含义是什么？     <li>   <em>  实现  </em>  ：对代码进行必要的修改，以便与各向异性的细化网格一起工作。     <li>   <em>  跳跃指标  </em>  : 在DG方法中，各向异性细化的一个简单指标。   </ol>  将不讨论离散化本身，也不讨论这里使用的非各向异性细化的实施技术。这一点请参考步骤12。

请注意，在编写这个教程程序的时候，各向异性的细化只在不连续的Galerkin有限元中完全实现。这一点以后可能会改变（或者已经改变）。




 @note  虽然这个程序是对step-12的修改，但它是在deal.II历史上早期写的step-12的一个版本，当时MeshWorker框架还没有出现。因此，它与现在的step-12几乎没有任何相似之处，除了它以相同的离散化方式求解相同的方程。




<h3>Anisotropic refinement</h3>

在前面的教程程序中，所有的适应过程都是基于 <em> 各向同性 </em> 细化单元，它将所有的边切成两半，并将这些分割的边形成新的单元（当然，还要加上一些额外的边、面和顶点）。在deal.II中， <em> 各向异性细化 </em> 指的是只分割部分边而不改变其他边的过程。例如，考虑一个简单的方形单元。

@code
  *-------*
  |       |
  |       |
  |       |
  *-------*
@endcode

经过通常的细化，它将由四个孩子组成，看起来像这样。

@code
  *---*---*
  |   |   |
  *---*---*     RefinementCase<2>::cut_xy
  |   |   |
  *---*---*
@endcode

新的各向异性细化可能有两种形式：一是我们可以将平行于水平X轴的边缘分割开来，形成这两个子单元。

@code
  *---*---*
  |   |   |
  |   |   |     RefinementCase<2>::cut_x
  |   |   |
  *---*---*
@endcode

或者我们可以拆分沿y轴运行的两条边，再次产生两个孩子，不过，看起来是这样的。

@code
  *-------*
  |       |
  *-------*     RefinementCase<2>::cut_y
  |       |
  *-------*
@endcode

所有单元的细化情况都由枚举 RefinementPossibilities::Possibilities, 来描述，上述各向异性情况被称为 @p cut_x 和 @p cut_y ，原因很明显。各向同性的细化情况在二维中被称为 @p cut_xy ，可以通过 RefinementCase<dim>::isotropic_refinement. 从细化案例类中请求。

在三维中，有第三个轴可以被分割，即z轴，因此我们在这里有一个额外的细化案例 @p cut_z 。各向同性的细化现在将沿x轴、y轴和z轴细化一个单元，因此被称为 @p  cut_xyz。另外还有 @p cut_xy,  @p cut_xz 和 @p cut_yz 的情况，它们沿两个轴精化单元，但不沿第三个轴精化。给出一个六面体单元，X轴向右，Y轴 "进入页面"，Z轴在顶部。

@code
      *-----------*
     /           /|
    /           / |
   /           /  |
  *-----------*   |
  |           |   |
  |           |   *
  |           |  /
  |           | /
  |           |/
  *-----------*
@endcode

我们有各向同性的细化情况。

@code
      *-----*-----*
     /     /     /|
    *-----*-----* |
   /     /     /| *
  *-----*-----* |/|
  |     |     | * |
  |     |     |/| *
  *-----*-----* |/
  |     |     | *
  |     |     |/
  *-----*-----*


  RefinementCase<3>::cut_xyz
@endcode

三种各向异性的情况，只细化一个轴。

@code
      *-----*-----*             *-----------*             *-----------*
     /     /     /|            /           /|            /           /|
    /     /     / |           *-----------* |           /           / |
   /     /     /  |          /           /| |          /           /  *
  *-----*-----*   |         *-----------* | |         *-----------*  /|
  |     |     |   |         |           | | |         |           | / |
  |     |     |   *         |           | | *         |           |/  *
  |     |     |  /          |           | |/          *-----------*  /
  |     |     | /           |           | *           |           | /
  |     |     |/            |           |/            |           |/
  *-----*-----*             *-----------*             *-----------*


  RefinementCase<3>::cut_x  RefinementCase<3>::cut_y  RefinementCase<3>::cut_z
@endcode

和三个案例，它们完善了三个轴中的两个。

@code
      *-----*-----*             *-----*-----*             *-----------*
     /     /     /|            /     /     /|            /           /|
    *-----*-----* |           /     /     / |           *-----------* |
   /     /     /| |          /     /     /  *          /           /| *
  *-----*-----* | |         *-----*-----*  /|         *-----------* |/|
  |     |     | | |         |     |     | / |         |           | * |
  |     |     | | *         |     |     |/  *         |           |/| *
  |     |     | |/          *-----*-----*  /          *-----------* |/
  |     |     | *           |     |     | /           |           | *
  |     |     |/            |     |     |/            |           |/
  *-----*-----*             *-----*-----*             *-----------*


  RefinementCase<3>::cut_xy RefinementCase<3>::cut_xz RefinementCase<3>::cut_yz
@endcode

对于一维问题，各向异性的细化不会产生任何影响，因为一个单元只有一个坐标方向，所以除了各向同性外，不可能以任何其他方式分割。

<h4>Motivation</h4>自适应局部细化是用来获得很好地适应有效解决手头问题的细网格。简而言之，产生较大误差的单元的尺寸被减小，以获得手头问题的更好的近似解。然而，很多问题都含有各向异性的特征。突出的例子是可压缩粘性流动中的冲击或边界层。一个有效的网格可以用较高长宽比的单元来逼近这些特征，而这些单元是根据上述特征定向的。只使用各向同性的细化，原始网格单元的长宽比会被保留下来，因为它们会被单元的子代所继承。因此，从各向同性的网格开始，边界层将被细化，以捕捉壁面法线方向上流场的快速变化，从而导致在法线和切线方向上都具有非常小的边缘长度的单元。通常情况下，在切线方向上的边长要大得多，因此可以使用更少的单元，而不会在近似精度上有明显的损失。各向异性的细化过程可以在每个细化步骤中把母细胞和子细胞的长宽比修改为两个系数。在多次细化的过程中，细单元的长宽比可以得到优化，从而节省了相当数量的单元和相应的自由度，从而节省了计算资源、内存以及CPU时间。

<h3>Implementation</h3>

大多数时候，当我们进行有限元计算时，我们一次只考虑一个单元，例如计算单元对全局矩阵的贡献，或插值边界值。然而，有时我们不得不看一下单元在我们的算法中是如何关联的。单元之间的关系有两种形式：邻居关系和母子关系。对于各向同性的细化情况，deal.II对始终保持的单元格关系使用了某些约定（不变量）。例如，一个细化的单元总是正好有 $2^{dim}$ 个子女。而且（除了1d情况），两个相邻的单元格最多可以相差一个细化级别：它们同样经常被细化，或者其中一个正好再被细化一次，在共同面上正好留下一个悬挂的节点。几乎所有的时候，这些不变量都只在库的内部实现中被关注。然而，在有些情况下，对它们的了解也与应用程序有关。

在当前情况下，值得注意的是，网格细化的种类会影响一些最基本的假设。因此，在应用程序中发现的一些常规代码将需要修改，以利用使用各向异性细化创建的网格的特征。对于那些对deal.II如何演变感兴趣的人来说，可能会感兴趣的是，这种不变量的松动需要一些不兼容的变化。例如，库中曾经有一个成员 GeometryInfo<dim>::children_per_cell ，规定一个单元一旦被细化后有多少个孩子。对于各向同性的细化，这个数字等于  $2^{dim}$  ，如上所述。然而，对于各向异性的细化，这个数字并不存在，因为在二维中可以是2或4，在三维中可以是2、4或8，因此成员 GeometryInfo<dim>::children_per_cell 已经被删除。它现在已经被 GeometryInfo<dim>::max_children_per_cell 所取代，后者指定了一个单元格可以有的<i>maximum</i>个子嗣。一个细化的单元有多少个子代以前是作为静态信息提供的，但现在它取决于一个单元的实际细化状态，可以使用 TriaAccessor::n_children(), 检索，这个调用对各向同性和各向异性的细化都同样有效。对于面和它们的子面也有非常类似的情况：相关的信息可以使用 GeometryInfo<dim>::max_children_per_face 或 <code>face->n_children()</code> 进行查询，这取决于上下文。

另一个重要的方面，也是本教程中最重要的方面，是在组装单元格之间的面的跳跃项时对邻居关系的处理。在步骤12中查看assemble_system函数的文档，我们注意到，我们需要决定一个相邻的单元是否更粗、更细或者与我们当前的单元处于同一（细化）水平。这些决定对于各向异性的细化并不适用，因为细胞的 <em> 级 </em> 所提供的信息并不足以完全描述各向异性的细胞；例如，一个二维细胞的终端子女是否首先在 $x$ 方向切割的二维单元，其子女随后在 $y$ 方向切割时是在第2层，还是在第1层，因为如果该单元被各向同性地精炼一次，就会产生同一组最好的单元？

在各向异性的细化之后，一个更粗的邻居不一定正好比我们低一个级别，而是几乎可以有相对于当前级别的任何级别；事实上，它甚至可以在一个更高的级别上，尽管它更粗。因此，必须在不同的基础上做出决定，而决定的意图却保持不变。

在下文中，我们将讨论当我们想计算对矩阵（或右手边）的贡献时可能发生的情况，其形式为

@f[
  \int_{\partial K} \varphi_i(x) \varphi_j(x) \; dx


@f]

或类似的；记住，我们使用FEFaceValues和FESubfaceValues类来整合这样的条款。我们还将展示如何编写适用于各向同性和各向异性细化的代码。

 <ul> 

    <li>   <em>  更精细的邻居  </em>  ：如果我们在一个活动单元上，想要整合到一个面  $f\subset \partial K$  上，第一个可能性是这个面后面的邻居更精细，即有孩子只占据了共同面的一部分。在这种情况下，所考虑的面必须是一个精致的面，这可以通过询问  <code>if (face->has_children())</code>  来确定。如果这是真的，我们需要在所有的子面中循环，得到这个子面后面的邻居的孩子，这样我们就可以用邻居重新输入一个FEFaceValues对象，用我们的单元格和相应的子面重新输入一个FESubfaceValues对象。

  对于各向同性的细化，这种情况相当简单，因为我们知道，在deal.II中，各向同性细化的自适应网格的一个不变性是，邻居只能正好相差一个细化等级。然而，对于各向异性细化的网格来说，这并不完全正确，特别是在三维中；在那里，我们感兴趣的位于 $f$ 另一侧的活动单元实际上可能不是我们邻居的孩子，而可能是孙子甚至是更远的后代。幸运的是，这种复杂性被隐藏在库的内部。我们所要做的就是调用 CellAccessor::neighbor_child_on_subface() 函数。尽管如此，在3D中，有两种情况需要特别考虑。     <ul>   <li>  如果邻居被各向异性地细化了一次以上，可能这里需要考虑的不是两个或四个而是三个子面。想象一下我们正在考虑的（三维）邻接单元的（二维）面的以下细化过程：首先该面沿x方向细化，后来只沿y方向细化左侧子面。

@code
   *-------*        *---*---*        *---*---*
   |       |        |   |   |        |   |   |
   |       |  --->  |   |   |  --->  *---*   |
   |       |        |   |   |        |   |   |
   *-------*        *---*---*        *---*---*
@endcode

     这里子脸的数量是三个。需要注意的是，对于一个面， TriaAccessor::n_children() 和 TriaAccessor::n_active_descendants(). 之间的细微差别。第一个函数返回直系子女的数量，在上面的例子中是两个，而第二个函数返回活动后代的数量（即，包括子女、孙子和进一步的后代），在上面的例子中是正确的三个。使用 <code>face->n_active_descendants()</code> 对各向同性和各向异性以及二维和三维情况都有效，所以应该始终使用它。应该注意的是，如果最右边图像左侧的两个小子面后面的任何一个单元被进一步细化，那么当前的单元（即我们从这个共同面看的那一面）也要被细化：之所以这样，是因为否则就会违反每条边只有一个悬挂节点的不变量。

      <li> 可能是，邻居比较粗，但仍有比我们当前单元更细的孩子。如果两个同样粗糙的单元被细化，其中一个单元在所考虑的面有两个孩子，另一个有四个孩子，这种情况就会发生。下图中的单元格只是相互分离，以显示各个细化的情况。

@code
      *-----------*     *-----------*
     /           /|    /           /|
    ############# |   +++++++++++++ |
   #           ## |  +           ++ *
  ############# # | +++++++++++++ +/|
  #           # # | +           + + |
  #           # # * +           +++ *
  #           # #/  +++++++++++++ +/
  #           # #   +           + +
  #           ##    +           ++
  #############     +++++++++++++
@endcode



  这里，左边的两个单元是在 $y$ -方向上对母单元进行各向异性分割的结果，而右边的四个单元是在 $y$  -和 $z$ -方向上同时进行各向异性细化的结果。   标有#的左边单元有两个标有+的更细的邻居，但左边单元的实际邻居是完整的右边母单元，因为标有+的两个单元更细，它们的直接母体是一个大单元。     </ul> 

  然而，幸运的是， CellAccessor::neighbor_child_on_subface() 可以自己处理这些情况，如果你在正确的子界面数量上循环，在上面的例子中，这是两个。 FESubfaceValues<dim>::reinit 函数也会照顾到这一点，因此，结果的状态总是正确的。然而，有一个小的注意事项。为了重新调用邻居的FEFaceValues对象，你需要知道指向当前单元格的面的索引。通常你会假设你直接得到的邻居和你一样粗或细，如果它有孩子的话，因此这个信息可以通过 CellAccessor::neighbor_of_neighbor(). 得到，然而如果邻居比较粗，你就必须使用 CellAccessor::neighbor_of_coarser_neighbor() 中的第一个值来代替。为了方便你，有一个 CellAccessor::neighbor_face_no() 可以为你做正确的事情，并返回所需的结果。

    <li>   <em>  邻居和我们的单元格一样细  </em>  ：在我们排除了所有存在更细的子代的情况后，我们只需要决定，邻居是否在这里更粗。为此，有一个 CellAccessor::neighbor_is_coarser() 函数，返回一个布尔值。为了得到相同粗度的邻居的相关情况，我们将使用  <code>else if (!cell->neighbor_is_coarser(face_no))</code>  。这个块里面的代码可以不动。然而，这里有一件事要提到。如果我们想使用一个规则，哪个单元应该在一个给定的面上组合某些条款，我们可以考虑步骤12中提出的规则。我们知道，我们必须舍弃将我们的单元格的水平与邻居的水平进行比较的部分，而用上面提出的对较粗的邻居的测试来取代。然而，我们也必须考虑到具有相同粗度的相邻单元具有相同指数（在不同水平上）的可能性。因此，我们必须包括单元格具有相同索引的情况，并给出一个额外的条件，即哪一个单元格应该集合条款，例如，我们可以选择较低层次的单元格。这个概念的细节可以在下面的实现中看到。

    <li>   <em>  较粗的邻居  </em>  ：剩下的情况很明显：如果没有精炼的邻居，而且邻居不像当前单元那么细，那么它一定是较粗的。因此我们可以留下旧的条件短语，简单地使用  <code>else</code>  。 CellAccessor::neighbor_of_coarser_neighbor() 函数照顾到各向异性细化的所有复杂性，结合一般三维网格上可能的非标准面的方向、翻转和旋转。

 </ul> 

<h4>Mesh smoothing</h4> 当一个三角形被细化时，没有被标记为细化的单元可能仍然被细化。这是由于额外的平滑算法，这些算法是必要的或明确要求的。特别是，在每条边上最多有一个悬空节点的限制，经常迫使邻近已经很细的单元的额外单元被细化，并被标记为进一步细化。

然而，deal.II也实现了一些算法，以确保得到的网格比最低限度的平滑，例如，确保没有孤立的精化单元被非精化单元所包围，因为这些岛屿上的额外自由度几乎都会受到悬挂节点的约束。关于网格平滑的更多信息，请参见三角形类及其 Triangulation::MeshSmoothing 成员的文档）。

大多数最初为各向同性情况开发的平滑算法已经被调整为以非常相似的方式用于各向异性和各向同性的细化工作。然而，有两种算法值得一提。<ol>  <li>   <code>MeshSmoothing::limit_level_difference_at_vertices</code>  : 在各向同性的环境中，该算法试图通过减少在共同顶点相遇的单元的细化水平差异来确保良好的近似质量。然而，对于各向异性的细化没有明确的对应概念，因此该算法不能与各向异性的细化结合使用。这个限制是由一个断言强制执行的，一旦在一个已经被各向异性细化的三角形上调用该算法，就会抛出一个错误。

    <li>   <code>MeshSmoothing::allow_anisotropic_smoothing</code>  : 如果引入细化来限制悬空节点的数量，往往不需要额外的单元来提高近似质量。这对DG方法来说尤其如此。如果你设置了标志 <code>allow_anisotropic_smoothing</code> ，平滑算法试图通过使用各向异性的细化来尽量减少可能不需要的额外单元的数量。如果你设置了这个平滑标志，你可能会得到各向异性的细化单元，即使你从未将一个细化标志设置为各向异性的细化。请注意，如果你的代码尊重各向异性网格的可能性，你只应该使用这个标志。结合一个合适的各向异性指标，这个标志可以帮助节省额外的单元，从而节省精力。   </ol> 




<h3>Jump indicator</h3>

利用各向异性细化的好处，需要一个指标来捕捉溶液的各向异性特征，并利用它们来进行细化过程。一般来说，各向异性的细化过程将包括几个步骤。<ol>  <li>  计算一个误差指标。     <li>  使用误差指标来标记单元进行细化，例如使用固定数量或分数的单元。这些单元将被自动标记为各向同性的细化。     <li>  只在被标记的单元上评估一个明显的各向异性指标。     <li>  使用各向异性指标为合适的单元设置一个新的各向异性细化标志，否则保持标志不变。     <li>  调用 Triangulation<dim>::execute_coarsening_and_refinement 来执行要求的细化，使用要求的各向同性和各向异性标志。   </ol>  这种方法类似于我们在步骤27中用于hp-细化的方法，具有很大的灵活性优势。任何误差指标都可以在各向异性过程中使用，也就是说，如果你有相当多的后验目标导向的误差指标可用，你可以像使用简单的凯利误差估计器一样方便地使用它们。精细化过程的各向异性部分不受这种选择的影响。此外，只要省去第三和第四步，就可以得到与你在deal.II或你的应用程序中的任何各向异性变化之前相同的各向异性的细化结果。作为最后一个优点，只对标记为细化的单元进行工作会使各向异性指标的评估更快，如果指标涉及很多单元的话，这在有很多单元的细网格上会变得很明显。

在这里，我们使用一个非常简单的方法，它只适用于DG方法。一般的想法是非常简单的。DG方法允许离散解在一个单元的面上跳跃，而在每个单元内是平滑的。当然，在极限情况下，我们期望随着我们对网格的细化和对真实解的近似程度越来越高，跳跃会趋于零。因此，在一个给定的面的大跳跃表明该单元应该被细化（至少是）正交于该面，而小跳跃则不会导致这一结论。当然，有可能确切的解决方案并不平滑，它也有跳跃的特征。然而，在这种情况下，一个面的大跳跃表明，这个面或多或少地与跳跃平行，并且在它的附近，因此我们再次期望与所考虑的面正交的细化是有效的。

所提出的指标计算平均跳跃 $K_j$ ，即离散解 $u$ 在单元格上与坐标方向 $f_i^j$ 、 $i=1,2$ 、 $j=1..d$ 正交的两个面上绝对跳跃 $|[u]|$ 的平均值。

@f[
K_j = \frac{\sum_{i=1}^2 \int_{f_i^j}|[u]| dx}{\sum_{i=1}^2 |f_i^j|} .


@f]

如果一个方向的平均跳动比其他方向的跳动的平均值大一定的系数 $\kappa$ ，即如果 $K_i > \kappa \frac 1{d-1} \sum_{j=1, j\neq i}^d K_j$ ，则该单元只沿该特定方向进行细化 $i$ ，否则该单元是各向同性细化的。

这样的标准很容易被推广到方程组：跳跃的绝对值将被矢量值跳跃的适当规范所取代。




<h3>The problem</h3>

我们解决步骤12中提出的线性传输方程。域被扩展到覆盖二维的 $[-1,1]\times[0,1]$ ，其中流场 $\beta$ 在域的右半部描述了一个围绕原点的逆时针四分之一圆，在域的左半部平行于x轴。流入边界再次位于 $x=1$ 处，并沿x轴的正向部分，边界条件选择与步骤12相同。


examples/step-30/doc/results.dox



<h1>Results</h1>


该程序的输出包括控制台输出、包含网格的SVG文件以及以VTU格式给出的解决方案。

@code
Performing a 2D run with isotropic refinement...


------------------------------------------------
Cycle 0:
   Number of active cells:       128
   Number of degrees of freedom: 512
   Time of assemble_system: 0.092049
   Writing grid to <grid-0.iso.svg>...
   Writing solution to <sol-0.iso.vtu>...


Cycle 1:
   Number of active cells:       239
   Number of degrees of freedom: 956
   Time of assemble_system: 0.109519
   Writing grid to <grid-1.iso.svg>...
   Writing solution to <sol-1.iso.vtu>...


Cycle 2:
   Number of active cells:       491
   Number of degrees of freedom: 1964
   Time of assemble_system: 0.08303
   Writing grid to <grid-2.iso.svg>...
   Writing solution to <sol-2.iso.vtu>...


Cycle 3:
   Number of active cells:       1031
   Number of degrees of freedom: 4124
   Time of assemble_system: 0.278987
   Writing grid to <grid-3.iso.svg>...
   Writing solution to <sol-3.iso.vtu>...


Cycle 4:
   Number of active cells:       2027
   Number of degrees of freedom: 8108
   Time of assemble_system: 0.305869
   Writing grid to <grid-4.iso.svg>...
   Writing solution to <sol-4.iso.vtu>...


Cycle 5:
   Number of active cells:       4019
   Number of degrees of freedom: 16076
   Time of assemble_system: 0.47616
   Writing grid to <grid-5.iso.svg>...
   Writing solution to <sol-5.iso.vtu>...



Performing a 2D run with anisotropic refinement...


--------------------------------------------------
Cycle 0:
   Number of active cells:       128
   Number of degrees of freedom: 512
   Time of assemble_system: 0.052866
   Writing grid to <grid-0.aniso.svg>...
   Writing solution to <sol-0.aniso.vtu>...


Cycle 1:
   Number of active cells:       171
   Number of degrees of freedom: 684
   Time of assemble_system: 0.050917
   Writing grid to <grid-1.aniso.svg>...
   Writing solution to <sol-1.aniso.vtu>...


Cycle 2:
   Number of active cells:       255
   Number of degrees of freedom: 1020
   Time of assemble_system: 0.064132
   Writing grid to <grid-2.aniso.svg>...
   Writing solution to <sol-2.aniso.vtu>...


Cycle 3:
   Number of active cells:       394
   Number of degrees of freedom: 1576
   Time of assemble_system: 0.119849
   Writing grid to <grid-3.aniso.svg>...
   Writing solution to <sol-3.aniso.vtu>...


Cycle 4:
   Number of active cells:       648
   Number of degrees of freedom: 2592
   Time of assemble_system: 0.218244
   Writing grid to <grid-4.aniso.svg>...
   Writing solution to <sol-4.aniso.vtu>...


Cycle 5:
   Number of active cells:       1030
   Number of degrees of freedom: 4120
   Time of assemble_system: 0.128121
   Writing grid to <grid-5.aniso.svg>...
   Writing solution to <sol-5.aniso.vtu>...
@endcode



这个文本输出显示了各向异性细化的连续应用所带来的单元数量的减少。在最后一个细化步骤之后，节省的数量已经积累到几乎是各向同性情况下所需单元和自由度的四倍。装配所需的时间也以类似的因素进行扩展。

第一个有趣的部分当然是看这些网格是什么样子的。左边是各向同性细化的网格，右边是各向异性的网格（颜色表示单元的细化程度）。

 <table width="80%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-0.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-0.aniso.9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-1.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-1.aniso.9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-2.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-2.aniso.9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-3.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-3.aniso.9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-4.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-4.aniso.9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-5.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.grid-5.aniso.9.2.png" alt="">
    </td>
  </tr>
</table> 


当然，另一个有趣的事情是看这两个网格序列上的解。在这里，它们是在细化周期1和4上，清楚地显示出解决方案确实是由<i>discontinuous</i>分片多项式组成。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.sol-1.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.sol-1.aniso.9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.sol-4.iso.9.2.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-30.sol-4.aniso.9.2.png" alt="">
    </td>
  </tr>
</table> 

我们看到，各向异性细化网格上的解与各向同性细化网格上的解非常相似。因此，各向异性指标似乎可以有效地选择适当的单元进行各向异性的细化。

这些图片也解释了为什么网格被细化成这样。在整个域的左边部分，细化只沿着 $y$ 的单元轴进行。在域的右边部分，细化以各向同性的细化为主，因为解的各向异性特征--从1到0的跳跃--在平流方向转弯的地方不能很好地与网格对齐。然而，在四分之一圆的底部和最接近（观察者）的部分，这种跳跃又变得越来越与网格对齐，细化算法的反应是创建长宽比越来越大的各向异性单元。

看起来，各向异性特征和粗大网格的必要对齐会大大降低实际问题的性能。这在一般情况下是不会错的。例如，如果将各向异性细化应用于出现冲击的问题（如步骤69中求解的方程），那么在许多情况下，冲击并没有与网格对齐，各向异性细化的帮助不大，除非同时引入技术将网格与冲击对齐。另一方面，许多陡峭的解的特征是由于边界层造成的。在这些情况下，网格已经与各向异性特征对齐，因为它当然是与边界本身对齐的，各向异性的细化几乎总是可以提高这些情况下适应网格的计算效率。


examples/step-31/doc/intro.dox

 <br> 

<i>This program was contributed by Martin Kronbichler and Wolfgang
Bangerth.
<br>
This material is based upon work partly supported by the National
Science Foundation under Award No. EAR-0426271 and The California Institute of
Technology. Any opinions, findings, and conclusions or recommendations
expressed in this publication are those of the author and do not
necessarily reflect the views of the National Science Foundation or of The
California Institute of Technology.
</i>


<a name="Intro"></a>

<h1>Introduction</h1>

<h3>The Boussinesq equations</h3>

这个程序涉及一个有趣的物理问题：如果流体（即液体或气体）遇到由温度差异引起的浮力差异，它是如何表现的？很明显，流体中温度较高（因此较轻）的部分会上升，温度较低（密度较大）的部分会在重力作用下下沉。

在流体运动速度足够慢，以至于惯性效应可以被忽略的情况下，描述这种行为的方程是布西尼斯克方程，其内容如下。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=&


  -\rho\; \beta \; T\; \mathbf{g},
  \\
  \nabla \cdot {\mathbf u} &=& 0,
  \\
  \frac{\partial T}{\partial t}
  +
  {\mathbf u} \cdot \nabla T


  -
  \nabla \cdot \kappa \nabla T &=& \gamma.


@f}

这些方程属于矢量值问题的范畴（这个主题的顶层概述可以在 @ref vector_valued 模块中找到）。这里， $\mathbf u$ 是速度场， $p$ 是压力， $T$ 是流体的温度。   $\varepsilon ({\mathbf u}) = \frac 12
[(\nabla{\mathbf u}) + (\nabla {\mathbf u})^T]$ 是速度的对称梯度。可以看出，速度和压力解决了描述不可压缩流体运动的斯托克斯方程，这个方程我们以前在步骤22中考虑过；我们将广泛借鉴在该程序中获得的经验，特别是关于高效线性斯托克斯求解器的经验。

流体运动的强制项是流体的浮力，表示为密度 $\rho$ 、热膨胀系数 $\beta$ 、温度 $T$ 和指向下方的重力矢量 $\mathbf{g}$ 的积。在第32步的介绍中给出了为什么右手边看起来像它的推导）。前两个方程描述了流体如何通过移动对温差做出反应，第三个方程说明了流体运动如何影响温度场：它是一个平流扩散方程，即温度附着在流体颗粒上，并在流场中平流，还有一个额外的扩散（热传导）项。在许多应用中，扩散系数相当小，温度方程实际上是传输的，而不是扩散主导的，因此其特征是双曲而不是椭圆；我们在开发一个稳定的离散化时必须考虑到这一点。

在上述方程中，右侧的 $\gamma$ 项表示热源，可能是一个空间和时间上的变化函数。   $\eta$ 和 $\kappa$ 表示粘度和扩散系数，在本教程程序中我们假定这两个系数为常数。当 $\eta$ 取决于温度时，更普遍的情况是物理应用中的一个重要因素。大多数材料随着温度的升高而变得更加流动（即 $\eta$ 随着 $T$ 的降低而降低）；有时，如在温度接近熔点的岩石矿物的情况下， $\eta$ 可能在典型的温度范围内发生数量级的变化。

我们注意到，上述斯托克斯方程可以通过引入<a target="_top"
href="http://en.wikipedia.org/wiki/Rayleigh_number">Rayleigh
number</a>  $\mathrm{Ra}=\frac{\|\mathbf{g}\| \beta \rho}{\eta \kappa} \delta T L^3$ 来实现非维度化，使用的是典型长度尺度 $L$ 、典型温差 $\delta T$ 、密度 $\rho$ 、热扩散率 $\eta$ 和热导率 $\kappa$  。   $\mathrm{Ra}$ 是一个无尺寸的数字，它描述了由温差引起的浮力变化导致的热传输和热扩散导致的热传输的比率。一个小的瑞利数意味着浮力相对于粘度来说并不强，流体运动 $\mathbf{u}$ 足够慢，因此热扩散 $\kappa\nabla T$ 是主要的热传输项。另一方面，高瑞利数的流体将显示出主导热传导的强烈对流。

对于我们感兴趣的计算热对流的大多数流体，瑞利数是非常大的，通常是 $10^6$ 或更大。从方程的结构中，我们看到这将导致大的压力差和大的速度。因此， $T$ 的对流-扩散方程中的对流项也将非常大，这个方程的精确解将要求我们选择小的时间步长。因此，具有大雷利数的问题很难用数值来解决，其原因与<a
href="http://en.wikipedia.org/wiki/Navier-stokes_equations">Navier-Stokes
equations</a>大时难以解决<a
href="http://en.wikipedia.org/wiki/Reynolds_number">Reynolds number
$\mathrm{Re}$</a>的问题相似。

请注意，大的瑞利数不一定涉及大的绝对速度。例如，地幔中的瑞利数大于 $10^6$  。然而，速度却很小：该材料实际上是固体岩石，但它是如此之热，而且处于压力之下，它可以非常缓慢地流动，每年最多只有几厘米的速度。然而，这可以导致在数百万年的时间尺度上的混合，这个时间尺度比相同数量的热量通过热传导分布要短得多，而且这个时间尺度与影响地球内部和表面结构的演变有关。

 @note 如果你对使用该程序作为你自己实验的基础感兴趣，你也会想看看它在step-32中的延续。此外，step-32后来被发展成更大的开放源代码ASPECT（见https://aspect.geodynamics.org/），它可以解决现实的问题，在试图将step-31变形为可以解决任何你想解决的问题之前，你可能想研究一下它。




<h3>Boundary and initial conditions</h3>

由于Boussinesq方程是在流体运动的惯性不起作用的假设下推导出来的，所以流场在每个时间段完全由该时间段的浮力差决定，而不是由以前的流场决定。这反映在上面的前两个方程是不包含时间导数的稳态斯托克斯方程的事实。因此，我们不需要速度或压力的初始条件。另一方面，温度场确实满足一个有时间导数的方程，所以我们需要初始条件 $T$  。

至于边界条件：如果 $\kappa>0$ ，那么温度满足一个二阶微分方程，需要边界周围所有时间的边界数据。这些数据可以是规定的边界温度 $T|_{\partial\Omega}=T_b$ （Dirichlet边界条件），也可以是规定的热通量 $\mathbf{n}\cdot\kappa\nabla
T|_{\partial\Omega}=\phi$ ；在这个程序中，我们将使用一个绝缘的边界条件，即规定没有热通量。   $\phi=0$  .

同样地，速度场要求我们提出边界条件。这些条件可以是 $\mathbf{u}=0$ 上的无滑移无通量条件 $\partial\Omega$ ，如果流体粘在边界上，或者无正常通量条件 $\mathbf n \cdot \mathbf
u = 0$ ，如果流体可以沿边界流动但不能穿过边界，或者任何数量的其他物理上合理的条件。在这个程序中，我们将使用无正常通量条件。




<h3>Solution approach</h3>

与步骤21中解决的方程一样，我们这里有一个微分代数方程（DAE）系统：就时间变量而言，只有温度方程是微分方程，而 $\mathbf{u}$ 和 $p$ 的斯托克斯系统没有时间导数，因此属于必须在每个时间瞬间保持的那种代数约束。与第21步的主要区别是，那里的代数约束是一个混合拉普拉斯系统，其形式为

@f{eqnarray*}
  \mathbf u + {\mathbf K}\lambda \nabla p &=& 0, \\
  \nabla\cdot \mathbf u &=& f,


@f}

现在我们有一个斯托克斯系统

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=& f, \\
  \nabla\cdot \mathbf u &=& 0,


@f}

其中 $\nabla \cdot \eta \varepsilon (\cdot)$ 是一个类似于拉普拉斯 $\Delta$ 的算子，适用于一个矢量场。

鉴于与我们在步骤21中所做的相似，我们选择类似的方法可能并不令人惊讶，尽管我们将不得不对微分算子左上角的算子变化进行调整。




<h4>Time stepping</h4>

作为DAE的问题结构允许我们使用与我们在步骤21中已经使用的相同的策略，即我们使用一个时间滞后方案：我们首先解决温度方程（使用外推的速度场），然后将新的温度解插入速度方程的右侧。不过，我们在代码中实现这一方案的方式是从一个稍微不同的角度来看问题。我们首先使用前一个时间步长的温度场来求解速度和压力的斯托克斯方程，这意味着我们得到前一个时间步长的速度。换句话说，我们首先求解时间步长 $n - 1$ 的斯托克斯系统，即

@f{eqnarray*}


  -\nabla \cdot (2\eta \varepsilon ({\mathbf u}^{n-1})) + \nabla p^{n-1} &=&


  -\rho\; \beta \; T^{n-1} \mathbf{g},
  \\
  \nabla \cdot {\mathbf u}^{n-1} &=& 0,


@f}

然后用外推速度场的温度方程到时间  $n$  。

与第21步相比，我们在这里将使用一个高阶时间步进方案，即用（单边）差分商 $\frac{\frac 32 T^{n}-2T^{n-1}+\frac 12 T^{n-2}}{k}$ 取代时间导数 $\frac{\partial T}{\partial t}$ ， $k$ 为时间步长。这就得到了离散化的时间温度方程

@f{eqnarray*}
  \frac 32 T^n


  -
  k\nabla \cdot \kappa \nabla T^n
  &=&
  2 T^{n-1}


  -
  \frac 12 T^{n-2}


  -
  k(2{\mathbf u}^{n-1} - {\mathbf u}^{n-2} ) \cdot \nabla (2T^{n-1}-T^{n-2})
  +
  k\gamma.


@f}

请注意温度方程是如何被半显式解决的：扩散被隐式处理，而平流被显式处理，使用温度和速度的外推法（或前推法），包括刚刚计算的速度  ${\mathbf u}^{n-1}$  。对当前时间水平的正向投影  $n$  是由泰勒扩展得出的，  $T^n
\approx T^{n-1} + k_n \frac{\partial T}{\partial t} \approx T^{n-1} + k_n
\frac{T^{n-1}-T^{n-2}}{k_n} = 2T^{n-1}-T^{n-2}$  。我们需要这个投影来保持BDF-2方案的精度。换句话说，我们在显式右手边使用的温度场是当前温度场的二阶近似值&mdash；不完全是显式时间步进方案，但从特征上看也不会太远。

温度外推的引入将时间步长限制在<a href="http://en.wikipedia.org/wiki/Courant–Friedrichs–Lewy_condition">
Courant-Friedrichs-Lewy (CFL) condition</a>，就像在 @ref step_21 "步骤-21 "中一样。(如果我们隐含地处理平流项，我们就不会有这个稳定条件，因为BDF-2方案是A级稳定的，代价是我们需要在每个时间步长建立一个新的温度矩阵。)我们将在<a href="#Results">results
section</a>中讨论时间步长的确切选择，但目前重要的是，这个CFL条件意味着时间步长 $k$ 可能在不同的时间步长中发生变化，我们必须稍微修改上述公式。如果 $k_n,k_{n-1}$ 是当前和前一个时间步长的时间步长，那么我们使用近似值

@f{align*}{
\frac{\partial T}{\partial t} \approx
 \frac 1{k_n}
 \left(
       \frac{2k_n+k_{n-1}}{k_n+k_{n-1}} T^{n}


       -
       \frac{k_n+k_{n-1}}{k_{n-1}}T^{n-1}
       +
       \frac{k_n^2}{k_{n-1}(k_n+k_{n-1})} T^{n-2}
 \right)
 @f}

和

@f{align*}{
T^n \approx
   T^{n-1} + k_n \frac{\partial T}{\partial t}
   \approx
   T^{n-1} + k_n
   \frac{T^{n-1}-T^{n-2}}{k_{n-1}}
   =
   \left(1+\frac{k_n}{k_{n-1}}\right)T^{n-1}-\frac{k_n}{k_{n-1}}T^{n-2},


@f}

并将上述方程概括如下。

@f{eqnarray*}
  \frac{2k_n+k_{n-1}}{k_n+k_{n-1}} T^n


  -
  k_n\nabla \cdot \kappa \nabla T^n
  &=&
  \frac{k_n+k_{n-1}}{k_{n-1}} T^{n-1}


  -
  \frac{k_n^2}{k_{n-1}(k_n+k_{n-1})} T^{n-2}


  -
  k_n{\mathbf u}^{*,n} \cdot \nabla T^{*,n}
  +
  k_n\gamma,


@f}



其中 ${(\cdot)}^{*,n} = \left(1+\frac{k_n}{k_{n-1}}\right)(\cdot)^{n-1} -
\frac{k_n}{k_{n-1}}(\cdot)^{n-2}$ 表示速度 $\mathbf u$ 和温度 $T$ 外推到时间级别 $n$ ，使用前两个时间步骤的数值。这不是一个容易读懂的方程，但会为我们提供所需的高阶精度。作为一致性检查，很容易验证，如果 $k_n=k_{n-1}$  ，它可以还原成与上面相同的方程。

最后我们注意到，选择高阶时间步进方案当然会迫使我们在内存中保留更多的时间步进；特别是，我们在这里需要保留 $T^{n-2}$ ，这是一个我们以前可以抛弃的向量。这似乎是一个麻烦，我们以前可以通过使用一阶时间步进方案来避免，但是正如我们在下面讨论稳定化问题时看到的那样，我们无论如何都需要这个向量，因此在时间离散化中保留它基本上是免费的，并给我们提供了使用高阶方案的机会。




<h4>Weak form and space discretization for the Stokes part</h4>

像解决混合拉普拉斯方程一样，解决斯托克斯方程需要我们为速度和压力变量选择特定的有限元对。因为这在步骤22中已经讨论过了，所以我们只简单介绍一下这个话题。这里，我们使用稳定对 $Q_{p+1}^d \times Q_p, p\ge 1$  。这些都是连续元素，所以我们可以通过部分积分和用离散函数替代连续函数来形成斯托克斯方程的弱形式，没有问题。

@f{eqnarray*}
  (\nabla {\mathbf v}_h, 2\eta \varepsilon ({\mathbf u}^{n-1}_h))


  -
  (\nabla \cdot {\mathbf v}_h, p^{n-1}_h)
  &=&


  -({\mathbf v}_h, \rho\; \beta \; T^{n-1}_h \mathbf{g}),
  \\
  (q_h, \nabla \cdot {\mathbf u}^{n-1}_h) &=& 0,


@f}

为所有测试函数  $\mathbf v_h, q_h$  。第一个方程的第一项被认为是张量之间的内积，即 $(\nabla {\mathbf v}_h, \eta \varepsilon ({\mathbf u}^{n-1}_h))_\Omega
 = \int_\Omega \sum_{i,j=1}^d [\nabla {\mathbf v}_h]_{ij}
           \eta [\varepsilon ({\mathbf u}^{n-1}_h)]_{ij}\, dx$  。因为这个乘积中的第二个张量是对称的，所以 $\nabla {\mathbf v}_h$ 的反对称分量不起作用，如果我们用 $\mathbf v_h$ 的对称梯度代替，会导致完全一样的形式。因此，我们考虑并实施的表述是

@f{eqnarray*}
  (\varepsilon({\mathbf v}_h), 2\eta \varepsilon ({\mathbf u}^{n-1}_h))


  -
  (\nabla \cdot {\mathbf v}_h, p^{n-1}_h)
  &=&


  -({\mathbf v}_h, \rho\; \beta \; T^{n-1}_h \mathbf{g}),
  \\
  (q_h, \nabla \cdot {\mathbf u}^{n-1}_h) &=& 0.


@f}



这与我们在第22步中已经讨论过的完全一样，这里就不多说了。




<h4>Stabilization, weak form and space discretization for the temperature equation</h4>

更有趣的问题是如何处理温度平流-扩散方程。默认情况下，并不是所有这个方程的离散化都是同样稳定的，除非我们要么做一些像上卷、稳定化，或者所有这些的事情。实现这一点的方法之一是使用不连续元素（即我们在步骤12中离散传输方程或在步骤20和步骤21中离散压力时使用的FE_DGQ类），并在单元间的界面上定义一个考虑到上卷的流量。如果我们有一个纯粹的平流问题，这可能是最简单的方法。然而，这里我们也有一些扩散，用不连续元素对拉普拉斯算子进行离散化是很麻烦的，因为有大量的附加项需要在单元间的每个面上进行积分。不连续元素还有一个缺点，即使用数值通量会带来额外的数值扩散，这种扩散无处不在，而我们真的希望将数值扩散的影响降到最低，只在需要稳定方案的地方应用它。

因此，一个更好的选择是在模型中加入一些非线性粘度。从本质上讲，这样做的目的是将温度方程的形式从

@f{eqnarray*}
  \frac{\partial T}{\partial t}
  +
  {\mathbf u} \cdot \nabla T


  -
  \nabla \cdot \kappa \nabla T &=& \gamma


@f}

到类似于

@f{eqnarray*}
  \frac{\partial T}{\partial t}
  +
  {\mathbf u} \cdot \nabla T


  -
  \nabla \cdot (\kappa+\nu(T)) \nabla T &=& \gamma,


@f}

其中 $\nu(T)$ 是一个额外的粘度（扩散）项，只在冲击和其他不连续点附近发挥作用。   $\nu(T)$ 的选择方式是，如果 $T$ 满足原始方程，则额外的粘性为零。

为了实现这一点，文献中包含了许多方法。我们在这里将遵循Guermond和Popov开发的一种方法，它建立在一个适当定义的残差和一个额外粘度的极限程序之上。为此，让我们定义一个残差 $R_\alpha(T)$ 如下。

@f{eqnarray*}
  R_\alpha(T)
  =
  \left(
  \frac{\partial T}{\partial t}
  +
  {\mathbf u} \cdot \nabla T


  -
  \nabla \cdot \kappa \nabla T - \gamma
  \right)
  T^{\alpha-1}


@f}

其中，我们以后将从 $[1,2]$ 范围内选择稳定指数 $\alpha$ 。请注意，如果 $T$ 满足温度方程， $R_\alpha(T)$ 将为零，因为此时括号内的项将为零。将条款相乘，我们得到以下完全等同的形式。

@f{eqnarray*}
  R_\alpha(T)
  =
  \frac 1\alpha
  \frac{\partial (T^\alpha)}{\partial t}
  +
  \frac 1\alpha
  {\mathbf u} \cdot \nabla (T^\alpha)


  -
  \frac 1\alpha
  \nabla \cdot \kappa \nabla (T^\alpha)
  +
  \kappa(\alpha-1)
  T^{\alpha-2} |\nabla T|^2


  -
  \gamma
  T^{\alpha-1}


@f}



有了这个残差，我们现在可以把人工黏度定义为一个片状常数函数，在直径为 $K$ 的每个单元上分别定义如下。

@f{eqnarray*}
  \nu_\alpha(T)|_K
  =
  \beta
  \|\mathbf{u}\|_{L^\infty(K)}
  \min\left\{
    h_K,
    h_K^\alpha
    \frac{\|R_\alpha(T)\|_{L^\infty(K)}}{c(\mathbf{u},T)}
  \right\}


@f}



这里， $\beta$ 是一个稳定常数（通过维度分析发现它是无单位的，因此与比例无关；我们将在<a href="#Results">results section</a>中讨论其选择）， $c(\mathbf{u},T)$ 是一个归一化常数，其单位必须是 $\frac{m^{\alpha-1}K^\alpha}{s}$  。我们将选择它作为 $c(\mathbf{u},T) =
 c_R\ \|\mathbf{u}\|_{L^\infty(\Omega)} \ \mathrm{var}(T)
 \ |\mathrm{diam}(\Omega)|^{\alpha-2}$  ，其中 $\mathrm{var}(T)=\max_\Omega T - \min_\Omega T$ 是目前温度值的范围（记住，浮力是由温度变化驱动的，而不是绝对温度）， $c_R$ 是一个无尺寸常数。为了理解这个方法为什么有效，请考虑这个问题。如果在一个特定的单元 $K$ 上，温度场是平滑的，那么我们希望那里的残差很小（事实上是在 ${\cal O}(h_K)$ 的数量级上），注入人工扩散的稳定项在那里的大小将是 $h_K^{\alpha+1}$ &mdash；也就是说，相当小，就像我们希望它在没有必要进行额外扩散时那样。另一方面，如果我们处于或接近温度场的不连续性，那么残差将很大； $\nu_\alpha(T)$ 定义中的最小操作将确保稳定项的大小为 $h_K$ &mdash；这是确保方案稳定的最佳人工粘性量。

这种方案是否真的有效是个好问题。Guermond和Popov的计算表明，这种形式的稳定方案实际上比其他大多数稳定方案（例如流线扩散，仅举最简单的一种）表现得更好。此外，对于 $\alpha\in
[1,2)$ ，他们甚至可以证明，对于线性传输方程，它比流线扩散产生更好的收敛阶数。对于 $\alpha=2$ ，目前还没有理论结果，但数值测试表明，其结果比 $\alpha=1$ 好得多。

一个更实际的问题是如何将这种人工扩散引入我们想要解决的方程。请注意，数值粘度 $\nu(T)$ 是随温度变化的，所以我们要解决的方程在 $T$ 中是非线性的&mdash；这不是人们对稳定方程的简单方法的期望，如果我们意识到 $\nu(T)$ 在 $T$ 中是不可分的，那就更不可能了。然而，我们没有理由绝望：我们仍然要在时间上进行离散，我们可以明确地处理这个术语。

在稳定参数的定义中，我们用  $\frac{\partial T}{\partial t} \approx
\frac{T^{n-1}-T^{n-2}}{k^{n-1}}$  对时间导数进行近似。这种近似只利用了可用的时间数据，这就是我们需要存储前两个时间步骤的数据的原因（这使我们能够使用BDF-2方案而不需要额外的存储成本）。我们现在可以简单地在 $t_{n-1}$ 处评估其余的项，但这样一来，离散残差无非是一个向后的欧拉近似，它只有一阶精度。因此，在平滑解的情况下，尽管外部BDF-2方案和空间FE离散化的时间精度为二阶，但残差仍为 $h$ 阶。这当然不是我们想要的（事实上，我们希望在解决方案表现良好的区域有较小的残差），所以需要更谨慎一些。这个问题的关键是观察我们构造的第一导数实际上是以 $t_{n-\frac{3}{2}}$ 为中心的。如果我们通过使用近似值 $\frac 12 T^{n-1}+\frac 12 T^{n-2}$ 来评估 $t_{n-\frac{3}{2}}$ 处的所有空间项，我们就可以得到所需的二阶精确残差计算，这意味着我们将非线性粘度计算为这个中间温度的函数， $\nu_\alpha =
\nu_\alpha\left(\frac 12 T^{n-1}+\frac 12 T^{n-2}\right)$  。请注意，这种对残差的评估无非是一个Crank-Nicholson方案，所以我们可以肯定，现在一切正常了。人们可能会想，现在的数值粘度没有在时间 $n$ 进行评估（相对于方程的其余部分），这是否是一个问题。然而，这种偏移是不严谨的。对于平滑解， $\nu_\alpha$ 将连续变化，所以时间偏移的误差比非线性粘度本身要小 $k$ 倍，也就是说，它是被遗漏的一个小的高阶贡献。这很好，因为该项本身已经达到了光滑区域的离散化误差水平。

使用上面介绍的BDF-2方案，这就得到了更简单的大小为 $k$ 的均匀时间步长的情况。

@f{eqnarray*}
  \frac 32 T^n


  -
  k\nabla \cdot \kappa \nabla T^n
  &=&
  2 T^{n-1}


  -
  \frac 12 T^{n-2}
  \\
  &&
  +
  k\nabla \cdot
  \left[
    \nu_\alpha\left(\frac 12 T^{n-1}+\frac 12 T^{n-2}\right)
    \ \nabla (2T^{n-1}-T^{n-2})
  \right]
  \\
  &&


  -
  k(2{\mathbf u}^{n-1}-{\mathbf u}^{n-2}) \cdot \nabla (2T^{n-1}-T^{n-2})
  \\
  &&
  +
  k\gamma.


@f}

在这个方程的左侧仍然是来自时间导数的项和我们隐含处理的原始（物理）扩散（这实际上是一个很好的项：从左侧产生的矩阵是质量矩阵和拉普拉斯矩阵的倍数&mdash；两者都是正定的，如果时间步长 $k$ 很小，和很容易反转）。在右侧，第一行的条款是时间导数的结果；第二行是时间 $t_{n-\frac
32}$ 的人工扩散；第三行包含平流条款，第四行是来源。请注意，人工扩散对当前时间的外推温度的作用，与我们在时间步进一节中讨论的平流作用相同。

我们在现实中必须使用的非均匀时间步长的形式要复杂一些（这就是为什么我们先展示了上面的简单形式），其内容为：。

@f{eqnarray*}
  \frac{2k_n+k_{n-1}}{k_n+k_{n-1}} T^n


  -
  k_n\nabla \cdot \kappa \nabla T^n
  &=&
  \frac{k_n+k_{n-1}}{k_{n-1}} T^{n-1}


  -
  \frac{k_n^2}{k_{n-1}(k_n+k_{n-1})} T^{n-2}
  \\
  &&
  +
  k_n\nabla \cdot
  \left[
    \nu_\alpha\left(\frac 12 T^{n-1}+\frac 12 T^{n-2}\right)
    \ \nabla  \left[
    \left(1+\frac{k_n}{k_{n-1}}\right)T^{n-1}-\frac{k_n}{k_{n-1}}T^{n-2}
  \right]
  \right]
  \\
  &&


  -
  k_n
  \left[
    \left(1+\frac{k_n}{k_{n-1}}\right){\mathbf u}^{n-1} -
    \frac{k_n}{k_{n-1}}{\mathbf u}^{n-2}
  \right]
  \cdot \nabla
  \left[
    \left(1+\frac{k_n}{k_{n-1}}\right)T^{n-1}-\frac{k_n}{k_{n-1}}T^{n-2}
  \right]
  \\
  &&
  +
  k_n\gamma.


@f}



在解决了所有这些问题之后，弱形式自然而然地从最后一个方程中显示的强形式中产生，我们立即得出了离散化方程的弱形式。

@f{eqnarray*}
  \frac{2k_n+k_{n-1}}{k_n+k_{n-1}} (\tau_h,T_h^n)
  +
  k_n (\nabla \tau_h, \kappa \nabla T_h^n)
  &=&
  \biggl(\tau_h,
  \frac{k_n+k_{n-1}}{k_{n-1}} T_h^{n-1}


  -
  \frac{k_n^2}{k_{n-1}(k_n+k_{n-1})} T_h^{n-2}
  \\
  &&\qquad


  -
  k_n
  \left[
    \left(1+\frac{k_n}{k_{n-1}}\right){\mathbf u}^{n-1} -
    \frac{k_n}{k_{n-1}}{\mathbf u}^{n-2}
  \right]
  \cdot \nabla
  \left[
    \left(1+\frac{k_n}{k_{n-1}}\right)T^{n-1}-\frac{k_n}{k_{n-1}}T^{n-2}
  \right]
  +
  k_n\gamma \biggr)
  \\
  &&


  -
  k_n \left(\nabla \tau_h,
    \nu_\alpha\left(\frac 12 T_h^{n-1}+\frac 12 T_h^{n-2}\right)
    \ \nabla \left[
    \left(1+\frac{k_n}{k_{n-1}}\right)T^{n-1}-\frac{k_n}{k_{n-1}}T^{n-2}
  \right]
  \right)


@f}

为所有离散测试函数  $\tau_h$  。在这里，扩散项已经被部分整合，我们已经使用，我们将施加没有热通量，  $\mathbf{n}\cdot\kappa\nabla T|_{\partial\Omega}=0$  。

这就产生了一个矩阵方程，其形式为

@f{eqnarray*}
  \left( \frac{2k_n+k_{n-1}}{k_n+k_{n-1}} M+k_n A_T\right) T_h^n
  = F(U_h^{n-1}, U_h^{n-2},T_h^{n-1},T_h^{n-2}),


@f}

考虑到左边的矩阵结构（两个正定矩阵之和），使用共轭梯度法很容易解决这个问题。




<h4>Linear solvers</h4>

如上所述，我们解决速度/压力和温度的联合系统的方法是使用算子分割，我们首先用旧的温度场解决速度和压力的斯托克斯系统，然后用刚刚计算的速度场解决新的温度场。关于算子分割方法的更广泛的讨论可以在步骤58中找到）。




<h5>Linear solvers for the Stokes problem</h5>

解决来自斯托克斯系统的线性方程已经在步骤22中进行了详细的讨论。特别是在该程序的结果部分，我们讨论了一些替代的线性求解器策略，结果发现这些策略比原来的方法更有效。在那里确定的最佳替代方案是使用一个由涉及舒尔补码的块状矩阵预处理的GMRES求解器。具体来说，斯托克斯算子导致了一个块状结构的矩阵

@f{eqnarray*}
  \left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)


@f}

正如那里所讨论的，一个好的预处理程序是

@f{eqnarray*}
  P
  =
  \left(\begin{array}{cc}
    A & 0 \\ B & -S
  \end{array}\right),
  \qquad
  \text{or equivalently}
  \qquad
  P^{-1}
  =
  \left(\begin{array}{cc}
    A^{-1} & 0 \\ S^{-1} B A^{-1} & -S^{-1}
  \end{array}\right)


@f}

其中 $S$ 是斯托克斯算子的舒尔补 $S=B^TA^{-1}B$  。当然，这个预处理程序是没有用的，因为我们不能形成矩阵的各种倒数，但我们可以用下面的方法作为预处理程序。

@f{eqnarray*}
  \tilde P^{-1}
  =
  \left(\begin{array}{cc}
    \tilde A^{-1} & 0 \\ \tilde S^{-1} B \tilde A^{-1} & -\tilde S^{-1}
  \end{array}\right)


@f}

其中 $\tilde A^{-1},\tilde S^{-1}$ 是反矩阵的近似值。特别是，事实证明 $S$ 在光谱上等同于质量矩阵，因此，用适用于压力空间上的质量矩阵的CG求解器取代 $\tilde
S^{-1}$ 是一个不错的选择。与步骤22稍有不同的是，我们在这里的动量方程中有一个系数 $\eta$ ，通过与那里相同的推导，我们应该得出结论，我们应该使用的是具有条目 $\tilde S_{ij}=(\eta^{-1}\varphi_i,\varphi_j)$ 的加权质量矩阵。

想出一个好的替代方案 $\tilde
A^{-1}$ 更为复杂，它对应于矢量值速度场的离散化对称拉普拉斯，即 $A_{ij} = (\varepsilon {\mathbf v}_i, 2\eta \varepsilon ({\mathbf
v}_j))$  。在步骤22中，我们用 $A$ 的稀疏LU分解（使用SparseDirectUMFPACK类）来代替 $\tilde A^{-1}$ &mdash; 完美的前置条件&mdash; 在2D中，但对于3D来说，内存和计算时间通常不足以实际计算这个分解；因此，我们在3D中只使用不完全LU分解（ILU，使用稀疏ILU类）。

对于这个项目，我们想走得更远一点。为此，请注意，矢量场上的对称化双线性形式 $(\varepsilon {\mathbf v}_i, 2 \eta \varepsilon ({\mathbf v}_j))$ 与非对称化版本 $(\nabla {\mathbf v}_i, \eta \nabla {\mathbf v}_j)
= \sum_{k,l=1}^d
  (\partial_k ({\mathbf v}_i)_l, \eta \partial_k ({\mathbf v}_j)_l)
$ 相差不大（请注意，在这个形式中因子2已经消失了）。然而，后者的优点是测试函数的 <code>dim</code> 矢量分量不是耦合的（好吧，几乎是，见下文），也就是说，得到的矩阵是块对角线的：每个矢量分量有一个块，这些块中的每个都等于这个矢量分量的拉普拉斯矩阵。因此，假设我们以这样的方式排列自由度，即首先对速度的所有 $x$ 分量进行编号，然后是 $y$ 分量，然后是 $z$ 分量，那么与这种稍有不同的双线性形式相关的矩阵 $\hat A$ 具有如下形式

@f{eqnarray*}
  \hat A =
  \left(\begin{array}{ccc}
    A_s & 0 & 0 \\ 0 & A_s & 0 \\ 0 & 0 & A_s
  \end{array}\right)


@f}

其中 $A_s$ 是一个拉普拉斯矩阵，其大小等于与矢量值速度的每个分量相关的形状函数数量。有了这个矩阵，我们就可以对速度矩阵 $A$ 的预处理进行如下定义。

@f{eqnarray*}
  \tilde A^{-1} =
  \left(\begin{array}{ccc}
    \tilde A_s^{-1} & 0 & 0 \\
    0 & \tilde A_s^{-1} & 0 \\
    0 & 0 & \tilde A_s^{-1}
  \end{array}\right),


@f}

其中 $\tilde A_s^{-1}$ 是拉普拉斯矩阵的预处理程序&mdash;我们非常清楚如何建立良好的预处理程序!

在现实中，故事并不那么简单。为了使矩阵 $\tilde A$ 确定，我们需要通过应用边界条件使各个块 $\tilde
A_s$ 确定。我们可以尝试通过在边界周围应用狄氏边界条件来做到这一点，然后，如果后者的矩阵是由斯托克斯问题产生的，我们在领域周围的速度分量上也有狄氏边界条件，即如果我们执行 $\mathbf{u} =
0$ ，那么如此定义的前置条件 $\tilde A^{-1}$ 就变成了 $A$ 的良好前置条件。

不幸的是，这个 "如果 "是 "如果且仅是如果"：在下面的程序中，我们将希望使用 $\mathbf u
\cdot \mathbf n = 0$ 形式的无流量边界条件（即允许与边界平行的流量%，但没有通过边界的流量）。在这种情况下，事实证明，上面定义的块状对角线矩阵不是一个好的预处理程序，因为它忽略了边界上的成分耦合。因此，更好的方法是如果我们将矩阵 $\hat A$ 建立为矢量拉普拉斯矩阵 $\hat A_{ij} = (\nabla {\mathbf v}_i,
\eta \nabla {\mathbf v}_j)$ ，然后应用与我们应用于 $A$ 相同的边界条件。如果这是一个围绕域的迪里希特边界条件， $\hat A$ 将像上面那样解耦为三个对角线块，如果边界条件是 $\mathbf u
\cdot \mathbf n = 0$ 的形式，那么这将在边界引入自由度的耦合，但只在那里。事实上，这被证明是一个比上面介绍的更好的预处理程序，而且几乎具有我们希望得到的所有好处。


总结这整个故事，我们可以看到。   <ul>   <li>  与我们在步骤22中从对称梯度产生的原始矩阵 $A$ 建立一个预处理程序相比，我们不得不期待基于拉普拉斯双线性形式的预处理程序表现得更差，因为它没有考虑到向量分量之间的耦合。

    <li> 另一方面，拉普拉斯矩阵的预处理程序通常比矢量问题的预处理程序更成熟，性能更好。例如，在写这篇文章的时候，代数%多重网格（AMG）算法对于标量问题已经非常成熟，但对于矢量问题却不是如此。

    <li> 在建立这个预处理程序时，我们将不得不建立矩阵 $\hat A$ 及其预处理程序。虽然这意味着我们必须存储一个之前不需要的额外矩阵，但与存储耦合矩阵 $A$ 的预处理程序相比，预处理程序 $\tilde A_s^{-1}$ 可能需要的内存要少得多。这是因为矩阵 $A_s$ 每行只有三分之一的条目对应于内部自由度，并且只在边界条件引入耦合的部分包含向量分量之间的耦合。因此，存储该矩阵是比较便宜的，我们可以预期，计算和存储预处理程序 $\tilde A_s$ 也将比为完全耦合的矩阵做这些事情便宜得多。   </ul> 




<h5>Linear solvers for the temperature equation</h5>

这是最容易的部分。温度方程的矩阵具有 $\alpha M + \beta A$ 的形式，其中 $M,A$ 是温度空间上的质量和刚度矩阵， $\alpha,\beta$ 是与时间步进方案以及当前和前一个时间步进有关的常数。这是一个对称正定和一个对称正半定矩阵之和，其结果也是对称正定的。此外， $\frac\beta\alpha$ 是一个与时间步长成正比的数字，因此只要网格很细就会变小，从而阻尼当时条件不好的刚度矩阵的影响。

因此，用共轭梯度算法反转这个矩阵，使用一个简单的预处理程序，与反转斯托克斯矩阵相比是微不足道和非常便宜的。




<h3>Implementation details</h3>

<h4>Using different DoFHandler objects</h4>

关于下面的程序，值得事先解释的一件事是使用了两个不同的DoFHandler对象。如果看一下上述方程的结构和它们的求解方案，就会发现几乎没有什么共同点能使斯托克斯部分和温度部分保持一致。在我们以前讨论 @ref
vector_valued "矢量值问题 "的所有教程程序中，我们总是只使用一个具有几个矢量分量的单一有限元，以及一个DoFHandler对象。有时，我们将得到的矩阵分解成若干块，以方便特定的求解器方案；例如，在目前程序所依据的斯托克斯方程的第22步程序中就是如此。

当然，我们在这里也可以这样做。我们将得到的线性系统看起来像这样。

@f{eqnarray*}
  \left(\begin{array}{ccc}
    A & B^T & 0 \\ B & 0 &0 \\ C & 0 & K
  \end{array}\right)
  \left(\begin{array}{ccc}
    U^{n-1} \\ P^{n-1} \\ T^n
  \end{array}\right)
  =
  \left(\begin{array}{ccc}
    F_U(T^{n-1}) \\ 0 \\ F_T(U^{n-1},U^{n-2},T^{n-1},T^{n-2})
  \end{array}\right).


@f}

这方面的问题是。我们从未同时使用整个矩阵。事实上，它从未真正同时存在。如上所述， $K$ 和 $F_T$ 依赖于已经计算出的解 $U^n$ ，在第一种情况下，通过时间步长（这依赖于 $U^n$ ，因为它必须满足CFL条件）。所以我们只有在已经解决了左上角 $2\times 2$ 块斯托克斯系统后才能组装它，一旦我们转向温度方程，我们就不再需要斯托克斯部分了；我们为一个在任何时候都不会以整体存在于内存中的矩阵建立一个对象，这导致我们在步骤21中跳了一些圈套，所以我们不要重复这类错误。此外，我们实际上并没有建立矩阵 $C$ ：因为当我们进入温度方程时，我们已经知道了 $U^n$ ，而且因为我们必须在这个时候组装右手边的 $F_T$ ，我们只是将项 $CU^n$ 移到右手边，并将其与所有其他项组装在一起。这意味着矩阵中不存在温度变量和斯托克斯变量耦合的部分，因此所有自由度的全局列举不再重要：如果我们有所有斯托克斯自由度的列举，以及所有温度自由度的独立列举就足够了。

从本质上讲，将<i>everything</i>放入一个块状矩阵中并没有什么用处（当然，对于 $2\times 2$ 斯托克斯部分，也有同样好的理由这样做），或者，就这一点而言，将所有东西放入同一个DoFHandler对象。

但这样做是否有<i>downsides</i>的好处？这些问题是存在的，尽管它们一开始可能并不明显。主要问题是，如果我们需要创建一个包含速度、压力和温度形状函数的全局有限元，并使用它来初始化DoFHandler。但是我们也用这个有限元对象来初始化我们使用的所有FEValues或FEFaceValues对象。这可能看起来不是什么大问题，但是想象一下，例如，当我们评估我们需要计算人工粘度 $
  R_\alpha(T)
  =
  \left(
  \frac{\partial T}{\partial t}
  +
  {\mathbf u} \cdot \nabla T


  -
  \nabla \cdot \kappa \nabla T - \gamma
  \right)
  T^{\alpha-1}
$ 的残差 $\nu_\alpha(T)|_K$ 时会发生什么。  为此，我们需要温度的拉普拉斯，我们使用形状函数的二阶导数（Hessians）张量来计算（为此我们必须给FEValues对象加上 <code>update_hessians</code> 标志）。现在，如果我们有一个包含速度、压力和温度的形状函数的有限性，这意味着我们必须计算<i>all</i>形状函数的Hessians，包括速度的许多高阶形状函数。这是很多我们不需要的计算，事实上，如果一个人要这样做（就像我们在程序的早期版本中那样），组装右手边需要大约四分之一的整体计算时间。

所以我们要做的是使用两个不同的有限元对象，一个用于斯托克斯成分，一个用于温度。这样就有两个不同的DoFHandlers，两个稀疏模式和两个用于斯托克斯和温度部分的矩阵，等等。每当我们要组装包含温度和斯托克斯形状函数的东西时（特别是斯托克斯和温度方程的右侧），我们就使用两个FEValues对象，用两个单元格迭代器进行初始化，通过与同一三角化对象相关的两个DoFHandler对象进行平行行走。对于这两个FEValues对象，我们当然使用相同的正交对象，这样我们就可以在同一组正交点上进行迭代，但是每个FEValues对象将只根据它实际需要计算的内容来获得更新标志。特别是，当我们像上面那样计算残差时，我们只要求得到斯托克斯形状函数的值，但也要求得到温度形状函数的Hessians &mdash；确实便宜得多，而且事实证明：组装温度方程的右手边现在是程序中几乎无法测量的一个组成部分。

有了这些变化，对程序进行计时，可以得出只有以下操作与整个运行时间有关。   <ul>   <li>  解决斯托克斯系统：72%的运行时间。     <li>  组装斯托克斯预处理程序，并使用Trilinos ML包计算代数多网格层次结构：占运行时间的11%。     <li>  函数  <code>BoussinesqFlowProblem::setup_dofs</code>  : 占整体运行时间的7%。     <li>  组装斯托克斯和温度右侧向量以及组装矩阵。7%.   </ul>  实质上这意味着除了代数多重网格之外，所有的瓶颈都已经被移除。




<h4>Using Trilinos</h4>

与我们在第17步和第18步中使用PETSc来支持我们的线性代数需求一样，我们在这个程序中使用了<a
href="http://trilinos.org">Trilinos</a>库的接口（安装说明见deal.II README文件）。Trilinos是一个非常大的集合，包括与线性和非线性代数有关的所有东西，以及围绕这些东西的各种工具（看起来它在未来也会向许多其他方向发展）。

使用Trilinos的主要原因，类似于我们探索的PETSc，是它是一个非常强大的库，比deal.II自己的线性代数库提供了很多工具。这尤其包括在集群上以%parallel方式工作的能力，使用MPI，以及更多种类的前置条件器。在后一类中，最有趣的能力之一是Trilinos ML包的存在，它实现了代数多栅（AMG）方法。我们将使用这个预处理程序对动量方程的二阶算子部分进行预处理。在步骤32中，我们将使用与这里讨论的相同的问题，探索以%并行方式解决问题的能力。

我们在第17步和第18步中使用的PETSc无疑是一个强大的库，它提供了大量处理矩阵、向量、迭代求解器和预处理器的函数，还有很多其他的东西，其中大部分在%parallel中运行得相当好。然而，它比Trilinos早了几年，是用C语言编写的，而且一般来说不像其他一些库那样容易使用。因此，deal.II也获得了与Trilinos的接口，Trilinos与PETSc有很多相同的功能。然而，它是一个年轻了好几年的项目，是用C++编写的，其作者一般都非常重视软件设计。




<h3>The testcase</h3>

我们在这里要解决的情况如下：我们用 $\kappa=10^{-6}, \eta=1, \rho=1, \beta=10$ 来解决上述的Boussinesq方程，即一个相对缓慢运动的流体，它几乎没有热扩散传导性，主要通过对流来传输热量。在边界上，我们将要求速度（ $\mathrm{n}\cdot\mathrm{u}=0$ ）和温度（ $\mathrm{n}\cdot\nabla T=0$ ）没有正态流量。这是在步骤22的介绍中讨论的情况之一，它固定了速度的一个分量，同时允许流动与边界%平行。还有 <code>dim-1</code> 分量需要固定，即法向应力的切向分量；对于这些分量，我们选择同质条件，这意味着我们不需要任何特殊条件。初始条件只对温度场是必要的，我们选择它为恒定的零。

然后，问题的演变完全由温度方程的右手边 $\gamma(\mathrm{x},t)$ 驱动，即由热源和汇驱动。在这里，我们选择了一个在圣诞讲座前发明的设置：美国的教室里当然禁止使用真实的蜡烛，但允许使用虚拟的蜡烛。因此，我们选择了三个球形的热源，不等距地靠近领域的底部，模仿三个蜡烛的样子。位于这些热源处的流体，最初处于静止状态，然后被加热，随着温度的升高，获得浮力，上升；更多的流体被拖上来，穿过热源，导致三个热羽上升，直到它们被外面下沉的流体循环所捕获，取代了因加热而上升的空气。


examples/step-31/doc/results.dox



<h1>Results</h1>

<h3> Results in 2d </h3>

当你在2D中运行该程序时，输出将看起来像这样。<code> <pre> 活动单元的数量：256（在5层） 自由度的数量：3556（2178+289+1089)

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：0.919118温度的9次CG迭代。    温度范围：-0.16687 1.30011

活动单元的数量：280（在6层） 自由度的数量：4062（2490+327+1245）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：0.459559温度的9次CG迭代。    温度范围：-0.0982971 0.598503

活动单元的数量：520（在7个层面上） 自由度的数量：7432（4562+589+2281）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：0.229779 温度的9次CG迭代。    温度范围：-0.0551098 0.294493

活动单元的数量：1072（在8层） 自由度的数量：15294（9398+1197+4699）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：0.11489 温度的9次CG迭代。    温度范围：-0.0273524 0.156861

活动单元的数量：2116（在9层） 自由度的数量：30114（18518+2337+9259）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：0.0574449温度的9次CG迭代。    温度范围：-0.014993 0.0738328

时间步骤1：t=0.0574449 装配...    解决...    斯托克斯子系统的56次GMRES迭代。    时间步长：0.0574449 温度的9次CG迭代。    温度范围：-0.0273934 0.14488

...</pre> </code>

在开始的时候，我们自适应地细化了几次网格，并总是返回到时间步长为零的新细化的网格上重新开始。只有这样，我们才开始实际的时间迭代。

程序运行了一段时间。时间步数为0、500、1000、1500、2000、3000、4000和5000的温度字段看起来是这样的（注意温度使用的色标并不总是相同）。

 <table align="center" class="doxtable">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.00.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.01.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.02.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.03.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.04.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.05.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.06.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.solution.07.png" alt="">
    </td>
  </tr>
</table> 

这里显示的视觉效果是使用实例的一个版本生成的，该版本在传输网格后没有强制执行约束。

可以看出，我们有三个加热流体的热源，因此产生了一个浮力效应，让流体的热袋上升并旋转起来。通过烟囱效应，这三股气流被来自外部并想加入上升气流的流体压在一起。请注意，由于流体最初处于静止状态，那些最初在源头上的流体部分比后来被充分发展的流场拖到源头上的流体获得更长的加热时间。因此，它更热，这一事实可以从三个羽流的红色尖端看出。还要注意流场的相对精细的特征，这是我们选择的温度方程的复杂传输稳定的结果。

除了上面的图片外，下面的图片显示了自适应网格和同一时间步长的流场。

 <table align="center" class="doxtable">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.00.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.01.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.02.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.03.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.04.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.05.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.06.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.2d.grid.07.png" alt="">
    </td>
  </tr>
</table> 




<h3> Results in 3d </h3>

当然，同样的事情也可以在3D中完成，将 <code>main()</code> 中的BoussinesqFlowProblem对象的模板参数从2改为3，这样，现在的输出看起来如下。

<code> <pre> 活动单元的数量：64（在3层） 自由度的数量：3041（2187+125+729）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：2.45098 温度的9次CG迭代。    温度范围：-0.675683 4.94725

活动单元的数量：288（在4层） 自由度的数量：12379（8943+455+2981）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：1.22549 温度的9次CG迭代。    温度范围：-0.527701 2.25764

活动单元的数量：1296（在5层） 自由度的数量：51497（37305+1757+12435）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：0.612745温度的10次CG迭代。    温度范围：-0.496942 0.847395

活动单元的数量：5048（在6层） 自由度的数量：192425（139569+6333+46523）。

时间步数0: t=0 正在组装...    重建斯托克斯预处理程序...    解算...    0次GMRES迭代，用于斯托克斯子系统。    时间步长：0.306373 温度的10次CG迭代。    温度范围：-0.267683 0.497739

时间步数1：t=0.306373 正在组装...    解决...    斯托克斯子系统的27次GMRES迭代。    时间步长：0.306373 温度的10次CG迭代。    温度范围：-0.461787 0.958679

...</pre> </code>

在时间步数为0、50、100、150、200、300、400、500、600、700和800的情况下，将温度等值线可视化，得到以下图示。

 <table align="center" class="doxtable">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.00.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.01.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.02.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.03.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.04.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.05.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.06.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.07.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.08.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.09.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.3d.solution.10.png" alt="">
    </td>
    <td>
    </td>
  </tr>
</table> 

第一张图片看起来像三只刺猬，这是因为我们的方案基本上是将源乘以第一时间步长投射到网格上，以获得第一时间步的温度场。由于源函数是不连续的，我们需要期待这个项目的过冲和欠冲。这就是事实上发生的情况（在2d中更容易检查），并导致等值面的皱缩外观。  这里显示的视觉效果是使用例子的一个版本生成的，该版本在传输网格后没有强制执行约束。




<h3> Numerical experiments to determine optimal parameters </h3>

现在的程序有三个参数，我们在理论上并没有掌握如何以最佳方式进行选择。这三个参数是。   <ul>   <li>  时间步骤必须满足CFL条件  $k\le \min_K \frac{c_kh_K}{\|\mathbf{u}\|_{L^\infty(K)}}$  。这里， $c_k$ 是无量纲的，但什么是正确的值？     <li>  在计算人工黏度时。

@f{eqnarray*}
  \nu_\alpha(T)|_K
  =
  \beta
  \|\mathbf{u}\|_{L^\infty(K)}
  \min\left\{
    h_K,
    h_K^\alpha
    \frac{\|R_\alpha(T)\|_{L^\infty(K)}}{c(\mathbf{u},T)}
  \right\},


@f}

      与 $c(\mathbf{u},T) =
      c_R\ \|\mathbf{u}\|_{L^\infty(\Omega)} \ \mathrm{var}(T)
      \ |\mathrm{diam}(\Omega)|^{\alpha-2}$  。       这里，无量纲%数 $\beta,c_R$ 的选择是有意义的。   </ul>  在所有这些情况下，我们将不得不期望每个值的正确选择取决于其他值的正确选择，而且很可能也取决于用于温度的有限元的空间尺寸和多项式程度。下面我们将讨论一些数值实验来选择常数  $c_k$  和  $\beta$  。

下面，我们将不讨论 $c_R$ 的选择问题。在程序中，我们将其设定为 $c_R=2^{\frac{4-2\alpha}{d}}$  。这个值的原因有点复杂，与程序的历史而不是推理有关：虽然全局缩放参数 $c(\mathbf{u},T)$ 的正确公式如上所示，但程序（包括与deal.II 6.2一起出厂的版本）最初有一个错误，即我们计算的是 $c(\mathbf{u},T) =
      \|\mathbf{u}\|_{L^\infty(\Omega)} \ \mathrm{var}(T)
      \ \frac{1}{|\mathrm{diam}(\Omega)|^{\alpha-2}}$ ，而在这里我们将缩放参数设置为1。由于我们只在 $\mathrm{diam}(\Omega)=2^{1/d}$ 的单位平方/立方体上进行计算，这完全等同于使用 $c_R=\left(2^{1/d}\right)^{4-2\alpha}=2^{\frac{4-2\alpha}{d}}$ 的正确公式。由于 $c_R$ 的这个值对于当前的程序来说似乎很好用，我们在程序中修正了公式，并将 $c_R$ 设置为一个值，正好再现了我们之前的结果。不过，我们将在第32步中再次审视这个问题。

然而，现在回到讨论 $c_k$ 和 $\beta$ 的什么值来选择。




<h4> Choosing <i>c<sub>k</sub></i><i>c<sub>k</sub></i> and beta </h4> 。

这两个常数肯定在某种程度上有联系。原因很容易看出来。在纯平流问题的情况下， $\frac{\partial T}{\partial t} + \mathbf{u}\cdot\nabla T = \gamma$ ，任何显式方案都必须满足形式为 $k\le \min_K \frac{c_k^a h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ 的CFL条件。另一方面，对于纯扩散问题， $\frac{\partial T}{\partial t} + \nu \Delta T = \gamma$ ，显式方案需要满足一个条件 $k\le \min_K \frac{c_k^d h_K^2}{\nu}$ 。因此，鉴于上述 $\nu$ 的形式，像我们这里要解决的平流扩散问题将导致一个 $
k\le \min_K \min \left\{
  \frac{c_k^a h_K}{\|\mathbf{u}\|_{L^\infty(K)}},
  \frac{c_k^d h_K^2}{\beta \|\mathbf{u}\|_{L^\infty(K)} h_K}\right\}
  =
  \min_K \left( \min \left\{
  c_k^a,
  \frac{c_k^d}{\beta}\right\}
  \frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}} \right)
$ 的条件。因此，我们必须面对这样一个事实：我们可能想选择 $\beta$ 大一些，以提高数值方案的稳定性（通过增加人工扩散量），但我们必须以更小的、因而更多的时间步骤为代价。因此，在实践中，人们希望尽可能地选择 $\beta$ ，以保持传输问题的充分稳定，同时尽量选择大的时间步长，以减少总体工作量。

要找到正确的平衡，唯一的办法是做一些计算实验。下面是我们的做法。我们稍微修改了程序，允许更少的网格细化（所以我们不一定要等那么久），并选择 $
  \nu(T)|_K
  =
  \beta
  \|\mathbf{u}\|_{L^\infty(K)} h_K
$ 来消除常数 $c_R$ 的影响（我们知道通过使用这个版本的 $\nu(T)$ 作为人工粘度，解决方案是稳定的，但我们可以通过使用这个人工粘度的更复杂的公式来改善情况--即使解决方案更清晰）。然后我们对不同的值 $c_k,\beta$ 运行程序，观察域中的最大和最小温度。我们期望看到的情况是这样的。如果我们选择的时间步长过大（即选择一个比理论上允许的大的 $c_k$ ），那么我们将得到温度的指数式增长。如果我们选择 $\beta$ 太小，那么传输稳定变得不充分，解决方案将显示出明显的振荡，但不是指数级增长。




<h5>Results for Q<sub>1</sub> elements</h5>

下面是我们对 $\beta=0.01, \beta=0.1$ ，和 $\beta=0.5$ ， $c_k$ 的不同选择，以及2d的双线性元素（ <code>temperature_degree=1</code> ）得到的结果。

 <table align="center" class="doxtable">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.timestep.q1.beta=0.01.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.timestep.q1.beta=0.03.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.timestep.q1.beta=0.1.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.timestep.q1.beta=0.5.png" alt="">
    </td>
  </tr>
</table> 

解释这些图表的方法是这样的：对于 $\beta=0.01$ 和 $c_k=\frac 12,\frac 14$ ，我们看到指数增长或至少是大的变化，但如果我们选择 $k=\frac 18\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ 或更小，那么这个方案虽然有点摇摆不定，但还是稳定的。对于更多的人工扩散，我们可以选择 $k=\frac 14\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ 或更小的 $\beta=0.03$ ， $k=\frac 13\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ 或更小的 $\beta=0.1$ ，并再次需要 $k=\frac 1{15}\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ 的 $\beta=0.5$ （这次是因为许多扩散需要一个小的时间步长）。

那么该如何选择呢？如果我们只是对大时间步长感兴趣，那么我们会选择 $\beta=0.1$ 和 $k=\frac 13\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$  。另一方面，我们也对准确性感兴趣，在这里，实际调查这些曲线所显示的内容可能会有兴趣。为此，请注意，我们从零温度开始，我们的来源是正的&mdash；所以我们会直观地期望温度永远不会降到零以下。但它确实如此，这是使用连续元素来近似不连续的解决方案时，吉布现象的结果。因此，我们可以看到，选择 $\beta$ 太小是不好的：太少的人工扩散会导致没有扩散掉的过冲和欠冲。另一方面，对于大的 $\beta$ ，最低温度在开始时下降到零以下，但随后迅速扩散回零。

另一方面，我们也来看看最高温度。观察溶液的电影，我们看到最初流体处于静止状态。源头不断加热相同体积的流体，其温度在开始时呈线性增长，直到其浮力能够使其向上移动。因此，流体中最热的部分被带离了溶液，取而代之的流体只被加热了很短的时间就被移出了源区，因此仍然比初始气泡要冷。如果 $\kappa=0$ （在程序中是非零的，但非常小），那么流体中最热的部分应该随着流动而平移，其温度不变。这就是我们在最小的 $\beta$ 图中可以看到的：一旦达到最高温度，它就几乎不再变化。另一方面，人工扩散越大，热点的扩散就越多。请注意，对于这个标准，时间步长的大小并不发挥重要作用。

因此，总结起来，可能最好的选择似乎是 $\beta=0.03$ 和 $k=\frac 14\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$  。曲线有点摇摆不定，但总的来说，图片看起来相当合理，除了由于吉布现象而在接近开始时间时出现一些过冲和欠冲的情况。




<h5>Results for Q<sub>2</sub> elements</h5>

我们也可以对高阶元素重复同样的实验序列。这里是温度的双二次方形状函数（ <code>temperature_degree=2</code> ）的图形，同时我们保留了斯托克斯系统的 $Q_2/Q_1$ 稳定泰勒-胡德元素。

 <table align="center" class="doxtable">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.timestep.q2.beta=0.01.png" alt="">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.timestep.q2.beta=0.03.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-31.timestep.q2.beta=0.1.png" alt="">
    </td>
  </tr>
</table> 

同样， $\beta$ 的小值会导致较少的扩散，但我们必须选择非常小的时间步长来保持事情的控制。太大的 $\beta$ 值会导致更多的扩散，但同样需要小的时间步骤。最佳值似乎是 $\beta=0.03$ ，和 $Q_1$ 元素一样，然后我们必须选择 $k=\frac 18\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ &mdash；正好是 $Q_1$ 元素的一半大小。]元素，如果我们把CFL条件说成是要求时间步长足够小，以便运输在每个时间步长中的移动距离不超过一个<i>grid point</i>距离（对于 $Q_1$ 元素是 $h_K$ ，但对于 $Q_2$ 元素是 $h_K/2$ ），这个事实可能并不令人惊讶。事实证明， $\beta$ 需要稍微大一点，以便在模拟后期获得稳定的结果，时间大于60，所以我们实际上在代码中选择它作为 $\beta = 0.034$ 。




<h5>Results for 3d</h5>

我们可以在3D中重复这些实验，找到每个 $\beta$ 值的最佳时间步骤，并找到 $\beta$ 的最佳值。人们发现，对于2d中已经使用的相同的 $\beta$ ，时间步长需要小一点，大约是1.2倍左右。这很容易解释：时间步长的限制是 $k=\min_K \frac{ch_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ ，其中 $h_K$ 是单元的<i>diameter</i>。然而，真正需要的是网格点之间的距离，它是 $\frac{h_K}{\sqrt{d}}$  。所以更合适的形式是  $k=\min_K \frac{ch_K}{\|\mathbf{u}\|_{L^\infty(K)}\sqrt{d}}$  。

第二个发现是，需要把 $\beta$ 选得稍微大一点（大约 $\beta=0.05$ 左右）。这就再次减少了我们可以采取的时间步骤。







<h5>Conclusions</h5>

总之，从上面的简单计算来看， $\beta=0.034$ 似乎是2D中稳定参数的一个好选择，而 $\beta=0.05$ 则是3D中的稳定参数。以独立于维度的方式，我们可以将其建模为 $\beta=0.017d$  。如果在更细的网格上做更长时间的计算（几千个时间步长），就会意识到时间步长还不够小，为了稳定，就必须把上述数值再降低一些（大约是 $\frac 78$ 的一个系数）。

因此，调和2D、3D和可变多项式程度并考虑到所有因素的公式如下。

@f{eqnarray*}
  k =
  \frac 1{2 \cdot 1.7} \frac 1{\sqrt{d}}
  \frac 2d
  \frac 1{q_T}
  \frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}
  =
  \frac 1{1.7 d\sqrt{d}}
  \frac 1{q_T}
  \frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}.


@f}

在第一种形式中（方程中心）， $\frac
1{2 \cdot 1.7}$ 是一个通用常数， $\frac 1{\sqrt{d}}$ 是说明单元直径和网格点间距的因素， $\frac 2d$ 说明 $\beta$ 随着空间尺寸的增加而增加， $\frac 1{q_T}$ 说明高阶元素的网格点之间的距离， $\frac{h_K}{\|\mathbf{u}\|_{L^\infty(K)}}$ 说明相对于单元尺寸的局部传输速度。这就是我们在程序中使用的公式。

至于对温度使用 $Q_1$ 或 $Q_2$ 元素的问题，以下考虑可能是有用的。首先，解决温度方程在整个方案中几乎不是一个因素，因为几乎所有的计算时间都用于解决每个时间步骤中的斯托克斯系统。因此，温度方程的高阶元素并不是一个重要的缺点。另一方面，如果比较一下由于不连续的源描述而产生的过冲和欠冲的大小，我们会注意到，对于上述 $\beta$ 和 $k$ 的选择， $Q_1$ 的解决方案下降到 $-0.47$ 左右，而 $Q_2$ 的解决方案只到 $-0.13$ （记住，精确解决方案根本不应该变成负数。这意味着 $Q_2$ 解明显更准确；因此程序使用这些高阶元素，尽管我们在较小的时间步长方面付出了代价。




<h3> Possibilities for extensions </h3>

有各种方法来扩展当前的程序。当然，特别感兴趣的是使其更快和/或提高程序的分辨率，特别是在3D方面。这就是step-32教程程序的主题，它将实现在集群上以%并行方式解决这个问题的策略。它也是更大的开放源代码ASPECT（见https://aspect.geodynamics.org/）的基础，它可以解决现实问题，并构成step-32的进一步发展。

另一个方向是使流体流动更加真实。这个程序最初是为了模拟各种情况，模拟地幔中的物质对流，即外地核和固体地壳之间的区域：在那里，物质从下面被加热，从上面被冷却，导致热对流。然而，这种流体的物理学要比这个程序中显示的复杂得多。地幔材料的粘度与温度有很大的关系，即 $\eta=\eta(T)$ ，这种关系经常被模拟为粘度随温度升高而呈指数下降。其次，地幔的大部分动态是由化学反应决定的，主要是构成地幔的各种晶体的相变；然后，斯托克斯方程右边的浮力项不仅取决于温度，而且还取决于某个特定位置的化学成分，这些化学成分被流场平流，但也作为压力和温度的函数而变化。我们将在以后的教程程序中也研究其中的一些影响。


examples/step-32/doc/intro.dox

 <br> 

<i>This program was contributed by Martin Kronbichler, Wolfgang
Bangerth, and Timo Heister.


This material is based upon work partly supported by the National
Science Foundation under Award No. EAR-0426271 and The California Institute of
Technology; and in a continuation by the National Science
Foundation under Award No. EAR-0949446 and The University of California
&ndash; Davis. Any opinions, findings, and conclusions or recommendations
expressed in this publication are those of the author and do not
necessarily reflect the views of the National Science Foundation, The
California Institute of Technology, or of The University of California
&ndash; Davis.


The work discussed here is also presented in the following publication:
<b>
  M. Kronbichler, T. Heister, W. Bangerth:
  <i>High Accuracy Mantle Convection Simulation through Modern Numerical
  Methods</i><b>
  M. Kronbichler, T. Heister, W. Bangerth:
  <i>High Accuracy Mantle Convection Simulation through Modern Numerical
  Methods</i>, Geophysical Journal International, 2012, 191, 12-29.
  <a href="http://dx.doi.org/10.1111/j.1365-246X.2012.05609.x">[DOI]</a><i>High Accuracy Mantle Convection Simulation through Modern Numerical
  Methods</i>, Geophysical Journal International, 2012, 191, 12-29.
  <a href="http://dx.doi.org/10.1111/j.1365-246X.2012.05609.x">[DOI]</a>
</b><a href="http://dx.doi.org/10.1111/j.1365-246X.2012.05609.x">[DOI]</a>
</b>


The continuation of development of this program has led to the much larger open
source code <i>ASPECT</i><i>ASPECT</i> (see http://aspect.geodynamics.org/) which is much
more flexible in solving many kinds of related problems.
</i>


<a name="Intro"></a>

<h1>Introduction</h1>

这个程序所做的事情与step-31已经做的差不多：它解决了描述温度不平衡的流体运动的Boussinesq方程。因此，我们在step-31中描述的所有方程仍然成立：我们使用相同的有限元方案、相同的时间步进算法和或多或少相同的温度平流-扩散方程的稳定方法来解决相同的一般偏微分方程（只做了些许修改，以适应问题设置的更多现实性）。因此，你可能首先要了解那个程序和它的实现，然后再研究当前的程序。

step-31和当前程序的不同之处在于，在这里，我们想以%并行的方式做事，既利用集群中许多机器的可用性（基于MPI的并行化），也利用一台机器中的许多处理器核心（基于线程的并行化）。因此，本程序的主要工作是引入必要的变化，以利用这些%并行计算资源的可用性。在这方面，它建立在第40步程序的基础上，该程序首先为大部分的%并行功能介绍了必要的类，而第55步则展示了如何为一个矢量值的问题做这件事。

除了这些变化之外，我们还使用了一个略微不同的预处理程序，而且我们将不得不做出一些改变，这与我们在这里想要解决一个<i>realistic</i>问题，而不是一个模型问题有关。特别是后者，将要求我们考虑比例问题，以及所考虑的方程中所有这些参数和系数的实际含义。我们将首先讨论影响数学公式和求解器结构变化的问题，然后讨论如何将事情并行化，最后讨论我们将考虑的实际测试案例。




<h3> Using the "right" pressure </h3>

在步骤31中，我们对速度和压力场使用了以下斯托克斯模型。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=&


  -\rho \; \beta \; T \mathbf{g},
  \\
  \nabla \cdot {\mathbf u} &=& 0.


@f}

第一个等式的右手边显得有点无动于衷。事情其实应该是这样的。我们需要作用在流体上的外力，我们假设这些外力只是由重力给出的。在目前的情况下，我们假设流体确实为了这个重力的目的而轻微膨胀，但还不足以让我们需要修改不可压缩性条件（第二个方程）。这意味着，为了右手边的目的，我们可以假设 $\rho=\rho(T)$  。一个可能不完全合理的假设是，我们可以假设密度作为温度的函数的变化很小，导致形式为 $\rho(T) = \rho_{\text{ref}}
[1-\beta(T-T_{\text{ref}})]$  的表达，即在参考温度下密度等于 $\rho_{\text{ref}}$ ，并且随着温度的升高（随着材料的膨胀）线性下降。然后，力平衡方程看起来正确地写成这样。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=&
  \rho_{\text{ref}} [1-\beta(T-T_{\text{ref}})] \mathbf{g}.


@f}

现在注意到，引力是由重力势产生的，如 $\mathbf g=-\nabla \varphi$  ，因此我们可以将其重新写成如下。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=&


  -\rho_{\text{ref}} \; \beta\; T\; \mathbf{g}


  -\rho_{\text{ref}} [1+\beta T_{\text{ref}}] \nabla\varphi.


@f}

右边的第二个项是与时间无关的，因此我们可以引入一个新的 "动态 "压力 $p_{\text{dyn}}=p+\rho_{\text{ref}}
[1+\beta T_{\text{ref}}] \varphi=p_{\text{total}}-p_{\text{static}}$ ，用它来表示斯托克斯方程。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p_{\text{dyn}} &=&


  -\rho_{\text{ref}} \; \beta \; T \; \mathbf{g},
  \\
  \nabla \cdot {\mathbf u} &=& 0.


@f}

这正是我们在第31步中使用的形式，这样做是合适的，因为流体流动的所有变化只由温度差异导致的动态压力驱动。(换句话说。任何因取标量场的梯度而导致的对右手边的贡献都对速度场没有影响）。)

另一方面，我们在这里将使用考虑总压力的斯托克斯方程的形式来代替。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=&
  \rho(T)\; \mathbf{g},
  \\
  \nabla \cdot {\mathbf u} &=& 0.


@f}

这有几个好处。

- 这样我们就可以在我们的程序中绘制压力图，它实际上显示的是包括温差影响以及上覆岩石的静压力在内的总压力。由于压力没有进一步出现在任何其他方程中，因此使用一个还是另一个，更多的是口味问题，而不是正确性问题。流动场是完全相同的，但我们得到的压力现在可以与地球物理书籍中给出的数值进行比较，例如，在地幔底部的压力。

- 如果我们想让这个模型更加真实，我们就必须考虑到许多材料参数（如粘度、密度等）不仅取决于温度，而且还取决于<i>total</i>压力。

- 上面的模型假设了一个线性依赖 $\rho(T) = \rho_{\text{ref}}
  [1-\beta(T-T_{\text{ref}})]$ ，并假定 $\beta$ 很小。在实践中，情况可能并非如此。事实上，现实的模型肯定不是线性的，而且 $\beta$ 至少在部分温度范围内也可能不小，因为密度的行为不仅大大取决于热膨胀，而且取决于相变。

- 这样做的最后一个原因将在结果部分讨论，涉及到对我们在这里使用的模型的可能扩展。这与我们在这里使用的温度方程（见下文）不包括包含压力的条款这一事实有关。然而，它应该包括：岩石，像气体一样，在你压缩它的时候会升温。因此，上升的物质以绝热方式冷却，而下沉的冷物质以绝热方式升温。我们在下面进一步讨论这个问题。

 @note  然而，这个程序有一个缺点。在地球上，动压比总压要小几个数量级。如果我们使用上述方程并解决所有变量，例如，4位数的精度，那么我们可能会得到正确的速度和总压力，但如果我们通过从总压力中减去静态部分来计算动态压力，我们将完全没有精度  $p_\text{static}=\rho_{\text{ref}}
[1+\beta T_{\text{ref}}] \varphi$  。例如，如果动压比静压小六个数量级，那么我们就需要将总压解到至少七位数的精度，才能得到任何精确的结果。也就是说，在实践中，这并不是一个限制性因素。




<h3> The scaling of discretized equations </h3>

请记住，我们要解决以下方程组。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=&
  \rho(T) \mathbf{g},
  \\
  \nabla \cdot {\mathbf u} &=& 0,
  \\
  \frac{\partial T}{\partial t}
  +
  {\mathbf u} \cdot \nabla T


  -
  \nabla \cdot \kappa \nabla T &=& \gamma,


@f}

用适当的边界条件和初始条件加以补充。正如第31步所讨论的，我们将通过在每个时间步长中首先求解斯托克斯问题，然后将温度方程向前移动一个时间间隔来解决这组方程。

本节所考虑的问题是斯托克斯问题：如果我们像往常一样对其进行离散化，我们会得到一个线性系统

@f{eqnarray*}
  M \; X
  =
  \left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)
  \left(\begin{array}{c}
    U \\ P
  \end{array}\right)
  =
  \left(\begin{array}{c}
    F_U \\ 0
  \end{array}\right)
  =
  F


@f}

在这个程序中，我们将用FGMRES求解器来解决这些问题。这个求解器一直迭代到这些线性方程的残差低于某个公差，也就是说，直到

@f[
  \left\|
  \left(\begin{array}{c}
    F_U - A U^{(k)} - B P^{(k)}
    \\
    B^T U^{(k)}
  \end{array}\right)
  \right\|
  < \text{Tol}.


@f]

从物理单位的角度来看，这没有任何意义：这里涉及的量有物理单位，所以残差的第一部分有单位 $\frac{\text{Pa}}{\text{m}}
\text{m}^{\text{dim}}$ （通过考虑术语 $(\nabla \cdot \mathbf v, p)_{\Omega}$ 和考虑压力有单位 $\text{Pa}=\frac{\text{kg}}{\text{m}\;\text{s}^2}$ 以及积分得到的系数 $\text{m}^{\text{dim}}$ 最容易确定），而残差的第二部分有单位 $\frac{\text{m}^{\text{dim}}}{\text{s}}$  。取这个残差向量的常数将得到一个单位为  $\text{m}^{\text{dim}-1} \sqrt{\left(\text{Pa}\right)^2 +
       \left(\frac{\text{m}}{\text{s}}\right)^2}$  的量。很明显，这样做是没有意义的，而且我们不应该惊讶这样做最终会伤害到我们。

那么，为什么这在这里是个问题，而在第31步却不是呢？原因是一切都很平衡：速度是1，压力也是1，粘度是1，域的直径是 $\sqrt{2}$  。结果是，虽然不符合逻辑，但没有发生什么坏事。另一方面，正如我们将在下面解释的那样，这里的事情不会是那么简单的缩放。   $\eta$ 将在 $10^{21}$ 左右，速度在 $10^{-8}$ 的数量级，压力在 $10^8$ 左右，域的直径是 $10^7$ 。换句话说，第一个方程的数量级将是  $\eta\text{div}\varepsilon(\mathbf u) \approx 10^{21} \frac{10^{-8}}{(10^7)^2}
\approx 10^{-1}$  ，而第二个方程将是  $\text{div}{\mathbf u}\approx \frac{10^{-8}}{10^7} \approx 10^{-15}$  左右。那么，这将导致这样的结果：如果求解器想使残差变小，它几乎会完全集中在第一组方程上，因为它们大得多，而忽略描述质量守恒的发散方程。这正是发生的情况：除非我们将公差设置为极小的值，否则所得到的流场肯定不是无发散的。作为一个辅助问题，事实证明，很难找到一个始终有效的公差；在实践中，人们往往最终得到一个公差，在大多数时间步骤中需要30或40次迭代，而在其他一些时间步骤中需要10,000次。

那么，在这样的情况下，数字分析员该怎么做呢？答案是要从根本上入手，首先确保一切在数学上是一致的。在我们的例子中，这意味着如果我们想联合解决斯托克斯方程组，我们必须对它们进行缩放，使它们都有相同的物理尺寸。在我们的例子中，这意味着将第二个方程乘以具有单位 $\frac{\text{Pa}\;\text{s}}{\text{m}}$ 的东西；一种选择是乘以 $\frac{\eta}{L}$ ，其中 $L$ 是我们领域的典型长度尺度（实验表明最好选择羽流的直径&mdash；大约10公里&mdash；而不是领域的直径）。使用 $\eta$ 和 $L$ 的这些%数，这个系数约为 $10^{17}$ 。因此，我们现在对斯托克斯系统得到这个。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) + \nabla p &=&
  \rho(T) \; \mathbf{g},
  \\
  \frac{\eta}{L} \nabla \cdot {\mathbf u} &=& 0.


@f}

这样做的问题是，结果不再是对称的（我们在左下方有 $\frac{\eta}{L} \nabla \cdot$ ，但在右上方没有它的转置算子）。然而，这可以通过引入一个按比例的压力 $\hat p = \frac{L}{\eta}p$ 来解决，我们得到按比例的方程式

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) +
  \nabla \left(\frac{\eta}{L} \hat p\right) &=&
  \rho(T) \; \mathbf{g},
  \\
  \frac{\eta}{L} \nabla \cdot {\mathbf u} &=& 0.


@f}

这现在是对称的。很明显，我们可以很容易地从我们作为这个程序的结果计算的比例压力 $\hat p$ 中恢复原始压力 $p$ 。

在下面的程序中，我们将引入一个与 <code>EquationData::pressure_scaling</code> 相对应的因子，我们将在系统矩阵和预处理程序的装配中使用这个因子。因为这很烦人而且容易出错，我们将在线性系统的解之后立即恢复未标定的压力，也就是说，解矢量的压力分量将立即被取消标定以检索物理压力。由于求解器使用的是我们可以通过推断以前的解来使用一个好的初始猜测，所以我们也要立即对压力进行缩放<i>before</i>求解。




<h3> Changes to the Stokes preconditioner and solver </h3>

在这个教程程序中，我们应用了步骤31中使用的预处理程序的一个变体。该预处理程序是以块状形式对系统矩阵 $M$ 进行操作，从而使乘积矩阵

@f{eqnarray*}
  P^{-1} M
  =
  \left(\begin{array}{cc}
    A^{-1} & 0 \\ S^{-1} B A^{-1} & -S^{-1}
  \end{array}\right)
  \left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)


@f}

其形式是基于Krylov的迭代求解器，如GMRES，可以在几次迭代中解决。然后，我们用基于矢量拉普拉斯矩阵的AMG预处理程序 $\tilde{A}$ 的作用取代了 $A$ 的精确逆，用压力空间上的质量矩阵 $M_p$ 来逼近舒尔补码 $S = B A^{-1} B^T$ ，并编写了一个<tt>InverseMatrix</tt>类，用于实现 $M_p^{-1}\approx S^{-1}$ 对矢量的作用。在InverseMatrix类中，我们使用了带有不完全Cholesky（IC）预处理的CG求解器来进行内部求解。

我们可以观察到，我们仅仅使用了预处理程序的作用来逼近速度逆 $A^{-1}$ （外部GMRES迭代处理了逆的近似特性），而我们对 $M_p^{-1}$ 使用了或多或少的<i>exact</i>逆，由完全收敛的CG解实现。这似乎是不平衡的，但这种疯狂是有系统的：几乎所有的努力都用在了左上角的区块上，我们将AMG预处理程序应用于此，而即使是压力质量矩阵的精确反转也基本上不需要花费什么。因此，如果它能帮助我们在一定程度上减少总的迭代次数，那么这种努力是值得的。

也就是说，尽管求解器对step-31工作得很好，但我们这里的问题有点复杂（细胞是变形的，压力有数量级的变化，我们要为更复杂的物理学提前做计划），所以我们要稍微改变一些东西。

- 对于更复杂的问题，事实证明，仅仅使用单一的AMG V-循环作为预处理器并不总是足够的。外围求解器在大多数时候都能在合理的迭代次数内收敛（例如，少于50次），但偶尔会出现突然需要700次左右的时间步骤。到底发生了什么，很难确定，但这个问题可以通过对左上角的块使用更精确的求解器来避免。因此，我们要使用CG迭代来反转预处理矩阵的左上块，并使用AMG作为CG求解器的预处理。

- 这样做的缺点是，当然，斯托克斯预处理程序变得更加昂贵（比我们只使用单个V型循环时大约昂贵10倍）。我们的策略是这样的：让我们只用V型循环作为预处理程序做多达30次的GMRES迭代，如果没有收敛，那么在这第一轮迭代后得到的斯托克斯解的最佳近似值，并将其作为我们使用具有相当宽松容忍度的完整内部求解器作为预处理程序的迭代的起始猜测。在我们所有的实验中，这只导致了少数额外迭代的收敛。

- 我们需要注意的一点是，当在前置条件器中使用具有宽松容忍度的CG时，那么 $y = \tilde A^{-1} r$ 就不再是 $r$ 的线性函数（当然，如果我们的求解器中具有非常严格的容忍度，或者我们只应用单一的V型循环，它就是如此）。这是一个问题，因为现在我们的预处理程序不再是一个线性算子；换句话说，每次GMRES使用它时，预处理程序看起来都不一样。标准的GMRES求解器无法处理这个问题，导致收敛缓慢甚至崩溃，但F-GMRES变体正是为了处理这种情况而设计的，我们因此使用了它。

- 另一方面，一旦我们确定使用F-GMRES，我们就可以放宽在倒置 $S$ 的预处理时使用的容忍度。在第31步中，我们对 $\tilde S$ 运行了一个预处理的CG方法，直到残差减少了7个数量级。在这里，我们可以再次宽松一些，因为我们知道外部预处理程序不会受到影响。

- 在第31步中，我们使用了一个左边的预处理程序，首先反转预处理矩阵的左上块，然后应用左下块（发散）的，再反转右下块。换句话说，预处理器的应用起到了左下块三角矩阵的作用。另一种选择是使用右预处理器，这里将是右上块三角化，即我们首先反转右下舒尔补码，应用右上（梯度）算子，然后反转椭圆的左上块。在某种程度上，选择哪一个是一个品味的问题。也就是说，在GMRES类型的求解器中，右预处理有一个明显的优势：我们决定是否应该停止迭代的残差是真正的残差，而不是预处理方程的规范。因此，将其与我们通常使用的停止标准，即右手边向量的规范进行比较要简单得多。在编写这段代码时，我们发现上面讨论的缩放问题也使我们难以确定适合于左预处理线性系统的停止准则，因此本程序使用了右预处理器。

- 在第31步中，我们对舒尔补码预处理中的压力质量矩阵和温度系统的解使用了IC（不完全Cholesky）预处理。在这里，我们原则上也可以这样做，但我们确实选择了一个更简单的预处理程序，即两个系统的雅可比预处理程序。这是因为在这里我们的目标是大规模的并行计算，IC/ILU的分解必须在每个处理器上对本地拥有的自由度逐块执行。这意味着，无论如何，预处理程序会变得更像一个雅可比预处理程序，所以我们宁愿直接从这个变体开始。请注意，我们只对有质量矩阵的CG求解器使用Jacobi预处理，无论如何它们都能提供最佳的（<i>h</i>独立的）收敛性，尽管它们通常需要两倍于IC预处理的迭代次数。

最后，让我们指出，在第31步中，我们通过逼近 $-\text{div}(-\eta\Delta)^{-1}\nabla \approx \frac 1{\eta} \mathbf{1}$ 来计算舒尔补数 $S=B A^{-1} B^T$ 。然而现在，我们已经对 $B$ 和 $B^T$ 算子进行了重新缩放。所以 $S$ 现在应该近似于 $-\frac{\eta}{L}\text{div}(-\eta\Delta)^{-1}\nabla \frac{\eta}{L} \approx
\left(\frac{\eta}{L}\right)^2 \frac 1{\eta} \mathbf{1}$  。我们用这个的右手边的离散形式作为我们对 $\tilde S$ 的近似 $S$ 。




<h3> Changes to the artificial viscosity stabilization </h3>

与第31步类似，我们将使用一个基于方程残差的人工黏度进行稳定。  作为与步骤-31的不同之处，我们将提供两个略有不同的稳定参数的定义。对于 $\alpha=1$ ，我们使用与步骤31相同的定义。

@f{eqnarray*}
  \nu_\alpha(T)|_K
  =
  \nu_1(T)|_K
  =
  \beta
  \|\mathbf{u}\|_{L^\infty(K)}
  h_K
  \min\left\{
    1,
    \frac{\|R_1(T)\|_{L^\infty(K)}}{c(\mathbf{u},T)}
  \right\}


@f}

我们从方程的残差 $\|R_1(T)\|_{L^\infty(K)}$ 中计算粘度，在残差较大的区域（陡峭的梯度周围），由与网格大小 $h_K$ 成比例的扩散来限制粘度。这个定义已被证明对给定的情况， $\alpha = 1$ 在step-31中效果很好，但它通常不如 $\alpha=2$ 的扩散有效。对于这种情况，我们选择一个稍微可读的粘度定义。

@f{eqnarray*}
  \nu_2(T)|_K = \min (\nu_h^\mathrm{max}|_K,\nu_h^\mathrm{E}|_K)


@f}

其中第一项又给出了最大耗散量（类似于一阶上风方案）。

@f{eqnarray*}
  \nu^\mathrm{max}_h|_K = \beta h_K \|\mathbf {u}\|_{L^\infty(K)}


@f}

而熵粘度的定义为

@f{eqnarray*}
  \nu^\mathrm{E}_h|_K = c_R \frac{h_K^2 \|R_\mathrm{2,E}(T)\|_{L^\infty(K)}}
  {\|E(T) - \bar{E}(T)\|_{L^\infty(\Omega)} }.


@f}



这个公式在<i>J.-L. Guermond, R. Pasquetti, \&
B. Popov, 2011.  Entropy viscosity method for nonlinear conservation laws, J.
Comput. Phys., 230, 4248--4267.</i>一文中有描述。与 $\alpha = 1$ 的情况相比，残差是由温度熵计算出来的， $T_m$ 是平均温度（我们在计算中选择最高和最低温度之间的平均值），这就得到了以下公式

@f{eqnarray*}
 R_\mathrm{E}(T) = \frac{\partial E(T)}{\partial t} +
    (T-T_\mathrm{m}) \left(\mathbf{u} \cdot \nabla T -  \kappa \nabla^2 T - \gamma\right).


@f}

 $\nu^\mathrm{E}_h|_K$ 公式中的分母被计算为熵与空间平均熵的整体偏差  $\bar{E}(T) =
\int_\Omega E(T) d\mathbf{x}/\int_\Omega d\mathbf{x}$  。如同在步骤31中，我们根据前两个时间层次的温度和速度来评估人工黏度，以避免其定义中的非线性。

上述粘度的定义很简单，但取决于两个参数，即  $\beta$  和  $c_R$  。  对于目前的程序，我们想在 $\alpha =1$ 的情况下对这两个参数更系统地去解决这个问题，使用我们在步骤31的结果部分选择离散化的另外两个参数 $c_k$ 和 $\beta$ 的相同推理。特别是，请记住，我们希望使人工粘度尽可能小，同时保持必要的大。在下文中，让我们描述一下人们可能遵循的一般策略。这里显示的计算是用程序的早期版本完成的，因此你在运行程序时得到的实际数值可能不再与这里显示的数值一致；尽管如此，一般的方法仍然有效，并已被用于寻找程序中实际使用的参数值。

为了了解发生了什么，请注意，下面我们将对973和4273开尔文之间的温度施加边界条件，初始条件也选择在这个范围内；出于这些考虑，我们在没有%内部热源或散热器的情况下运行程序，因此温度应该总是在这个范围内，排除任何%内部振荡。如果最低温度下降到973开尔文以下，那么我们需要通过增加 $\beta$ 或减少 $c_R$ 来增加稳定度。

正如我们在第31步所做的那样，我们首先通过使用 "传统 "公式确定 $\beta$ 的最佳值

@f{eqnarray*}
  \nu_\alpha(T)|_K
  =
  \beta
  \|\mathbf{u}\|_{L^\infty(K)}
    h_K,


@f}

我们知道，只要 $\beta$ 足够大，它就是稳定的。在2d中做几百个时间步数（在比程序中显示的网格更粗的网格上，用不同的粘度影响传输速度，从而影响时间步数大小），将产生以下图表。

 <img src="https://www.dealii.org/images/steps/developer/step-32.beta.2d.png" alt=""> 

可以看出， $\beta \le 0.05$ 的数值太小，而 $\beta=0.052$ 似乎是有效的，至少在这里显示的时间范围内。顺便说一句，这里至少有两个问题是人们可能想知道的。首先，当解决方案变得不稳定时，会发生什么？看一下图形输出，我们可以看到，在这些实验所选择的不合理的粗大网格下，大约在 $t=10^{15}$ 秒的时间里，一直向冷的外部边界上升，然后向侧面扩散的热物质羽流开始相互靠近，将中间的冷物质挤出去。这就形成了一个细胞层，流体从两个相对的侧面流入，并向第三个侧面流出，显然，这种情况会在没有足够稳定的情况下产生这些不稳定性。第二：在步骤31中，我们使用了 $\beta=0.015\cdot\text{dim}$ ；为什么这在这里不起作用？这个问题的答案并不完全清楚--稳定参数肯定取决于单元格的形状等因素，在第31步中我们使用的是正方形，而在当前程序中则是梯形。不管具体原因是什么，我们至少有一个 $\beta$ 的值，即2d的0.052，对当前程序有效。在3d中也可以做类似的实验，我们发现 $\beta=0.078$ 是一个很好的选择&mdash; 整齐地引出公式 $\beta=0.026 \cdot \textrm{dim}$  。

有了这个值，我们就可以回到粘度的原始公式 $\nu$ ，并玩弄常数 $c_R$ ，使其尽可能大，以便使 $\nu$ 尽可能小。这样我们就得到了这样的画面。

 <img src="https://www.dealii.org/images/steps/developer/step-32.beta_cr.2d.png" alt=""> 

因此， $c_R=0.1$ 似乎是这里的正确值。虽然这个图形是针对指数 $\alpha=1$ 得到的，但在程序中我们用 $\alpha=2$ 代替，在这种情况下，必须重新调整参数（并观察到 $c_R$ 出现在分子中而不是分母中）。事实证明， $c_R=1$ 与 $\alpha=2$ 一起工作。




<h3> Locally conservative Stokes discretization </h3>

Stokes的标准Taylor-Hood离散化，使用 $Q_{k+1}^d
\times Q_k$ 元素，是全局保守的，即 $\int_{\partial\Omega}
\mathbf n \cdot \mathbf u_h = 0$  。这很容易看出：发散方程的弱形式为  $(q_h, \textrm{div}\; \mathbf u_h)=0, \forall
q_h\in Q_h$  。因为压力空间确实包含函数  $q_h=1$  ，所以我们得到

@f{align*}
  0 = (1, \textrm{div}\; \mathbf u_h)_\Omega
  = \int_\Omega \textrm{div}\; \mathbf u_h
  = \int_{\partial\Omega} \mathbf n \cdot \mathbf u_h


@f}

由发散定理决定。这个性质很重要：如果我们想用速度场 $u_h$ 沿途输送其他量（如电流方程中的温度，但也可以是化学物质的浓度或完全是人为的示踪量），那么守恒性质保证所输送的量保持恒定。

也就是说，在有些应用中，这个<i>global</i>属性是不够的。相反，我们希望它在每个单元上都持有<i>locally</i>。这可以通过使用空间 $Q_{k+1}^d \times DGP_k$ 进行离散化来实现，我们用相同程度的完整多项式的<i>discontinuous</i>空间代替压力的张量积多项式 $k$ 空间。(注意，2d中的张量积多项式包含函数 $1, x, y, xy$ ，而完全多项式只包含函数 $1,x,y$ ) 。这个空间对斯托克斯方程来说是稳定的。

因为空间是不连续的，我们现在可以特别选择测试函数  $q_h(\mathbf x)=\chi_K(\mathbf x)$  ，即单元格  $K$  的特征函数。然后我们以类似于上面的方式得到

@f{align*}
  0
  = (q_h, \textrm{div}\; \mathbf u_h)_\Omega
  = (1, \textrm{div}\; \mathbf u_h)_K
  = \int_K \textrm{div}\; \mathbf u_h
  = \int_{\partial K} \mathbf n \cdot \mathbf u_h,


@f}

显示了单元格 $K$ 的保存属性。这显然对每个细胞都是成立的。

使用这种离散化是有充分理由的。如上所述，这个元素保证了每个单元上平流量的守恒。第二个优点是，我们用作预处理的压力质量矩阵代替了Schur补码，成为块状对角线，因此非常容易反转。然而，也有缺点。首先，现在有更多的压力变量，增加了问题的总体规模，尽管这在实践中似乎没有造成太大的影响。但更重要的是，现在每个单元上的发散是零，而以前不是，这并不能保证发散是点状的小。事实上，我们可以很容易地验证，与标准Taylor-Hood离散化相比，这个离散化的 $L_2$ 准则是<i>larger</i>。然而，两者都以相同的速度收敛到零，因为很容易看到 $\|\textrm{div}\; u_h\|=
\|\textrm{div}\; (u-u_h)\|=
\|\textrm{trace}\; \nabla (u-u_h)\|\le
\|\nabla (u-u_h)\|={\cal O}(h^{k+2})$  。因此，并不是先验的，仅仅因为我们现在有更多的自由度，误差就真的小了。

鉴于这些考虑，目前还不清楚应该选择哪种离散化方式。因此，我们把这个问题留给用户，并在输入文件中规定使用哪个参数。




<h3> Higher order mappings for curved boundaries </h3>

在程序中，我们将使用一个球壳作为域。这意味着域的内部和外部边界不再是 "直的"（我们通常指它们是可以用FlatManifold类表示的双线性表面）。相反，它们是弯曲的，如果我们已经使用高阶有限元来计算速度，那么在程序中使用一个弯曲的近似值似乎是谨慎的。因此，我们将引入一个MappingQ类型的成员变量，表示这样的映射（步骤10和步骤11首次引入这样的映射），我们将在与边界相邻的单元的所有计算中使用。由于这只影响到相对较小的一部分单元格，额外的努力并不是很大，我们将对这些单元格使用四分法映射。ls.




<h3> Parallelization on clusters </h3>

在三维空间中运行具有显著雷利数的对流代码需要大量的计算；在整个地球模拟的情况下，需要一或几亿个未知数的数量。这显然不能用一台机器来完成（至少在2010年我们开始编写这段代码时不能）。因此，我们需要将其并行化。科学代码在计算机集群的多台机器上的并行化几乎总是使用消息传递接口（MPI）来完成。这个程序也不例外，它遵循了第17步和第18步程序的一般精神，尽管在实践中它更多地借用了第40步，在该步中我们首先介绍了当我们想<i>completely</i>分布所有计算时使用的类和策略，而第55步则展示了如何为 @ref vector_valued  "向量值问题"：包括，例如，将网格分割成若干部分，使每个处理器只存储自己的份额和一些幽灵单元，以及使用任何处理器都不可能有足够的内存在本地保存组合解向量的条目的策略。我们的目标是以合理的可扩展性在数百甚至数千台处理器上运行这段代码。

 @note  即使它有一个较大的数字，步骤40在逻辑上是在当前程序之前。第55步的情况也是如此。在你试图理解我们在这里所做的事情之前，你可能会想看看这些程序。

MPI是一个相当笨拙的编程接口。它是一套半面向对象的函数，虽然人们用它在网络上发送数据，但需要明确地描述数据类型，因为MPI函数坚持以 <code>void*</code> 对象的形式获得数据的地址，而不是通过重载或模板自动推断数据类型。我们已经在第17步和第18步中看到，如何通过将所有必要的通信放到deal.II库中，或者在这些程序中放到PETSc中，来避免几乎所有的MPI。我们将在这里做一些类似的事情：就像第40步和第55步一样，deal.II和底层的p4est库负责分配网格所需的所有通信，而我们将让Trilinos库（以及命名空间TrilinosWrappers中的包装器）处理线性代数组件的并行化问题。我们已经在step-31中使用了Trilinos，在这里也会这样做，不同的是我们将使用它的%并行能力。

Trilinos由大量的包组成，实现了基本的%并行线性代数操作（Epetra包），不同的求解器和预处理包，以及对deal.II不太重要的东西（例如。deal.II的Trilinos接口封装了Trilinos提供的许多与PDE求解器相关的东西，并提供了封装类（在命名空间TrilinosWrappers中），使Trilinos的矩阵、向量、求解器和预处理器类看起来与deal.II自己对这些功能的实现非常相同。然而，与deal.II的类相比，如果我们给它们提供必要的信息，它们可以在%并行中使用。因此，有两个Trilinos类我们必须直接处理（而不是通过包装器），这两个类都是Trilinos的Epetra基本线性代数和工具类库的一部分。   <ul>   <li>  Epetra_Comm类是MPI "通信器 "的抽象，也就是说，它描述了多少台机器和哪些机器可以相互通信。   每个分布式对象，如稀疏矩阵或矢量，我们可能想在不同的机器上存储部分，需要有一个通信器对象来知道有多少部分，在哪里可以找到它们，以及如何访问它们。

  在这个程序中，我们只真正使用了一个通信器对象--基于MPI变量 <code>MPI_COMM_WORLD</code> --它包含了<i>all</i>个一起工作的进程。在 $N$ 机器上启动一个进程，但只在其中的一个子集上存储向量，产生一个只包括这个子集的机器的通信器对象是完全合法的；不过，在这里确实没有令人信服的理由这样做。

 <li>  IndexSet类用于描述一个向量的哪些元素或一个矩阵的哪些行应该驻留在作为通信器一部分的当前机器上。要创建这样一个对象，你需要知道（i）元素或行的总数，（ii）你想在本地存储的元素的索引。我们将在下面的 <code>partitioners</code> 函数中设置这些 <code>BoussinesqFlowProblem::setup_dofs</code> ，然后把它交给我们创建的每个%parallel对象。

  与PETSc不同，Trilinos没有假设矢量的元素需要被分割成连续的小块。至少在原则上，我们可以在一个处理器上存储所有偶数索引的元素，在另一个处理器上存储所有奇数索引的元素。当然，这不是很有效率，但这是可能的。此外，这些分区的元素不一定是相互排斥的。这一点很重要，因为在对解决方案进行后处理时，我们需要访问所有本地相关的或至少是本地活跃的自由度（定义见 @ref distributed 上的模块，以及步骤40中的讨论）。那么Trilinos矢量认为哪些元素是本地拥有的，对我们来说并不重要。我们所关心的是，它在本地存储了我们所需要的那些元素。   </ul> 

还有一些与将网格分布到若干处理器上有关的概念；在尝试理解这个程序之前，你可能想看一下 @ref
distributed 模块和步骤40或步骤55。  程序的其余部分几乎完全不知道我们没有完全在本地存储所有对象的事实。有几个地方我们必须将所有单元的循环限制在本地拥有的单元上，或者我们需要区分只存储本地拥有的元素的向量和存储本地相关的所有元素的向量（见 @ref GlossLocallyRelevantDof "这个词汇表条目"），但总的来说，使程序在%parallel中运行所需的大量繁重工作都很好地隐藏在这个程序赖以建立的库中。在任何情况下，当我们在程序代码中看到这些位置时，我们会对它们进行评论。




<h3> Parallelization within individual nodes of a cluster </h3>

使程序并行化的第二个策略是利用这样一个事实，即今天大多数计算机都有一个以上的处理器，它们都可以访问相同的内存。换句话说，在这个模型中，我们不需要明确地说哪块数据在哪里，我们需要的所有数据都可以直接访问，我们要做的就是在可用的处理器之间分割<i>processing</i>这些数据。然后，我们将把它与上述的MPI并行化结合起来，也就是说，我们将让一台机器上的所有处理器一起工作，例如，为这台机器实际 "拥有 "的单元汇集对全局矩阵的局部贡献，而不是为那些被其他机器拥有的单元。我们将把这种策略用于本程序中经常进行的四种操作：组装斯托克斯和温度矩阵，组装形成斯托克斯预处理的矩阵，以及组装温度系统的右手边。

所有这些操作基本上都是这样的：我们需要在 <code>cell-@>subdomain_id()</code> 等于我们机器在用于所有通信的通信器对象中的索引（即 <code>MPI_COMM_WORLD</code>  ，如上所述）的所有单元中循环。我们实际要使用的测试，简明扼要地描述了我们为什么要测试这个条件，是  <code>cell-@>is_locally_owned()</code>  。在每一个这样的单元上，我们需要集合对全局矩阵或向量的局部贡献，然后我们必须将每个单元的贡献复制到全局矩阵或向量中。请注意，第一部分（循环）定义了一个必须发生的迭代器的范围。第二部分，本地贡献的组装是在这个步骤序列中花费大部分CPU时间的事情，也是一个可以在%并行中完成的典型例子：每个单元的贡献完全独立于所有其他单元的贡献。第三部分，复制到全局矩阵中，不能在%parallel中进行，因为我们正在修改一个对象，所以几个线程不能同时读取一个现有的矩阵元素，增加他们的贡献，并将总和写回内存而不产生<a
href="http://en.wikipedia.org/wiki/Race_condition">race condition</a>危险。

deal.II有一个类，正是为这个工作流程而生的。WorkStream，首先在步骤9和步骤13中讨论。它的使用在 @ref threads 模块中也有大量的记录（在 @ref MTWorkStream "WorkStream类 "一节），我们不会在这里重复那里阐述的原理和详细说明，尽管你会想通读这个模块以了解从头开始的空间和每单元数据之间的区别。我只想说，我们需要以下条件。

- 迭代器的范围是我们要处理的那些单元格。这是由FilteredIterator类提供的，它的作用就像deal.II中的其他单元格迭代器一样，只是它跳过了所有不满足特定谓词（即，一个评估为真或假的标准）的单元。在我们的例子中，该谓词是一个单元格是否为本地所有。

- 一个为上面确定的每项任务在每个单元上做工作的函数，即集合对斯托克斯矩阵和预调节器、温度矩阵和温度右侧的局部贡献的函数。这些是下面代码中的 <code>BoussinesqFlowProblem::local_assemble_stokes_system</code> 、 <code>BoussinesqFlowProblem::local_assemble_stokes_preconditioner</code> 、 <code>BoussinesqFlowProblem::local_assemble_temperature_matrix</code> 和 <code>BoussinesqFlowProblem::local_assemble_temperature_rhs</code> 函数。这四个函数都可以有几个实例同时并行运行。

- 将前一个函数的结果复制到全局对象中的函数，并按顺序运行以避免竞赛条件。这些是 <code>BoussinesqFlowProblem::copy_local_to_global_stokes_system</code> 、 <code>BoussinesqFlowProblem::copy_local_to_global_stokes_preconditioner</code> 、 <code>BoussinesqFlowProblem::copy_local_to_global_temperature_matrix</code> 、和 <code>BoussinesqFlowProblem::copy_local_to_global_temperature_rhs</code> 函数。

我们将在实际代码中再评论一些要点，但总的来说，它们的结构应该从  @ref threads  的讨论中清楚。

WorkStream的底层技术识别需要处理的 "任务"（例如，在一个单元上组装本地贡献），并将这些任务自动安排到可用的处理器上。WorkStream通过将迭代器范围分割成合适的小块，自动创建这些任务。

 @note  在每个MPI进程中使用多个线程，只有当你在集群的每个节点上运行的MPI进程少于这台机器上的处理器核心时才有意义。否则，MPI已经让你的处理器很忙了，你不会从使用线程中获得任何额外的速度。例如，如果你的集群节点有8个内核，就像在写这篇文章的时候经常有的那样，如果你的批处理调度程序在每个节点上放8个MPI进程，那么使用线程并不能使程序更快。因此，你可能想在运行之前，要么配置你的deal.II不使用线程，要么将 Utilities::MPI::MPI_InitFinalize 中的线程数设置为1（第三个参数），或者 "export DEAL_II_NUM_THREADS=1"。也就是说，在写这篇文章的时候，我们只用WorkStream类来组装（部分）线性系统，而程序的75%或更多的运行时间是在没有并行化的线性求解器中度过的&mdash;换句话说，我们最好的希望是将剩下的25%并行化。




<h3> The testcase </h3>

这个程序的设置稍微让人想起我们当初想解决的问题（见步骤31的介绍）：地幔的对流。因此，我们选择了以下数据，所有这些数据在程序中都是以米和秒为单位（国际单位制）出现的，即使我们在这里以其他单位列出它们。然而，我们注意到，这些选择基本上仍然只是示范性的，而不是要形成对地幔对流的完全现实的描述：为此，必须实现更多、更困难的物理学，而且目前这个程序中也缺少其他几个方面。我们将在结果部分再次讨论这个问题，但现在要说明的是，在写这篇文章时，提供真实的描述是正在开发的<i>ASPECT</i>代码的一个目标。

作为提醒，让我们再次说明我们要解决的方程是这些。

@f{eqnarray*}


  -\nabla \cdot (2 \eta \varepsilon ({\mathbf u})) +
  \nabla \left( \frac{\eta}{L} \hat p\right) &=&
  \rho(T) \mathbf{g},
  \\
  \frac{\eta}{L} \nabla \cdot {\mathbf u} &=& 0,
  \\
  \frac{\partial T}{\partial t}
  +
  {\mathbf u} \cdot \nabla T


  -
  \nabla \cdot \kappa \nabla T &=& \gamma,


@f}

用边界条件和初始条件增强。然后我们必须选择以下数量的数据。   <ul>   <li>  域是一个环形（2D）或一个球壳（3D），其内外半径与地球的半径一致：地球的总半径为6371km，地幔从大约35km的深度开始（就在由<a target="_top"
  href="http://en.wikipedia.org/wiki/Continental_crust">continental</a>和<a
  target="_top" href="http://en.wikipedia.org/wiki/Oceanic_crust">oceanic
  plates</a>组成的固体地球<a target="_top"
  href="http://en.wikipedia.org/wiki/Crust_(geology)">crust</a>之下）到2890km深度（<a target="_top" href="http://en.wikipedia.org/wiki/Outer_core">outer earth
  core</a>开始）。因此半径为 $R_0=(6371-2890)\text{km},
  R_1=(6371-35)\text{km}$  。这个领域是使用 GridGenerator::hyper_shell() 函数方便地生成的。

    <li>  在地壳和地幔的界面，温度在500到900摄氏度之间，而在其底部则是4000摄氏度左右（例如，见<a target="_top"
  href="http://en.wikipedia.org/wiki/Mantle_(geology)">this Wikipedia
  entry</a>）。因此，在开尔文中，我们选择 $T_0=(4000+273)\text{K}$  ， $T_1=(500+273)\text{K}$ 作为内外边缘的边界条件。

  除此以外，我们还必须为温度场指定一些初始条件。由于已经持续了40多亿年的对流，地球的真实温度场是相当复杂的--事实上，我们正是想通过这样的程序来探索这种温度分布的特性。因此，我们在这里并没有什么有用的东西可以提供，但是我们可以希望，如果我们从一些东西开始，让事情运行一段时间，确切的初始条件就不再那么重要了&mdash; 事实上，通过查看<a href="#Results">results section
  below</a>中显示的图片就可以看出。我们在这里使用的初始温度场是由@f{align*}
    s &= \frac{\|\mathbf x\|-R_0}{R_1-R_0}, \\
    \varphi &= \arctan \frac{y}{x}, \\
    \tau &= s + \frac 15 s(1-s) \sin(6\varphi) q(z), \\
    T(\mathbf x) &= T_0(1-\tau) + T_1\tau,
  @f}给出半径的。

  其中@f{align*}
    q(z) = \left\{
    \begin{array}{ll}
      1 & \text{in 2d} \\
      \max\{0, \cos(\pi |z/R_1|)\} & \text{in 3d}
    \end{array}
    \right. .
  @f}

  这个复杂的函数本质上是内部和外部温度之间的线性轮廓的扰动。在2D中，函数 $\tau=\tau(\mathbf x)$ 看起来是这样的（我从<a
  href="http://www.wolframalpha.com/input/?i=plot+%28sqrt%28x^2%2By^2%29%2B0.2*%28sqrt%28x^2%2By^2%29*%281-sqrt%28x^2%2By^2%29%29*sin%286*atan2%28x%2Cy%29%29%29%2C+x%3D-1+to+1%2C+y%3D-1+to+1">this
  page</a>得到的图片）。

    <img src="https://www.dealii.org/images/steps/developer/step-32.2d-initial.png" alt=""> 

  这个剖面的重点是，如果我们在 $T(\mathbf x)$ 的定义中使用 $s$ 而不是 $\tau$ ，那么它将只是一个线性内插。   $\tau$ 在内部和外部边界具有与 $s$ 相同的函数值（分别为0和1），但它根据角度和3D中的 $z$ 值将温度曲线拉长一些，产生线性内插场的角度依赖性扰动。我们将在结果部分看到，这是一个完全不实际的温度场（尽管它将会产生有趣的图像），因为温度的平衡状态将是一个几乎恒定的温度，在内部和外部边界有边界层。

    <li>  温度方程的右边包含了内部加热%的速率  $\gamma$  。地球确实通过几种机制自然升温：放射性衰变、化学分离（较重的元素沉到底部，较轻的元素升到顶部；逆流耗散的能量相当于这一分离过程中的势能损失）；随着地球内部固体核心的增长，液态金属结晶释放热量；以及流体运动时粘性摩擦产生的热量耗散。

  化学分离很难建模，因为它需要将地幔物质建模为多个相；它也是一个相对较小的效应。结晶热就更难了，因为它只限于温度和压力允许相变的区域，也就是一个不连续的过程。鉴于对这两种现象进行建模的困难，我们将忽略它们。

  另外两个很容易处理，考虑到我们对温度方程进行缩放的方式，可得出方程@f[
    \gamma(\mathbf x)
     =
     \frac{\rho q+2\eta \varepsilon(\mathbf u):\varepsilon(\mathbf u)}
     {\rho c_p},
  @f]

  其中 $q$ 是 $\frac{W}{kg}$ 中的辐射性加热，列举器中的第二项是粘性摩擦加热。   $\rho$  是密度， $c_p$  是比热。文献中提供了以下近似值。   $c_p=1250 \frac{J}{kg\; K}, q=7.4\cdot 10^{-12}\frac{W}{kg}$  .   其他参数将在本节的其他地方讨论。

  我们在这里忽略了一个内部热源，即绝热加热，这将导致一个令人惊讶的温度场。这一点将在下面的结果部分进行详细评论。

    <li> 对于速度，我们在内半径处选择 $\mathbf{v}=0$ 作为边界条件（即流体粘在地心上），在外半径处选择 $\mathbf{n}\cdot\mathbf{v}=0$ （即流体沿地壳底部切向流动）。这两种情况在物理上都不过分正确：当然，在这两个边界上，流体可以切向流动，但它们会通过与界面另一侧的介质（分别是金属核心和地壳）摩擦而产生剪切应力。这样的情况可以用切向速度的罗宾式边界条件来模拟；在这两种情况下，法向（垂直）速度将为零，尽管即使这样也不完全正确，因为大陆板块也有垂直运动（例如，见<a
  href="http://en.wikipedia.org/wiki/Postglacial_rebound">post-glacial
  rebound</a>的现象）。但是，对切向速度来说，另一侧的介质也在运动，这已经使事情变得更糟了，因此，在最简单的情况下，剪应力将与<i>velocity
  difference</i>成正比，导致边界条件的形式为@f{align*}
    \mathbf{n}\cdot [2\eta \varepsilon(\mathbf v)]
    &=
    s \mathbf{n} \times [\mathbf v - \mathbf v_0],
    \\
    \mathbf{n} \cdot \mathbf v &= 0,
  @f}

  有一个比例常数  $s$  。然而，我们没有走这条路，而是选择了零（棒）和切向流的边界条件。

  顺便提一下，我们也可以在内外边界都选择切向流动条件。然而，这有一个明显的缺点：它使速度不是唯一定义的。原因是所有对应于绕域中心旋转的固体体的速度场 $\hat{\mathbf v}$ 都满足 $\mathrm{div}\;
  \varepsilon(\hat{\mathbf v})=0, \mathrm{div} \;\hat{\mathbf v} = 0$ ，和 $\mathbf{n} \cdot \hat{\mathbf v} = 0$ 。因此，如果 $\mathbf v$ 满足方程和边界条件，那么 $\mathbf v +
  \hat{\mathbf v}$  也满足。这当然不是一个我们想避免的好情况。解决这个问题的传统方法是在边界上选一个任意的点，通过选择速度在那里的所有分量为零，将其称为你的固定点。(在三维空间中，必须选择两个点。)由于这个程序开始时并不打算太现实，我们通过简单地固定整个内部边界的速度来避免这种复杂情况。

    <li> 根据第一顺序，重力矢量总是指向下方。对于像地球这样大的物体来说，问题只是："向上 "是什么地方。天真的答案当然是 "径向向内，向地球中心"。所以在地球表面，我们有@f[
    \mathbf g
    =


    -9.81 \frac{\text{m}}{\text{s}^2} \frac{\mathbf x}{\|\mathbf x\|},
  @f]

  其中 $9.81 \frac{\text{m}}{\text{s}^2}$ 刚好是地球表面的平均重力加速度。但是在地球内部，问题变得有点复杂：例如，在地球的（轨道）中心，你有物质在各个方向上同样用力拉扯，所以 $\mathbf g=0$  。在这两者之间，净力的描述如下：让我们用<a target="_top"
  href="http://en.wikipedia.org/wiki/Potential_energy#Gravitational_potential_energy">gravity
  potential</a>来定义@f[
    \varphi(\mathbf x)
    =
    \int_{\text{earth}}


    -G \frac{\rho(\mathbf y)}{\|\mathbf x-\mathbf y\|}
    \ \text{d}y,
  @f] 。

  那么 $\mathbf g(\mathbf x) = -\nabla \varphi(\mathbf x)$  。如果我们假设密度 $\rho$ 在整个地球上是恒定的，我们可以产生一个重力矢量的分析表达式（不要试图以某种方式整合上述方程--它导致了椭圆积分；一个更简单的方法是注意到 $-\Delta\varphi(\mathbf x) = -4\pi G \rho
  \chi_{\text{earth}}(\mathbf x)$ 并利用径向对称性在所有 ${\mathbb R}^3$ 中解决这个偏微分方程）。   @f[
    \mathbf g(\mathbf x) =
    \left\{
      \begin{array}{ll}


        -\frac{4}{3}\pi G \rho \|\mathbf x\| \frac{\mathbf x}{\|\mathbf x\|}
        & \text{for} \ \|\mathbf x\|<R_1, \\


        -\frac{4}{3}\pi G \rho R^3 \frac{1}{\|\mathbf x\|^2}
        \frac{\mathbf x}{\|\mathbf x\|}
        & \text{for} \ \|\mathbf x\|\ge R_1.
      \end{array}
    \right.
  @f]

  因子 $-\frac{\mathbf x}{\|\mathbf x\|}$ 是指向径向内的单位矢量。当然，在这个问题中，我们只对与地球内部有关的分支感兴趣，即 $\|\mathbf
  x\|<R_1$ 。因此，我们将只考虑表达式@f[
    \mathbf g(\mathbf x) =


        -\frac{4}{3}\pi G \rho \|\mathbf x\| \frac{\mathbf x}{\|\mathbf x\|}
        =


        -\frac{4}{3}\pi G \rho \mathbf x
        =


        - 9.81 \frac{\mathbf x}{R_1} \frac{\text{m}}{\text{s}^2},
  @f] 。

  其中我们可以推断出最后一个表达式，因为我们知道地球在表面的重力（其中 $\|x\|=R_1$  ）。

  我们可以通过整合 $\varphi(r)$ 的微分方程，在密度分布是径向对称的情况下，即 $\rho(\mathbf
  x)=\rho(\|\mathbf x\|)=\rho(r)$ ，推导出一个更一般的表达。在这种情况下，我们将得到@f[
    \varphi(r)
    = 4\pi G \int_0^r \frac 1{s^2} \int_0^s t^2 \rho(t) \; dt \; ds.
  @f] 。




  然而，这有两个问题。(i) 地球不是均匀的，即密度 $\rho$ 取决于 $\mathbf x$ ；事实上它甚至不是一个只取决于半径 $r=\|\mathbf x\|$ 的函数。因此，在现实中，重力并不总是随着我们的深入而减少：因为地心比地幔的密度大得多，重力实际上在地心地幔边界的 $10.7
  \frac{\text{m}}{\text{s}^2}$ 左右达到峰值（见<a
  target="_top" href="http://en.wikipedia.org/wiki/Earth's_gravity">this
  article</a>）。(ii) 密度，以及由此产生的重力矢量，在时间上甚至不是恒定的：毕竟，我们要解决的问题是与时间有关的热的、密度较小的物质的上涌和冷的密度大的物质的下涌。这就导致了重力矢量随空间和时间的变化而变化，并不总是直接指向下方。

  为了不使情况变得更加复杂，我们可以使用这样的近似值：在地幔的内部边界，重力是 $10.7 \frac{\text{m}}{\text{s}^2}$ ，在外部边界，重力是 $9.81 \frac{\text{m}}{\text{s}^2}$ ，在每种情况下都是径向向内的，在两者之间，重力随着离地球中心的径向距离而线性变化。也就是说，实际上稍微现实一点，假设（就像我们下面做的那样）地幔具有恒定的密度也不是那么难。在这种情况下，上面的方程可以被整合，我们得到一个 $\|\mathbf{g}\|$ 的表达式，我们可以拟合常数以匹配地幔顶部和底部的重力，得到@f[
    \|\mathbf{g}\|
    = 1.245\cdot 10^{-6} \frac{1}{\textrm{s}^2} r + 7.714\cdot 10^{13} \frac{\textrm{m}^3}{\textrm{s}^2}\frac{1}{r^2}.
  @f]



    <li> 地幔的密度在空间上有变化，但变化幅度不大。   $\rho_{\text{ref}}=3300 \frac{\text{kg}}{\text{m}^3}$ 是参考温度 $T_{\text{ref}}=293$ 开尔文时的密度的一个相对较好的平均值。

    <li>  热膨胀系数 $\beta$ 也随深度变化（通过其对温度和压力的依赖）。在接近地表的地方，它似乎是 $\beta=45\cdot 10^{-6} \frac 1{\text{K}}$ ，而在地心地幔边界，它可能更接近 $\beta=10\cdot
  10^{-6} \frac 1{\text{K}}$ 。作为一个合理的值，让我们选择 $\beta=2\cdot 10^{-5} \frac 1{\text{K}}$ 。那么密度与温度的关系是 $\rho(T)=[1-\beta(T-T_{\text{ref}})]\rho_{\text{ref}}$  。

    <li>  我们需要指定的第二个至最后一个参数是粘度  $\eta$  。这是一个棘手的问题，因为在地幔典型的温度和压力下，岩石的流动非常缓慢，以至于在实验室里无法准确地确定粘度。那么我们如何知道地幔的粘度呢？最常用的方法是考虑在冰期和冰期之后，冰盾形成和消失的时间尺度比地幔流动的时间尺度短。因此，大陆在冰盾的附加重量下慢慢沉入地幔，而在冰盾再次消失后，它们又慢慢升起（这被称为<a target="_top"
  href="http://en.wikipedia.org/wiki/Postglacial_rebound"><i>postglacial
  rebound</i><i>postglacial
  rebound</i></a>）。通过测量这种反弹的速度，我们可以推断出流向反弹的大陆板块下腾出的区域的物质的粘度。

  使用这种技术，发现 $\eta=10^{21} \text{Pa}\;\text{s}
  = 10^{21} \frac{\text{N}\;\text{s}}{\text{m}^2}
  = 10^{21} \frac{\text{kg}}{\text{m}\;\text{s}}$ 附近的数值是最有可能的，尽管这上面的误差至少是一个数量级的。

  虽然我们将使用这个值，但我们不得不再次提醒，有许多物理原因可以假设这不是正确的值。首先，它确实应该取决于温度：较热的材料很可能比较冷的材料的粘性要小。然而，在现实中，情况甚至更为复杂。地幔中的大多数岩石随着温度和压力的变化而发生相变：根据温度和压力的不同，不同的晶体构型在热力学上比其他的更受青睐，即使地幔的化学成分是均匀的。例如，常见的地幔物质MgSiO<sub>3</sub>在整个地幔的大部分地区以其<a target="_top"
  href="http://en.wikipedia.org/wiki/Perovskite_(structure)">perovskite
  structure</a>的形式存在，但在地幔下部，同样的物质只以<a targe="_top"
  href="http://en.wikipedia.org/wiki/Postperovskite">post-perovskite</a>的形式稳定。显然，为了计算现实的粘度，我们不仅需要知道地幔的确切化学成分和所有物质的粘度，而且还必须计算所有物质在每个正交点的热力学上最稳定的配置。在编写这个程序时，这不是一个可行的建议。

    <li>  我们的最后一个材料参数是热扩散率 $\kappa$  ，其定义为 $\kappa=\frac{k}{\rho c_p}$  ，其中 $k$  是热导率， $\rho$  是密度， $c_p$  是比热。对于这一点，文献表明，它从上地幔的 $0.7$ 左右增加到下地幔的 $1.7 \frac{\text{mm}^2}{\text{s}}$ 左右，尽管确切的数值其实并不那么重要：通过对流的热传输比通过热传导的热传输要重要几个数量级。可能有兴趣知道的是，地幔中最丰富的材料--过氧化物，在超过大约120GPa的压力下似乎变得透明（例如，见J. Badro等人，《科学》305，383-386（2004年））；因此，在下地幔中，通过辐射传输的热传输可能比通过热传导更有效。

  鉴于这些考虑，让我们选择 $\kappa=1 \frac{\text{mm}^2}{\text{s}} =10^{-6} \frac{\text{m}^2}{\text{s}}$ 作为本方案的目的。   </ul> 

所有这些方程数据都在程序中定义在 <code>EquationData</code> 命名空间。当运行时，该程序产生的长期最大速度大约为每年10-40厘米（见下面的结果部分），大约是物理上正确的数量级。我们将设定结束时间为10亿年。

 @note  上述常数和材料参数的选择在很大程度上遵循了G.Schubert和D.L.Turcotte和P.Olson（剑桥，2001）的综合书籍《地球和行星的地幔对流，第一部分》。它包含了关于如何使程序更加真实的广泛讨论。




<h3> Implementation details </h3>

与step-31相比，这个程序有一些值得注意的区别。

-  <code>EquationData</code> 命名空间要大得多，这反映了我们现在有更多的物理学需要处理的事实。也就是说，这些额外的物理细节大部分是在这个命名空间的函数中自成一体的，并没有扩散到程序的其他部分。

- 更明显的可见性是，我们把大量的参数放入由ParameterHandler类处理的输入文件中（例如，见步骤29，关于用这个类设置运行时参数文件的方法）。当人们想避免仅仅因为想玩弄一个参数而重新编译程序时，这往往是有意义的（例如，想想确定上面讨论的稳定常数的最佳值的参数研究），特别是考虑到重新编译当前规模的程序需要花费非同小可的时间。为了仅仅概述我们从固定值移入输入文件的参数种类，这里列出了一个典型的 <code>\step-32.prm</code> 文件。   @code
# Listing of Parameters
# ---------------------
# The end time of the simulation in years.
set End time                            = 1e8


# Whether graphical output is to be generated or not. You may not want to get
# graphical output if the number of processors is large.
set Generate graphical output           = false


# The number of adaptive refinement steps performed after initial global
# refinement.
set Initial adaptive refinement         = 1


# The number of global refinement steps performed on the initial coarse mesh,
# before the problem is first solved there.
set Initial global refinement           = 1


# The number of time steps between each generation of graphical output files.
set Time steps between graphical output = 50


# The number of time steps after which the mesh is to be adapted based on
# computed error indicators.
set Time steps between mesh refinement  = 10



subsection Discretization
  # The polynomial degree to use for the velocity variables in the Stokes
  # system.
  set Stokes velocity polynomial degree       = 2


  # The polynomial degree to use for the temperature variable.
  set Temperature polynomial degree           = 2


  # Whether to use a Stokes discretization that is locally conservative at the
  # expense of a larger number of degrees of freedom, or to go with a cheaper
  # discretization that does not locally conserve mass (although it is
  # globally conservative.
  set Use locally conservative discretization = true
end



subsection Stabilization parameters
  # The exponent in the entropy viscosity stabilization.
  set alpha = 2


  # The beta factor in the artificial viscosity stabilization. An appropriate
  # value for 2d is 0.052 and 0.078 for 3d.
  set beta  = 0.078


  # The c_R factor in the entropy viscosity stabilization.
  set c_R   = 0.5
end
  @endcode



- 很明显，有很多变化是与我们想在可能非常多的机器上运行我们的程序这一事实有关的。尽管人们可能会怀疑这需要我们完全重新构建我们的代码，但事实上并非如此（尽管在deal.II中实现大部分功能的类从实现的角度来看肯定非常不同，但这并没有反映在它们的公共接口中）。相反，这些变化大多是微妙的，主类的整体结构几乎没有变化。也就是说，魔鬼在细节中：正确地进行%并行计算，没有死锁，确保正确的数据在正确的地方可用（例如，见关于全分布式向量与有鬼魂元素的向量的讨论），以及避免瓶颈是很困难的，关于这个话题的讨论将出现在本程序中的很多地方。




<h3> Outlook </h3>

这是一个教程性的程序。这意味着至少它的大部分重点需要放在演示如何使用deal.II和相关的库上，而不是通过过度关注物理细节来稀释这个教学课程。尽管上面有关于物理参数选择的长篇大论，但程序中专门讨论这个问题的部分实际上是很短的，而且是自成一体的。

也就是说，第31步和目前的第32步都不是偶然出现的，而肯定是作为通向更全面的计划的路标，该计划将模拟地幔的对流。我们把这个代码称为<i>ASPECT</i>（简称<i>Advanced %Solver for Problems in Earth's
ConvecTion</i>）；它的开发是由<a href="http://www.geodynamics.org">Computational Infrastructure in
Geodynamics</a>计划资助的，得到了美国国家科学基金会的支持。关于<i>ASPECT</i>的更多信息可在其<a href="https://aspect.geodynamics.org/">homepage</a>中找到。


examples/step-32/doc/results.dox



<h1>Results</h1>

当运行时，该程序以与step-31相同的方式模拟三维对流，尽管有一个完全不同的测试案例。




<h3>Comparison of results with \step-31</h3>

然而，在我们讨论这个测试案例之前，让我们展示一下这个程序稍早的版本的一些结果，该版本正是在解决我们在第31步中使用的测试案例，只是我们现在以并行方式解决它，而且分辨率要高很多。我们展示这些结果主要是为了比较。

下面是两张图片，如果我们选择 <code>main()</code> 中的3d计算，以及设置 <code>initial_refinement=3</code> 和 <code>n_pre_refinement_steps=4</code> ，则可以看到这种更高的分辨率。在所示的时间步骤中，网格有大约72,000和236,000个单元，分别为2,680,000和8,250,000个自由度，比我们在步骤31中的可用度多了一个数量级。

 <table align="center" class="doxtable">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-32.3d.cube.0.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-32.3d.cube.1.png" alt="">
    </td>
  </tr>
</table> 

计算是在德克萨斯A&amp;M大学Brazos集群的50个处理器的子集上完成的。




<h3>Results for a 2d circular shell testcase</h3>

接下来，我们将用目录中的参数文件运行step-32，但有一个变化：我们将最终时间增加到1e9。这里我们使用的是16个处理器。启动的命令是（注意，step-32.prm是默认的）。

<code> <pre>  $ mpirun -np 16 ./step-32
</pre>
</code>


Note that running a job on a cluster typically requires going through a job
scheduler, which we won't discuss here. The output will look roughly like
this:


<code>
<pre>
\$  mpirun -np 16 ./step-32 活动单元的数量：12,288（在6层） 自由度的数量：186,624（99,840+36,864+49,920）。

时间步数0：t=0年

   重建斯托克斯预处理程序...    解决斯托克斯系统...41次迭代。    最大速度：60.4935厘米/年 时间步长：18166.9年 温度的17次CG迭代 温度范围：973 4273.16

活动单元的数量：15,921（在7层） 自由度的数量：252,723（136,640+47,763+68,320）。

时间步数0：t=0年

   重建斯托克斯预处理程序...    解决斯托克斯系统...50次迭代。    最大速度：60.3223厘米/年 时间步长：10557.6年 温度的19次CG迭代 温度范围：973 4273.16

活动单元的数量：19,926（在8层） 自由度的数量：321,246（174,312+59,778+87,156）。

时间步数0：t=0年

   重建斯托克斯预处理程序...    解决斯托克斯系统...50次迭代。    最大速度：57.8396厘米/年 时间步长：5453.78年 温度的18次CG迭代 温度范围：973 4273.16

时间步数1：t=5453.78年

   解决斯托克斯系统...49次迭代。    最大速度：59.0231厘米/年 时间步长：5345.86年 温度的18次CG迭代 温度范围：973 4273.16

时间步数2：t=10799.6年

   解决斯托克斯系统...24次迭代。    最大速度：60.2139厘米/年 时间步长：5241.51年 温度的17次CG迭代 温度范围：973 4273.16

[...]

时间步数100：t=272151年

   解决斯托克斯系统......21次迭代。    最大速度：161.546厘米/年 时间步长：1672.96年 温度的17次CG迭代 温度范围：973 4282.57

活动单元的数量：56,085（在8层） 自由度的数量：903,408（490,102+168,255+245,051）。




+---------------------------------------------+------------+------------+ | 从开始到现在，总的壁挂时间经过了115s构建斯托克斯预调节器 | 12 | 2.09s | 1.8% | 解算斯托克斯系统 | 103 | 90.4s | 79% | 解算温度系统 | 103 | 1.53s | 1.3% | 后处理 | 3 | 0.532s | 0.完善网格结构，第一部分 | 12 | 0.93s | 0.81% | 完善网格结构，第二部分 | 12 | 0.384s | 0.33% | 设置阻尼系统 | 13 | 2.96s | 2.6% | +---------------------------------+-----------+------------+------------+

[...]

+---------------------------------------------+------------+------------+ | 从开始到现在总共经过了多少壁挂时间 | 9.14e+04s | | | | 部分 | 调用次数 | 壁挂时间 | 占总数的百分比 | +---------------------------------+-----------+------------+------------+ | 组装斯托克斯系统 | 47045 | 2.05e+03s | 2.2% | 组装温度矩阵 | 4707 | 310s | 0.34% | 组装温度rhs | 47045 | 8.7e+03s | 9.4707 | 1.48e+03s | 1.6% | 解决斯托克斯系统 | 47045 | 7.34e+04s | 80% | 解决温度系统 | 47045 | 1.46e+03s | 1.6% | 后处理 | 1883 | 222s | 0.24% | | 完善网格结构，第一部分 | 4706 | 641s | 0.7% | 完善网格结构，第二部分 | 4706 | 259s | 0.28% | 设置阻尼系统 | 4707 | 1.86e+03s | 2% | +---------------------------------+-----------+------------+------------+ </pre> </code>

当时间达到输入文件中选择的10亿年时，模拟就会终止。  你可以从中推断出不同的最终时间的模拟需要多长时间（时间步长最终确定在20,000年左右，所以计算20亿年需要100,000个时间步长，给或给20%）。  从这里可以看出，我们把大部分的计算时间花在了组装线性系统和&mdash;首先&mdash;解决斯托克斯系统。


为了演示输出，我们在这里展示了每1250个时间步骤的输出。   <table>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-000.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-050.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-100.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-150.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-200.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-250.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-300.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-350.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-400.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-450.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-500.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-550.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-time-600.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-cells.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-32-2d-partition.png" alt="">
    </td>
  </tr>
</table> 

最后两张图片显示了网格以及16个子域和16个处理器的同一计算的网格划分情况。这个模拟的全部动态只有通过看动画才能看到，例如<a
href="https://www.dealii.org/images/steps/developer/step-32-2d-temperature.webm">shown
on this site</a>。由于其艺术质量和对岩浆羽流演变的迷人描述，这个图像非常值得观看。

如果你看电影，你会看到对流模式经历了几个阶段。首先，它摆脱了不稳定的温度分层，热物质被致密的冷物质覆盖。在这个巨大的驱动力被消除后，我们有了一种稳定的情况，几个小球开始从内圈的热边界层中分离出来并上升，几个冷指也从外部边界层中掉下来。在这一阶段，解决方案仍然大部分是对称的，反映了原始网格的12倍对称性。在最后一个阶段，流体进入剧烈的混沌搅拌，其中所有的对称性都消失了。这是一个随后继续主导流动的模式。

如果我们看一下模拟中作为时间函数的最大速度，也可以确定这些不同阶段。

 <img src="https://www.dealii.org/images/steps/developer/step-32.2d.t_vs_vmax.png" alt=""> 

在这里，当温度分层不稳定时，速度（以厘米/年表示）在开始时变得非常大，达到几米/年的数量级）。然后平静下来，变成相对较小的数值，然后在混乱的搅动系统中再次回升。在那里，它保持在每年10-40厘米的范围内，完全在物理上预期的区域内。




<h3>Results for a 3d spherical shell testcase</h3>

三维计算在计算上是非常昂贵的。此外，如上所述，有趣的行为只有在相当长的时间后才开始，需要更多的CPU时间，而不是在一个典型的集群上可用。因此，与其在这里展示一个完整的模拟，不如让我们简单地展示几张图片，我们使用这个程序的后续程序，称为<i>ASPECT</i>（简称<i>Advanced
%Solver for Problems in Earth's ConvecTion</i>），该程序正在独立于deal.II开发，已经包括了下面讨论的一些扩展。下面两张图片显示了温度的等值线和领域（连同网格）在512个处理器上的划分。

<p align="center">  <img src="https://www.dealii.org/images/steps/developer/step-32.3d-sphere.solution.png" alt=""> 

 <img src="https://www.dealii.org/images/steps/developer/step-32.3d-sphere.partition.png" alt="">  </p>  。


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

这个程序有许多可以扩展的方向。正如在介绍的最后提到的，在本教程程序完成时，其中大部分正在<i>ASPECT</i>（简称<i>Advanced %Solver for Problems
in Earth's ConvecTion</i>）代码中积极开发。具体来说，下面这些肯定是人们应该解决的话题，以使程序更加有用。

 <ul>   <li>  <b>Adiabatic heating/cooling:</b> 我们在模拟中得到的温度场在一段时间后大多是恒定的，在内部和外部边界有边界层，冷和热物质的流线混合一切。然而，这并不符合我们的预期，即靠近地心的东西应该比靠近地表的东西更热。原因是我们使用的能量方程不包括一个描述绝热冷却和加热的术语：岩石，像气体一样，在你压缩它的时候会加热。因此，上升的物质以绝热方式冷却，而下沉的冷物质则以绝热方式加热。因此，正确的温度方程看起来有点像这样。   @f{eqnarray*}
    \frac{D T}{Dt}


    -
    \nabla \cdot \kappa \nabla T &=& \gamma + \tau\frac{Dp}{Dt},
  @f}

  或者，扩大平流导数  $\frac{D}{Dt} =
  \frac{\partial}{\partial t} + \mathbf u \cdot \nabla$  : @f{eqnarray*}
    \frac{\partial T}{\partial t}
    +
    {\mathbf u} \cdot \nabla T


    -
    \nabla \cdot \kappa \nabla T &=& \gamma +
    \tau\left\{\frac{\partial
    p}{\partial t} + \mathbf u \cdot \nabla p \right\}.
  @f} 。

  换句话说，随着岩石体积中压力的增加（ $\frac{Dp}{Dt}>0$ ），我们会得到一个额外的热源，反之亦然。

  压力的时间导数实施起来有点困难。如果有必要，我们可以利用导言中概述的事实进行近似，即压力可以分解为由于温差和由此产生的流动而产生的动态部分，以及仅由上层岩石的静压力产生的静态部分。由于后者要大得多，我们可以对 $p\approx p_{\text{static}}=-\rho_{\text{ref}}
  [1+\beta T_{\text{ref}}] \varphi$ 进行近似处理，从而对 $\frac{Dp}{Dt} \approx \left\{- \mathbf u \cdot \nabla \rho_{\text{ref}}
  [1+\beta T_{\text{ref}}]\varphi\right\} = \rho_{\text{ref}}
  [1+\beta T_{\text{ref}}] \mathbf u \cdot \mathbf g$ 进行处理。   换句话说，如果流体沿着重力方向（向下）运动，它将被压缩，因为在这种情况下 $\mathbf u
  \cdot \mathbf g > 0$ 我们得到一个正的热源。反之，如果流体逆着重力方向运动，它将被冷却。

 <li>  <b>Compressibility:</b> 正如在上面的温度模型中已经暗示的那样，地幔岩石不是不可压缩的。相反，鉴于地幔中的巨大压力（在地核-地幔边界，压力约为140GPa，相当于大气压力的140万倍），岩石实际上确实被压缩到它在表面压力下的密度的1.5倍左右。对这一情况进行建模会遇到很多困难。首先，质量守恒方程不再是 $\textrm{div}\;\mathbf u=0$ ，而应该是 $\textrm{div}(\rho\mathbf u)=0$ ，其中密度 $\rho$ 现在不再是空间常数，而是取决于温度和压力。一个后果是，该模型现在不再是线性的；线性化的斯托克斯方程也不再是对称的，需要我们重新考虑预处理程序，甚至可能是离散化。至于如何解决这个问题，我们在这里就不做详细介绍了。

 <li>  <b>Nonlinear material models:</b> 正如在不同地方已经暗示的那样，材料参数，如密度、粘度和各种热参数，在整个地幔中并不恒定。相反，它们非线性地依赖于压力和温度，在粘度的情况下，还依赖于应变率  $\varepsilon(\mathbf u)$  。对于复杂的模型，准确解决这些模型的唯一方法可能是在每个时间步骤中实际迭代出这种依赖关系，而不是简单地将系数冻结在从前一个（几个）时间步骤推算出来的数值上。

 <li>  <b>Checkpoint/restart:</b> 在一些处理器上以2D运行这个程序可以在一两天内解决现实的模型。然而，在3d中，计算时间非常大，以至于会遇到两个典型问题。(i) 在大多数计算集群上，排队系统将单个作业的运行时间限制在2或3天；(ii) 在数百个处理器上运行几天，由于硬件故障、错误配置或断电而丢失计算结果是一种耻辱。这两个问题都可以通过定期保存程序的状态来解决，如果有必要，在这个时候重新启动程序。这种技术通常被称为<i>checkpoint/restart</i>，它要求将程序的整个状态写到一个永久的存储位置（例如硬盘）。考虑到这个程序的数据结构的复杂性，这并不是完全微不足道的（也可能涉及到写入数千兆字节或更多的数据），但可以通过意识到可以在两个时间步骤之间保存状态，其中基本上只包括网格和解向量；在重新启动期间，然后首先以之前的方式重新列举自由度，然后重新组装矩阵。然而，考虑到这里涉及的数据结构的分布性质，保存和恢复程序的状态并不简单。一个额外的复杂性是由以下事实引入的：人们可能希望在两次运行之间改变处理器的数量，例如，因为人们可能希望在一个比用于在中间时间预计算起始温度场的网格更精细的网格上继续计算。

 <li>  <b>Predictive postprocessing:</b> 像这样的计算的重点不是简单地解决方程。相反，它通常是探索不同的物理模型，并将其与我们在地球表面可以测量到的东西进行比较，以发现哪些模型是现实的，哪些是与现实相矛盾的。为此，我们需要从我们的解决方案向量中计算出与我们可以观察到的东西有关的数量。例如，其中包括地球表面的热流，以及整个地幔的地震速度，因为这些影响到地震仪所记录的地震波。

 <li>  <b>Better refinement criteria:</b> 从上面的3D案例可以看出，3D的网格主要是沿着内部边界细化的。这是因为那里的边界层比领域中的任何其他过渡都要强，导致我们几乎只在那里细化，基本上没有沿着羽流的方向细化。我们当然需要更好的细化标准来跟踪我们真正感兴趣的部分，而不是这里使用的标准，即应用于温度的KellyErrorEstimator，能够做到。   </ul> 


还有许多其他方法来扩展当前的程序。然而，与其在这里讨论它们，不如让我们指出更大的开放源代码ASPECT（见https://aspect.geodynamics.org/），它构成了step-32的进一步发展，并且已经包括了许多这样可能的扩展。


examples/step-33/doc/intro.dox

 <br> 

<i>
This program was written for fun by David Neckels (NCAR) while working
at Sandia (on the Wyoming Express bus to and from Corrales each day).
The main purpose was to better understand Euler flow.
The code solves the basic Euler equations of gas dynamics, by using a
fully implicit Newton iteration (inspired by Sandia's Aria code).  The
code may be configured by an input file to run different simulations
on different meshes, with differing boundary conditions.
<br>
The original code and documentation was later slightly modified by Wolfgang
Bangerth to make it more modular and allow replacing the parts that are
specific to the Euler equations by other hyperbolic conservation laws without
too much trouble.
</i>

 @note  程序使用<a
href="http://trilinos.org">Trilinos</a>线性求解器（这些可以在Trilinos的Aztec/Amesos包中找到）和一个自动微分包，Sacado，也是Trilinos的一部分。deal.II必须被配置为使用Trilinos。请参考<a
href="../../readme.html#trilinos">ReadMe</a>文件以了解如何做到这一点。

 @note  虽然这个程序很好地展示了自动微分的使用，但它并没有表达欧拉方程求解器的技术水平。对于这个方程有更快、更准确的方法，你应该看看步骤67和步骤69，看看这个方程如何更有效地得到解决。




<a name="Intro"></a><h1>Introduction</h1> 。

<h3>Euler flow</h3>

描述可压缩、无粘性气体运动的方程（所谓的气体动力学欧拉方程）是一个基本的守恒定律系统。在空间维度 $d$ 中，其内容为

@f[
\partial_t \mathbf{w} + \nabla \cdot \mathbf{F}(\mathbf{w}) =
\mathbf{G}(\mathbf w),


@f]

解 $\mathbf{w}=(\rho v_1,\ldots,\rho v_d,\rho,
E)^{\top}$ 包括 $\rho$ 流体密度， ${\mathbf v}=(v_1,\ldots v_d)^T$ 流速（因此 $\rho\mathbf v$ 是线性动量密度），和 $E$ 气体的能量密度。我们将上述方程式解释为  $\partial_t \mathbf{w}_i + \nabla \cdot \mathbf{F}_i(\mathbf{w}) = \mathbf
G_i(\mathbf w)$  ,  $i=1,\ldots,dim+2$  。

对于欧拉方程，通量矩阵 $\mathbf F$ （或通量函数系统）被定义为（这里显示的是情况 $d=3$ ）。

@f{eqnarray*}
  \mathbf F(\mathbf w)
  =
  \left(
  \begin{array}{ccc}
    \rho v_1^2+p & \rho v_2v_1  & \rho v_3v_1 \\
    \rho v_1v_2  & \rho v_2^2+p & \rho v_3v_2 \\
    \rho v_1v_3  & \rho v_2v_3  & \rho v_3^2+p \\
    \rho v_1 & \rho v_2 & \rho v_3 \\
    (E+p) v_1 & (E+p) v_2 & (E+p) v_3
  \end{array}
  \right),


@f}

我们将只选择重力的影响作为特定的右手边强制力，用以下方式描述

@f{eqnarray*}
  \mathbf G(\mathbf w)
  =
  \left(
  \begin{array}{c}
    g_1\rho \\
    g_2\rho \\
    g_3\rho \\
    0 \\
    \rho \mathbf g \cdot \mathbf v
  \end{array}
  \right),


@f}

其中 $\mathbf g=(g_1,g_2,g_3)^T$ 表示重力矢量。有了这个，整个方程组就变成了：

@f{eqnarray*}
  \partial_t (\rho v_i) + \sum_{s=1}^d \frac{\partial(\rho v_i v_s +
  \delta_{is} p)}{\partial x_s} &=& g_i \rho, \qquad i=1,\dots,d, \\
  \partial_t \rho + \sum_{s=1}^d \frac{\partial(\rho v_s)}{\partial x_s} &=& 0,  \\
  \partial_t E + \sum_{s=1}^d \frac{\partial((E+p)v_s)}{\partial x_s} &=&
  \rho \mathbf g \cdot \mathbf v.


@f}

这些方程分别描述了动量、质量和能量的守恒。该系统被一个定义压力的关系所封闭。   $p =
(\gamma -1)(E-\frac{1}{2} \rho |\mathbf v|^2)$  .对于空气（主要是氮气和氧气）和其他双原子气体的成分，其比热比为  $\gamma=1.4$  。

这个问题显然属于矢量值问题的范畴。关于如何在deal.II中处理这些问题的一般概述可以在 @ref vector_valued 模块中找到。

<h3>Discretization</h3>

考虑到这是一个双曲问题，与步骤12中讨论的简单问题的风格相同，以通常的方式进行微调：我们选择一个有限元空间 $V_h$ ，并针对我们的（矢量值）测试函数 $\mathbf{z} \in V_h$ 积分我们的守恒法。  然后我们通过部分积分，用<i> numerical </i>通量 $\mathbf{H}$ 来近似边界通量。

@f{eqnarray*}
&&\int_{\Omega} (\partial_t \mathbf{w}, \mathbf{z}) + (\nabla \cdot \mathbf{F}(\mathbf{w}), \mathbf{z}) \\
&\approx &\int_{\Omega} (\partial_t \mathbf{w}, \mathbf{z}) - (\mathbf{F}(\mathbf{w}), \nabla \mathbf{z}) + h^{\eta}(\nabla \mathbf{w} , \nabla \mathbf{z}) + \int_{\partial \Omega} (\mathbf{H}(\mathbf{w}^+, \mathbf{w}^-, \mathbf{n}), \mathbf{z}^+),


@f}

其中上标 $+$ 表示一个函数的内部轨迹， $-$ 表示外部轨迹。扩散项 $h^{\eta}(\nabla \mathbf{w} , \nabla \mathbf{z})$ 是严格为了稳定而引入的，其中 $h$ 是网格大小， $\eta$ 是一个参数，规定要增加多少扩散。

在边界上，我们必须说清楚外痕 $\mathbf{w}^-$ 是什么。根据边界条件，我们规定以下两种情况。   <ul>   <li>  流入边界： $\mathbf{w}^-$ 被规定为理想值。   <li>  超音速流出边界： $\mathbf{w}^- = \mathbf{w}^+$   <li>  亚音速流出边界： $\mathbf{w}^- = \mathbf{w}^+$  除了能量变量被修改为支持规定的压力 $p_o$  ，即 $\mathbf{w}^- =(\rho^+, \rho v_1^+, \dots, \rho v_d^+, p_o/(\gamma -1) + 0.5 \rho |\mathbf{v}^+|^2)$   <li>  反射边界：我们设定 $\mathbf{w}^-$  ，使 $(\mathbf{v}^+ + \mathbf{v}^-) \cdot \mathbf{n} = 0$  和 $\rho^- = \rho^+,E^-=E^+$  。   </ul> 

关于这些问题的更多信息可以在Ralf Hartmann的博士论文中找到（"Adaptive Finite Element Methods for the Compressible Euler Equations"，博士论文，海德堡大学，2002）。

我们使用时间步长方案来替代上述方程中的时间导数。为了简单起见，我们将 $ \mathbf{B}({\mathbf{w}_{n}})(\mathbf z) $ 定义为时间步长 $n$ 的空间残差。

@f{eqnarray*}
 \mathbf{B}(\mathbf{w}_{n})(\mathbf z)  &=&


- \int_{\Omega} \left(\mathbf{F}(\mathbf{w}_n),
\nabla\mathbf{z}\right) +  h^{\eta}(\nabla \mathbf{w}_n , \nabla \mathbf{z}) \\
&& +
\int_{\partial \Omega} \left(\mathbf{H}(\mathbf{w}_n^+,
\mathbf{w}^-(\mathbf{w}_n^+), \mathbf{n}), \mathbf{z}\right)


-
\int_{\Omega} \left(\mathbf{G}(\mathbf{w}_n),
\mathbf{z}\right) .


@f}



因此，在每个时间步骤，我们的完全离散化是，应用于任何测试函数 $\mathbf z$ 的残差等于零。

@f{eqnarray*}
R(\mathbf{W}_{n+1})(\mathbf z) &=&
\int_{\Omega} \left(\frac{{\mathbf w}_{n+1} - \mathbf{w}_n}{\delta t},
\mathbf{z}\right)+
\theta \mathbf{B}({\mathbf{w}}_{n+1}) +  (1-\theta) \mathbf{B}({\mathbf w}_{n}) \\
&=& 0


@f}

其中 $ \theta \in [0,1] $ 和 $\mathbf{w}_i = \sum_k \mathbf{W}_i^k \mathbf{\phi}_k$  。选择 $\theta=0$ 的结果是显式（正向）欧拉方案， $\theta=1$ 是稳定的隐式（反向）欧拉方案，而 $\theta=\frac 12$ 是克拉克-尼克尔森方案。

在下面的实现中，我们选择Lax-Friedrichs通量的函数 $\mathbf H$ ，即 $\mathbf{H}(\mathbf{a},\mathbf{b},\mathbf{n}) =
\frac{1}{2}(\mathbf{F}(\mathbf{a})\cdot \mathbf{n} +
\mathbf{F}(\mathbf{b})\cdot \mathbf{n} + \alpha (\mathbf{a} - \mathbf{b}))$ ，其中 $\alpha$ 是输入文件中指定的一个固定数字，或者 $\alpha$ 是一个与网格有关的值。在后一种情况下，它被选为 $\frac{h}{2\delta T}$ ， $h$ 是施加磁通量的面的直径，而 $\delta T$ 是当前的时间步长。

有了这些选择，将残差等同于零就会产生一个非线性方程组  $R(\mathbf{W}_{n+1})=0$  。我们通过牛顿迭代来解决这个非线性系统（与步骤15中解释的方法相同），即通过迭代

@f{eqnarray*}
R'(\mathbf{W}^k_{n+1},\delta \mathbf{W}_{n+1}^k)(\mathbf z) & = & -
R(\mathbf{W}^{k}_{n+1})(\mathbf z) \qquad \qquad \forall \mathbf z\in V_h \\
\mathbf{W}^{k+1}_{n+1} &=& \mathbf{W}^k_{n+1} + \delta \mathbf{W}^k_{n+1},


@f}

直到 $|R(\mathbf{W}^k_{n+1})|$ （残差）足够小。通过用有限元空间的节点基础而不是所有的 $\mathbf z$ 进行测试，我们得出了一个 $\delta \mathbf W$ 的线性系统。

@f{eqnarray*}
\mathbf R'(\mathbf{W}^k_{n+1})\delta \mathbf{W}^k_{n+1} & = & -
\mathbf R(\mathbf{W}^{k}_{n+1}).


@f}

一般来说，这个线性系统既不是对称的，也没有任何特定的确定性属性。我们将使用直接求解器或Trilinos的GMRES实现来解决它。从<a href="#Results">results shown below</a>中可以看出，这种全隐式迭代收敛速度非常快（通常为3步），并具有牛顿方法所期望的二次收敛顺序。




<h3> Automatic differentiation </h3>

由于计算雅各布矩阵 $\mathbf R'(\mathbf W^k)$ 是一个可怕的野兽，我们使用一个自动微分包，Sacado，来做这个。  Sacado是<a
href="http://trilinos.org" target="_top">Trilinos</a>框架内的一个包，提供了一个C++模板类 <code>Sacado::Fad::DFad</code> （ <code>Fad</code> 代表 "前向自动微分"），支持基本算术运算符和函数，如 <code> sqrt, sin, cos, pow, </code> 等。为了使用这个功能，人们声明一个这种类型的变量集合，然后将这个集合中的一些变量表示为自由度，其余的变量是独立变量的函数。  这些变量在算法中被使用，随着变量的使用，它们对自由度的敏感度被持续更新。

可以想象，对于整个雅各布矩阵来说，这可能是非常昂贵的：自变量的数量是 $\mathbf W^k$ ，因变量是向量 $\mathbf
R(\mathbf W^k)$ 的元素。这两个向量很容易有几万个元素或更多。  然而，需要注意的是，并非 $\mathbf R$ 的所有元素都依赖于 $\mathbf W^k$ 的所有元素：事实上， $\mathbf R$ 中的一个条目只依赖于 $\mathbf W^k$ 的一个元素，如果两个相应的形状函数重叠并以弱形式耦合。

具体来说，定义当前单元上的残差可能依赖的最小独立AD变量集是明智的：在每个元素上，我们定义那些对应于定义在这个单元上的自由度的独立变量（或者，如果我们必须计算单元之间的跳转项，则对应于定义在两个相邻单元上的自由度），而因变量是本地残差向量的元素。如果不这样做，即把<i>all</i>和 $\mathbf W^k$ 的元素定义为独立的，将导致大量零的计算非常昂贵：局部残差向量的元素几乎独立于解向量的所有元素，因此它们的导数为零；然而，试图计算这些零可以轻易地占用整个程序90%甚至更多的计算时间，正如这个程序首次编写几年后，一个学生无意中做的实验所示。


回到自动计算雅各布系数的问题上。作者将这种方法与手工编码的雅各布式并列使用，用于不可压缩的Navier-Stokes问题，发现Sacado方法与使用手工编码的雅各布式一样快，但无限简单，而且不容易出错。由于使用自动差分只需要编码残差 $R(\mathbf{W})$ ，确保代码的正确性和维护代码变得非常简单--雅各布矩阵 $\mathbf R'$ 基本上是由计算残差 $\mathbf
R$ 的同一代码计算的。

说了这么多，这里有一个非常简单的例子，显示Sacado如何被使用。

@code
#include <Sacado.hpp>
#include <iostream>


using fad_double = Sacado::Fad::DFad<double>;


main() {


  fad_double a,b,c;


  a = 1; b = 2;


  a.diff(0,2);  // Set a to be dof 0, in a 2-dof system.


  b.diff(1,2);  // Set b to be dof 1, in a 2-dof system.


  c = 2*a+cos(a*b);


  double *derivs = &c.fastAccessDx(0); // Access derivatives


  std::cout << "dc/da = " << derivs[0] << ", dc/db=" << derivs[1] << std::endl;


}
@endcode



输出的是 $c(a,b)=2a+\cos(ab)$ 在 $a=1,b=2$ 的导数 $\frac{\partial c(a,b)}{\partial a},
\frac{\partial c(a,b)}{\partial b}$  。

应该注意的是，Sacado提供了更多的自动差分功能，而不是本程序中使用的小子集。  然而，理解上面的例子就足以理解Sacado在这个欧拉流程序中的使用。

<h3> Trilinos solvers </h3> 该程序使用Aztec迭代求解器或Amesos稀疏直接求解器，两者均由Trilinos包提供。  这个软件包本身就是为了用于并行程序而设计的，然而，它也可以像这里一样，轻松地用于串行程序。  Epetra软件包是基本的矢量/矩阵库，解算器是在此基础上建立的。  这个非常强大的包可以用来描述矢量的平行分布，并定义对这些矢量进行操作的稀疏矩阵。  请查看注释代码，了解更多关于这些求解器在例子中的使用细节。

<h3> Adaptivity </h3> 这个例子使用了一个特别的细化指标，该指标在冲击类问题中显示出一定的作用，在包括下坡流的例子中也是如此。  我们根据密度的平方梯度进行细化。悬空节点的处理是通过计算不同细化水平的单元的数值通量来实现的，而不是像迄今为止的所有其他教程程序那样使用AffineConstraints类。  通过这种方式，这个例子结合了连续和DG的方法论。它还简化了Jacobian的生成，因为我们不必通过用于计算自由度的自动微分来跟踪受限自由度。

 @note  而这个程序是在2008年写的，我们不知道有什么出版物会真正使用这种方法。然而，A. Dedner、R. Kl&ouml;fkorn和M. Kr&auml;nkel最近的一篇论文（"Continuous Finite-Elements on Non-Conforming Grids Using Discontinuous Galerkin Stabilization", Proceedings of Finite Volumes for Complex Applications VII - Methods and Theoretical Aspects, Springer, 2014）接近。

此外，我们强制规定了细化水平的最大数量，以控制细化的程度。  根据作者的经验，对于与时间有关的问题的适应性，如果不注意的话，细化很容易导致仿真戛然而止，因为时间步长的限制，如果网格在领域的任何部分变得太细的话。  在这个例子中，细化的数量被限制，让用户指定在网格的任何地方出现的最大细化水平。  这样一来，细化就不会使模拟速度减慢到停滞不前。  当然，这纯粹是一种启发式的策略，如果作者的顾问听说了，作者可能会被永远放逐出有限元误差估计界。

<h3>Input deck, initial and boundary conditions</h3>

我们使用一个输入文件平台来驱动仿真。  通过这种方式，我们可以改变边界条件和其他重要的模拟属性，而不必重新编译。  关于格式的更多信息，请看<a href="#Results">results section</a>，在那里我们更详细地描述了一个输入文件的例子。

在以前的例子程序中，我们通常对初始和边界条件进行硬编码。在这个程序中，我们改用表达式解析器类FunctionParser，这样我们就可以在输入文件中指定一个通用表达式，并在运行时对其进行解析&mdash；这样，我们就可以改变初始条件而不需要重新编译程序。因此，在下面的程序中不会声明名为InitialConditions或BoundaryConditions的类。




<h3>Implementation</h3>

这个程序的实现被分成三个基本部分。   <ul>   <li>   <code>EulerEquations</code> 类，封装了完全描述欧拉方程具体内容的一切。这包括通量矩阵 $\mathbf F(\mathbf W)$ 、数值通量 $\mathbf F(\mathbf
  W^+,\mathbf W^-,\mathbf n)$ 、右手边 $\mathbf G(\mathbf W)$ 、边界条件、细化指标、输出的后处理，以及需要了解解向量和方程的各个组成部分的含义的类似事情。

    <li>  一个命名空间，处理与运行时参数有关的一切。

    <li>   <code>ConservationLaw</code>  处理时间步进、外部非线性和内部线性求解、组装线性系统以及驱动所有这些的顶层逻辑的类。   </ul> 

这种方法的原因是它将程序中的各种问题分开： <code>ConservationLaw</code> 是以这样一种方式编写的，即相对简单地将其适用于不同的方程组。人们只需为其他双曲方程重新实现 <code>EulerEquations</code> 类的成员，或者用额外的方程来增加现有的方程（例如通过添加额外的变量，或者通过添加化学成分等）。然而，这种修改不会影响到时间步进，或者非线性求解器，如果正确的话，因此 <code>ConservationLaw</code> 中的任何内容都不必修改。

同样，如果我们想改进线性或非线性求解器，或者改进时间步进方案（正如在<a
href="#Results">results section</a>的末尾所暗示的），那么这根本不需要对 <code>EulerEquations</code> 进行修改。


examples/step-33/doc/results.dox

<a name="Results"></a>

<h1>Results</h1>

我们用网格 <code>slide.inp</code> （该文件与本程序的源代码在同一目录下）和以下的输入牌（在同一目录下有 <code>input.prm</code> ）运行该问题。

@verbatim
# Listing of Parameters
# ---------------------


# The input grid
set mesh = slide.inp


# Stabilization parameter
set diffusion power = 2.0


# --------------------------------------------------
# Boundary conditions
# We may specify boundary conditions for up to MAX_BD boundaries.
# Your .inp file should have these boundaries designated.
subsection boundary_1
  set no penetration = true # reflective boundary condition
end


subsection boundary_2
  # outflow boundary
  # set w_2 = pressure
  # set w_2 value = 1.5 - y
end


subsection boundary_3
  set no penetration = true # reflective
  # set w_3 = pressure
  # set w_3 value = 1.0
end


subsection boundary_4
  set no penetration = true #reflective
end


# --------------------------------------------------
# Initial Conditions
# We set the initial conditions of the conservative variables.  These lines
# are passed to the expression parsing function.  You should use x,y,z for
# the coordinate variables.


subsection initial condition
  set w_0 value = 0
  set w_1 value = 0
  set w_2 value = 10*(x<-0.7)*(y> 0.3)*(y< 0.45) + (1-(x<-0.7)*(y> 0.3)*(y< 0.45))*1.0
  set w_3 value = (1.5-(1.0*1.0*y))/0.4
end


# --------------------------------------------------
# Time stepping control
subsection time stepping
  set final time = 10.0 # simulation end time
  set time step  = 0.02 # simulation time step
  set theta scheme value = 0.5
end


subsection linear solver
  set output         = quiet
  set method         = gmres
  set ilut fill      = 1.5
  set ilut drop tolerance = 1e-6
  set ilut absolute tolerance = 1e-6
  set ilut relative tolerance = 1.0
end


# --------------------------------------------------
# Output frequency and kind
subsection output
  set step           = 0.01
  set schlieren plot = true
end


# --------------------------------------------------
# Refinement control
subsection refinement
  set refinement = true # none only other option
  set shock value = 1.5
  set shock levels = 1 # how many levels of refinement to allow
end


# --------------------------------------------------
# Flux parameters
subsection flux
 set stab = constant
 #set stab value = 1.0
end
@endverbatim



当我们运行该程序时，我们会得到以下的输出。

@verbatim
...
T=0.14
   Number of active cells:       1807
   Number of degrees of freedom: 7696


   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   7.015e-03        0008        3.39e-13
   2.150e-05        0008        1.56e-15
   2.628e-09        0008        5.09e-20
   5.243e-16        (converged)


T=0.16
   Number of active cells:       1807
   Number of degrees of freedom: 7696


   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   7.145e-03        0008        3.80e-13
   2.548e-05        0008        7.20e-16
   4.063e-09        0008        2.49e-19
   5.970e-16        (converged)


T=0.18
   Number of active cells:       1807
   Number of degrees of freedom: 7696


   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   7.395e-03        0008        6.69e-13
   2.867e-05        0008        1.33e-15
   4.091e-09        0008        3.35e-19
   5.617e-16        (converged)
...
@endverbatim



这个输出报告了牛顿迭代的进度和时间步长。请注意，我们对牛顿迭代的实现确实显示了预期的二次收敛顺序：每一步的非线性残差的规范大致是上一步的规范的平方。这导致了我们在这里可以看到的非常快速的收敛。这种情况一直保持到 $t=1.9$ 时，这时非线性迭代报告缺乏收敛。

@verbatim
...


T=1.88
   Number of active cells:       2119
   Number of degrees of freedom: 9096


   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   2.251e-01        0012        9.78e-12
   5.698e-03        0012        2.04e-13
   3.896e-05        0012        1.48e-15
   3.915e-09        0012        1.94e-19
   8.800e-16        (converged)


T=1.9
   Number of active cells:       2140
   Number of degrees of freedom: 9184


   NonLin Res     Lin Iter       Lin Res
   _____________________________________
   2.320e-01        0013        3.94e-12
   1.235e-01        0016        6.62e-12
   8.494e-02        0016        6.05e-12
   1.199e+01        0026        5.72e-10
   1.198e+03        0002        1.20e+03
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan
   7.030e+03        0001        nan





----------------------------------------------------
Exception on processing:


--------------------------------------------------------
An error occurred in line <2476> of file <\step-33.cc> in function
    void Step33::ConservationLaw<dim>::run() [with int dim = 2]
The violated condition was:
    nonlin_iter <= 10
The name and call sequence of the exception was:
    ExcMessage ("No convergence in nonlinear solver")
Additional Information:
No convergence in nonlinear solver


--------------------------------------------------------


Aborting!


----------------------------------------------------
@endverbatim



我们可以通过查看解决方案的动画来找出原因和可能的补救措施。

运行这些计算的结果是一堆输出文件，我们可以将其传递给我们选择的可视化程序。当我们把它们整理成一个电影时，过去几个时间步骤的结果看起来是这样的。

 <img src="https://www.dealii.org/images/steps/developer/step-33.oscillation.gif " alt="" height="300"> 

正如我们所看到的，当大质量的流体碰到左下角时，会发生一些振荡，导致迭代的发散。解决这个问题的一个懒办法是添加更多的粘性。如果我们将扩散功率设置为 $\eta = 1.5$ ，而不是 $2.0$ ，模拟就能度过这一危机。那么，结果就会是这样。


 <img src="https://www.dealii.org/images/steps/developer/step-33.slide.ed2.gif " alt="" height="300"> 

沉重的流体在重力作用下被拉下斜坡，在那里与滑雪屋相撞，并被抛向空中！希望每个人都能逃脱。  希望每个人都能逃过一劫!还有，我们可以看到由于人为的粘性，重质和轻质之间的界限很快就模糊了。

我们还可以直观地看到自适应细化网格的演变。

 <img src="https://www.dealii.org/images/steps/developer/step-33.slide.adapt.ed2.gif " alt="" height="300"> 

根据上面讨论的启发式细化方案，自适应性跟随并先于流动模式。





<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Stabilization</h4>

我们选择的数值方案在人工粘度小的时候不是特别稳定，而在人工粘度大的时候则过于扩散。此外，众所周知，还有一些更先进的技术来稳定解决方案，例如流线扩散、最小二乘法稳定条款、熵粘性。




<h4>Better linear solvers</h4>

虽然作为非线性求解器的牛顿方法在时间步长足够小的情况下似乎效果很好，但线性求解器是可以改进的。例如，在目前的方案中，只要我们使用迭代求解器，每个牛顿步骤都要重新计算ILU；同样，对于直接求解器，每个步骤都要计算牛顿矩阵的LU分解。这显然是一种浪费：从一个牛顿步骤到另一个牛顿步骤，可能还有不同的时间步骤，牛顿矩阵不会发生根本性的变化：一个牛顿步骤的ILU或稀疏LU分解可能仍然是下一个牛顿或时间步骤的非常好的预处理。因此，避免重新计算将是减少计算时间的一个好办法。

我们可以更进一步：由于接近收敛时，牛顿矩阵只发生一点变化，我们也许可以定义一个准牛顿方案，即在每次牛顿迭代中我们只重新计算残差（即右手边的向量），并重新使用牛顿矩阵。由此产生的方案很可能不是二次收敛的，我们必须期望多做几次非线性迭代；然而，鉴于我们不必每次都花时间建立牛顿矩阵，由此产生的方案很可能更快。




<h4>Cache the explicit part of residual</h4>

在 ConservationLaw::assemble_cell_term 函数中计算的残差为 $R_i = \left(\frac{\mathbf{w}^{k}_{n+1} - \mathbf{w}_n}{\delta t}
    , \mathbf{z}_i \right)_K  +
      \theta \mathbf{B}({\mathbf{w}^{k}_{n+1}})(\mathbf{z}_i)_K +
      (1-\theta) \mathbf{B}({\mathbf{w}_{n}}) (\mathbf{z}_i)_K $ 这意味着我们在一个牛顿迭代步骤中计算了两次空间残差：一次是关于当前解 $\mathbf{w}^{k}_{n+1}$ ，另一次是关于最后一个时间步长的解 $\mathbf{w}_{n}$ ，在一个时间步长的所有牛顿迭代中保持相同。在牛顿迭代过程中缓存残差 $ \mathbf{B}({\mathbf{w}_{n}}) (\mathbf{z}_i)_K$ 的显式部分将节省大量的人力。




<h4>Other conservation laws</h4>

最后，作为超越欧拉方程直接求解的一个方向，本程序非常努力地将所有专门针对欧拉方程的实现分离到一个类中（ <code>EulerEquation</code> 类），而将所有专门用于组装矩阵和向量、非线性和线性求解器以及一般顶层逻辑的实现分离到另一个类中（ <code>ConservationLaw</code> 类）。

通过替换该类中通量矩阵和数值通量的定义，以及那里定义的其他各种部分，应该也可以将 <code>ConservationLaw</code> 类应用于其他双曲守恒定律。


examples/step-34/doc/intro.dox

 <br> 

<i>This program was contributed by Luca Heltai (thanks to Michael
Gratton for pointing out what the exact solution should have been in
the three dimensional case).  </i>

 @dealiiTutorialDOI{10.5281/zenodo.495473,https://zenodo.org/badge/DOI/10.5281/zenodo.495473.svg} 

<a name="Intro"></a>

<h1>Introduction</h1>

<h3> Irrotational flow </h3> 无粘性流体经过一个物体（例如空气经过飞机机翼，或空气或水经过螺旋桨）的不可压缩运动，通常由流体力学的欧拉方程来模拟。

\f{align*}
  \frac{\partial }{\partial t}\mathbf{v} + (\mathbf{v}\cdot\nabla)\mathbf{v}
  &=


  -\frac{1}{\rho}\nabla p + \mathbf{g}
  \qquad &\text{in } \mathbb{R}^n \backslash \Omega
  \\
  \nabla \cdot \mathbf{v}&=0
  &\text{in } \mathbb{R}^n\backslash\Omega
\f}其中流体密度 $\rho$ 和由外力引起的加速度 $\mathbf{g}$ 是给定的，速度 $\mathbf{v}$ 和压力 $p$ 是未知数。这里 $\Omega$ 是一个封闭的有界区域，代表流体在其周围运动的体。

上述方程可以从纳维-斯托克斯方程推导出来，假设与压力梯度、惯性力和外力的影响相比，粘度造成的影响可以忽略不计。这是步骤22中讨论的斯托克斯方程的相反情况，斯托克斯方程是主导粘度的极限情况，即速度非常小，惯性力可以被忽略掉。另一方面，由于假定的不可压缩性，该方程不适合于非常高速的气体流动，在那里必须考虑到压缩性和气体的状态方程，导致气体动力学的欧拉方程，一个双曲系统。

在本教程程序中，我们将只考虑没有外力的静止流动。

\f{align*}
  (\mathbf{v}\cdot\nabla)\mathbf{v}
  &=


  -\frac{1}{\rho}\nabla p
  \qquad &\text{in } \mathbb{R}^n \backslash \Omega
  \\
  \nabla \cdot \mathbf{v}&=0
  &\text{in } \mathbb{R}^n\backslash\Omega
\f}


欧拉方程的解的唯一性通过添加边界条件得到保证

\f[
  \label{eq:boundary-conditions}
  \begin{aligned}
    \mathbf{n}\cdot\mathbf{v}& = 0 \qquad && \text{ on } \partial\Omega \\
    \mathbf{v}& = \mathbf{v}_\infty && \text{ when } |\mathbf{x}| \to \infty,
  \end{aligned}
\f]

这就是说，身体在我们的坐标系中是静止的，不具有渗透性，而流体在无限远处具有（恒定）速度 $\mathbf{v}_\infty$ 。另一种观点是，我们的坐标系随着身体移动，而背景流体在无限远处处于静止状态。注意，我们将法线 $\mathbf{n}$ 定义为域 $\Omega$ 的<i>outer</i>法线，它与积分域的外法线相反。

对于静止和非静止的流动，求解过程从求解第二个方程中的速度开始，然后代入第一个方程，以找到压力。静止欧拉方程的求解通常是为了了解给定的（可能是复杂的）几何形状在系统上强制执行规定运动时的行为。

这个过程的第一步是将参照系从一个与身体一起运动的坐标系改变为一个身体在一个无限大的静止流体中运动的坐标系。这可以通过引入一个新的速度 $\mathbf{\tilde{v}}=\mathbf{v}-\mathbf{v}_\infty$ 来表示，对于这个速度，我们发现同样的方程成立（因为 $\nabla\cdot
\mathbf{v}_\infty=0$ ），我们有边界条件

\f[
  \label{eq:boundary-conditions-tilde}
  \begin{aligned}
    \mathbf{n}\cdot\mathbf{\tilde{v}}& = -\mathbf{n}\cdot\mathbf{v}_\infty \qquad && \text{ on } \partial\Omega \\
    \mathbf{\tilde{v}}& = 0 && \text{ when } |\mathbf{x}| \to \infty,
  \end{aligned}
\f]

如果我们假设流体是无旋转的，即 $\nabla \times
\mathbf{v}=0$ 中的 $\mathbb{R}^n\backslash\Omega$ ，我们可以用标量函数的梯度来表示速度，从而也可以表示扰动速度。

\f[
  \mathbf{\tilde{v}}=\nabla\phi,
\f] ，因此上述欧拉方程的第二部分可以改写为未知数的同质拉普拉斯方程  $\phi$  。

\f{align*}
\label{laplace}
\Delta\phi &= 0 \qquad &&\text{in}\ \mathbb{R}^n\backslash\Omega,
	   \\
	   \mathbf{n}\cdot\nabla\phi &= -\mathbf{n}\cdot\mathbf{v}_\infty
	   && \text{on}\ \partial\Omega
\f}而动量方程还原为伯努利方程，该方程将压力  $p$  表示为势的函数  $\phi$  。

\f[
\frac{p}{\rho} +\frac{1}{2} | \nabla \phi |^2 = 0 \in \Omega.
\f]

因此，我们可以通过解决势的拉普拉斯方程来解决这个问题。  我们回顾一下，下列函数，称为拉普拉斯方程的基本解。

\f[ \begin{aligned}
\label{eq:3} G(\mathbf{y}-\mathbf{x}) = &


-\frac{1}{2\pi}\ln|\mathbf{y}-\mathbf{x}| \qquad && \text{for } n=2 \\
G(\mathbf{y}-\mathbf{x}) = &
\frac{1}{4\pi}\frac{1}{|\mathbf{y}-\mathbf{x}|}&& \text{for } n=3,
\end{aligned}
\f]

在分布意义上满足方程的要求。

\f[


-\Delta_y G(\mathbf{y}-\mathbf{x}) = \delta(\mathbf{y}-\mathbf{x}),
\f]

其中导数是在变量 $\mathbf{y}$ 中完成的。通过使用通常的格林同一性，我们的问题可以只写在边界上  $\partial\Omega = \Gamma$  。我们回顾一下第二个格林同位数的一般定义。

\f[\label{green}
  \int_{\omega}
  (-\Delta u)v\,dx + \int_{\partial\omega} \frac{\partial u}{\partial \tilde{\mathbf{n}} }v \,ds
  =
  \int_{\omega}
  (-\Delta v)u\,dx + \int_{\partial\omega} u\frac{\partial v}{\partial \tilde{\mathbf{n}}} \,ds,
\f]

其中 $\tilde{\mathbf{n}}$ 是 $\omega$ 的表面的法线，从积分域 $\omega$ 向外指向。

在我们的例子中，积分域是 $\mathbb{R}^n\backslash\Omega$ ，其边界是 $ \Gamma_\infty \cup
\Gamma$ ，其中无穷大的 "边界 "被定义为

\f[
\Gamma_\infty \dealcoloneq \lim_{r\to\infty} \partial B_r(0).
\f]

在我们的程序中，法线被定义为<i>outer</i>到域 $\Omega$ ，也就是说，它们实际上是<i>inner</i>到积分域，在定义各种积分时，需要注意法线的正确符号，即用 $-\mathbf{n}$ 代替 $\tilde{\mathbf{n}}$ 。

如果我们把 $u$ 和 $v$ 分别与 $\phi$ 的解和拉普拉斯方程的基本解代入格林%同，只要 $\mathbf{x}$ 被选在 $\mathbb{R}^n\backslash\Omega$ 区域，就可以得到。

\f[
  \phi(\mathbf{x}) -
  \int_{\Gamma\cup\Gamma_\infty}\frac{\partial G(\mathbf{y}-\mathbf{x})}{\partial \mathbf{n}_y}\phi(\mathbf{y})\,ds_y
  =


  -\int_{\Gamma\cup\Gamma_\infty}G(\mathbf{y}-\mathbf{x})\frac{\partial \phi}{\partial \mathbf{n}_y}(\mathbf{y})\,ds_y
  \qquad \forall\mathbf{x}\in \mathbb{R}^n\backslash\Omega
\f]

其中法线现在指向<i>inward</i>的积分域。

请注意，在上述方程中，我们也有 $\Gamma_\infty$ 处的边界部分的积分。利用我们问题的边界条件，我们有 $\nabla \phi$ 在无限远处为零（这简化了右侧 $\Gamma_\infty$ 上的积分）。

左手边出现的 $\Gamma_\infty$ 上的积分可以通过观察 $\nabla\phi=0$ 来处理，这意味着 $\phi$ 在无穷远处必然是常数。我们把它的值定义为 $\phi_\infty$  。  要证明这一点是很容易的

\f[


-\int_{\Gamma_\infty} \frac{\partial G(\mathbf{y}-\mathbf{x})}
{\partial \mathbf{n}_y}\phi_\infty \,ds_y =
\lim_{r\to\infty} \int_{\partial B_r(0)} \frac{\mathbf{r}}{r} \cdot \nabla G(\mathbf{y}-\mathbf{x})
\phi_\infty \,ds_y = -\phi_\infty.
\f]

利用这一结果，我们可以利用所谓的单层和双层势能算子，只在边界上 $\Gamma$ 还原上述方程。

\f[\label{integral}
  \phi(\mathbf{x}) - (D\phi)(\mathbf{x}) = \phi_\infty


  -\left(S \frac{\partial \phi}{\partial n_y}\right)(\mathbf{x})
  \qquad \forall\mathbf{x}\in \mathbb{R}^n\backslash\Omega.
\f]

(这些算子的名称来自于它们分别描述了 $\mathbb{R}^n$ 中由于沿表面的单一薄片电荷和由于沿表面的双片电荷和反电荷而产生的电动势)。

在我们的例子中，我们知道边界上 $\phi$ 的纽曼值： $\mathbf{n}\cdot\nabla\phi = -\mathbf{n}\cdot\mathbf{v}_\infty$  。因此。

\f[
  \phi(\mathbf{x}) - (D\phi)(\mathbf{x}) = \phi_\infty +
   \left(S[\mathbf{n}\cdot\mathbf{v}_\infty]\right)(\mathbf{x})
   \qquad \forall\mathbf{x} \in \mathbb{R}^n\backslash\Omega.
\f] 如果我们对上述方程的 $\mathbf{x}$ 采取趋向于 $\Gamma$ 的极限，利用众所周知的单层和双层算子的特性，我们得到一个正好在 $\Omega$ 的边界 $\Gamma$ 的方程。

\f[\label{SD}
  \alpha(\mathbf{x})\phi(\mathbf{x}) - (D\phi)(\mathbf{x}) = \phi_\infty +
  \left(S [\mathbf{n}\cdot\mathbf{v}_\infty]\right)(\mathbf{x})
  \quad \mathbf{x}\in \partial\Omega,
\f]

这就是我们要找的边界积分方程（BIE），其中量 $\alpha(\mathbf{x})$ 是点 $\mathbf{x}$ 看到积分域 $\mathbb{R}^n\backslash\Omega$ 的角度或实体角的分数。

特别是，在边界 $\mathbf{x}$ 是可微的（即光滑）的点上，我们有 $\alpha(\mathbf{x})=\frac 12$ ，但在边界有角或边的点上，数值可能会更小或更大。

代入单层和双层运算符，我们得到。

\f[
  \alpha(\mathbf{x}) \phi(\mathbf{x})
  + \frac{1}{2\pi}\int_{\partial \Omega}  \frac{
  (\mathbf{y}-\mathbf{x})\cdot\mathbf{n}_y  }{ |\mathbf{y}-\mathbf{x}|^2 }
  \phi(\mathbf{y}) \,ds_y
  = \phi_\infty


    -\frac{1}{2\pi}\int_{\partial \Omega}  \ln|\mathbf{y}-\mathbf{x}| \, \mathbf{n}\cdot\mathbf{v_\infty}\,ds_y
\f]为二维流动和

\f[
  \alpha(\mathbf{x}) \phi(\mathbf{x})
   + \frac{1}{4\pi}\int_{\partial \Omega} \frac{ (\mathbf{y}-\mathbf{x})\cdot\mathbf{n}_y  }{ |\mathbf{y}-\mathbf{x}|^3 }\phi(\mathbf{y})\,ds_y
  = \phi_\infty +
  \frac{1}{4\pi}\int_{\partial \Omega} \frac{1}{|\mathbf{y}-\mathbf{x}|} \, \mathbf{n}\cdot\mathbf{v_\infty}\,ds_y
\f]适用于三维流动，其中基本解的法向导数被写成了便于计算的形式。在任何一种情况下， $\phi$ 都是完全在边界上提出的积分方程的解，因为 $\mathbf{x},\mathbf{y}\in\partial\Omega$  。

注意，点 $\mathbf{x}$ 看到域 $\Omega$ 的角度（在2D中）或实体角（在3D中） $\alpha(\mathbf{x})$ 的分数可以用双层势本身定义。

\f[
\alpha(\mathbf{x}) \dealcoloneq 1 -
\frac{1}{2(n-1)\pi}\int_{\partial \Omega} \frac{ (\mathbf{y}-\mathbf{x})\cdot\mathbf{n}_y  }
{ |\mathbf{y}-\mathbf{x}|^{n} }\phi(\mathbf{y})\,ds_y = 1+
\int_{\partial \Omega} \frac{ \partial G(\mathbf{y}-\mathbf{x}) }{\partial \mathbf{n}_y} \, ds_y.
\f]

如果我们考虑到这样一个事实，即纯诺伊曼问题的解在一个任意常数 $c$ 以内都是已知的，这意味着，如果我们将诺伊曼数据设为零，那么任何常数 $\phi = \phi_\infty$ 都将是一个解。在边界积分方程中插入常数解和诺伊曼边界条件，我们有

@f{align*}
\alpha\left(\mathbf{x}\right)\phi\left(\mathbf{x}\right)
&=\int_{\Omega}\phi\left(\mathbf{y}\right)\delta\left(\mathbf{y}-\mathbf{x}\right)\, dy\\
\Rightarrow
\alpha\left(\mathbf{x}\right)\phi_\infty
&=\phi_\infty\int_{\Gamma\cup\Gamma_\infty}\frac{ \partial G(\mathbf{y}-\mathbf{x}) }{\partial \mathbf{n}_y} \, ds_y
=\phi_\infty\left[\int_{\Gamma_\infty}\frac{ \partial G(\mathbf{y}-\mathbf{x}) }{\partial \mathbf{n}_y} \, ds_y
+\int_{\Gamma}\frac{ \partial G(\mathbf{y}-\mathbf{x}) }{\partial \mathbf{n}_y} \, ds_y
\right]


@f}

在 $\Gamma_\infty$ 上的积分是统一的，见上文，所以除以常数 $\phi_\infty$ 就得到了上面 $\alpha(\mathbf{x})$ 的明确表达。

虽然这个示例程序实际上只关注边界积分方程的求解，但在一个现实的设置中，我们仍然需要对速度进行求解。为此，请注意，我们刚刚计算了 $\phi(\mathbf{x})$ 的所有 $\mathbf{x}\in\partial\Omega$ 。在下一步中，我们可以计算（如果我们愿意，可以分析）所有 $\mathbb{R}^n\backslash\Omega$ 中的解 $\phi(\mathbf{x})$  。为此，回顾一下，我们有

\f[
  \phi(\mathbf{x})
  =
  \phi_\infty +
  (D\phi)(\mathbf{x})
  +
  \left(S[\mathbf{n}\cdot\mathbf{v}_\infty]\right)(\mathbf{x})
  \qquad \forall\mathbf{x}\in \mathbb{R}^n\backslash\Omega.
\f]，现在我们有了右手边的所有东西（ $S$ 和 $D$ 是我们可以评估的积分，边界上的法线速度已经给出，边界上的 $\phi$ 我们刚刚计算了）。最后，我们就可以恢复速度为  $\mathbf{\tilde v}=\nabla \phi$  。

注意，对 $\mathbf{x} \in
\Omega$ 的上述公式的评估结果应该是零，因为狄拉克三角 $\delta(\mathbf{x})$ 在域 $\mathbb{R}^n\backslash\Omega$ 的积分根据定义总是零。

作为最后的测试，让我们验证这个速度是否确实满足静止流场的动量平衡方程，即对于某个（未知）压力 $p$ 和一个给定的常数 $\rho$ ， $\mathbf{v}\cdot\nabla\mathbf{v} = -\frac 1\rho \nabla p$ 中是否 $\mathbf{v}=\mathbf{\tilde
v}+\mathbf{v}_\infty=\nabla\phi+\mathbf{v}_\infty$ 。换句话说，我们想验证上面所说的伯努利定律确实成立。为了证明这一点，我们用这个方程的左手边等同于

@f{align*}
  \mathbf{v}\cdot\nabla\mathbf{v}
  &=
  [(\nabla\phi+\mathbf{v}_\infty)\cdot\nabla] (\nabla\phi+\mathbf{v}_\infty)
  \\
  &=
  [(\nabla\phi+\mathbf{v}_\infty)\cdot\nabla] (\nabla\phi)


@f}

其中我们使用了 $\mathbf{v}_\infty$ 是常数。我们想把这个表达式写成某个东西的梯度（记住 $\rho$ 是一个常数）。如果我们单独考虑方程的组成部分，下一步会更方便（对出现两次的指数求和是隐含的）。

@f{align*}
  [\mathbf{v}\cdot\nabla\mathbf{v}]_i
  &=
  (\partial_j\phi+v_{\infty,j}) \partial_j \partial_i\phi
  \\
  &=
  \partial_j [(\partial_j\phi+v_{\infty,j}) \partial_i\phi]


  -
  \partial_j [(\partial_j\phi+v_{\infty,j})] \partial_i\phi
  \\
  &=
  \partial_j [(\partial_j\phi+v_{\infty,j}) \partial_i\phi]


@f}

因为  $\partial_j \partial_j\phi = \Delta \phi = 0$  和  $\textrm{div}
\ \mathbf{v}_\infty=0$  。下一个。

@f{align*}
  [\mathbf{v}\cdot\nabla\mathbf{v}]_i
  &=
  \partial_j [(\partial_j\phi+v_{\infty,j}) \partial_i\phi]
  \\
  &=
  \partial_j [(\partial_j\phi) (\partial_i\phi)]
  +
  \partial_j [v_{\infty,j} \partial_i\phi]
  \\
  &=
  \partial_j [(\partial_j\phi) (\partial_i\phi)]
  +
  \partial_j [v_{\infty,j}] \partial_i\phi
  +
  v_{\infty,j} \partial_j \partial_i\phi
  \\
  &=
  \partial_j [(\partial_j\phi) (\partial_i\phi)]
  +
  v_{\infty,j} \partial_j \partial_i\phi
  \\
  &=
  \partial_i \partial_j [(\partial_j\phi) \phi]


  -
  \partial_j [\partial_i (\partial_j\phi) \phi]
  +
  \partial_i [v_{\infty,j} \partial_j \phi]


  -
  \partial_i [v_{\infty,j}] \partial_j \phi


@f}

同样，最后一项消失了，因为 $\mathbf{v}_\infty$ 是常数，我们可以将第一项和第三项合并为一项。

@f{align*}
  [\mathbf{v}\cdot\nabla\mathbf{v}]_i
  &=
  \partial_i (\partial_j [(\partial_j\phi) \phi + v_{\infty,j} \partial_j \phi])


  -
  \partial_j [\partial_i (\partial_j\phi) \phi]
  \\
  &=
  \partial_i [(\partial_j\phi)(\partial_j \phi) + v_{\infty,j} \partial_j \phi]


  -
  \partial_j [\partial_i (\partial_j\phi) \phi]


@f}



我们现在只需要对最后一项再做一下按摩。使用乘积规则，我们得到

@f{align*}
  \partial_j [\partial_i (\partial_j\phi) \phi]
  &=
  \partial_i [\partial_j \partial_j\phi] \phi
  +
  \partial_i [\partial_j \phi] (\partial_j \phi).


@f}

这些项中的第一个是零（因为，同样，对 $j$ 的求和得到 $\Delta\phi$ ，它是零）。最后一项可以写成 $\frac 12
\partial_i [(\partial_j\phi)(\partial_j\phi)]$ ，它是理想的梯度形式。因此，我们现在可以最终说明

@f{align*}
  [\mathbf{v}\cdot\nabla\mathbf{v}]_i
  &=
  \partial_i (\partial_j [(\partial_j\phi) \phi + v_{\infty,j} \partial_j \phi])


  -
  \partial_j [\partial_i (\partial_j\phi) \phi]
  \\
  &=
  \partial_i
  \left[
    (\partial_j\phi)(\partial_j \phi) + v_{\infty,j} \partial_j \phi


    -
    \frac 12 (\partial_j\phi)(\partial_j\phi)
  \right],
  \\
  &=
  \partial_i
  \left[
    \frac 12 (\partial_j\phi)(\partial_j \phi) + v_{\infty,j} \partial_j \phi
  \right],


@f}

或以矢量形式。

@f[
  \mathbf{v}\cdot\nabla\mathbf{v}
  =
  \nabla
  \left[
    \frac 12 \mathbf{\tilde v}^2
    + \mathbf{v}_{\infty} \cdot \mathbf{\tilde v}
  \right],


@f]

或者换句话说。

@f[
  p
  =


  -\rho
  \left[
    \frac 12 \mathbf{\tilde v}^2
    + \mathbf{v}_{\infty} \cdot \mathbf{\tilde v}
  \right]
  =


  -\rho
  \left[
    \frac 12 \mathbf{v}^2


    -
    \frac 12 \mathbf{v}_{\infty}^2
  \right]
  .


@f]

因为压力只确定到一个常数（它只在方程中出现一个梯度），一个同样有效的定义是

@f[
  p
  =


  -\frac 12 \rho \mathbf{v}^2
  .


@f]

这正是上面提到的伯努利定律。




<h3>The numerical approximation</h3>

边界积分方程（BIE）的数值近似通常被称为边界元素法或面板法（后者主要用于计算流体力学界）。以下测试问题的目的是解决具有诺伊曼边界条件的拉普拉斯方程的积分表述，分别使用二维和三维空间的圆和球体，沿途说明了允许人们使用deal.II库处理边界元素问题几乎与有限元问题一样容易的特点。

为此，让 $\mathcal{T}_h = \bigcup_i K_i$ 成为流形 $\Gamma = \partial \Omega$ 的一个细分，如果 $n=2$ 则为 $M$ 线段，如果 $n=3$ 则为 $M$  四边形。我们将称每个单独的线段或四边形为<i>element</i>或<i>cell</i>，与周围空间的维度 $n$ 无关。我们将有限维空间 $V_h$ 定义为

\f[
  \label{eq:definition-Vh}
  V_h \dealcoloneq \{ v \in C^0(\Gamma) \text{ s.t. } v|_{K_i} \in \mathcal{Q}^1(K_i),
  \forall i\},
\f]的基函数 $\psi_i(\mathbf{x})$ ，我们将使用通常的FE_Q有限元，但这次它被定义在一个一维的流形上（我们通过使用第二个模板参数，通常默认为等于第一个；这里，我们将在一个 <code>dim</code> 维的空间中创建对象 <code>FE_Q@<dim-1,dim@></code> to indicate that we have <code>dim-1</code> 维单元）。一个 $\phi_h$ 的元素 $V_h$ 是由其系数的向量 $\boldsymbol{\phi}$ 唯一识别的，也就是说。

\f[
  \label{eq:definition-of-element}
  \phi_h(\mathbf{x}) \dealcoloneq \phi_i \psi_i(\mathbf{x}), \qquad
  \boldsymbol{\phi} \dealcoloneq \{ \phi_i \},
\f]，其中求和隐含在重复索引上。请注意，我们可以在这里使用不连续的元素&mdash；事实上，没有真正的理由使用连续的元素，因为积分表述并不意味着我们的试验函数有任何导数，所以连续性是不必要的，而且在文献中经常只使用片断常数元素。

<h3> Collocation boundary element method </h3>

到目前为止，最常见的边界积分方程的近似方法是使用基于碰撞的边界元素方法。

这种方法要求在一些与系统未知数数量相等的定位点上评估边界积分方程。这些点的选择是一个微妙的问题，需要仔细研究。假设这些点暂时是已知的，并称它们为 $\mathbf x_i$ 和 $i=0...n\_dofs$  。

那么问题就变成了。给定基准点 $\mathbf{v}_\infty$ ，在 $V_h$ 中找到一个函数 $\phi_h$ ，使得以下 $n\_dofs$ 方程得到满足。

\f{align*}
    \alpha(\mathbf{x}_i) \phi_h(\mathbf{x}_i)


    - \int_{\Gamma_y} \frac{ \partial G(\mathbf{y}-\mathbf{x}_i)}{\partial\mathbf{n}_y }
    \phi_h(\mathbf{y}) \,ds_y =
    \int_{\Gamma_y} G(\mathbf{y}-\mathbf{x}_i) \,
    \mathbf{n}_y\cdot\mathbf{v_\infty} \,ds_y
    ,
\f}

其中数量 $\alpha(\mathbf{x}_i)$ 是点 $\mathbf{x}_i$ 看到域 $\Omega$ 的（实体）角度的分数，如上所述，我们设定 $\phi_\infty$ 为零。  如果支持点 $\mathbf{x}_i$ 选择得当，那么问题可以写成以下线性系统。

\f[
\label{eq:linear-system}
(\mathbf{A}+\mathbf{N})\boldsymbol\phi = \mathbf{b},
\f]

其中

\f[
\begin{aligned}
\mathbf{A}_{ij}&=
\alpha(\mathbf{x}_i) \psi_j(\mathbf{x}_i)
= 1+\int_\Gamma
\frac{\partial G(\mathbf{y}-\mathbf{x}_i)}{\partial \mathbf{n}_y}\,ds_y
\psi_j(\mathbf{x}_i)
\\
\mathbf{N}_{ij}&= - \int_\Gamma
  \frac{\partial G(\mathbf{y}-\mathbf{x}_i)}{\partial \mathbf{n}_y}
  \psi_j(\mathbf{y}) \,ds_y
\\
\mathbf{b}_i&= \int_\Gamma
   G(\mathbf{y}-\mathbf{x}_i)  \, \mathbf{n}_y\cdot\mathbf{v_\infty}
   ds_y.
\end{aligned}
\f]

从线性代数的角度来看，可能的最佳选择是使矩阵 $\mathbf{A}+\mathbf{N}$ 成为最对角线的主导。一个自然的选择是选择 $\mathbf{x}_i$ 搭配点作为节点基函数 $\psi_i(\mathbf{x})$ 的支持点。在这种情况下， $\psi_j(\mathbf{x}_i)=\delta_{ij}$  ，因此，矩阵 $\mathbf{A}$ 是对角线，其条目为

\f[
  \mathbf{A}_{ii}
  =
  1+\int_\Gamma
  \frac{\partial G(\mathbf{y}-\mathbf{x}_i)}{\partial \mathbf{n}_y}\,ds_y
  =
  1-\sum_j N_{ij},
\f]，其中我们使用了 $\sum_j \psi_j(\mathbf{y})=1$ 作为通常的拉格朗日元素。有了这样的选择，矩阵 $\mathbf{A}$ 、 $\mathbf{N}$ 和右手边 $\mathbf{b}$ 的条目的计算需要对三角形 $\mathcal{T}_h$ 元素的奇异积分进行评估。在这些情况下，所有的积分都是在参考简单域上进行的，也就是说，我们假设 $\mathcal{T}_h$ 的每个元素 $K_i$ 可以表示为参考边界元素 $\hat K \dealcoloneq [0,1]^{n-1}$ 的线性（二维）或双线性（三维）变换，并且我们在从实数元素 $K_i$ 到参考元素 $\hat K$ 的变量改变后执行积分。

<h3> Treating the singular integrals. </h3>

在二维空间，没有必要计算系统矩阵的对角线元素 $\mathbf{N}_{ii}$ ，因为即使分母在 $\mathbf{x}=\mathbf{y}$ 时归零，分子也总是零，因为 $\mathbf{n}_y$ 和 $(\mathbf{y}-\mathbf{x})$ 是正交的。]和 $(\mathbf{y}-\mathbf{x})$ 是正交的（在我们对 $\Omega$ 边界的多边形近似上），唯一的奇异积分出现在对 $\mathbf{b}_i$ 的第i个元素的计算上。

\f[
  \frac{1}{\pi}
  \int_{K_i}
  \ln|\mathbf{y}-\mathbf{x}_i| \, \mathbf{n}_y\cdot\mathbf{v_\infty} \,ds_y.
\f]

这可以通过QGaussLogR正交公式轻松处理。

同样，也可以使用QGaussOneOverR正交公式来进行三维空间的奇异积分。有兴趣的读者可以在其文档中找到关于这些正交规则如何工作的详细解释。

得到的矩阵 $\mathbf{A}+\mathbf{N}$ 是完整的。根据其大小，使用直接求解器或迭代求解器可能会很方便。为了这个例子代码的目的，我们选择只使用一个迭代求解器，而不提供任何预处理程序。

如果这是一个生产代码，而不是一个原理演示，有一些技术可以用来不存储完整的矩阵，而只存储那些大的和/或相关的条目。在边界元素方法的文献中，有大量的方法可以确定哪些元素是重要的，哪些是不重要的，从而使这些矩阵的表示方法明显稀疏，也有利于快速评估向量和矩阵之间的标量积。这不是本程序的目标，我们把它留给更复杂的实现。




<h3>Implementation</h3>

实现起来相当直接。在以前的教程程序中都没有用到的主要一点是，deal.II中的大多数类不仅在维度上有模板，而且实际上在我们提出微分方程的流形的维度以及这个流形嵌入的空间的维度上也有模板。默认情况下，第二个模板参数等于第一个，这意味着我们要在二维空间的一个二维区域上求解。在这种情况下，要使用的三角化类是 <code>Triangulation@<2@></code> ，这相当于写成 <code>Triangulation@<2,2@></code> 的方式。

然而，事实并非如此：在目前的例子中，我们想在球体表面求解，这是一个嵌入三维空间的二维流形。因此，正确的类将是 <code>Triangulation@<2,3@></code> ，相应地，我们将使用 <code>DoFHandler@<2,3@></code> 作为DoF处理类， <code>FE_Q@<2,3@></code> 作为有限元。

关于如何处理生活在弯曲流形上的事物的一些进一步细节，可以在报告<a target="_top"
href="http://www.dealii.org/reports/codimension-one/desimone-heltai-manigrasso.pdf"><i>Tools
for the Solution of PDEs Defined on Curved Manifolds with the deal.II
Library</i><i>Tools
for the Solution of PDEs Defined on Curved Manifolds with the deal.II
Library</i> by A. DeSimone, L. Heltai, C. Manigrasso</a>中找到。此外，Step-38教程程序将我们在这里展示的内容扩展到了流形上提出的方程不是积分算子而实际上涉及导数的情况。




<h3>Testcase</h3>

我们要解决的测试案例是一个圆形（2D）或球形（3D）的障碍物。这些几何体的网格将从当前目录下的文件中读入，然后一个SphericalManifold类型的对象将被附加到三角形上，以允许网格细化，尊重离散的初始网格背后的连续几何。

对于一个半径为 $a$ 的球体，以 $U$ 的速度在 $x$ 方向平移，势为

@f{align*}
\phi = -\frac{1}{2}U \left(\frac{a}{r}\right)3 r \cos\theta


@f}

例如，见J. N. Newman, <i>Marine Hydrodynamics</i>, 1977, pp.对于单位速度和半径，并限制 $(x,y,z)$ 位于球体表面， $\phi = -x/2$  。在测试问题中，流量为 $(1,1,1)$  ，因此在球体表面上适当的精确解是上述解与沿 $y$ 和 $z$ 轴的类似解的叠加，即 $\phi =
\frac{1}{2}(x + y + z)$  。


examples/step-34/doc/results.dox



<h1>Results</h1>

我们使用以下 <code>parameters.prm</code> 文件（也可以在所有其他源文件所在的目录中找到）运行该程序。

@verbatim
# Listing of Parameters
# ---------------------
set Extend solution on the -2,2 box = true
set External refinement             = 5
set Number of cycles                = 4
set Run 2d simulation               = true
set Run 3d simulation               = true



subsection Exact solution 2d
  # Any constant used inside the function which is not a variable name.
  set Function constants  =


  # Separate vector valued expressions by ';' as ',' is used internally by the
  # function parser.
  set Function expression = x+y   # default: 0


  # The name of the variables as they will be used in the function, separated
  # by ','.
  set Variable names      = x,y,t
end



subsection Exact solution 3d
  # Any constant used inside the function which is not a variable name.
  set Function constants  =


  # Separate vector valued expressions by ';' as ',' is used internally by the
  # function parser.
  set Function expression = .5*(x+y+z)   # default: 0


  # The name of the variables as they will be used in the function, separated
  # by ','.
  set Variable names      = x,y,z,t
end



subsection Quadrature rules
  set Quadrature order          = 4
  set Quadrature type           = gauss
  set Singular quadrature order = 5
end



subsection Solver
  set Log frequency = 1
  set Log history   = false
  set Log result    = true
  set Max steps     = 100
  set Tolerance     = 1.e-10
end



subsection Wind function 2d
  # Any constant used inside the function which is not a variable name.
  set Function constants  =


  # Separate vector valued expressions by ';' as ',' is used internally by the
  # function parser.
  set Function expression = 1; 1  # default: 0; 0


  # The name of the variables as they will be used in the function, separated
  # by ','.
  set Variable names      = x,y,t
end



subsection Wind function 3d
  # Any constant used inside the function which is not a variable name.
  set Function constants  =


  # Separate vector valued expressions by ';' as ',' is used internally by the
  # function parser.
  set Function expression = 1; 1; 1 # default: 0; 0; 0


  # The name of the variables as they will be used in the function, separated
  # by ','.
  set Variable names      = x,y,z,t
end
@endverbatim



当我们运行该程序时，屏幕上会打印出以下内容。

@verbatim
DEAL::
DEAL::Parsing parameter file parameters.prm
DEAL::for a 2 dimensional simulation.
DEAL:GMRES::Starting value 2.21576
DEAL:GMRES::Convergence step 1 value 2.37635e-13
DEAL::Cycle 0:
DEAL::   Number of active cells:       20
DEAL::   Number of degrees of freedom: 20
DEAL:GMRES::Starting value 3.15543
DEAL:GMRES::Convergence step 1 value 2.89310e-13
DEAL::Cycle 1:
DEAL::   Number of active cells:       40
DEAL::   Number of degrees of freedom: 40
DEAL:GMRES::Starting value 4.46977
DEAL:GMRES::Convergence step 1 value 3.11815e-13
DEAL::Cycle 2:
DEAL::   Number of active cells:       80
DEAL::   Number of degrees of freedom: 80
DEAL:GMRES::Starting value 6.32373
DEAL:GMRES::Convergence step 1 value 3.22474e-13
DEAL::Cycle 3:
DEAL::   Number of active cells:       160
DEAL::   Number of degrees of freedom: 160
DEAL::
cycle cells dofs    L2(phi)     Linfty(alpha)
    0    20   20 4.465e-02    - 5.000e-02    -
    1    40   40 1.081e-02 2.05 2.500e-02 1.00
    2    80   80 2.644e-03 2.03 1.250e-02 1.00
    3   160  160 6.529e-04 2.02 6.250e-03 1.00
DEAL::
DEAL::Parsing parameter file parameters.prm
DEAL::for a 3 dimensional simulation.
DEAL:GMRES::Starting value 2.84666
DEAL:GMRES::Convergence step 3 value 8.68638e-18
DEAL::Cycle 0:
DEAL::   Number of active cells:       24
DEAL::   Number of degrees of freedom: 26
DEAL:GMRES::Starting value 6.34288
DEAL:GMRES::Convergence step 5 value 1.38740e-11
DEAL::Cycle 1:
DEAL::   Number of active cells:       96
DEAL::   Number of degrees of freedom: 98
DEAL:GMRES::Starting value 12.9780
DEAL:GMRES::Convergence step 5 value 3.29225e-11
DEAL::Cycle 2:
DEAL::   Number of active cells:       384
DEAL::   Number of degrees of freedom: 386
DEAL:GMRES::Starting value 26.0874
DEAL:GMRES::Convergence step 6 value 1.47271e-12
DEAL::Cycle 3:
DEAL::   Number of active cells:       1536
DEAL::   Number of degrees of freedom: 1538
DEAL::
cycle cells dofs    L2(phi)     Linfty(alpha)
    0    24   26 3.437e-01    - 2.327e-01    -
    1    96   98 9.794e-02 1.81 1.239e-01 0.91
    2   384  386 2.417e-02 2.02 6.319e-02 0.97
    3  1536 1538 5.876e-03 2.04 3.176e-02 0.99
@endverbatim



从2d中的收敛表可以看出，如果我们选择足够精确的正交公式，那么我们得到的 $\alpha(\mathbf{x})$ 的误差应该正好是元素数量的倒数。用N段大小相等的圆近似产生一个有N个面的正多边形，其角度正好是 $\pi-\frac {2\pi}{N}$ ，因此我们的误差应该正好是 $\frac 12 - (\frac 12 -\frac 1N) = \frac 1N$  。事实上，这是一个很好的指标，表明我们正在以适当的方式进行奇异积分。

势的近似 $\phi$ 的误差主要是由于域的近似。通过使用高阶映射可以得到更好的近似值。

如果我们修改main()函数，将fe_degree和mapping_degree设置为2，并提高参数文件中正交公式的顺序，我们得到以下二维模拟的收敛表

@verbatim
cycle cells dofs    L2(phi)     Linfty(alpha)
    0    20   40 5.414e-05    - 2.306e-04    -
    1    40   80 3.623e-06 3.90 1.737e-05 3.73
    2    80  160 2.690e-07 3.75 1.253e-05 0.47
    3   160  320 2.916e-08 3.21 7.670e-06 0.71
@endverbatim



和

@verbatim
cycle cells dofs    L2(phi)     Linfty(alpha)
    0    24   98 3.770e-03    - 8.956e-03    -
    1    96  386 1.804e-04 4.39 1.182e-03 2.92
    2   384 1538 9.557e-06 4.24 1.499e-04 2.98
    3  1536 6146 6.617e-07 3.85 1.892e-05 2.99
@endverbatim



三维的情况下。我们可以看到，高阶映射的收敛结果要好得多，这主要是由于曲线几何的分辨率更高。请注意，在自由度相同的情况下，例如在三维模拟中Q1案例的第3步和Q2案例的第2步，误差大约低三个数量级。

运行这些计算的结果是一堆输出文件，我们可以将其传递给我们选择的可视化程序。输出文件有两种：边界元素表面的势，以及扩展到内外域的势。在二维的情况下，这两个文件的组合看起来像

 <img src="https://www.dealii.org/images/steps/developer/step-34_2d.png" alt=""> 

而在三维空间中，我们首先显示的是表面上的电位，同时还有一个等高线图。

 <img src="https://www.dealii.org/images/steps/developer/step-34_3d.png" alt=""> 

然后是潜力的外部等高线图，不透明度设置为25%。

 <img src="https://www.dealii.org/images/steps/developer/step-34_3d-2.png" alt=""> 


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

这是第一个考虑解决嵌入高维空间的曲面上定义的方程的教程程序。但这里讨论的方程相对简单，因为它只涉及一个积分算子，而不涉及在曲面上更难定义的导数。step-38教程程序考虑了这类问题并提供了必要的工具。

从实际角度来看，这里使用的边界元素方法（BEM）有两个瓶颈。首先是组装矩阵的成本是*二次方的未知数，即 ${\cal O}(N^2)$ ，其中 $N$ 是未知数的总数。通过查看`assemble_system()`函数可以看出这一点，它有这样的结构。

@code
    for (const auto &cell : dof_handler.active_cell_iterators())
      {
        ...


        for (unsigned int i = 0; i < dof_handler.n_dofs(); ++i)
          ...
@endcode

这里，第一个循环走过了所有的单元格（一个系数 $N$ ），而内循环则贡献了另一个系数 $N$  。

这必须与*局部*微分算子的有限元方法进行对比。在那里，我们在所有单元上进行循环（ $N$ 的一个因子），并在每个单元上做一个与有多少单元或未知数无关的工作。这显然是一个瓶颈。

第二个瓶颈是系统矩阵是密集的（即是FullMatrix类型），因为每个自由度都与其他自由度相耦合。正如上面所指出的，仅仅*计算*这个带有 $N^2$ 非零项的矩阵必然需要至少 ${\cal O}(N^2)$ 次操作，但值得指出的是，仅仅做一个矩阵-向量乘积也需要这么多操作。如果用于解决线性系统的GMRES方法需要的迭代次数随着问题的大小而增长，就像通常的情况一样，那么解决线性系统需要的运算次数甚至比 ${\cal O}(N^2)$ 还要快。

"真实 "边界元素方法通过确定矩阵的哪些条目将是小的，因此可以被忽略的策略来解决这些问题（当然，代价是引入额外的误差）。这可以通过认识到矩阵项随着自由度 $i$ 和 $j$ 定义的位置之间的（物理）距离衰减而实现。这可以在快速多极法（FMM）等方法中得到利用，这些方法可以控制哪些矩阵项必须被存储和计算以达到一定的精度，并且--如果做得好的话--导致方法中线性系统的装配和求解都需要少于 ${\cal O}(N^2)$ 的操作。

实施这些方法显然为扩展目前的计划提供了机会。


examples/step-35/doc/intro.dox

 <br> 

<i>
This program grew out of a student project by Abner Salgado at Texas A&M
University. Most of the work for this program is by him.
</i>

<a name="Intro"></a>

<h1> Introduction </h1>

<a name="Motivation"></a>

<h3> Motivation </h3> 本程序的目的是展示如何有效地解决不可压缩的时间依赖性纳维-斯托克斯方程。这些方程描述了粘性不可压缩流体的流动，读作

@f{align*}
  u_t + u \cdot \nabla u - \nu \Delta u + \nabla p = f, \\
  \nabla \cdot u = 0,


@f}

其中 $u$ 表示流速， $p$ 表示压力。这个方程组由初始条件来补充

@f[
  u |_{t=0} = u_0,


@f]

与 $u_0$ 足够光滑和螺线管，以及合适的边界条件。例如，一个可接受的边界条件，是

@f[
  u|_{\partial\Omega} = u_b.


@f]

也可以规定其他边界条件。在我们这里解决的测试案例中，边界被划分为两个不相交的子集 $\partial\Omega = \Gamma_1 \cup \Gamma_2$ ，我们有

@f[
  u|_{\Gamma_1} = u_b,


@f]

和

@f[
 u\times n|_{\Gamma_2} = 0, \quad p|_{\Gamma_2} = 0


@f]

其中 $n$ 是外部单位法线。 $\Gamma_2$ 上的边界条件经常被用来模拟外流条件。

在以前的教程中（例如参见第20步和第22步），我们已经看到了如何使用Schur补数方法来解决与时间无关的斯托克斯方程。对于随时间变化的情况，在时间离散化之后，我们将得到一个类似于以下的系统

@f{align*}
  \frac1\tau u^k - \nu \Delta u^k + \nabla p^k = F^k, \\
  \nabla \cdot u^k = 0,


@f}

其中 $\tau$ 是时间步长。虽然这个系统的结构与斯托克斯系统相似，因此可以用Schur补数的方法来解决，但事实证明，Schur补数的条件数与 $\tau^{-2}$ 成正比。这使得该系统非常难解，也意味着对于纳维-斯托克斯方程来说，这不是一个有用的求解途径。

<a name="Projection"></a>

<h3> Projection methods </h3>

相反，我们需要想出一个不同的方法来解决与时间有关的纳维-斯托克斯方程。解决这些问题的困难来自于速度和压力是通过约束条件耦合在一起的事实

@f[
  \nabla \cdot u = 0,


@f]

对其而言，压力是拉格朗日乘数。投影方法旨在将这一约束与扩散（拉普拉斯）算子脱钩。

让我们简短地描述一下投影方法在半离散情况下的样子。我们的目标是获得一个速度 $\{u^k\}$ 和压力 $\{p^k\}$ 序列。我们还将得到一个辅助变量的序列 $\{\phi^k\}$ 。假设从初始条件和一阶方法的应用中我们已经找到了  $(u^0,p^0,\phi^0=0)$  和  $(u^1,p^1,\phi^1=p^1-p^0)$  。那么投影法包括以下步骤。   <ul>   <li>  <b>Step 0</b> 。外推法。定义一下。   @f[
    u^\star = 2u^k - u^{k-1}, \quad p^\sharp = p^k + \frac43 \phi^k - \frac13 \phi^{k-1}.
  @f]

    <li>  <b>Step 1</b>:扩散步骤。我们发现 $u^{k+1}$ 可以解决单一线性方程@f[
    \frac1{2\tau}\left( 3u^{k+1} - 4u^k + u^{k-1} \right)
    + u^\star \cdot\nabla u^{k+1} + \frac12 \left( \nabla \cdot u^\star \right) u^{k+1}


    -\nu \Delta u^{k+1} + \nabla p^\sharp
    = f^{k+1},
    \quad
    u^{k+1}|_{\Gamma_1} = u_b,
    \quad
    u^{k+1} \times n|_{\Gamma_2} = 0.
  @f]。



    <li>  <b>Step 2</b>:投影。找到能解决@f[
    \Delta \phi^{k+1} = \frac3{2\tau} \nabla \cdot u^{k+1},
    \quad
    \partial_n \phi^{k+1}|_{\Gamma_1} = 0,
    \quad
    \phi^{k+1}|_{\Gamma_2} = 0
  @f]的 $\phi^{k+1}$ 。

    <li>  <b>Step 3</b>:压力校正。这里我们有两个选项。       <ul>   <li>  <i>Incremental Method in Standard Form</i>。压力的更新方式是。       @f[
        p^{k+1} = p^k + \phi^{k+1}.
      @f]

        <li>  <i>Incremental Method in Rotational Form</i>。在这种情况下，@f[
        p^{k+1} = p^k + \phi^{k+1} - \nu \nabla \cdot u^{k+1}.
      @f] 。

      </ul>  </ul>  。

在不详细说明的情况下，让我们对我们刚刚描述的投影方法做一些说明。   <ul>   <li>  平流项 $u\cdot\nabla u$ 被其<i>skew symmetric form</i> @f[
    u \cdot \nabla u + \frac12 \left( \nabla\cdot u \right) u.
  @f]取代。

  这与连续方程是一致的（因为 $\nabla\cdot u = 0$  ，尽管对于离散解来说，这在点上是不正确的），它需要保证时间步进方案的无条件稳定性。此外，为了使该术语线性化，我们使用 $u^\star$ 的二阶外推 $u^{k+1}$  。     <li>  投影步骤是亥姆霍兹分解的实现 @f[
    L^2(\Omega)^d = H \oplus \nabla H^1_{\Gamma_2}(\Omega),
  @f] 。

  其中@f[
    H = \left\{ v \in L^2(\Omega)^d:\  \nabla\cdot v =0, \  v\cdot n|_{\Gamma_1} = 0 \right\},
  @f]

  和@f[
    H^1_{\Gamma_2}(\Omega) = \left\{ q \in H^1(\Omega):\ q|_{\Gamma_2} = 0 \right\}.
  @f]

  事实上，如果我们在 $u^{k+1}$ 上使用这种分解，我们可以得到@f[
    u^{k+1} = v^{k+1} + \nabla \left( \frac{2\tau}{3}  \phi^{k+1} \right),
  @f]

  与 $v^{k+1}\in H$  。取这个方程的发散，我们得出了投影方程。     <li>  上面概述的两种变体中更准确的是旋转变体。然而，下面的程序同时实现了两种变体。此外，根据作者的经验，如果粘度 $\nu$ 是可变的，应该使用标准形式。   </ul> 


 <p>  van Kan在 <ul>   <li>  J. van Kan, "A second-order accurate pressure-correction scheme for viscous incompressible flow", SIAM Journal on Scientific and Statistical Computing, Vol. 7, no.3, pp. 870-891, 1986  </ul>  并由Guermond在 <ul>   <li>  J.-L. Guermond分析。L. Guermond, "Un résultat de convergence d'ordre deux en temps pour l'approximation des équations de Navier-Stokes par une technique de projection incrémentale", ESAIM: Mathematical Modelling and Numer Analysis, vol. 33, no. 1, pp. 169-189, 1999  </ul>  。事实证明，这种技术受到运动压力的非物理边界条件的影响，导致收敛率降低。为了防止这种情况，Timmermans等人在 <ul>   <li>  L. Timmermans, P. Minev, and F. Van De Vosse, "An approximate projection scheme for incompressible flow using spectral elements", International Journal for Numerical Methods in Fluids, vol. 22, no. 7, pp.673-688, 1996  </ul>  旋转压力校正投影方法，使用运动压力的分歧校正。 <ul>   <li>  J.-L. Guermond和J. Shen, "On the error estimates for the rotational pressure-correction projection methods", Mathematics of Computation, vol. 73, no. 248, pp.1719-1737, 2004  </ul>  对Stokes问题进行了全面分析。   </p> 

<a name ="fullydiscrete"></a>

<h3> The Fully Discrete Setting </h3>为了获得该方法的完全离散设置，我们一如既往地需要一个变分公式。鉴于边界条件的性质，这里有一个微妙的问题。当我们把方程乘以一个合适的测试函数时，出现的一个项是

@f[


  -\nu \int_\Omega \Delta u \cdot v.


@f]

如果我们，比如说，在整个边界上有迪里希特的边界条件，那么经过部分积分，我们将得到

@f[


  -\nu \int_\Omega \Delta u \cdot v = \nu \int_\Omega \nabla u : \nabla v


                                    - \int_{\partial\Omega} \partial_n u \cdot v
                                    = \nu \int_\Omega \nabla u : \nabla v.


@f]

这种表述的优点之一是，它完全解耦了速度的各个组成部分。此外，它们都共享同一个系统矩阵。这可以在程序中加以利用。

然而，考虑到非标准的边界条件，为了能够考虑到这些条件，我们需要使用以下%的特征

@f[
  \Delta u = \nabla\nabla\cdot u - \nabla\times\nabla\times u,


@f]

因此，当我们通过部分积分并考虑到边界条件时，我们可以得到

@f[


  -\nu \int_\Omega \Delta u \cdot v = \nu \int_\Omega \left[ \nabla \cdot u \nabla \cdot v
                                    + \nabla \times u \nabla \times v \right],


@f]

这就是我们必须使用的形式。请注意，这是对速度分量的耦合。此外，为了强制执行压力的边界条件，我们需要重写

@f[
  \int_\Omega \nabla p \cdot v = -\int_\Omega p \nabla \cdot v + \int_{\Gamma_1} p v\cdot n
                                + \int_{\Gamma_2} p v\cdot n
                               = -\int_\Omega p \nabla \cdot v,


@f]

其中 $\Gamma_1$ 中的边界积分在速度的边界条件下等于零， $\Gamma_2$ 中的积分在压力的边界条件下等于零。

在简化的情况下，边界 $\Gamma_2$ 与坐标轴平行%，这在我们下面进行的测试案例中成立，实际上可以表明

@f[
  \nu \int_\Omega \nabla u : \nabla v = \nu \int_\Omega \left[ \nabla \cdot u \nabla \cdot v
                                    + \nabla \times u \nabla \times v \right].


@f]

这个问题在文献中并不经常涉及。更多信息，读者可以参考，例如， <ul>   <li>  J.-L. GUERMOND, L. QUARTAPELLE, On the approximation of the unsteady Navier-Stokes equations by finite element projection methods, Numer.Math., 80 (1998) 207-238  <li>  J.-L. GUERMOND, P. MINEV, J. SHEN, Error analysis of pressure-correction schemes for the Navier-Stokes equations with open boundary conditions, SIAM J. Numer.Anal., 43 1 (2005) 239-258.   </ul> 




<a name = "implementation"></a>

<h3> Implementation </h3>

我们对投影方法的实现遵循<i>verbatim</i>上面的描述。然而，我们必须注意到，与其他大多数有多个解分量的问题不同，我们没有使用矢量值的有限元。相反，我们对速度和压力的分量分别使用单独的有限元，并对这些分量使用不同的 <code>DoFHandler</code> 's。这样做的主要原因是，正如我们从方案的描述中看到的，速度和压力的 <code>dim</code> 分量是解耦的。因此，所有速度分量的方程看起来都是一样的，具有相同的系统矩阵，并能以%的速度平行求解。很明显，这种方法也有其缺点。例如，在集合矩阵和右手边时，我们需要保持几个 <code>DoFHandler</code> s和迭代器的同步；获得矢量值函数的固有量（如发散）变得有点尴尬，以及其他。

<a name ="testcase"></a>

<h3> The Testcase </h3>

我们在这个程序中使用的测试案例包括围绕一个方形障碍物的流动。其几何形状如下。

 <img src="https://www.dealii.org/images/steps/developer/step-35.geometry.png" alt=""> 

与 $H=4.1$ ，使几何形状略微不对称。

我们在顶壁、底壁和障碍物上都施加了无滑动的边界条件。在左边，我们有流入的边界条件

@f[
  u =
  \left( \begin{array}{c} 4 U_m y (H-y)/H^2 \\ 0 \end{array} \right),


@f]

与 $U_m = 1.5$ ，即流入的边界条件对应于这个配置的Poiseuille流。最后，在右边的垂直壁上，我们规定速度的垂直分量和压力都应该是零。最后的时间  $T=10$  。


examples/step-35/doc/results.dox

<a name="results"></a>

<h1>Results</h1>

<a name="Re100"></a>

<h3> Re = 100 </h3>

我们用下面的 <code>parameter-file.prm</code> 来运行代码，它可以在与源代码相同的目录中找到。

@verbatim
  # First a global definition
  # the type of method we want to use
  set Method_Form = rotational


  subsection Physical data
    # In this subsection we declare the physical data
    # The initial and final time, and the Reynolds number
    set initial_time = 0.
    set final_time   = 25.
    set Reynolds     = 100
  end


  subsection Time step data
    # In this subsection we declare the data that is to be used for time discretization,
    # i.e. the time step dt
    set dt = 5e-3
  end


  subsection Space discretization
    # In this subsection we declare the data that is relevant to the space discretization
    # we set the number of global refines the triangulation must have
    # and the degree k of the pair Q_(k+1)--Q_k of velocity--pressure finite element spaces
    set n_of_refines = 3
    set pressure_fe_degree = 1
  end


  subsection Data solve velocity
    # In this section we declare the parameters that are going to control the solution process
    # for the velocity.
    set max_iterations = 1000  # maximal number of iterations that GMRES must make
    set eps            = 1e-6  # stopping criterion
    set Krylov_size    = 30    # size of the Krylov subspace to be used in GMRES
    set off_diagonals  = 60    # number of off diagonals that ILU must compute
    set diag_strength  = 0.01  # diagonal strengthening value
    set update_prec    = 10    # this number indicates how often the preconditioner must be updated
  end


  #The output frequency
  set output = 50


  #Finally we set the verbosity level
  set verbose = false
@endverbatim



由于 <code>verbose</code> parameter is set to <code>false</code> ，除了程序当前工作的时间步数，我们没有得到任何形式的输出。如果我们把它设置为 <code>true</code> ，我们就会得到关于程序正在做什么以及每个迭代过程要做多少步才能收敛等信息。

让我们绘制 $t=1,5,12,20,25$ （即时间步长200、1000、2400、4000和5000）的所得结果，其中左栏显示涡度，右栏显示速度场。

 <table>
  <tr>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.vorticity.0.9.3.png" alt="" width="400"> </td>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.velocity.0.9.3.png" alt="" width="400"> </td>
  </tr>
  <tr>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.vorticity.1.9.3.png" alt="" width="400"> </td>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.velocity.1.9.3.png" alt="" width="400"> </td>
  </tr>
  <tr>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.vorticity.2.9.3.png" alt="" width="400"> </td>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.velocity.2.9.3.png" alt="" width="400"> </td>
  </tr>
  <tr>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.vorticity.3.9.3.png" alt="" width="400"> </td>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.velocity.3.9.3.png" alt="" width="400"> </td>
  </tr>
  <tr>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.vorticity.4.9.3.png" alt="" width="400"> </td>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_100.velocity.4.9.3.png" alt="" width="400"> </td>
  </tr>
</table> 

图像很好地显示了障碍物后面涡流链的发展和延伸，涡度的符号表明这是一个左转或右转的涡流。


<a name="Re500"></a>

<h3> Re = 500 </h3>

我们可以将参数文件中的雷诺数  $Re$  改为  $500$  。这样做，并在一定程度上减少时间步长，在时间 $t=20,40$ 时得到以下图像。

 <table>
  <tr>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_500.vorticity.0.9.3.png" alt="" width="400"> </td>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_500.velocity.0.9.3.png" alt="" width="400"> </td>
  </tr>
  <tr>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_500.vorticity.1.9.3.png" alt="" width="400"> </td>
    <td> <img src="https://www.dealii.org/images/steps/developer/step-35.Re_500.velocity.1.9.3.png" alt="" width="400"> </td>
  </tr>
</table> 

对于这个较大的雷诺数，我们观察到不切实际的振荡，特别是涡度的振荡。离散化方案现在很难正确地解决流动问题，而流动应该仍然是层状的和有组织的。这些现象是典型的离散化方案，它们在溶解度不足的情况下缺乏稳健性，其中溶解度不足意味着用网格尺寸而不是几何体的物理尺寸计算的雷诺数很大。我们看一下放大的障碍物后面的区域，以及我们在那里的网格尺寸。


 <img src="https://www.dealii.org/images/steps/developer/step-35.Re_500.zoom.9.3.png" alt="" width="400"> 

我们可以通过在参数文件中多设置一个网格细化来重新运行模拟，从而轻松测试我们的假设。

 <img src="https://www.dealii.org/images/steps/developer/step-35.Re_500.zoom_2.9.3.png" alt="" width="400"> 

事实上，现在的涡度场看起来更加平滑了。虽然我们可以预期进一步细化网格也会抑制剩余的振荡，但我们应该采取措施在粗略分辨率的限制下获得一个强大的方案，如下所述。


<a name="extensions"></a>

<h3> Possibilities for extensions </h3>

这个程序可以在以下方向扩展。   <ul>   <li>  自适应网格细化。正如我们所看到的，我们在一个单一的固定网格上计算了所有的东西。   使用自适应网格细化可以导致精度的提高，同时不会明显增加计算时间。

    <li>  自适应时间步长。虽然目前显然没有关于可变时间步长的投影方法的理论，但实践表明，它们的表现非常好。

    <li>  高雷诺%数。正如我们从结果中看到的，增加雷诺数会大大改变离散化方案的行为。使用众所周知的稳定化技术，我们可以计算这个问题或其他许多问题中的流动，当雷诺数非常大，计算成本要求空间分辨率，而流动只能得到有限的解决，特别是对于三维湍流。

    <li>  可变密度的不可压缩流。对于密度可变的不可压缩流的情况，有类似投影的方法。如果不同密度的流体混合在一起，例如淡水和盐水，或者酒精和水，这种流动就会发挥作用。

    <li>  可压缩纳维-斯托克斯方程。这些方程适用于这样的情况：速度足够高，以至于流体变得可压缩，但速度不够快，以至于我们进入了一个粘度变得可以忽略的制度，纳维-斯托克斯方程需要被气体动力学的双曲欧拉方程取代。如果速度超过音速的三分之一，可压缩性就开始成为一个因素，所以它对几乎所有的地面交通工具来说都不是一个因素。另一方面，商业喷气式飞机的飞行速度约为音速的85%，机翼上的流动变得明显超音速，在这种情况下，可压缩的纳维尔-斯托克斯方程也不再适用。然而，在这两者之间的范围有重要的应用，如小型飞机或许多欧洲和东亚国家的快速列车。   </ul> 


examples/step-36/doc/intro.dox

 <br> 

<i>This program was contributed by Toby D. Young and Wolfgang
Bangerth.  </i>

<a name="Preamble"></a>

<h1>Preamble</h1>

在这个例子中，我们要解决的问题是一个特征谱问题。特征值问题出现在广泛的问题背景中，例如在计算腔体中的电磁驻波、鼓膜的振动模式或湖泊和河口的振荡中。最神秘的应用之一可能是量子力学中静止或准静止波函数的计算。后一种应用是我们在此想研究的，尽管本方案中概述的一般技术当然同样适用于上述其他应用。

Eigenspectrum问题的一般形式是

@f{align*}
	L \Psi &= \varepsilon \Psi \qquad &&\text{in}\ \Omega\quad,
	\\
	\Psi &= 0 &&\text{on}\ \partial\Omega\quad,


@f}

其中 $\Psi=\Psi(\mathbf x)$ 上的迪里切特边界条件也可以用诺伊曼或罗宾条件代替； $L$ 是一个算子，一般也包含微分算子。

在适当的条件下，上述方程有一组解 $\Psi_\ell,\varepsilon_\ell$  ,  $\ell\in {\cal I}$  ，其中 $\cal I$ 可以是一个有限的或无限的集合（在后一种情况下，它可能是一个离散的或有时至少是部分连续的集合）。在这两种情况下，让我们注意到，我们要计算的不再只是一个单一的解决方案，而是一组解决方案（各种特征函数和相应的特征值）。从数字上寻找这类特征值问题的所有特征值（特征函数）的问题是一个艰巨的挑战。事实上，如果集合 $\cal I$ 是无限的，这个挑战当然是难以解决的。  然而，大多数时候，我们实际上只对这些值（函数）的一小部分感兴趣；幸运的是，我们将在这个教程程序中使用的SLEPc库的接口允许我们选择特征谱的哪一部分和我们想要解决的多少个解决方案。

在这个程序中，我们使用的eigenspectrum求解器是由deal.II提供的类，围绕<a href="http://www.grycap.upv.es/slepc/" target="_top">SLEPc</a>库的线性代数实现；SLEPc本身建立在<a
href="http://www.mcs.anl.gov/petsc/" target="_top">PETSc</a>库的线性代数内容之上。

<a name="Intro"></a>

<h1>Introduction</h1>

静止的量子力学的基本方程是薛定谔方程，它模拟粒子在外部势中的运动  $V(\mathbf x)$  。粒子由一个波函数 $\Psi(\mathbf x)$ 描述，它满足一个（非维度化）形式的关系

@f{align*} [-\Delta + V(\mathbf x)]
\Psi(\mathbf x) &= \varepsilon \Psi(\mathbf x) \qquad &&\text{in}\
\Omega\quad, \\ \Psi &= 0 &&\text{on}\ \partial\Omega\quad.


@f}

因此，这个粒子只能存在于一定数量的特征态中，这些特征态对应于作为该方程解的能量特征值 $\varepsilon_\ell$ 。量子力学的正统（哥本哈根）解释认为，如果一个粒子具有能量 $\varepsilon_\ell$ ，那么在位置 $\mathbf x$ 找到它的概率与 $|\Psi_\ell(\mathbf
x)|^2$ 成正比，其中 $\Psi_\ell$ 是对应于这个特征值的特征函数。

为了在数值上找到这个方程的解，即一组成对的特征值/特征函数，我们使用通常的有限元方法，将左边的方程与测试函数相乘，通过部分积分，在有限维空间中通过近似 $\Psi(\mathbf
x)\approx\Psi_h(\mathbf x)=\sum_{j}\phi_j(\mathbf x)\tilde\psi_j$ 寻找解，其中 $\tilde\psi$ 是一个扩展系数的矢量。然后，我们立即得出以下方程，将连续特征值问题离散化：@f[ \sum_j [(\nabla\phi_i,
\nabla\phi_j)+(V(\mathbf x)\phi_i,\phi_j)] \tilde{\psi}_j =
\varepsilon_h \sum_j (\phi_i, \phi_j) \tilde{\psi}_j\quad.  @f] 在矩阵和矢量符号中，这个方程然后读作。@f[ A
\tilde{\Psi} = \varepsilon_h M \tilde{\Psi} \quad, @f] 其中 $A$ 是由微分算子 $L$ 产生的刚度矩阵，而 $M$ 是质量矩阵。特征值问题的解决方案是一个特征谱  $\varepsilon_{h,\ell}$  ，以及相关的特征函数  $\Psi_\ell=\sum_j \phi_j\tilde{\psi}_j$  。




<h3>Eigenvalues and Dirichlet boundary conditions</h3>

在这个程序中，我们对波函数 $\Psi$ 使用了Dirichlet边界条件。从有限元代码的角度来看，这意味着只有内部的自由度是<i>freedom</i>的实数度：边界上的自由度不是自由的，但毕竟是被迫有一个零值。另一方面，有限元方法的力量和简单性主要来自于我们只是在每个单元上做同样的事情，而不需要过多考虑一个单元在哪里，它是否在一个不太精细的单元上，因此有一个悬挂的节点，或者与边界相邻。所有这些检查都会使有限元线性系统的组装变得难以忍受，甚至更难阅读。

因此，当然，当你用DoFHandler对象分配自由度时，你并不关心你列举的一些自由度是否处于迪里切特边界。他们都会得到数字。我们只需要在以后应用边界值的时候照顾到这些自由度。有两种基本的方法（要么使用 MatrixTools::apply_boundary_values() <i>after</i>装配线性系统，要么使用 AffineConstraints::distribute_local_to_global() <i>during</i>装配；更多信息见 @ref constraints "约束模块"），但两者的结果都一样：一个线性系统的总行数等于<i>all</i>自由度的数量，包括那些位于边界的自由度。然而，受迪里希特条件约束的自由度与线性系统的其他部分分开，方法是将相应的行和列清零，在对角线上放一个正条目，并在右手边放相应的迪里希特值。

如果你暂时假设我们将自由度重新编号，使迪里切特边界上的所有自由度排在最后，那么我们在求解一个有右手边的常规PDE时得到的线性系统将是这样的。

@f{align*}
  \begin{pmatrix}
    A_i & 0 \\ 0 & D_b
  \end{pmatrix}
  \begin{pmatrix}
    U_i \\ U_b
  \end{pmatrix}
  =
  \begin{pmatrix}
    F_i \\ F_b
  \end{pmatrix}.


@f}

这里，下标 $i$ 和 $b$ 分别对应于内部和边界自由度。内部自由度满足线性系统 $A_i U_i=F_i$ ，在内部产生正确的解，边界值由 $U_b = D_b^{-1} F_b$ 决定，其中 $D_b$ 是一个对角矩阵，由消除边界自由度的过程产生， $F_b$ 是以这样的方式选择的： $U_{b,j}=D_{b,jj}^{-1} F_{b,j}$ 对每个边界自由度 $j$ 都有正确的边界值。 对于好奇的人来说，矩阵 $D_b$ 的条目是将修改后的局部贡献加入全局矩阵的结果，对于局部矩阵，如果非零，对角线元素被设置为其绝对值；否则，它们被设置为对角线的绝对值的平均值。这个过程保证了 $D_b$ 的条目是正的，并且大小与对角线的其他条目相当，确保所产生的矩阵不会因为涉及到大小迥异的矩阵条目的舍入而产生不合理的精度损失。最终出现在对角线上的实际数值是很难预测的，你应该把它们当作任意的、不可预测的，但却是正的。)

对于 "常规 "的线性系统，这一切都导致了正确的解决方案。另一方面，对于特征值问题，这就不那么简单了。在那里，消除边界值会影响到我们在当前教程程序中要解决的矩阵 $A$ 和 $M$ 。消除边界值后，我们就会得到一个可以这样划分的特征值问题。

@f{align*}
  \begin{pmatrix}
    A_i & 0 \\ 0 & D_A
  \end{pmatrix}
  \begin{pmatrix}
    \tilde\Psi_i \\ \tilde\Psi_b
  \end{pmatrix}
  =
  \epsilon_h
  \begin{pmatrix}
    M_i & 0 \\ 0 & D_M
  \end{pmatrix}
  \begin{pmatrix}
    \tilde\Psi_i \\ \tilde\Psi_b
  \end{pmatrix}.


@f}

这种形式清楚地表明，有两组特征值：我们关心的那些，以及来自分离问题的虚假特征值。

@f[
  D_A \tilde \Psi_b = \epsilon_h D_M \Psi_b.


@f]

这些特征值是虚假的，因为它们是由一个只在边界节点上操作的特征值系统产生的--这些节点不是<i>freedom</i>的实数度。当然，由于两个矩阵 $D_A,D_M$ 是对角线，我们可以准确地量化这些虚假的特征值：它们是 $\varepsilon_{h,j}=D_{A,jj}/D_{M,jj}$ （其中指数 $j$ 正好对应于受迪里切特边界值约束的自由度）。

那么，如何处理这些问题呢？第一部分是识别我们的特征值求解器何时找到其中一个。为此，程序通过计算所有受限自由度上表达式 $\varepsilon_{h,j}=D_{A,jj}/D_{M,jj}$ 的最小和最大，计算并打印出这些特征值所在的区间。在下面的程序中，这已经足够了：我们发现这个区间位于我们感兴趣并计算的最小特征值和相应的特征函数的集合之外，所以这里我们不需要做什么。

另一方面，我们可能会发现我们在这个程序中计算的一个特征值恰好在这个区间内，在这种情况下，我们不会立即知道它是一个虚假的还是一个真正的特征值。在这种情况下，我们可以在计算完两个矩阵后简单地缩放其中一个矩阵的对角线元素，从而将它们从特征谱的感兴趣的频率上移开。这可以通过使用以下代码来完成，确保所有假的特征值都正好等于 $1.234\cdot 10^5$  。

@code
    for (unsigned int i = 0; i < dof_handler.n_dofs(); ++i)
      if (constraints.is_constrained(i))
        {
          stiffness_matrix.set(i, i, 1.234e5);
          mass_matrix.set(i, i, 1);
        }
@endcode

然而，这里没有采用这种策略，因为我们从程序中得到的虚假特征值恰好大于我们将计算的和感兴趣的最低的五个。




<h3>Implementation details</h3>

下面的程序实质上只是步骤4的一个稍加修改的版本。有所不同的是以下几点。

 <ul> 

 <li>  主类（名为  <code>EigenvalueProblem</code>  ）现在不再有单一的解向量，而是有一整套我们想要计算的各种特征函数的向量。此外， <code>main</code> 函数对这里的一切都有顶层控制，它通过 <code>SlepcInitialize</code> 和 <code>SlepFinalize</code> 同时初始化和最终确定SLEPc和PETSc的接口。 </li> 

 <li>  我们在步骤17和步骤18中使用PETSc矩阵和向量，因为这是SLEPc特征值求解器所要求的。 </li> 

 <li>  函数 <code>EigenvalueProblem::solve</code> 与教程中迄今为止所见的任何函数都完全不同，因为它不只是求解一个线性系统，而是实际求解特征值问题。它建立在SLEPc库上，更直接的是建立在类 SLEPcWrappers::SolverKrylovSchur.</li> 的deal.II SLEPc包装器上。

 <li>  我们使用ParameterHandler类来描述一些输入参数，如势的确切形式 $V({\mathbf
x})$  ，网格的全局细化步数，或我们要解决的特征值的数量。我们可以在这方面做得更多，但只限于在运行时选择一些实际的输入文件参数。为了看看在这方面可以做什么，看看 @ref step_29 "步骤-29 "和步骤-33。 </li> 

 <li>  我们使用FunctionParser类使潜在  $V(\mathbf
x)$  的运行时参数，可以在输入文件中指定为公式。 </li> 

 </ul> 

程序的其余部分以一种相当直接的方式从第4步开始。


examples/step-36/doc/results.dox



<h1>Results</h1>

<h3>Running the problem</h3>

该问题的输入由一个输入文件 <code>\step-36.prm</code> 设定参数，例如，该文件可以包含以下文本。

@code
set Global mesh refinement steps         = 5
set Number of eigenvalues/eigenfunctions = 5
set Potential                            = 0
@endcode



这里，域内电势为零，我们知道特征值由 $\lambda_{(mn)}=\frac{\pi^2}{4}(m^2+n^2)$ 给出，其中 $m,n\in{\mathbb N^+}$  。特征函数是正弦和余弦，在 $m$ 和 $n$ 方向的周期为 $x$ 和 $y$ 。这与我们的程序产生的输出相匹配。

@code
examples/\step-36> make run
============================ Running \step-36
   Number of active cells:       1024
   Number of degrees of freedom: 1089
   Solver converged in 67 iterations.


      Eigenvalue 0 : 4.93877
      Eigenvalue 1 : 12.3707
      Eigenvalue 2 : 12.3707
      Eigenvalue 3 : 19.8027
      Eigenvalue 4 : 24.837


   Job done.  @endcode 这些特征值正是对应于 $(m,n)=(1,1)$ 、 $(1,2)$ 和 $(2,1)$ 、 $(2,2)$ 和 $(3,1)$ 等对。相应的特征方程的可视化看起来是这样的。

 <table width="80%">
<tr>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.default.eigenfunction.0.png" alt=""></td>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.default.eigenfunction.1.png" alt=""></td>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.default.eigenfunction.2.png" alt=""></td>
</tr>
<tr>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.default.eigenfunction.3.png" alt=""></td>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.default.eigenfunction.4.png" alt=""></td>
<td></td>
</tr>
</table> 

<h3>Possibilities for extensions</h3>

在操场上玩几个游戏总是值得的!所以这里有几个建议。

 <ul> 

 <li> 上面使用的势（称为<i>infinite well</i>，因为它是一个由无限高的墙包围的平坦势）很有趣，因为它允许有分析上已知的解决方案。然而，除此之外，它是相当无聊的。也就是说，通过在输入文件中设置不同的势来玩弄这个势是很容易的。例如，让我们假设我们想在2d中使用以下势。

@f[
  V(x,y) = \left\{
       \begin{array}{ll}


         -100 & \text{if}\ \sqrt{x^2+y^2}<\frac 34 \ \text{and}
                         \ xy>0
         \\


         -5 & \text{if}\ \sqrt{x^2+y^2}<\frac 34 \ \text{and}
                         \ xy\le 0
         \\
         0 & \text{otherwise}
      \end{array} \right.\quad.


@f]

换句话说，在半径为0.75的圆的两个扇面中，电位为-100，在另外两个扇面中为-5，而在圆外为零。我们可以通过在输入文件中使用以下内容来实现这一点。

@code
set Potential = if (x^2 + y^2 < 0.75^2, if (x*y > 0, -100, -5), 0)
@endcode

此外，如果我们还将网格细化程度提高一级，我们会得到以下结果。

@code
examples/\step-36> make run
============================ Running \step-36
   Number of active cells:       4096
   Number of degrees of freedom: 4225


   Eigenvalue 0 : -74.2562
   Eigenvalue 1 : -72.7322
   Eigenvalue 2 : -42.7406
   Eigenvalue 3 : -42.2232
   Eigenvalue 4 : -37.0744
@endcode



输出文件还包含一个内插的势的版本，看起来像这样（注意，正如预期的那样，最低的几个特征模式的概率密度 $|\Psi(\mathbf x)|^2$ 只有在势最低的地方才是显著的，即在势的内圈的右上角和左下角部分）。

 <img src="https://www.dealii.org/images/steps/developer/step-36.mod.potential.png" alt=""> 

前五个特征函数现在是这样的。

 <table width="80%">
<tr>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.mod.eigenfunction.0.png" alt=""></td>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.mod.eigenfunction.1.png" alt=""></td>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.mod.eigenfunction.2.png" alt=""></td>
</tr>
<tr>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.mod.eigenfunction.3.png" alt=""></td>
<td><img src="https://www.dealii.org/images/steps/developer/step-36.mod.eigenfunction.4.png" alt=""></td>
<td></td>
</tr>
</table> 

 <li> 在我们对问题的推导中，我们假设粒子被限制在一个域 $\Omega$ 中，并且在这个域的边界处，它的概率 $|\Psi|^2$ 为零。这相当于解决所有 ${\mathbb R}^d$ 上的特征值问题，并假设能量势只在 $\Omega$ 区域内是有限的，而在区域外是无限的。比较容易的是，在 $|\Psi(\mathbf x)|^2$ 的所有位置 $\mathbf x$ ， $V(\mathbf
x)=\infty$ 。那么问题来了，如果我们的势不是这种形式的，即没有一个势是无限的有界域，会发生什么？在这种情况下，可能值得只考虑一个非常大的边界域，其中 $V(\mathbf x)$ 即使不是无限的，也至少是非常大的。在这样的情况下玩一玩，探索一下当我们使计算区域越来越大时，频谱和特征函数如何变化。

 <li>  如果我们研究简单的谐波振荡器问题 $V(\mathbf x)=c|\mathbf x|^2$ 会怎样？这个势正是上一段所讨论的形式，具有超球面对称性。人们可能想用一个大的外半径的球面域，来近似于全空间问题（例如，通过引用 GridGenerator::hyper_ball). 

 <li>  上面的图显示了波函数  $\Psi(\mathbf x)$  ，但感兴趣的物理量实际上是粒子处于位置  $|\Psi(\mathbf x)|^2$  的概率密度。一些可视化程序可以从输入文件中的数据计算出衍生量，但我们也可以在创建输出文件时立即这样做。这样做的工具是DataPostprocessor类，可以和DataOut类一起使用。如何做到这一点的例子可以在步骤29和步骤33中找到。

 <li>  如果盒子里的粒子有%的内部自由度会怎样？例如，如果该粒子是一个自旋-  $1/2$  粒子？在这种情况下，我们可能要开始解决一个矢量值的问题，而不是。

 <li>  我们这里的deal.II库的实现使用PETScWrappers和SLEPcWrappers，适合在串行机器架构上运行。然而，对于更大的网格和更多的自由度，我们可能希望在并行架构上运行我们的应用程序。上述代码的并行实现在这里可能特别有用，因为广义的特征谱问题比前面大多数教程中考虑的标准问题的解决成本更高。幸运的是，修改上述程序使其符合MPI标准是一个相对简单的过程。关于如何做到这一点的简图可以在 @ref
step_17 "step-17 "中找到。

deal.II有与其中之一ARPACK（见<a
href="../../external-libs/arpack.html">the ARPACK configuration page</a>的设置说明）的接口，在ArpackSolver类中实现。下面是一个简短的、快速的概述，说明使用它需要改变什么，前提是你有一个工作的ARPACK安装，并且deal.II已经为它正确配置了（见deal.II <a href="../../readme.html" target="body">README</a>文件）。

首先，为了使用ARPACK接口，我们可以回到使用标准的deal.II矩阵和向量，所以我们首先替换PETSc和SLEPc头文件

@code
#include <deal.II/lac/petsc_sparse_matrix.h>
#include <deal.II/lac/petsc_vector.h>
#include <deal.II/lac/slepc_solver.h>
@endcode

与这些。

@code
#include <deal.II/lac/arpack_solver.h>
#include <deal.II/lac/sparse_direct.h>
#include <deal.II/lac/sparse_matrix.h>
#include <deal.II/lac/compressed_sparsity_pattern.h>
@endcode

ARPACK允许复杂的特征值，所以我们还需要

@code
#include <complex>
@endcode



其次，我们在主类中切换回deal.II矩阵和向量定义。

@code
    SparsityPattern                     sparsity_pattern;
    SparseMatrix<double>                stiffness_matrix, mass_matrix;
    std::vector<Vector<double> >        eigenfunctions;
    std::vector<std::complex<double>>   eigenvalues;
@endcode

并按照惯例对它们进行初始化  <code>make_grid_and_dofs()</code>  。

@code
    sparsity_pattern.reinit (dof_handler.n_dofs(),
                             dof_handler.n_dofs(),
                             dof_handler.max_couplings_between_dofs());


    DoFTools::make_sparsity_pattern (dof_handler, sparsity_pattern);
    constraints.condense (sparsity_pattern);
    sparsity_pattern.compress();


    stiffness_matrix.reinit (sparsity_pattern);
    mass_matrix.reinit (sparsity_pattern);
@endcode



为了用ARPACK解决特征值问题，我们最后需要修改  <code>solve()</code>  。

@code
  template <int dim>
  unsigned int EigenvalueProblem<dim>::solve ()
  {
    SolverControl solver_control (dof_handler.n_dofs(), 1e-9);


    SparseDirectUMFPACK inverse;
    inverse.initialize (stiffness_matrix);


    const unsigned int num_arnoldi_vectors = 2*eigenvalues.size() + 2;
    ArpackSolver::AdditionalData additional_data(num_arnoldi_vectors);


    ArpackSolver eigensolver (solver_control, additional_data);
    eigensolver.solve (stiffness_matrix,
                       mass_matrix,
                       inverse,
                       eigenvalues,
                       eigenfunctions,
                       eigenvalues.size());


    for (unsigned int i=0; i<eigenfunctions.size(); ++i)
      eigenfunctions[i] /= eigenfunctions[i].linfty_norm ();


    return solver_control.last_step ();
  }
@endcode

请注意我们是如何使用精确分解（使用SparseDirectUMFPACK）作为ARPACK的预处理程序的。   </ul> 


examples/step-37/doc/intro.dox

 <br> 

<i>
This program was contributed by Katharina Kormann and Martin
Kronbichler.


The algorithm for the matrix-vector product is based on the article <a
href="http://dx.doi.org/10.1016/j.compfluid.2012.04.012">A generic interface
for parallel cell-based finite element operator application</a><a
href="http://dx.doi.org/10.1016/j.compfluid.2012.04.012">A generic interface
for parallel cell-based finite element operator application</a> by Martin
Kronbichler and Katharina Kormann, Computers and Fluids 63:135&ndash;147,
2012, and the paper &quot;Parallel finite element operator application: Graph
partitioning and coloring&quot; by Katharina Kormann and Martin Kronbichler
in: Proceedings of the 7th IEEE International Conference on e-Science, 2011.


This work was partly supported by the German Research Foundation (DFG) through
the project "High-order discontinuous Galerkin for the exa-scale" (ExaDG)
within the priority program "Software for Exascale Computing" (SPPEXA). The
large-scale computations shown in the results section of this tutorial program
were supported by Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu)
by providing computing time on the GCS Supercomputer SuperMUC at Leibniz
Supercomputing Centre (LRZ, www.lrz.de) through project id pr83te. </i> 。

<a name="Intro"></a>

<h1>Introduction</h1>

这个例子展示了如何在超立方体上实现一个无矩阵的方法，即不明确存储矩阵元素的方法，用于具有可变系数的二阶泊松方程。该线性系统将用多网格方法求解，并使用MPI的大规模并行性。

无矩阵方法的主要动机是，在今天的处理器上，对主内存的访问（即对不适合缓存的对象）已经成为许多偏微分方程求解器的瓶颈。为了执行基于矩阵的矩阵-向量乘积，现代CPU花在等待数据从内存到达的时间远远多于实际进行浮点乘法和加法的时间。因此，如果我们可以通过重新计算矩阵元素来代替在内存中查找矩阵元素，或者更确切地说，这些条目所代表的运算符&mdash;，我们可能会在整体运行时间方面获胜，即使这需要大量的额外浮点运算。也就是说，用一个微不足道的实现来实现这一点是不够的，我们需要真正关注细节来获得性能。这个教程程序和上面提到的论文展示了如何实现这样一个方案，并演示了可以获得的速度提升。




<h3>The test case</h3>

在这个例子中，我们考虑泊松问题@f{eqnarray*} -
\nabla \cdot a(\mathbf x) \nabla u &=& 1, \\ u &=& 0 \quad \text{on}\
\partial \Omega @f}，其中 $a(\mathbf x)$ 是一个可变系数。下面，我们将解释如何在不明确形成矩阵的情况下实现这个问题的矩阵-向量乘积。当然，对于其他方程也可以用类似的方法进行构造。

我们选择 $\Omega=[0,1]^3$ 和 $a(\mathbf x)=\frac{1}{0.05 +
2\|\mathbf x\|^2}$ 作为域。由于系数是围绕原点对称的，但域却不是，我们最终会得到一个非对称的解决方案。




<h3>Matrix-vector product implementation</h3>

为了找出我们如何编写一个执行矩阵-向量乘积的代码，但不需要存储矩阵元素，让我们先看看一个有限元矩阵<i>A</i>是如何组装起来的。

@f{eqnarray*}
A = \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}}
P_{\mathrm{cell,{loc-glob}}}^T A_{\mathrm{cell}} P_{\mathrm{cell,{loc-glob}}}.


@f}

在这个公式中，矩阵<i>P</i><sub>cell,loc-glob</sub>是一个矩形矩阵，定义了从当前单元的局部自由度到全局自由度的索引映射。可以建立这个算子的信息通常被编码在 <code>local_dof_indices</code> 变量中，并在deal.II中用于汇编调用填充矩阵。这里，<i>A</i><sub>cell</sub>表示与<i>A</i>相关的单元矩阵。

如果我们要进行矩阵-向量乘积，因此我们可以使用

@f{eqnarray*}
y &=& A\cdot u = \left(\sum_{\text{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
A_\mathrm{cell} P_\mathrm{cell,{loc-glob}}\right) \cdot u
\\
&=& \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
A_\mathrm{cell} u_\mathrm{cell}
\\
&=& \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
v_\mathrm{cell},


@f}

其中<i>u</i><sub>cell</sub>是<i>u</i>在各单元自由度处的值，而<i>v</i><sub>cell</sub>=<i>A</i><sub>cell</sub><i>u</i><sub>cell</sub>相应为结果。因此，实现拉普拉斯的局部作用的一个天真尝试是使用以下代码。

@code
Matrixfree<dim>::vmult (Vector<double>       &dst,
                        const Vector<double> &src) const
{
  dst = 0;


  QGauss<dim>  quadrature_formula(fe.degree+1);
  FEValues<dim> fe_values (fe, quadrature_formula,
                           update_gradients | update_JxW_values|
                           update_quadrature_points);


  const unsigned int   dofs_per_cell = fe.n_dofs_per_cell();
  const unsigned int   n_q_points    = quadrature_formula.size();


  FullMatrix<double>   cell_matrix (dofs_per_cell, dofs_per_cell);
  Vector<double>       cell_src (dofs_per_cell),
                       cell_dst (dofs_per_cell);
  const Coefficient<dim> coefficient;
  std::vector<double> coefficient_values(n_q_points);


  std::vector<unsigned int> local_dof_indices (dofs_per_cell);


  for (const auto & cell : dof_handler.active_cell_iterators())
    {
      cell_matrix = 0;
      fe_values.reinit (cell);
      coefficient.value_list(fe_values.get_quadrature_points(),
                             coefficient_values);


      for (unsigned int q=0; q<n_q_points; ++q)
        for (unsigned int i=0; i<dofs_per_cell; ++i)
          for (unsigned int j=0; j<dofs_per_cell; ++j)
            cell_matrix(i,j) += (fe_values.shape_grad(i,q) *
                                 fe_values.shape_grad(j,q) *
                                 fe_values.JxW(q)*
                                 coefficient_values[q]);


      cell->get_dof_indices (local_dof_indices);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        cell_src(i) = src(local_dof_indices(i));


      cell_matrix.vmult (cell_dst, cell_src);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        dst(local_dof_indices(i)) += cell_dst;
    }
}
@endcode



在这里，我们忽略了边界条件以及我们可能有的任何悬空节点，尽管使用AffineConstraints类来包括这两者都不是很困难。请注意，我们首先以通常的方式生成局部矩阵，作为每个局部矩阵项的所有正交点的总和。为了形成上述公式中表达的实际乘积，我们提取细胞相关自由度的 <code>src</code> 的值（<i>P</i><sub>cell,loc-glob</sub>的作用），乘以局部矩阵（<i>A</i><sub>cell</sub>），最后把结果加到目标向量 <code>dst</code> （<i>P</i><sub>cell,loc-glob</sub><sup>T</sup>的动作，加在所有元素上）。原则上不会比这更难。

虽然这段代码是完全正确的，但它非常慢。对于每个单元，我们生成一个局部矩阵，这需要三个嵌套循环，循环长度等于局部自由度的数量来计算。然后，乘法本身是由两个嵌套循环完成的，这意味着它要便宜得多。

改善这一点的一个方法是认识到，从概念上讲，局部矩阵可以被认为是三个矩阵的乘积。

@f{eqnarray*}
A_\mathrm{cell} = B_\mathrm{cell}^T D_\mathrm{cell} B_\mathrm{cell},


@f}

对于拉普拉斯算子的例子，<i>q</i>*dim+<i>d,i</i>的第1个元素<sub>cell</sub>是由 <code>fe_values.shape_grad(i,q)[d]</code> 给出。这个矩阵由 <code>dim*n_q_points</code> 行和 @p dofs_per_cell 列组成。矩阵<i>D</i><sub>cell</sub>是对角线，包含了 <code>fe_values.JxW(q) * coefficient_values[q]</code> 的值（或者说， @p 这些值中每一个的dim副本）。这种有限元矩阵的表示方法经常可以在工程文献中找到。

当单元格矩阵被应用于一个矢量时。

@f{eqnarray*}
A_\mathrm{cell}\cdot u_\mathrm{cell} = B_\mathrm{cell}^T
D_\mathrm{cell} B_\mathrm{cell} \cdot u_\mathrm{cell},


@f}

这样就不会形成矩阵-矩阵乘积，而是每次用一个矩阵与一个矢量从右到左相乘，这样就只形成三个连续的矩阵-矢量乘积。这种方法去掉了局部矩阵计算中的三个嵌套循环，从而将一个单元格的工作复杂度从类似 $\mathcal
{O}(\mathrm{dofs\_per\_cell}^3)$ 降低到 $\mathcal
{O}(\mathrm{dofs\_per\_cell}^2)$  。对这种算法的解释是，我们首先将本地DoF上的值向量转换为正交点上的梯度向量。在第二个循环中，我们把这些梯度乘以积分权重和系数。第三次循环应用第二个梯度（转置形式），这样我们就得到了单元斗室上的（拉普拉斯）值矢量。

上述代码的瓶颈是对每一个 FEValues::reinit 的调用所做的操作，其花费的时间和其他步骤加起来差不多（至少如果网格是非结构化的；deal.II可以识别结构化网格上的梯度往往是不变的）。这当然不理想，我们希望能做得更好。reinit函数所做的是计算实空间的梯度，使用从实空间到参考单元的转换的Jacobian来转换参考单元上的梯度。这是为单元格上的每个基函数和每个正交点进行的。雅各布系数并不取决于基函数，但它在不同的正交点上通常是不同的。如果你只建立一次矩阵，就像我们在以前所有的教程程序中所做的那样，没有什么需要优化的，因为 FEValues::reinit 需要在每个单元上调用。在这个过程中，转换是在计算局部矩阵元素时应用的。

然而，在一个无矩阵的实现中，我们会经常计算这些积分，因为迭代求解器在求解过程中会多次应用矩阵。因此，我们需要考虑是否可以缓存一些在运算器应用中被重用的数据，也就是积分计算。另一方面，我们意识到我们不能缓存太多的数据，否则我们又回到了内存访问成为主导因素的情况。因此，我们不会在矩阵<i>B</i>中存储转换后的梯度，因为一般来说，对于曲线网格的每个基函数和每个元素上的正交点，它们都是不同的。

诀窍是去掉雅各布变换的因素，首先只在参考单元上应用梯度。这个操作将本地道夫上的值向量插值到正交点上的（单位坐标）梯度向量。在这里，我们首先应用我们从梯度中分解出来的雅各布，然后应用正交点的权重，最后应用转置的雅各布来准备第三个循环，通过单元格上的梯度测试并对正交点求和。

让我们再次用矩阵的方式来写。让矩阵<i>B</i><sub>cell</sub>表示与单元有关的梯度矩阵，每一行包含正交点上的值。它由矩阵与矩阵的乘积构成@f{eqnarray*} B_\mathrm{cell} =
J_\mathrm{cell}^{-\mathrm T} B_\mathrm{ref\_cell}, @f}，其中<i>B</i><sub>ref_cell</sub>表示参考单元的梯度，<i>J</i><sup>-T</sup><sub>cell</sub>表示从单位到实数单元的变换的反转置Jacobian（在变换的语言中，由<i>J</i><sup>-T</sup><sub>cell</sub>表示协变变换的操作）。<i>J</i><sup>-T</sup><sub>cell</sub>是块对角线的，块的大小等于问题的维度。每个对角线块都是雅各布变换，从参考单元到实际单元。

把事情放在一起，我们发现

@f{eqnarray*}
A_\mathrm{cell} = B_\mathrm{cell}^T D B_\mathrm{cell}
                = B_\mathrm{ref\_cell}^T J_\mathrm{cell}^{-1}
                  D_\mathrm{cell}
                  J_\mathrm{cell}^{-\mathrm T} B_\mathrm{ref\_cell},


@f}

所以我们要计算积（从右边开始计算局部积）。

@f{eqnarray*}
v_\mathrm{cell} = B_\mathrm{ref\_cell}^T J_\mathrm{cell}^{-1} D J_\mathrm{cell}^{-\mathrm T}
B_\mathrm{ref\_cell} u_\mathrm{cell}, \quad
v = \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
v_\mathrm{cell}.


@f}



@code
  FEValues<dim> fe_values_reference (fe, quadrature_formula,
                                     update_gradients);
  Triangulation<dim> reference_cell;
  GridGenerator::hyper_cube(reference_cell, 0., 1.);
  fe_values_reference.reinit (reference_cell.begin());


  FEValues<dim> fe_values (fe, quadrature_formula,
                           update_inverse_jacobians | update_JxW_values |
                           update_quadrature_points);


  for (const auto & cell : dof_handler.active_cell_iterators())
    {
      fe_values.reinit (cell);
      coefficient.value_list(fe_values.get_quadrature_points(),
                             coefficient_values);


      cell->get_dof_indices (local_dof_indices);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        cell_src(i) = src(local_dof_indices(i));


      temp_vector = 0;
      for (unsigned int q=0; q<n_q_points; ++q)
        for (unsigned int d=0; d<dim; ++d)
          for (unsigned int i=0; i<dofs_per_cell; ++i)
            temp_vector(q*dim+d) +=
              fe_values_reference.shape_grad(i,q)[d] * cell_src(i);


      for (unsigned int q=0; q<n_q_points; ++q)
        {
          // apply the transposed inverse Jacobian of the mapping
          Tensor<1,dim> temp;
          for (unsigned int d=0; d<dim; ++d)
            temp[d] = temp_vector(q*dim+d);
          for (unsigned int d=0; d<dim; ++d)
            {
              double sum = 0;
              for (unsigned int e=0; e<dim; ++e)
                sum += fe_values.inverse_jacobian(q)[e][d] *
                               temp[e];
              temp_vector(q*dim+d) = sum;
            }


          // multiply by coefficient and integration weight
          for (unsigned int d=0; d<dim; ++d)
            temp_vector(q*dim+d) *= fe_values.JxW(q) * coefficient_values[q];


          // apply the inverse Jacobian of the mapping
          for (unsigned int d=0; d<dim; ++d)
            temp[d] = temp_vector(q*dim+d);
          for (unsigned int d=0; d<dim; ++d)
            {
              double sum = 0;
              for (unsigned int e=0; e<dim; ++e)
                sum += fe_values.inverse_jacobian(q)[d][e] *
                       temp[e];
              temp_vector(q*dim+d) = sum;
            }
        }


      cell_dst = 0;
      for (unsigned int i=0; i<dofs_per_cell; ++i)
        for (unsigned int q=0; q<n_q_points; ++q)
          for (unsigned int d=0; d<dim; ++d)
            cell_dst(i) += fe_values_reference.shape_grad(i,q)[d] *
                                   temp_vector(q*dim+d);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        dst(local_dof_indices(i)) += cell_dst(i);
    }
}
@endcode



注意我们如何为参考单元梯度创建一个额外的FEValues对象，以及如何将其初始化为参考单元。然后，实际的导数数据是由反的、转置的Jacobian（deal.II将Jacobian矩阵从实单元到单位单元称为inverse_jacobian，因为正向转换是从单位单元到实单元）应用的。因子 $J_\mathrm{cell}^{-1} D_\mathrm{cell} J_\mathrm{cell}^{-\mathrm T}$ 是块对角线超过正交的。在这种形式下，人们意识到可变系数（可能通过张量表示）和一般网格拓扑结构的雅各布变换对变换单元格导数的系数有类似的影响。

在这一点上，人们可能会想，为什么我们要分别存储矩阵 $J_\mathrm{cell}^{-\mathrm T}$ 和系数，而不是只存储完整的因子 $J_\mathrm{cell}^{-1} D_\mathrm{cell}
J_\mathrm{cell}^{-\mathrm T}$  。后者会使用更少的内存，因为张量是对称的，在三维中具有六个独立的值，而对于前者，我们需要九个条目用于反转雅各布系数，一个用于正交权重和雅各布行列式，一个用于系数，总共是11个双数。原因是前者允许通过一个共同的缓存数据框架来实现通用的微分算子，而后者则专门存储拉普拉斯的系数。如果应用需要，这种专门化可能会得到回报，值得考虑。请注意，deal.II中的实现足够聪明，可以检测笛卡尔或仿生几何，其中雅各布系数在整个单元中是恒定的，不需要为每个单元存储（实际上在不同的单元中也常常是相同的）。

从操作数的角度来看，最后的优化是利用基函数中的张量积结构，这是最为关键的。这是可能的，因为我们已经从<i>B</i><sub>ref_cell</sub>描述的参考单元操作中剔除了梯度，即对参考单元的完全规则的数据域进行插值操作。我们举例说明在两个空间维度上降低复杂度的过程，但是同样的技术也可以用在更高的维度上。在参考单元上，基函数是张量积形式的  $\phi(x,y,z) = \varphi_i(x) \varphi_j(y)$  。矩阵<i>B</i><sub>ref_cell</sub>计算第一分量的部分具有 $B_\mathrm{sub\_cell}^x = B_\mathrm{grad,x} \otimes B_\mathrm{val,y}$ 的形式，其中<i>B</i><sub>grad,x</sub>和<i>B</i><sub>val,y</sub>包含所有一维正交点上所有一维基函数的评价。用含有属于基函数 $\varphi_i(x) \varphi_j(y)$ 的系数的<i>U</i>组成矩阵<i>U(j,i)</i>，我们得到 $(B_\mathrm{grad,x} \otimes
B_\mathrm{val,y})u_\mathrm{cell} = B_\mathrm{val,y} U B_\mathrm{grad,x}$ 。这就把计算这个乘积的复杂度从 $p^4$ 降低到 $2 p^3$ ，其中<i>p</i>-1是有限元的度数（即，等价地，<i>p</i>是每个坐标方向上的形状函数的数量），或者一般来说 $p^{2d}$ 到 $d p^{d+1}$ 。我们之所以用多项式度数来看复杂度，是因为我们希望能够到高度数，可能会增加多项式度数<i>p</i>而不是网格分辨率。像这里使用的中等度数的好算法是独立于维度的多项式度数的线性算法，而不是基于矩阵的方案或通过FEValues的天真评价。在deal.II的实现中所使用的技术自20世纪80年代以来就已经在谱元界建立起来。

实现一个无矩阵和基于单元的有限元算子，与以前的教程程序中显示的通常的矩阵装配代码相比，需要一个有点不同的程序设计。做到这一点的数据结构是MatrixFree类和FEEvaluation类，前者收集所有数据并在所有单元上发出一个（并行）循环，后者利用张量积结构评估有限元基函数。

本教程中展示的无矩阵的矩阵-向量乘积的实现比使用稀疏矩阵的线性元素的矩阵-向量乘积要慢，但由于张量乘积结构降低了复杂度，并且在计算过程中减少了内存传输，所以对所有高阶元素来说速度更快。当在一个多核处理器上工作时，减少内存传输的影响特别有利，因为在这个处理器上有几个处理单元共享内存的访问。在这种情况下，一个受计算约束的算法将显示出几乎完美的并行加速（除了可能通过涡轮模式改变处理器的时钟频率，这取决于有多少个核心在工作），而一个受内存传输约束的算法可能无法实现类似的加速（即使工作是完全并行的，我们可以期待像稀疏矩阵-向量产品那样的完美缩放）。这种实现方式的另一个好处是，我们不必建立稀疏矩阵本身，这也可能是相当昂贵的，这取决于基础微分方程。此外，上述框架可以简单地推广到非线性运算，正如我们在步骤48中所展示的那样。




<h3>Combination with multigrid</h3>

上面，我们花了很大的力气来实现一个不实际存储矩阵元素的矩阵-向量积。然而，在许多用户代码中，人们想要的不仅仅是做一些矩阵-向量乘积&mdash；在求解线性系统时，人们希望尽可能少做这些操作。理论上，我们可以使用CG方法，而不需要预处理；然而，这对拉普拉斯的效率并不高。相反，预调节器是用来提高收敛速度的。不幸的是，大多数比较常用的预处理方法，如SSOR、ILU或代数多网格（AMG）不能在这里使用，因为它们的实现需要了解系统矩阵的元素。

一个解决方案是使用几何多网格方法，如步骤16所示。众所周知，它们的速度非常快，而且适合我们的目的，因为所有的成分，包括不同网格层之间的转移，都可以用与单元格集合相关的矩阵-向量产品来表示。我们需要做的就是找到一个基于矩阵-向量乘积而不是所有矩阵条目的平滑器。一个这样的候选方法是阻尼雅可比迭代，它需要访问矩阵对角线，但它在阻尼所有高频误差方面往往不够好。雅可比方法的特性可以通过所谓的切比雪夫迭代进行几次改进。切比雪夫迭代由矩阵-向量乘积的多项式表达式描述，其中的系数可以被选择来实现某些特性，在这种情况下，可以平滑误差的高频成分，这些误差与雅可比预处理矩阵的特征值相关。在零度时，具有最佳阻尼参数的雅可比方法被检索出来，而高阶修正被用来改善平滑特性。切比雪夫平滑法在多网格中的有效性已经被证明，例如在文章<a href="http://www.sciencedirect.com/science/article/pii/S0021999103001943">
<i>M. Adams, M. Brezina, J. Hu, R. Tuminaro. Parallel multigrid smoothers:
polynomial versus Gauss&ndash;Seidel, J. Comput. Phys. 188:593&ndash;610,
2003</i><i>M. Adams, M. Brezina, J. Hu, R. Tuminaro. Parallel multigrid smoothers:
polynomial versus Gauss&ndash;Seidel, J. Comput. Phys. 188:593&ndash;610,
2003</i></a>中。这篇文章还指出了我们在这里利用的切比雪夫平滑器的另一个优势，即它们很容易并行化，而SOR/Gauss&ndash;Seidel平滑依赖于替换，对于这种替换，天真的并行化在矩阵的对角线子块上工作，从而降低了效率（更多细节见例如Y. Saad, Iterative Methods for Sparse Linear Systems, SIAM, 2nd edition, 2003, chapters 11 & 12）。

然后，在多网格框架中的实现就很简单了。本程序中的多网格实现与step-16类似，包括自适应性。




<h3>Using CPU-dependent instructions (vectorization)</h3>

FEEvaluation中的计算内核是以优化使用计算资源的方式来编写的。为了达到这个目的，他们不对双倍数据类型进行操作，而是对我们称之为VectorizedArray的东西进行操作（例如，查看 FEEvaluationBase::get_value, 的返回类型，对于标量元素是VectorizedArray，对于矢量有限元素是Tensor of VectorizedArray）。VectorizedArray是一个双数或浮点数的短阵列，其长度取决于使用的特定计算机系统。例如，基于x86-64的系统支持流式SIMD扩展（SSE），处理器的矢量单元可以通过一条CPU指令处理两个双数（或四个单精度浮点数）。较新的处理器（大约从2012年起）支持所谓的高级向量扩展（AVX），有256位操作数，可以分别使用四个双数和八个浮点数。矢量化是一个单指令/多数据（SIMD）的概念，也就是说，一条CPU指令被用来同时处理多个数据值。通常情况下，有限元程序不会明确使用矢量化，因为这个概念的好处只体现在算术密集型操作中。大部分典型的有限元工作负载都受到内存带宽的限制（对稀疏矩阵和向量的操作），在这种情况下，额外的计算能力是无用的。

不过，在幕后，优化的BLAS包可能严重依赖矢量化。另外，优化的编译器可能会自动将涉及标准代码的循环转化为更有效的矢量化形式（deal.II在矢量更新的常规循环中使用OpenMP SIMD pragmas）。然而，数据流必须非常有规律，才能让编译器产生高效的代码。例如，受益于矢量化的原型操作（矩阵-矩阵乘积）的自动矢量化在大多数编译器上都失败了（截至2012年初编写本教程并在2016年底更新时，gcc和英特尔编译器都无法为 FullMatrix::mmult 函数，甚至在更简单的情况下也不行，即矩阵边界是编译时常量而不是 FullMatrix::mmult). 中的运行时常量。此外，有可能被一起处理的数据可能没有以连续的方式布置在内存中，或者没有对处理器需要的地址边界进行必要的对齐。或者编译器可能无法证明数据阵列在一次加载几个元素时不会重叠。

因此，在deal.II的无矩阵实现中，我们选择在最适合于有限元计算的层次上应用矢量化。所有单元的计算通常是完全相同的（除了从向量读写时使用的间接寻址中的索引），因此SIMD可以用来一次处理几个单元。在下面的所有内容中，你可以考虑用一个向量数组来保存几个单元的数据。记住，它与空间维度和元素数量无关，例如在Tensor或Point中。

请注意，矢量化取决于代码运行的CPU，以及代码的编译对象。为了给你的计算机生成最快的FEEvaluation内核，你应该用所谓的<i>native</i>处理器变体编译deal.II。当使用gcc编译器时，可以通过在cmake构建设置中设置变量<tt>CMAKE_CXX_FLAGS</tt>为<tt>"-march=native"</tt>来启用它（在命令行中，指定<tt>-DCMAKE_CXX_FLAGS="-march=native"</tt>，更多信息见deal.II阅读手册）。其他编译器也有类似的选项。我们在本例的run()函数中输出当前的矢量化长度。




<h3>Running multigrid on large-scale parallel computers</h3>

如上所述，无矩阵框架中的所有组件都可以通过MPI使用领域分解轻松实现并行化。由于在deal.II中通过p4est（详见step-40）可以很容易地访问大规模的并行网格，而且基于单元格的循环与无矩阵评估<i>only</i>需要在每个处理器上将网格分解成大小基本相同的块，因此编写一个使用分布式内存工作的并行程序所需的工作相对较少。虽然其他使用MPI的教程程序依赖于PETSc或Trilinos，但这个程序使用deal.II自己的并行向量设施。

deal.II并行向量类， LinearAlgebra::distributed::Vector, 持有解决方案的处理器本地部分以及重影自由度的数据字段，即由远程处理器拥有的自由度，但由当前处理器拥有的单元访问。在 @ref GlossLocallyActiveDof "术语表 "中，这些自由度被称为本地活动自由度。函数 MatrixFree::initialize_dof_vector() 提供了一个设置这种设计的方法。请注意，悬挂节点可以与额外的重影自由度有关，这些自由度必须包括在分布式矢量中，但不属于 @ref
GlossLocallyActiveDof "词汇表 "意义上的本地活动自由度。此外，分布式向量持有本地拥有但其他处理器需要的DoF的MPI元数据。这个向量类设计的一个好处是对重影项的访问方式。在向量的存储方案中，数据阵列延伸到解决方案的处理器本地部分之外，有更多的向量条目可用于重影自由度。这为所有本地活动自由度提供了一个连续的索引范围。(注意，索引范围取决于网格的具体配置。)由于无矩阵操作可以被认为是在做性能关键的线性代数，而性能关键的代码不能把时间浪费在做MPI全局到MPI局部的索引转换上，一个MPI等级的局部索引空间的可用性是很重要的。这里访问事物的方式是直接数组访问。这是通过 LinearAlgebra::distributed::Vector::local_element(), 提供的，但实际上很少需要，因为所有这些都发生在FEEvaluation的内部。

 LinearAlgebra::distributed::Vector 的设计与我们之前在step-40和step-32中使用的 PETScWrappers::MPI::Vector 和 TrilinosWrappers::MPI::Vector 数据类型类似，但由于我们不需要这些库的其他并行功能，所以我们使用deal.II的 LinearAlgebra::distributed::Vector 类来代替在本教程程序中链接另一个大型库。还要注意的是，PETSc和Trilinos向量不提供对直接数组访问的幽灵条目的细粒度控制，因为它们抽象出了必要的实现细节。


examples/step-37/doc/results.dox



<h1>Results</h1>

<h3>Program output</h3>

由于这个例子解决的是与步骤5相同的问题（除了不同的系数），所以对解决方案没有什么可说的。我们还是展示了一张图片，通过等高线和体积渲染来说明解决方案的大小。

 <img src="https://www.dealii.org/images/steps/developer/step-37.solution.png" alt=""> 

更有趣的是评估多网格求解器的某些方面。当我们在二维运行这个程序时，对于二次（ $Q_2$ ）元素，我们得到以下输出（当在一个核心上以释放模式运行时）。

@code
Vectorization over 2 doubles = 128 bits (SSE2)
Cycle 0
Number of degrees of freedom: 81
Total setup time               (wall) 0.00159788s
Time solve (6 iterations)  (CPU/wall) 0.000951s/0.000951052s


Cycle 1
Number of degrees of freedom: 289
Total setup time               (wall) 0.00114608s
Time solve (6 iterations)  (CPU/wall) 0.000935s/0.000934839s


Cycle 2
Number of degrees of freedom: 1089
Total setup time               (wall) 0.00244665s
Time solve (6 iterations)  (CPU/wall) 0.00207s/0.002069s


Cycle 3
Number of degrees of freedom: 4225
Total setup time               (wall) 0.00678205s
Time solve (6 iterations)  (CPU/wall) 0.005616s/0.00561595s


Cycle 4
Number of degrees of freedom: 16641
Total setup time               (wall) 0.0241671s
Time solve (6 iterations)  (CPU/wall) 0.019543s/0.0195441s


Cycle 5
Number of degrees of freedom: 66049
Total setup time               (wall) 0.0967851s
Time solve (6 iterations)  (CPU/wall) 0.07457s/0.0745709s


Cycle 6
Number of degrees of freedom: 263169
Total setup time               (wall) 0.346374s
Time solve (6 iterations)  (CPU/wall) 0.260042s/0.265033s
@endcode



如同步骤16，我们看到随着自由度的增加，CG的迭代次数保持不变。恒定的迭代次数（加上最佳的计算特性）意味着当问题大小在一个周期内翻两番时，计算时间大约翻了四倍。该代码在存储方面也非常有效。大约200-400万个自由度适合于1GB的内存，也见下面的MPI结果。一个有趣的事实是，尽管没有建立矩阵，但解决一个线性系统比设置要便宜（大约一半的时间花在 DoFHandler::distribute_dofs() 和 DoFHandler::distribute_mg_dofs() 的调用上）。这表明这种方法的效率很高，但也表明deal.II数据结构的设置相当昂贵，设置成本必须在几个系统求解中摊销。

如果我们在三个空间维度上运行程序，就不会有太大变化。由于我们使用了均匀的网格细化，我们得到的元素数量是八倍，每个周期的自由度大约是八倍。

@code
Vectorization over 2 doubles = 128 bits (SSE2)
Cycle 0
Number of degrees of freedom: 125
Total setup time               (wall) 0.00231099s
Time solve (6 iterations)  (CPU/wall) 0.000692s/0.000922918s


Cycle 1
Number of degrees of freedom: 729
Total setup time               (wall) 0.00289083s
Time solve (6 iterations)  (CPU/wall) 0.001534s/0.0024128s


Cycle 2
Number of degrees of freedom: 4913
Total setup time               (wall) 0.0143182s
Time solve (6 iterations)  (CPU/wall) 0.010785s/0.0107841s


Cycle 3
Number of degrees of freedom: 35937
Total setup time               (wall) 0.087064s
Time solve (6 iterations)  (CPU/wall) 0.063522s/0.06545s


Cycle 4
Number of degrees of freedom: 274625
Total setup time               (wall) 0.596306s
Time solve (6 iterations)  (CPU/wall) 0.427757s/0.431765s


Cycle 5
Number of degrees of freedom: 2146689
Total setup time               (wall) 4.96491s
Time solve (6 iterations)  (CPU/wall) 3.53126s/3.56142s
@endcode



既然如此简单，我们看看如果我们增加多项式的度数会发生什么。当在三维中选择度数为4，即在 $\mathcal Q_4$ 元素上，通过改变程序顶部的一行<code>const unsigned int degree_finite_element=4;</code>，我们得到以下程序输出。

@code
Vectorization over 2 doubles = 128 bits (SSE2)
Cycle 0
Number of degrees of freedom: 729
Total setup time               (wall) 0.00633097s
Time solve (6 iterations)  (CPU/wall) 0.002829s/0.00379395s


Cycle 1
Number of degrees of freedom: 4913
Total setup time               (wall) 0.0174279s
Time solve (6 iterations)  (CPU/wall) 0.012255s/0.012254s


Cycle 2
Number of degrees of freedom: 35937
Total setup time               (wall) 0.082655s
Time solve (6 iterations)  (CPU/wall) 0.052362s/0.0523629s


Cycle 3
Number of degrees of freedom: 274625
Total setup time               (wall) 0.507943s
Time solve (6 iterations)  (CPU/wall) 0.341811s/0.345788s


Cycle 4
Number of degrees of freedom: 2146689
Total setup time               (wall) 3.46251s
Time solve (7 iterations)  (CPU/wall) 3.29638s/3.3265s


Cycle 5
Number of degrees of freedom: 16974593
Total setup time               (wall) 27.8989s
Time solve (7 iterations)  (CPU/wall) 26.3705s/27.1077s
@endcode



由于一定网格上的 $\mathcal Q_4$ 元素对应于一半网格大小的 $\mathcal Q_2$ 元素，我们可以比较第四周期使用四度多项式和第五周期使用二次多项式的运行时间，两者都是210万自由度。令人惊讶的效果是，尽管多用了一次线性迭代， $\mathcal Q_4$ 元素的求解器实际上比四次方的情况略快。高阶多项式的速度与低阶多项式类似，甚至比低阶多项式更快，这是通过和分解进行无矩阵算子评估的主要优势之一，见<a
href="http://dx.doi.org/10.1016/j.compfluid.2012.04.012">matrix-free
paper</a>。这与基于矩阵的方法有根本的不同，后者随着多项式度数的增加和耦合的密集，每个未知数的成本会越来越高。

此外，对于更高的订单，设置也变得更便宜，这是因为需要设置的元素更少。

最后，让我们看一下度数为8的时间，这相当于低阶方法的另一轮网格细化。

@code
Vectorization over 2 doubles = 128 bits (SSE2)
Cycle 0
Number of degrees of freedom: 4913
Total setup time               (wall) 0.0842004s
Time solve (8 iterations)  (CPU/wall) 0.019296s/0.0192959s


Cycle 1
Number of degrees of freedom: 35937
Total setup time               (wall) 0.327048s
Time solve (8 iterations)  (CPU/wall) 0.07517s/0.075999s


Cycle 2
Number of degrees of freedom: 274625
Total setup time               (wall) 2.12335s
Time solve (8 iterations)  (CPU/wall) 0.448739s/0.453698s


Cycle 3
Number of degrees of freedom: 2146689
Total setup time               (wall) 16.1743s
Time solve (8 iterations)  (CPU/wall) 3.95003s/3.97717s


Cycle 4
Number of degrees of freedom: 16974593
Total setup time               (wall) 130.8s
Time solve (8 iterations)  (CPU/wall) 31.0316s/31.767s
@endcode



在这里，初始化似乎比以前慢得多，这主要是由于矩阵对角线的计算，它实际上是在每个单元格上计算一个729 x 729的矩阵，扔掉除对角线以外的所有东西。然而，解算时间再次非常接近四次方的情况，这表明理论上预期的随着多项式程度的增加而出现的线性增长几乎完全被更好的计算特性和高阶方法在几个单元上的自由度份额较小而增加了评估的复杂性所抵消。

<h3>Comparison with a sparse matrix</h3>

为了了解无矩阵实现的能力，我们通过测量问题初始化的计算时间（分配DoF、设置和装配矩阵、设置多网格结构）以及无矩阵变体和基于稀疏矩阵的变体的实际求解时间，将上面的3D例子与基于稀疏矩阵的变体的性能进行比较。如上图所示，我们将预处理程序建立在浮点数上，将实际的矩阵和向量建立在双数上。测试在英特尔酷睿i7-5500U笔记本处理器（两个核心，支持<a
href="http://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a>，即用一条CPU指令就可以完成对双数的四次操作，这在FEEvaluation中被大量使用）、优化模式和两个MPI行列上运行。

 <table align="center" class="doxtable">
  <tr>
    <th>&nbsp;</th>
    <th colspan="2">Sparse matrix</th>
    <th colspan="2">Matrix-free implementation</th>
  </tr>
  <tr>
    <th>n_dofs</th>
    <th>Setup + assemble</th>
    <th>&nbsp;Solve&nbsp;</th>
    <th>Setup + assemble</th>
    <th>&nbsp;Solve&nbsp;</th>
  </tr>
  <tr>
    <td align="right">125</td>
    <td align="center">0.0042s</td>
    <td align="center">0.0012s</td>
    <td align="center">0.0022s</td>
    <td align="center">0.00095s</td>
  </tr>
  <tr>
    <td align="right">729</td>
    <td align="center">0.012s</td>
    <td align="center">0.0040s</td>
    <td align="center">0.0027s</td>
    <td align="center">0.0021s</td>
  </tr>
  <tr>
    <td align="right">4,913</td>
    <td align="center">0.082s</td>
    <td align="center">0.012s</td>
    <td align="center">0.011s</td>
    <td align="center">0.0057s</td>
  </tr>
  <tr>
    <td align="right">35,937</td>
    <td align="center">0.73s</td>
    <td align="center">0.13s</td>
    <td align="center">0.048s</td>
    <td align="center">0.040s</td>
  </tr>
  <tr>
    <td align="right">274,625</td>
    <td align="center">5.43s</td>
    <td align="center">1.01s</td>
    <td align="center">0.33s</td>
    <td align="center">0.25s</td>
  </tr>
  <tr>
    <td align="right">2,146,689</td>
    <td align="center">43.8s</td>
    <td align="center">8.24s</td>
    <td align="center">2.42s</td>
    <td align="center">2.06s</td>
  </tr>
</table> 

该表清楚地显示，无矩阵实现的求解速度是两倍以上，而在初始化成本方面，则是六倍以上。随着问题大小被放大8倍，我们注意到，时间通常也会上升8倍（因为求解器的迭代次数恒定为6次）。主要的偏差是在5k到36k自由度的稀疏矩阵中，时间增加了12倍。这是处理器中的（L3）缓存不能再容纳矩阵-向量乘积所需的所有数据的阈值，所有的矩阵元素必须从主内存中获取。

当然，这种情况不一定适用于所有情况，因为在有些问题上，对矩阵项的了解可以使解算器的效果好得多（如当系数的变化比上面的例子更强烈时）。此外，这也取决于计算机系统。目前的系统具有良好的内存性能，因此稀疏矩阵的性能相当好。尽管如此，对于本例中使用的<i>Q</i><sub>2</sub>元素，无矩阵的实现已经给出了一个不错的速度。这一点对于时间依赖性或非线性问题尤其明显，在这些问题中，稀疏矩阵需要一次又一次地被重新组合，有了这个类，这就变得容易多了。当然，由于产品的复杂性更好，当元素的阶数增加时，该方法获得了越来越大的优势（无矩阵实现每个自由度的成本为4<i>d</i><sup>2</sup><i>p</i>，而稀疏矩阵为2<i>p<sup>d</sup></i>，所以无论如何它在4阶以上的3d中会获胜）。

<h3> Results for large-scale parallel computations on SuperMUC</h3>

正如介绍和代码中的注释所解释的，这个程序可以用MPI并行运行。事实证明，几何多栅方案工作得非常好，可以扩展到非常大的机器。据作者所知，这里显示的几何多网格结果是截至2016年底用deal.II完成的最大计算，在<a
href="https://www.lrz.de/services/compute/supermuc/systemdescription/">complete
SuperMUC Phase 1</a>的多达147456个核心上运行。超过1000个核心的可扩展性的要素是，没有任何依赖于全局问题大小的数据结构被完整地保存在一个处理器上，并且通信不是太频繁，以避免遇到网络的延迟问题。  对于用迭代求解器求解的PDEs，通信延迟往往是限制因素，而不是网络的吞吐量。以SuperMUC系统为例，两个处理器之间的点对点延迟在1e-6到1e-5秒之间，取决于MPI网络中的距离。这一类的矩阵-向量产品与 @p LaplaceOperator 涉及几个点对点通信步骤，与每个核心上的计算交错进行。由此产生的矩阵-向量乘积的延迟约为1e-4秒。全局通信，例如一个 @p MPI_Allreduce 操作，在MPI网络中的所有等级上累积每个等级的单一数字之和，其延迟为1e-4秒。这个程序中使用的多网格V型循环也是全局通信的一种形式。想一想发生在单个处理器上的粗略网格求解。在开始之前，它积累了来自所有处理器的贡献。当完成后，粗网格解决方案被转移到更细的层次，在那里越来越多的处理器帮助平滑，直到细网格。从本质上讲，这是在网络中的处理器上的一个树状模式，并由网格控制。相对于 @p MPI_Allreduce 的操作，在还原中的树被优化为MPI网络中的实际链接，多网格V-cycle是根据网格的划分来做的。因此，我们不能期望有同样的优化效果。此外，多网格循环并不是简单地在细化树上走来走去，而是在做平滑的时候在每一层上进行通信。换句话说，多网格中的全局通信更具挑战性，与提供较少优化机会的网格有关。测得的V型周期的延迟在6e-3和2e-2秒之间，即与60至200次MPI_Allreduce操作相同。

下图显示了在 $\mathcal Q_3$ 元素上进行的缩放实验。沿着这条线，问题的大小保持不变，因为核的数量在增加。当内核数量增加一倍时，人们期望计算时间减少一半，灰色虚线表示。结果显示，在达到0.1秒左右的绝对时间之前，该实现显示了几乎理想的行为。解算器的公差已经被设定为解算器执行五次迭代。这种绘制数据的方式是该算法的<b>strong scaling</b>。当我们走到非常大的核心数时，曲线会提前变平，这是因为SuperMUC中的通信网络，距离较远的处理器之间的通信会稍慢一些。

 <img src="https://www.dealii.org/images/steps/developer/step-37.scaling_strong.png" alt=""> 

此外，该图还包含了<b>weak scaling</b>的结果，列出了当处理器内核和元素的数量都以相同的速度增加时，算法的表现。在这种情况下，我们期望计算时间保持不变。在算法上，CG的迭代次数恒定在5次，所以我们从这一点来看是好的。图中的线条是这样排列的：每个数据系列中的左上角点代表每个处理器的相同大小，即131,072个元素（或每个核心大约350万个自由度）。表示理想的强缩放的灰色线条相隔8个相同的系数。结果再次表明，缩放比例几乎是理想的。当从288个核到147456个核时，并行效率在75%左右，每个核的局部问题大小为75万自由度，在288个核上需要1.0秒，在2304个核上需要1.03秒，在18000个核上需要1.19秒，在147000个核上需要1.35秒。这些算法对处理器的利用率也达到了很高。在147k核心上最大的计算在SuperMUC上达到约1.7 PFLOPs/s，其中算术峰值为3.2 PFLOPs/s。对于一个迭代式PDE求解器来说，这是一个非常高的数字，而且通常只有密集线性代数才会达到显著的数字。稀疏线性代数被限制在这个数值的十分之一。

正如介绍中提到的，无矩阵方法减少了数据结构的内存消耗。除了由于更少的内存传输而带来的更高的性能外，该算法还允许非常大的问题被装入内存。下图显示了随着我们增加问题的大小，直到计算耗尽内存的上限时的计算时间。我们对1k核、8k核和65k核进行了计算，发现问题的大小几乎可以在两个数量级上进行理想的扩展。这张图中显示的最大的计算涉及2920亿（ $2.92 \cdot 10^{11}$ ）个自由度。在147k核心的DG计算中，上述算法也被运行，涉及多达5490亿（2^39）个自由度。

 <img src="https://www.dealii.org/images/steps/developer/step-37.scaling_size.png" alt=""> 

最后，我们注意到，在对上述大规模系统进行测试的同时，deal.II中的多网格算法也得到了改进。原始版本包含了基于MGSmootherPrecondition的次优代码，其中一些MPI_Allreduce命令（检查所有向量条目是否为零）在每一级的平滑操作上都要进行，这在65k核以上的系统中才变得明显。然而，下面的图片显示，改进已经在较小的规模上得到了回报，这里显示的是对 $\mathcal Q_5$ 元素在多达14336个内核上的计算。

 <img src="https://www.dealii.org/images/steps/developer/step-37.scaling_oldnew.png" alt=""> 




<h3> Adaptivity</h3>

正如代码中所解释的，这里介绍的算法是为运行在自适应细化的网格上准备的。如果只有部分网格被细化，多网格循环将以局部平滑的方式运行，并通过 MatrixFreeOperators::Base 类对细化程度不同的界面施加迪里切条件进行平滑。由于自由度在层次上的分布方式，将层次单元的所有者与第一个下级活动单元的所有者联系起来，在MPI中不同的处理器之间可能存在不平衡，这限制了可扩展性，约为2到5倍。

<h3> Possibilities for extensions</h3>

<h4> Kelly error estimator </h4>

如上所述，代码已经准备好用于局部自适应h-精简。对于泊松方程，可以采用KellyErrorEstimator类中实现的Kelly误差指标。然而，我们需要小心处理平行向量的鬼魂指数。为了评估误差指标中的跳跃项，每个MPI进程需要知道本地相关的DoF。然而 MatrixFree::initialize_dof_vector() 函数只用一些本地相关的DoF来初始化向量。在向量中提供的鬼魂指数是一个严格的集合，只有那些在单元积分（包括约束解决）中被触及的指数。这种选择有性能上的原因，因为与矩阵-向量乘积相比，发送所有本地相关的自由度会过于昂贵。因此，原样的解决方案向量不适合KellyErrorEstimator类。诀窍是改变分区的幽灵部分，例如使用一个临时向量和 LinearAlgebra::distributed::Vector::copy_locally_owned_data_from() ，如下所示。

@code
IndexSet locally_relevant_dofs;
DoFTools::extract_locally_relevant_dofs(dof_handler, locally_relevant_dofs);
LinearAlgebra::distributed::Vector<double> copy_vec(solution);
solution.reinit(dof_handler.locally_owned_dofs(),
                locally_relevant_dofs,
                triangulation.get_communicator());
solution.copy_locally_owned_data_from(copy_vec);
constraints.distribute(solution);
solution.update_ghost_values();
@endcode



<h4> Shared-memory parallelization</h4>

这个程序只用MPI来并行化。作为一种选择，MatrixFree循环也可以在混合模式下发出，例如通过在集群的节点上使用MPI并行化，在一个节点的共享内存区域内通过Intel TBB使用线程。要使用这一点，就需要在主函数的MPI_InitFinalize数据结构中同时设置线程数，并将 MatrixFree::AdditionalData::tasks_parallel_scheme 设置为partition_color，以便真正并行地进行循环。这个用例将在步骤-48中讨论。

<h4> Inhomogeneous Dirichlet boundary conditions </h4>

所提出的程序假定了同质的Dirichlet边界条件。当进入非均质条件时，情况就有点复杂了。为了理解如何实现这样的设置，让我们首先回顾一下这些条件是如何在数学公式中出现的，以及它们是如何在基于矩阵的变体中实现的。从本质上讲，非均质Dirichlet条件将解决方案中的一些节点值设定为给定值，而不是通过变分原理来确定它们。

@f{eqnarray*}
u_h(\mathbf{x}) = \sum_{i\in \mathcal N} \varphi_i(\mathbf{x}) u_i =
\sum_{i\in \mathcal N \setminus \mathcal N_D} \varphi_i(\mathbf{x}) u_i +
\sum_{i\in \mathcal N_D} \varphi_i(\mathbf{x}) g_i,


@f}

其中 $u_i$ 表示解决方案的节点值， $\mathcal N$ 表示所有节点的集合。集合 $\mathcal N_D\subset \mathcal N$ 是受迪里希特边界条件约束的节点子集，其中解被强制等于 $u_i = g_i = g(\mathbf{x}_i)$ 作为迪里希特约束的节点点上的边界值插值 $i\in \mathcal
N_D$  。然后我们把这个解的表示插入到弱的形式中，例如上面所示的拉普拉斯，并把已知量移到右边。

@f{eqnarray*}
(\nabla \varphi_i, \nabla u_h)_\Omega &=& (\varphi_i, f)_\Omega \quad \Rightarrow \\
\sum_{j\in \mathcal N \setminus \mathcal N_D}(\nabla \varphi_i,\nabla \varphi_j)_\Omega \, u_j &=&
(\varphi_i, f)_\Omega


-\sum_{j\in \mathcal N_D} (\nabla \varphi_i,\nabla\varphi_j)_\Omega\, g_j.


@f}

在这个公式中，对所有的基函数 $\varphi_i$ 与 $i\in N \setminus \mathcal N_D$ 进行测试，这些基函数与迪里希特条件约束的节点没有关系。

在deal.II的实现中，右手边的积分 $(\nabla \varphi_i,\nabla \varphi_j)_\Omega$ 已经包含在我们在每个单元格上组装的局部矩阵贡献中。当使用 AffineConstraints::distribute_local_to_global() 时，正如在步骤6和步骤7的教程程序中首次描述的那样，我们可以通过将本地矩阵的列<i>j</i>和行<i>i</i>相乘来说明不均匀约束的贡献<i>j</i> 的局部矩阵根据积分 $(\varphi_i,
\varphi_j)_\Omega$ 乘以不均匀性，然后从全局右侧向量中的位置<i>i</i>中减去所得，也见 @ref
constraints  模块。实质上，我们使用一些从方程左侧被消除的积分来最终确定右侧的贡献。当首先将所有条目写进左侧矩阵，然后通过 MatrixTools::apply_boundary_values(). 消除矩阵的行和列时，也会涉及类似的数学。

原则上，属于受限自由度的成分可以从线性系统中剔除，因为它们不携带任何信息。实际上，在deal.II中，我们总是保持线性系统的大小不变，以避免处理两种不同的编号系统，并避免对两种不同的索引集产生混淆。为了确保在不向受限行添加任何东西时，线性系统不会变得奇异，我们再向矩阵对角线添加假条目，否则与真实条目无关。

在无矩阵方法中，我们需要采取不同的方法，因为 @p LaplaceOperator类代表了<b>homogeneous</b>算子的矩阵-向量乘积（最后一个公式的左手边）。  传递给 MatrixFree::reinit() 的AffineConstraints对象是否包含不均匀约束并不重要，只要它代表一个<b>linear</b>算子， MatrixFree::cell_loop() 调用将只解决约束的同质部分。

在我们的无矩阵代码中，非均质条件的贡献最终会在右侧计算中与矩阵算子完全脱钩，并由上述不同的函数处理。因此，我们需要明确地生成进入右手边的数据，而不是使用矩阵装配的副产品。由于我们已经知道如何在一个向量上应用算子，我们可以尝试对一个向量使用这些设施，我们只设置Dirichlet值。

@code
  // interpolate boundary values on vector solution
  std::map<types::global_dof_index, double> boundary_values;
  VectorTools::interpolate_boundary_values(mapping,
                                           dof_handler,
                                           0,
                                           BoundaryValueFunction<dim>(),
                                           boundary_values);
  for (const std::pair<const types::global_dof_index, double> &pair : boundary_values)
    if (solution.locally_owned_elements().is_element(pair.first))
      solution(pair.first) = pair.second;
@endcode

或者说，如果我们已经将不均匀约束填充到AffineConstraints对象中。

@code
  solution = 0;
  constraints.distribute(solution);
@endcode



然后我们可以将向量 @p solution 传递给 @p  LaplaceOperator::vmult_add() 函数，并将新的贡献添加到 @p system_rhs向量中，在 @p LaplaceProblem::assemble_rhs() 函数中被填充。然而，这个想法并不奏效，因为vmult()函数中使用的 FEEvaluation::read_dof_values() 调用假定所有约束条件的值都是同质的（否则运算符就不是线性运算符，而是仿射运算符）。为了同时检索不均匀性的值，我们可以选择以下两种策略中的一种。

<h5> Use FEEvaluation::read_dof_values_plain() to avoid resolving constraints </h5>

FEEvaluation类有一个设施，正是为了解决这个要求。对于非均质的Dirichlet值，我们确实希望在从向量 @p solution. 中读取数据时跳过隐含的均质（Dirichlet）约束。例如，我们可以扩展 @p  LaplaceProblem::assemble_rhs() 函数来处理非均质的Dirichlet值，如下所示，假设Dirichlet值已经被插值到对象 @p constraints:  中

@code
template <int dim>
void LaplaceProblem<dim>::assemble_rhs()
{
  solution = 0;
  constraints.distribute(solution);
  solution.update_ghost_values();
  system_rhs = 0;


  const Table<2, VectorizedArray<double>> &coefficient = system_matrix.get_coefficient();
  FEEvaluation<dim, degree_finite_element> phi(*system_matrix.get_matrix_free());
  for (unsigned int cell = 0;
       cell < system_matrix.get_matrix_free()->n_cell_batches();
       ++cell)
    {
      phi.reinit(cell);
      phi.read_dof_values_plain(solution);
      phi.evaluate(EvaluationFlags::gradients);
      for (unsigned int q = 0; q < phi.n_q_points; ++q)
        {
          phi.submit_gradient(-coefficient(cell, q) * phi.get_gradient(q), q);
          phi.submit_value(make_vectorized_array<double>(1.0), q);
        }
      phi.integrate(EvaluationFlags::values|EvaluationFlags::gradients);
      phi.distribute_local_to_global(system_rhs);
    }
  system_rhs.compress(VectorOperation::add);
}
@endcode



在这段代码中，我们用忽略所有约束的 FEEvaluation::read_dof_values_plain() 代替了用于暂定解向量的 FEEvaluation::read_dof_values() 函数。由于这种设置，我们必须确保其他约束条件，例如通过悬挂节点，已经正确地分布到输入向量中，因为它们没有像 FEEvaluation::read_dof_values_plain(). 那样被解决。 在循环内部，我们然后评估拉普拉斯，并用 @p LaplaceOperator 类中的 FEEvaluation::submit_gradient() 重复二次导数调用，但符号调换，因为我们想根据上述公式减去右侧向量的迪里希条件的贡献。当我们调用 FEEvaluation::integrate() 时，我们将关于值槽和第一导数槽的两个参数设置为真，以说明在正交点的循环中加入的两个项。一旦右手边集合完毕，我们就继续求解同质问题的线性系统，比如说涉及到一个变量 @p solution_update. 在求解之后，我们可以将 @p solution_update 加入到包含最终（非同质）解决方案的 @p solution 向量中。

请注意，拉普拉斯的负号与我们需要用来建立右手边的强制力的正号是一个更普遍的概念。我们所实施的只不过是牛顿的非线性方程方法，但应用于线性系统。我们在迪里切特边界条件方面使用了对变量 @p solution 的初始猜测，并计算了残差 $r = f - Au_0$  。然后线性系统被解为  $\Delta u = A^{-1} (f-Au)$  ，我们最后计算出  $u = u_0 + \Delta u$  。对于一个线性系统，我们显然在一次迭代后就能达到精确解。如果我们想将代码扩展到非线性问题，我们会将 @p assemble_rhs() 函数重新命名为一个更具描述性的名字，如 @p  assemble_residual()，计算残差的（弱）形式，而 @p LaplaceOperator::apply_add() 函数将得到残差相对于解变量的线性化。

<h5> Use LaplaceOperator with a second AffineConstraints object without Dirichlet conditions </h5>

获得重新使用 @p  LaplaceOperator::apply_add() 函数的第二个替代方法是添加第二个LaplaceOperator，跳过Dirichlet约束。为了做到这一点，我们初始化第二个MatrixFree对象，它没有任何边界值约束。这个 @p matrix_free 对象然后被传递给一个 @p LaplaceOperator 类实例 @p inhomogeneous_operator，它只用于创建右手边。

@code
template <int dim>
void LaplaceProblem<dim>::assemble_rhs()
{
  system_rhs = 0;
  AffineConstraints<double> no_constraints;
  no_constraints.close();
  LaplaceOperator<dim, degree_finite_element, double> inhomogeneous_operator;


  typename MatrixFree<dim, double>::AdditionalData additional_data;
  additional_data.mapping_update_flags =
    (update_gradients | update_JxW_values | update_quadrature_points);
  std::shared_ptr<MatrixFree<dim, double>> matrix_free(
    new MatrixFree<dim, double>());
  matrix_free->reinit(dof_handler,
                      no_constraints,
                      QGauss<1>(fe.degree + 1),
                      additional_data);
  inhomogeneous_operator.initialize(matrix_free);


  solution = 0.0;
  constraints.distribute(solution);
  inhomogeneous_operator.evaluate_coefficient(Coefficient<dim>());
  inhomogeneous_operator.vmult(system_rhs, solution);
  system_rhs *= -1.0;


  FEEvaluation<dim, degree_finite_element> phi(
    *inhomogeneous_operator.get_matrix_free());
  for (unsigned int cell = 0;
       cell < inhomogeneous_operator.get_matrix_free()->n_cell_batches();
       ++cell)
    {
      phi.reinit(cell);
      for (unsigned int q = 0; q < phi.n_q_points; ++q)
        phi.submit_value(make_vectorized_array<double>(1.0), q);
      phi.integrate(EvaluationFlags::values);
      phi.distribute_local_to_global(system_rhs);
    }
  system_rhs.compress(VectorOperation::add);
}
@endcode



这种技术的更复杂的实现可以重新使用原始的MatrixFree对象。这可以通过用多个块初始化MatrixFree对象来实现，其中每个块对应于不同的AffineConstraints对象。这样做需要对LaplaceOperator类进行大量的修改，但是库中的 MatrixFreeOperators::LaplaceOperator 类可以做到这一点。关于如何设置块的更多信息，请参见 MatrixFreeOperators::Base 中关于块的讨论。


examples/step-38/doc/intro.dox

 <br> 

<i>This program was contributed by Andrea Bonito and M. Sebastian Pauletti,
with editing and writing by Wolfgang Bangerth.
<br>
This material is based upon work supported by the National Science
Foundation under Grant No. DMS-0914977. Any opinions, findings and conclusions
or recommendations expressed in this material are those of the author(s) and
do not necessarily reflect the views of the National Science Foundation
(NSF).
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

在这个例子中，我们展示了如何解决由四边形组成的一维曲面 $\Gamma \subset \mathbb R^3$ 上的偏微分方程（PDE），即在三维的曲面或二维的直线上。我们重点讨论以下的椭圆二阶PDE

@f{align*}


-\Delta_\Gamma u &= f \qquad \text{on } \qquad \Gamma,\\
u  &= g \qquad \text{on} \qquad \partial \Gamma,


@f}

它概括了我们以前在几个早期教程程序中解决的拉普拉斯方程。我们的实现是基于step-4的。step-34也可以解决低维曲面上的问题；但是，在那里我们只考虑不涉及解变量导数的积分方程，而在这里我们实际上要研究只在一个（可能是弯曲的）曲面上定义的函数的导数是什么意思。

为了定义上述算子，我们首先要介绍一些符号。让 $\mathbf x_S:\hat S \rightarrow S$ 是一个由参考元素 $\hat S \subset \mathbb R^2$ 构成的曲面 $S$ 的参数化，即每个点 $\hat{\mathbf x}\in\hat S$ 诱导出一个点 ${\mathbf
  x}_S(\hat{\mathbf x}) \in S$  。那么让

@f[
G_S\dealcoloneq (D \mathbf{x}_S)^T \ D \mathbf{x}_S


@f]

表示相应的第一基本形式，其中 $D
\mathbf{x}_S=\left(\frac{\partial x_{S,i}(\hat{\mathbf x})}{\partial \hat x_j}\right)_{ij}$ 是映射的导数（雅各布）。在下文中， $S$ 将是整个表面 $\Gamma$ ，或者对有限元方法更方便的是任何面 $S \in
{\mathbb T}$ ，其中 ${\mathbb T}$ 是由四边形构成的 $\Gamma$ 的分区（三角化）。我们现在可以定义一个函数 $v : S \rightarrow \mathbb
R$ 的切向梯度，即

@f[
(\nabla_S v)\circ \mathbf x_S \dealcoloneq  D \mathbf x_S \ G_S^{-1} \ \nabla (v \circ \mathbf x_S).


@f]

表面拉普拉斯(也叫拉普拉斯-贝特拉米算子)的定义是  $\Delta_S \dealcoloneq \nabla_S \cdot \nabla_S$  。请注意，在光滑表面上计算表面梯度的另一种方法  $\Gamma$  是

@f[
\nabla_S v = \nabla \tilde v - \mathbf n (\mathbf n \cdot \nabla \tilde v),


@f]

其中 $\tilde v$ 是 $v$ 在 $\Gamma$ 的管状邻域的 "平滑 "扩展， $\mathbf n$ 是 $\Gamma$ 的法线。由于 $\Delta_S = \nabla_S \cdot \nabla_S$ ，我们推导出

@f[
\Delta_S v = \Delta \tilde v - \mathbf n^T \ D^2 \tilde v \ \mathbf n - (\mathbf n \cdot \nabla \tilde v) (\nabla \cdot \mathbf n - \mathbf n^T \ D \mathbf n \ \mathbf n ).


@f]

值得一提的是，上述表达式中出现的术语 $\nabla \cdot \mathbf n - \mathbf n \ D \mathbf n \ \mathbf n$ 是曲面的总曲率（主曲率之和）。

像往常一样，我们只对弱解感兴趣，为此我们可以使用 $C^0$ 有限元（而不是像强解那样要求 $C^1$ 的连续性）。因此，我们求助于弱的表述

@f[
\int_\Gamma \nabla_\Gamma u \cdot
\nabla_\Gamma v = \int_\Gamma f \ v  \qquad \forall v \in H^1_0(\Gamma)


@f]

并利用分区 ${\mathbb T}$ 的优势，进一步编写

@f[
\sum_{K\in  {\mathbb T}}\int_K \nabla_{K} u \cdot \nabla_{K} v = \sum_{K\in
  {\mathbb T}} \int_K f \ v  \qquad \forall v \in H^1_0(\Gamma).


@f]

此外，上述表达式中的每个积分都是在参考元素 $\hat K \dealcoloneq [0,1]^2$ 中计算的，因此

@f{align*}
\int_{K} \nabla_{K} u \cdot \nabla_{K} v
&=
\int_{\hat K} \nabla (u \circ \mathbf x_K)^T G_K^{-1} (D \mathbf
  x_K)^T D \mathbf x_K G_K^{-1} \nabla (v \circ \mathbf x_K) \sqrt{\det
    (G_K)}
\\
&=
\int_{\hat K} \nabla (u \circ \mathbf x_K)^T G_K^{-1} \nabla (v \circ \mathbf x_K) \sqrt{\det
    (G_K)}


@f}

和

@f[
\int_{K} f \ v = \int_{\hat K} (f \circ \mathbf x_K) (v \circ \mathbf
x_K)  \sqrt{\det
    (G_K)}.


@f]

最后，我们使用由点 $\{p_l\}_{l=1}^N\subset
\hat K$ 和权重 $\{w_l\}_{l=1}^N \subset \mathbb R^+_*$ 定义的正交公式来评估上述积分，得到

@f[\int_{K} \nabla_{K} u \cdot \nabla_{K} v \approx \sum_{l=1}^N
 (\nabla (u \circ \mathbf x_K)(p_l))^T G^{-1}(p_l)  \nabla (v \circ \mathbf x_K)
(p_l) \sqrt{\det (G(p_l))} \ w_l


@f]

和

@f[
\int_{K} f \ v \approx \sum_{l=1}^N (f \circ \mathbf x_K)(p_l) \ (v \circ \mathbf x_K)(p_l) \sqrt{\det (G(p_l))} \ w_l.


@f]




幸运的是，deal.II已经有了所有的工具来计算上述表达式。事实上，它们与我们求解通常的拉普拉斯的方法几乎没有区别，只需要在FEValues类的构造函数中提供表面坐标映射。这个曲面描述给定，在二维曲面的情况下，两个例程 FEValues::shape_grad 和 FEValues::JxW 会返回

@f{align*}
\text{FEValues::shape\_grad}(i,l)&=D \mathbf x_K(p_l) G^{-1}(p_l)D(\varphi_i \circ \mathbf x_K)
  (p_l)
\\
\text{FEValues::JxW}(l) &=  \sqrt{\det (G(p_l))} \ w_l.


@f}

这正好提供了我们的计算所需的术语。

在更广泛的意义上，表面有限元逼近的细节可以在[Dziuk, in Partial differential equations and calculus of variations 1357, Lecture Notes in Math., 1988], [Demlow, SIAM J. Numer. Anal. 47(2), 2009] 和 [Bonito, Nochetto, and Pauletti, SIAM J. Numer. Anal. 48(5), 2010] 中找到。




<h3>Testcase</h3>

一般来说，当你想在数值上测试一个算法的准确性和/或收敛性，你需要提供一个精确的解决方案。通常的技巧是选择一个我们希望成为解决方案的函数，然后对其应用微分算子，为右侧定义一个强制项。这就是我们在这个例子中所做的。在当前情况下，域的形式显然也是至关重要的。

我们为二维问题制作一个测试案例，为三维问题制作另一个测试案例。

 <ul>   <li>  在2d中，让我们选择一个半圆作为域。在这个域上，我们选择函数 $u(\mathbf x)=-2x_1x_2$ 作为解决方案。为了计算右手边，我们必须计算解函数的表面拉普拉斯。有（至少）两种方法可以做到这一点。第一种是使用 $u(\mathbf x)$ 的自然延伸（仍然用 $u$ 表示）在 $\mathbb R^d$ 上投影掉上面描述的法向导数，即计算@f[


    -\Delta_\Gamma u =  \Delta u - \mathbf n^T \ D^2 u \ \mathbf n - (\mathbf n \cdot \nabla u)\ \kappa,
  @f] 。

  其中  $\kappa$  是  $\Gamma$  的总曲率。   由于我们在单位圆上， $\mathbf n=\mathbf x$ 和 $\kappa = 1$ 所以@f[


    -\Delta_\Gamma u = -8 x_1x_2.
  @f]



  一个更简单的方法，至少对于目前二维空间的曲线的情况，是注意到我们可以用变换 $t \in
  [0,\pi]$ 将区间 $\Omega$ 映射到域 $\mathbf x(t)= \left(\begin{array}{c} \cos t \\ \sin t \end{array}\right)$ 。   在位置  $\mathbf x=\mathbf x(t)$  上，解的值是  $u(\mathbf x(t)) = -2\cos t \sin t$  。   考虑到转换是保长的，即长度为 $dt$ 的线段被映射到完全相同长度的曲线上，那么切向拉普拉斯就满足@f{align*}
    \Delta_\Gamma u
    &= \frac{d^2}{dt^2}(-2\cos t \sin t)
    = -2 \frac{d}{dt}(-\sin^2 t + \cos^2 t)
    = -2 (-2 \sin t \cos t - 2 \cos t \sin t)
    \\
    &= 8 \sin t \cos t
    \\
    &= 8 x_1x_2,
  @f} 。

  这当然和我们上面的结果是一样的。   </li>   <li>  在三维中，域又是单位球表面的一半，即半球或圆顶。我们选择 $u(\mathbf x)=-2\sin(\pi x_1)\cos(\pi x_2)e^z$ 作为解决方案。我们可以用上面的方法计算方程的右边， $f=-\Delta_\Gamma u$ ，（用 $\kappa = 2$ ），得到一个笨拙而冗长的表达。你可以在源代码中找到完整的表达式。   </li>   </ul> 。

在程序中，我们还将计算出解的 $H^1$ 半规范误差。由于解函数及其数值近似只在流形上定义，这个误差函数的明显定义是 $| e |_{H^1(\Gamma)}
  = | \nabla_\Gamma e |_{L_2(\Gamma)}
  = \left( \int_\Gamma | \nabla_\Gamma (u-u_h) |^2 \right)^{1/2}$  。这就要求我们为函数 VectorTools::integrate_difference （在步骤7中首次引入）提供<i>tangential</i>梯度 $\nabla_\Gamma u$ ，我们将通过在下面的程序中实现函数 <code>Solution::gradient</code> 来实现。




<h3>Implementation</h3>

如果你已经读完了第4步，并且理解了上面关于解和右边如何对应的讨论，你也会立即熟悉这个程序。事实上，只有两件事是有意义的。

- 我们生成三角计算域的网格的方式。

- 我们使用映射对象的方式来描述，我们解决偏微分方程的领域不是平面的，实际上是弯曲的。

在第10步和第11步中已经介绍了映射对象，正如那里所解释的，只要你对边界的样子有一个有效的描述，你通常不需要知道它们是如何工作的。从本质上讲，我们将简单地声明一个适当的MappingQ类型的对象，它将自动从三角图中获得边界描述。然后，该映射对象将被传递给适当的函数，我们将得到库中预定义的半圆或半球形的边界描述。

该程序的其余部分紧跟步骤4，至于计算误差，则是步骤7。这个程序的某些方面，特别是在Triangulation、DoFHandler和类似的类上使用两个模板参数，已经在步骤34中作了详细描述；你不妨也读一读这个教程程序。


examples/step-38/doc/results.dox



<h1>Results</h1>

当你运行该程序时，应在屏幕上打印出以下输出。

@verbatim
Surface mesh has 1280 cells.
Surface mesh has 5185 degrees of freedom.
H1 error = 0.0217136
@endverbatim




通过在 <code>LaplaceBeltrami::make_grid_and_dofs</code> 函数中玩弄全局细化的数量，可以增加或减少网格细化。例如，多做一次细化，只运行三维曲面问题，得到的输出结果如下。

@verbatim
Surface mesh has 5120 cells.
Surface mesh has 20609 degrees of freedom.
H1 error = 0.00543481
@endverbatim



这就是我们所期望的：将网格尺寸缩小2倍，误差下降4倍（记住我们使用的是双二次元）。从一到五次细化的全部误差序列看起来是这样的，整齐地遵循理论上预测的模式。

@verbatim
0.339438
0.0864385
0.0217136
0.00543481
0.00135913
@endverbatim



最后，该程序产生图形输出，我们可以将其可视化。下面是一个结果图。

 <img src="https://www.dealii.org/images/steps/developer/step-38.solution-3d.png" alt=""> 

该程序也适用于2D中的1D曲线，而不仅仅是3D中的2D曲面。你可以通过改变 <code>main()</code> 中的模板参数来测试这一点，像这样。

@code
      LaplaceBeltramiProblem<2> laplace_beltrami;
@endcode

域是一条2D的曲线，我们可以通过使用第三维（和颜色）来表示函数 $u(x)$ 的值来可视化解决方案。这样看起来就像这样（白色的曲线是域，彩色的曲线是被挤压到第三维的解决方案，清楚地显示了当曲线从域的一个象限移动到相邻的象限时符号的变化）。

 <img src="https://www.dealii.org/images/steps/developer/step-38.solution-2d.png" alt=""> 


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

只有当表面比仅仅是一个半球体更有趣时，在表面上的计算才会变得有趣。为了达到这个目的，deal.II可以通过通常的GridIn类读取描述曲面的网格。或者，万一你有一个分析性的描述，一个简单的网格有时可以被拉伸和弯曲成我们感兴趣的形状。

让我们考虑一个相对简单的例子：我们把之前用过的半球体，在Z方向上拉伸10倍，然后把X和Y坐标拼一下。让我们先展示一下计算域和解决方案，然后再讨论下面的实现细节。

 <img src="https://www.dealii.org/images/steps/developer/step-38.warp-1.png" alt=""> 

 <img src="https://www.dealii.org/images/steps/developer/step-38.warp-2.png" alt=""> 

产生这种网格的方法是使用 GridTools::transform() 函数。它需要一个方法来转换每个单独的网格点到不同的位置。让我们在这里使用下面这个相当简单的函数（记住：在一个方向上拉伸，在另外两个方向上拼凑）。

@code
template <int spacedim>
Point<spacedim> warp(const Point<spacedim> &p)
{
  Point<spacedim> q = p;
  q[spacedim-1] *= 10;


  if (spacedim >= 2)
    q[0] += 2*std::sin(q[spacedim-1]);
  if (spacedim >= 3)
    q[1] += 2*std::cos(q[spacedim-1]);


  return q;
}
@endcode



如果我们遵循 <code>LaplaceBeltrami::make_grid_and_dofs</code> 函数，我们会像以前一样提取半球形表面网格，将其扭曲成我们想要的形状，并根据需要经常进行细化。但这并不像我们所希望的那样简单：细化需要我们有一个适当的流形对象附加到三角形上，描述细化时网格的新顶点应该位于何处。我相信可以通过简单地撤销上面的变换（重新得到球面），找到球面上新的点的位置，然后重新扭曲结果，以一种不太复杂的方式描述这个流形。但我是个懒人，既然这样做并不是真正的重点，我们还是让我们的生活变得简单一点：我们将提取半球体，根据需要对其进行细化，摆脱描述流形的对象，因为我们现在不再需要它，然后最后对网格进行扭曲。使用上面的函数，这将看起来如下。

@code
template <int spacedim>
void LaplaceBeltrami<spacedim>::make_grid_and_dofs()
{
  {
    Triangulation<spacedim> volume_mesh;
    GridGenerator::half_hyper_ball(volume_mesh);


    volume_mesh.refine_global(4);


    std::set<types::boundary_id> boundary_ids;
    boundary_ids.insert(0);


    GridGenerator::extract_boundary_mesh(volume_mesh, triangulation,
                                         boundary_ids);
    GridTools::transform(&warp<spacedim>, triangulation);       /* ** */
    std::ofstream x("x"), y("y");
    GridOut().write_gnuplot(volume_mesh, x);
    GridOut().write_gnuplot(triangulation, y);
  }


  std::cout << "Surface mesh has " << triangulation.n_active_cells()
            << " cells."
            << std::endl;
  ...
}
@endcode



请注意，唯一必要的补充是标有星号的那一行。不过值得指出的是：由于我们将流形描述从表面网格中分离出来，所以当我们在程序的其余部分使用映射对象时，它不再有曲线边界描述可言。相反，它将不得不使用隐含的FlatManifold类，该类用于域的所有未明确指定不同流形对象的部分。因此，无论我们使用MappingQ(2)、MappingQ(15)还是MappingQ1，我们的网格的每个单元都将使用双线性近似进行映射。

撇开所有这些缺点不谈，得到的图片还是很好看的。与步骤38中的内容唯一不同的是，我们把右手边改为 $f(\mathbf x)=\sin x_3$ ，把边界值（通过 <code>Solution</code> 类）改为 $u(\mathbf x)|_{\partial\Omega}=\cos x_3$  。当然，我们现在已经不知道确切的解决方案，所以在 <code>LaplaceBeltrami::run</code> 末尾的误差计算将得到一个毫无意义的数字。


examples/step-39/doc/intro.dox

<a name="Intro"></a>

在这个程序中，我们使用内部惩罚方法和Nitsche的弱边界条件来解决Poisson方程。我们在局部细化的网格上使用多网格方法，这些网格是用一个体块准则和一个基于单元和面残差的标准误差估计器生成的。所有的运算符都是用MeshWorker接口实现的。

像步骤12一样，离散化依赖于有限元空间，它在网格单元 $K\in \mathbb T_h$ 内是多项式的，但在单元之间没有连续性。由于这种函数在每个内部面 $F\in \mathbb F_h^i$ 上有两个值，每边一个，我们定义均值和跳跃算子如下：让<i>K</i><sub>1</sub>和<i>K</i><sub>2</sub>是共享一个面的两个单元，让函数的轨迹<i>u<sub>i</sub></i>和外法向量<b>n</b><i><sub>i</sub></i>相应地被标记。然后，在这个面上，我们让

@f[
	\average{ u } = \frac{u_1 + u_2}2


@f]



注意，如果这样的表达式包含一个法向量，那么平均运算符就会变成一个跳跃。该问题的内部惩罚方法

@f[


  -\Delta u = f \text{ in }\Omega \qquad u = u^D \text{ on } \partial\Omega


@f]

成为

@f{multline*}
  \sum_{K\in \mathbb T_h} (\nabla u, \nabla v)_K
  \\
  + \sum_{F \in F_h^i} \biggl\{4\sigma_F (\average{ u \mathbf n}, \average{ v \mathbf n })_F


  - 2 (\average{ \nabla u },\average{ v\mathbf n })_F


  - 2 (\average{ \nabla v },\average{ u\mathbf n })_F
  \biggr\}
  \\
  + \sum_{F \in F_h^b} \biggl\{2\sigma_F (u, v)_F


  - (\partial_n u,v)_F


  - (\partial_n v,u)_F
  \biggr\}
  \\
  = (f, v)_\Omega + \sum_{F \in F_h^b} \biggl\{
  2\sigma_F (u^D, v)_F - (\partial_n v,u^D)_F
  \biggr\}.


@f}



这里， $\sigma_F$ 是惩罚参数，其选择如下：对于<i>F</i>单元格<i>K</i>的一个面，计算数值

@f[
\sigma_{F,K} = p(p+1) \frac{|F|_{d-1}}{|K|_d},


@f]

其中<i>p</i>是有限元函数的多项式程度， $|\cdot|_d$ 和 $|\cdot|_{d-1}$ 表示相应对象的 $d$ 和 $d-1$ 维度的Hausdorff度量。如果面在边界上，选择 $\sigma_F = \sigma_{F,K}$  。对于一个内部的面，我们取这个面的两个值的平均值。

在我们的有限元程序中，我们区分了三种不同的积分，分别对应于上面的单元、内部面和边界面的总和。由于 MeshWorker::loop 为我们组织了这些和，我们只需要实现对每个网格元素的积分。下面的MatrixIntegrator类有这三个函数用于公式的左边，RHSIntegrator类用于右边。

正如我们将在下面看到的，甚至误差估计也是相同的结构，因为它可以写成

@f{align*}
  \eta^2 &= \eta_K^2 + \eta_F^2 + \eta_B^2
  \\
  \eta_K^2 &= \sum_{K\in \mathbb T_h} h^2 \|f + \Delta u_h\|^2
  \\
  \eta_F^2 &= \sum_{F \in F_h^i} \biggl\{
    4 \sigma_F \| \average{u_h\mathbf n} \|^2 + h \|\average{\partial_n u_h}\|^2 \biggr\}
  \\
  \eta_B^2 &= \sum_{F \in F_h^b} 2\sigma_F \| u_h-u^D \|^2.


@f}



因此，下面用于组装矩阵、右手和误差估计的函数显示，这些循环都是通用的，可以用同样的方式进行编程。

这个程序与步骤12b有关，因为它使用MeshWorker和非连续Galerkin方法。在那里，我们解决的是一个平流问题，而这里是一个扩散问题。在这里，我们还使用了多网格预处理和一个理论上合理的误差估计器，见Karakashian和Pascal（2003）。Kanschat (2004)详细讨论了多层次方案。Hoppe, Kanschat, and Warburton (2009)讨论了自适应迭代及其收敛性（对于三角形网格）。


examples/step-39/doc/results.dox



<h1>Results</h1>

<h3>Logfile output</h3> 首先，该程序产生通常的日志文件，在这里存储在<tt>deallog</tt>。它的内容是（省略了中间的步骤

@code
DEAL::Element: FE_DGQ<2>(3)
DEAL::Step 0
DEAL::Triangulation 16 cells, 2 levels
DEAL::DoFHandler 256 dofs, level dofs 64 256
DEAL::Assemble matrix
DEAL::Assemble multilevel matrix
DEAL::Assemble right hand side
DEAL::Solve
DEAL:cg::Starting value 37.4071
DEAL:cg::Convergence step 13 value 1.64974e-13
DEAL::energy-error: 0.297419
DEAL::L2-error:     0.00452447
DEAL::Estimate 0.990460
DEAL::Writing solution to <sol-00.gnuplot>...
DEAL::
DEAL::Step 1
DEAL::Triangulation 25 cells, 3 levels
DEAL::DoFHandler 400 dofs, level dofs 64 256 192
DEAL::Assemble matrix
DEAL::Assemble multilevel matrix
DEAL::Assemble right hand side
DEAL::Solve
DEAL:cg::Starting value 37.4071
DEAL:cg::Convergence step 14 value 3.72262e-13
DEAL::energy-error: 0.258559
DEAL::L2-error:     0.00288510
DEAL::Estimate 0.738624
DEAL::Writing solution to <sol-01.gnuplot>...
DEAL::
DEAL::Step 2
DEAL::Triangulation 34 cells, 4 levels
DEAL::DoFHandler 544 dofs, level dofs 64 256 256 128
DEAL::Assemble matrix
DEAL::Assemble multilevel matrix
DEAL::Assemble right hand side
DEAL::Solve
DEAL:cg::Starting value 37.4071
DEAL:cg::Convergence step 15 value 1.91610e-13
DEAL::energy-error: 0.189234
DEAL::L2-error:     0.00147954
DEAL::Estimate 0.657507
DEAL::Writing solution to <sol-02.gnuplot>...


...


DEAL::Step 10
DEAL::Triangulation 232 cells, 11 levels
DEAL::DoFHandler 3712 dofs, level dofs 64 256 896 768 768 640 512 256 256 256 256
DEAL::Assemble matrix
DEAL::Assemble multilevel matrix
DEAL::Assemble right hand side
DEAL::Solve
DEAL:cg::Starting value 51.1571
DEAL:cg::Convergence step 15 value 7.19599e-13
DEAL::energy-error: 0.0132475
DEAL::L2-error:     1.00423e-05
DEAL::Estimate 0.0470724
DEAL::Writing solution to <sol-10.gnuplot>...
DEAL::
DEAL::Step 11
DEAL::Triangulation 322 cells, 12 levels
DEAL::DoFHandler 5152 dofs, level dofs 64 256 1024 1024 896 768 768 640 448 320 320 320
DEAL::Assemble matrix
DEAL::Assemble multilevel matrix
DEAL::Assemble right hand side
DEAL::Solve
DEAL:cg::Starting value 52.2226
DEAL:cg::Convergence step 15 value 8.15195e-13
DEAL::energy-error: 0.00934891
DEAL::L2-error:     5.41095e-06
DEAL::Estimate 0.0329102
DEAL::Writing solution to <sol-11.gnuplot>...
DEAL::
@endcode



例如，该日志显示共轭梯度迭代步骤的数量恒定在大约15个。

<h3>Postprocessing of the logfile</h3>

 <img src="https://www.dealii.org/images/steps/developer/step-39-convergence.svg" alt="">  使用perl脚本<tt>postprocess.pl</tt>，我们提取相关数据到<tt>output.dat</tt>，可以用<tt>gnuplot</tt>绘制图形。例如，上面的图是用gnuplot脚本<tt>plot_errors.gpl</tt>制作的，通过

@code
perl postprocess.pl deallog &> output.dat
gnuplot plot_errors.gpl
@endcode



参考数据可以在<tt>output.reference.dat</tt>中找到。


examples/step-4/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{12,13} 

deal.II有一个独特的功能，我们称之为 "无维度编程"。你可能已经注意到，在前面的例子中，许多类的后缀都是角括号中的数字。这是为了表明，例如，二维和三维空间的三角形是不同的，但是相关的数据%类型。我们完全可以把它们称为 <code>Triangulation2d</code> and <code>Triangulation3d</code> 而不是 <code>Triangulation@<2@></code> 和 <code>Triangulation@<3@></code> 来命名这两个类，但这有一个重要的缺点：假设你有一个功能完全相同的函数，但在2D或3D三角形上，取决于我们目前想在哪个维度上解方程（如果你不相信一个函数在所有维度上都做同样的事情是常见的情况，看看下面的代码就知道了，2D和3D之间几乎没有区别！）。我们将不得不把同一个函数写两次，一次在 <code>Triangulation2d</code> 上工作，一次在 <code>Triangulation3d</code> 上工作。这在编程中是一个不必要的障碍，并且导致了保持两个函数同步的麻烦（最好是），或者在两个版本不同步时难以发现错误（最坏的情况是；这可能是更常见的情况）。





这种障碍可以通过使用C++语言提供的一些模板魔法来规避：模板化的类和函数并不是真正的类或函数，而只是取决于一个尚未定义的数据类型参数或在定义时也未知的数值的一种模式。然而，如果你向它提供了所需的信息，编译器可以从这些模板中建立适当的类或函数。当然，模板的部分内容可以依赖于模板参数，它们将在编译时被解析为特定的模板参数。例如，考虑下面这段代码。

@code
  template <int dim>
  void make_grid (Triangulation<dim> &triangulation)
  {
    GridGenerator::hyper_cube (triangulation, -1, 1);
  };
@endcode






在编译器看到这个函数的时候，它对 <code>dim</code> 的实际值并不了解。编译器唯一拥有的是一个模板，即蓝图，如果给定 <code>make_grid</code> 的特定值有一个未知的值，编译器暂时没有可以生成的代码。




然而，如果以后下来，编译器会遇到一些代码，例如，看起来像这样。

@code
  Triangulation<2> triangulation;
  make_grid (triangulation);
@endcode

那么编译器将推断出请求将函数 <code>make_grid</code> 替换为 <code>dim==2</code> ，并将上述模板编译为一个到处都用2替换了dim的函数，也就是说，它将编译该函数，就好像它被定义为

@code
  void make_grid (Triangulation<2> &triangulation)
  {
    GridGenerator::hyper_cube (triangulation, -1, 1);
  };
@endcode






然而，值得注意的是，函数 <code>GridGenerator::hyper_cube</code> 也取决于维度，所以在这种情况下，编译器将调用函数 <code>GridGenerator::hyper_cube@<2@></code> ，而如果dim是3，它将调用 <code>GridGenerator::hyper_cube@<3@></code> ，这可能是（实际上是）一个完全无关的函数。




对成员变量也可以这样做。考虑一下下面的函数，它可能反过来调用上面的函数。

@code
  template <int dim>
  void make_grid_and_dofs (Triangulation<dim> &triangulation)
  {
    make_grid (triangulation);


    DoFHandler<dim> dof_handler(triangulation);
    ...
  };
@endcode

这个函数有一个类型为  <code>DoFHandler@<dim@></code>  的成员变量。同样，编译器在知道哪个维度之前不能编译这个函数。如果你像上面那样为一个特定的维度调用这个函数，编译器将使用模板，用调用的维度替换所有出现的dim，并编译它。如果你为不同的维度多次调用该函数，它将多次编译，每次都调用正确的 <code>make_grid</code> 函数，并为成员变量保留适当的内存量；注意， <code>DoFHandler</code> 的大小可能，事实上也确实取决于空间维度。




deal.II库是围绕这个独立于维度的编程概念建立的，因此允许你以一种不需要区分空间维度的方式来编程。应该注意的是，只有在极少数的地方才有必要使用 <code>if</code>s or <code>switch</code> es来实际比较尺寸。然而，由于编译器必须为每个维度单独编译每个函数，即使在那里，它在编译时也知道 <code>dim</code> 的值，因此将能够优化掉 <code>if</code> 语句和未使用的分支。




在这个例子程序中，我们将展示如何独立编程维度（事实上，这比你必须照顾到维度还要简单），我们将把上一个例子的拉普拉斯问题扩展到一个同时在两个和三个空间维度运行的程序。其他的扩展是使用非恒定的右手边函数和非零边界值。




 @note  在使用模板时，C++强加了各种语法限制，有时让人有点难以理解为什么到底要这样写。一个典型的例子是，在很多地方都需要使用关键字 <code>typename</code> 。如果你已经不完全熟悉，那么在<a
href="http://www.dealii.org/">deal.II homepage</a>中链接的deal.II常见问题解答（FAQ）中解释了其中的几个困难。

<！--我们需要一个空行来正确结束上述块。


examples/step-4/doc/results.dox



<h1>Results</h1>


程序的输出看起来如下（迭代次数可能会有一到两次的变化，这取决于你的计算机，因为这通常取决于浮点运算的舍入精度，而这在不同的处理器之间是不同的）。

@code
Solving problem in 2 space dimensions.
   Number of active cells: 256
   Total number of cells: 341
   Number of degrees of freedom: 289
   26 CG iterations needed to obtain convergence.
Solving problem in 3 space dimensions.
   Number of active cells: 4096
   Total number of cells: 4681
   Number of degrees of freedom: 4913
   30 CG iterations needed to obtain convergence.
@endcode

很明显，在三个空间维度中，单元格的数量，因此也是自由度的数量要高得多。这里看不到的是，除了矩阵中更多的行和列之外，在三个空间维度中，矩阵的每一行也有明显更多的条目。这就导致了解方程组时需要付出更多的数值努力，当你实际运行程序时，你可以从两个求解步骤的运行时间中感受到这一点。




该程序产生两个文件。   <code>solution-2d.vtk</code> 和 <code>solution-3d.vtk</code> ，可以用VisIt或Paraview程序查看（如果你没有这些程序，你可以很容易地在程序中改变输出格式，使你更容易查看）。解决方案的可视化是一门艺术，但它也可以很有趣，所以你应该玩一玩你最喜欢的可视化工具，熟悉它的功能。下面是我想出的2D解决方案。

<p align="center">  <img src="https://www.dealii.org/images/steps/developer/step-4.solution-2d.png" alt="">   </p>  。

(  @dealiiVideoLectureSeeAlso{11,32})  图片显示了所考虑的问题的解决方案，是一个三维图。可以看出，该解在域的内部几乎是平的，而在边界附近有较高的曲率。当然，这是因为对于拉普拉斯方程来说，解的曲率等于右手边，而右手边被选为四次多项式，在内部几乎为零，只有在接近域的边界时才急剧上升；右手边函数的最大值在域的角落，在那里解的移动也最迅速。很高兴看到解沿着域的边界遵循理想的二次边界值。将计算出的解与分析出的解进行验证也是很有用的。关于这一技术的解释，请参见步骤7。

另一方面，尽管图片中没有明确显示网格线，但你可以看到它们在解决方案中的小疙瘩。这清楚地表明，解决方案还没有被计算到非常高的精度，为了得到更好的解决方案，我们可能必须在更细的网格上进行计算。

在三个空间维度上，可视化就比较困难了。左图显示了解决方案和它在域的表面上计算出来的网格。这很好，但它的缺点是完全掩盖了内部的情况。右图是通过显示解的恒定值的表面（如左上角的图例所示），试图将内部的情况也可视化。如果我们把各个表面弄得稍微透明一些，这样就有可能透过它们看到后面的东西，那么等值面图片看起来就最好了。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-4.solution-3d.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-4.contours-3d.png" alt="">
    </td>
  </tr>
</table> 

 @note  关于可视化的最后一句话：可视化的想法是给人以洞察力，这与显示信息是不同的。特别是，在一张图片上很容易显示过多的信息，但在显示更多的信息的同时，也使人们更难收集到洞察力。举个例子，我用来生成这些图片的程序，VisIt，默认情况下在每个轴上都有刻度线，在 $x$ 轴上贴上一个大胖标签 "X轴"，其他轴也是如此，在左上方显示提取数据的文件名，在右下方显示用户的名字以及时间和日期。这些在这里都不重要：轴同样容易辨认，因为左下方的三脚架仍然可见，而且我们从程序中知道域是 $[-1,1]^3$ ，所以不需要刻度线。因此，我关掉了图片中所有不相干的东西：可视化的艺术在于把图片缩减到那些对看清自己想看的东西很重要的部分，而不是其他。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>


基本上，玩这个程序的可能性与前一个程序相同，只是它们现在也适用于3D情况。为了获得灵感，请阅读<a href="step_3.html#extensions"
target="body">possible extensions in the documentation of step 3</a>。


examples/step-40/doc/intro.dox

 <br> 

<i>This program was contributed by Timo Heister, Martin Kronbichler and Wolfgang
Bangerth.
<br>
This material is based upon work partly supported by the National
Science Foundation under Award No. EAR-0426271 and The California Institute of
Technology. Any opinions, findings, and conclusions or recommendations
expressed in this publication are those of the author and do not
necessarily reflect the views of the National Science Foundation or of The
California Institute of Technology.
</i>




 @note  作为这个程序的前提条件，你需要同时安装PETSc和p4est库。在<a
href="../../readme.html" target="body">README</a>文件中描述了deal.II与这两个附加库的安装。还要注意的是，为了正常工作，本程序需要访问实现代数多网格的Hypre预处理程序包；它可以作为PETSc的一部分安装，但必须在配置PETSc时明确启用；参见PETSc安装说明中的链接页面。


<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{41.5,41.75} 

鉴于今天的计算机，大多数有限元计算可以在一台机器上完成。因此，以前的大多数教程程序只显示了这一点，可能是在一些处理器之间进行分工，但这些处理器都可以访问相同的共享内存空间。也就是说，有些问题对于单台机器来说实在是太大了，在这种情况下，必须以适当的方式将问题分割给多台机器，每台机器都为整体贡献自己的一部分。在第17步和第18步中展示了一个简单的方法，我们展示了一个程序如何使用<a
href="http://www.mpi-forum.org/" target="_top">MPI</a>来并行组装线性系统，存储它，解决它，并计算误差估计。所有这些操作的扩展都是相对微不足道的（关于操作 "扩展 "的定义，见 @ref GlossParallelScaling "本词汇表条目"），但是有一个明显的缺点：为了使这个实现适度简单，每个MPI处理器都必须保留自己的整个Triangulation和DoFHandler对象的副本。因此，虽然我们可以怀疑（有充分的理由）上面列出的操作可以扩展到成千上万的计算机和数十亿个单元和数十亿个自由度的问题规模，但在每一个最后的处理器上为这成千上万的计算机所解决的整个问题建立一个大的网格显然是不能扩展的：这将需要永远，也许更重要的是没有一台机器会有足够的内存来存储一个有十亿个单元的网格（至少在写这篇文章时没有）。在现实中，像第17步和第18步这样的程序不可能在超过100或200个处理器上运行，即使在那里，存储Triangulation和DoFHandler对象也会消耗每台机器上的绝大部分内存。

因此，我们需要以不同的方式来处理这个问题：为了扩展到非常大的问题，每个处理器只能存储自己的一小块三角形和DoFHandler对象。deal.II在 parallel::distributed 命名空间和其中的类中实现了这样一个方案。它建立在一个外部库上，<a
href="http://www.p4est.org/">p4est</a>（对表达式<i>parallel forest</i>的发挥，描述了将分层构造的网格作为四叉树或八叉树的森林进行并行存储）。你需要<a
href="../../external-libs/p4est.html">install and configure p4est</a>，但除此之外，它的所有工作原理都隐藏在deal.II的表面之下。

本质上， parallel::distributed::Triangulation 类和DoFHandler类中的代码所做的是分割全局网格，使每个处理器只存储其 "拥有 "的一小部分，以及围绕其拥有的单元的一层 "幽灵 "单元。在我们想要解决偏微分方程的领域的其余部分发生了什么，对每个处理器来说都是未知的，如果需要这些信息，只能通过与其他机器的交流来推断。这意味着我们还必须以不同于例如第17步和第18步的方式来思考问题：例如，没有一个处理器可以拥有用于后处理的整个解矢量，程序的每一部分都必须被并行化，因为没有一个处理器拥有顺序操作所需的所有信息。

在 @ref distributed 文档模块中描述了这种并行化如何发生的一般概述。在阅读本程序的源代码之前，你应该先阅读它，以获得一个顶层的概述。在 @ref distributed_paper "分布式计算论文 "中也提供了关于我们将在程序中使用的许多术语的简明讨论。也许值得一读，以了解本程序内部如何工作的背景信息。




<h3>The testcase</h3>

这个程序基本上重新解决了我们在步骤6中已经做的事情，即它解决了拉普拉斯方程

@f{align*}


  -\Delta u &= f \qquad &&\text{in}\ \Omega=[0,1]^2, \\
  u &= 0 \qquad &&\text{on}\ \partial\Omega.


@f}

当然不同的是，现在我们要在一个可能有十亿个单元，有十亿个左右自由度的网格上这样做。毫无疑问，对于这样一个简单的问题，这样做是完全愚蠢的，但毕竟一个教程程序的重点不是做一些有用的东西，而是展示如何使用deal.II来实现有用的程序。尽管如此，为了使事情至少有一点点有趣，我们选择右侧为一个不连续的函数。

@f{align*}
  f(x,y)
  =
  \left\{
  \begin{array}{ll}
    1 & \text{if}\ y > \frac 12 + \frac 14 \sin(4\pi x), \\


    -1 & \text{otherwise},
  \end{array}
  \right.


@f}

使得解沿着蜿蜒穿过域的正弦线有一个奇点。因此，网格的细化将集中在这条线上。你可以在下面结果部分的网格图中看到这一点。

与其在这里继续做冗长的介绍，不如让我们直接进入程序代码。如果你已经读完了步骤6和 @ref distributed 文档模块，大部分将要发生的事情你应该已经熟悉了。事实上，比较这两个程序，你会发现在%parallel中工作所需的额外努力几乎是微不足道的：这两个程序的代码行数差不多（尽管步骤6在处理系数和输出方面花费了更多的空间）。在任何情况下，下面的评论将只针对使step-40与step-6不同的事情，而且在 @ref distributed 文档模块中还没有涵盖。




 @note  这个程序将能够在你想扔给它的多少个处理器上进行计算，以及你有多少内存和耐心来解决多大的问题。然而，<i>is</i>有一个限制：未知数的数量不能超过可以用类型 types::global_dof_index. 的对象存储的最大数量。默认情况下，这是<code>unsigned int</code>的别名，在今天大多数机器上是一个32位的整数，限制了你大约40亿（实际上，由于这个程序使用PETSc，你将被限制在一半，因为PETSc使用有符号整数）。然而，这可以在配置过程中改变为使用64位整数，见ReadMe文件。这将使问题的大小在短期内不太可能超过。


examples/step-40/doc/results.dox



<h1>Results</h1>

当你在单个处理器上或在几个本地MPI安装上运行该程序时，你应该得到这样的输出。

@code
Cycle 0:
   Number of active cells:       1024
   Number of degrees of freedom: 4225
   Solved in 10 iterations.



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.176s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assembly                        |         1 |    0.0209s |        12% |
| output                          |         1 |    0.0189s |        11% |
| setup                           |         1 |    0.0299s |        17% |
| solve                           |         1 |    0.0419s |        24% |
+---------------------------------+-----------+------------+------------+



Cycle 1:
   Number of active cells:       1954
   Number of degrees of freedom: 8399
   Solved in 10 iterations.



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.327s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assembly                        |         1 |    0.0368s |        11% |
| output                          |         1 |    0.0208s |       6.4% |
| refine                          |         1 |     0.157s |        48% |
| setup                           |         1 |    0.0452s |        14% |
| solve                           |         1 |    0.0668s |        20% |
+---------------------------------+-----------+------------+------------+



Cycle 2:
   Number of active cells:       3664
   Number of degrees of freedom: 16183
   Solved in 11 iterations.


...
@endcode



确切的数字是不同的，这取决于我们使用多少个处理器；这是由于预处理程序取决于问题的分区，然后解决方案在最后几位上有所不同，因此，网格细化也略有不同。不过，这里最值得注意的是，迭代次数并不随问题的大小而增加。这保证了我们甚至可以有效地解决最大的问题。

当在足够多的机器上运行时（比如说几千台），这个程序可以相对容易地在不到一分钟的时间内解决有远超过10亿个未知数的问题。另一方面，这样的大问题已经不能被视觉化，所以我们也只在16个处理器上运行该程序。下面是一个网格，以及它在16个处理器上的划分，还有相应的解决方案。

 <table width="100%">
<tr>
<td>
  <img src="https://www.dealii.org/images/steps/developer/step-40.mesh.png" alt="">
</td>
<td>
  <img src="https://www.dealii.org/images/steps/developer/step-40.solution.png" alt="">
</td>
</tr>
</table> 

左边的网格仅有7,069个单元。当然，这个问题我们在单台处理器上使用step-6就已经很容易解决了，但是这个程序的重点是展示如何编写一个可以扩展到更多机器的程序。例如，这里有两张图，显示了如果我们采取越来越多的处理器，程序的大量部分的运行时间是如何在大约5200万和37500万自由度的问题上扩展的（这些和接下来的几张图取自 @ref distributed_paper "分布式计算论文 "的早期版本；显示在更大数量的处理器上运行数据的更新图，以及更多的解释可以在该论文的最终版本中找到）。

 <table width="100%">
<tr>
<td>
  <img src="https://www.dealii.org/images/steps/developer/step-40.strong2.png" alt="">
</td>
<td>
  <img src="https://www.dealii.org/images/steps/developer/step-40.strong.png" alt="">
</td>
</tr>
</table> 

可以清楚地看到，这个程序可以很好地扩展到非常多的处理器。关于我们认为的 "可扩展 "程序的讨论，见 @ref GlossParallelScaling "本词汇表条目"）。曲线，特别是线性求解器，在图形的右端变得有点摇摆不定，因为每个处理器要做的事情太少，无法抵消通信成本（在上面两个例子中，每个处理器要解决的整个问题的部分，在使用4,096个处理器时，只有13,000和90,000个自由度；一个好的经验法则是，如果每个处理器至少有100,000个未知数，并行程序就会运行良好）。

虽然上面的强扩展图显示，如果我们采取越来越多的处理器，我们可以越来越快地解决一个固定大小的问题，但更有趣的问题可能是，问题可以变得多大，以便在一个特定大小的机器上仍然可以在合理的时间内解决它们。我们在下面两张256和4096处理器的图中展示了这一点。

 <table width="100%">
<tr>
<td>
  <img src="https://www.dealii.org/images/steps/developer/step-40.256.png" alt="">
</td>
<td>
  <img src="https://www.dealii.org/images/steps/developer/step-40.4096.png" alt="">
</td>
</tr>
</table> 

这些图显示的是，程序的所有部分都随着自由度数的增加而线性扩展。这一次，由于局部问题的规模太小，线条在左边摇摆不定。关于这些结果的更多讨论，我们参考了 @ref distributed_paper "分布式计算论文"。

那么，一个人能够解决的最大问题是多大？在写这个问题的时候，限制因素是程序使用<a
href="http://acts.nersc.gov/hypre/" target="_top">Hypre package</a>中的BoomerAMG代数多网格方法作为预处理程序，不幸的是，它使用有符号的32位整数来索引%分布式矩阵的元素。这将问题的大小限制在 $2^{31}-1=2,147,483,647$ 个自由度。从上面的图中可以看出，可扩展性会超过这个数字，而且可以预期，给定超过上面显示的4096台机器也会进一步减少计算时间。也就是说，人们当然可以期待，这个限制最终会被hybre的开发者解除。

另一方面，这并不意味着deal.II不能解决更大的问题。事实上，step-37展示了如何解决不仅仅是一点点，而是大大超过我们在这里所展示的任何问题的问题。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

从某种意义上说，这个程序是拉普拉斯方程的终极解算器：只要你有足够的处理器，它基本上可以把方程解到你想要的精度。由于拉普拉斯方程本身在这种精度水平上并不十分有趣，因此，更有趣的扩展可能性不在于这个程序，而在于它之后的内容。例如，本教程中的其他几个程序都有相当长的运行时间，特别是在3D中。因此，使用这里解释的技术来扩展其他程序以支持并行的分布式计算将是有趣的。我们在step-32教程程序中对step-31做了这样的处理，但同样的做法也适用于，例如，用于双曲时间相关问题的step-23和step-25，用于气体动力学的step-33，或用于纳维-斯托克斯方程的step-35。

也许同样有趣的是后处理的问题。如上所述，我们只展示了16个处理器的解决方案和网格的图片，因为4,096个处理器解决10亿个未知数会产生几10G的图形输出。目前，除非在至少几百个处理器上运行，否则没有任何程序能够以任何合理的方式将如此大量的数据可视化。然而，有一些方法，可视化程序直接与每个处理器上的求解器进行通信，每个可视化进程渲染这个处理器上的求解器所计算的场景部分。实现这样的接口将允许快速可视化那些在其他方面不适合用图形显示的东西。


examples/step-41/doc/intro.dox

 <br> 

<i>This program was contributed by Jörg Frohne (University of Siegen,
Germany) while on a long-term visit to Texas A&amp;M University.
<br>
This material is based upon work partly supported by ThyssenKrupp Steel Europe.
</i>


<a name="Intro"></a>

<h3>Introduction</h3>

这个例子是基于二维的拉普拉斯方程，涉及的问题是，如果一个膜被一些外力偏转，但也被一个障碍物所限制，会发生什么。换句话说，想想一个弹性膜在边界处被夹在一个矩形框架上（我们选择 $\Omega =
\left[-1,1\right]^2$ ），由于重力作用而下垂。如果膜下有一个障碍物，阻止它达到平衡位置，如果重力是唯一存在的力，现在会发生什么？在目前的例子程序中，我们将考虑在膜下有一个楼梯的障碍物，重力推着膜。

这个问题通常被称为 "障碍问题"（也见<a
href="http://en.wikipedia.org/wiki/Obstacle_problem">this Wikipedia article</a>），它的结果是一个变分不等式，而不是变成弱形式的变分方程。下面我们将从经典的表述中推导出它，但在我们继续讨论数学问题之前，让我们展示一下我们在这个教程程序中要考虑的问题的解决方式，以获得一些我们应该期待的直觉。

 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.png" alt="">
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.png" alt="">
    </td>
  </tr>
</table> 

在这里，在左边，我们看到膜的位移。下面的障碍物的形状是清晰可见的。在右边，我们叠加了膜的哪些部分与障碍物接触。我们以后会把这组点称为 "活动集"，以表明这里有一个不等式约束在活动。




<h3>Classical formulation</h3>

该问题的经典表述具有以下形式。

@f{align*}


 -\textrm{div}\ \sigma &\geq f & &\quad\text{in } \Omega,\\
 \sigma &= \nabla u & &\quad\text{in } \Omega,\\
 u(\mathbf x) &= 0 & &\quad\text{on }\partial\Omega,\\
(-\Delta u - f)(u - g) &= 0 & &\quad\text{in } \Omega,\\
 u(\mathbf x) &\geq g(\mathbf x) & &\quad\text{in } \Omega


@f}

与 $u\in H^2(\Omega)$  。    $u$  是一个标量值函数，表示膜的垂直位移。第一个方程被称为平衡条件，有一个区域密度的力  $f$  。这里，我们将考虑这个力是重力。第二个方程被称为胡克定律，即应力 $\sigma$ 与位移 $u$ 的梯度成正比（比例常数，通常用 $E$ 表示，这里被设定为1，但不失一般性；如果它是常数，它可以被放入右边的函数）。在边界，我们有零迪里希特条件。很明显，前两个方程可以结合起来，得到 $-\Delta u \ge f$  。

直观地说，重力是向下作用的，所以 $f(\mathbf x)$ 是一个负函数（我们在这个程序中选择 $f=-10$ ）。那么，第一个条件意味着作用在膜上的总力是重力加上一些正值：即障碍物在它们两个接触的地方对膜施加的向上的力。这个额外的力有多大？我们还不知道（我们也不知道它实际作用的 "位置"），但它必须是使膜不穿透障碍物的。

上面的第四个等式和最后一个不等式构成了障碍条件，它必须在整个领域的每一点都成立。这两个条件中的后者意味着膜必须在任何地方都高于障碍物 $g(\mathbf x)$ 。倒数第二个方程，通常被称为 "互补条件"，说的是在膜不与障碍物接触的地方（即那些 $\mathbf x$ 的地方 $u(\mathbf x) - g(\mathbf x) \neq 0$ ），那么 $-\Delta u=f$ 在这些地方；换句话说，没有额外的力作用在那里，如预期的那样。另一方面，在 $u=g$ 的地方，我们可以有 $-\Delta u-f
\neq 0$ ，也就是说，可以有额外的力（尽管不一定要有：膜有可能只是接触而不是压住障碍物）。




<h3>Derivation of the variational inequality</h3>

获得障碍物问题的变量表述的一个明显方法是考虑总势能。

@f{equation*}
 E(u) \dealcoloneq \dfrac{1}{2}\int\limits_{\Omega} \nabla u \cdot \nabla u - \int\limits_{\Omega} fu.


@f}

我们必须找到以下最小化问题的解决方案 $u\in G$ 。

@f{equation*}
 E(u)\leq E(v)\quad \forall v\in G,


@f}

与可接受位移的凸集。

@f{equation*}
 G \dealcoloneq \lbrace v\in V: v\geq g \text{ a.e. in } \Omega\rbrace,\quad V\dealcoloneq H^1_0(\Omega).


@f}

这组数据照顾到了上述第三和第五个条件（边界值和互补条件）。

现在考虑 $E$ 的最小化器 $u\in G$ 和任何其他函数 $v\in
G$  。那么函数

@f{equation*}
 F(\varepsilon) \dealcoloneq E(u+\varepsilon(v-u)),\quad\varepsilon\in\left[0,1\right],


@f}

在 $\varepsilon = 0$ 处取最小值（因为 $u$ 是能量函数 $E(\cdot)$ 的最小值），因此，对于 $v$ 的任何选择， $F'(0)\geq 0$ 。请注意， $u+\varepsilon(v-u) = (1-\varepsilon)u+\varepsilon v\in G$  因为 $G$  的凸性。如果我们计算 $F'(\varepsilon)\vert_{\varepsilon=0}$ ，就可以得到我们要寻找的变异公式。

<i>Find a function $u\in G$ with</i>

@f{equation*}
 \left(\nabla u, \nabla(v-u)\right) \geq \left(f,v-u\right) \quad \forall v\in G.


@f}



这是变分不等式的典型形式，不仅仅是 $v$ 出现在双线性形式中，实际上还有 $v-u$  。原因是这样的：如果 $u$ 不受约束，那么我们可以在 $G$ 中找到测试函数 $v$ ，从而使 $v-u$ 可以有任何符号。通过选择测试函数 $v_1,v_2$ 使 $v_1-u = -(v_2-u)$ ，可以看出，只有当两边事实上相等时，不等式才能对 $v_1$ 和 $v_2$ 都成立，也就是说，我们得到一个变异的相等。

另一方面，如果 $u=g$ ，那么 $G$ 只允许测试函数 $v$ ，所以实际上 $v-u\ge 0$  。这意味着我们不能像上面那样用 $v-u$ 和 $-(v-u)$ 来测试这个方程，所以我们不能再得出两边实际上相等的结论。因此，这就模仿了我们上面讨论互补性条件的方式。




<h3>Formulation as a saddle point problem</h3>

上面的变分不等式在工作中是很尴尬的。因此，我们想把它重新表述为一个等价的鞍点问题。我们引入拉格朗日乘子 $\lambda$ 和拉格朗日乘子 $K\subset V'$ 、 $V'$ 的凸锥 $V$ 、 $K \dealcoloneq \{\mu\in V': \langle\mu,v\rangle\geq 0,\quad \forall
v\in V, v \le 0 \}$ 的对偶空间，其中 $\langle\cdot,\cdot\rangle$ 表示 $V'$ 和 $V$  之间的对偶性。直观地说， $K$ 是所有 "非正函数 "的锥体，除了 $K\subset (H_0^1)'$ ，所以也包含了除正函数之外的其他对象。这就产生了。

<i>Find $u\in V$ and $\lambda\in K$ such that</i>

@f{align*}
 a(u,v) + b(v,\lambda) &= f(v),\quad &&v\in V\\
 b(u,\mu - \lambda) &\leq \langle g,\mu - \lambda\rangle,\quad&&\mu\in K,


@f}

<i>with</i>

@f{align*}
 a(u,v) &\dealcoloneq \left(\nabla u, \nabla v\right),\quad &&u,v\in V\\
 b(u,\mu) &\dealcoloneq \langle u,\mu\rangle,\quad &&u\in V,\quad\mu\in V'.


@f}

换句话说，我们可以把 $\lambda$ 看作是障碍物对膜施加的额外正力的负数。上面陈述的第二行中的不等式似乎只有错误的符号，因为我们在 $\lambda=0$ 的地方有 $\mu-\lambda<0$ ，鉴于 $K$ 的定义。

Glowinski, Lions and Tr&eacute;moli&egrave;res.中阐述了这个鞍点问题 $(u,\lambda)\in V\times K$ 的存在性和唯一性。Numerical Analysis of Variational Inequalities, North-Holland, 1981.




<h3>Active Set methods to solve the saddle point problem</h3>

有不同的方法来解决变量不等式。作为一种可能性，你可以把鞍点问题理解为一个带有不等式约束的凸二次方程序（QP）。

为了达到这个目的，让我们假设我们用相同的有限元空间来离散 $u$ 和 $\lambda$ ，例如通常的 $Q_k$ 空间。然后我们会得到方程

@f{eqnarray*}
 &A U + B\Lambda = F,&\\
 &[BU-G]_i \geq 0, \quad \Lambda_i \leq 0,\quad \Lambda_i[BU-G]_i = 0
\qquad \forall i.&


@f}

其中 $B$ 是所选有限元空间上的质量矩阵，上面的指数 $i$ 是针对位于域内部的自由度集合 $\cal S$ 中的所有自由度（我们在周边有迪里希条件）。然而，如果我们在组合产生这个质量矩阵的所有项时使用一个特殊的正交规则，即一个正交公式，其中正交点只位于定义了形状函数的插值点；因为除了一个形状函数外，所有的形状函数在这些位置都是零，所以我们得到一个对角线质量矩阵，具有

@f{align*}
  B_{ii} = \int_\Omega \varphi_i(\mathbf x)^2\ \textrm{d}x,
  \qquad
  B_{ij}=0 \ \text{for } i\neq j.


@f}

为了定义 $G$ ，我们使用与 $B$ 相同的技术。换句话说，我们定义

@f{align*}
  G_{i} = \int_\Omega g_h(x) \varphi_i(\mathbf x)\ \textrm{d}x,


@f}

其中 $g_h$ 是 $g$ 的一个合适的近似值。然后， $B_{ii}$ 和 $G_i$ 定义中的积分由梯形规则近似。有了这个，上面的方程可以重述为

@f{eqnarray*}
 &A U + B\Lambda = F,&\\
 &U_i-B_{ii}^{-1}G_i \ge 0, \quad \Lambda_i \leq 0,\quad \Lambda_i[U_i-B_{ii}^{-1}G_i] = 0
\qquad \forall i\in{\cal S}.&


@f}



现在我们为每个自由度 $i$ 定义函数

@f{equation*}
 C([BU]_i,\Lambda_i) \dealcoloneq -\Lambda_i + \min\lbrace 0, \Lambda_i + c([BU]_i - G_i) \rbrace,


@f}

在这个程序中，我们选择 $c>0$ 。这是一种惩罚参数，取决于问题本身，需要选择足够大的参数；例如，如果我们使用7个全局细化，使用当前程序对 $c = 1$ 没有收敛作用）。)

经过一番挠头，人们可以说服自己，上面的不等式可以等效地改写为

@f{equation*}
 C([BU]_i,\Lambda_i) = 0, \qquad \forall i\in{\cal S}.


@f}

我们在这里将使用的原始-双重主动集策略是一个迭代方案，它基于这个条件来预测下一个主动集和非主动集 $\mathcal{A}_k$ 和 $\mathcal{F}_k$ （即那些指数 $i$ 的互补集，对于这些指数 $U_i$ 要么等于要么不等于障碍物的值 $B^{-1}G$  ）。关于这种方法的更深入的处理，见Hintermueller, Ito, Kunisch:The primal-dual active set strategy as a semismooth newton method, SIAM J. OPTIM., 2003, Vol.13, No.3, pp.865-888.

<h3>The primal-dual active set algorithm</h3>

初级-二级主动集方法的算法工作原理如下（注： $B = B^T$  ）。

1.初始化  $\mathcal{A}_k$  和  $\mathcal{F}_k$  ，使  $\mathcal{S}=\mathcal{A}_k\cup\mathcal{F}_k$  和  $\mathcal{A}_k\cap\mathcal{F}_k=\emptyset$  并设置  $k=1$  。2.找出满足@f{align*}
  AU^k + B\Lambda^k &= F,\\
  [BU^k]_i &= G_i\quad&&\forall i\in\mathcal{A}_k,\\
  \Lambda_i^k &= 0\quad&&\forall i\in\mathcal{F}_k.
 @f}的原始-双数对 $(U^k,\Lambda^k)$ 。

请注意，第二个和第三个条件意味着正好 $|S|$ 个未知数是固定的，第一个条件产生了确定 $U$ 和 $\Lambda$ 所需的剩余 $|S|$ 个方程。3.3. 用@f{equation*}
 \begin{split}
  \mathcal{A}_{k+1} \dealcoloneq \lbrace i\in\mathcal{S}:\Lambda^k_i + c([BU^k]_i - G_i)< 0\rbrace,\\
  \mathcal{F}_{k+1} \dealcoloneq \lbrace i\in\mathcal{S}:\Lambda^k_i + c([BU^k]_i - G_i)\geq 0\rbrace.
 \end{split}
 @f}定义新的活动和非活动集。

如果 $\mathcal{A}_{k+1}=\mathcal{A}_k$ （然后，显然也是 $\mathcal{F}_{k+1}=\mathcal{F}_k$ ），则停止，否则设置 $k=k+1$ 并转到步骤（2）。

该方法被称为 "原始-双重"，因为它同时使用原始变量（位移 $U$ ）以及双重变量（拉格朗日乘数 $\Lambda$ ）来确定下一个活动集。

在本节的最后，让我们补充两点意见。首先，对于任何满足这些条件的原始-双重对 $(U^k,\Lambda^k)$ ，我们可以区分以下几种情况。

1.   $\Lambda^k_i + c([BU^k]_i - G_i) < 0$  (i active)。     <br>  然后是 $[BU^k]_i<G_i$ 和 $\Lambda^k_i=0$ （渗透）或 $\Lambda^k_i<0$ 和 $[BU^k]_i=G_i$ （压载）。2.   $\Lambda^k_i + c([BU^k]_i - G_i)\geq 0$  (i不活动)。     <br>  然后是 $[BU^k]_i\geq G_i$ 和 $\Lambda^k_i=0$ （无接触）或 $\Lambda^k_i\geq0$ 和 $[BU^k]_i=G_i$ （无压迫负荷）。

第二，上面的方法在直觉上似乎是正确的，也是有用的，但有点临时性的。然而，它可以通过以下方式简明地推导出来。为此，请注意，我们要解决的是非线性系统

@f{eqnarray*}
 &A U + B\Lambda = F,&\\
 &C([BU-G]_i, \Lambda_i) = 0,
\qquad \forall i.&


@f}

我们可以通过始终围绕前一个迭代进行线性化（即应用牛顿方法）来迭代解决，但为此我们需要对不可微分的函数 $C(\cdot,\cdot)$ 进行线性化。也就是说，它是可微的，事实上我们有

@f{equation*}
 \dfrac{\partial}{\partial U^k_i}C([BU^k]_i,\Lambda^k_i) = \begin{cases}
                                   cB_{ii},& \text{if}\ \Lambda^k_i + c([BU^k]_i - G_i)< 0\\
                                   0,& \text{if}\ \Lambda^k_i + c([BU^k]_i - G_i)\geq 0.
                                  \end{cases}


@f}



@f{equation*}
 \dfrac{\partial}{\partial\Lambda^k_i}C([BU^k]_i,\Lambda^k_i) = \begin{cases}
                                   0,& \text{if}\ \Lambda^k_i + c([BU^k]_i - G_i)< 0\\


                                   -1,& \text{if}\ \Lambda^k_i + c([BU^k]_i - G_i)\geq 0.
                                  \end{cases}


@f}

这表明一个半光滑的牛顿步骤，其形式为

@f{equation*}
 \begin{pmatrix}
 A_{\mathcal{F}_k\mathcal{F}_k} & A_{\mathcal{F}_k\mathcal{A}_k} & B_{\mathcal{F}_k} & 0\\
 A_{\mathcal{A}_k\mathcal{F}_k} & A_{\mathcal{A}_k\mathcal{A}_k} & 0 & B_{\mathcal{A}_k}\\
 0 & 0 & -Id_{\mathcal{F}_k} & 0\\
 0 & cB_{\mathcal{A}_k} & 0 & 0
\end{pmatrix}
\begin{pmatrix}
 \delta U^k_{\mathcal{F}_k}\\ \delta U^k_{\mathcal{A}_k}\\ \delta \Lambda^k_{\mathcal{F}_k}\\ \delta \Lambda^k_{\mathcal{A}_k}
\end{pmatrix}
=


-\begin{pmatrix}
 (AU^k + \Lambda^k - F)_{\mathcal{F}_k}\\ (AU^k + \Lambda^k - F)_{\mathcal{A}_k}\\ -\Lambda^k_{\mathcal{F}_k}\\ c(B_{\mathcal{A}_k} U^k - G)_{\mathcal{A}_k}
\end{pmatrix},


@f}

其中，我们将矩阵  $A,B$  以及向量以自然的方式分成行和列，其索引属于活动集  ${\mathcal{A}_k}$  或非活动集  ${\mathcal{F}_k}$  。

我们也可以通过设置 $\delta U^k \dealcoloneq
U^{k+1} - U^k$ 和 $\delta \Lambda^k \dealcoloneq \Lambda^{k+1} - \Lambda^k$ 并将所有已知项带到右手边来解决我们感兴趣的变量，而不是求解更新 $\delta U, \delta \Lambda$  。这就得到了

@f{equation*}
\begin{pmatrix}
 A_{\mathcal{F}_k\mathcal{F}_k} & A_{\mathcal{F}_k\mathcal{A}_k} & B_{\mathcal{F}_k} & 0\\
 A_{\mathcal{A}_k\mathcal{F}_k} & A_{\mathcal{A}_k\mathcal{A}_k} & 0 & B_{\mathcal{A}_k}\\
 0 & 0 & Id_{\mathcal{F}_k} & 0\\
 0 & B_{\mathcal{A}_k} & 0 & 0
\end{pmatrix}
\begin{pmatrix}
 U^k_{\mathcal{F}_k}\\ U^k_{\mathcal{A}_k}\\ \Lambda^k_{\mathcal{F}_k}\\ \Lambda^k_{\mathcal{A}_k}
\end{pmatrix}
=
\begin{pmatrix}
 F_{\mathcal{F}_k}\\ F_{\mathcal{A}_k}\\ 0\\ G_{\mathcal{A}_k}
\end{pmatrix}.


@f}

这些是上文描述基本算法时概述的方程式。

我们甚至可以进一步推动这一点。很容易看出，我们可以消除第三行和第三列，因为它意味着 $\Lambda_{\mathcal{F}_k} = 0$  。

@f{equation*}
\begin{pmatrix}
 A_{\mathcal{F}_k\mathcal{F}_k} & A_{\mathcal{F}_k\mathcal{A}_k} & 0\\
 A_{\mathcal{A}_k\mathcal{F}_k} & A_{\mathcal{A}_k\mathcal{A}_k} & B_{\mathcal{A}_k}\\
 0 & B_{\mathcal{A}_k} & 0
\end{pmatrix}
\begin{pmatrix}
 U^k_{\mathcal{F}_k}\\ U^k_{\mathcal{A}_k}\\ \Lambda^k_{\mathcal{A}_k}
\end{pmatrix}
=
\begin{pmatrix}
 F_{\mathcal{F}_k}\\ F_{\mathcal{A}_k}\\ G_{\mathcal{A}_k}
\end{pmatrix}.


@f}

这表明，事实上我们只需要解决位于活动集上的拉格朗日乘数。通过考虑第二行，我们将通过以下方式恢复全部拉格朗日乘数向量

@f{equation*}
 \Lambda^k_S = B^{-1}\left(f_{\mathcal{S}} - A_{\mathcal{S}}U^k_{\mathcal{S}}\right).


@f}

由于第三行和 $B_{\mathcal{A}_k}$ 是一个对角线矩阵的事实，我们能够直接计算出 $U^k_{\mathcal{A}_k}=B^{-1}_{\mathcal{A}_k}G_{\mathcal{A}_k}$ 。因此，我们也可以把线性系统写成如下。

@f{equation*}
\begin{pmatrix}
 A_{\mathcal{F}_k\mathcal{F}_k} & 0\\
 0 & Id_{\mathcal{A}_k} \\
\end{pmatrix}
\begin{pmatrix}
 U^k_{\mathcal{F}_k}\\ U^k_{\mathcal{A}_k}
\end{pmatrix}
=
\begin{pmatrix}
 F_{\mathcal{F}_k} - A_{\mathcal{F}_k\mathcal{A}_k}B^{-1}_{\mathcal{A}_k}G_{\mathcal{A}_k}
 \\
 B_{\mathcal{A}_k}^{-1}G_{\mathcal{A}_k}
\end{pmatrix}.


@f}

幸运的是，这种形式很容易得出：我们只需建立通常的拉普拉斯线性系统即可

@f{equation*}
\begin{pmatrix}
 A_{\mathcal{F}_k\mathcal{F}_k} & A_{\mathcal{F}_k\mathcal{A}_k} \\
 A_{\mathcal{A}_k\mathcal{F}_k} & A_{\mathcal{A}_k\mathcal{A}_k}
\end{pmatrix}
\begin{pmatrix}
 U^k_{\mathcal{F}_k}\\ U^k_{\mathcal{A}_k}
\end{pmatrix}
=
\begin{pmatrix}
 F_{\mathcal{F}_k}\\ F_{\mathcal{A}_k}
\end{pmatrix},


@f}

然后让AffineConstraints类消除所有受限自由度，即 $U^k_{\mathcal{A}_k}=B^{-1}_{\mathcal{A}_k}G_{\mathcal{A}_k}$ ，其方式与 $\mathcal{A}_k$ 中的自由度是Dirichlet数据一样。结果线性系统（上面的第二个到最后一个）是对称和正定的，我们用CG方法和Trilinos的AMG预处理程序来解决它。




<h3>Implementation</h3>

本教程与第4步很相似。程序的总体结构遵循步骤4，但略有不同。

- 我们需要两个新的方法，  <code>assemble_mass_matrix_diagonal</code>  和  <code>update_solution_and_constraints</code>  。

- 我们需要新的成员变量来表示我们这里的约束。

- 我们改变求解器的预处理程序。


如果你想了解目前的计划，你可能想阅读一下步骤4。


examples/step-41/doc/results.dox



<h1>Results</h1>

运行该程序会产生这样的输出。

@code
Number of active cells: 16384
Total number of cells: 21845
Number of degrees of freedom: 16641


Newton iteration 0
   Assembling system...
   Solving system...
      Error: 0.310059 -> 5.16619e-05 in 5 CG iterations.
   Updating active set...
      Size of active set: 13164
   Residual of the non-contact part of the system: 1.61863e-05
   Writing graphical output...


Newton iteration 1
   Assembling system...
   Solving system...
      Error: 1.11987 -> 0.00109377 in 6 CG iterations.
   Updating active set...
      Size of active set: 12363
   Residual of the non-contact part of the system: 3.9373
   Writing graphical output...


...


Newton iteration 17
   Assembling system...
   Solving system...
      Error: 0.00713308 -> 2.29249e-06 in 4 CG iterations.
   Updating active set...
      Size of active set: 5399
   Residual of the non-contact part of the system: 0.000957525
   Writing graphical output...


Newton iteration 18
   Assembling system...
   Solving system...
      Error: 0.000957525 -> 2.8033e-07 in 4 CG iterations.
   Updating active set...
      Size of active set: 5399
   Residual of the non-contact part of the system: 2.8033e-07
   Writing graphical output...
@endcode



一旦活动集不再变化，迭代就会结束（此时它有5399个受限自由度）。代数前提条件显然工作得很好，因为我们只需要4-6次CG迭代来解决线性系统（尽管这也与我们对线性求解器的精度要求不高有很大关系）。

更具启示性的是看一连串的图形输出文件（每三步显示一次，最左边一栏是迭代的编号）。

 <table align="center">
  <tr>
    <td valign="top">
      0 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.00.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.00.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.3d.00.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      3 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.03.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.03.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.3d.03.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      6 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.06.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.06.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.3d.06.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      9 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.09.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.09.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.3d.09.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      12 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.12.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.12.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.3d.12.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      15 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.15.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.15.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.3d.15.png" alt="">
    </td>
  </tr>
  <tr>
    <td valign="top">
      18 &nbsp;
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.18.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.active-set.18.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.displacement.3d.18.png" alt="">
    </td>
  </tr>
</table> 

图片显示，在第一步中，解决方案（在没有任何约束条件的情况下被计算出来的）是如此的弯曲，以至于几乎每一个内部点都必须被反弹到阶梯函数上，产生一个不连续的解决方案。在活动集迭代的过程中，这种不切实际的膜的形状被平滑掉了，与最下层阶梯的接触消失了，解决方案也稳定下来。

除此以外，程序还输出拉格朗日乘数的值。请记住，这些是接触力，所以在接触集上只应该是正的，而在接触集之外是零。另一方面，如果一个拉格朗日乘数在活动集上是负的，那么这个自由度必须从活动集上删除。下面的图片显示了迭代1、9和18中的乘数，我们用红色和棕色表示正值，蓝色表示负值。

 <table align="center">
  <tr>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.forces.01.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.forces.09.png" alt="">
    </td>
    <td valign="top">
      <img src="https://www.dealii.org/images/steps/developer/step-41.forces.18.png" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      Iteration 1
    </td>
    <td align="center">
      Iteration 9
    </td>
    <td align="center">
      Iteration 18
    </td>
  </tr>
</table> 

很容易看出，正值在接触集的内部很好地收敛为适度的值，在台阶的边缘有很大的向上的力，正如人们所期望的那样（以支持那里的膜的大曲率）；在活动集的边缘，乘数最初是负的，导致集合缩小，直到在迭代18，不再有负的乘数，算法已经收敛了。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

与本教程的任何程序一样，有许多明显的扩展和实验的可能性。第一个很清楚：引入自适应性。接触问题是自适应网格的主要候选者，因为解决方案有沿着它不太规则的线（膜和障碍物之间建立接触的地方）和解决方案非常光滑的其他区域（或者，在目前的情况下，在它与障碍物接触的地方是恒定的）。在目前的程序中加入这一点应该不会造成太多困难，但要为此找到一个好的误差估计器并非易事。

一个更具挑战性的任务是扩展到3D。这里的问题不是简单地让一切都在三维中运行。相反，当一个三维物体变形并与一个障碍物接触时，障碍物并不像这里的情况那样在域内作为一个约束体的力量发挥作用。相反，接触力只作用于物体的边界。那么不等式就不在微分方程中，而实际上在（诺伊曼型）边界条件中，尽管这导致了一种类似的变分不等式。在数学上，这意味着拉格朗日乘数只存在于表面，当然，如果方便的话，它也可以通过零扩展到域中。在目前的程序中，人们不需要明确地形成和存储这个拉格朗日乘数。

对于三维案例来说，另一个有趣的问题是考虑有摩擦的接触问题。在几乎每个机械过程中，摩擦都有很大的影响。为了建模，我们必须考虑到接触面的切向应力。我们还必须注意到，摩擦给我们的问题增加了另一个非线性。

另一个不简单的修改是实现一个更复杂的构成法则，如非线性弹性或弹塑性材料行为。这里的困难在于如何处理通过非线性构成法产生的额外非线性。


examples/step-42/doc/intro.dox

 <br> 

<i>This program was contributed by Jörg Frohne (University of Siegen,
Germany) while on a long-term visit to Texas A&amp;M University, with significant
contributions by Timo Heister and Wolfgang Bangerth.
<br>
<br>
The code described here provides the basis for the numerical experiments shown
in the following paper:
<br>
  J. Frohne, T. Heister, W. Bangerth: <b>Efficient numerical methods for the large-scale, parallel
                  solution of elastoplastic contact problems</b><b>Efficient numerical methods for the large-scale, parallel
                  solution of elastoplastic contact problems</b>.
  Accepted for publication in International Journal for Numerical Methods in Engineering, 2015.
</i> 。




<a name="Intro"></a>

<h3>Introduction</h3>

这个例子是第41步的延伸，考虑的是三维接触问题，具有各向同性硬化的弹塑性材料行为。换句话说，它考虑的是，如果把一个刚性的障碍物推到一个三维体上，它是如何变形的（接触问题），其中的变形受弹塑性材料法则（一种只能容纳一定最大应力的材料）的制约，随着变形的累积，该材料会硬化。为了说明我们打算做什么，在讨论太多细节之前，让我们只展示一张解决方案的图片（可变形体是一个立方体--实际上只显示了一半--，障碍物对应于一个汉字，将在下面讨论）。

 <img src="https://www.dealii.org/images/steps/developer/step-42.CellConstitutionLi2.png" alt=""> 


这个问题的描述意味着，与第41步相比，我们必须照顾到一个额外的非线性因素：材料行为。由于我们在这里考虑的是一个三维问题，我们还必须考虑到一个事实，即现在接触区是在可变形体的边界，而不是在内部。最后，与第41步相比，我们还必须在处理线性系统和不等式约束时处理悬空节点，因为我们希望使用自适应网格；在后一种情况下，我们将不得不处理优先考虑悬空节点的约束还是不等式的约束更重要。

由于在三维空间中很容易达到几百万个自由度，即使使用自适应网格细化，我们决定使用Trilinos和p4est来并行运行我们的代码，在步骤40的框架上进行并行化。并行化的其他指针可以在步骤32中找到。




<h3>Classical formulation</h3>

该问题的经典表述具有以下形式。

@f{align*}
 \varepsilon(\mathbf u) &= A\sigma + \varepsilon^p & &\quad\text{in } \Omega,\\


  -\textrm{div}\ \sigma &= \mathbf f & &\quad\text{in } \Omega,\\
  \varepsilon^p:(\tau - \sigma) &\geq 0\quad\forall\tau\text{ with
  }\mathcal{F}(\tau)\leq 0 & &\quad\text{in } \Omega,\\
  \mathbf u &= 0 & &\quad\text{on }\Gamma_D,\\
  \sigma \mathbf n - [\mathbf n \cdot(\sigma \mathbf n)]\mathbf n &= 0,
  \quad \mathbf n \cdot (\sigma
  \mathbf n) \leq 0 & &\quad\text{on }\Gamma_C,\\
  (\mathbf n \cdot (\sigma
  \mathbf n))(\mathbf n \cdot \mathbf u - g) &= 0,\quad \mathbf n
  \cdot \mathbf u - g \leq 0 & &\quad\text{on } \Gamma_C.


@f}

这里，这些方程的第一个定义了应变 $\varepsilon(\mathbf u)=\frac{1}{2}\left(\nabla \mathbf u
  + \nabla \mathbf u^T\right)$ 和应力 $\sigma$ 之间的关系，通过四阶顺应性张量 $A$ ； $\varepsilon^p$ 提供了应变的塑性成分，确保应力不超过屈服应力。我们将只考虑各向同性的材料，对于这些材料， $A$ 可以用Lam&eacute;模量 $\lambda$ 和 $\mu$ 表示，或者用体模量 $\kappa$ 和 $\mu$ 表示。第二个方程是力的平衡；我们在此不考虑任何体力，并假定 $\mathbf f=0$  。第三行的互补条件意味着，如果 $\mathcal{F}(\sigma)< 0$ ，则 $\varepsilon^p=0$ ，但当且仅当 $\mathcal{F}(\sigma) = 0$ ， $\varepsilon^p$ 可能是一个非零张量，特别是在这种情况下， $\varepsilon^p$ 必须指向 $\partial
\mathcal{F}(\sigma)/\partial \sigma$ 的方向。不等式 $\mathcal{F}(\sigma)\le 0$ 是塑性材料只能支持有限的应力；换句话说，如果外力会导致 $\sigma$ 的应力，那么它们就会产生塑性变形 $\varepsilon^p$ 的反应。这种<i>yield function</i>的典型形式是 $\mathcal{F}(\sigma)=|\sigma^D|-\sigma_{\text{yield}}$ ，其中 $\tau^D
= \tau - \dfrac{1}{3}tr(\tau)I$ 是张量的偏离部分， $|\cdot|$ 表示弗罗本尼斯规范。

进一步的方程描述了 $\Gamma_D$ 上固定的零位移，在可能出现接触的表面 $\Gamma_C=\partial\Omega\backslash\Gamma_D$ 上，障碍物施加的法向力 $\sigma_n=\mathbf n \cdot (\sigma(\mathbf u)
  \mathbf n)$ 是向内的（障碍物对我们的身体没有 "拉力"），切向分量为零 $\mathbf \sigma_t= \sigma \mathbf n - \mathbf \sigma_n \mathbf n
= \sigma \mathbf n - [\mathbf n \cdot(\sigma \mathbf n)]\mathbf n$  。最后一个条件又是一个互补条件，意味着在 $\Gamma_C$ 上，只有当身体与障碍物接触时，法向力才能非零；第二部分描述了障碍物和身体的不可穿透性。最后两个方程通常被称为Signorini接触条件。

大多数材料--尤其是金属--都有这样的特性，即它们在变形时表现出一定的硬化。换句话说， $\sigma_{\text{yield}}$ 随着变形而增加。在实践中，导致硬化的不是弹性变形，而是塑性成分。有不同的构成法则来描述这些材料行为。最简单的称为线性各向同性硬化，由流动函数  $\mathcal{F}(\sigma,\varepsilon^p) = \vert\sigma^D\vert - (\sigma_0 +
\gamma^{\text{iso}}|\varepsilon^p|)$  描述。




<h3>Reformulation as a variational inequality</h3>

一般来说，处理不等式是相当笨拙的。在这里，我们必须处理两个问题：塑性和接触问题。正如本页顶部提到的论文中详细描述的那样，我们至少可以重新表述塑性，使其看起来像一个非线性，然后我们可以用牛顿方法处理。这在数学上略显棘手，因为非线性不只是一些平滑的函数，而是在应力达到屈服应力的地方有结点；然而，对于这样的<i>semismooth</i>函数，可以证明牛顿方法仍然收敛。

在不涉及细节的情况下，我们也将摆脱作为独立变量的应力，而完全用位移来工作  $\mathbf u$  。最终，这种重构的目标是，我们希望最终得到一个对称的、正定的问题--比如一个线性化的弹性问题，其空间变量系数由塑性行为产生--需要在每个牛顿步骤中解决。我们希望如此，因为有高效和可扩展的方法来解决这样的线性系统，如用代数多重网格的CG预处理。这与我们继续使用包含位移和应力的混合公式所得到的类似于混合拉普拉斯的鞍点问题（见第20步）是相反的，第20步已经提示了构建良好的求解器和预处理器是多么困难。

说到这里，让我们简单陈述一下我们在重构后得到的问题（同样，细节可以在论文中找到）。找到一个位移 $\mathbf u \in
V^+$ ，以便

@f{align*}
\left(P_{\Pi}(C\varepsilon(\mathbf u)),\varepsilon(\varphi) - \varepsilon(\mathbf u)\right) \geq 0,\quad \forall \varphi\in V^+.


@f}

其中投影仪 $P_\Pi$ 被定义为

@f{align*}
 P_{\Pi}(\tau) \dealcoloneq \begin{cases}
    \tau, & \text{if }\vert\tau^D\vert \leq \sigma_0,\\
    \left[
      \dfrac{\gamma^{\text{iso}}}{2\mu + \gamma^{\text{iso}}} +
      \left(1-\dfrac{\gamma^{\text{iso}}}{2\mu + \gamma^{\text{iso}}}\right)\dfrac{\sigma_0}{\vert\tau^D\vert}
    \right]\tau^D
    + \dfrac{1}{3}\text{trace}(\tau) I, & \text{if }\vert\tau^D\vert >
    \sigma_0,
  \end{cases}


@f}

和空间 $V^+$ 是满足接触条件的所有位移的空间。

@f{align*}
  V
  &=
  \left\{ \mathbf u\in \left[H^1(\Omega)\right]^{d}:
    \mathbf u = 0 \text{ on } \Gamma_D\right\},
  \\
  V^+
  &=
  \left\{ \mathbf u\in V: \mathbf n \cdot \mathbf u\leq g \text{ on } \Gamma_C \right\}.


@f}



在实际代码中，我们将使用缩写  $\gamma=\dfrac{\gamma^{\text{iso}}}{2\mu + \gamma^{\text{iso}}}$  。

鉴于这种表述，我们将应用两种技术。

- 运行牛顿方法来迭代出投影仪的非线性。

- 为接触条件运行一个主动设置方法，方法与我们在步骤41中所做的基本相同。

一个严格的方法是在我们迭代牛顿方法到收敛时保持活动集的固定（或者也许反过来：在进入下一个牛顿迭代之前找到最终的活动集）。在实践中，事实证明，每个活动集迭代只做一个牛顿步骤就足够了，所以我们将同时迭代它们。我们还将每隔一段时间细化一下网格。




<h3>A Newton method for the plastic nonlinearity</h3>

如前所述，我们将通过应用牛顿方法来处理算子 $P_\Pi$ 的非线性，尽管该算子在严格意义上是不可微的。然而，它满足了<i>slant</i>的可微条件，这就足以使牛顿方法发挥作用。由此产生的方法被称为<i>semi-smooth Newton method</i>，听起来令人印象深刻，但实际上只是一个牛顿方法应用于一个具有适当选择的 "导数 "的半光滑函数。

在目前的情况下，我们将通过在每个迭代 $i$ 中求解以下方程来运行我们的迭代（仍然是不等式，但是线性化）。

@f{align*}
  \label{eq:linearization}
  \left(I_{\Pi}\varepsilon(\tilde {\mathbf u}^{i}),
    \varepsilon(\varphi) - \varepsilon(\tilde {\mathbf u}^{i})\right) \geq
  \left(\left(I_{\Pi}\varepsilon({\mathbf u}^{i-1}),
    \varepsilon(\varphi) - \varepsilon(\tilde {\mathbf u}^{i})\right) -
  \left(P_{\Pi}(C\varepsilon({\mathbf u}^{i-1})),
    \varepsilon(\varphi) - \varepsilon(\tilde {\mathbf u}^{i})\right)\right),
  \quad \forall \varphi\in V^+,


@f}

其中，等级4张量 $I_\Pi=I_\Pi(\varepsilon^D(\mathbf u^{i-1}))$ 由以下公式给出

@f{align}
  I_\Pi = \begin{cases}
    C_{\mu} + C_{\kappa}, & \hspace{-8em} \text{if } \vert C\varepsilon^D(\mathbf u^{i-1}) \vert \leq \sigma_0,
    \\
    \frac{\gamma^{\text{iso}}}{2\mu + \gamma^{\text{iso}}} C_{\mu} + \frac{\left(1-\frac{\gamma^{\text{iso}}}{2\mu + \gamma^{\text{iso}}}\right)\sigma_0}{\vert C\varepsilon^D(\mathbf u^{i-1}) \vert}\left(C_{\mu} -
      2\mu\dfrac{C\varepsilon^D(\mathbf u^{i-1})\otimes C\varepsilon^D(\mathbf
        u^{i-1})}{\vert C\varepsilon^D(\mathbf u^{i-1})\vert^2}\right) + C_{\kappa}, & \text{ else.}
\end{cases}


@f}

这个张量是 $P_\Pi(C\cdot)$ 围绕 $\varepsilon^D(\mathbf u^{i-1})$ 的（形式）线性化。对于我们这里考虑的线性各向同性材料，投影仪的体积和剪切分量由以下公式给出

@f{gather*}
  C_{\kappa} = \kappa I\otimes I,
  \qquad\qquad\qquad\qquad
  C_{\mu} = 2\mu\left(\mathbb{I}  - \dfrac{1}{3} I\otimes
    I\right),


@f}

其中 $I$ 和 $\mathbb{I}$ 分别是等级为2和4的认同张量。

请注意，这个问题对应于线性弹性接触问题，其中 $I_\Pi$ 扮演弹性张量的角色  $C=A^{-1}$  。事实上，如果材料在某一点上没有塑性，那么 $I_\Pi=C$  。然而，在材料具有塑性的地方， $I_\Pi$ 是一个空间变化的函数。在任何情况下，我们必须解决牛顿迭代的系统 $\tilde {\mathbf u}^{i}$ 使我们更接近重写我们问题的目标，使我们能够使用众所周知的椭圆系统的求解器和预处理器。

作为对牛顿方法的最后说明，让我们提一下，正如牛顿方法常见的那样，我们需要通过控制步长来使其全球化。换句话说，虽然上面的系统求解的是 $\tilde {\mathbf u}^{i}$ ，但最后的迭代结果将是

@f{align*}
  {\mathbf u}^{i} = {\mathbf u}^{i-1} + \alpha_i (\tilde {\mathbf u}^{i} - {\mathbf u}^{i-1})


@f}

其中右边括号中的差值扮演了传统牛顿方向的角色， $\delta {\mathbf u}^{i}$  。我们将用标准的直线搜索来确定 $\alpha^i$ 。




<h3>Active Set methods to solve the saddle point problem</h3>

这个要在每个牛顿步骤中解决的线性化问题基本上与步骤41一样。唯一的区别在于接触区是在边界而不是在域中。但这没有进一步的后果，所以我们参考步骤41的文件，唯一的提示是 $\mathcal{S}$ 这次包含了接触边界的所有顶点 $\Gamma_C$ 。和那里一样，我们需要做的是保持一个自由度子集的固定，导致额外的约束，可以写成一个鞍点问题。然而，正如论文中所讨论的，通过以适当的方式写这些约束，消除自由度之间的耦合，我们最终会得到一组节点，这些节点基本上只是附加了Dirichlet值。




<h3>Overall algorithm</h3>

上述算法结合了阻尼半光滑牛顿法（我们用于非线性构成法）和半光滑牛顿法用于接触。它的工作原理如下。<ol>  <li>  初始化活动和非活动集 $\mathcal{A}_i$ 和 $\mathcal{F}_i$ ，使 $\mathcal{S} = \mathcal{A}_i \cup \mathcal{F}_i$ 和 $\mathcal{A}_i \cap
 \mathcal{F}_i = \emptyset$ 和集 $i = 1$  。这里， $\mathcal{S}$ 是位于可能发生接触的域的表面的所有自由度的集合。  起始值 $\hat U^0 \dealcoloneq
 P_{\mathcal{A}_k}(0)$ 满足我们的障碍条件，也就是说，我们将初始零位移投射到可行位移集合上。

   <li>  组装牛顿矩阵  $A_{pq} \dealcoloneq a'(
 U^{i-1};\varphi_p,\varphi_q)$  和右侧  $F(\hat U^{i-1})$  。  这些对应于线性化的牛顿步骤，暂时忽略了接触不等式。

   <li>  找到满足@f{align*}
 A\tilde U^i + B\Lambda^i & = F, &\\
 \left[B^T\tilde U^i\right]_p & = G_p & \forall p\in\mathcal{A}_i,\\
 \Lambda^i_p & = 0 & \forall p\in\mathcal{F}_i.
 @f}的原始-双数对 $(\tilde U^i,\Lambda^i)$  。

如同步骤-41，我们可以通过消除第一个方程中 ${\cal A}_i$ 的那些自由度来获得这个问题的解决方案，并获得一个线性系统 $\hat {\hat A}(U^{i-1}) \tilde U^i = \hat {\hat H}(U^{i-1})$  。




   <li>  通过应用直线搜索和计算 $U^{i-1}$ 和 $\tilde U^i$ 的线性组合来减弱 $i>2$ 的牛顿迭代。这需要找到一个 $\alpha^i_l \dealcoloneq 2^{-l},(l=0,\ldots,10)$ ，以便@f{gather*}U^i \dealcoloneq \alpha^i_l\bar U^i +
 (1-\alpha^i_l)U^{i-1}@f}。

满足@f{gather*}
   \vert {\hat R}\left({\mathbf u}^{i}\right) \vert < \vert {\hat R}\left({\mathbf u}^{i-1}\right) \vert.
 \f}与 ${\hat R}\left({\mathbf u}\right)=\left(P_{Pi}(C\varepsilon(u)),\varepsilon(\varphi^{i}_p\right)$ ，除了(i)元素 $p\in\mathcal{A}_i$ ，我们设置 ${\hat R}\left({\mathbf u}\right)=0$ ，和(ii)对应于悬挂节点的元素，我们以通常方式消除。

   <li>  通过@f{gather*}\mathcal{A}_{i+1} \dealcoloneq \lbrace p\in\mathcal{S}:\Lambda^i_p +
 c\left(\left[B^TU^i\right]_p - G_p\right) > 0\rbrace,@f}定义新的活动和非活动集。

@f{gather*}\mathcal{F}_{i+1} \dealcoloneq \lbrace p\in\mathcal{S}:\Lambda^i_p +
 c\left(\left[B^TU^i\right]_p - G_p\right) \leq 0\rbrace.@f}



   <li> 项目 $U^i$ ，使其满足接触不等式，@f{gather*}\hat U^i \dealcoloneq P_{\mathcal{A}_{i+1}}(U^i).@f} 。

这里， $P_{\mathcal{A}}(U)$ 是 $\mathcal{A}$ 中的活性成分对间隙@f{gather*}P_{\mathcal{A}}(U)_p \dealcoloneq \begin{cases}
 U_p, & \textrm{if}\quad p\notin\mathcal{A}\\
 g_{h,p}, & \textrm{if}\quad
 p\in\mathcal{A},
 \end{cases}@f}的投影。

其中 $g_{h,p}$ 是<i>gap</i>，表示障碍物与身体未位移配置的距离。

   <li>  如果 $\mathcal{A}_{i+1} = \mathcal{A}_k$ 和 $\left\|
 {\hat R}\left({\mathbf u}^{i}\right) \right\|_{\ell_2} < \delta$ 则停止，否则设置 $i=i+1$ 并转到步骤（1）。这一步确保我们只有在找到正确的活动集和塑性已经迭代到足够的精度时才停止迭代。   </ol> 

在这个算法的第3步中，矩阵 $B\in\mathbb{R}^{n\times m}$ ,  $n>m$ 描述了位移和拉格朗日乘数（接触力）的基数的耦合，在我们的情况下它不是二次的，因为 $\Lambda^k$ 只定义在 $\Gamma_C$ ，即可能发生接触的面。如文中所示，我们可以选择 $B$ 是一个每行只有一个条目的矩阵，（另见H&uuml;eber, Wohlmuth:A primal-dual active set strategy for non-linear multibody contact problems, Comput.Method Appl. Mech.Engrg.194, 2005, pp.3147-3166）。)矢量 $G$ 是由间隙 $g_h$ 的合适近似值定义的。

@f{gather*}G_p = \begin{cases}
g_{h,p}, & \text{if}\quad p\in\mathcal{S}\\
0, & \text{if}\quad p\notin\mathcal{S}.
\end{cases}@f}






<h3>Adaptive mesh refinement</h3>

由于我们的程序是在三维空间中运行的，所以程序执行的计算很昂贵。因此，使用自适应网格细化是在可接受的运行时间内的一个重要步骤。为了使我们的生活更轻松，我们简单地选择已经在deal.II中实现的KellyErrorEstimator。我们把包含位移 $u$ 的解向量交给它。正如我们将在结果中看到的，它产生了一个相当合理的接触区和塑性的自适应网格。




<h3>Implementation</h3>

本教程实质上是步骤40和步骤41的混合体，但我们没有使用PETSc，而是让Trilinos库来处理线性代数的并行化问题（就像步骤32一样）。由于我们试图解决一个类似于步骤41的问题，我们将使用同样的方法，但现在是并行的。

一个困难是处理来自Dirichlet条件的约束，悬挂节点和由接触产生的不平等条件。为此，我们创建了三个AffineConstraints类型的对象，它们描述了各种约束条件，我们将在每次迭代中适当地组合它们。

与第41步相比，该计划有一些新的课程。

 <ul>   <li>   <code>ConstitutiveLaw</code>  描述材料的塑性行为。

 <li>   <code>SphereObstacle</code> 描述一个球体，作为被推入可变形弹性体的障碍物。   是用这个还是下一个类来描述障碍物，由输入参数文件决定。

 <li>   <code>ChineseObstacle</code> （和一个辅助类）是一个允许我们从一个文件中读入障碍物的类。在我们将在结果部分展示的例子中，这个文件将是 <code>'obstacle_file.dat'</code> ，并对应于显示力或力量的中文、日文或韩文符号的数据（见http://www.orientaloutpost.com/："这个词可用于激励--它也可以指力量/运动/推进/力。它可以是任何使你继续前进的内部或外部事物。这是用中文表达动机的最安全方式。如果你的听众是日本人，请看另一个关于动机的条目。这是日语和韩语中的一个词，但它的意思是 "动力 "或 "动能"（没有你可能正在寻找的动机的意思）"）。实质上，我们将假装有一个印章（即对应于平底障碍物的面具，没有中间高度的碎片），我们把它压在身体里。有关的符号看起来如下（也可参见本节顶部的图片，了解最终结果是怎样的）。

    <img src="https://www.dealii.org/images/steps/developer/step-42.character.png" alt="" width="25%">   </ul> 。

除此以外，让我们只对以下方面进行评论。   <ul>   <li>  程序允许你通过参数文件从两个不同的粗略网格中进行选择。这些是立方体 $[0,1]^3$ 或半球体，其开放面朝向正 $z$ 方向。

 <li> 在这两种情况下，我们将假设可能与障碍物接触的边界部分具有边界指标一的惯例。对于这两种网格，我们假定这是一个自由表面，即身体要么在那里接触，要么没有力作用在它身上。对于半球体，弯曲部分的边界指标为零，我们在那里施加零位移。对于盒子，我们沿底部施加零位移，但允许沿边的垂直位移（尽管没有水平位移）。   </ul> 


examples/step-42/doc/results.dox



<h1>Results</h1>

包含这个程序的目录还包含一些输入参数文件，可以用来创建各种不同的模拟。例如，用 <code>p1_adaptive.prm</code> 参数文件（用球作为障碍物，用盒子作为领域）在16个核心上运行该程序会产生这样的输出。

@code
    Using output directory 'p1adaptive/'
    FE degree 1
    transfer solution false


Cycle 0:
   Number of active cells: 512
   Number of degrees of freedom: 2187


  Newton iteration 1
      Updating active set...
         Size of active set: 1
      Assembling system...
      Solving system...
         Error: 173.076 -> 1.64265e-06 in 7 Bicgstab iterations.
      Accepting Newton solution with residual: 1.64265e-06


   Newton iteration 2
      Updating active set...
         Size of active set: 1
      Assembling system...
      Solving system...
         Error: 57.3622 -> 3.23721e-07 in 8 Bicgstab iterations.
      Accepting Newton solution with residual: 24.9028
      Active set did not change!


   Newton iteration 3
      Updating active set...
         Size of active set: 1
      Assembling system...
      Solving system...
         Error: 24.9028 -> 9.94326e-08 in 7 Bicgstab iterations.
      Residual of the non-contact part of the system: 1.63333
         with a damping parameter alpha = 1
      Active set did not change!


...


  Newton iteration 6
      Updating active set...
         Size of active set: 1
      Assembling system...
      Solving system...
         Error: 1.43188e-07 -> 3.56218e-16 in 8 Bicgstab iterations.
      Residual of the non-contact part of the system: 4.298e-14
         with a damping parameter alpha = 1
      Active set did not change!
      Writing graphical output... p1_adaptive/solution-00.pvtu



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      1.13s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assembling                      |         6 |     0.463s |        41% |
| Graphical output                |         1 |    0.0257s |       2.3% |
| Residual and lambda             |         4 |    0.0754s |       6.7% |
| Setup                           |         1 |     0.227s |        20% |
| Setup: constraints              |         1 |    0.0347s |       3.1% |
| Setup: distribute DoFs          |         1 |    0.0441s |       3.9% |
| Setup: matrix                   |         1 |    0.0119s |       1.1% |
| Setup: vectors                  |         1 |   0.00155s |      0.14% |
| Solve                           |         6 |     0.246s |        22% |
| Solve: iterate                  |         6 |    0.0631s |       5.6% |
| Solve: setup preconditioner     |         6 |     0.167s |        15% |
| update active set               |         6 |    0.0401s |       3.6% |
+---------------------------------+-----------+------------+------------+


Peak virtual memory used, resident in kB: 541884 77464
Contact force = 37.3058


...


Cycle 3:
   Number of active cells: 14652
   Number of degrees of freedom: 52497


   Newton iteration 1
      Updating active set...
         Size of active set: 145
      Assembling system...
      Solving system...
         Error: 296.309 -> 2.72484e-06 in 10 Bicgstab iterations.
      Accepting Newton solution with residual: 2.72484e-06


...


   Newton iteration 10
      Updating active set...
         Size of active set: 145
      Assembling system...
      Solving system...
         Error: 2.71541e-07 -> 1.5428e-15 in 27 Bicgstab iterations.
      Residual of the non-contact part of the system: 1.89261e-13
         with a damping parameter alpha = 1
      Active set did not change!
      Writing graphical output... p1_adaptive/solution-03.pvtu



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      38.4s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assembling                      |        10 |      22.5s |        58% |
| Graphical output                |         1 |     0.327s |      0.85% |
| Residual and lambda             |         9 |      3.75s |       9.8% |
| Setup                           |         1 |      4.83s |        13% |
| Setup: constraints              |         1 |     0.578s |       1.5% |
| Setup: distribute DoFs          |         1 |      0.71s |       1.8% |
| Setup: matrix                   |         1 |     0.111s |      0.29% |
| Setup: refine mesh              |         1 |      4.83s |        13% |
| Setup: vectors                  |         1 |   0.00548s |     0.014% |
| Solve                           |        10 |      5.49s |        14% |
| Solve: iterate                  |        10 |       3.5s |       9.1% |
| Solve: setup preconditioner     |        10 |      1.84s |       4.8% |
| update active set               |        10 |     0.662s |       1.7% |
+---------------------------------+-----------+------------+------------+


Peak virtual memory used, resident in kB: 566052 105788
Contact force = 56.794


...
@endcode



每个周期结束时的表格显示了最近一次网格细化周期的计算时间（这些数字当然是针对产生该输出的机器而言的）和程序不同部分的调用次数，如装配或计算残差。上面的一些数字可以通过将解决方案从一个网格转移到下一个网格来改善，我们在这里没有行使这个选项。当然，你也可以通过使用更多的处理器来使程序运行得更快，特别是在后期的细化周期中：附带的论文显示，至少有1000个内核的良好扩展性。

在一个典型的运行中，你可以看到，对于每一个细化步骤，活动集--接触点--首先被迭代出来。之后，牛顿方法只需要解决塑性问题。对于更细的网格，在最后4或5次牛顿迭代中可以看到二次收敛。

我们不会在这里详细讨论每个输入文件的情况。相反，让我们只展示解决方案的图片（如果单元格的正交点为零，塑性不等式处于活动状态，则域的左半部分被省略）。

 <table align="center">
  <tr>
    <td>
    <img src="https://www.dealii.org/images/steps/developer/step-42.CellConstitutionColorbar.png">
    </td>
    <td>
    <img src="https://www.dealii.org/images/steps/developer/step-42.CellConstitutionBall2.png" alt="" width="70%">
    </td>
    <td valign="top">
      &nbsp;
    </td>
    <td>
    <img src="https://www.dealii.org/images/steps/developer/step-42.CellConstitutionLi2.png" alt="" alt="" width="70%">
    </td>
  </tr>
</table> 

图中显示了适应性细化以及细胞在与球接触过程中的塑化程度。请记住，我们考虑每个正交点的应力偏差部分的规范，以查看是否有弹性或塑性行为。蓝色意味着这个单元只包含弹性正交点，与所有正交点都被塑化的红色单元相反。在顶面的中间--网格最细的地方--非常仔细地看可以看到由障碍物引起的凹陷。这是 <code>move_mesh()</code> 函数的结果。然而，由于我们在这里考虑的障碍物的压痕非常小，所以很难辨别这种效果；我们可以玩玩将网格的顶点按计算出的位移的倍数进行位移。

关于使用该程序可以获得的结果的进一步讨论，见本页面最上方提到的出版物。


<a name="extensions"></a>

<h1>Possibilities for extensions</h1>

像往常一样，有多种可能性来扩展这个程序。从算法的角度来看，这个程序在写作时已经达到了我们所能达到的程度，使用了接触不等式、塑性非线性和线性求解器的最佳可用算法。然而，就更现实的情况而言，人们希望用这个程序做一些事情。   <ul>   <li>  将程序从静态扩展到准静态情况，也许可以通过选择后向欧拉模式来实现时间离散化。一些理论结果可以在Jörg Frohne的博士论文中找到，<i>FEM-Simulation
der Umformtechnik metallischer Oberfl&auml;chen im Mikrokosmos</i>，德国锡根大学，2011。

 <li> 考虑有摩擦力的接触问题也将是一个有趣的进步。在几乎每个机械过程中，摩擦都有很大的影响。  为了模拟这种情况，我们必须考虑到接触面的切向应力。摩擦也给我们的问题增加了另一个不等式，因为只要切向应力不超过某个极限，身体和障碍物通常会粘在一起，超过这个极限，两个身体就会互相滑过。

 <li>  如果我们已经模拟了摩擦性接触，下一步要考虑的是接触区的发热。由两个物体之间的摩擦引起的热量会提高可变形物体的温度，并导致一些材料参数的变化。

 <li>  对于接触以及塑性，实施更精确的、与问题相适应的误差估计器可能是有意义的。   </ul> 


examples/step-43/doc/intro.dox

 <br> 

<i>
This program was contributed by Chih-Che Chueh (University of Victoria) and
Wolfgang Bangerth. Results from this program are used and discussed in the
following publications (in particular in the second one):


- Chih-Che Chueh, Marc Secanell, Wolfgang Bangerth, Ned Djilali. Multi-level
  adaptive simulation of transient two-phase flow in heterogeneous porous
  media. Computers &amp; Fluids, 39:1585-1596, 2010


- Chih-Che Chueh, Ned Djilali, Wolfgang Bangerth. An h-adaptive operator
  splitting method for two-phase flow in 3D heterogeneous porous
  media. SIAM Journal on Scientific Computing, 35:B149-B175, 2013.


The implementation discussed here uses and extends
parts of the step-21 and step-31 tutorial programs.


The work of the Chih-Che Chueh was funded through the Canada Research Chairs
Program and the MITACS Network of Centres of Excellence. Parts of the work by
Wolfgang Bangerth were funded through Award No. KUS-C1-016-04, made by the King
Abdullah University of Science and Technology, and through an Alfred P. Sloan
Research Fellowship.
This material is also in parts based upon work supported by the National
Science Foundation under Award No. EAR-0426271 and The California Institute of
Technology; and in a continuation by the National Science
Foundation under Award No. EAR-0949446 and The University of California
&ndash; Davis. Any opinions, findings, and conclusions or recommendations
expressed in this publication are those of the author and do not
necessarily reflect the views of the National Science Foundation, The
California Institute of Technology, or of The University of California
&ndash; Davis.
</i>


<a name="Intro"></a><h1>Introduction</h1> 。

多孔介质中的多相流模拟是一个无处不在的问题，我们以前在步骤20和步骤21中已经以某种形式解决了这个问题。然而，正如在那里很容易看到的那样，它面临两个主要困难：数值精度和效率。第一个问题在第20步的静止求解器中很容易看到：使用最低阶的Raviart-Thomas元素不可能产生高度精确的解决方案。我们需要更精确的方法。第二个原因从时间相关的步骤-21中可以看出：该程序慢得令人发指，没有希望在合理的时间范围内得到高度准确的三维解。

在这个项目中，为了克服这两个问题，有五个方面我们正在努力改进，以实现高性能的模拟器。

 <ul>   <li>  高阶空间离散  <li>  自适应网格细化  <li>  自适应时间步进  <li>  运算器分割  <li>  高效求解器和预处理  </ul> 

这个计划的大部分灵感来自第31步，但这里讨论的几个技术是原创的。




<h3>Advection-dominated two-phase flow mathematical model.</h3>

我们考虑的是两相不相溶的不可压缩流体的流动。毛细管和重力效应被忽略了，粘性效应被假定为主导。这种流动的管理方程与步骤21中使用的方程相同，为

@f{align*}
  \mathbf{u}_t &= - \mathbf{K} \lambda_t \left(S\right) \nabla p, \\
  \nabla \cdot \mathbf{u}_t &= q, \\
  \epsilon \frac{\partial S}{\partial t} + \nabla \cdot \left( \mathbf{u}_t  F\left( S \right) \right)&=0,


@f}

其中 $S$ 是第二（润湿）相的饱和度（体积分数在零和一之间）， $p$ 是压力， $\mathbf{K}$ 是渗透率张量， $\lambda_t$ 是总流动性， $\epsilon$ 是孔隙度， $F$ 是湿润相的分流量， $q$ 是源项， $\mathbf{u}_t$ 是总速度。总流动性、润湿相的部分流量和总速度分别由以下公式给出

@f{align*}
   \lambda_t(S)&= \lambda_w + \lambda_{nw} = \frac{k_{rw}(S)}{\mu_w} + \frac{k_{rnw}(S)}{\mu_{nw}}, \\
   F(S) &= \frac{\lambda_w}{\lambda_t} = \frac{\lambda_w}{\lambda_w + \lambda_{nw}} = \frac{k_{rw}(S)/\mu_w}{k_{rw}(S)/\mu_w + k_{rnw}(S)/\mu_{nw}}, \\
   \mathbf{u}_t &= \mathbf{u}_w + \mathbf{u}_{nw} = -\lambda_t(S)\mathbf{K} \cdot \nabla p,


@f}

其中下标 $w, nw$ 分别代表湿润和非湿润阶段。

为方便起见，饱和度方程中的孔隙度 $\epsilon$ 可被视为时间变量的比例系数，被设定为1。根据相对渗透率 $k_{rw}$ 和 $k_{rnw}$ 对饱和度的依赖性的常用规定，我们用

@f{align*}
   k_{rw}  &= S^2, \qquad&\qquad
   k_{rnw} &= \left( 1-S \right)^2.


@f}



上面的多孔介质方程由饱和度的初始条件和压力的边界条件来补充。由于饱和度和压力梯度唯一地决定了速度，所以速度的边界条件是没有必要的。由于流动方程不包含时间导数，因此不需要速度和压力变量的初始条件。流场将边界分为流入或流出部分。具体来说。

@f[
   \mathbf{\Gamma}_{in}(t) = \left\{\mathbf{x} \in \partial \Omega:\mathbf{n} \cdot \mathbf{u}_t<0\right\},


@f]

我们通过在流入边界上施加饱和变量的边界值，得出一个完整的模型  $\mathbf{\Gamma}_{in}$  。




<h3>Adaptive operator splitting and time stepping.</h3>

从第21步可以看出，一旦我们知道了流量变量，求解速度和压力的流量方程是程序中花费时间远大于饱和度变量的（明确）更新步骤的部分。另一方面，压力和速度对饱和度的依赖性很弱，因此可以考虑每隔几步只求解压力和速度，而每步更新饱和度。如果我们能找到一个关于何时需要更新流量变量的标准，我们把这种拆分称为 "自适应算子拆分 "方案。

在这里，我们使用以下后验标准来决定何时重新计算压力和速度变量（详细的推导和描述可以在[Chueh, Djilali and Bangerth 2011]中找到）。

@f{align*}
  \theta(n,n_p)
  =
    \max_{\kappa\in{\mathbb T}}
    \left(
    \left\|
      \frac 1{\lambda_t\left(S^{(n-1)}\right)}


      - \frac 1{\lambda_t\left(S^{(n_p)}\right)} \right\|_{L^\infty(\kappa)}
    \left\|\|\mathbf{K}^{-1}\|_1\right\|_{L^\infty(\kappa)}
    \right).


@f}

其中括号内的上标表示定义任何数量的饱和时间步数， $n_p<n$ 代表我们实际计算压力和速度的最后一步。如果 $\theta(n,n_p)$ 超过某个阈值，我们就重新计算流量变量；否则，我们在时间步骤 $n$ 中跳过这个计算，只将饱和变量向前移动一个时间步骤。

简而言之，该算法允许我们执行若干长度为 $\Delta t_c^{(n)}=t^{(n)}_c-t^{(n-1)}_c$ 的饱和时间步长，直到上述标准告诉我们重新计算速度和压力变量，导致一个长度为

@f[
   \Delta t_p^{(n)} = \sum_{i=n_p+1}^{n} \Delta t_c^{(i)}.


@f]

我们根据Courant-Friedrichs-Lewy（CFL）限制来选择（微型）步骤的长度，标准是

@f[
  \Delta t_c = \frac{\textrm{min}_{K}h_{K}}{7 \|\mathbf{u}_t\|_{L^{\infty}\left(\Omega\right)}},


@f]

我们已经证实，对于下面讨论的饱和方程的有限元和时间步长方案的选择是稳定的（ $h_K$ 表示单元 $K$ 的直径）。其结果是一个方案，微观和宏观的时间步长都不统一，两者都是自适应选择。

<h3>Time discretization.</h3> 利用这种时间离散化，我们从IMPES方法中得到每个时间步骤的以下方程组（见步骤21）。

@f{align*}
   \mathbf{u}^{(n)}_t + \lambda_t\left(S^{(n-1)}\right) \mathbf{K} \nabla p^{(n)} =0, \\
   \nabla \cdot \mathbf{u}^{(n)}_t = q, \\
   \epsilon \left( \frac{S^{(n-1)}-S^{(n)}}{\Delta t^{(n)}_c} \right) + \mathbf{u}^{(n)}_t \cdot \nabla F\left(S^{(n-1)}\right) + F\left(S^{(n-1)}\right) \nabla \cdot \mathbf{u}^{(n)}_t =0.


@f}




利用 $\nabla \cdot \mathbf{u}_t = q$ 这一事实，时间离散的饱和度方程变为

@f{align*}
  &\epsilon \left( \frac{S^{(n)}-S^{(n-1)}}{\Delta t^{(n)}_c} \right) + \mathbf{u}^{(n)}_t \cdot \nabla F\left(S^{(n-1)}\right) + F\left(S^{(n-1)}\right)q=0.


@f}



<h3>Weak form, space discretization for the pressure-velocity part.</h3>

通过将定义总速度的方程 $\mathbf u_t^{(n)}$ 和用源项表示其发散的方程分别与测试函数 $\mathbf{v}$ 和 $w$ 相乘，然后根据需要进行分项积分，问题的弱形式为。找出 $\mathbf u, p$ ，以便对所有测试函数 $\mathbf{v}, w$ 而言，存在

@f{gather*}
   \left( \left( \mathbf{K} \lambda_t\left(S^{(n-1)}\right) \right)^{-1} \mathbf{u}^{(n)}_t, \mathbf{v}\right)_{\Omega} - \left(p^{(n)}, \nabla \cdot \mathbf{v}\right)_{\Omega} = -\left(p^{(n)}, \mathbf{n} \cdot \mathbf{v} \right)_{\partial \Omega}, \\


   - \left( \nabla \cdot \mathbf{u}^{(n)}_t,w\right)_{\Omega} = - \big(q,w\big)_{\Omega}.


@f}

这里， $\mathbf{n}$ 代表 $\partial
\Omega$ 的单位外向法向量，压力 $p^{(n)}$ 可以在边界 $\partial \Omega$ 的开放部分弱化规定，而在那些规定了速度的部分（例如具有 $\mathbf n \cdot \mathbf
u=0$ 的不渗透边界，该术语完全消失了，因为 $\mathbf n \cdot \mathbf
v=0$  。

我们使用连续有限元来离散速度和压力方程。具体来说，我们使用混合有限元来确保同时对矢量变量（如流体速度）和标量变量（如压力）进行高阶逼近。对于鞍点问题，公认的是需要满足所谓的Babuska-Brezzi或Ladyzhenskaya-Babuska-Brezzi（LBB）条件[Brezzi 1991, Chen 2005]以确保压力-速度系统的稳定性。在本工作中，通过使用比压力高一阶的速度元素，即 $u_h \in Q^d_{p+1}$ 和 $p_h \in Q_p$ 来满足这些稳定性条件，其中 $p=1$ ， $d$ 是空间维度， $Q_s$ 表示每个变量的张量积Lagrange多项式的空间 $s$ 。

<h3>Stabilization, weak form and space discretization for the saturation transport equation.</h3>为饱和方程选择的 $Q_1$ 元素在没有上卷或其他类型的稳定化的情况下不会导致稳定的离散化，并且在数值解中会出现虚假的震荡。添加一个人工扩散项是消除这些振荡的一种方法[Chen 2005]。另一方面，添加过多的扩散项会在解中涂抹出尖锐的锋面，并且会出现网格定向困难[Chen 2005]。为了避免这些影响，我们使用了由[Guermond和Pasquetti 2008]提出并在[Chueh, Djilali, Bangerth 2011]和[Kronbichler, Heister and Bangerth, 2011]以及步骤31中验证的人工扩散项。

这种方法修改了饱和度方程的（离散）弱形式，改为

@f{align*}
  \left(\epsilon \frac{\partial S_h}{\partial t},\sigma_h\right)


  -
  \left(\mathbf{u}_t  F\left( S_h \right),
    \nabla \sigma_h\right)
  +
  \left(\mathbf n \cdot \mathbf{u}_t  \hat F\left( S_h \right),
    \sigma_h\right)_{\partial\Omega}
  +
  (\nu(S_h) \nabla S_h, \nabla \sigma_h)
  &=0
  \qquad
  \forall \sigma_h,


@f}

其中 $\nu$ 是人工扩散参数， $\hat F$ 是域的边界上适当选择的数值通量（我们为此选择明显的全上风通量）。

根据[Guermond and Pasquetti 2008]（以及[Chueh, Djilali and Bangerth 2011]中的详细说明），我们将参数作为一个片状常数函数，设置在直径为 $K$ 的每个单元上，为

@f[
   \nu(S_h)|_{K} = \beta \| \mathbf{u}_t \max\{F'(S_h),1\} \|_{L^{\infty}(K)} \textrm{min} \left\{ h_{K},h^{\alpha}_{K} \frac{\|\textrm{Res}(S_h)\|_{L^{\infty}(K)}}{c(\mathbf{u}_t,S)} \right\}


@f]

其中 $\alpha$ 为稳定化指数， $\beta$ 为用户定义的无量纲稳定化常数。按照[Guermond和Pasquetti 2008]以及步骤31的实现，速度和饱和度全局归一化常数 $c(\mathbf{u}_t,S)$ 和残差 $\textrm{Res}(S)$ 分别为

@f[
   c(\mathbf{u}_t,S) = c_R \|\mathbf{u}_t \max\{F'(S),1\}\|_{L^{\infty}(\Omega)} \textrm{var}(S)^\alpha | \textrm{diam} (\Omega) |^{\alpha - 2}


@f]

和

@f[
   \textrm{Res}(S) = \left( \epsilon \frac{\partial S}{\partial t} + \mathbf{u}_t \cdot \nabla F(S) + F(S)q \right) \cdot S^{\alpha - 1}


@f]

其中 $c_R$ 是用户定义的第二个无维常数， $\textrm{diam}(\Omega)$ 是域的直径， $\textrm{var}(S) =
\textrm{max}_{\Omega} S - \textrm{min}_{\Omega} S$ 是整个计算域中目前饱和值的范围 $\Omega$  。

这种稳定方案与更简单的方案，如有限体积（或不连续Galerkin）方法或流线型上风Petrov Galerkin（SUPG）离散法相比有很多优点。特别是，人工扩散项主要作用于不连续点附近，因为在饱和度平稳的地区，残差很小。因此，它提供了一个更高的精度。另一方面，它是非线性的，因为  $\nu$  取决于饱和度  $S$  。我们通过明确处理所有的非线性项来避免这一困难，这导致了以下时间步长的完全离散问题  $n$  。

@f{align*}
   &\left( \epsilon S_h^{(n)},\sigma_h\right)_{\Omega} - \Delta t^{(n)}_c \Big(F\left(S_h^{(n-1)}\right)\mathbf{u}^{*}_t,\nabla\sigma_h\Big)_{\Omega} + \Delta t^{(n)}_c \Big(F\left(S_h^{(n-1)}\right)\left(\mathbf{n}\cdot\mathbf{u}^{*}_t\right),\sigma_h\Big)_{\partial\Omega} \nonumber \\
   & \quad = \left( \epsilon S_h^{(n-1)},\sigma_h\right)_{\Omega} - \Delta t^{(n)}_c \bigg(\nu\left(S_h^{(n-1)}\right)\nabla S_h^{(n-1)},\nabla\sigma_h\bigg)_{\Omega} \nonumber \\
   & \qquad + \Delta t^{(n)}_c \bigg(\mathbf{n}\cdot\nu\left(S_h^{(n-1)}\right)\nabla S^{(n-1)},\sigma_h\bigg)_{\partial\Omega}


@f}

其中 $\mathbf{u}_t^{*}$ 是从 $\mathbf{u}^{(n_p)}_t$ 和 $\mathbf{u}^{(n_{pp})}_t$ 线性外推到当前时间 $t^{(n)}$ 的速度，如果 $\theta<\theta^*$ ，而 $\mathbf{u}_t^{*}$ 是 $\mathbf{u}^{(n_p)}_t$ ，如果 $\theta>\theta^*$  。因此，该方程在 $S_h^{(n)}$ 中是线性的，所需要的是用饱和空间上的质量矩阵来解决。

由于饱和度的Dirichlet边界条件只施加在流入边界上，所以上述方程左边的第三个项需要进一步分成两部分。

@f{align*}
  &\Delta t^{(n)}_c \Big(F\left(S_h^{(n-1)}\right)\left(\mathbf{n}\cdot\mathbf{u}^{(n)}_t\right),\sigma_h\Big)_{\partial\Omega} \nonumber \\
  &\qquad= \Delta t^{(n)}_c \Big(F\left(S^{(n-1)}_{(+)}\right)\left(\mathbf{n}\cdot\mathbf{u}^{(n)}_{t(+)}\right),\sigma_h\Big)_{\partial\Omega_{(+)}} + \Delta t^{(n)}_c \Big(F\left(S^{(n-1)}_{(-)}\right)\left(\mathbf{n}\cdot\mathbf{u}^{(n)}_{t(-)}\right),\sigma_h\Big)_{\partial\Omega_{(-)}}


@f}

其中 $\partial\Omega_{(-)} = \left\{\mathbf{x} \in \partial\Omega : \mathbf{n}
  \cdot \mathbf{u}_t<0\right\}$ 和 $\partial\Omega_{(+)} = \left\{\mathbf{x} \in \partial\Omega : \mathbf{n} \cdot
  \mathbf{u}_t>0\right\}$ 分别代表流入和流出的边界。我们使用上风公式选择数值，即 $S^{(n-1)}_{(+)}$ 和 $\mathbf{u}^{(n)}_{t(+)}$ 对应于从当前单元中提取的数值，而 $S^{(n-1)}_{(-)}$ 和 $\mathbf{u}^{(n)}_{t(-)}$ 的数值是来自邻近的边界 $\partial\Omega_{(-)}$ 。




<h3>Adaptive mesh refinement.</h3>

适应性地选择网格以解决尖锐的饱和前沿是我们算法中实现效率的一个基本要素。在这里，我们使用[Chueh, Djilali and Bangerth 2011]中使用的相同的冲击型细化方法来选择那些应该被细化或粗化的单元。三角形的每个单元 $K$ 的细化指标是通过以下方式计算的

@f[
   \eta_{K} = |\nabla S_h(\mathbf x_K)|


@f]

其中 $\nabla S_h(\mathbf x_K)$ 是在 $\mathbf x_K$ 单元的中心评价的离散饱和变量的梯度。这种方法类似于可压缩流动问题中经常使用的方法，即用密度梯度来表示细化。也就是说，正如我们将在<a href="#Results">results section</a>的结尾处讨论的那样，这被证明不是一个非常有用的标准，因为它基本上到处都导致细化。我们在这里只是为了说明问题而展示它。




<h3>Linear system and its preconditioning.</h3>

按照上面讨论的治理方程的离散化，我们得到一个时间步长为 $(n)$ 的线性方程组，形式如下。

@f[
 \left(
  \begin{array}{ccc}
   \mathbf{M}^{\mathbf{u}} & \mathbf{B}^{T} & \mathbf{0}  \\
   \mathbf{B}           & \mathbf{0}     & \mathbf{0}   \\
   \mathbf{H}           & \mathbf{0}     & \mathbf{M}^{S}
  \end{array}
 \right)
 \left(
  \begin{array}{c}
   \mathbf{U}^{(n)} \\
   \mathbf{P}^{(n)} \\
   \mathbf{S}^{(n)}
  \end{array}
 \right)
 =
 \left(
  \begin{array}{c}
   0 \\
   \mathbf{F}_{2} \\
   \mathbf{F}_{3}
  \end{array}
 \right)


@f]

其中各个矩阵和向量的定义如下，使用形状函数 $\mathbf{v}_i$ 表示速度， $\phi_i$ 表示压力和饱和度。

@f{align*}
  \mathbf{M}^{\mathbf{u}}_{ij}
  &= \left( \left( \mathbf{K} \lambda_t\left(S^{(n-1)}\right) \right)^{-1}
  \mathbf{v}_{i},\mathbf{v}_{j}\right)_{\Omega},
  &
  \mathbf{M}^{S}_{ij}           &= \left(\epsilon \phi_i,\phi_j\right)_{\Omega}
  \\
  \mathbf{B}_{ij}
  &= - \left( \nabla \cdot \mathbf{v}_{j},\phi_{i}\right)_{\Omega},
  &
  \mathbf{H}_{ij}
  &= - \Delta t^{(n)}_c \Big( F\left(S^{(n-1)}\right) \mathbf{v}_i,\nabla\phi_j\Big)_{\Omega}
  \\
  \left(\mathbf{F}_{2}\right)_i
  &= - \big(F\left(S^{(n-1)}\right)q,\phi_i\big)_{\Omega},


@f}

和 $\mathbf{F}_{3}$ 在稳定传输方程的定义中给出。

如果我们把左上角的 $2\times 2$ 板块的矩阵视为一个板块，那么上面的线性系统是块状三角形形式。因此，我们可以首先求解速度和压力（除非我们决定用 $\mathbf U^{(n_p)}$ 来代替速度），然后再求解饱和度变量。其中第一个步骤要求我们解决

@f[
 \left(
  \begin{array}{cc}
   \mathbf{M}^{\mathbf{u}} & \mathbf{B}^{T}  \\
   \mathbf{B}           & \mathbf{0}
  \end{array}
 \right)
 \left(
  \begin{array}{c}
   \mathbf{U}^{(n)} \\
   \mathbf{P}^{(n)}
  \end{array}
 \right)
 =
 \left(
  \begin{array}{c}
   0 \\
   \mathbf{F}_{2}
  \end{array}
 \right)


@f]

我们对这个线性系统采用广义最小残差（GMRES）方法[Saad和Schultz 1986]。速度-压力系统的理想预处理方法是

@f{align*}
\mathbf{P} =
 \left(
  \begin{array}{cc}
   \mathbf{M}^{\mathbf{u}} &  \mathbf{0}  \\
   \mathbf{B}           & -\mathbf{S}
  \end{array}
 \right),
 & \qquad
 \mathbf{P}^{-1} =
 \left(
  \begin{array}{cc}
   \left(\mathbf{M}^{\mathbf{u}}\right)^{-1}                              &  \mathbf{0}  \\
   \mathbf{S}^{-1} \mathbf{B} \left(\mathbf{M}^{\mathbf{u}}\right)^{-1}   & -\mathbf{S}^{-1}
  \end{array}
 \right)
 @f}

其中 $\mathbf{S}=\mathbf{B}\left(\mathbf{M}^{\mathbf{u}}\right)^{-1}\mathbf{B}^T$ 是系统的Schur补充[Zhang 2005]。这个预处理程序是最优的，因为

@f{align*}
 \mathbf{P}^{-1}
 \left(
  \begin{array}{cc}
   \mathbf{M}^{\mathbf{u}} & \mathbf{B}^{T}  \\
   \mathbf{B}           & \mathbf{0}
  \end{array}
 \right)
 =
  \left(
  \begin{array}{cc}
   \mathbf{I}         &  \left(\mathbf{M}^{\mathbf{u}}\right)^{-1} \mathbf{B}^{T}  \\
   \mathbf{0}         &  \mathbf{I}
  \end{array}
 \right),


@f}

对其而言，可以证明GMRES在两次迭代中收敛。

然而，我们当然不能指望使用速度质量矩阵和Schur补数的精确求逆。因此，我们采用[Silvester and Wathen 1994]最初为斯托克斯系统提出的方法。将其适用于当前的方程组，得到预处理程序

@f{align*}
 \mathbf{\tilde{P}}^{-1} =
 \left(
  \begin{array}{cc}
   \widetilde{\left(\mathbf{{M}}^{\mathbf{u}}\right)^{-1}}
                              &  \mathbf{0}  \\
   \widetilde{\mathbf{{S}}^{-1}} \mathbf{B} \widetilde{\left(\mathbf{{M}}^{\mathbf{u}}\right)^{-1}}   & -\widetilde{\mathbf{{S}}^{-1}}
  \end{array}
 \right)


@f}

其中蒂尔德表示精确逆矩阵的近似值。特别是，由于 $\left(\mathbf{{M}}^{\mathbf{u}}\right)^{-1}=\left( \left(
    \mathbf{K} \lambda_t \right)^{-1}
  \mathbf{v}_{i},\mathbf{v}_{j}\right)_{\Omega}$ 是一个稀疏的对称和正定矩阵，我们为 $\widetilde{\left(\mathbf{{M}}^{\mathbf{u}}\right)^{-1}}$ 选择了这个矩阵的稀疏不完全Cholesky分解的单一应用[Golub和Van Loan 1996]。我们注意到，对应于非混合形式的多孔介质流动算子的舒尔补， $-\nabla \cdot [\mathbf K
\lambda_t(S)]\nabla$ 和 $\mathbf{\tilde {S}} = \left( \left( \mathbf{K} \lambda_t \right) \nabla \phi_{i},\nabla \phi_{j}\right)_{\Omega}$ 应该是实际舒尔补矩阵 $\mathbf
S$ 的良好近似。由于这两个矩阵又都是对称和正定的，所以我们用 $\mathbf{\tilde S}$ 的不完全Cholesky分解来表示 $\widetilde
{\mathbf{{S}}^{-1}}$ 。需要注意的是， $\mathbf{\tilde S}$ 需要用Dirichlet边界条件建立，以确保其可逆性。

一旦有了速度 $\mathbf{U}^{(n)} \equiv \mathbf{u}^*_t$ ，我们就可以把 $\mathbf{H}$ 和 $\mathbf{F}_{3}$ 组合起来，用以下方法解决饱和度的问题

@f{align*}
  \mathbf{M}^{S} \mathbf{S}^{(n)} = \mathbf{F}_{3} - \mathbf{H} \mathbf{U}^{(n)}.


@f}

其中质量矩阵 $\mathbf{M}^{S}$ 用共轭梯度法求解，再一次使用不完全的Cholesky分解作为预处理。

<h3>The test cases.</h3>

 @note  这里讨论的实现使用并扩展了这个库的步骤21、步骤31和步骤33教程的部分程序。特别是，如果你想了解它是如何工作的，请参考step-21关于数学问题的讨论，以及step-31，大部分的实现都来自于此。我们将不讨论在步骤31中已经讨论过的实现的各个方面。

我们展示了一些两相流方程的数值结果，这些方程通过适当的初始和边界条件，结合两种不同的渗透率模型的选择而得到增强。在所考虑的问题中，没有内部源项（ $q=0$ ）。如上所述，定量的数值结果在[Chueh, Djilali and Bangerth 2011]中提出。

为了简单起见，我们选择了 $\Omega=[0,1]^d,d=2,3$ ，尽管所有的方法（以及我们的实现）在一般的非结构化网格上都应该同样工作。

初始条件只需要饱和变量，我们选择 $S(\mathbf{x},0)=0.2$ ，即多孔介质最初是由非湿润（80%）和湿润（20%）相的混合物填充。这与步骤21中的初始条件不同，在该步骤中我们采用了 $S(\mathbf{x},0)=0$ ，但由于复杂的数学原因，在那里的长篇评论中提到，目前使用基于熵的人工扩散项的方法在不对方法进行额外修改的情况下不能收敛到这个初始条件的粘度解。因此，我们在目前的计划中选择了这个修改过的版本。

此外，我们在边界上规定了一个线性压力。

@f[
   p(\mathbf{x},t) = 1 - x \qquad
   \textrm{on} \quad \partial \Omega \times [0,T].


@f]

压力和饱和度唯一地决定了速度，而速度决定了一个边界段是流入还是流出的边界。在边界的流入部分， $\mathbf{\Gamma}_{in}(t)$ ，我们规定

@f{align*}
   S(\mathbf{x},t) = 1 \qquad & \textrm{on} \quad \mathbf{\Gamma}_{in}(t) \cap \left\{x = 0\right\}, \\
   S(\mathbf{x},t) = 0 \qquad & \textrm{on} \quad \mathbf{\Gamma}_{in}(t) \backslash \left\{x = 0\right\}.


@f}

换句话说，该领域被来自左边的湿润相淹没。对于边界的流出部分，不需要饱和的边界条件。

所有用于二维/三维案例的数值和物理参数都列在下表中。

 <table align="center" class="tutorial" width="50%">
<tr>
    <th>Parameter                           </th><th>Symbol          </th><th>Value               </th><th>units     </th></tr><tr>
    <td>Porosity                            </td><td>$\epsilon$      </td><td>1.0                 </td><td>-                   </td></tr><tr>
    <td>Viscosity (wetting)                 </td><td>$\mu_w$         </td><td>0.2                 </td><td>$kg \cdot m^{-1} \cdot sec^{-1}$   </td></tr><tr>
    <td>Viscosity (nonwetting)              </td><td>$\mu_{nw}$      </td><td>1.0                 </td><td>$kg \cdot m^{-1} \cdot sec^{-1}$      </td></tr><tr>
    <td>Stabilization exponent              </td><td>$\alpha$        </td><td>1.0                 </td><td>-     </td></tr><tr>
    <td>Stabilization constant              </td><td>$\beta$         </td><td>2D: 0.3; 3D: 0.27   </td><td>- </td></tr><tr>
    <td>Normalization constant              </td><td>$c_R$           </td><td>1.0                 </td><td>- </td></tr><tr>
    <td>Number of high-permeability regions </td><td>$N$             </td><td>50; 200             </td><td>- </td></tr><tr>
    <td>Operator splitting threshold        </td><td>$\theta^\ast$   </td><td>5.0              </td><td>- </td></tr>
</table> 




<h3>List of references</h3>


<ol>  <li>  CC Chueh, N Djilali and W Bangerth.   <br>  三维异质多孔介质中两相流的h-适应性算子分割方法。   <br>  SIAM科学计算杂志，第35卷（2013），第B149-B175页

 <li>  M. Kronbichler, T. Heister, and W. Bangerth  <br>  通过现代数值方法进行高精度地幔对流模拟。   <br>  Geophysics Journal International, vol. 191 (2012), pp.

 <li>  F Brezzi和M Fortin。   <br>  <i>Mixed and Hybrid Finite Element Methods</i>.   <br>  Springer-Verlag, 1991.

 <li>  Z陈。   <br>  <i>Finite Element Methods and Their Applications</i>.   <br>  Springer, 2005.

 <li>  JL Guermond和R Pasquetti.   <br>  基于熵的非线性粘度的守恒定律的傅里叶近似。   <br>  <i>Comptes Rendus Mathematique</i>, 346(13-14): 801-806, 2008.

 <li>  CC Chueh, M Secanell, W Bangerth, and N Djilali.   <br>  异质多孔介质中瞬态两相流的多级自适应模拟。   <br>  <i>Computers and Fluids</i>, 39:1585-1596, 2010.

 <li>  Y Saad和MH Schultz。   <br>  Gmres:用于解决非对称线性系统的广义最小残差算法。   <br>  <i>SIAM Journal on Scientific and Statistical Computing</i>, 7(3):856-869, 1986.

 <li>  F张。   <br>  <i>The Schur Complement and its Applications</i>.   <br>  Springer, 2005.

 <li>  D Silvester和A Wathen。   <br>  稳定的斯托克斯系统的快速迭代解第二部分：使用一般的块状先决条件。   <br>  <i>SIAM Journal on Numerical Analysis</i>, 31(5):1352-1367, 1994.

 <li>  GH Golub和CF van Loan。   <br>  <i>Matrix Computations</i>.   <br>  第三版，约翰霍普金斯大学，1996年。

 <li>  SE Buckley和MC Leverett。   <br>  沙子中流体位移的机制。   <br>  <i>AIME Trans.</i>, 146:107-116, 1942.

 </ol> 


examples/step-43/doc/results.dox



<h1>Results</h1>


这个程序的输出与第21步的输出其实没有什么不同：毕竟它解决的是同一个问题。更重要的是定量指标，如解决方案的准确性以及计算所需的时间。这些在本页顶部列出的两份出版物中都有详细记载，我们在此不再重复。

也就是说，如果没有几张好的照片，任何教程程序都是不完整的，所以这里有一些三维运行的输出。

 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-43.3d.velocity.png" alt="">
	<p align="center">
        Velocity vectors of flow through the porous medium with random
        permeability model. Streaming paths of high permeability and resulting
        high velocity are clearly visible.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-43.3d.streamlines.png" alt="">
	<p align="center">
        Streamlines colored by the saturation along the streamline path. Blue
        streamlines indicate low saturations, i.e., the flow along these
	streamlines must be slow or else more fluid would have been
        transported along them. On the other hand, green paths indicate high
        velocities since the fluid front has already reached further into the
        domain.
	</p>
    </td>
  </tr>
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-43.3d.saturation.png" alt="">
	<p align="center">
        Streamlines with a volume rendering of the saturation, showing how far
        the fluid front has advanced at this time.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-43.3d.mesh.png" alt="">
	<p align="center">
	Surface of the mesh showing the adaptive refinement along the front.
	</p>
    </td>
  </tr>
</table> 


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

人们对这个程序的主要反对意见是它仍然太慢了：在合理的细网格上的三维计算实在是太昂贵了，无法以合理的快速周转来进行常规计算。这与我们写step-31时的情况相似，这个程序从它那里得到了很多灵感。解决办法也是类似的，因为它也在那里。我们需要以类似于从第31步衍生出第32步的方式来并行化这个程序。事实上，步骤32中使用的所有技术也可以转移到这个程序中，使程序立即在几十或几百个处理器上运行。

一个不同的方向是使该程序与许多其他多孔介质的应用更加相关。具体来说，一个途径是去找多孔介质流动模拟器的主要用户，即石油工业。在那里，该领域的应用以多相流（即超过我们这里的两相）为主，以及它们之间可能发生的反应（或任何其他相的质量交换方式，如通过溶解和从油相中冒出的气体）。此外，气体的存在往往会导致流体的可压缩性效应。这些效应通常共同组成了广泛使用的 "黑油模型"。在考虑储层中石油的控制性燃烧以提高压力和温度时，多相之间的真正反应也在油藏模型中发挥作用。不过，这些问题要复杂得多，留待今后的项目研究。

最后，从数学的角度来看，我们得出了在某一时间步长重新计算速度/压力解的标准，其前提是我们要把在当前时间步长会得到的解与上次实际解这个系统时计算的解进行比较。然而，在程序中，每当我们没有重新计算解决方案时，我们并不只是使用之前计算的解决方案，而是从之前两次求解系统的结果中推算出来。因此，该标准被悲观地表述为：我们真正应该比较的是在当前时间步长得到的解与外推的解。在这方面重述该定理是一个练习。

也有其他方法可以扩展这个程序的数学基础；例如，人们可以说，我们关心的不是速度，而实际上是饱和度。因此，人们可能会问，我们在这里用来决定 $\mathbf u$ 是否需要重新计算的标准是否合适；例如，人们可能会提出，决定一个错误的速度场事实上是否会影响饱和方程的解（以及影响的程度）也很重要。这自然会导致敏感性分析。

从算法的角度来看，我们在这里使用了一个工程中经常使用的细化标准，即通过查看解的梯度。然而，如果你检查解决方案，你会发现它几乎在所有地方都迅速导致细化，甚至在明显没有必要的区域：因此经常使用并不需要暗示它是一个有用的标准开始。另一方面，用一个不同的、更好的标准来取代这个标准应该不是很困难。例如，许多其他程序中使用的KellyErrorEstimator类当然也应该适用于当前的问题。


examples/step-44/doc/intro.dox

 <br> 

<i>This program was contributed by Jean-Paul Pelteret and Andrew McBride.
<br>
This material is based upon work supported by  the German Science Foundation (Deutsche
Forschungsgemeinschaft, DFG), grant STE 544/39-1,  and the National Research Foundation of South Africa.
</i>

 @dealiiTutorialDOI{10.5281/zenodo.439772,https://zenodo.org/badge/DOI/10.5281/zenodo.439772.svg} 

<a name="Intro"></a>

<h1>Introduction</h1>

本教程的主题是非线性固体力学。经典的单场方法（例如见步骤18）不能正确描述准不可压缩材料的响应。响应过于僵硬；这种现象被称为锁定。锁定问题可以通过各种替代策略来规避。其中一个策略是三场公式。在这里，它被用来模拟各向同性连续体的三维、完全非线性（几何和材料）响应。材料响应被近似为超弹性。此外，所采用的三场公式对准不可压缩和可压缩材料都有效。

本报告的目的是为使用deal.II处理非线性固体力学的问题提供基础。线性问题在步骤8中得到了解决。在第18步中部分考虑了几何非线性问题的非标准的、超弹性的形式：使用了线性化构成关系的速率形式，问题域随着运动的进行而变化。围绕非线性运动学的重要概念在理论和实施中都没有。然而，第18步确实描述了许多关键概念，以便在deal.II的框架内实现弹性。

我们从非线性运动学的速成课程开始。为了简单起见，我们将注意力限制在准静态问题上。此后，我们介绍了各种关键的应力测量，并描述了构成模型。然后，在解释用于管理材料的类的结构之前，我们详细描述了三场公式。然后介绍了例子问题的设置。

 @note  本教程是针对三维空间的弹性问题而开发的（并在介绍中进行了描述）。  虽然空间维度可以在main()例程中改变，但需要注意的是。  一般来说，二维弹性问题只是作为三维问题的理想化而存在。  也就是说，它们要么是平面应变，要么是平面应力。  这些选择中的任何一个的假设都需要被一致地施加。  更多信息请参见步骤8的说明。

<h3>List of references</h3>

这里实施的三场公式是由Simo等人（1985）开创的，被称为混合雅各布-压力公式。重要的相关贡献包括Simo和Taylor（1991）以及Miehe（1994）的贡献。这里采用的符号在很大程度上借鉴了Holzapfel（2001）对非线性固体力学理论方面的出色概述。Hughes (2000)对与不可压缩弹性（小应变时）有关的问题作了很好的概述。

<ol>  <li>  J.C. Simo, R.L. Taylor and K.S. Pister (1985), Variational and projection methods for the volume constraint in finite deformation elasto-plasticity,  <em>  Computer Methods in Applied Mechanics and Engineering  </em>  , <strong> 51</strong>, 1-3, 177-208. 		DOI: <a href="http://doi.org/10.1016/0045-7825(85)90033-7">10.1016/0045-7825(85)90033-7</a>;  <li>  J.C. Simo and R.L. Taylor (1991), Quasi-incompressible finite elasticity in principal stretches.Continuum basis and numerical algorithms,  <em>  Computer Methods in Applied Mechanics and Engineering  </em>  , <strong> 85 </strong>, 3, 273-310. 		DOI: <a href="http://doi.org/10.1016/0045-7825(91)90100-K">10.1016/0045-7825(91)90100-K</a>;  <li>  C. Miehe (1994), Aspects of the formulation and finite element implementation of large strain isotropic elasticity  <em>  International Journal for Numerical Methods in Engineering  </em>  <strong> 37 /strong>, 12, 1981-2004. 		DOI: <a href="http://doi.org/10.1002/nme.1620371202">10.1002/nme.1620371202</a>;  <li>  G.A. Holzapfel (2001), Nonlinear Solid Mechanics.A Continuum Approach for Engineering, John Wiley & Sons. 		ISBN: 0-471-82304-X;  <li>  T.J.R. Hughes (2000), The Finite Element Method:线性静态和动态有限元分析》，多佛。 		ISBN: 978-0486411811  </ol> .

<ol>  <li>  J-P. V. Pelteret, D. Davydov, A. McBride, D. K. Vu, and P. Steinmann (2016), 在一个耦合问题中使用这种三场公式的例子记录在<ol>  <li>  J-P.V. Pelteret, D. Davydov, A. McBride, D. K. Vu, and P. Steinmann (2016), Computational electro-and magneto-elasticity for quasi-incompressible media immersed in free space,  <em>  International Journal for Numerical Methods in Engineering  </em>  。 		DOI: <a href="http://doi.org/10.1002/nme.5254">10.1002/nme.5254</a>  </ol>  。

<h3> Notation </h3>

我们可以把四阶张量看作是将二阶张量（矩阵）映射到自己身上的线性算子，其方式与矩阵将向量映射到向量上一样。有各种四阶单位张量，在即将到来的介绍中会用到。四阶单位张量 $\mathcal{I}$ 和 $\overline{\mathcal{I}}$ 定义如下

@f[
	\mathbf{A} = \mathcal{I}:\mathbf{A}
		\qquad \text{and} \qquad
	\mathbf{A}^T = \overline{\mathcal{I}}:\mathbf{A} \, .


@f]

注意  $\mathcal{I} \neq \overline{\mathcal{I}}^T$  。此外，我们通过以下方式定义对称和偏斜对称的四阶单位张量

@f[
	\mathcal{S} \dealcoloneq \dfrac{1}{2}[\mathcal{I} + \overline{\mathcal{I}}]
		\qquad \text{and} \qquad
	\mathcal{W} \dealcoloneq \dfrac{1}{2}[\mathcal{I} - \overline{\mathcal{I}}] \, ,


@f]

以致于

@f[
	\dfrac{1}{2}[\mathbf{A} + \mathbf{A}^T] = \mathcal{S}:\mathbf{A}
		\qquad \text{and} \qquad
	\dfrac{1}{2}[\mathbf{A} - \mathbf{A}^T] = \mathcal{W}:\mathbf{A} \, .


@f]

identity_tensor()返回的四阶  <code>SymmetricTensor</code>  是  $\mathcal{S}$  。




<h3>Kinematics</h3>

让时间域表示为 $\mathbb{T} = [0,T_{\textrm{end}}]$  ，其中 $t \in \mathbb{T}$ 和 $T_{\textrm{end}}$ 是总的问题持续时间。考虑一个连续体，在时间 $t=0$ 占据参考配置 $\Omega_0$ 。参考配置中的%粒子由位置矢量 $\mathbf{X}$ 识别。身体在后来的时间 $t>0$ 的配置被称为当前配置，表示为 $\Omega$ ，粒子由矢量 $\mathbf{x}$ 识别。参考配置和当前配置之间的非线性映射，表示为  $\boldsymbol{\varphi}$  ，作用如下。

@f[
	\mathbf{x} = \boldsymbol{\varphi}(\mathbf{X},t) \, .


@f]

粒子的位移的材料描述被定义为

@f[
	\mathbf{U}(\mathbf{X},t) = \mathbf{x}(\mathbf{X},t) - \mathbf{X} \, .


@f]



变形梯度 $\mathbf{F}$ 被定义为运动的材料梯度。

@f[
	\mathbf{F}(\mathbf{X},t)
		\dealcoloneq \dfrac{\partial \boldsymbol{\varphi}(\mathbf{X},t)}{\partial \mathbf{X}}
		= \textrm{Grad}\ \mathbf{x}(\mathbf{X},t)
		= \mathbf{I} + \textrm{Grad}\ \mathbf{U} \, .


@f]

变形梯度 $J(\mathbf{X},t) \dealcoloneq \textrm{det}\ \mathbf{F}(\mathbf{X},t) > 0$ 的行列式在参考配置和当前配置中映射出相应的体积元素，分别表示为 $\textrm{d}V$ 和 $\textrm{d}v$  ，为

@f[
	\textrm{d}v = J(\mathbf{X},t)\; \textrm{d}V \, .


@f]



就空间和材料坐标而言，变形的两个重要度量是左和右Cauchy-Green张量，分别表示为 $\mathbf{b} \dealcoloneq \mathbf{F}\mathbf{F}^T$ 和 $\mathbf{C} \dealcoloneq \mathbf{F}^T\mathbf{F}$  。它们都是对称的和正定的。

格林-拉格朗日应变张量的定义为

@f[
	\mathbf{E} \dealcoloneq \frac{1}{2}[\mathbf{C} - \mathbf{I} ]
		= \underbrace{\frac{1}{2}[\textrm{Grad}^T \mathbf{U} +	\textrm{Grad}\mathbf{U}]}_{\boldsymbol{\varepsilon}}
			+ \frac{1}{2}[\textrm{Grad}^T\ \mathbf{U}][\textrm{Grad}\ \mathbf{U}] \, .


@f]

如果假定变形为无限小，那么右边的第二项就可以忽略， $\boldsymbol{\varepsilon}$ （线性化的应变张量）是应变张量的唯一组成部分。从问题的设置来看，这个假设在步骤18中是不成立的，这使得在该教程程序中使用线性化的 $\boldsymbol{\varepsilon}$ 作为应变度量值得怀疑。

为了处理材料在受到体积和剪切型变形时表现出的不同响应，我们考虑将变形梯度 $\mathbf{F}$ 和左Cauchy-Green张量 $\mathbf{b}$ 分解为体积变化（体积）和体积保持（等效）部分。

@f[
	\mathbf{F}
		= (J^{1/3}\mathbf{I})\overline{\mathbf{F}}
	\qquad \text{and} \qquad
	\mathbf{b}
        = (J^{2/3}\mathbf{I})\overline{\mathbf{F}}\,\overline{\mathbf{F}}^T
		=  (J^{2/3}\mathbf{I})\overline{\mathbf{b}} \, .


@f]

显然， $\textrm{det}\ \mathbf{F} = \textrm{det}\ (J^{1/3}\mathbf{I}) = J$  。

空间速度场被表示为 $\mathbf{v}(\mathbf{x},t)$  。空间速度场相对于空间坐标的导数给出空间速度梯度  $\mathbf{l}(\mathbf{x},t)$  ，即

@f[
	\mathbf{l}(\mathbf{x},t)
		\dealcoloneq \dfrac{\partial \mathbf{v}(\mathbf{x},t)}{\partial \mathbf{x}}
		= \textrm{grad}\ \mathbf{v}(\mathbf{x},t) \, ,


@f]

其中 $\textrm{grad} \{\bullet \}
= \frac{\partial \{ \bullet \} }{ \partial \mathbf{x}}
= \frac{\partial \{ \bullet \} }{ \partial \mathbf{X}}\frac{\partial \mathbf{X} }{ \partial \mathbf{x}}
= \textrm{Grad} \{ \bullet \} \mathbf{F}^{-1}$  。




<h3>Kinetics</h3>

考奇应力定理将作用在当前构型 $\mathbf{t}$ 的无穷小表面元素上的考奇牵引力 $\mathrm{d}a$ 等同于考奇应力张量 $\boldsymbol{\sigma}$ （一个空间量）与表面的外向单位法线 $\mathbf{n}$ 的积，即

@f[
	\mathbf{t}(\mathbf{x},t, \mathbf{n}) = \boldsymbol{\sigma}\mathbf{n} \, .


@f]

Cauchy应力是对称的。同样，作用于参考构型 $\mathbf{T}$ 中的无穷小表面元素的第一皮奥拉-基尔霍夫牵引力 $\mathrm{d}A$ 是第一皮奥拉-基尔霍夫应力张量 $\mathbf{P}$ （两点张量）与表面的外向单位法线 $\mathbf{N}$ 的乘积，为

@f[
	\mathbf{T}(\mathbf{X},t, \mathbf{N}) = \mathbf{P}\mathbf{N} \, .


@f]

Cauchy牵引力 $\mathbf{t}$ 和第一个Piola-Kirchhoff牵引力 $\mathbf{T}$ 的关系为

@f[
	\mathbf{t}\mathrm{d}a = \mathbf{T}\mathrm{d}A \, .


@f]

这可以用<a href="http://en.wikipedia.org/wiki/Finite_strain_theory">Nanson's formula</a>来证明。

第一个Piola-Kirchhoff应力张量与Cauchy应力的关系为

@f[
	\mathbf{P} = J \boldsymbol{\sigma}\mathbf{F}^{-T} \, .


@f]

进一步的重要应力测量是（空间）基尔霍夫应力  $\boldsymbol{\tau} = J \boldsymbol{\sigma}$  和（参考）第二Piola-Kirchhoff应力  $\mathbf{S} = {\mathbf{F}}^{-1} \boldsymbol{\tau} {\mathbf{F}}^{-T}$  。




<h3> Push-forward and pull-back operators </h3>

前推和后拉运算符允许人们在材料和空间设置之间转换各种措施。这里使用的应力测量是逆变的，而应变测量是协变的。

二阶协变张量 $(\bullet)^{\text{cov}}$ 的前推和后拉操作分别由以下方法给出。

@f[
	\chi_{*}(\bullet)^{\text{cov}} \dealcoloneq \mathbf{F}^{-T} (\bullet)^{\text{cov}} \mathbf{F}^{-1}
	\qquad \text{and} \qquad
	\chi^{-1}_{*}(\bullet)^{\text{cov}} \dealcoloneq \mathbf{F}^{T} (\bullet)^{\text{cov}} \mathbf{F} \, .


@f]



二阶禁忌张量 $(\bullet)^{\text{con}}$ 的前推和后拉操作分别由以下方法给出。

@f[
	\chi_{*}(\bullet)^{\text{con}} \dealcoloneq \mathbf{F} (\bullet)^{\text{con}} \mathbf{F}^T
	\qquad \text{and} \qquad
	\chi^{-1}_{*}(\bullet)^{\text{con}} \dealcoloneq \mathbf{F}^{-1} (\bullet)^{\text{con}} \mathbf{F}^{-T} \, .


@f]

例如  $\boldsymbol{\tau} = \chi_{*}(\mathbf{S})$  。




<h3>Hyperelastic materials</h3>

超弹性材料的响应受亥姆霍兹自由能函数 $\Psi = \Psi(\mathbf{F}) = \Psi(\mathbf{C}) = \Psi(\mathbf{b})$ 的制约，该函数作为应力的势能。例如，如果Helmholtz自由能取决于右Cauchy-Green张量 $\mathbf{C}$ ，那么各向同性的超弹性响应为

@f[
	\mathbf{S}
		= 2 \dfrac{\partial \Psi(\mathbf{C})}{\partial \mathbf{C}} \, .


@f]

如果亥姆霍兹自由能取决于左Cauchy-Green张量 $\mathbf{b}$ ，那么各向同性的超弹性响应为

@f[
	\boldsymbol{\tau}
		= 2 \dfrac{\partial \Psi(\mathbf{b})}{\partial \mathbf{b}} \mathbf{b}
		=  2 \mathbf{b} \dfrac{\partial \Psi(\mathbf{b})}{\partial \mathbf{b}} \, .


@f]



根据变形梯度的乘法分解，亥姆霍兹自由能可以分解为

@f[
	\Psi(\mathbf{b}) = \Psi_{\text{vol}}(J) + \Psi_{\text{iso}}(\overline{\mathbf{b}}) \, .


@f]

同样，基尔霍夫应力可以分解为体积部分和等效部分 $\boldsymbol{\tau} = \boldsymbol{\tau}_{\text{vol}} + \boldsymbol{\tau}_{\text{iso}}$ ，其中。

@f{align*}
	\boldsymbol{\tau}_{\text{vol}} &=
		2 \mathbf{b} \dfrac{\partial \Psi_{\textrm{vol}}(J)}{\partial \mathbf{b}}
		\\
		&= p J\mathbf{I} \, ,
		\\
	\boldsymbol{\tau}_{\text{iso}} &=
		2 \mathbf{b} \dfrac{\partial \Psi_{\textrm{iso}} (\overline{\mathbf{b}})}{\partial \mathbf{b}}
		\\
		&= \underbrace{( \mathcal{I} - \dfrac{1}{3} \mathbf{I} \otimes \mathbf{I})}_{\mathbb{P}} : \overline{\boldsymbol{\tau}} \, ,


@f}

其中 $p \dealcoloneq \dfrac{\partial \Psi_{\text{vol}}(J)}{\partial J}$ 是压力响应。   $\mathbb{P}$ 是投影张量，它提供了欧拉环境下的偏差算子。虚构的基尔霍夫应力张量 $\overline{\boldsymbol{\tau}}$ 被定义为

@f[
	\overline{\boldsymbol{\tau}}
		\dealcoloneq 2 \overline{\mathbf{b}} \dfrac{\partial \Psi_{\textrm{iso}}(\overline{\mathbf{b}})}{\partial \overline{\mathbf{b}}} \, .


@f]






 @note  上述定义的压力响应与固体力学中广泛使用的压力定义不同，即 $p = - 1/3 \textrm{tr} \boldsymbol{\sigma} = - 1/3 J^{-1} \textrm{tr} \boldsymbol{\tau}$  。这里 $p$ 是静水压力。我们在本教程中使用压力响应（尽管我们把它称为压力）。

<h4> Neo-Hookean materials </h4>

与可压缩<a href="http://en.wikipedia.org/wiki/Neo-Hookean_solid">neo-Hookean material</a>相对应的亥姆霍兹自由能由以下公式给出

@f[
    \Psi \equiv
        \underbrace{\kappa [ \mathcal{G}(J) ] }_{\Psi_{\textrm{vol}}(J)}
        + \underbrace{\bigl[c_1 [ \overline{I}_1 - 3] \bigr]}_{\Psi_{\text{iso}}(\overline{\mathbf{b}})} \, ,


@f]

其中 $\kappa \dealcoloneq \lambda + 2/3 \mu$ 是体积模量（ $\lambda$ 和 $\mu$ 是Lam&eacute; 参数）和 $\overline{I}_1 \dealcoloneq \textrm{tr}\ \overline{\mathbf{b}}$  。函数 $\mathcal{G}(J)$ 被要求是严格凸的，并满足 $\mathcal{G}(1) = 0$ 等条件，进一步的细节见Holzapfel（2001）。在这项工作中  $\mathcal{G} \dealcoloneq \frac{1}{4} [ J^2 - 1 - 2\textrm{ln}J ]$  .

不可压缩性对所有运动施加了等效约束  $J=1$  。对应于不可压缩的新胡克材料的亥姆霍兹自由能由以下公式给出

@f[
    \Psi \equiv
        \underbrace{\bigl[ c_1 [ I_1 - 3] \bigr] }_{\Psi_{\textrm{iso}}(\mathbf{b})} \, ,


@f]

其中  $ I_1 \dealcoloneq \textrm{tr}\mathbf{b} $  。因此，通过从可压缩自由能中去除体积分量并执行  $J=1$  得到不可压缩响应。




<h3>Elasticity tensors</h3>

我们将使用Newton-Raphson策略来解决非线性边界值问题。因此，我们将需要将构成关系线性化。

材料描述中的四阶弹性张量定义为

@f[
	\mathfrak{C}
		= 2\dfrac{\partial \mathbf{S}(\mathbf{C})}{\partial \mathbf{C}}
		= 4\dfrac{\partial^2 \Psi(\mathbf{C})}{\partial \mathbf{C} \partial \mathbf{C}} \, .


@f]

空间描述 $\mathfrak{c}$ 中的四阶弹性张量由 $\mathfrak{C}$ 的推演得到，为

@f[
	\mathfrak{c} = J^{-1} \chi_{*}(\mathfrak{C})
		\qquad \text{and thus} \qquad
	J\mathfrak{c} = 4 \mathbf{b} \dfrac{\partial^2 \Psi(\mathbf{b})} {\partial \mathbf{b} \partial \mathbf{b}} \mathbf{b}	\, .


@f]

四阶弹性张量（对于超弹性材料）同时拥有主要和次要的对称性。

四阶空间弹性张量可以写成以下解耦形式。

@f[
	\mathfrak{c} = \mathfrak{c}_{\text{vol}} + \mathfrak{c}_{\text{iso}} \, ,


@f]

其中

@f{align*}
	J \mathfrak{c}_{\text{vol}}
		&= 4 \mathbf{b} \dfrac{\partial^2 \Psi_{\text{vol}}(J)} {\partial \mathbf{b} \partial \mathbf{b}} \mathbf{b}
		\\
		&= J[\widehat{p}\, \mathbf{I} \otimes \mathbf{I} - 2p \mathcal{I}]
			\qquad \text{where} \qquad
		\widehat{p} \dealcoloneq p + \dfrac{\textrm{d} p}{\textrm{d}J} \, ,
		\\
	J \mathfrak{c}_{\text{iso}}
		&=  4 \mathbf{b} \dfrac{\partial^2 \Psi_{\text{iso}}(\overline{\mathbf{b}})} {\partial \mathbf{b} \partial \mathbf{b}} \mathbf{b}
		\\
		&= \mathbb{P} : \mathfrak{\overline{c}} : \mathbb{P}
			+ \dfrac{2}{3}[\overline{\boldsymbol{\tau}}:\mathbf{I}]\mathbb{P}


			- \dfrac{2}{3}[ \mathbf{I}\otimes\boldsymbol{\tau}_{\text{iso}}
				+ \boldsymbol{\tau}_{\text{iso}} \otimes \mathbf{I} ] \, ,


@f}

其中空间描述中的虚构弹性张量 $\overline{\mathfrak{c}}$ 被定义为

@f[
	\overline{\mathfrak{c}}
		= 4 \overline{\mathbf{b}} \dfrac{ \partial^2 \Psi_{\textrm{iso}}(\overline{\mathbf{b}})} {\partial \overline{\mathbf{b}} \partial \overline{\mathbf{b}}} \overline{\mathbf{b}} \, .


@f]



<h3>Principle of stationary potential energy and the three-field formulation</h3>

系统的总势能 $\Pi$ 是内部和外部势能之和，分别表示为 $\Pi_{\textrm{int}}$ 和 $\Pi_{\textrm{ext}}$  。我们希望通过最小化势能找到平衡配置。

如上所述，我们采用了三场的表述。我们用 $\mathbf{\Xi} \dealcoloneq \{ \mathbf{u}, \widetilde{p}, \widetilde{J} \}$ 表示主要未知数的集合。独立运动学变量 $\widetilde{J}$ 作为对 $J$ 的约束进入公式，由拉格朗日乘数 $\widetilde{p}$ （压力，我们将看到）强制执行。

这里使用的三场变分原理由以下公式给出

@f[
	\Pi(\mathbf{\Xi}) \dealcoloneq \int_\Omega \bigl[
		\Psi_{\textrm{vol}}(\widetilde{J})
		+ \widetilde{p}\,[J(\mathbf{u}) - \widetilde{J}]
		+ \Psi_{\textrm{iso}}(\overline{\mathbf{b}}(\mathbf{u}))
		\bigr] \textrm{d}v
	+ 	\Pi_{\textrm{ext}} \, ,


@f]

其中外部电势的定义为

@f[
	\Pi_{\textrm{ext}}
		= - \int_\Omega \mathbf{b}^\text{p} \cdot \mathbf{u}~\textrm{d}v


			- \int_{\partial \Omega_{\sigma}} \mathbf{t}^\text{p} \cdot \mathbf{u}~\textrm{d}a \, .


@f]

当前配置 $\partial \Omega$ 的边界由两部分组成： $\partial \Omega = \partial \Omega_{\mathbf{u}} \cup \partial \Omega_{\sigma}$  ，其中 $\partial \Omega_{\mathbf{u}} \cap \partial \Omega_{\boldsymbol{\sigma}} = \emptyset$  。规定的Cauchy牵引力，表示为  $\mathbf{t}^\text{p}$  ，被应用于  $ \partial \Omega_{\boldsymbol{\sigma}}$  ，而运动被规定在边界的其余部分  $\partial \Omega_{\mathbf{u}}$  。每单位电流体积的体力表示为  $\mathbf{b}^\text{p}$  。




势的静止性如下

@f{align*}
	R(\mathbf\Xi;\delta \mathbf{\Xi})
		&= D_{\delta \mathbf{\Xi}}\Pi(\mathbf{\Xi})
		\\
		&= \dfrac{\partial \Pi(\mathbf{\Xi})}{\partial \mathbf{u}} \cdot \delta \mathbf{u}
			+ \dfrac{\partial \Pi(\mathbf{\Xi})}{\partial \widetilde{p}} \delta \widetilde{p}
			+ \dfrac{\partial \Pi(\mathbf{\Xi})}{\partial \widetilde{J}} \delta \tilde{J}
			\\
		&= \int_{\Omega_0}  \left[
			\textrm{grad}\ \delta\mathbf{u} : [ \underbrace{[\widetilde{p} J \mathbf{I}]}_{\equiv \boldsymbol{\tau}_{\textrm{vol}}}
            +  \boldsymbol{\tau}_{\textrm{iso}}]
			+ \delta \widetilde{p}\, [ J(\mathbf{u}) - \widetilde{J}]
			+ \delta \widetilde{J}\left[ \dfrac{\textrm{d} \Psi_{\textrm{vol}}(\widetilde{J})}{\textrm{d} \widetilde{J}}


            -\widetilde{p}\right]
			\right]~\textrm{d}V
			\\
		&\quad - \int_{\Omega_0} \delta \mathbf{u} \cdot \mathbf{B}^\text{p}~\textrm{d}V


			- \int_{\partial \Omega_{0,\boldsymbol{\sigma}}} \delta \mathbf{u} \cdot \mathbf{T}^\text{p}~\textrm{d}A
			\\
		&=0 \, ,


@f}

对于所有虚拟位移 $\delta \mathbf{u} \in H^1(\Omega)$ ，受 $\delta \mathbf{u} = \mathbf{0}$ 对 $\partial \Omega_{\mathbf{u}}$ 的约束，以及所有虚拟压力 $\delta \widetilde{p} \in L^2(\Omega)$ 和虚拟膨胀 $\delta \widetilde{J} \in L^2(\Omega)$ 。

人们应该注意到，在三个场的表述中 $\boldsymbol{\tau}_{\textrm{vol}} \equiv \widetilde{p} J \mathbf{I}$ ，体积基尔霍夫应力的定义和随后的体积正切与超弹性材料一节中给出的一般形式略有不同，其中 $\boldsymbol{\tau}_{\textrm{vol}} \equiv p J\mathbf{I}$ 。这是因为压力 $\widetilde{p}$ 现在是一个主要的场，而不是一个构成性的派生量。我们需要仔细区分主要场和从构成关系中得到的场。

 @note  虽然变量都是用空间量来表示的，但积分的领域是初始配置。这种方法被称为  <em>  总拉格朗日公式  </em>  。在步骤18中给出的方法，其积分域是当前配置，可以称为  <em>  更新的拉格朗日公式  </em>  。这两种方法的各种优点在文献中被广泛讨论。然而，应该指出的是，它们是等同的。


与残留物相对应的欧拉-拉格朗日方程为：。

@f{align*}
	&\textrm{div}\ \boldsymbol{\sigma} + \mathbf{b}^\text{p} = \mathbf{0} && \textrm{[equilibrium]}
		\\
	&J(\mathbf{u}) = \widetilde{J} 		&& \textrm{[dilatation]}
		\\
	&\widetilde{p} = \dfrac{\textrm{d} \Psi_{\textrm{vol}}(\widetilde{J})}{\textrm{d} \widetilde{J}} && \textrm{[pressure]} \, .


@f}

第一个方程是空间设置中的（准静态）平衡方程。第二个是约束条件  $J(\mathbf{u}) = \widetilde{J}$  。第三个是压力的定义  $\widetilde{p}$  。

 @note 下面的简化单场推导（ $\mathbf{u}$ 是唯一的主变量）使我们清楚地知道如何将积分的极限转化为参考域。

@f{align*}
\int_{\Omega}\delta \mathbf{u} \cdot [\textrm{div}\ \boldsymbol{\sigma} + \mathbf{b}^\text{p}]~\mathrm{d}v
&=
\int_{\Omega} [-\mathrm{grad}\delta \mathbf{u}:\boldsymbol{\sigma} + \delta \mathbf{u} \cdot\mathbf{b}^\text{p}]~\mathrm{d}v
  + \int_{\partial \Omega} \delta \mathbf{u} \cdot \mathbf{t}^\text{p}~\mathrm{d}a \\
&=


- \int_{\Omega_0} \mathrm{grad}\delta \mathbf{u}:\boldsymbol{\tau}~\mathrm{d}V
+ \int_{\Omega_0} \delta \mathbf{u} \cdot J\mathbf{b}^\text{p}~\mathrm{d}V
 + \int_{\partial \Omega_0} \delta \mathbf{u} \cdot \mathbf{T}^\text{p}~\mathrm{d}A \\
&=


- \int_{\Omega_0} \mathrm{grad}\delta \mathbf{u}:\boldsymbol{\tau}~\mathrm{d}V
+ \int_{\Omega_0} \delta \mathbf{u} \cdot \mathbf{B}^\text{p}~\mathrm{d}V
 + \int_{\partial \Omega_{0,\sigma}} \delta \mathbf{u} \cdot \mathbf{T}^\text{p}~\mathrm{d}A \\
&=


- \int_{\Omega_0} [\mathrm{grad}\delta\mathbf{u}]^{\text{sym}} :\boldsymbol{\tau}~\mathrm{d}V
+ \int_{\Omega_0} \delta \mathbf{u} \cdot \mathbf{B}^\text{p}~\mathrm{d}V
 + \int_{\partial \Omega_{0,\sigma}} \delta \mathbf{u} \cdot \mathbf{T}^\text{p}~\mathrm{d}A \, ,


@f}

其中 $[\mathrm{grad}\delta\mathbf{u}]^{\text{sym}} = 1/2[ \mathrm{grad}\delta\mathbf{u} + [\mathrm{grad}\delta\mathbf{u}]^T] $  。

我们将使用迭代牛顿-拉弗森方法来解决非线性剩余方程  $R$  。为了简单起见，我们假设死荷载，即荷载不因变形而改变。

在  $t_{\textrm{n}-1}$  的已知状态和  $t_{\textrm{n}}$  的当前未知状态之间的数量变化被表示为  $\varDelta \{ \bullet \} = { \{ \bullet \} }^{\textrm{n}} - { \{ \bullet \} }^{\textrm{n-1}}$  。在当前迭代 $\textrm{i}$ 的数量值表示为  ${ \{ \bullet \} }^{\textrm{n}}_{\textrm{i}} = { \{ \bullet \} }_{\textrm{i}}$  。迭代  $\textrm{i}$  和  $\textrm{i}+1$  之间的增量变化被表示为  $d \{ \bullet \} \dealcoloneq \{ \bullet \}_{\textrm{i}+1} - \{ \bullet \}_{\textrm{i}}$  。

假设系统的状态在某个迭代中是已知的  $\textrm{i}$  。用牛顿-拉弗森方法求解的非线性治理方程的线性化近似值是：找到  $d \mathbf{\Xi}$  ，以便

@f[
	R(\mathbf{\Xi}_{\mathsf{i}+1}) =
		R(\mathbf{\Xi}_{\mathsf{i}})
		+ D^2_{d \mathbf{\Xi}, \delta \mathbf{\Xi}} \Pi(\mathbf{\Xi_{\mathsf{i}}}) \cdot d \mathbf{\Xi} \equiv 0 \, ,


@f]

然后设置  $\mathbf{\Xi}_{\textrm{i}+1} = \mathbf{\Xi}_{\textrm{i}}
+ d \mathbf{\Xi}$  。切线由以下公式给出

@f[
	D^2_{d \mathbf{\Xi}, \delta \mathbf{\Xi}} \Pi( \mathbf{\Xi}_{\mathsf{i}} )
		= D_{d \mathbf{\Xi}} R( \mathbf{\Xi}_{\mathsf{i}}; \delta \mathbf{\Xi})
		=: K(\mathbf{\Xi}_{\mathsf{i}}; d \mathbf{\Xi}, \delta \mathbf{\Xi}) \, .


@f]

因此。

@f{align*}
 	K(\mathbf{\Xi}_{\mathsf{i}}; d \mathbf{\Xi}, \delta \mathbf{\Xi})
 		&=
 			D_{d \mathbf{u}} R( \mathbf{\Xi}_{\mathsf{i}}; \delta \mathbf{\Xi}) \cdot d \mathbf{u}
 			\\
 				&\quad +
 			 	D_{d \widetilde{p}} R( \mathbf{\Xi}_{\mathsf{i}}; \delta \mathbf{\Xi})  d \widetilde{p}
 			 \\
 			 	&\quad +
 			  D_{d \widetilde{J}} R( \mathbf{\Xi}_{\mathsf{i}}; \delta \mathbf{\Xi})  d \widetilde{J} \, ,


@f}

其中

@f{align*}
	D_{d \mathbf{u}} R( \mathbf{\Xi}; \delta \mathbf{\Xi})
 	&=
 	\int_{\Omega_0} \bigl[ \textrm{grad}\ \delta \mathbf{u} :
 			\textrm{grad}\ d \mathbf{u} [\boldsymbol{\tau}_{\textrm{iso}} + \boldsymbol{\tau}_{\textrm{vol}}]
 			+ \textrm{grad}\ \delta \mathbf{u} :[
             \underbrace{[\widetilde{p}J[\mathbf{I}\otimes\mathbf{I} - 2 \mathcal{I}]}_{\equiv J\mathfrak{c}_{\textrm{vol}}} +
             J\mathfrak{c}_{\textrm{iso}}] :\textrm{grad} d \mathbf{u}
 		\bigr]~\textrm{d}V \, ,
 		\\
 	&\quad + \int_{\Omega_0} \delta \widetilde{p} J \mathbf{I} : \textrm{grad}\ d \mathbf{u} ~\textrm{d}V
 	\\
 	D_{d \widetilde{p}} R( \mathbf{\Xi}; \delta \mathbf{\Xi})
 	&=
 	\int_{\Omega_0} \textrm{grad}\ \delta \mathbf{u} : J \mathbf{I} d \widetilde{p} ~\textrm{d}V


 		-  \int_{\Omega_0} \delta \widetilde{J} d \widetilde{p}  ~\textrm{d}V \, ,
 	\\
 	D_{d \widetilde{J}} R( \mathbf{\Xi}; \delta \mathbf{\Xi})
 	&=  -\int_{\Omega_0} \delta \widetilde{p} d \widetilde{J}~\textrm{d}V
 	 + \int_{\Omega_0} \delta \widetilde{J}  \dfrac{\textrm{d}^2 \Psi_{\textrm{vol}}(\widetilde{J})}{\textrm{d} \widetilde{J}\textrm{d}\widetilde{J}} d \widetilde{J} ~\textrm{d}V \, .


@f}



注意，以下条款被称为几何应力和材料对切线矩阵的贡献。

@f{align*}
& \int_{\Omega_0} \textrm{grad}\ \delta \mathbf{u} :
 			\textrm{grad}\ d \mathbf{u} [\boldsymbol{\tau}_{\textrm{iso}} +  \boldsymbol{\tau}_{\textrm{vol}}]~\textrm{d}V
 			&& \quad {[\textrm{Geometrical stress}]} \, ,
 		\\
& \int_{\Omega_0} \textrm{grad} \delta \mathbf{u} :
 			[J\mathfrak{c}_{\textrm{vol}} + J\mathfrak{c}_{\textrm{iso}}] :\textrm{grad}\ d \mathbf{u}
 		~\textrm{d}V
 		&& \quad {[\textrm{Material}]} \, .


@f}






<h3> Discretization of governing equations </h3>

这里使用的三场公式对准不可压缩材料是有效的，即在 $\nu \rightarrow 0.5$ （其中 $\nu$ 是<a
href="http://en.wikipedia.org/wiki/Poisson's_ratio">Poisson's ratio</a>）的地方，要很好地选择 $\mathbf{u},~\widetilde{p}$ 和 $\widetilde{J}$ 的插值场。通常情况下，选择 $Q_n \times DGPM_{n-1} \times DGPM_{n-1}$ 。这里 $DGPM$ 是FE_DGPMonomial类。一个流行的选择是 $Q_1 \times DGPM_0 \times DGPM_0$ ，它被称为平均扩张法（见Hughes（2000）的直观讨论）。这个代码可以容纳 $Q_n \times DGPM_{n-1} \times DGPM_{n-1}$ 的表述。不连续的近似允许 $\widetilde{p}$ 和 $\widetilde{J}$ 被浓缩出来，并恢复了基于位移的经典方法。

对于完全不可压缩的材料 $\nu = 0.5$ 和三场公式仍将表现出锁定行为。这可以通过在自由能中引入一个额外的约束条件来克服，其形式为  $\int_{\Omega_0} \Lambda [ \widetilde{J} - 1]~\textrm{d}V$  。这里 $\Lambda$ 是一个拉格朗日乘数，用于强制执行等时约束条件。进一步的细节见Miehe (1994)。

线性化的问题可以写成

@f[
	\mathbf{\mathsf{K}}( \mathbf{\Xi}_{\textrm{i}}) d\mathbf{\Xi}
	=
	\mathbf{ \mathsf{F}}(\mathbf{\Xi}_{\textrm{i}})


@f]

其中

@f{align*}
		\underbrace{\begin{bmatrix}
			\mathbf{\mathsf{K}}_{uu}	&	\mathbf{\mathsf{K}}_{u\widetilde{p}}	& \mathbf{0}
			\\
			\mathbf{\mathsf{K}}_{\widetilde{p}u}	&	\mathbf{0}	&	\mathbf{\mathsf{K}}_{\widetilde{p}\widetilde{J}}
			\\
			\mathbf{0}	& 	\mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{p}}		& \mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{J}}
		\end{bmatrix}}_{\mathbf{\mathsf{K}}(\mathbf{\Xi}_{\textrm{i}})}
		\underbrace{\begin{bmatrix}
			d \mathbf{\mathsf{u}}\\
            d \widetilde{\mathbf{\mathsf{p}}} \\
            d \widetilde{\mathbf{\mathsf{J}}}
		\end{bmatrix}}_{d \mathbf{\Xi}}
        =
        \underbrace{\begin{bmatrix}


			-\mathbf{\mathsf{R}}_{u}(\mathbf{u}_{\textrm{i}}) \\


            -\mathbf{\mathsf{R}}_{\widetilde{p}}(\widetilde{p}_{\textrm{i}}) \\


           -\mathbf{\mathsf{R}}_{\widetilde{J}}(\widetilde{J}_{\textrm{i}})
		\end{bmatrix}}_{ -\mathbf{\mathsf{R}}(\mathbf{\Xi}_{\textrm{i}}) }
=
        \underbrace{\begin{bmatrix}
			\mathbf{\mathsf{F}}_{u}(\mathbf{u}_{\textrm{i}}) \\
            \mathbf{\mathsf{F}}_{\widetilde{p}}(\widetilde{p}_{\textrm{i}}) \\
           \mathbf{\mathsf{F}}_{\widetilde{J}}(\widetilde{J}_{\textrm{i}})
		\end{bmatrix}}_{ \mathbf{\mathsf{F}}(\mathbf{\Xi}_{\textrm{i}}) } \, .


@f}



在配方中没有压力和膨胀（主要）变量的导数存在。因此，压力和膨胀的不连续有限元插值产生了 $\mathbf{\mathsf{K}}_{\widetilde{p}\widetilde{J}}$ 、 $\mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{p}}$ 和 $\mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{J}}$ 的块对角矩阵。因此，我们可以很容易地表达每个单元上的场 $\widetilde{p}$ 和 $\widetilde{J}$ ，只需倒置一个局部矩阵并乘以局部右手。然后我们可以将结果插入其余的方程中，并恢复一个经典的基于位移的方法。为了在元素水平上凝结出压力和膨胀的贡献，我们需要以下结果。

@f{align*}
		d \widetilde{\mathbf{\mathsf{p}}}
		& = \mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{p}}^{-1} \bigl[
			 \mathbf{\mathsf{F}}_{\widetilde{J}}


			 - \mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{J}} d \widetilde{\mathbf{\mathsf{J}}} \bigr]
			\\
		d \widetilde{\mathbf{\mathsf{J}}}
		& = \mathbf{\mathsf{K}}_{\widetilde{p}\widetilde{J}}^{-1} \bigl[
			\mathbf{\mathsf{F}}_{\widetilde{p}}


			- \mathbf{\mathsf{K}}_{\widetilde{p}u} d \mathbf{\mathsf{u}}
			\bigr]
		\\
		 \Rightarrow d \widetilde{\mathbf{\mathsf{p}}}
		&=  \mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{p}}^{-1} \mathbf{\mathsf{F}}_{\widetilde{J}}


		- \underbrace{\bigl[\mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{p}}^{-1} \mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{J}}
		\mathbf{\mathsf{K}}_{\widetilde{p}\widetilde{J}}^{-1}\bigr]}_{\overline{\mathbf{\mathsf{K}}}}\bigl[ \mathbf{\mathsf{F}}_{\widetilde{p}}


 		- \mathbf{\mathsf{K}}_{\widetilde{p}u} d \mathbf{\mathsf{u}} \bigr]


@f}

因此

@f[
		\underbrace{\bigl[ \mathbf{\mathsf{K}}_{uu} + \overline{\overline{\mathbf{\mathsf{K}}}}~ \bigr]
		}_{\mathbf{\mathsf{K}}_{\textrm{con}}} d \mathbf{\mathsf{u}}
		=
        \underbrace{
		\Bigl[
		\mathbf{\mathsf{F}}_{u}


			- \mathbf{\mathsf{K}}_{u\widetilde{p}} \bigl[ \mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{p}}^{-1} \mathbf{\mathsf{F}}_{\widetilde{J}}


			- \overline{\mathbf{\mathsf{K}}}\mathbf{\mathsf{F}}_{\widetilde{p}} \bigr]
		\Bigr]}_{\mathbf{\mathsf{F}}_{\textrm{con}}}


@f]

其中

@f[
		\overline{\overline{\mathbf{\mathsf{K}}}} \dealcoloneq
			\mathbf{\mathsf{K}}_{u\widetilde{p}} \overline{\mathbf{\mathsf{K}}} \mathbf{\mathsf{K}}_{\widetilde{p}u} \, .


@f]

请注意，由于 $\widetilde{p}$ 和 $\widetilde{J}$ 选择的是元素层面的不连续，所有需要反转的矩阵都是在元素层面定义的。

构建各种贡献的程序如下。

- 构建  $\mathbf{\mathsf{K}}$  。

- 形成  $\mathbf{\mathsf{K}}_{\widetilde{p}\widetilde{J}}^{-1}$  的元素，并存储在  $\mathbf{\mathsf{K}}_{\widetilde{p}\widetilde{J}}$  中的  $\mathbf{\mathsf{K}}$  。

- 形成 $\overline{\overline{\mathbf{\mathsf{K}}}}$ 并添加到 $\mathbf{\mathsf{K}}_{uu}$ ，得到 $\mathbf{\mathsf{K}}_{\textrm{con}}$ 。

- 修改后的系统矩阵被称为  ${\mathbf{\mathsf{K}}}_{\textrm{store}}$  。   也就是@f[
        \mathbf{\mathsf{K}}_{\textrm{store}}
\dealcoloneq
        \begin{bmatrix}
			\mathbf{\mathsf{K}}_{\textrm{con}}	&	\mathbf{\mathsf{K}}_{u\widetilde{p}}	& \mathbf{0}
			\\
			\mathbf{\mathsf{K}}_{\widetilde{p}u}	&	\mathbf{0}	&	\mathbf{\mathsf{K}}_{\widetilde{p}\widetilde{J}}^{-1}
			\\
			\mathbf{0}	& 	\mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{p}}		& \mathbf{\mathsf{K}}_{\widetilde{J}\widetilde{J}}
		\end{bmatrix} \, .
  @f] 。






<h3> The material class </h3>

一个好的面向对象的材料类的设计将有利于本教程扩展到广泛的材料类型。在本教程中，我们只有一个名为Material_Compressible_Neo_Hook_Three_Field的材料类。理想情况下，这个类会派生自超弹性材料（HyperelasticMaterial），而超弹性材料会派生自基类Material。这里使用的三场性质的表述也使问题复杂化。

三场公式的亥姆霍兹自由能函数为  $\Psi = \Psi_\text{vol}(\widetilde{J}) + \Psi_\text{iso}(\overline{\mathbf{b}})$  。Kirchhoff应力的等效部分 ${\boldsymbol{\tau}}_{\text{iso}}(\overline{\mathbf{b}})$ 与使用超弹性材料的单场公式得到的相同。然而，自由能的体积部分现在是一个主要变量的函数  $\widetilde{J}$  。因此，对于三场公式来说，基尔霍夫应力 ${\boldsymbol{\tau}}_{\text{vol}}$ 的体积部分的构成反应（和正切）并不像单场公式那样由超弹性构成法给出。我们可以将术语 $\boldsymbol{\tau}_{\textrm{vol}} \equiv \widetilde{p} J \mathbf{I}$ 标记为体积基尔霍夫应力，但压力 $\widetilde{p}$ 不是由自由能得出的；它是一个主场。

为了有一个灵活的方法，我们决定Material_Compressible_Neo_Hook_Three_Field仍然能够计算并返回一个体积Kirchhoff应力和正切。为了做到这一点，我们选择在与正交点相关的Material_Compressible_Neo_Hook_Three_Field类中存储插值的主域 $\widetilde{p}$ 和 $\widetilde{J}$ 。这个决定应该在以后的阶段，当教程扩展到考虑其他材料时，再重新审视。




<h3> Numerical example </h3>

这里考虑的数值例子是一个压缩下的几乎不可压缩的块。这个基准问题取自

- S. Reese, P. Wriggers, B.D. Reddy (2000), A new locking-free brick element technique for large deformation problems in elasticity,  <em>  Computers and Structures  </em>  , <strong> 75</strong>, 291-304.   DOI:<a href="http://doi.org/10.1016/S0045-7949(99)00137-6">10.1016/S0045-7949(99)00137-6</a>。

   <img src="https://www.dealii.org/images/steps/developer/step-44.setup.png" alt=""> 

该材料是具有<a href="http://en.wikipedia.org/wiki/Shear_modulus">shear modulus</a> $\mu = 80.194e6$ 和 $\nu = 0.4999$ 的准不可压缩的新胡克式。对于这样一个材料特性的选择，传统的单场 $Q_1$ 方法将锁定。也就是说，响应会过于僵硬。初始和最终配置显示在上面的图片中。利用对称性，我们只求解四分之一的几何体（即一个尺寸为 $0.001$ 的立方体）。域的上表面的内四分之一受到 $p_0$ 的载荷。


examples/step-44/doc/results.dox



<h1>Results</h1>

首先，我们提出了一系列3维结果与文献中的结果的比较（见Reese等人(2000)），以证明该程序按预期工作。

我们首先比较了 $Q_1-DGPM_0-DGPM_0$ 和 $Q_2-DGPM_1-DGPM_1$ 公式的网格细化的收敛性，如下图所总结的。块的上表面的中点的垂直位移被用来评估收敛性。对于不同的载荷参数 $p/p_0$ 值，两种方案都表现出良好的收敛特性。这些结果与文献中的结果一致。低阶公式通常高估了低层次细化的位移，而高阶插值方案则低估了位移，但程度较轻。这个基准，以及其他一系列没有在这里显示的基准，使我们相信代码在正常工作。

 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
     <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q1-P0_convergence.png" alt="">
	<p align="center">
        Convergence of the $Q_1-DGPM_0-DGPM_0$ formulation in 3-d.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q2-P1_convergence.png" alt="">
	<p align="center">
        Convergence of the $Q_2-DGPM_1-DGPM_1$ formulation in 3-d.
	</p>
    </td>
  </tr>
</table> 


下面是运行该问题产生的典型屏幕输出。所展示的特殊情况是 $Q_2-DGPM_1-DGPM_1$ 公式的情况。很明显，使用Newton-Raphson方法，可以得到二次收敛的解决方案。在所有的时间步长中，解的收敛是在5个牛顿增量内实现的。收敛后的位移的 $L_2$ -norm比几何尺度小几个数量级。

@code
Grid:
	 Reference volume: 1e-09
Triangulation:
	 Number of active cells: 64
	 Number of degrees of freedom: 2699
    Setting up quadrature point data...


Timestep 1 @ 0.1s
___________________________________________________________________________________________________________________________________________________________
                 SOLVER STEP                   |  LIN_IT   LIN_RES    RES_NORM     RES_U     RES_P      RES_J     NU_NORM      NU_U       NU_P       NU_J
___________________________________________________________________________________________________________________________________________________________
  0  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     786  2.118e-06  1.000e+00  1.000e+00  0.000e+00  0.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00
  1  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     552  1.031e-03  8.563e-02  8.563e-02  9.200e-13  3.929e-08  1.060e-01  3.816e-02  1.060e-01  1.060e-01
  2  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     667  5.602e-06  2.482e-03  2.482e-03  3.373e-15  2.982e-10  2.936e-03  2.053e-04  2.936e-03  2.936e-03
  3  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     856  6.469e-10  2.129e-06  2.129e-06  2.245e-19  1.244e-13  1.887e-06  7.289e-07  1.887e-06  1.887e-06
  4  ASM_R  CONVERGED!
___________________________________________________________________________________________________________________________________________________________
Relative errors:
Displacement:	7.289e-07
Force: 		2.451e-10
Dilatation:	1.353e-07
v / V_0:	1.000e-09 / 1.000e-09 = 1.000e+00



[...]


Timestep 10 @ 1.000e+00s
___________________________________________________________________________________________________________________________________________________________
                 SOLVER STEP                   |  LIN_IT   LIN_RES    RES_NORM     RES_U     RES_P      RES_J     NU_NORM      NU_U       NU_P       NU_J
___________________________________________________________________________________________________________________________________________________________
  0  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     874  2.358e-06  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00
  1  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     658  2.942e-04  1.544e-01  1.544e-01  1.208e+13  1.855e+06  6.014e-02  7.398e-02  6.014e-02  6.014e-02
  2  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     790  2.206e-06  2.908e-03  2.908e-03  7.302e+10  2.067e+03  2.716e-03  1.433e-03  2.716e-03  2.717e-03
  3  ASM_R  ASM_K  CST  ASM_SC  SLV  PP  UQPH  |     893  2.374e-09  1.919e-06  1.919e-06  4.527e+07  4.100e+00  1.672e-06  6.842e-07  1.672e-06  1.672e-06
  4  ASM_R  CONVERGED!
___________________________________________________________________________________________________________________________________________________________
Relative errors:
Displacement:	6.842e-07
Force: 		8.995e-10
Dilatation:	1.528e-06
v / V_0:	1.000e-09 / 1.000e-09 = 1.000e+00
@endcode






使用定时器类，我们可以分辨出代码的哪些部分需要最高的计算费用。对于一个有大量自由度的案例（即高度精细化），下面给出了定时器的典型输出。本教程中的大部分代码都是基于Step-18和其他文章中描述、讨论和演示的优化而开发的。超过93%的时间花在线性求解器上，很明显，对于大型三维问题，可能有必要投资一个更好的求解器。SSOR预处理程序不是多线程的，但对于这类实体问题是有效的。研究使用另一种求解器，如通过Trilinos库提供的求解器，可能是有益的。




@code
+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    | 9.874e+02s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble system right-hand side |        53 | 1.727e+00s |  1.75e-01% |
| Assemble tangent matrix         |        43 | 2.707e+01s |  2.74e+00% |
| Linear solver                   |        43 | 9.248e+02s |  9.37e+01% |
| Linear solver postprocessing    |        43 | 2.743e-02s |  2.78e-03% |
| Perform static condensation     |        43 | 1.437e+01s |  1.46e+00% |
| Setup system                    |         1 | 3.897e-01s |  3.95e-02% |
| Update QPH data                 |        43 | 5.770e-01s |  5.84e-02% |
+---------------------------------+-----------+------------+------------+
@endcode




然后我们用ParaView对两种情况的结果进行了可视化。第一个是最粗的网格和最低阶插值方法。   $Q_1-DGPM_0-DGPM_0$  .第二种是在细化网格上使用 $Q_2-DGPM_1-DGPM_1$ 公式。位移的垂直分量、压力 $\widetilde{p}$ 和扩张 $\widetilde{J}$ 场显示如下。


对于第一种情况，很明显，粗略的空间离散化加上大位移导致了低质量的解决方案（加载比为 $p/p_0=80$ ）。此外，元素之间的压力差非常大。元素上的恒定压力场意味着大的压力梯度没有被捕获。然而，应该注意的是，即使在这种离散性差的情况下，在标准 $Q_1$ 位移公式中会出现的锁定现象也不会出现。块体顶面的跟踪节点的最终垂直位移仍在收敛解的12.5%以内。压力解决方案是非常粗略的，在相邻的单元之间有很大的跳跃。很明显，离施加的牵引力最近的体积经历了压缩，而域的外延则处于膨胀状态。膨胀解场和压力场明显相关，正的膨胀表示正压区域，负的表示压缩区域。正如介绍中所讨论的，压缩性压力有一个负号，而扩张性压力有一个正号。这源于体积应变能量函数的定义，与压力的物理现实的解释相反。


 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q1-P0_gr_1_p_ratio_80-displacement.png" alt="">
	<p align="center">
        Z-displacement solution for the 3-d problem.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q1-P0_gr_1_p_ratio_80-pressure.png" alt="">
	<p align="center">
        Discontinuous piece-wise constant pressure field.
	</p>
    </td>
     <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q1-P0_gr_1_p_ratio_80-dilatation.png" alt="">
	<p align="center">
        Discontinuous piece-wise constant dilatation field.
	</p>
    </td>
  </tr>
</table> 

结合空间细化和高阶插值方案，产生了高质量的解决方案。三个网格细化加上 $Q_2-DGPM_1-DGPM_1$ 公式产生的结果清楚地抓住了问题的力学原理。牵引面的变形得到了很好的解决。我们现在可以观察到所施加的牵引力的实际范围，最大的力被施加在表面的中心点，导致最大的压缩。尽管领域中出现了很高的应变，特别是在施加牵引力的区域的边界，但解决方案仍然是准确的。压力场被捕捉到的细节比以前多得多。压缩和膨胀区域之间有明显的区别和过渡，压力场的线性近似允许在子元素尺度上对压力进行精细的可视化。然而，应该注意的是，压力场仍然是不连续的，可以在一个连续的网格上进行平滑处理，以达到后期处理的目的。




 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q2-P1_gr_3_p_ratio_80-displacement.png" alt="">
	<p align="center">
        Z-displacement solution for the 3-d problem.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q2-P1_gr_3_p_ratio_80-pressure.png" alt="">
	<p align="center">
        Discontinuous linear pressure field.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Q2-P1_gr_3_p_ratio_80-dilatation.png" alt="">
	<p align="center">
        Discontinuous linear dilatation field.
	</p>
    </td>
  </tr>
</table> 

这一简要的分析结果表明，三场公式能够有效地规避高度不可压缩介质的体积锁定。混合配方能够准确模拟近乎不可压缩的块体在压缩状态下的位移。命令行输出显示，在极度压缩下的体积变化导致泊松比为0.4999的体积变化小于0.01%。

在运行时间方面，对于类似的自由度数量， $Q_2-DGPM_1-DGPM_1$ 公式往往比 $Q_1-DGPM_0-DGPM_0$ 的计算成本更高（通过为低阶插值增加一个额外的网格细化级别产生）。下图显示了在一台4核（8线程）机器上连续运行的一批测试的情况。高阶方法计算时间的增加可能是由于高阶元素所需的带宽增加。如前所述，使用更好的求解器和预处理程序可以减轻使用高阶公式的费用。据观察，对于给定的问题，与单线程的SSOR预处理程序相比，使用多线程的Jacobi预处理程序可以减少72%的计算运行时间（在最坏的情况下是具有大量自由度的高阶公式）。然而，根据作者的经验，雅可比预处理方法可能不适合某些涉及替代构成模型的有限应变问题。


 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
     <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.Normalised_runtime.png" alt="">
	<p align="center">
        Runtime on a 4-core machine, normalised against the lowest grid resolution $Q_1-DGPM_0-DGPM_0$ solution that utilised a SSOR preconditioner.
	</p>
    </td>
  </tr>
</table> 


最后，下面展示了两个不同级别的网格细化的2维问题的位移解决方案的结果。很明显，由于二维模拟的额外约束，所产生的位移场虽然在质量上相似，但与三维模拟的情况不同。


 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.2d-gr_2.png" alt="">
	<p align="center">
        Y-displacement solution in 2-d for 2 global grid refinement levels.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-44.2d-gr_5.png" alt="">
	<p align="center">
        Y-displacement solution in 2-d for 5 global grid refinement levels.
	</p>
    </td>
  </tr>
</table> 

<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

这项工作有许多明显的延伸。

- 首先，可以在自由能函数中加入一个额外的约束条件，以便在材料中强制执行高度的不可压缩性。一个额外的拉格朗日乘数将被引入，但这可以最容易地使用增强的拉格朗日乘数的原则来处理。这在  <em>  Simo和Taylor (1991)  </em>  中得到了证明。

- 这个模型中使用的构成关系是比较基本的。将材料类分成两个独立的类，一个处理体积响应，另一个处理等温线响应，并产生一个通用的材料类（即具有抽象的虚拟函数，派生类必须实现），允许增加更复杂的材料模型，这可能是有益的。这些模型可以包括其他超弹性材料、塑性和粘弹性材料以及其他材料。

- 该程序是为解决单节点多核机器上的问题而开发的。只要稍加努力，该程序就可以通过使用Petsc或Trilinos扩展到大规模的计算环境，使用的技术与step-40中演示的类似。这主要涉及对设置、装配、 <code>PointHistory</code> 和线性求解器例程的修改。

- 由于该程序假定为准静态平衡，为了研究惯性效应很重要的问题，例如涉及冲击的问题，有必要进行扩展以包括动态效应。

- 对于高度非线性问题，负载和解的限制程序可能是必要的。可以增加一个线搜索算法，将步长限制在牛顿增量内，以确保最佳收敛性。也可能需要使用负载限制方法，如Riks方法，来解决涉及几何不稳定性的不稳定问题，如屈曲和快穿。

- 许多物理问题涉及接触。有可能将物体间的摩擦或无摩擦接触的影响纳入这个程序。这将涉及到在自由能函数中增加一个额外的项，因此需要增加装配程序。我们还需要管理接触问题（检测和应力计算）本身。在自由能函数中增加惩罚项的一个替代方法是使用主动集方法，如步骤41中使用的方法。

- 使用LinearOperators的完整缩减程序已经被编码到线性求解器例程中。这也可以通过应用schur_complement()操作符来实现，以更自动化的方式缩减一个或多个字段。

- 最后，自适应网格细化，如步骤6和步骤18所示，可以提供额外的求解精度。


examples/step-45/doc/intro.dox

 <br> 

［<i>This program was contributed by Daniel Arndt and Matthias Maier.</i>］ ［<a name="Intro"></a>］

<h1>Introduction</h1>

在这个例子中，我们介绍了如何在deal.II中使用周期性边界条件。周期性边界条件是代数约束，通常出现在一个大域的代表性区域的计算中，这些区域在一个或多个方向上重复。

一个例子是模拟光子晶体的电子结构，因为它们有一个类似格子的结构，因此，往往只需要在格子的一个盒子上进行实际计算。为了能够以这种方式进行，我们必须假设该模型可以周期性地扩展到其他盒子上；这要求解决方案具有周期性结构。

<a name="Procedure"></a>

<h1>Procedure</h1>

deal.II提供了一些高水平的入口来施加周期性边界条件。应用周期性边界条件的一般方法包括三个步骤（也见 @ref GlossPeriodicConstraints "关于周期性边界条件的词汇表条目"）。

-# 创建一个网格

-# 识别边界不同部分的那些面对，在这些面对上的解应该是对称的，使用 GridTools::collect_periodic_faces()  。

-# 使用 parallel::distributed::Triangulation::add_periodicity() 将周期性信息添加到网格中。

-# 使用 DoFTools::make_periodicity_constraints() 添加周期性约束。

第二和第三步对于使用 parallel::distributed::Triangulation 类的平行网格是必要的，以确保位于域的对面但由周期性面连接的单元是鬼层的一部分，如果它们中的一个存储在本地处理器上。如果三角结构不是 parallel::distributed::Triangulation, 类，这些步骤就没有必要。

第一步包括收集匹配的周期性面，并将它们存储在 <code>std::vector</code> 的 GridTools::PeriodicFacePair. 中，这是通过函数 GridTools::collect_periodic_faces() 来完成的，例如可以这样调用。

@code
GridTools::collect_periodic_faces(dof_handler,
                                  b_id1,
                                  b_id2,
                                  direction,
                                  matched_pairs,
                                  offset = <default value>,
                                  matrix = <default value>,
                                  first_vector_components = <default value>);
@endcode



这个调用在周期性边界上的容器dof_handler的所有面进行循环，其边界指标分别为 @p b_id1  和  @p b_id2, 。(你可以在创建粗略网格后手工分配这些边界指标，见 @ref GlossBoundaryIndicator  "边界指标"。另外，如果你指定了 "着色 "标志，你也可以让命名空间GridGenerator中的许多函数来做这件事；在这种情况下，这些函数会给边界的不同部分分配不同的边界指标，细节通常在这些函数的文档中详细说明）。)

具体来说，如果 $\text{vertices}_{1/2}$ 是两个面 $\text{face}_{1/2}$ 的顶点，那么上面的函数调用将匹配成对的面（和道夫），使得 $\text{vertices}_2$ 和 $matrix\cdot \text{vertices}_1+\text{offset}$ 之间的差异在除方向之外的每个分量中都消失，并将产生的对与相关数据存储在 @p matched_pairs. 中（关于匹配过程的详细信息，见 GridTools::orthogonal_equality() ）。

例如，考虑彩色单位方块 $\Omega=[0,1]^2$ ，其边界指标0在左边，1在右边，2在下面，3在上面的面。参见 GridGenerator::hyper_cube() 的文件，了解这个关于如何分配边界指标的惯例）。然后。

@code
GridTools::collect_periodic_faces(dof_handler,
                                  /*b_id1*/ 0,
                                  /*b_id2*/ 1,
                                  /*direction*/ 0,
                                  matched_pairs);
@endcode

将产生周期性约束，使 $u(0,y)=u(1,y)$ 为所有 $y\in[0,1]$ 。

如果我们转而考虑由 $(0,0)$ ,  $(1,1)$ ,  $(1,2)$ ,  $(0,1)$ 的凸壳给出的平行四边形，我们可以通过指定一个 @p offset: 来实现约束 $u(0,y)=u(1,y+1)$  。

@code
GridTools::collect_periodic_faces(dof_handler,
                                  /*b_id1*/ 0,
                                  /*b_id2*/ 1,
                                  /*direction*/ 0,
                                  matched_pairs,
                                  Tensor<1, 2>(0.,1.));
@endcode

或

@code
GridTools::collect_periodic_faces(dof_handler,
                                  /*b_id1*/ 0,
                                  /*b_id2*/ 1,
                                  /*arbitrary direction*/ 0,
                                  matched_pairs,
                                  Tensor<1, 2>(1.,1.));
@endcode

在这里，边界指标0和1的分配也是源于 GridGenerator::parallelogram() 的文件。

由此产生的 @p matched_pairs 可以在 DoFTools::make_periodicity_constraints 中使用，用于为AffineConstraints对象填充周期性约束。

@code
DoFTools::make_periodicity_constraints(matched_pairs, constraints);
@endcode



除了这个高水平的接口外，还有结合这两个步骤的 DoFTools::make_periodicity_constraints 的变体（见 DofTools::make_periodicity_constraints). 的变体）可用。

如果需要更多的灵活性，也有一个与 DoFTools::make_periodicity_constraints 的低级接口。该低级变体允许直接指定两个应被约束的面。

@code
using namespace DoFTools;
make_periodicity_constraints(face_1,
                             face_2,
                             affine_constraints,
                             component_mask = <default value>;
                             face_orientation = <default value>,
                             face_flip = <default value>,
                             face_rotation = <default value>,
                             matrix = <default value>);
@endcode

在这里，我们需要使用 @p face_orientation,  @p face_flip 和 @p face_orientation. 来指定两个面的方向。 要想了解更详细的描述，请看 DoFTools::make_periodicity_constraints. 的文档。除了自我解释的 @p component_mask 和 @p affine_constraints. 之外，其余的参数与高级接口相同。


<a name="problem"></a>

<h1>A practical example</h1>

在下文中，我们将展示如何在一个更复杂的例子中使用上述函数。任务是对斯托克斯流的速度分量实施旋转的周期性约束。

在由 $\Omega=\{{\bf x}\in(0,1)^2:\|{\bf x}\|\in (0.5,1)\}$ 定义的四分之一圆上，我们要解决斯托克斯问题

@f{eqnarray*}


  -\Delta \; \textbf{u} + \nabla p &=& (\exp(-100\|{\bf x}-(.75,0.1)^T\|^2),0)^T, \\


  -\textrm{div}\;  \textbf{u}&=&0,\\
  \textbf{u}|_{\Gamma_1}&=&{\bf 0},


@f}

其中边界 $\Gamma_1$ 被定义为 $\Gamma_1 \dealcoloneq \{x\in \partial\Omega: \|x\|\in\{0.5,1\}\}$  。对于边界的其余部分，我们将使用周期性边界条件，即

@f{align*}
  u_x(0,\nu)&=-u_y(\nu,0)&\nu&\in[0,1]\\
  u_y(0,\nu)&=u_x(\nu,0)&\nu&\in[0,1].


@f}



网格将由 GridGenerator::quarter_hyper_shell(), 生成，该文件还记录了如果其`colorize'参数设置为`true'，它是如何为其各种边界分配边界指标的。


examples/step-45/doc/results.dox



<h1>Results</h1>

创建的输出结果并不十分令人惊讶。我们只是看到，相对于左、下边界而言，解决方案是周期性的。

 <img src="https://www.dealii.org/images/steps/developer/step-45.periodic.png" alt=""> 

如果没有周期性约束，我们最终会得到以下解决方案。

 <img src="https://www.dealii.org/images/steps/developer/step-45.non_periodic.png" alt=""> 


examples/step-46/doc/intro.dox

 <br> 

<i>This program was contributed by Wolfgang Bangerth.
<br>
This material is based upon work partly supported by the National Science
Foundation under Award No. EAR-0949446 and The University of California
&ndash; Davis. Any opinions, findings, and conclusions or recommendations
expressed in this publication are those of the author and do not necessarily
reflect the views of the National Science Foundation or of The University of
California &ndash; Davis.  </i>


<a name="Intro"></a>

<h1>Introduction</h1>

这个程序处理的是在领域的不同部分耦合不同物理学的问题。具体来说，让我们考虑以下情况，即把斯托克斯流体与弹性固体耦合起来（这两个问题以前在步骤22和步骤8中分别讨论过，你可能想在那里阅读一下各个方程式）。

- 在 $\Omega$ 的 $\Omega_f$ 部分，我们有一个流动的流体，满足与时间无关的斯托克斯方程（以涉及应变张量的形式）。   @f{align*}


    -2\eta\nabla \cdot \varepsilon(\mathbf v) + \nabla p &= 0,
          \qquad \qquad && \text{in}\ \Omega_f\\


    -\nabla \cdot \mathbf v &= 0  && \text{in}\ \Omega_f.
  @f}

  这里， $\mathbf v, p$ 分别是流体的速度和压力。   我们规定了部分外部边界上的速度，@f{align*}
    \mathbf v = \mathbf v_0 \qquad\qquad
     \text{on}\ \Gamma_{f,1} \subset \partial\Omega \cap \partial\Omega_f
  @f} 。

  而我们假设外部边界的其余部分为自由流动条件，@f{align*}
    (2\eta \varepsilon(\mathbf v) - p \mathbf 1) \cdot \mathbf n = 0
     \qquad\qquad
     \text{on}\ \Gamma_{f,2} = \partial\Omega \cap \partial\Omega_f \backslash
     \Gamma_{f,1}.
  @f}



- 域的其余部分， $\Omega_s = \Omega \backslash \Omega_f$ 被一个固体占据，其变形场 $\mathbf u$ 满足弹性方程，@f{align*}


    -\nabla \cdot C \varepsilon(\mathbf u) = 0 \qquad\qquad
    & \text{in}\ \Omega_s,
  @f}。

  其中 $C$ 是等级4的弹性张量（我们将使用一个特别简单的形式，假设固体是各向异性的）。   它在对沿固体边界流动的流体所施加的力的反应中发生变形。我们假设这种变形非常小，以至于它对流体没有反馈作用，也就是说，这种耦合只是在一个方向。为了简单起见，我们将假设固体的外部边界是被夹紧的，即@f{align*}
    \mathbf u = \mathbf 0 \qquad\qquad
     \text{on}\ \Gamma_{s,1} = \partial\Omega \cap \partial\Omega_s
  @f} 。



- 作为小位移假设的结果，我们将对流体和固体之间的界面提出以下边界条件：首先，我们对流体没有滑移的边界条件，@f{align*}
    \mathbf v = \mathbf 0 \qquad\qquad
     \text{on}\ \Gamma_{i} = \partial\Omega_s \cap \partial\Omega_f.
  @f} 。

  其次，固体上的力（牵引力）等于来自流体的法向应力，@f{align*}
    (C \varepsilon(\mathbf u)) \mathbf n =
    (2 \eta \varepsilon(\mathbf v) - p \mathbf 1) \mathbf n \qquad\qquad
     \text{on}\ \Gamma_{i} = \partial\Omega_s \cap \partial\Omega_f,
  @f} 。

  其中 $\mathbf{n}$ 是 $\Gamma_{i}$ 上的法向量，从固体指向流体。

我们通过遵循我们通常的规则，即从左边乘以一个测试函数并在域上进行积分，得到这个问题的弱表述。那么它看起来像这样。找到 $y = \{\mathbf v, p,
\mathbf u\} \in Y \subset H^1(\Omega_f)^d \times L_2(\Omega_f) \times
H^1(\Omega_s)^d$ ，使得

@f{align*}
	2 \eta (\varepsilon(\mathbf a), \varepsilon(\mathbf v))_{\Omega_f}


	- (\nabla \cdot \mathbf a, p)_{\Omega_f}


	- (q, \nabla \cdot \mathbf v)_{\Omega_f} &
	\\
	+ (\varepsilon(\mathbf b), C \varepsilon(\mathbf u))_{\Omega_s} &
	\\


	- (\mathbf b,
           (2 \eta \varepsilon(\mathbf v) - p \mathbf 1) \mathbf n)_{\Gamma_i}
	&=
	0,


@f}

为所有测试函数 $\mathbf a, q, \mathbf b$ ；第一、第二和第三行分别对应于流体、固体和界面贡献。请注意， $Y$ 只是上述空间的一个子空间，以适应各种迪里切特边界条件。

当然，只要有两个Triangulation和两个DoFHandler对象，两个子域各一个，就可以实现这种耦合。另一方面，如果有一个知道整个问题离散化的单一DoFHandler对象，那么deal.II的使用就简单多了。

这个程序是关于如何实现这一点的。请注意，我们的目标并不是要提出一个特别有用的物理模型（一个现实的流固交互模型必须考虑到固体的有限变形和它对流体的影响）：这毕竟只是一个旨在演示技术的教程程序，而不是为了解决实际问题。此外，我们将假设子域之间的界面与粗略的网格单元面对齐。




<h3>The general idea</h3>

在讨论更多细节之前，让我们先说明一下：这是一个有多个解变量的问题；为此，你可能想先阅读一下 @ref vector_valued 文档模块，它介绍了我们处理有多个解变量问题的基本哲学框架。但回到手头的问题上。

在deal.II中实现这类问题的基本思路如下：在问题表述中，速度和压力变量 $\mathbf v, p$ 只存在于流体子域 $\Omega_f$ 中。但我们假设将它们以零点扩展到整个域 $\Omega$ （在一般情况下，这意味着它们沿 $\Gamma_i$ 将是不连续的）。那么，什么是这些变量的适当函数空间呢？我们知道，在 $\Omega_f$ 上我们应该要求 $\mathbf v \in H^1(\Omega_f)^d, p \in L_2(\Omega_f)$ ，所以对于 $\tilde{\mathbf v}, \tilde p$ 到整个域的扩展，下面出现了一组有用的函数空间。

@f{align*}
  \tilde {\mathbf v} &\in V
   = \{\tilde {\mathbf v}|_{\Omega_f} \in H^1(\Omega_f)^d, \quad
       \tilde {\mathbf v}|_{\Omega_s} = 0 \}
  \\
  \tilde p &\in P
  = \{\tilde p|_{\Omega_f} \in L_2(\Omega_f), \quad
       \tilde p|_{\Omega_s} = 0 \}.


@f}

(由于这对目前的讨论并不重要，我们从函数空间的选择中省略了边界值的问题；这个问题也影响到我们是否可以为压力选择 $L_2$ 或者我们是否必须为压力选择空间 $L_{2,0}(\Omega_f)=\{q\in L_2(\Omega_f): \int_{\Omega_f} q
= 0\}$ 。不过，这些问题都与下面的讨论无关)。

请注意，这些确实是一个具有明显规范的线性函数空间。由于在实践中不可能发生混淆，因此我们今后将再次省略省略号，以表示一个函数对整个域的扩展，并简单地用 $\mathbf v, p$ 来指代原始函数和扩展函数。

对于离散化，我们需要 $V_h,P_h$ 的有限维子空间 $V, P$  。对于斯托克斯，我们从步骤22中知道，适当的选择是 $Q_{p+1}^d\times Q_P$ ，但这只适用于流体占据的那部分域。对于扩展场，让我们使用以下定义在三角形上的子空间  $\mathbb T$  。

@f{align*}
  V_h
   &= \{{\mathbf v}_h \quad | \quad
       \forall K \in {\mathbb T}:
       {\mathbf v}_h|_K \in Q_{p+1}^d\  \text{if}\ K\subset {\Omega_f}, \quad
       {\mathbf v}_h|_{\Omega_f}\ \text{is continuous}, \quad
       {\mathbf v}_h|_K = 0\ \text{if}\ K\subset {\Omega_s}\}
   && \subset V
  \\
  P_h
  &= \{ p_h \quad | \quad
       \forall K \in {\mathbb T}:
       p_h|_K \in Q_p\  \text{if}\ K\subset {\Omega_f}, \quad
       p_h|_{\Omega_f}\ \text{is continuous}, \quad
       p_h|_K = 0\ \text{if}\ K\subset {\Omega_s}\ \}
   && \subset P.


@f}

换句话说，在 $\Omega_f$ 上，我们选择了通常的离散空间，但我们保留了由零扩展的（不连续的）。要说明的是，我们现在需要一个描述在单元上为零的函数的有限元空间&mdash;而这正是FE_Nothing类的用武之地：它描述了一个常数为零的函数的有限维函数空间。这个奇特的线性向量空间的一个特殊属性是它没有自由度：它不仅仅是有限维度的，它实际上是零维的，因此对于这种类型的对象， FiniteElement::n_dofs_per_cell() 将返回零。为了下面的讨论，让我们给这个空间一个合适的符号。

@f[
  Z = \{ \varphi: \varphi(x)=0 \}.


@f]

符号 $Z$ 提醒了这个空间的函数为零的事实。很明显，我们选择 $Z_h=Z$  。

对于我们用来描述弹性方程的变量，上面的整个讨论都可以重复。在这里，对于扩展变量，我们有

@f{align*}
  \tilde {\mathbf u} &\in U
   = \{\tilde {\mathbf u}|_{\Omega_s} \in H^1(\Omega_f)^d, \quad
       \tilde {\mathbf u}|_{\Omega_f} \in Z(\Omega_s)^d \},


@f}

而我们通常会使用这样的一个有限元空间

@f{align*}
  U_h
   &= \{{\mathbf u}_h \quad | \quad
       \forall K \in {\mathbb T}:
       {\mathbf u}_h|_K \in Q_r^d\  \text{if}\ K\subset {\Omega_s}, \quad
       {\mathbf u}_h|_{\Omega_f}\ \text{is continuous}, \quad
       {\mathbf u}_h|_K \in Z^d\ \text{if}\ K\subset {\Omega_f}\}
   && \subset U


@f}

的多项式程度  $r$  。

因此，总结起来，我们要在以下空间寻找一个离散的矢量值解 $y_h = \{\mathbf v_h, p_h, \mathbf u_h\}$ 。

@f{align*}
  Y_h = \{
      & y_h = \{\mathbf v_h, p_h, \mathbf u_h\} : \\
      & y_h|_{\Omega_f} \in Q_{p+1}^d \times Q_p \times Z^d, \\
      & y_h|_{\Omega_s} \in Z^d \times Z \times Q_r^d \}.


@f}






<h3>Implementation</h3>

那么，我们如何实现这种事情呢？首先，我们意识到，离散空间 $Y_h$ 本质上需要两个不同的有限元。首先，在流体子域上，我们需要元素 $Q_{p+1}^d \times Q_p \times Z^d$ ，这在deal.II中很容易通过以下方式实现

@code
  FESystem<dim> (FE_Q<dim>(p+1), dim,
		 FE_Q<dim>(p), 1,
		 FE_Nothing<dim>(), dim),
@endcode

其中 <code>FE_Nothing</code> 实现了永远为零的函数的空间。其次，在实体子域上，我们需要元素 $\in Z^d \times Z \times Q_r^d$ ，我们用以下方法得到它

@code
  FESystem<dim> (FE_Nothing<dim>(), dim,
		 FE_Nothing<dim>(), 1,
		 FE_Q<dim>(r), dim),
@endcode



下一步是，我们将这两个元素中的每一个都与占据两个子域的细胞联系起来。为此，我们认识到，从某种意义上说，这两个元素只是彼此的变化，因为它们具有相同数量的向量分量，但具有不同的多项式度数&mdash；这很像人们在 $hp$ 有限元方法中的做法，这也正是我们在这里要做的：我们将（ab）使用hp-namespace的类和设施，将不同的元素分配给不同的单元。换句话说，我们将使用 hp::FECollection, 中的两个有限元与一个适当的 hp::QCollection 集成，使用 hp::FEValues 对象，而我们的DoFHandler将处于<i>hp</i>模式下。你不妨看一下步骤27，了解所有这些概念的概况。

在继续描述测试案例之前，让我们先澄清一下<i>why</i>这种将函数以零为单位扩展到整个领域，然后将问题映射到hp-framework上的方法是有意义的。

- 它使事情变得统一。在所有单元格中，向量分量的数量是相同的（这里是 <code>2*dim+1</code> ）。这使得各种事情都成为可能，因为统一的描述允许代码的重复使用。例如，计算每个向量分量的自由度 (DoFTools::count_dofs_per_fe_component), 按分量对自由度进行排序 (DoFRenumbering::component_wise), ，随后将矩阵和向量分割成块，以及其他许多函数都能一如既往地工作，而不需要为它们添加特殊的逻辑来描述某些变量只存在于部分领域的情况。因此，在像现在这样的程序中，你已经有了各种工具，这些工具最初并不是为多物理场情况编写的，但在目前的背景下却能正常工作。

- 它可以方便地进行图形化输出。我们支持的所有图形输出格式都要求输出中的每个字段都定义在网格的所有节点上。但是考虑到现在所有的解决方案组件都存在于各个地方，我们现有的DataOut例程可以像以前一样工作，并产生适合于可视化的图形输出--这些字段将简单地被扩展为0，如果不需要，可视化程序可以很容易地过滤掉这个值。

- 基本上没有成本。FE_Nothing的技巧并没有给整个问题增加任何自由度，我们也不需要处理属于这些分量的形状函数&mdash；FE_Nothing没有自由度，也没有形状函数，它所做的只是占用了矢量分量。




<h3> Specifics of the implementation </h3>

更具体地说，在该方案中，我们必须解决以下几点。

- 实现双线性形式，特别是处理界面项，在矩阵和稀疏模式中都是如此。

- 在边界的外部和内部部分实施迪里希特边界条件  $\partial\Omega_f,\partial\Omega_s$  。




<h4>Dealing with the interface terms</h4>

让我们首先讨论实现双线性形式，在离散水平上，我们记得它是

@f{align*}
	2 \eta (\varepsilon(\mathbf a_h), \varepsilon(\mathbf v_h))_{\Omega_f}


	- (\nabla \cdot \mathbf a_h, p_h)_{\Omega_f}


	- (q_h, \nabla \cdot \mathbf v_h)_{\Omega_f} &
	\\
	+ (\varepsilon(\mathbf b_h), C \varepsilon(\mathbf u_h))_{\Omega_s} &
	\\


	- (\mathbf b_h,
           (2 \eta \varepsilon(\mathbf v_h) - p \mathbf 1) \mathbf n)_{\Gamma_i}
	&=
	0,


@f}

鉴于我们已经将场扩展为零，原则上我们可以将子域上的积分写成整个域 $\Omega$ ，尽管在决定对哪些项进行积分之前，首先询问一个单元是弹性区域还是流体区域的一部分，这没有什么额外的努力。实际上，对这些项进行积分并不十分困难；对于斯托克斯方程，相关步骤已在步骤22中显示，而对于弹性方程，我们基本上采取 @ref vector_valued 模块中的形式（而不是步骤8中的形式）。

更值得关注的是界面术语。

@f[


	-(\mathbf b_h,
           (2 \eta \varepsilon(\mathbf v_h) - p \mathbf 1) \mathbf n)_{\Gamma_i}.


@f]

基于我们假设界面 $\Gamma_i$ 与细胞边界重合，这实际上可以写成一组面积分。如果我们用提取器符号 $\psi_i\in Y_h$ 表示形状函数 $\psi_i[\mathbf v],\psi_i[p], \psi_i[\mathbf u]$ 的速度、压力和位移分量，那么上述项就会产生对全局矩阵项 $i,j$ 的如下贡献。

@f[


	-\sum_K (\psi_i[\mathbf u],
           (2 \eta \varepsilon(\psi_j[\mathbf v]) - \psi_j[p] \mathbf 1)
	   \mathbf n)_{\partial K \cap \Gamma_i}.


@f]

虽然不是很明显，但这个术语带来了一点复杂的问题：虽然 $\psi_i[\mathbf u]$ 和 $\mathbf n$ 是在界面的实体一侧评估的（它们分别是位移和对 $\Omega_s$ 的法向量的测试函数，我们需要在界面的流体一侧评估 $\psi_j[\mathbf v],\psi_j[p]$ ，因为它们对应于流体施加的应力/力。换句话说，在我们的实现中，我们将需要界面两边的FEFaceValue对象。让事情变得更糟糕的是，我们可能还必须处理这样一个事实，即一方或另一方可能被细化，使我们需要在一个面的部分区域进行整合。请看下面的实现，如何处理这个问题。

作为一个额外的复杂问题，由这个术语产生的矩阵条目需要以某种方式添加到矩阵的稀疏模式中。这是DoFTools命名空间中各种函数的领域，比如 DoFTools::make_sparsity_pattern 和 DoFTools::make_flux_sparsity_pattern. 本质上，这些函数所做的是模拟系统矩阵装配过程中发生的事情：每当装配将非零条目写入全局矩阵，DoFTools中的函数将添加一个条目到稀疏模式中。因此，我们可以这样做：让 DoFTools::make_sparsity_pattern 将所有由常规的逐个单元积分产生的条目添加到稀疏性模式中，然后用手做同样的事情，即由接口项产生的条目。如果你看一下下面的程序中界面积分的实现，那么如何做应该是显而易见的，最多只需要不超过100行的代码。

但我们是懒人：界面项是沿一个面耦合两个相邻单元的自由度，这正是人们在非连续Galerkin方案中要做的事情，函数 DoFTools::make_flux_sparsity_pattern 就是为此而写。与通常的 DoFTools::make_sparsity_pattern: 相比，这是一个矩阵条目的超集，它还将添加所有计算来自所有面的两侧自由度的耦合项的条目。不幸的是，对于这个函数的最简单版本，这是一个相当大的超集。例如，考虑下面这个有两个单元和一个 $Q_1$ 有限元的网格。

@code
  2---3---5
  |   |   |
  0---1---4
@endcode

这里，由 DoFTools::make_sparsity_pattern 产生的稀疏模式将只有在一个单元上耦合的自由度的条目。然而，它不会有稀疏模式条目 $(0,4),(0,5),(2,4),(2,5)$  。然而，由 DoFTools::make_flux_sparsity_pattern 生成的稀疏模式将有这些条目：它假定你想为一个双线性形式建立一个稀疏模式，该形式将<i>all</i>自由度从相邻的单元上耦合起来。这不是我们想要的：我们的界面项只作用于一小部分单元，我们当然不需要两个相邻流体单元或两个相邻固体单元之间的所有额外耦合。此外，我们使用高阶元素的事实意味着我们确实会产生比实际需要多得多的条目：在最粗的网格上，在2D中，44,207个非零条目而不是16,635个 DoFTools::make_sparsity_pattern, ，导致我们后来建立的矩阵中出现大量的零（当然，16,635是不够的，因为它们不包括界面条目）。这个比例在3D中会更糟糕。

所以极度懒惰是有代价的：矩阵中的条目太多。但我们可以适度偷懒：有一个 DoFTools::make_flux_sparsity_pattern 的变体，允许我们指定有限元的哪些矢量分量与哪些其他分量耦合，既可以用单元术语，也可以用面术语。对于实体子域中的单元，我们将所有位移相互耦合；对于流体单元，所有速度与所有速度和压力耦合，但压力不与自身耦合。由于没有一个单元同时拥有两组变量，因此没有必要区分这两种单元，所以我们可以这样写掩码。

@code
    Table<2,DoFTools::Coupling> cell_coupling (fe_collection.n_components(),
					       fe_collection.n_components());


    for (unsigned int c=0; c<fe_collection.n_components(); ++c)
      for (unsigned int d=0; d<fe_collection.n_components(); ++d)
	if (((c<dim+1) && (d<dim+1)
	     && !((c==dim) && (d==dim)))
	    ||
	    ((c>=dim+1) && (d>=dim+1)))
	  cell_coupling[c][d] = DoFTools::Coupling::always;
@endcode

在这里，我们使用了这样一个事实：有限元的第一个 <code>dim</code> 分量是速度，然后是压力，最后是 <code>dim</code> 位移。(我们也可以说，速度/压力也与位移耦合，因为没有一个单元同时拥有两组变量)。另一方面，界面条款需要一个像这样的掩码。

@code
    Table<2,DoFTools::Coupling> face_coupling (fe_collection.n_components(),
					       fe_collection.n_components());


    for (unsigned int c=0; c<fe_collection.n_components(); ++c)
      for (unsigned int d=0; d<fe_collection.n_components(); ++d)
	if ((c>=dim+1) && (d<dim+1))
	  face_coupling[c][d] = DoFTools::Coupling::always;
@endcode

换句话说，所有的位移测试函数（组件 <code>c@>=dim+1</code> ）与界面另一侧的所有速度和压力形状函数耦合。这并不完全正确，尽管很接近：事实上，界面的确切形式仅指那些在共同界面上确实为非零的压力位移形状函数，这对所有形状函数来说并不正确；另一方面，它确实耦合了所有速度（因为积分涉及速度形状函数的梯度，这些梯度在单元的所有面上均为非零）。然而，我们在上面建立的掩码，并不具备这些微妙的能力。尽管如此，通过这些掩码，我们设法将稀疏模式的条目数降低到21028个&mdash；目前来说已经足够了。




<h4>Velocity boundary conditions on the interface</h4>

第二个困难是，虽然我们知道如何在外部边界上强制执行速度或应力为零（使用 VectorTools::interpolate_boundary_values, 调用适当的分量掩码，并为固体和流体外部边界设置不同的边界指标），但现在我们还需要在内部界面上的速度为零，即 $\mathbf v|_{\Gamma_i}=0$  。在写这篇文章时，deal.II中没有处理这部分的函数，但用手实现并不特别困难：基本上，我们只需要在所有单元上循环，如果它是一个流体单元，而它的邻居是一个固体单元，然后添加约束，确保这个面上的速度自由度为零。在处理相邻的固体单元被细化的情况下，有必要进行一些处理，产生以下代码。

@code
std::vector<unsigned int> local_face_dof_indices (stokes_fe.dofs_per_face);
for (const auto &cell: dof_handler.active_cell_iterators())
  if (cell_is_in_fluid_domain (cell))
    for (const auto f : cell->face_indices())
      if (!cell->at_boundary(f))
        {
          bool face_is_on_interface = false;


          if ((cell->neighbor(f)->has_children() == false)
	          &&
	          (cell_is_in_solid_domain (cell->neighbor(f))))
	        face_is_on_interface = true;
          else if (cell->neighbor(f)->has_children() == true)
	        {
              // The neighbor does have children. See if any of the cells
              // on the other side are elastic
	          for (unsigned int sf=0; sf<cell->face(f)->n_children(); ++sf)
	            if (cell_is_in_solid_domain (cell->neighbor_child_on_subface(f, sf)))
	              {
                   face_is_on_interface = true;
		            break;
	              }
	        }


          if (face_is_on_interface)
           {
             cell->face(f)->get_dof_indices (local_face_dof_indices, 0);
             for (unsigned int i=0; i<local_face_dof_indices.size(); ++i)
             if (stokes_fe.face_system_to_component_index(i).first < dim)
               constraints.add_line (local_face_dof_indices[i]);
           }
        }
@endcode



调用 <code>constraints.add_line(t)</code> 告诉AffineConstraints为自由度 <code>t</code> 启动一个新的约束，其形式为 $x_t=\sum_{l=0}^{N-1} c_{tl} x_l +
b_t$  。通常情况下，我们会将单个系数 $c_{tl}$ 设置为非零值（使用 AffineConstraints::add_entry) 或将 $b_t$ 设置为非零值（使用 AffineConstraints::set_inhomogeneity); 像上面那样什么都不做，虽然看起来很有趣，但只是让约束成为 $x_t=0$ ，这正是我们在当前情况下需要的。对 FiniteElement::face_system_to_component_index 的调用确保了我们只将速度分量的边界值设置为零，而不是压力分量。

请注意，在有些情况下，这可能会产生不正确的结果：特别是，一旦我们找到当前流体单元的一个实体邻接子，我们就会假设共同面上的所有邻接子都在实体子域。但事实并非如此，例如，考虑以下的网格。

@code
+---------+----+----+
|         | f  |    |
|    f    +----+----+
|         | s  |    |
+---------+----+----+
@endcode



在这种情况下，我们将把左单元右面的所有速度自由度设置为零，这对该面的顶部自由度来说是不正确的。也就是说，只有当流体和固体子域不与一组完整的粗网格单元重合时才会发生这种情况&mdash;但这与本介绍第一节末尾所述的假设是矛盾的。




<h3>The testcase</h3>

我们将考虑以下情况作为一个测试案例。

 <img src="https://www.dealii.org/images/steps/developer/step-46.layout.png" alt=""> 

正如本文顶部所讨论的，我们需要在一些地方假设一个单元完全处于域的流体部分或固体部分，此外，一个不活动单元的所有子域也属于同一个子域。如果粗略网格已经将网格细分为实体和流体粗略网格单元，这一点肯定可以得到保证；考虑到上面概述的几何形状，我们可以通过使用 $8\times 8$ 粗略网格，方便地提供 GridGenerator::subdivided_hyper_rectangle 函数来实现。

底部的固定边界意味着 $\mathbf u=0$ ，我们也为顶部的流动规定了迪里希特条件，因此我们在左边得到流入，在右边得到流出。在左边和右边的边界，没有对流动施加明确的边界条件，产生隐性的无应力条件  $(2\eta
\varepsilon(\mathbf v) - p \mathbf 1) \cdot \mathbf n = 0$  。上面已经讨论了两个域之间的界面条件。

为了简单起见，我们选择材料参数为 $\eta=\lambda=\mu=1$  。在下面的结果部分，我们还将展示一个可以从同一程序中获得的三维模拟。边界条件和几何形状的定义几乎与上面的2d情况类似。




<h4>Identifying which subdomain a cell is in</h4>

在程序中，我们需要一种方法来识别一个细胞处于域的哪一部分。有许多不同的方法可以做到这一点。一个典型的方法是使用每个单元的 @ref GlossSubdomainId "subdomain_id "标签，尽管这个字段在%并行计算中具有特殊意义。另一种方法是 @ref GlossMaterialId "material_id "字段，也是每个单元格都有的。它有一个额外的优点，就是在网格细化时，它可以从母体继承到子体；换句话说，我们在创建网格时设置一次材料ID，即使经过几次细化循环，它对所有活动单元都是正确的。因此，我们采用这种方法：我们定义一个 <code>enum</code> ，用符号名称来表示材料ID的数字，并使用它们来识别单元在域的哪一部分。

其次，我们使用一个在<i>hp</i>模式下运行的DoFHandler类型的对象。该类需要知道哪些单元将使用斯托克斯有限元，哪些使用弹性有限元。因此，在每个细化周期的开始，我们必须走过所有的单元，并将（在hp-parlance中）活动FE索引设置为任何适合当前情况的索引。虽然我们可以使用符号名称来表示材料ID，但主动FE索引实际上是一个数字，经常用于索引对象的集合（例如 hp::FECollection 和 hp::QCollection); 类型），这意味着主动FE索引实际上对于领域的流体部分必须是0，对于弹性部分必须是1。




<h4>Linear solvers</h4>

这个程序主要是为了展示如何处理领域内不同部分的不同物理现象，以及如何在deal.II中实现这样的模型。因此，我们不会费力想出一个好的求解器：我们只是使用SparseDirectUMFPACK类，它总是有效的，即使不是最佳的复杂性。然而，我们将在<a href="#Results">results</a>部分对可能的其他求解器进行评论。




<h4>Mesh refinement</h4>

这个程序的一个比较棘手的方面是如何估计误差。因为它几乎适用于任何程序，所以我们想使用KellyErrorEstimator，在这里我们也可以用下面这样的代码相对容易地做到。

@code
  Vector<float> stokes_estimated_error_per_cell (triangulation.n_active_cells());
  Vector<float> elasticity_estimated_error_per_cell (triangulation.n_active_cells());


  std::vector<bool> stokes_component_mask (dim+1+dim, false);
  for (unsigned int d=0; d<dim; ++d)
    stokes_component_mask[d] = true;
  KellyErrorEstimator<dim>::estimate (dof_handler,
                                      face_q_collection,
                                      std::map<types::boundary_id, const Function<dim>*>(),
                                      solution,
                                      stokes_estimated_error_per_cell,
                                      stokes_component_mask);


  std::vector<bool> elasticity_component_mask (dim+1+dim, false);
  for (unsigned int d=0; d<dim; ++d)
    elasticity_component_mask[dim+1+d] = true;
  KellyErrorEstimator<dim>::estimate (dof_handler,
                                      face_q_collection,
                                      std::map<types::boundary_id, const Function<dim>*>(),
                                      solution,
                                      elasticity_estimated_error_per_cell,
                                      elasticity_component_mask);
@endcode

这就为每个单元提供了两套误差指标。然后我们会以某种方式将它们合并成一个用于网格细化，例如使用类似下面的方法（注意，我们将两个向量中的平方误差指标归一化，因为误差量的物理单位在当前情况下并不匹配，导致两个子域之间的误差指标可能存在数量级的差异）。

@code
  stokes_estimated_error_per_cell /= stokes_estimated_error_per_cell.l2_norm();
  elasticity_estimated_error_per_cell /= elasticity_estimated_error_per_cell.l2_norm();


  Vector<float> estimated_error_per_cell (triangulation.n_active_cells());
  estimated_error_per_cell += stokes_estimated_error_per_cell;
  estimated_error_per_cell += elasticity_estimated_error_per_cell;
@endcode

(在代码中，我们实际上以4:1的比例权衡误差指标，以支持在斯托克斯子域上计算的误差指标，因为细化在其他方面严重偏向弹性子域，但这只是一个技术问题。因素4已经被启发式地确定为相当好的工作。)

虽然这个原则是合理的，但它并不完全像预期的那样工作。原因是KellyErrorEstimator类是通过整合每个单元面周围的解的梯度跳跃来计算误差指标。这个跳跃在解不连续和扩展为零的地方可能非常大；它也不会随着网格的细化而变小。KellyErrorEstimator类不能忽视这个接口，因为它基本上只看到<i>hp</i>模式下的DoFHandler，其中元素类型从一个单元改变到另一个单元&mdash；正是<i>hp</i>模式所设计的东西，当前程序中的接口看起来与步骤27中的接口没有什么不同，例如，当然也没有更合理的。尽管如此，最终的结果是，在两个子域之间的界面两侧都有一层单元，其误差指标大得不合理。因此，大部分的网格细化工作都集中在界面上。

如果我们有一个真正理解问题的细化指标，并且在积分跳跃项时简单地忽略子域之间的界面，这显然就不会发生。另一方面，这个程序是关于展示如何表示我们在不同子域有不同物理学的问题，而不是关于KellyErrorEstimator的特殊性，因此我们诉诸于被称为 "启发式 "的大锤子：我们简单地把界面上的单元格的误差指标设置为零。这就切断了误差指标中的尖峰。乍看之下，人们也会认为它阻止了网格在界面上的细化，但是相邻的单元只能有一级细化的要求，仍然会导致一个合理的细化网格。

虽然这显然是一个次优的解决方案，但它目前是可行的，并为未来的改进留下了空间。


examples/step-46/doc/results.dox

<a name="Results"></a>

<h1>Results</h1>

<h3>2d results</h3>


当运行该程序时，你应该得到如下输出。

@code
Refinement cycle 0
   Number of active cells: 64
   Number of degrees of freedom: 531
   Assembling...
   Solving...
   Writing output...


Refinement cycle 1
   Number of active cells: 136
   Number of degrees of freedom: 1260
   Assembling...
   Solving...
   Writing output...


Refinement cycle 2
   Number of active cells: 436
   Number of degrees of freedom: 3723
   Assembling...
   Solving...
   Writing output...


Refinement cycle 3
   Number of active cells: 1072
   Number of degrees of freedom: 7493
   Assembling...
   Solving...
   Writing output...


Refinement cycle 4
   Number of active cells: 2632
   Number of degrees of freedom: 15005
   Assembling...
   Solving...
   Writing output...


Refinement cycle 5
   Number of active cells: 5944
   Number of degrees of freedom: 29437
   Assembling...
   Solving...
   Writing output...
@endcode



结果很容易被可视化。

 <table width="80%" align="center">
  <tr valign="top">
    <td valign="top" align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-46.9.2.velocity-2d.png" alt="">
      <p align="center">
        Magnitude and vectors for the fluid velocity.
      </p>
    </td>
    <td valign="top" align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-46.9.2.pressure-2d.png" alt="">
      <p align="center">
        Fluid pressure. The dynamic range has been truncated to cut off the
        pressure singularities at the top left and right corners of the domain
        as well as the top corners of the solid that forms re-entrant corners
        into the fluid domain.
      </p>
    </td>
    <td valign="top" align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-46.9.2.displacement-2d.png" alt="">
      <p align="center">
        Magnitude and vectors for the solid displacement.
      </p>
    </td>
  </tr>
</table> 

这些图很容易解释：当水流在固体直立部分的左边向下、右边向上时，它产生的压力在左边高，在右边低，这些力量使固体的垂直部分向右弯曲。




<h3>3d results</h3>

通过将 <code>FluidStructureProblem</code> 类中的维度改为3，我们也可以运行同样的问题3D。你会得到如下的输出。

@code
Refinement cycle 0
   Number of active cells: 512
   Number of degrees of freedom: 11631
   Assembling...
   Solving...
   Writing output...


Refinement cycle 1
   Number of active cells: 1716
   Number of degrees of freedom: 48984
   Assembling...
   Solving...
   Writing output...


Refinement cycle 2
   Number of active cells: 8548
   Number of degrees of freedom: 245746
   Assembling...
   Solving...
@endcode

你会发现，最大的瓶颈是求解器。SparseDirectUmfpack在2016年的工作站上解决这个问题的最后一次迭代需要将近5个小时和大约80GB的内存（倒数第二次迭代只用了16分钟）。显然，这里需要一个更好的求解器，这个话题在下面讨论。

结果也可以被可视化，并产生良好的图片。这里有一张，显示了速度的矢量图（橙色），实体位移（蓝色），以及实体区域的阴影。

<p align="center">  <img src="https://www.dealii.org/images/steps/developer/step-46.9.2.3d.png" alt="">   </p>  。

除了缺乏一个好的求解器之外，网格也有点不平衡：网格细化严重偏向于流体子域（在2D中，情况恰恰相反，促使我们对流体误差指标的权重更高）。显然，如果想继续做更多的三维计算，对两个子域中误差指标的相对重要性进行一些调整是很重要的。


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Linear solvers and preconditioners</h4>

改进程序的一个明显的地方是使用一个更复杂的求解器&mdash；特别是一个能很好地扩展并能解决现实的三维问题的求解器。这在这里其实不难实现，因为从流体到固体的单向耦合。为此，假设我们将自由度重新排序，首先是所有的速度和压力自由度，然后是所有的位移（使用 DoFRenumbering::component_wise). 很容易实现），那么系统矩阵可以被分成以下的块状形式。

@f[
  A_\text{global}
  =
  \begin{pmatrix}
    A_{\text{fluid}} & 0 \\
    B & A_{\text{solid}}
  \end{pmatrix}


@f]

其中 $A_{\text{fluid}}$ 是速度和压力的斯托克斯矩阵（它可以进一步细分为 $2\times 2$ 矩阵，如步骤22，尽管这对目前的目的不重要）， $A_{\text{solid}}$ 是位移的弹性方程的结果， $B$ 是来自界面条件的矩阵。现在注意到，这个矩阵

@f[
  A_\text{global}^{-1}
  =
  \begin{pmatrix}
    A_{\text{fluid}}^{-1} & 0 \\


    -A_\text{solid}^{-1} B
      A_\text{fluid}^{-1} & A_{\text{solid}}^{-1}
  \end{pmatrix}


@f]

是 $A_\text{global}$ 的逆数。应用这个矩阵只需要与 $A_\text{fluid}$ 和 $A_\text{solid}$ 各解一次，因为

@f[
  \begin{pmatrix}
    p_x \\ p_y
  \end{pmatrix}
  =
  \begin{pmatrix}
    A_{\text{fluid}}^{-1} & 0 \\


    -A_\text{solid}^{-1} B
      A_\text{fluid}^{-1} & A_{\text{solid}}^{-1}
  \end{pmatrix}
  \begin{pmatrix}
    x \\ y
  \end{pmatrix}


@f]

可以计算为 $p_x = A_{\text{fluid}}^{-1} x$ ，然后是 $p_y = A_{\text{solid}}^{-1} (y-Bp_x)$  。

因此，人们可以预期，

@f[
  \widetilde{A_\text{global}^{-1}}
  =
  \begin{pmatrix}
    \widetilde{A_{\text{fluid}}^{-1}} & 0 \\


    -\widetilde{A_\text{solid}^{-1}} B
      \widetilde{A_\text{fluid}^{-1}} & \widetilde{A_{\text{solid}}^{-1}}
  \end{pmatrix}


@f]

如果  $\widetilde{A_{\text{fluid}}^{-1}}
\approx A_{\text{fluid}}^{-1}, \widetilde{A_{\text{solid}}^{-1}}
\approx A_{\text{solid}}^{-1}$  ，将是一个好的预处理程序。

这意味着，我们只需要为斯托克斯和弹性方程分别提供良好的预处理。这些都是众所周知的：对于斯托克斯，我们可以使用step-22的结果部分所讨论的预处理程序；对于弹性，一个好的预处理程序将是一个几何或代数多重网格的单一V形周期。然而，还有更多的开放性问题。对于由两个子调节器构建的 "优化 "求解器块-三角调节器，经常出现的一点是，在为子调节器选择参数时，在单独解决两个问题时效果好的值，在组合成多物理学调节器时可能不是最佳值。  特别是，当单独解决固体或流体力学问题时，在收敛所需的迭代次数和每次迭代应用预调节器的成本之间进行平衡，可能导致人们为斯托克斯问题选择昂贵的预调节器，为弹性问题选择便宜的预调节器（或者反之）。  然而，当结合在一起时，还有一个额外的约束，即你希望两个子预处理程序以大致相同的速度收敛，否则便宜的预处理程序可能会增加全局的迭代次数，而昂贵的预处理程序则会增加每迭代的成本。例如，虽然单一的AMG V型循环本身是一个很好的弹性方法，但当结合到一个多物理问题时，可能会有动力使用一个完整的W型循环或多个循环来帮助降低总求解时间。




<h4>Refinement indicators</h4>

正如介绍中提到的，我们在这个程序中使用的细化指标是相当临时的。一个更好的会明白，解的梯度在界面上的跳跃并不是错误的指示，而是可以预期的，并且在积分跳跃项的时候忽略界面。然而，这并不是KellyErrorEstimator类所做的。另一个更大的问题是，这种估计器首先是否是一个好的策略：例如，如果我们想在位移的某个特定方面（例如实体右上角的位移）有最大的准确性，那么将流体和实体的误差指标放大到相同的程度是否合适？也许有必要用比固体更高的精度来解决流体问题，因为流体的解决方案直接影响到固体的解决方案？也许正好相反？

因此，改进该程序的一个明显的可能性是实施一个更好的细化标准。关于这个话题有一些文献；各种可能的起点之一是Thomas Wick的论文 "Adaptive finite elements for monolithic fluid-structure interaction on a prolongated domain:应用于心脏瓣膜模拟"，2011年机械学计算机方法会议论文集（CMM-2011），2011年5月9-12日，波兰华沙。




<h4>Verification</h4>

上面的结果纯粹是定性的，因为没有证据表明我们的方案实际上是收敛的。因此，一个显而易见的事情是增加一些量化的措施来检查该方案至少收敛到<i>something</i>。例如，我们可以为每个细化周期输出实体的右上角突出到流体子域的部分的偏移。或者我们可以计算出流体对实体施加的净力向量或扭矩。




<h4>Better models</h4>

在现实中，大多数流体结构的相互作用问题是这样的：固体的运动确实影响了流体的流动。例如，空气在气箔周围的作用力导致它弯曲并改变其形状。同样地，一面旗帜在风中飘动，完全改变了它的形状。

这种双向耦合的问题通常在任意拉格朗日欧拉（ALE）框架下处理，其中固体的位移以某种平滑的方式扩展到流体领域，而不是像我们在这里所做的那样以零为单位。然后，扩展的位移场被用来对我们计算流体流动的网格进行变形。此外，界面上流体的边界条件不再是速度为零；相反，在一个时间相关的程序中，流体速度必须等于沿界面的位移的时间导数。


examples/step-47/doc/intro.dox

 <br> 

<i>
This program was contributed by Natasha Sharma, Guido Kanschat, Timo
Heister, Wolfgang Bangerth, and Zhuoran Wang.


The first author would like to acknowledge the support of NSF Grant
No. DMS-1520862.
Timo Heister and Wolfgang Bangerth acknowledge support through NSF
awards DMS-1821210, EAR-1550901, and OAC-1835673.
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

这个程序处理的是<a
href="https://en.wikipedia.org/wiki/Biharmonic_equation">biharmonic
equation</a>。

@f{align*}{
  \Delta^2 u(\mathbf x) &= f(\mathbf x)
  \qquad \qquad &&\forall \mathbf x \in \Omega.


@f}

这个方程出现在薄结构的建模中，如体育场的屋顶。当然，这些物体在现实中是三维的，其横向范围与垂直厚度的长宽比很大，但人们通常可以通过对内力在垂直方向上的变化作出假设，将这些结构非常准确地建模为二维的。这些假设导致了上面的方程式。

该模型通常有两种不同的类型，取决于施加什么样的边界条件。第一种情况。

@f{align*}{
  u(\mathbf x) &= g(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega, \\
  \Delta u(\mathbf x) &= h(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega,


@f}

对应于连接到高度为 $g(\mathbf x)$ 的墙顶的薄结构的边缘，这样作用在结构上的弯曲力为 $h(\mathbf x)$ ；在大多数物理情况下，我们会有 $h=0$ ，对应于结构只是坐在墙顶。

在边界值的第二种可能情况下，我们将有

@f{align*}{
  u(\mathbf x) &= g(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega, \\
  \frac{\partial u(\mathbf x)}{\partial \mathbf n} &= j(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega.


@f}

这相当于一个 "钳制 "的结构，对于这个结构来说，非零的 $j(\mathbf x)$ 意味着对水平面有一定的角度。

就像拉普拉斯方程的迪里希特和诺依曼边界条件一样，当然有可能在边界的一部分有一种边界条件，而在其余部分有另一种。




<h3> What's the issue? </h3>

该方程的基本问题是它的解有四个导数。在我们在步骤3、步骤4和其他几个教程中处理的拉普拉斯方程的情况下，人们乘以一个测试函数，进行积分，通过部分积分，最后在测试函数和试验函数上只得到一个导数--对于全局连续的函数，人们可以做到这一点，但在单元之间的界面上可能有结点。导数可能不在界面上定义，但那是在一个较低维的流形上（所以不在积分值中显示出来）。

但是对于双调子方程，如果按照同样的程序，在整个领域（即所有单元的联盟）上使用积分，最终会在测试函数和试验函数上各产生两个导数。如果使用通常的片状多项式函数，并在单元格界面上有结点，那么第一个导数将产生一个不连续的梯度，第二个导数在界面上有delta函数--但由于测试函数和试验函数的第二个导数都产生一个delta函数，我们将尝试对两个delta函数的乘积进行积分。例如，在1d中， $\varphi_i$ 是通常的片状线性 "帽子函数"，我们会得到这样的积分

@f{align*}{
  \int_0^L (\Delta \varphi_i) (\Delta \varphi_j)
  =
  \int_0^L
  \frac 1h \left[\delta(x-x_{i-1}) - 2\delta(x-x_i) + \delta(x-x_{i+1})\right]
  \frac 1h \left[\delta(x-x_{j-1}) - 2\delta(x-x_j) + \delta(x-x_{j+1})\right]


@f}

其中 $x_i$ 是定义形状函数 $\varphi_i$ 的节点位置， $h$ 是网格大小（假设为均匀）。问题是，积分中的delta函数是用以下关系定义的

@f{align*}{
  \int_0^L \delta(x-\hat x) f(x) \; dx
  =
  f(\hat x).


@f}

但这只有在以下情况下才行得通：(i)  $f(\cdot)$ 实际上在 $\hat x$ 处定义良好，(ii) 它是有限的。另一方面，以下形式的积分

@f{align*}{
\int_0^L \delta(x-x_i) \delta (x-x_i)


@f}

是没有意义的。类似的推理也可以适用于2D和3D的情况。

换句话说。这种试图在整个领域内进行整合，然后再按部分进行整合的方法不可能成功。

历史上，数值分析家试图通过发明 "C<sup>1</sup>连续 "的有限元来解决这个问题，也就是说，使用的形状函数不仅是连续的，而且还有连续的一导数。这是诸如阿吉里斯元素、克拉夫-托歇尔元素和其他元素的领域，这些元素都是在20世纪60年代末开发的。从二十一世纪的角度来看，它们的结构只能说是怪异的。如果想使用一般的网格，它们的实现也是非常麻烦的。因此，它们在很大程度上已经失去了作用，deal.II目前不包含这些形状函数的实现。




<h3> What to do instead? </h3>

那么，如何解决此类问题呢？这在一定程度上取决于边界条件。如果有第一组边界条件，即，如果方程是

@f{align*}{
  \Delta^2 u(\mathbf x) &= f(\mathbf x)
  \qquad \qquad &&\forall \mathbf x \in \Omega, \\
  u(\mathbf x) &= g(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega, \\
  \Delta u(\mathbf x) &= h(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega,


@f}

那么下面的诀窍就能起作用（至少如果域是凸的，见下文）。正如我们通过引入第二个变量从常规拉普拉斯方程中得到步骤20的混合拉普拉斯方程一样，我们可以在这里引入一个变量 $v=\Delta u$ ，然后可以用下面的 "混合 "系统代替上面的方程。

@f{align*}{


  -\Delta u(\mathbf x) +v(\mathbf x) &= 0
  \qquad \qquad &&\forall \mathbf x \in \Omega, \\


  -\Delta v(\mathbf x) &= -f(\mathbf x)
  \qquad \qquad &&\forall \mathbf x \in \Omega, \\
  u(\mathbf x) &= g(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega, \\
  v(\mathbf x) &= h(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega.


@f}

换句话说，我们最终得到的实质上是 $u,v$ 的两个耦合的拉普拉斯方程组，每个方程组都有迪里希勒型边界条件。我们知道如何解决这样的问题，使用第20步或第22步的技术为这个系统构造良好的求解器和预处理器应该不是很困难。所以这种情况很容易处理。

 @note 值得指出的是，这只适用于边界有角的域，如果该域也是凸的--换句话说，如果没有重入角。   这听起来是一个相当随意的条件，但考虑到以下两个事实，它是有意义的。原始双调方程的解必须满足  $u\in H^2(\Omega)$  。另一方面，上面的混合系统重述表明， $u$ 和 $v$ 都满足 $u,v\in H^1(\Omega)$ ，因为这两个变量只解决一个泊松方程。换句话说，如果我们想确保混合问题的解 $u$ 也是原来的偏谐方程的解，那么我们需要能够以某种方式保证 $-\Delta u=v$ 的解实际上比只是 $H^1(\Omega)$ 更光滑。这一点可以作如下论证。对于凸域，<a href="https://en.wikipedia.org/wiki/Elliptic_operator#Elliptic_regularity_theorem">"elliptic
  regularity"</a>意味着，如果右侧 $v\in H^s$ ，那么 $u\in H^{s+2}$ 如果域是凸的并且边界足够光滑。(如果域的边界足够光滑，也可以保证这一点--但边界没有角的域在现实生活中不是很实用。)   我们知道 $v\in H^1$ ，因为它解决了方程 $-\Delta v=f$ ，但我们仍然留下了边界凸性的条件；我们可以证明多边形的凸域足以保证在这种情况下 $u\in H^2$ （光滑的有界凸域将导致 $u\in H^3$ ，但我们不需要这么多规则）。另一方面，如果域不是凸的，我们就不能保证混合系统的解在 $H^2$ 中，因此可能会得到一个不能等于原始偏谐方程的解。

更复杂的情况是，如果我们有 "钳制 "的边界条件，也就是说，如果方程看起来像这样。

@f{align*}{
  \Delta^2 u(\mathbf x) &= f(\mathbf x)
  \qquad \qquad &&\forall \mathbf x \in \Omega, \\
  u(\mathbf x) &= g(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega, \\
  \frac{\partial u(\mathbf x)}{\partial \mathbf n} &= j(\mathbf x) \qquad \qquad
  &&\forall \mathbf x \in \partial\Omega.


@f}

混合系统的相同技巧在这里不起作用，因为我们最终会对 $u$ 采用<i>both</i>的迪里切特和诺伊曼边界条件，但对 $v$ 则没有。


在20世纪90年代和21世纪初，这一难题的解决方案随着非连续Galerkin方法的出现而到来。与使用<i>discontinuous</i>形状函数处理拉普拉斯方程，通过惩罚不连续的大小来获得每个形状函数上有一个导数的方程的方案一样，我们可以使用一个使用<i>continuous</i>（但不是 $C^1$ 连续）形状函数的方案，惩罚导数的跳跃来获得每个形状函数上有两个导数的方案。与拉普拉斯方程的内部惩罚（IP）方法相类似，这种用于双调方程的方案通常被称为 $C^0$ IP（或C0IP）方法，因为它使用 $C^0$ （连续但不连续可微）形状函数与内部惩罚公式。




<h3> Derivation of the C0IP method </h3>

我们以Susanne Brenner和Li-Yeng Sung在 "C  $^0$  多边形域上线性四阶边界值问题的内部惩罚方法" @cite Brenner2005 中提出的 $C^0$ IP方法为基础，该方法是针对具有 "钳制 "边界条件的双谐波方程而提出的。

如前所述，这种方法依赖于使用 $C^0$ 拉格朗日有限元，其中 $C^1$ 的连续性要求被放宽，并被内部惩罚技术所取代。为了推导这个方法，我们考虑一个 $C^0$ 形状函数 $v_h$ ，它在 $\partial\Omega$ 上消失。我们引入符号 $ \mathbb{F} $ 作为 $\mathbb{T}$ 的所有面的集合， $ \mathbb{F}^b $ 作为边界面的集合， $ \mathbb{F}^i $ 作为内部面的集合，供下面进一步使用。由于 $v_h$ 的高阶导数在每个界面 $e\in \mathbb{F}$ 上有两个值（由两个单元 $K_{+},K_{-} \in \mathbb{T}$ 共享），我们通过在 $e$ 上定义以下单值函数来应对这一不连续性。

@f{align*}{
  \jump{\frac{\partial^k v_h}{\partial \mathbf n^k}}
  &=
  \frac{\partial^k v_h|_{K_+}}{\partial \mathbf n^k} \bigg |_e


  - \frac{\partial^k v_h|_{K_-}}{\partial \mathbf n^k} \bigg |_e,
  \\
  \average{\frac{\partial^k v_h}{\partial \mathbf n^k}}
  &=
  \frac{1}{2}
  \bigg( \frac{\partial^k v_h|_{K_+}}{\partial \mathbf n^k} \bigg |_e
  + \frac{\partial^k v_h|_{K_-}}{\partial \mathbf n^k} \bigg |_e \bigg )


@f}

为 $k =1,2$ （即为梯度和二阶导数矩阵），其中 $\mathbf n$ 表示从 $K_+$ 指向 $K_-$ 的一个单位向量法线。在文献中，这些函数分别被称为 "跳跃 "和 "平均 "操作。

为了得到 $C^0$ IP的近似值 $u_h$ ，我们将双调方程乘以 $v_h$ ，然后对 $\Omega$ 进行积分。如上所述，我们不能用这些形状函数对 $\Omega$ 的所有部分进行积分，但我们可以对每个单元进行积分，因为这些形状函数只是每个单元的多项式。因此，我们首先在每个网格单元 $K \in {\mathbb{T}}$ 上使用下面的分项积分公式。

@f{align*}{
  \int_K v_h (\Delta^2 w_h)
  &= \int_K v_h (\nabla\cdot\nabla) (\Delta w_h)
  \\
  &= -\int_K \nabla v_h \cdot (\nabla \Delta w_h)
     +\int_{\partial K} v_h (\nabla \Delta w_h \cdot \mathbf n).


@f}

在这一点上，我们有两个选择。我们可以再一次整合域项的 $\nabla\Delta w_h$ ，得到

@f{align*}{
  \int_K v_h (\Delta^2 w_h)
  &= \int_K (\Delta v_h) (\Delta w_h)
     +\int_{\partial K} v_h (\nabla \Delta w_h \cdot \mathbf n)


     -\int_{\partial K} (\nabla v_h \cdot \mathbf n) \Delta w_h.


@f}

由于各种原因，这被证明是一个对我们的目的没有用处的变体。

相反，我们要做的是认识到 $\nabla\Delta w_h = \text{grad}\,(\text{div}\,\text{grad}\, w_h)$  ，我们可以将这些操作重新排序为 $\nabla\Delta w_h = \text{div}\,(\text{grad}\,\text{grad}\, w_h)$ ，其中我们通常写成 $\text{grad}\,\text{grad}\, w_h = D^2 w_h$ ，表示这是第二导数的 "黑森 "矩阵。通过这样的重新排序，我们现在可以整合发散，而不是梯度算子，我们得到以下结果。

@f{align*}{
  \int_K v_h (\Delta^2 w_h)
  &= \int_K (\nabla \nabla v_h) : (\nabla \nabla w_h)
     +\int_{\partial K} v_h (\nabla \Delta w_h \cdot \mathbf n)


     -\int_{\partial K} (\nabla v_h \otimes \mathbf n) : (\nabla\nabla w_h)
  \\
  &= \int_K (D^2 v_h) : (D^2 w_h)
     +\int_{\partial K} v_h (\nabla \Delta w_h \cdot \mathbf n)


     -\int_{\partial K} (\nabla v_h) \cdot (D^2 w_h \mathbf n).


@f}

这里，冒号表示对其左边和右边的矩阵的指数进行双缩，即两个张量之间的标量乘积。两个向量 $a \otimes b$ 的外积可以得到矩阵 $(a \otimes b)_{ij} = a_i b_j$  。

然后，我们对所有单元格 $K \in  \mathbb{T}$ 进行求和，并考虑到这意味着每个内部面在求和中出现两次。因此，如果我们把所有的东西分成细胞内部的积分之和和细胞界面的单独之和，我们就可以使用上面定义的跳跃和平均运算符。还有两个步骤。首先，由于我们的形状函数是连续的，形状函数的梯度可能是不连续的，但连续性保证了实际上只有梯度的法向分量是不连续的，而切向分量是连续的。其次，当网格大小为零时，产生的离散公式并不稳定，为了得到一个稳定的公式，收敛到正确的解，我们需要增加以下条款。

@f{align*}{


-\sum_{e \in \mathbb{F}} \int_{e}
  \average{\frac{\partial^2 v_h}{\partial \mathbf n^2}}
  \jump{\frac{\partial u_h}{\partial \mathbf n}}
+ \sum_{e \in \mathbb{F}}
  \frac{\gamma}{h_e}\int_e
  \jump{\frac{\partial v_h}{\partial \mathbf n}}
  \jump{\frac{\partial u_h}{\partial \mathbf n}}.


@f}

然后，在进行出现的取消后，我们得出以下双调子方程的C0IP表述：找到 $u_h$ ，使 $u_h =
g$ 对 $\partial \Omega$ 和

@f{align*}{
\mathcal{A}(v_h,u_h)&=\mathcal{F}(v_h) \quad \text{holds for all test functions } v_h,


@f}

其中

@f{align*}{
\mathcal{A}(v_h,u_h):=&\sum_{K \in \mathbb{T}}\int_K D^2v_h:D^2u_h \ dx
\\
&


 -\sum_{e \in \mathbb{F}} \int_{e}
  \jump{\frac{\partial v_h}{\partial \mathbf n}}
  \average{\frac{\partial^2 u_h}{\partial \mathbf n^2}} \ ds


 -\sum_{e \in \mathbb{F}} \int_{e}
 \average{\frac{\partial^2 v_h}{\partial \mathbf n^2}}
 \jump{\frac{\partial u_h}{\partial \mathbf n}} \ ds
\\
&+ \sum_{e \in \mathbb{F}}
 \frac{\gamma}{h_e}
 \int_e
 \jump{\frac{\partial v_h}{\partial \mathbf n}}
 \jump{\frac{\partial u_h}{\partial \mathbf n}} \ ds,


@f}

和

@f{align*}{
\mathcal{F}(v_h)&:=\sum_{K \in \mathbb{T}}\int_{K} v_h f \ dx


-
\sum_{e \in \mathbb{F}, e\subset\partial\Omega}
\int_e \average{\frac{\partial^2 v_h}{\partial \mathbf n^2}} j \ ds
+
\sum_{e \in \mathbb{F}, e\subset\partial\Omega}
\frac{\gamma}{h_e}
\int_e \jump{\frac{\partial v_h}{\partial \mathbf n}} j \ ds.


@f}

这里， $\gamma$ 是惩罚参数，它既弱化了边界条件的执行

@f{align*}{
\frac{\partial u(\mathbf x)}{\partial \mathbf n} = j(\mathbf x)


@f}

在边界界面 $e \in \mathbb{F}^b$ 上，也确保在极限 $h\rightarrow 0$ 中， $u_h$ 收敛为 $C^1$ 连续函数。   $\gamma$ 被选择为足够大以保证方法的稳定性。我们将在下面的程序中讨论我们的选择。




<h4>Convergence Rates </h4> 在多边形域上，双调方程的弱解 $u$ 存在于 $H^{2 +\alpha}(\Omega)$ 中，其中 $\alpha \in(1/2, 2]$ 是由 $\Omega$ 的角的内角决定。例如，只要 $\Omega$ 是凸的， $\alpha=1$ ； $\alpha$ 可能小于1，如果域有重心角，但如果所有内角之一接近 $\pi$ ， $\alpha$ 就接近于 $1$  。

现在假设 $C^0$ IP解 $u_h$ 被 $C^0$ 形状函数近似，其程度为多项式 $p \ge 2$  。然后，上面概述的离散化产生了下面讨论的收敛率。


<b>Convergence in the $C^0$ IP-norm</b>

理想情况下，我们希望测量 "能量准则" $\|D^2(u-u_h)\|$ 中的收敛性。然而，这并不可行，因为同样地，离散解 $u_h$ 并没有两个（弱）导数。相反，我们可以定义一个离散的（ $C^0$  IP）半规范，"等同于 "能量规范，如下所示。

@f{align*}{
 |u_h|_{h}^2 :=
 \sum\limits_{K \in \mathbb{T}} \big|u_h\big|_{H^2(K)}^2
 +
 \sum\limits_{e \in \mathbb{F} }
 \frac{\gamma }{h_e} \left\|
 \jump{\frac{\partial u_h}{\partial \mathbf n}} \right\|_{L^2(e)}^2.


@f}



在这个半规范中，上面提到的论文中的理论得出，我们可以期望

@f{align*}{
 |u-u_h|_{h}^2 = {\cal O}(h^{p-1}),


@f}

我们知道，拉普拉斯方程的通常离散化的收敛率是真实的，这与我们所期望的差不多。

当然，只有在精确解足够平滑的情况下，这才是真的。事实上，如果 $f \in H^m(\Omega)$ 有 $m \ge 0$ ， $u \in H^{2+\alpha}(\Omega)$ 其中 $ 2 < 2+\alpha  \le m+4$ ，那么 $C^0$ IP方法的收敛率是 $\mathcal{O}(h^{\min\{p-1, \alpha\}})$ 。换句话说，只有当解平滑到 $\alpha\ge p-1$ 时，才能期待最佳收敛率；这只有在以下情况下才会发生：(i) 域是凸的，边界足够平滑，(ii)  $m\ge p-3$  。当然，在实践中，解决方案是什么就是什么（与我们选择的多项式程度无关），那么最后一个条件可以等同于说，如果 $p$ 不大，那么选择 $m$ 大肯定没有意义。换句话说， $p$ 唯一合理的选择是 $p\le
m+3$ ，因为更大的多项式度数不会导致更高的收敛阶数。

就本程序而言，我们有点懒得实际实现这个等价的语义规则--尽管这并不难，而且会成为一个很好的练习。相反，我们将简单地在程序中检查 "坏的" $H^2$ 语义规则是什么？

@f{align*}{
 \left(|u_h|^\circ_{H^2}\right)^2
 :=
 \sum\limits_{K \in \mathbb{T}} \big|u_h\big|_{H^2(K)}^2
 =
 \sum\limits_{K \in \mathbb{T}} \big|D^2 u_h\big|_{L_2}^2


@f}

产量。从理论的角度来看，这个准则的收敛率当然不可能比<i>worse</i>的收敛率高，因为它只包含了必要条件的一个子集，但至少可以想象到它会更好。还有一种情况是，即使程序中存在一个错误，我们也能得到最佳收敛率，而这个错误只会在 $|\cdot|_h$ 中出现的额外条款中显示出次优的收敛率。但是，人们可能希望，如果我们在破碎规范和下面讨论的规范中得到最优速率，那么这个程序确实是正确的。结果部分将证明，我们在所有显示的规范中都得到了最优率。


<b>Convergence in the $L_2$-norm</b>

在  $L_2$  -norm中的最佳收敛率是  $\mathcal{O}(h^{p+1})$  提供的  $p \ge 3$  。更多细节可以在  @cite Engel2002  的定理4.6中找到。

下面的程序中默认的是选择 $p=2$ 。在这种情况下，该定理并不适用，事实上，人们只能得到 $\mathcal{O}(h^2)$ 而不是 $\mathcal{O}(h^3)$ ，我们将在结果部分展示。


<b>Convergence in the $H^1$-seminorm</b>

鉴于我们在最好的情况下对相当于 $H^2$ 半规范的规范期待 $\mathcal{O}(h^{p-1})$ ，对 $L_2$ 规范期待 $\mathcal{O}(h^{p+1})$ ，人们可能会问在 $H^1$ 半规范中会发生什么，它介于其他两种规范之间。一个合理的猜测是，我们应该期待 $\mathcal{O}(h^{p})$  。可能在某个地方有一篇论文证明了这一点，但我们在下面也验证了这个猜想在实验上是真实的。




<h3>Other Boundary Conditions</h3>

我们注意到，对于具有其他边界条件的偏谐方程--例如，对于第一组边界条件即 $u(\mathbf x) =
g(\mathbf x)$ 和 $\Delta u(\mathbf x)= h(\mathbf x)$ 上的 $\partial\Omega$ --的IP方法的推导，可以通过对 $\mathcal{A}(\cdot,\cdot)$ 和 $\mathcal{F}(\cdot)$ 的适当修改得到，这些修改在书中的章节 @cite Brenner2011 中描述。




<h3>The testcase</h3>

剩下要描述的最后一步是这个程序的求解内容。像往常一样，三角函数是一个既好又坏的选择，因为它不在我们可能寻求解决方案的任何多项式空间中，同时又比实际解决方案通常更平滑（这里，它在 $C^\infty$ 中，而实际解决方案在凸多边形域上通常只在 $H^3$ 左右，如果域不是凸的，则在 $H^2$ 和 $H^3$ 之间）。但是，由于我们没有办法用相对简单的公式来描述现实问题的解决方案，所以我们就用下面的方法，在单位平方的域上 $\Omega$  。

@f{align*}{
  u = \sin(\pi x) \sin(\pi y).


@f}

因此，我们需要选择以下条件作为边界条件。

@f{align*}{
  g &= u|_{\partial\Omega} = \sin(\pi x) \sin(\pi y)|_{\partial\Omega},
  \\
  j &= \frac{\partial u}{\partial\mathbf n}|_{\partial\Omega}
  \\
    &= \left.\begin{pmatrix}
                \pi\cos(\pi x) \sin(\pi y) \\
                \pi\sin(\pi x) \cos(\pi y)
             \end{pmatrix}\right|_{\partial\Omega} \cdot \mathbf n.


@f}

右手边很容易计算为

@f{align*}{
  f = \Delta^2 u = 4 \pi^4 \sin(\pi x) \sin(\pi y).


@f}

该程序有 `ExactSolution::Solution` 和 `ExactSolution::RightHandSide` 类来编码这一信息。


examples/step-47/doc/results.dox



<h1>Results</h1>

我们用介绍中讨论的右手边和边界值运行程序。这些将产生域 $\Omega = (0,1)^2$ 上的解 $u = \sin(\pi x) \sin(\pi y)$ 。我们用 $Q_2$ 、 $Q_3$ 和 $Q_4$ 元素来测试这个设置，我们可以通过`main()`函数中的`fe_degree`变量来改变。通过网格细化， $L_2$ 的收敛率、 $H^1$ 的近似值率和 $H^2$ 的近似值收敛率对于 $u$ 应该分别为2、2、1（如介绍中所述， $L_2$ 的规范为次优）；对于 $Q_3$ 为4、3、2；而对于 $Q_4$ 为5、4、3。

从文献来看，并不立即清楚惩罚参数 $\gamma$ 应该是什么。例如， @cite Brenner2009 指出它需要大于1，并选择 $\gamma=5$  。FEniCS/Dolphin教程选择它为 $\gamma=8$  ，见https://fenicsproject.org/docs/dolfin/1.6.0/python/demo/documented/biharmonic/python/documentation.html 。   @cite Wells2007 使用的 $\gamma$ 值大于Kirchhoff板的元素所属的边数（见他们的第4.2节）。这表明也许 $\gamma = 1$ ,  $2$ , 太小了；另一方面， $p(p+1)$ 的值也是合理的，其中 $p$ 是多项式的度数。通过与拉普拉斯方程的不连续Galerkin公式相比较，人们期望最后一个选择是可行的（例如，见步骤39和步骤74的讨论），而且它在这里也将证明是可行的。但是我们应该检查 $\gamma$ 的哪个值是正确的，下面我们将这样做；改变 $\gamma$ 在`assemble_system()`中定义的两个`face_worker`和`boundary_worker`函数中很容易。




<h3>Test results on <i>Q<sub>2</sub></i><i>Q<sub>2</sub></i> with <i>&gamma; = p(p+1)</i><i>&gamma; = p(p+1)</i> </h3>

我们用不同的细化网格运行代码，得到以下收敛率。

 <table align="center" class="doxtable">
  <tr>
   <th>Number of refinements </th><th>  $\|u-u_h^\circ\|_{L_2}$ </th><th>  Conv. rates  </th><th>  $|u-u_h|_{H^1}$ </th><th> Conv. rates </th><th> $|u-u_h|_{H^2}$ </th><th> Conv. rates </th>
  </tr>
  <tr>
   <td>   2                  </td><td>   8.780e-03 </td><td>       </td><td>  7.095e-02   </td><td>           </td><td>  1.645 </td><td>   </td>
  </tr>
  <tr>
   <td>   3                  </td><td>   3.515e-03   </td><td>  1.32 </td><td> 2.174e-02  </td><td>     1.70     </td><td> 8.121e-01  </td><td>  1.018  </td>
  </tr>
  <tr>
   <td>   4                  </td><td>   1.103e-03   </td><td>  1.67   </td><td> 6.106e-03    </td><td>  1.83        </td><td>   4.015e-01 </td><td> 1.016  </td>
  </tr>
  <tr>
   <td>   5                  </td><td>  3.084e-04  </td><td>  1.83   </td><td>  1.622e-03   </td><td>    1.91        </td><td> 1.993e-01 </td><td>  1.010   </td>
  </tr>
</table>  我们可以看到， $L_2$ 的收敛率在2左右， $H^1$  -seminorm收敛率在2左右， $H^2$  -seminorm收敛率在1左右。后两者与理论上的预期收敛率相符；对于前者，我们没有定理，但鉴于介绍中的评论，对于它是次优的也不奇怪。




<h3>Test results on <i>Q<sub>3</sub></i><i>Q<sub>3</sub></i> with <i>&gamma; = p(p+1)</i><i>&gamma; = p(p+1)</i> </h3>


 <table align="center" class="doxtable">
  <tr>
   <th>Number of refinements </th><th>  $\|u-u_h^\circ\|_{L_2}$ </th><th>  Conv. rates  </th><th>  $|u-u_h|_{H^1}$ </th><th> Conv. rates </th><th> $|u-u_h|_{H^2}$ </th><th> Conv. rates </th>
  </tr>
  <tr>
   <td>   2                  </td><td>    2.045e-04 </td><td>       </td><td>   4.402e-03   </td><td>           </td><td> 1.641e-01 </td><td>   </td>
  </tr>
  <tr>
   <td>   3                  </td><td>   1.312e-05   </td><td> 3.96  </td><td>  5.537e-04  </td><td>   2.99     </td><td> 4.096e-02 </td><td>  2.00  </td>
  </tr>
  <tr>
   <td>   4                  </td><td>   8.239e-07 </td><td>  3.99  </td><td> 6.904e-05   </td><td> 3.00     </td><td> 1.023e-02 </td><td> 2.00 </td>
  </tr>
  <tr>
   <td>   5                  </td><td>   5.158e-08  </td><td>  3.99 </td><td> 8.621e-06 </td><td>  3.00      </td><td> 2.558e-03  </td><td>  2.00  </td>
  </tr>
</table>  我们可以看到， $L_2$  收敛率在4左右， $H^1$  -seminorm 收敛率在3左右， $H^2$  -seminorm 收敛率在2左右。当然，这符合我们的理论预期。




<h3>Test results on <i>Q<sub>4</sub></i><i>Q<sub>4</sub></i> with <i>&gamma; = p(p+1)</i><i>&gamma; = p(p+1)</i> </h3>

 <table align="center" class="doxtable">
  <tr>
   <th>Number of refinements </th><th>  $\|u-u_h^\circ\|_{L_2}$ </th><th>  Conv. rates  </th><th>  $|u-u_h|_{H^1}$ </th><th> Conv. rates </th><th> $|u-u_h|_{H^2}$ </th><th> Conv. rates </th>
  </tr>
  <tr>
   <td>   2                  </td><td>    6.510e-06 </td><td>       </td><td> 2.215e-04   </td><td>           </td><td>  1.275e-02 </td><td>   </td>
  </tr>
  <tr>
   <td>   3                  </td><td>   2.679e-07  </td><td>  4.60  </td><td> 1.569e-05  </td><td>   3.81    </td><td> 1.496e-03 </td><td>  3.09  </td>
  </tr>
  <tr>
   <td>   4                  </td><td>   9.404e-09  </td><td> 4.83   </td><td> 1.040e-06    </td><td> 3.91       </td><td> 1.774e-04 </td><td> 3.07 </td>
  </tr>
  <tr>
   <td>   5                  </td><td>   7.943e-10 </td><td>  3.56  </td><td>   6.693e-08 </td><td> 3.95     </td><td> 2.150e-05  </td><td> 3.04    </td>
  </tr>
</table>  我们可以看到， $L_2$  norm收敛率在5左右， $H^1$  -seminorm收敛率在4左右，而 $H^2$  -seminorm收敛率在3左右。在最细的网格上， $L_2$ 规范收敛率比我们的理论预期小得多，因为线性求解器由于舍入而成为限制因素。当然在这种情况下， $L_2$ 误差也已经非常小了。




<h3>Test results on <i>Q<sub>2</sub></i><i>Q<sub>2</sub></i> with <i>&gamma; = 1</i><i>&gamma; = 1</i> </h3>

为了与上述结果进行比较，现在让我们也考虑一下我们简单地选择 $\gamma=1$ 的情况。

 <table align="center" class="doxtable">
  <tr>
   <th>Number of refinements </th><th>  $\|u-u_h^\circ\|_{L_2}$ </th><th>  Conv. rates  </th><th>  $|u-u_h|_{H^1}$ </th><th> Conv. rates </th><th> $|u-u_h|_{H^2}$ </th><th> Conv. rates </th>
  </tr>
  <tr>
   <td>   2                  </td><td>   7.350e-02 </td><td>       </td><td>   7.323e-01   </td><td>           </td><td> 10.343 </td><td>   </td>
  </tr>
  <tr>
   <td>   3                  </td><td>   6.798e-03   </td><td> 3.43  </td><td> 1.716e-01   </td><td>   2.09    </td><td>4.836 </td><td>  1.09 </td>
  </tr>
  <tr>
   <td>   4                  </td><td>  9.669e-04   </td><td> 2.81   </td><td> 6.436e-02    </td><td> 1.41      </td><td>  3.590 </td><td> 0.430 </td>
  </tr>
  <tr>
   <td>   5                  </td><td>   1.755e-04 </td><td> 2.46 </td><td>  2.831e-02  </td><td>    1.18      </td><td>3.144  </td><td>  0.19  </td>
  </tr>
</table>  虽然 $L_2$ 规范的收敛率 $u$ 或多或少符合理论预期，但 $H^1$  -seminorm和 $H^2$  -seminorm似乎并没有像预期那样收敛。比较 $\gamma = 1$ 和 $\gamma = p(p+1)$ 的结果，很明显， $\gamma = p(p+1)$ 是一个更好的惩罚。鉴于 $\gamma=1$ 对于 $Q_2$ 元素来说已经太小了，如果用 $Q_3$ 元素重复实验，结果更加令人失望，这可能就不奇怪了。我们再次只得到2、1、0的收敛率--也就是说，不比 $Q_2$ 元素好（尽管误差的大小更小）。然而，也许令人惊讶的是，当使用 $Q_4$ 元素时，人们获得了或多或少的预期收敛顺序。无论如何，这种不确定性表明， $\gamma=1$ 充其量是一个有风险的选择，最坏的情况是一个不可靠的选择，我们应该选择 $\gamma$ 更大。




<h3>Test results on <i>Q<sub>2</sub></i><i>Q<sub>2</sub></i> with <i>&gamma; = 2</i><i>&gamma; = 2</i> </h3>

由于 $\gamma=1$ 显然太小了，人们可能猜想 $\gamma=2$ 实际上可能效果更好。下面是在这种情况下得到的结果。

 <table align="center" class="doxtable">
  <tr>
   <th>Number of refinements </th><th>  $\|u-u_h^\circ\|_{L_2}$ </th><th>  Conv. rates  </th><th>  $|u-u_h|_{H^1}$ </th><th> Conv. rates </th><th> $|u-u_h|_{H^2}$ </th><th> Conv. rates </th>
  </tr>
  <tr>
   <td>   2                  </td><td>   4.133e-02 </td><td>       </td><td>  2.517e-01   </td><td>           </td><td> 3.056 </td><td>   </td>
  </tr>
  <tr>
   <td>   3                  </td><td>  6.500e-03   </td><td>2.66  </td><td> 5.916e-02  </td><td>  2.08    </td><td>1.444 </td><td>  1.08 </td>
  </tr>
  <tr>
   <td>   4                  </td><td> 6.780e-04   </td><td> 3.26  </td><td> 1.203e-02    </td><td> 2.296      </td><td> 6.151e-01 </td><td> 1.231 </td>
  </tr>
  <tr>
   <td>   5                  </td><td> 1.622e-04 </td><td> 2.06 </td><td>  2.448e-03  </td><td>   2.297     </td><td> 2.618e-01  </td><td> 1.232  </td>
  </tr>
</table>  在这种情况下，收敛率或多或少符合理论预期，但与 $\gamma =
p(p+1)$ 的结果相比，变化更大。同样，我们可以对 $Q_3$ 和 $Q_4$ 元素重复这种实验。在这两种情况下，我们会发现我们获得了大致的预期收敛率。那么，更感兴趣的可能是比较误差的绝对大小。在上表中，对于 $Q_2$ 情况，最细网格上的误差在 $\gamma=p(p+1)$ 和 $\gamma=2$ 情况下是相当的，而对于 $Q_3$ ， $\gamma=2$ 的误差要比 $\gamma=p(p+1)$ 的大很多。对于 $Q_4$ 的情况也是如此。




<h3> Conclusions for the choice of the penalty parameter </h3>

关于应该使用哪种 "合理 "的惩罚参数的结论是， $\gamma=p(p+1)$ 产生了预期的结果。因此，它是目前编写的代码所使用的。




<h3> Possibilities for extensions </h3>

这个方案有一些明显的扩展，会有意义。

- 该程序使用一个正方形域和一个均匀的网格。真正的问题不是这样的，我们应该验证在其他形状的域上的收敛性，特别是在弯曲的边界上。人们也可能对使用自适应网格细化来解决规则性较差的区域感兴趣。

- 从更多的理论角度来看，上面的收敛结果只使用了 "破损的" $H^2$ 半规范 $|\cdot|^\circ_{H^2}$ ，而不是 "等同的 "规范 $|\cdot|_h$  。这足以让我们相信，这个程序并没有从根本上被破坏。然而，测量我们有理论结果的实际规范的误差可能是有趣的。例如，使用FEInterfaceValues类与 MeshWorker::mesh_loop() 结合，实现这一补充应该不会太困难，其精神与我们用于组装线性系统的精神相同。


  <h4> Derivation for the simply supported plates </h4>

  类似于实施中所涉及的 "夹持 "边界条件，我们将推导出 $C^0$ IP有限元方案，用于简单支撑板。   @f{align*}{
    \Delta^2 u(\mathbf x) &= f(\mathbf x)
    \qquad \qquad &&\forall \mathbf x \in \Omega,
    u(\mathbf x) &= g(\mathbf x) \qquad \qquad
    &&\forall \mathbf x \in \partial\Omega, \\
    \Delta u(\mathbf x) &= h(\mathbf x) \qquad \qquad
    &&\forall \mathbf x \in \partial\Omega.
  @f}

  我们用测试函数 $v_h$ 乘以双调方程，并对 $ K $ 进行积分，得到。   @f{align*}{
    \int_K v_h (\Delta^2 u_h)
     &= \int_K (D^2 v_h) : (D^2 u_h)
       + \int_{\partial K} v_h \frac{\partial (\Delta u_h)}{\partial \mathbf{n}}


       -\int_{\partial K} (\nabla v_h) \cdot (\frac{\partial \nabla u_h}{\partial \mathbf{n}}).
  @f}



  将所有单元格 $K \in  \mathbb{T}$ 相加，因为 $\Delta u_h$ 的法线方向在两条单元格共享的每条内边上指向相反的方向， $v_h = 0$ 在 $\partial \Omega$ 上，@f{align*}{
  \sum_{K \in \mathbb{T}} \int_{\partial K} v_h \frac{\partial (\Delta u_h)}{\partial \mathbf{n}} = 0,
  @f}

  并通过细胞界面上的跳跃定义，@f{align*}{


  -\sum_{K \in \mathbb{T}} \int_{\partial K} (\nabla v_h) \cdot (\frac{\partial \nabla u_h}{\partial \mathbf{n}}) = -\sum_{e \in \mathbb{F}} \int_{e} \jump{\frac{\partial v_h}{\partial \mathbf{n}}} (\frac{\partial^2 u_h}{\partial \mathbf{n^2}}).
  @f} 。

  我们将域的内部面和边界面分开，@f{align*}{


  -\sum_{K \in \mathbb{T}} \int_{\partial K} (\nabla v_h) \cdot (\frac{\partial \nabla u_h}{\partial \mathbf{n}}) = -\sum_{e \in \mathbb{F}^i} \int_{e} \jump{\frac{\partial v_h}{\partial \mathbf{n}}} (\frac{\partial^2 u_h}{\partial \mathbf{n^2}})


  - \sum_{e \in \partial \Omega} \int_{e} \jump{\frac{\partial v_h}{\partial \mathbf{n}}} h,
  @f} 。

  其中 $\mathbb{F}^i$ 是内部面的集合。   这使我们得出@f{align*}{
  \sum_{K \in \mathbb{T}} \int_K (D^2 v_h) : (D^2 u_h) \ dx - \sum_{e \in \mathbb{F}^i} \int_{e} \jump{\frac{\partial v_h}{\partial \mathbf{n}}} (\frac{\partial^2 u_h}{\partial \mathbf{n^2}}) \ ds
  = \sum_{K \in \mathbb{T}}\int_{K} v_h f  \ dx + \sum_{e\subset\partial\Omega} \int_{e} \jump{\frac{\partial v_h}{\partial \mathbf{n}}} h \ ds.
  @f}。



  为了使离散问题对称化和稳定化，我们加入了对称化和稳定化项。   我们最终得到双调方程的 $C^0$ IP有限元方案：找到 $u_h$ ，使 $u_h =g$ 上的 $\partial \Omega$ 和@f{align*}{
  \mathcal{A}(v_h,u_h)&=\mathcal{F}(v_h) \quad \text{holds for all test functions } v_h,
  @f}

  其中@f{align*}{
  \mathcal{A}(v_h,u_h):=&\sum_{K \in \mathbb{T}}\int_K D^2v_h:D^2u_h \ dx
  \\
  &


   -\sum_{e \in \mathbb{F}^i} \int_{e}
    \jump{\frac{\partial v_h}{\partial \mathbf n}}
    \average{\frac{\partial^2 u_h}{\partial \mathbf n^2}} \ ds


   -\sum_{e \in \mathbb{F}^i} \int_{e}
   \average{\frac{\partial^2 v_h}{\partial \mathbf n^2}}
   \jump{\frac{\partial u_h}{\partial \mathbf n}} \ ds
  \\
  &+ \sum_{e \in \mathbb{F}^i}
   \frac{\gamma}{h_e}
   \int_e
   \jump{\frac{\partial v_h}{\partial \mathbf n}}
   \jump{\frac{\partial u_h}{\partial \mathbf n}} \ ds,
  @f}

  和@f{align*}{
  \mathcal{F}(v_h)&:=\sum_{K \in \mathbb{T}}\int_{K} v_h f \ dx
  +
  \sum_{e\subset\partial\Omega}
  \int_e \jump{\frac{\partial v_h}{\partial \mathbf n}} h \ ds.
  @f}

  这个边界案例的实现与 "钳制 "版本类似，只是在系统组装时不再需要`边界_工人'，并且根据配方改变右手边。


examples/step-48/doc/intro.dox



<i>
This program was contributed by Katharina Kormann and Martin
Kronbichler.


The algorithm for the matrix-vector product is based on the article <a
href="http://dx.doi.org/10.1016/j.compfluid.2012.04.012">A generic
interface for parallel cell-based finite element operator
application</a><a
href="http://dx.doi.org/10.1016/j.compfluid.2012.04.012">A generic
interface for parallel cell-based finite element operator
application</a> by Martin Kronbichler and Katharina Kormann, Computers
and Fluids 63:135&ndash;147, 2012, and the paper &quot;Parallel finite element operator
application: Graph partitioning and coloring&quot; by Katharina
Kormann and Martin Kronbichler in: Proceedings of the 7th IEEE
International Conference on e-Science, 2011.  </i>

<a name="Intro"></a>

<h1>Introduction</h1>

这个程序演示了如何使用基于单元的有限元算子与MatrixFree类的实现，这是在step-37中首次介绍的，用于解决非线性偏微分方程。此外，我们再看一下无矩阵框架内对约束条件的处理。最后，我们将使用显式时间步进方法来解决问题，并介绍高斯-洛巴托有限元，在这种情况下非常方便，因为它们的质量矩阵可以准确地被对角线矩阵所接近，因此是可逆的。这一特性的两个成分是：首先，根据Gauss-Lobatto正交规则的点分布，对Lagrange多项式的结点进行分布。其次，正交是用同样的Gauss-Lobatto正交规则完成的。在这个公式中，只要 $\int_K \varphi_i \varphi_j
dx\approx \sum_q \varphi_i \varphi_j \mathrm{det}(J) \big |_{x_q}$ ，积分 $i\neq j$ 就会变成零，因为在定义拉格朗日多项式的点中，正好有一个函数 $\varphi_j$ 是一，其他都是零。此外，拉格朗日多项式的节点的Gauss-Lobatto分布将节点向元素边界聚集。这就为高阶离散化方法提供了条件良好的多项式基础。事实上，具有等距节点的FE_Q元素的条件数随着度数的增加而呈指数级增长，这破坏了约5级以上的任何好处。由于这个原因，高斯-洛巴托点是FE_Q元素的默认分布（但在度数为1和2时，这些点相当于等距点）。

<h3> Problem statement and discretization </h3>

作为一个例子，我们选择解决正弦-戈登孤子方程

\f{eqnarray*}
u_{tt} &=& \Delta u -\sin(u) \quad\mbox{for}\quad (x,t) \in
\Omega \times (t_0,t_f],\\
{\mathbf n} \cdot \nabla u &=& 0
\quad\mbox{for}\quad (x,t) \in \partial\Omega \times (t_0,t_f],\\
u(x,t_0) &=& u_0(x).
\f}

在步骤25中已经介绍过。作为一种简单的显式时间积分方法，我们选择使用方程的二阶表述的跃迁蛙方案。通过这个时间步长，该方案以弱的形式读取

\f{eqnarray*}
(v,u^{n+1}) = (v,2 u^n-u^{n-1} -
(\Delta t)^2 \sin(u^n)) - (\nabla v, (\Delta t)^2 \nabla u^n),
\f}其中<i> v</i>表示一个测试函数，索引<i>n</i>代表时间步数。

对于空间离散化，我们选择FE_Q元素，其基函数定义为插值高斯-洛巴托正交规则的支持点。此外，当我们计算基函数的积分以形成质量矩阵和上述方程右边的算子时，我们使用高斯-洛巴托正交规则，其支持点与有限元的节点点相同，以评估积分。由于有限元是拉格朗日的，这将产生方程左侧的对角线质量矩阵，使每个时间步长的线性系统的解变得微不足道。

使用这个正交规则，对于<i>p</i>th阶有限元，我们使用<i>(2p-1)</i>th阶精确公式来评估积分。由于在计算质量矩阵时，两个<i>p</i>阶基函数的乘积在每个方向上给出了一个具有多项式程度<i>2p</i>的函数，所以积分的计算并不精确。  然而，在具有仿生元素形状的网格上，整体收敛特性不受正交误差的干扰，L2误差与<i>h<sup>p+1</sup></i>成正比。但是请注意，当积分不再是多项式时，一些三维设置的L2误差<i>O(h<sup>p</sup>)</i>甚至<i>O(h<sup>p-1</sup>)</i>的次优收敛率的阶次减少已被报道<a href="https://dx.doi.org/10.1002/num.20353">in
literature</a>在变形（非affine）元素形状的波方程上。

除了在使用显式时间步进时我们可以避免用这种类型的元素来解决线性系统外，它们还具有另外两个优点。当我们使用和-因子化方法来评估有限元算子时（参见步骤37），我们必须在正交点评估函数。在Gauss-Lobatto元素的情况下，正交点和有限元的节点点重合，这种操作是微不足道的，因为正交点的函数值是由其一维系数给出的。这样一来，与一般的高斯正交相比，有限元算子评估的算术工作减少了大约两倍。

总结一下讨论，通过使用正确的有限元和正交规则组合，我们最终得到一个方案，我们只需要计算对应于上述公式的右手边向量，然后在每个时间步骤中乘以对角线质量矩阵的逆。当然，在实践中，我们提取对角线元素，只在程序开始时反转一次。

<h3>Implementation of constraints</h3>

在 <code>deal.II</code> 中处理约束的通常方法是使用AffineConstraints类，该类建立了一个稀疏矩阵，存储关于哪些自由度（DoF）被约束以及如何被约束的信息。这种格式使用了不必要的大量内存，因为没有那么多不同类型的约束：例如，在每个单元上使用线性有限元时，悬挂节点的情况下，大多数约束具有 $x_k = \frac 12 x_i + \frac 12 x_j$ 的形式，其中系数 $\frac 12$ 总是相同，只有 $i,j,k$ 不同。虽然存储这些多余的信息在一般情况下不是问题，因为在矩阵和右手边的装配过程中只需要一次，但在无矩阵的方法中，它成为一个瓶颈，因为在那里，每次我们应用算子时都要访问这些信息，而算子评估的其余部分是如此之快。因此，MatrixFree使用一个我们称为 <code>constraint_pool</code> 的变量来收集不同约束的权重，而不是AffineConstraints对象。然后，只需要存储网格中每个约束的标识符而不是所有的权重。此外，约束不是在前后处理步骤中应用的，而是在我们评估有限元算子时应用的。因此，约束信息被嵌入到变量 <code>indices_local_to_global</code> 中，用于从全局矢量中提取单元信息。如果一个DoF被约束， <code>indices_local_to_global</code> 变量包含它被约束的DoF的全局索引。然后，我们手头还有另一个变量 <code>constraint_indicator</code> ，对于每个单元，持有被约束的DoF的局部指数以及约束类型的标识符。幸运的是，你不会在示例程序中看到这些数据结构，因为类 <code>FEEvaluation</code> 会在没有用户互动的情况下处理这些约束。

在存在悬空节点的情况下，通过Gauss-Lobatto正交/节点点程序在元素层面获得的对角线质量矩阵并不能直接转化为对角线全局质量矩阵，因为遵循行和列的约束也会增加非对角线的条目。正如在<a href="https://dx.doi.org/10.4208/cicp.101214.021015a">Kormann
(2016)</a>中所解释的，在一个矢量上插值约束，保持质量矩阵的对角线形状，与方程一致，直到与正交误差相同大小的误差。在下面的程序中，我们将简单地组装质量矩阵的对角线，就像它是一个矢量一样，以实现这种近似。




<h3> Parallelization </h3>

MatrixFree类可以在三个层次上进行并行化。分布式节点集群上的MPI并行化，由线程积木库安排的线程并行化，以及最后通过SIMD数据类型在两个（或更多）单元的批次上工作的矢量化（有时称为跨元素或外部矢量化）。正如我们在第37步中已经讨论过的，通过使用特定于你的系统的指令集，你将得到最好的性能，例如，使用cmake变量<tt>-DCMAKE_CXX_FLAGS="-march=native"</tt>。MPI并行化已经在步骤37中被利用了。这里，我们额外考虑用TBB进行线程并行化。这相当简单，因为我们需要做的就是告诉MatrixFree对象的初始化，我们想通过变量 MatrixFree::AdditionalData::thread_parallel_scheme. 来使用线程并行方案。 在设置过程中，建立了一个类似于 @ref workstream_paper 中描述的依赖图，这允许安排 @p local_apply 函数在单元块上的工作，而没有几个线程访问同一个向量索引。相对于WorkStream循环，还应用了一些额外的巧妙技巧来避免<a
href="https://dx.doi.org/10.1109/eScience.2011.53">Kormann and Kronbichler
(2011)</a>中描述的全局同步。

请注意，这个程序是为分布式三角测量 (parallel::distributed::Triangulation), 而设计的，它要求deal.II配置<a href="http://www.p4est.org/">p4est</a>，如<a href="../../readme.html">deal.II ReadMe</a>文件中所述。然而，也支持非分布式三角法，在这种情况下，计算将以串行方式运行。

<h3> The test case </h3>

在我们的例子中，我们选择初始值为\f{eqnarray*} u(x,t) =
\prod_{i=1}^{d} -4 \arctan \left(
\frac{m}{\sqrt{1-m^2}}\frac{\sin\left(\sqrt{1-m^2} t +c_2\right)}{\cosh(mx_i+c_1)}\right)
\f}，并在时间区间[-10,10]内解决方程。常数被选择为 $c_1=c_1=0$ 和<i> m=0.5</i>。如步骤25所述，在一维中<i>u</i>作为<i>t</i>的函数是正弦-戈登方程的精确解。然而，对于更高的维度，情况并非如此。


examples/step-48/doc/results.dox



<h1>Results</h1>

<h3>Comparison with a sparse matrix</h3>

为了证明使用MatrixFree类而不是标准的 <code>deal.II</code> 汇编例程来评估旧时间步长的信息的好处，我们研究了代码在非自适应网格上的一个简单串行运行。由于很多时间花在评估正弦函数上，我们不仅显示了完整的正弦-戈登方程的数字，还显示了波浪方程（正弦-戈登方程中跳过的正弦项）的数字。我们同时使用二阶和四阶元素。结果总结在下表中。

 <table align="center" class="doxtable">
  <tr>
    <th>&nbsp;</th>
    <th colspan="3">wave equation</th>
    <th colspan="2">sine-Gordon</th>
  </tr>
  <tr>
    <th>&nbsp;</th>
    <th>MF</th>
    <th>SpMV</th>
    <th>dealii</th>
    <th>MF</th>
    <th>dealii</th>
  </tr>
  <tr>
    <td>2D, $\mathcal{Q}_2$</td>
    <td align="right"> 0.0106</td>
    <td align="right"> 0.00971</td>
    <td align="right"> 0.109</td>
    <td align="right"> 0.0243</td>
    <td align="right"> 0.124</td>
  </tr>
  <tr>
    <td>2D, $\mathcal{Q}_4$</td>
    <td align="right"> 0.0328</td>
    <td align="right"> 0.0706</td>
    <td align="right"> 0.528</td>
    <td align="right"> 0.0714</td>
    <td align="right"> 0.502</td>
   </tr>
   <tr>
    <td>3D, $\mathcal{Q}_2$</td>
    <td align="right"> 0.0151</td>
    <td align="right"> 0.0320</td>
    <td align="right"> 0.331</td>
    <td align="right"> 0.0376</td>
    <td align="right"> 0.364</td>
   </tr>
   <tr>
    <td>3D, $\mathcal{Q}_4$</td>
    <td align="right"> 0.0918</td>
    <td align="right"> 0.844</td>
    <td align="right"> 6.83</td>
    <td align="right"> 0.194</td>
    <td align="right"> 6.95</td>
   </tr>
</table> 

很明显，无矩阵代码远远超过了deal.II中的标准汇编程序。在三维和四阶元素中，一个运算符的评估速度也几乎是稀疏矩阵-向量乘积的十倍。

<h3>Parallel run in 2D and 3D</h3>

我们从一个具有12个核心/24个线程的工作站（一个英特尔至强E5-2687W v4 CPU运行在3.2 GHz，启用了超线程）上获得的程序输出开始，以发布模式运行程序。

@code
\$ make run
Number of MPI ranks:            1
Number of threads on each rank: 24
Vectorization over 4 doubles = 256 bits (AVX)


   Number of global active cells: 15412
   Number of degrees of freedom: 249065
   Time step size: 0.00292997, finest cell: 0.117188


   Time:     -10, solution norm:  9.5599
   Time:   -9.41, solution norm:  17.678
   Time:   -8.83, solution norm:  23.504
   Time:   -8.24, solution norm:    27.5
   Time:   -7.66, solution norm:  29.513
   Time:   -7.07, solution norm:  29.364
   Time:   -6.48, solution norm:   27.23
   Time:    -5.9, solution norm:  23.527
   Time:   -5.31, solution norm:  18.439
   Time:   -4.73, solution norm:  11.935
   Time:   -4.14, solution norm:  5.5284
   Time:   -3.55, solution norm:  8.0354
   Time:   -2.97, solution norm:  14.707
   Time:   -2.38, solution norm:      20
   Time:    -1.8, solution norm:  22.834
   Time:   -1.21, solution norm:  22.771
   Time:  -0.624, solution norm:  20.488
   Time: -0.0381, solution norm:  16.697
   Time:   0.548, solution norm:  11.221
   Time:    1.13, solution norm:  5.3912
   Time:    1.72, solution norm:  8.4528
   Time:    2.31, solution norm:  14.335
   Time:    2.89, solution norm:  18.555
   Time:    3.48, solution norm:  20.894
   Time:    4.06, solution norm:  21.305
   Time:    4.65, solution norm:  19.903
   Time:    5.24, solution norm:  16.864
   Time:    5.82, solution norm:  12.223
   Time:    6.41, solution norm:   6.758
   Time:    6.99, solution norm:  7.2423
   Time:    7.58, solution norm:  12.888
   Time:    8.17, solution norm:  17.273
   Time:    8.75, solution norm:  19.654
   Time:    9.34, solution norm:  19.838
   Time:    9.92, solution norm:  17.964
   Time:      10, solution norm:  17.595


   Performed 6826 time steps.
   Average wallclock time per time step: 0.0013453s
   Spent 14.976s on output and 9.1831s on computations.
@endcode



在3D中，各自的输出看起来像

@code
\$ make run
Number of MPI ranks:            1
Number of threads on each rank: 24
Vectorization over 4 doubles = 256 bits (AVX)


   Number of global active cells: 17592
   Number of degrees of freedom: 1193881
   Time step size: 0.0117233, finest cell: 0.46875


   Time:     -10, solution norm:  29.558
   Time:   -7.66, solution norm:  129.13
   Time:   -5.31, solution norm:  67.753
   Time:   -2.97, solution norm:  79.245
   Time:  -0.621, solution norm:  123.52
   Time:    1.72, solution norm:  43.525
   Time:    4.07, solution norm:  93.285
   Time:    6.41, solution norm:  97.722
   Time:    8.76, solution norm:  36.734
   Time:      10, solution norm:  94.115


   Performed 1706 time steps.
   Average wallclock time per time step: 0.0084542s
   Spent 16.766s on output and 14.423s on computations.
@endcode



一个自由度超过一百万的时间步长需要0.008秒（注意，在求解线性系统时，我们需要许多处理器来达到这样的数字）。

如果我们用一个纯粹的MPI并行化取代线程并行化，时间就会变成。

@code
\$ mpirun -n 24 ./step-48
Number of MPI ranks:            24
Number of threads on each rank: 1
Vectorization over 4 doubles = 256 bits (AVX)
...
   Performed 1706 time steps.
   Average wallclock time per time step: 0.0051747s
   Spent 2.0535s on output and 8.828s on computations.
@endcode



我们观察到输出的急剧加速（这是有道理的，因为输出的大部分代码没有通过线程并行化，而对于MPI则是如此），但低于我们从并行性中期望的12的理论系数。更有趣的是，当从纯线程变量切换到纯MPI变量时，计算也变得更快。这是MatrixFree框架的一个一般观察结果（截至2019年更新此数据）。主要原因是，为实现并行执行而做出的关于冲突单元批处理工作的决定过于悲观：虽然它们确保在不同的线程上不会同时进行相邻单元的工作，但这种保守的设置意味着在相邻单元被触及时，相邻单元的数据也会从缓存中被驱逐。此外，对于给定的具有17592个单元的网格，目前的方案无法为所有24个线程提供一个恒定的负载。

目前的程序还允许将MPI并行化与线程并行化混合起来。在有多个节点的集群上运行程序时，这是最有利的，使用MPI进行节点间并行化，使用线程进行节点内并行化。在上面使用的工作站上，我们可以在超线程区域运行线程（即为12个MPI行列中的每一个使用2个线程）。将MPI与线程混合的一个重要设置是确保将任务适当地分到CPU上。在许多集群上，放置是通过`mpirun/mpiexec`环境自动进行的，或者可以有手动设置。在这里，我们简单地报告了程序的普通版本的运行时间（注意到当适当的分档完成后，事情可以向仅有MPI的程序的时间改进）。

@code
\$ mpirun -n 12 ./step-48
Number of MPI ranks:            12
Number of threads on each rank: 2
Vectorization over 4 doubles = 256 bits (AVX)
...
   Performed 1706 time steps.
   Average wallclock time per time step: 0.0056651s
   Spent 2.5175s on output and 9.6646s on computations.
@endcode






<h3>Possibilities for extensions</h3>

这个程序中有几处可以改进，使其更加有效（除了步骤25中讨论的改进边界条件和物理东西）。

 <ul>   <li>  <b>Faster evaluation of sine terms:</b> 从上面平波方程和正弦-戈登方程的比较中可以明显看出，正弦项的评估在有限元算子应用的总时间中占主导地位。这有几个原因。首先，VectorizedArray场的deal.II正弦计算没有被矢量化（与算子应用的其他部分相反）。这可以通过将正弦计算交给一个具有矢量化正弦计算的库来解决，比如英特尔的数学内核库（MKL）。通过使用MKL中的函数 <code>vdSin</code> ，该程序在二维中使用了一半的计算时间，在三维中使用了40%的时间。另一方面，正弦计算在结构上要比其他本地操作中的加法和乘法等简单算术操作复杂得多。

    <li>  <b>Higher order time stepping:</b> 虽然该实现允许空间部分的任意顺序（通过调整有限元的程度），但时间步进方案是一个标准的二阶跃迁方案。由于波的传播问题的解通常是非常平滑的，所以误差很可能被时间步进部分所支配。当然，这可以通过使用较小的时间步长（在固定的空间分辨率下）来解决，但如果使用高阶时间步长也会更有效率。虽然对于一阶系统来说，这样做是很简单的（使用一些高阶的Runge&ndash;Kutta方案，可能结合像<a
  href="http://en.wikipedia.org/wiki/Dormand%E2%80%93Prince_method">Dormand&ndash;Prince
  method</a>那样的自适应时间步长选择），但对于二阶公式来说，这更具挑战性。至少在有限差分社区，人们通常使用PDE来寻找改善时间误差的空间修正项。

 </ul> 


examples/step-49/doc/intro.dox

<i>This program was contributed by Timo Heister. Parts of the results section
were contributed by Yuhan Zhou, Wolfgang Bangerth, and David Wells.</i>

<a name="Intro"></a>

<h1> Introduction </h1> 本教程是步骤1的扩展，演示了几种获得比那里显示的更多的网格的方法。

 @note  本教程也可作为Jupyter Python笔记本，使用deal.II python接口。该笔记本与原始的C++程序在同一目录下提供。

生成复杂的几何图形是一项具有挑战性的任务，特别是在三个空间维度。我们将讨论几种方法，但这个清单并不详尽。此外，没有一种方法适合所有的问题。

这个例子程序显示了一些为计算而创建和修改网格的方法，并以与我们在步骤1中相同的方式将它们输出为 <code>.vtu</code> 文件。没有做其他的计算或自适应细化；我们的想法是，你可以在其他更多的模拟器中使用这里的技术作为构建模块。请注意，这个例子程序并没有展示本介绍中讨论的所有生成网格的方法。




<h3>General concerns about meshes</h3>

当你使用自适应网格细化时，你肯定希望初始网格尽可能地粗大。因为只要你有内存和CPU时间，你就可以用自适应细化技术把它做得越细越好。然而，这就要求你不要把网格单元浪费在域的某些地方，因为这些单元是没有价值的。因此，你不希望从一个太细的网格开始，因为这已经占用了你的单元预算的很大一部分，而且你无法粗化初始网格中的单元。

也就是说，你的网格需要充分捕捉给定的几何体。




<h3>How to create meshes</h3>

有几种方法来创建一个初始网格。网格可以通过多种方式进行修改或组合，这一点将在后面讨论。

<h4>Using GridGenerator</h4>

生成网格的最简单方法是使用命名空间GridGenerator中的函数，这在步骤1中已经讨论过了。  有许多不同的辅助函数可用，包括 GridGenerator::hyper_cube(),   GridGenerator::hyper_shell(),   GridGenerator::hyper_ball(),  和  GridGenerator::hyper_cube_with_cylindrical_hole().  。




<h4>Constructing your own mesh programmatically</h4>

如果GridGenerator命名空间中没有适合你想做的事情，你总是可以在你的程序中 "手工 "创建一个三角图。为此，你需要一个带有坐标的顶点列表和一个引用这些顶点的单元格列表。你可以在步骤14的函数<tt>create_coarse_grid()</tt>中找到一个例子。GridGenerator中的所有函数都以这种方式实现。

我们很乐意接受更多的功能加入到GridGenerator中。因此，如果你最终写了一个可能对更多人有用的函数，请将其贡献出来。




<h4>Importing from external programs</h4>

GridIn类可以从磁盘的文件中读取许多不同的网格格式。如何做到这一点，在步骤5中有解释，在本例中可以看到函数 <code>grid_1</code> ，见下面的代码。

网格可以由不同的工具生成，如<a
href="http://gmsh.info" target="_top">gmsh</a>、<a
href="https://lagrit.lanl.gov/" target="_top">lagrit</a>和<a
href="http://cubit.sandia.gov/" target="_top">cubit</a>。更多信息见GridIn的文档。问题是，deal.II需要的网格只由四边形和六面体组成--四面体的网格无法工作（这意味着不能直接使用tetgen等工具）。

我们将描述一个使用%Gmsh的可能工作流程。%Gmsh是我们所知道的最小和最快速设置的开源工具。它可以生成非结构化的二维四面体网格。在三维中，它可以挤压二维网格以获得六面体网格；将非结构化几何体三维网格化为六面体是可能的，尽管这些网格的质量有一些问题，意味着这些网格有时只能在交易中工作。

在%Gmsh中，一个网格的基本描述是基于文本的 <code>.geo</code> 文件，其格式可以包含计算、循环、变量等。这种格式在允许描述复杂的几何图形方面是相当灵活的。然后，网格是由表面表示法生成的，表面表示法是由线条循环列表建立的，线条循环列表又是由点建立的。 <code>.geo</code>  脚本可以用手写和编辑，也可以通过在%Gmsh内用图形创建对象来自动生成。在许多情况下，最好是把这两种方法结合起来。如果你想用手写的话，可以在 "几何 "选项卡下按 "重载 "来轻松地重新加载文件，并在gmsh的图形用户界面上看到效果。

本教程包含一个例子 <code>.geo</code> 文件，描述一个内部有两个物体被切割出来的盒子。这就是 <code>example.geo</code> 在%Gmsh中的样子（显示边界指标以及下面要讨论的网格）。

 <img src="https://www.dealii.org/images/steps/developer/step-49.gmsh_picture.png" alt=""> 

你可能想用文本编辑器打开 <code>example.geo</code> 文件（它与<tt>step-49.cc</tt>源文件位于同一目录），看看它是如何结构的。你可以看到域的边界是如何由一些线组成的，后来我们把几条线组合成 "物理线"（或 "物理面"），列出逻辑线的编号。"物理 "对象是携带边界指标信息的对象（见 @ref GlossBoundaryIndicator "本词汇表条目"）。

 @note  这个文件包含 "物理线 "和 "物理面 "是很重要的。它们提供了在deal.II中使用的边界指标和材料ID。没有这些物理实体，任何东西都不会被导入deal.II中。

deal.II的GridIn类可以读取%Gmsh编写的 <code>.msh</code> 格式，该格式包含为 <code>.geo</code> file. You generate the <code>.msh</code> 描述的几何体创建的网格，通过运行指令

@code
gmsh -2 example.geo
@endcode



在命令行中，或者在加载文件后点击%Gmsh中的 "Mesh "和 "2D"。  现在这是从 <code>.msh</code> 文件中读取的网格，并由deal.II再次保存为图像（见当前程序的 <code>grid_1</code> 功能）。

 <img src="https://www.dealii.org/images/steps/developer/step-49.grid-1.png" alt=""> 

 @note  %Gmsh有许多其他接口，人们可以通过这些接口来描述几何图形。特别是，它能够与Python和Julia等脚本语言连接，但也可以用C++编写脚本。这些接口很有用，如果人们不只是想为一个单一的几何体生成网格（在这种情况下，图形界面或者在简单的情况下，手写的".geo "文件可能是最简单的方法），而是想对几何体进行参数化研究，为此需要为某些参数不同的几何体生成许多网格。另一种情况是，如果已经有一个CAD几何体，只需要一个网格；事实上，这可以在deal.II中使用 Gmsh::create_triangulation_from_boundary_curve() 函数来完成。




<h3>Modifying a Mesh</h3>

在以上述方式获得一个（或几个）网格后，在将其用于有限元计算之前，有许多方法可以对其进行操作。




<h4>Transformations</h4>

GridTools命名空间包含了一系列的小函数，用于以各种方式转换给定的网格。函数  GridTools::shift,   GridTools::rotate,   GridTools::scale  的用法相当明显，所以我们在此不讨论这些函数。

函数 GridTools::transform 允许你使用平滑函数对给定网格的顶点进行变换。在step-38的结果部分也给出了它的使用实例，但让我们在这里展示一个更简单的例子。在当前程序的函数 <code>grid_5()</code> 中，我们用正弦曲线对网格的y坐标进行扰动。

 <table width="60%" align="center">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-5a.png" alt=""> regular input mesh
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-5.png" alt=""> output mesh
    </td>
  </tr>
</table> 

同样地，我们可以用公式  $(x,y) \mapsto (x,\tanh(2 y)/\tanh(2))$  将一个有规律的细化单位方格转换为y方向的墙体适应网格。这在本教程的  <code>grid_6()</code>  中完成。   <table width="60%" align="center">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-6a.png" alt=""> regular input mesh
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-6.png" alt=""> wall-adapted output mesh
    </td>
  </tr>
</table> 

最后，函数 GridTools::distort_random 允许你将网格中的顶点（可选择忽略边界节点）随机移动。这在 <code>grid_7()</code> 中进行了演示，其结果如下。

 <table width="60%" align="center">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-7a.png" alt=""> regular input mesh
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-7.png" alt=""> perturbed output mesh
    </td>
  </tr>
</table> 

这个函数主要是为了否定在研究常规网格收敛时得到的一些超收敛效应，以及抑制deal.II中的一些优化，这些优化可以利用单元格形状相似的事实。超级收敛是指如果一个网格具有某些对称性--例如，如果进入一个顶点的边对这个顶点是对称的，并且如果对一个单元的所有顶点都是这样的话

归根结底，这是由于如果对误差进行泰勒扩展，对称性导致了这样一个事实，即预期的扩展的下一个项恰好是零，而误差的阶数是由*第二个下*项决定的。一个扭曲的网格没有这些对称性，因此误差反映了在*任何*种网格上解方程时将会看到的情况，而不是显示只反映特定情况的东西)。




<h4>Merging Meshes</h4>

该函数 GridGenerator::merge_triangulations() 允许你将两个给定的三角形对象合并为一个。  要做到这一点，共享边或面的顶点必须完全匹配。  排列两个网格可以用  GridTools::shift  和  GridTools::scale.  来实现。 在本教程的函数  <code>grid_2()</code>  中，我们合并了一个带圆孔的正方形（用  GridGenerator::hyper_cube_with_cylindrical_hole())  生成）和一个矩形（用  GridGenerator::subdivided_hyper_rectangle()).  生成）。 函数  GridGenerator::subdivided_hyper_rectangle()  允许你指定重复的数量和角的位置，所以这里不需要手动移动三角网格。你应该以图形方式检查网格，以确保单元格排布正确，并且在合并后的三角图中不存在未配对的节点。

这些是输入网格和输出网格。

 <table width="80%" align="center">
  <tr>
    <td align="center"><img src="https://www.dealii.org/images/steps/developer/step-49.grid-2a.png" alt="" height="200px">input mesh 1</td>
    <td align="center"><img src="https://www.dealii.org/images/steps/developer/step-49.grid-2b.png" alt="" height="200px">input mesh 2</td>
    <td align="center"><img src="https://www.dealii.org/images/steps/developer/step-49.grid-2.png" alt="" height="200px">merged mesh</td>
  </tr>
</table> 




<h4>Moving Vertices</h4>

函数  <code>grid_3()</code>  展示了在现有网格中挑选个别顶点并移动它们的能力。请注意，这有可能产生退化的或倒置的单元，你不应该期望使用这样的网格会产生任何有用的东西。在这里，我们通过向上移动顶部顶点来创建一个不完全居中的圆柱形孔的盒子。

 <table width="60%" align="center">
  <tr>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-3a.png" alt="" height="200px"> input mesh
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-49.grid-3.png" alt="" height="200px"> top vertices moved upwards
    </td>
  </tr>
</table> 

关于如何做到这一点的确切方法，见下面的代码。




<h4>Extruding Meshes</h4>

如果你需要一个可以通过挤压给定的2D网格（可以通过上述任何一种方式创建）来创建的3D网格，你可以使用函数  GridGenerator::extrude_triangulation().  参见本教程中的  <code>grid_4()</code>  函数为例。请注意，对于这个特殊的情况，所给的结果也可以用3D版本的 GridGenerator::hyper_cube_with_cylindrical_hole(). 来实现。主要的用法是一个2D网格，例如用%Gmsh生成，如上所述从 <code>.msh</code> 文件中读入。这是grid_4()的输出。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-49.grid-4base.png" alt=""> input mesh
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-49.grid-4.png" alt=""> extruded output mesh
    </td>
  </tr>
</table> 




<h3> After you have a coarse mesh </h3>

使用上面讨论的方法创建一个粗略的网格只是第一步。当你有了它，它通常可以作为进一步细化网格的基础。这并不困难，事实上，如果你的几何体只由直面组成，那就没有其他事情可做。然而，如果你有一个更复杂的几何体，情况往往就不是这样了，除了创建网格之外，还有更多的步骤是必须的。我们将在下面的<a href="#Results">results section</a>中详细介绍这些步骤。


examples/step-49/doc/results.dox



<h1>Results</h1>

该程序产生一系列 <code>.vtu</code> 的三角形文件。这些方法已在上文讨论。




<h3>Next steps: Curved Cells</h3>

正如介绍中提到的，使用这里讨论的方法创建一个粗略的网格只是第一步。为了细化网格，Triangulation需要知道在边、面和单元格的中点上放置新的顶点。默认情况下，这些新的点会被放置在周围点的算术平均值上，但如果你需要的是粗略网格没有充分解决的弯曲边界，这并不是你想要的。例如，对于这个网格，中心孔应该是圆形的。

 <img src="https://www.dealii.org/images/steps/developer/step-49.grid-2a.png" alt="" height="200px"> 

如果你只是简单地细化它，三角测量类就不能知道你是想让孔变成圆形还是八角形。默认的做法是沿着现有的直线放置新的点。经过两个网格细化步骤后，这将产生以下的网格，这不是我们想要的。

 <img src="https://www.dealii.org/images/steps/developer/step-49.grid-2d-refined.png" alt="" height="200px"> 

需要发生的是，你告诉三角函数，你实际上是想使用一个弯曲的几何体。做到这一点的方法需要三个步骤。

- 创建一个描述所需几何图形的对象。这个对象将在细化三角图以获得新的点位置时被查询。如果在系统组装过程中使用了MappingQ或MappingQGeneric这样的高阶映射，它也将被用来计算形状函数值。   在deal.II中，Manifold类和继承自它的类（如PolarManifold和FlatManifold）执行这些计算。

- 通知Triangulation对象使用哪个Manifold类。默认情况下，Triangulation使用FlatManifold来进行所有的几何计算，它假定所有的单元格边缘都是直线，所有的四边形都是平的。你可以通过调用 Triangulation::set_manifold 函数将Manifold类附加到Triangulation上，该函数将 <code>manifold_id</code> 与Manifold对象关联。关于这方面的更多信息，请参见 @ref GlossManifoldIndicator "关于这个主题的词汇表条目"。

- 最后，你必须用正确的 <code>manifold_id</code> 标记单元和单元面。例如，你可以通过以下方式得到一个在直角坐标中带有弯曲单元的环形扇面（但在极坐标中是矩形）。   @code
  Triangulation<2> tria;
  GridGenerator::hyper_cube(tria);
  const auto cell = tria.begin_active();
  cell->vertex(2) = Point<2>(-0.5, 1.0);
  cell->vertex(3) = Point<2>(1.5, 1.0);
  tria.set_all_manifold_ids(42);
  tria.set_manifold(42, PolarManifold<2>(Point<2>(0.5, -1.0)));
  tria.refine_global(3);
  @endcode

  现在，当网格被细化时，所有的单元格分割计算都将在极坐标中进行。

GridGenerator命名空间中的所有函数，如果创建的网格中的某些单元应该是弯曲的，也会将正确的Manifold对象附加到所提供的Triangulation上：也就是说，对于这些函数，我们默认会得到正确的行为。然而，对于手工生成的网格，情况要有趣得多。

为了更详细地说明这个过程，让我们考虑一个由Yuhan Zhou创建的例子，作为2013年德克萨斯A&amp;M大学的一个学期项目的一部分。目标是生成（和使用）一个描述微观结构的电气设备的几何体。在一个CAD程序中，这个几何体看起来像这样。

 <img src="https://www.dealii.org/images/steps/developer/step-49.yuhan.1.png" alt=""> 

在下文中，我们将引导你完成为这个几何体创建网格的整个过程，包括通过展示可能出错的一些常见陷阱。

实现这一目标的第一步是创建一个粗略的网格，通过为每个截面创建一个2D粗略的网格，将它们挤压到第三个方向，然后将它们粘在一起。下面的代码使用之前描述的技术来完成这个工作。

@code
// Given a list of points and how vertices connect to cells, create a
// mesh. This is in the same way as we do in step 14.
void create_2d_grid(
  const std::vector<Point<2>> &vertices,
  const std::vector<
    std::array<unsigned int, GeometryInfo<2>::vertices_per_cell>>
    &               vertex_indices,
  Triangulation<2> &coarse_grid)
{
  std::vector<CellData<2>> cells(vertex_indices.size());
  for (unsigned int i = 0; i < cells.size(); ++i)
    {
      for (unsigned int j = 0; j < vertex_indices[i].size(); ++j)
        cells[i].vertices[j] = vertex_indices[i][j];
    }


  coarse_grid.create_triangulation(vertices, cells, SubCellData());
}



// Create a triangulation that covers the entire volume
void create_3d_grid(Triangulation<3> &triangulation)
{
  // Generate first cross section
  const std::vector<Point<2>> vertices_1{{-1.5, 0.},
                                         {-0.5, 0.},
                                         {0.5, 0.},
                                         {1.5, 0.},


                                         {-1.5, 1.5},
                                         {-0.5, 1.5},
                                         {0.5, 1.5},
                                         {1.5, 1.5},


                                         {-1.5, 3.},
                                         {-0.5, 3.},
                                         {0.5, 3.},
                                         {1.5, 3.},


                                         {-0.5, 3 + 0.5 * sqrt(3)},
                                         {0.5, 3 + 0.5 * sqrt(3)},


                                         {-0.75, 3 + 0.75 * sqrt(3)},
                                         {0.75, 3 + 0.75 * sqrt(3)}};


  const std::vector<std::array<unsigned int, GeometryInfo<2>::vertices_per_cell>>
    cell_vertices_1 = {{{0, 1, 4, 5}},
                       {{1, 2, 5, 6}},
                       {{3, 7, 2, 6}},
                       {{4, 5, 8, 9}},
                       {{5, 6, 9, 10}},
                       {{7, 11, 6, 10}},
                       {{8, 9, 14, 12}},
                       {{9, 10, 12, 13}},
                       {{11, 15, 10, 13}},
                       {{14, 12, 15, 13}}};


  // Copy vertices into a 2d triangulation
  Triangulation<2> triangulation_2d_1;
  create_2d_grid(vertices_1, cell_vertices_1, triangulation_2d_1);


  // Then extrude it into a 3d piece
  Triangulation<3> triangulation_3d_1;
  GridGenerator::extrude_triangulation(triangulation_2d_1,
                                       5,
                                       2.5,
                                       triangulation_3d_1);


  // Now do the same with the second volume
  const std::vector<Point<2>> vertices_2{{-2.5, 0.},
                                         {-1.5, 0.},
                                         {-0.5, 0.},
                                         {0.5, 0.},
                                         {1.5, 0.},
                                         {2.5, 0.},


                                         {-2.5, 1.5},
                                         {-1.5, 1.5},
                                         {-0.5, 1.5},
                                         {0.5, 1.5},
                                         {1.5, 1.5},
                                         {2.5, 1.5},


                                         {-2.5, 3.},
                                         {-1.5, 3.},
                                         {-0.5, 3.},
                                         {0.5, 3.},
                                         {1.5, 3.},
                                         {2.5, 3.},


                                         {-0.5, 3. + 0.5 * sqrt(3)},
                                         {0.5, 3. + 0.5 * sqrt(3)},


                                         {-0.75, 3. + 0.75 * sqrt(3)},
                                         {0.75, 3. + 0.75 * sqrt(3)},


                                         {-1.25, 3. + 1.25 * sqrt(3)},
                                         {1.25, 3. + 1.25 * sqrt(3)}};


  const std::vector<std::array<unsigned int, GeometryInfo<2>::vertices_per_cell>>
    cell_vertices_2 = {{{0, 1, 6, 7}},
                       {{1, 2, 7, 8}},
                       {{2, 3, 8, 9}},
                       {{4, 10, 3, 9}},
                       {{5, 11, 4, 10}},
                       {{6, 7, 12, 13}},
                       {{7, 8, 13, 14}},
                       {{8, 9, 14, 15}},
                       {{10, 16, 9, 15}},
                       {{11, 17, 10, 16}},
                       {{12, 13, 22, 20}},
                       {{13, 14, 20, 18}},
                       {{14, 15, 18, 19}},
                       {{16, 21, 15, 19}},
                       {{17, 23, 16, 21}},
                       {{20, 18, 21, 19}},
                       {{22, 20, 23, 21}}};


  Triangulation<2> triangulation_2d_2;
  create_2d_grid(vertices_2, cell_vertices_2, triangulation_2d_2);


  Triangulation<3> triangulation_3d_2;
  GridGenerator::extrude_triangulation(triangulation_2d_2,
                                       5,
                                       2.5,
                                       triangulation_3d_2);


  // Also shift this triangulation in the z-direction so that it matches the
  // end face of the first part
  GridTools::shift(Point<3>(0, 0, 2.5), triangulation_3d_2);


  // Now first merge these two pieces, then shift the first piece in
  // z-direction beyond the second, and merge the shifted piece with the two
  // previously merged one into the final one:
  Triangulation<3> triangulation_3d_tmp;
  GridGenerator::merge_triangulations(triangulation_3d_1,
                                      triangulation_3d_2,
                                      triangulation_3d_tmp);


  GridTools::shift(Point<3>(0, 0, 5), triangulation_3d_1);


  GridGenerator::merge_triangulations(triangulation_3d_tmp,
                                      triangulation_3d_1,
                                      triangulation);
}
@endcode



这就形成了以下的网格。

<img src="https://www.dealii.org/images/steps/developer/step-49.yuhan.8.png" alt="" width="400" height="355">

这个网格具有正确的一般形状，但是顶部的单元现在是多边形的：它们的边缘不再是沿着圆的，我们没有非常准确地表示原始几何形状。下一步是教给域的顶部部分，它应该是弯曲的。换句话说，所有在顶部边界单元上进行的计算都应该以圆柱坐标而不是笛卡尔坐标进行。我们可以通过创建一个CylindricalManifold对象并将其与上面的单元格相关联来做到这一点  $y = 3$  。这样，当我们细化上面的单元时，我们将沿着同心圆而不是直线来放置新的点。

在deal.II中，我们用继承自Manifold的类来描述所有的几何体。默认的几何图形是笛卡尔的，在FlatManifold类中实现。顾名思义，Manifold及其继承类提供了一种用微分几何的思想和术语来描述曲线和曲线单元的一般方法：例如，CylindricalManifold继承自ChartManifold，它通过回拉和前推来描述几何体。一般来说，人们应该认为Triangulation类描述了一个域的拓扑结构（当然，除了存储顶点的位置之外），而Manifold类描述了一个域的几何结构（例如，一对顶点是否位于圆弧或直线上）。Triangulation将通过对与该单元相关的Manifold进行计算来细化单元，而不管该单元是否在边界上。换句话说：Manifold类不需要任何关于Triangulation边界实际位置的信息：由Triangulation来查询正确的Manifold，以便对单元格进行计算。大多数的Manifold函数（例如， Manifold::get_intermediate_point) ）对域本身一无所知，只是假设给它的点是沿着测地线的。在这种情况下，在下面构建的CylindricalManifold中，测地线是沿正交于 $z$ 轴的圆弧，以直线 $(0, 3, z)$ 为中心。

由于领域的三个顶部部分都使用相同的测地线，我们将把所有中心在 $y = 3$ 线以上的单元格标记为圆柱形的性质。

@code
const Tensor<1, 3>           axis({0.0, 0.0, 1.0});
const Point<3>               axial_point(0, 3.0, 0.0);
const CylindricalManifold<3> cylinder(axis, axial_point);
const types::manifold_id     cylinder_id = 8;


Triangulation<3> triangulation;
create_3d_grid(triangulation);
triangulation.set_manifold(cylinder_id, cylinder);


for (auto &cell : triangulation.active_cell_iterators())
  if (cell->center()[1] >= 3.0)
    cell->set_all_manifold_ids(cylinder_id);


triangulation.refine_global(1);
@endcode



通过这段代码，我们得到一个看起来像这样的网格。

<img src="https://www.dealii.org/images/steps/developer/step-49.yuhan.9.png" alt="" width="400" height="355">

这一变化修复了边界，但产生了一个新的问题：与圆柱体轴线相邻的单元格严重扭曲。我们应该使用笛卡尔坐标对这些中心单元进行计算以避免这个问题。沿着中心线的单元格都有一个面接触到线 $(0, 3, z)$ ，所以，为了实现这一点，我们回去把这些单元格上的 <code>manifold_id</code> s改写为0（这是默认的）。

@code
const Tensor<1, 3>           axis({0.0, 0.0, 1.0});
const Point<3>               axial_point(0, 3.0, 0.0);
const CylindricalManifold<3> cylinder(axis, axial_point);
const types::manifold_id     cylinder_id = 8;


Triangulation<3> triangulation;
create_3d_grid(triangulation);
triangulation.set_manifold(cylinder_id, cylinder);


for (auto &cell : triangulation.active_cell_iterators())
  if (cell->center()[1] >= 3.0)
    cell->set_all_manifold_ids(cylinder_id);


for (const auto &cell : triangulation.active_cell_iterators())
  for (const auto &face : cell->face_iterators())
    {
      const Point<3> face_center = face->center();
      if (std::abs(face_center[0]) < 1.0e-5 &&
          std::abs(face_center[1] - 3.0) < 1.0e-5)
        cell->set_all_manifold_ids(numbers::flat_manifold_id);
    }


triangulation.refine_global(1);
@endcode



这给了我们以下的网格。

<img src="https://www.dealii.org/images/steps/developer/step-49.yuhan.10.png" alt="" width="400" height="355">

这给了我们一个很好的网格，每个圆心的单元仍然是笛卡尔的，而边界周围的单元是沿着圆的。如果我们再细化两次，我们可以真正看到边界拟合网格的良好细节。

<img src="https://www.dealii.org/images/steps/developer/step-49.yuhan.11.png" alt="" width="400" height="355">




<h3> Possibilities for extensions </h3>

<h4> Assigning different boundary ids </h4>

为本教程中描述的以某种形式生成的网格分配不同的边界ID，以应用不同的边界条件，通常是很有用的。

例如，你可能想对这个程序中第一个网格的右边边界应用不同的边界条件。要做到这一点，遍历单元格和它们的面，确定正确的面（例如使用`cell->center()`来查询单元格中心的坐标，就像我们在步骤1中做的那样，或者使用`cell->face(f)->get_boundary_id()`来查询该单元格第 $f$ 个面的当前边界指标）。然后你可以使用`cell->face(f)->set_boundary_id()`来设置边界指标为不同的内容。你可以回顾一下步骤1，看看网格的迭代是如何进行的。

<h4> Extracting a boundary mesh </h4>

在流形上的计算，就像在step-38中做的那样，需要一个嵌入到高维空间的曲面网格。虽然有些网格可以用GridGenerator命名空间来构建或者从文件中加载，但有时从体积网格中提取一个表面网格也是很有用的。

使用函数  GridGenerator::extract_boundary_mesh()  来提取网格的表面元素。在一个三维网格上使用这个函数（一个`三角网格<3,3>`，例如从`grid_4()`），这将返回一个`三角网格<2,3>`，你可以在步骤38中使用。  也可以尝试提取一个`三角网格<2,2>`的边界网格。


<!--

本教程可能的扩展。

- 用于收敛研究的非结构化网格数据库

- 如何删除或禁用网格内的一个单元格

-->


examples/step-5/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{14} 

这个例子并没有显示出革命性的新东西，但它显示了许多比以前的例子更小的改进，也显示了许多通常可以在有限元程序中发现的小东西。其中包括。   <ul>   <li>  在连续细化的网格上进行计算。至少在数学科学中，在一个层次的网格上计算解是很常见的，以便对解的精度有一个感觉；如果你在一个网格上只有一个解，你通常无法猜测解的精度。此外，deal.II被设计用来支持自适应算法，其中在连续细化的网格上的迭代求解是算法的核心。虽然在这个例子中没有使用自适应网格，但这里为它们奠定了基础。     <li>  在实际应用中，领域经常被自动网格生成器细分为三角形。为了使用它们，从文件中读取粗大的网格是很重要的。在这个例子中，我们将读取一个UCD（非结构化单元数据）格式的粗网格。当这个程序在2000年左右首次编写时，UCD格式是AVS Explorer所使用的--这个程序在当时被合理地广泛使用，但现在已经不再重要了。尽管如此，该文件格式仍然存在，并且仍然被一些程序所理解）。     <li>  有限元程序通常会使用大量的计算时间，所以有时需要进行一些优化。我们将展示其中的一些。     <li>  另一方面，有限元程序往往是相当复杂的，所以调试是一个重要方面。我们通过使用断言来支持安全编程，断言在调试模式下检查参数和%内部状态的有效性，但在优化模式下被删除。(  @dealiiVideoLectureSeeAlso{18})   <li>  关于数学方面，我们展示了如何支持椭圆算子中的可变系数，以及如何对线性方程组使用预处理迭代求解器。   </ul> 

这里要解决的方程式如下。

@f{align*}


  -\nabla \cdot a(\mathbf x) \nabla u(\mathbf x) &= 1 \qquad\qquad & \text{in}\ \Omega,
  \\
  u &= 0 \qquad\qquad & \text{on}\ \partial\Omega.


@f}

如果 $a(\mathbf x)$ 是一个恒定的系数，这就只是泊松方程了。然而，如果它确实是空间可变的，它就是一个更复杂的方程（通常被称为 "扩展泊松方程"）。根据变量 $u$ 所指的内容，它可以模拟各种情况，具有广泛的适用性。

- 如果 $u$ 是电动势，那么 $-a\nabla u$ 是介质中的电流，系数 $a$ 是介质在任何特定点的电导率。在这种情况下，方程的右侧将是电源密度，通常为零或由局部的、类似德尔塔的函数组成）。

- 如果 $u$ 是薄膜的垂直挠度，那么 $a$ 将是对局部刚度的测量。这就是让我们解释下面结果部分所显示的图像的解释。

由于拉普拉斯/泊松方程出现在如此多的场合中，因此除了上面列出的两种解释外，还有许多其他解释。

当组装这个方程的线性系统时，我们需要弱的形式，这里的内容如下。

@f{align*}
  (a \nabla \varphi, \nabla u) &= (\varphi, 1) \qquad \qquad \forall \varphi.


@f}

 <code>assemble_system</code> 函数中的实现紧随其后。


examples/step-5/doc/results.dox



<h1>Results</h1>


下面是控制台的输出。

@code
Cycle 0:
   Number of active cells: 20
   Total number of cells: 20
   Number of degrees of freedom: 25
   13 CG iterations needed to obtain convergence.
Cycle 1:
   Number of active cells: 80
   Total number of cells: 100
   Number of degrees of freedom: 89
   18 CG iterations needed to obtain convergence.
Cycle 2:
   Number of active cells: 320
   Total number of cells: 420
   Number of degrees of freedom: 337
   29 CG iterations needed to obtain convergence.
Cycle 3:
   Number of active cells: 1280
   Total number of cells: 1700
   Number of degrees of freedom: 1313
   52 CG iterations needed to obtain convergence.
Cycle 4:
   Number of active cells: 5120
   Total number of cells: 6820
   Number of degrees of freedom: 5185
   95 CG iterations needed to obtain convergence.
Cycle 5:
   Number of active cells: 20480
   Total number of cells: 27300
   Number of degrees of freedom: 20609
   182 CG iterations needed to obtain convergence.
@endcode






在每个周期中，单元格的数量翻了两番，CG迭代的数量大约翻了一番。另外，在每个周期中，程序写出一个VTU格式的输出图形文件。它们被描述为以下内容。

 <table width="100%">
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-5.solution-0-r9.2.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-5.solution-1-r9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-5.solution-2-r9.2.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-5.solution-3-r9.2.png" alt="">
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-5.solution-4-r9.2.png" alt="">
    </td>
    <td>
      <img src="https://www.dealii.org/images/steps/developer/step-5.solution-5-r9.2.png" alt="">
    </td>
  </tr>
</table> 




由于系数的可变性（那里的曲率减少的程度与系数增加的程度相同），溶液的顶部区域被压扁了。溶液的梯度沿着界面是不连续的，尽管这在上面的图片中不是很明显。我们将在下一个例子中更详细地研究这个问题。

图片还显示，这个程序计算出来的解在非常粗的网格上其实是相当错误的（它的大小是错误的）。这是因为没有任何数值方法能保证粗大网格上的解是特别准确的--但我们知道解<i>converges</i>是精确的解，事实上你可以看到从一个网格到下一个网格的解似乎在最后不再有太大的变化。


examples/step-50/doc/intro.dox

 <br> 

<i>
This program was contributed by Thomas C. Clevenger and Timo Heister.
<br>
This material is based upon work partly supported by the National
Science Foundation Award DMS-2028346, OAC-2015848, EAR-1925575, by the Computational
Infrastructure in Geodynamics initiative (CIG), through the NSF under Award
EAR-0949446 and EAR-1550901 and The University of California -- Davis.
</i>

 @dealiiTutorialDOI{10.5281/zenodo.4004166,https://zenodo.org/badge/DOI/10.5281/zenodo.4004166.svg} 

 @note  作为这个程序的前提条件，你需要同时安装p4est和PETSc或Trilinos库。在<a href="../../readme.html" target="body">README</a>文件中描述了deal.II和这些附加库的安装情况。


<a name="Intro"></a>

<h1>Introduction</h1>


这个例子显示了deal.II中的多级函数在并行、分布式网格上的应用，并给出了几何和代数多栅方法的比较。代数多网格(AMG)的前置条件与step-40中使用的相同。考虑了两种几何多网格（GMG）预处理方法：一种是类似于步骤16的基于矩阵的版本（但用于并行计算），另一种是步骤37中讨论的无矩阵版本。我们的目标是找出哪种方法能够为大型并行计算提供最佳解算器。

本教程是基于  @cite clevenger_par_gmg  中的一个数值例子。关于deal.II中多网格实现的详细背景，请参见该出版物。我们将在下面的文字中总结一些结果。

代数多网格方法显然是最容易用deal.II实现的，因为诸如 TrilinosWrappers::PreconditionAMG 和 PETScWrappers::PreconditionBoomerAMG 这样的类本质上是黑盒子预处理程序，即使是并行计算，也只需要几行就能设置好。另一方面，几何多网格方法需要对整个代码库进行修改 -- 不是很多，但必须知道自己在做什么。

这个程序的结果将显示，代数和几何多网格方法的性能大致相当<i>when using matrix-based formulations</i>，而无矩阵的几何多网格方法对于这里所考虑的问题要好很多。另一个结论是，当每个处理器的未知数小于20,000个时，基于矩阵的几何多网格方法真的不能很好地扩展。




<h3>The testcase</h3>

我们考虑变系数拉普拉斯的弱表述

@f{align*}
 (\epsilon \nabla u, \nabla v) = (f,v) \quad \forall v \in V_h


@f}

在域 $\Omega = [-1,1]^\text{dim} \setminus [0,1]^\text{dim}$ （二维的L形域和三维的Fichera角）上，如果 $\min(x,y,z)>-\frac{1}{2}$ ，则 $\epsilon = 100$ 。换句话说， $\epsilon$ 是沿着域的边缘或面跑到重入角的小，这在下图中会看到。

边界条件在整个边界上是 $u=0$ ，右手边是 $f=1$  。我们使用连续 $Q_2$ 元素来表示离散的有限元空间 $V_h$ ，并使用基于残差的、单元的后验误差估计器 $e(K) = e_{\text{cell}}(K) + e_{\text{face}}(K)$ ，来自 @cite karakashian2003posteriori 的

@f{align*}
 e_{\text{cell}}(K) &= h^2 \| f + \epsilon \triangle u \|_K^2, \\
 e_{\text{face}}(K) &= \sum_F h_F \| \jump{ \epsilon \nabla u \cdot n } \|_F^2,


@f}

来适应性地细化网格。(这是KellyErrorEstimator类中使用的Kelly误差估计器的概括，KellyErrorEstimator类驱动大多数其他教程程序中的网格细化。)下图显示了二维的求解和细化：  <img width="400px" src="https://www.dealii.org/images/steps/developer/step-50-2d-solution.png" alt="">  在三维中，求解看起来类似（见下文）。在左边你可以看到解决方案，在右边我们显示了靠近域中心的 $x$ 的切片，显示了自适应细化的网格。   <table width="60%" align="center">
  <tr>
    <td align="center">
      <img width="400px" src="https://www.dealii.org/images/steps/developer/step-50-3d-solution.png" alt="">
    </td>
    <td align="center">
      <img width="400px" src="https://www.dealii.org/images/steps/developer/step-50-refinement.png" alt="">
    </td>
  </tr>
</table> 在二维和三维中，你都可以看到自适应细化拾取了角部奇点和粘度跳跃的内部奇点，而沿分离两个粘度的线的界面（正确地）没有被细化，因为它被充分地解决。这是因为由系数跳跃导致的解决方案中的扭结与细胞界面对齐。




<h3>Workload imbalance for geometric multigrid methods</h3>

如上所述，这个程序的目的是展示代数和几何多网格方法在这个问题上的应用，并做到并行计算。使算法扩展到大型并行机器的一个重要组成部分是确保每个处理器都有相同的工作量。更准确地说，重要的是没有一小部分处理器比其他处理器有更多的工作，因为如果是这样的话，很大一部分处理器会闲置，等待小部分处理器完成。相反，一小部分处理器的工作大大超过<i>less</i>并不是问题，因为大多数处理器继续生产，只有一小部分处理器在完成工作后闲置。)

对于活跃的网格，我们使用 parallel::distributed::Triangulation 类，正如在步骤40中所做的那样，它使用外部库<a href="http://www.p4est.org/">p4est</a>中的功能在处理器之间分配活跃单元。对于多级层次结构中的非活动单元，deal.II实现了我们所说的 "第一子规则"，对于层次结构中的每个单元，我们递归地将一个单元的父级分配给第一个子单元的所有者。下面的数字给出了这样一个分布的例子。这里的左图表示使用空间填充曲线划分的二维网格样本的活动单元（这也是p4est用来划分单元的方法）；中间的图片给出了活动网格的树状表示；右图给出了单元的多级层次结构。颜色和数字代表不同的处理器。树上的圆形节点是非活动单元，使用 "长子规则 "进行分配。

 <img width="800px" src="https://www.dealii.org/images/steps/developer/step-50-workload-example.png" alt=""> 

在这个例子中，屏幕上的输出包括一个 "分区效率 "的值，这个值由 MGTools::workload_imbalance(). 给出，将用 $\mathbb{E}$ 表示，量化了多网格层次结构中每一层没有完美的工作平衡所产生的开销。这种不平衡在上面的例子中很明显：虽然 $\ell=2$ 层在三个处理器的四个单元中尽可能的平衡，但粗略的 $\ell=0$ 层只有一个处理器有工作，而 $\ell=1$ 层只有两个处理器有工作，其中一个处理器的工作是另一个的三倍。

对于定义 $\mathbb{E}$ ，需要注意的是，由于我们使用局部平滑来定义多网格层次（参见 @ref mg_paper "多网格论文 "中对局部平滑的描述），一个单元的细化水平对应于该单元的多网格水平。现在，让 $N_{\ell}$ 为 $\ell$ 层的单元数（包括活动和非活动单元）， $N_{\ell,p}$ 为进程 $p$ 所拥有的子集。我们还将用 $P$ 表示处理器的总数量。假设任何一个处理器的工作量与该处理器拥有的单元格数量成正比，每个处理器的最佳工作量为

@f{align*}
W_{\text{opt}} = \frac1{P}\sum_{\ell} N_{\ell} = \sum_{\ell}\left(\frac1{P}\sum_{p}N_{\ell,p}\right).


@f}

接下来，假设每一层的工作都是同步的（即在V型循环的每一层，在进入下一层之前，所有的处理器都必须完成工作），每一层的极限工作由以下公式给出

@f{align*}
W_\ell = \max_{p} N_{\ell,p},


@f}

和总的并行复杂性

@f{align*}
W = \sum_{\ell} W_\ell.


@f}

然后我们将 $\mathbb{E}$ 定义为最佳分区与当前分区的并行复杂度之比

@f{align*}
  \mathbb{E} = \frac{W_{\text{opt}}}{W}.


@f}

对于上面的例子分布，我们有

@f{align*}
W_{\text{opt}}&=\frac{1}{P}\sum_{\ell} N_{\ell} = \frac{1}{3} \left(1+4+4\right)= 3 \qquad
\\
W &= \sum_\ell W_\ell = 1 + 2 + 3 = 6
\\
\mathbb{E} &= \frac{W_{\text{opt}}}{W} = \frac12.


@f}

这个值 MGTools::workload_imbalance()  $= 1/\mathbb{E}$ 代表了我们对GMG方法（vmults、assembly等）所期望的时间增加的因素，因为与完全负载平衡的工作负载相比，网格分区的不平衡。我们将在下面的结果部分报告一连串的网格，并与观察到的减速进行比较，因为我们的处理器数量越来越大（通常，负载不平衡也会变大）。

这些考虑在 @cite clevenger_par_gmg 中得到了更详细的考虑，其中包含了对分区效率模型和不平衡对GMG V周期时间的影响的全面讨论。总之， $\mathbb{E}$ 的值高度依赖于所使用的局部网格细化程度，对于全局细化的网格有一个最佳值 $\mathbb{E} \approx 1$ 。通常对于自适应细化的网格，用于分配单个网格的处理器数量对 $\mathbb{E}$ 有负面影响，但只到一个平移点，即处理器数量增加时，不平衡度保持相对稳定，进一步细化对 $\mathbb{E}$ 的影响很小。最后， $1/\mathbb{E}$ 被证明可以准确地表示出对V型周期的计时所预期的并行扩展的减慢。

应该注意的是，在多级网格之间有可能存在一些异步工作，特别是纯粹的近邻MPI通信，而且可以构建一个自适应网格，由于异步工作 "掩盖 "了不平衡，效率模型将远远高估V-周期的减慢（假设各级同步）。然而，对于大多数现实的自适应网格来说，预期这种异步工作只会掩盖非常小的一部分不平衡，效率模型会很好地描述减速。




<h3>Workload imbalance for algebraic multigrid methods</h3>

上面的考虑表明，我们必须期待在deal.II中实现的几何多网格算法的可扩展性有一定的限制，因为即使在网格的最细层是完全负载平衡的情况下，较粗层也可能不是。同时，较粗层的权重较小（ $W_\ell$ 对 $W$ 的贡献较小），因为较粗层的单元较少，因此，对整体运行时间的贡献不如较细层。换句话说，较粗层次的不平衡可能不会导致大局的影响。

代数多网格方法当然是基于一种完全不同的方法来创建层次结构的。特别是，他们纯粹是在分析系统矩阵的基础上创建这些层次，并且在作为 TrilinosWrappers::PreconditionAMG 和 PETScWrappers::PreconditionBoomerAMG 类基础的hypre和ML/MueLu包中都实现了非常复杂的算法，以确保问题在每个层次上都得到良好的负载平衡。在某种意义上，这些算法比几何多网格方法更简单，因为它们只处理矩阵本身，而不是所有的网格、邻居、父母和其他几何实体的内涵。同时，为了使代数多网格方法能够扩展到非常大的问题，人们也做了很多工作，包括将在某一层次上工作的处理器数量减少到所有处理器的一个子集，如果不这样的话，处理器花在计算上的时间会比花在通信上的时间少。(人们可能会注意到，在几何多网格算法中也有可能实现这些相同的想法，在这些算法中，人们有目的地将一些处理器闲置在较粗的层次上，以减少通信量。只是目前deal.II没有这样做。)

然而，这些并不是我们在这里通常需要担心的问题。在大多数情况下，我们使用代数多网格方法作为黑箱方法。




<h3>Running the program</h3>

如上所述，这个程序可以使用三种不同的方式来求解线性系统：基于矩阵的几何多网格（"MB"），无矩阵几何多网格（"MF"）和代数多网格（"AMG"）。这个程序所在的目录有后缀为".prm "的输入文件，适用于所有这三种选项，以及2D和3D。

你可以按以下方式执行该程序

@code
  ./step-50 gmg_mb_2d.prm
@endcode

而这将从给定的输入文件（这里是`mg_mb_2d.prm`）中获取运行时参数。

该程序的目的是要并行运行，你可以使用诸如以下的命令来实现这一点

@code
  mpirun -np 4 ./step-50 gmg_mb_2d.prm
@endcode

如果你想，比如说，在四个处理器上运行。也就是说，如果你有多少个处理器，程序也可以在`-np 28672`下运行）。


examples/step-50/doc/results.dox



<h1>Results</h1>

当你使用以下命令运行该程序时

@code
mpirun -np 16 ./step-50  gmg_mf_2d.prm
@endcode

屏幕输出应该如下。

@code
Cycle 0:
   Number of active cells:       12 (2 global levels)
   Partition efficiency:         0.1875
   Number of degrees of freedom: 65 (by level: 21, 65)
   Number of CG iterations:      10
   Global error estimate:        0.355373
   Wrote solution_00.pvtu



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |    0.0163s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble right-hand side        |         1 |  0.000374s |       2.3% |
| Estimate                        |         1 |  0.000724s |       4.4% |
| Output results                  |         1 |   0.00277s |        17% |
| Setup                           |         1 |   0.00225s |        14% |
| Setup multigrid                 |         1 |   0.00181s |        11% |
| Solve                           |         1 |   0.00364s |        22% |
| Solve: 1 multigrid V-cycle      |         1 |  0.000354s |       2.2% |
| Solve: CG                       |         1 |   0.00151s |       9.3% |
| Solve: Preconditioner setup     |         1 |   0.00125s |       7.7% |
+---------------------------------+-----------+------------+------------+


Cycle 1:
   Number of active cells:       24 (3 global levels)
   Partition efficiency:         0.276786
   Number of degrees of freedom: 139 (by level: 21, 65, 99)
   Number of CG iterations:      10
   Global error estimate:        0.216726
   Wrote solution_01.pvtu



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |    0.0169s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble right-hand side        |         1 |  0.000309s |       1.8% |
| Estimate                        |         1 |   0.00156s |       9.2% |
| Output results                  |         1 |   0.00222s |        13% |
| Refine grid                     |         1 |   0.00278s |        16% |
| Setup                           |         1 |   0.00196s |        12% |
| Setup multigrid                 |         1 |    0.0023s |        14% |
| Solve                           |         1 |   0.00565s |        33% |
| Solve: 1 multigrid V-cycle      |         1 |  0.000349s |       2.1% |
| Solve: CG                       |         1 |   0.00285s |        17% |
| Solve: Preconditioner setup     |         1 |   0.00195s |        12% |
+---------------------------------+-----------+------------+------------+


Cycle 2:
   Number of active cells:       51 (4 global levels)
   Partition efficiency:         0.41875
   Number of degrees of freedom: 245 (by level: 21, 65, 225, 25)
   Number of CG iterations:      11
   Global error estimate:        0.112098
   Wrote solution_02.pvtu



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |    0.0183s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble right-hand side        |         1 |  0.000274s |       1.5% |
| Estimate                        |         1 |   0.00127s |       6.9% |
| Output results                  |         1 |   0.00227s |        12% |
| Refine grid                     |         1 |    0.0024s |        13% |
| Setup                           |         1 |   0.00191s |        10% |
| Setup multigrid                 |         1 |   0.00295s |        16% |
| Solve                           |         1 |   0.00702s |        38% |
| Solve: 1 multigrid V-cycle      |         1 |  0.000398s |       2.2% |
| Solve: CG                       |         1 |   0.00376s |        21% |
| Solve: Preconditioner setup     |         1 |   0.00238s |        13% |
+---------------------------------+-----------+------------+------------+
.
.
.
@endcode

在这里，"solve() "函数的时间被分成三部分：设置多网格预处理程序，执行单一的多网格V型循环，以及CG求解器。被计时的V型循环对整个求解来说是不必要的，只是为了让人们了解AMG和GMG的不同成本。还应注意的是，当使用AMG求解器时，"工作量不平衡 "不包括在输出中，因为不需要粗网格的层次结构。

本节中的所有结果都是在英特尔至强铂金8280（Cascade Lake）节点上收集的，这些节点有56个内核，每个节点有192GB，支持AVX-512指令，允许对8个双倍数进行矢量化（矢量化仅用于无矩阵计算）。代码是用gcc 7.1.0和intel-mpi 17.0.3编译的。Trilinos 12.10.1被用于基于矩阵的GMG/AMG计算。

然后我们可以通过调用step-50目录下的输入文件来收集各种信息。使用这些文件，并调整网格细化步骤的数量，我们可以得出程序的扩展性如何的信息。

下表给出了该程序在高达256M自由度和7168个处理器上的弱比例计时。(回顾一下，在增加处理器数量的同时，弱缩放保持每个处理器的自由度数量不变；也就是说，它考虑的是越来越大的问题。)这里， $\mathbb{E}$ 是介绍中的分区效率（也等于1.0/工作量不平衡），"Setup "是设置、设置多重网格、装配和装配多重网格的组合，"Prec "是预处理程序的设置。理想情况下，在每个问题大小上，各个求解器的所有时间都保持不变，但由于分区效率从最大问题大小到最小问题大小从0.371下降到0.161，我们期望看到GMG的时间大约增加 $0.371/0.161=2.3$ 倍。事实上，这与我们实际得到的情况非常接近。

 <table align="center" class="doxtable">
<tr>
  <th colspan="4"></th>
  <th></th>
  <th colspan="4">MF-GMG</th>
  <th></th>
  <th colspan="4">MB-GMG</th>
  <th></th>
  <th colspan="4">AMG</th>
</tr>
<tr>
  <th align="right">Procs</th>
  <th align="right">Cycle</th>
  <th align="right">DoFs</th>
  <th align="right">$\mathbb{E}$</th>
  <th></th>
  <th align="right">Setup</th>
  <th align="right">Prec</th>
  <th align="right">Solve</th>
  <th align="right">Total</th>
  <th></th>
  <th align="right">Setup</th>
  <th align="right">Prec</th>
  <th align="right">Solve</th>
  <th align="right">Total</th>
  <th></th>
  <th align="right">Setup</th>
  <th align="right">Prec</th>
  <th align="right">Solve</th>
  <th align="right">Total</th>
</tr>
<tr>
  <td align="right">112</th>
  <td align="right">13</th>
  <td align="right">4M</th>
  <td align="right">0.37</th>
  <td></td>
  <td align="right">0.742</th>
  <td align="right">0.393</th>
  <td align="right">0.200</th>
  <td align="right">1.335</th>
  <td></td>
  <td align="right">1.714</th>
  <td align="right">2.934</th>
  <td align="right">0.716</th>
  <td align="right">5.364</th>
  <td></td>
  <td align="right">1.544</th>
  <td align="right">0.456</th>
  <td align="right">1.150</th>
  <td align="right">3.150</th>
</tr>
<tr>
  <td align="right">448</th>
  <td align="right">15</th>
  <td align="right">16M</th>
  <td align="right">0.29</th>
  <td></td>
  <td align="right">0.884</th>
  <td align="right">0.535</th>
  <td align="right">0.253</th>
  <td align="right">1.672</th>
  <td></td>
  <td align="right">1.927</th>
  <td align="right">3.776</th>
  <td align="right">1.190</th>
  <td align="right">6.893</th>
  <td></td>
  <td align="right">1.544</th>
  <td align="right">0.456</th>
  <td align="right">1.150</th>
  <td align="right">3.150</th>
</tr>
<tr>
  <td align="right">1,792</th>
  <td align="right">17</th>
  <td align="right">65M</th>
  <td align="right">0.22</th>
  <td></td>
  <td align="right">1.122</th>
  <td align="right">0.686</th>
  <td align="right">0.309</th>
  <td align="right">2.117</th>
  <td></td>
  <td align="right">2.171</th>
  <td align="right">4.862</th>
  <td align="right">1.660</th>
  <td align="right">8.693</th>
  <td></td>
  <td align="right">1.654</th>
  <td align="right">0.546</th>
  <td align="right">1.460</th>
  <td align="right">3.660</th>
</tr>
<tr>
  <td align="right">7,168</th>
  <td align="right">19</th>
  <td align="right">256M</th>
  <td align="right">0.16</th>
  <td></td>
  <td align="right">1.214</th>
  <td align="right">0.893</th>
  <td align="right">0.521</th>
  <td align="right">2.628</th>
  <td></td>
  <td align="right">2.386</th>
  <td align="right">7.260</th>
  <td align="right">2.560</th>
  <td align="right">12.206</th>
  <td></td>
  <td align="right">1.844</th>
  <td align="right">1.010</th>
  <td align="right">1.890</th>
  <td align="right">4.744</th>
</tr>
</table> 

另一方面，最后一组列中的代数多网格相对来说不受网格层次不平衡度增加的影响（因为它不使用网格层次），时间的增长反而是由文献中记载的其他因素驱动的（最明显的是，代数多网格方法的某些部分的算法复杂度似乎是 ${\cal O}(N
\log N)$ ，而不是几何多网格的 ${\cal O}(N)$ ）。

上表的短处是，无矩阵的几何多网格方法似乎是解决这个方程的最快方法，即使不是以很大的优势。另一方面，基于矩阵的方法始终是最差的。

下图提供了每种方法的强大扩展结果，也就是说，我们在越来越多的处理器上解决同一个问题。具体来说，我们考虑在56至28672个处理器上，经过16个网格细化周期（32M DoFs）和19个周期（256M DoFs）后的问题。

 <img width="600px" src="https://www.dealii.org/images/steps/developer/step-50-strong-scaling.png" alt=""> 

虽然基于矩阵的GMG求解器和AMG的规模相似，求解时间也相似（至少在每个处理器有大量未知数的情况下--比如说，几万个），但无矩阵的GMG求解器的规模要好得多，在较粗的网格上，只用八分之一的处理器就能解决较细的问题，与AMG求解器的时间大致相当。反之，在相同数量的处理器上，它可以用大约八分之一的时间解决同样的问题。




<h3> Possibilities for extensions </h3>

<h4> Testing convergence and higher order elements </h4>

有限元度目前是硬编码为2，见主类的模板参数。这很容易改变。为了测试，最好是切换到一个有参考解的测试问题。这样，你可以比较错误率。

<h4> Coarse solver </h4>

一个更有趣的例子是涉及到一个更复杂的粗大的网格（见步骤49的启发）。这种情况下的问题是，网格层次的最粗层实际上是相当大的，我们必须考虑如何有效地解决粗层问题。这对代数多网格方法来说不是一个问题，因为它们只是继续建立越来越粗的矩阵层次，而不管它们的几何来源）。

在这里的程序中，我们只是简单地用共轭梯度法解决粗级问题，没有任何预处理程序。如果粗略问题真的很小，这是可以接受的--例如，如果粗略网格有一个单元，那么粗略网格问题在2d中有一个 $9\times 9$ 矩阵，在3d中有一个 $27\times 27$ 矩阵；对于我们在当前程序的 $L$ 形域上使用的粗略网格，这些大小在2d中是 $21\times 21$ ，在3d中有 $117\times 117$ 。但如果粗略的网格由数百或数千个单元组成，这种方法将不再起作用，并可能开始主导每个V型单元的整体运行时间。一个常见的方法是使用代数多网格预处理程序来解决粗网格问题；然而，这将需要组装粗矩阵（即使是无矩阵版本）作为AMG实现的输入。


examples/step-51/doc/intro.dox

 <br> 

<i>
This program was contributed by Martin Kronbichler and Scott Miller.
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

本教程程序介绍了对流-扩散方程的可混合的不连续Galkerin方法的实现。

<h3> Hybridizable discontinuous Galerkin methods </h3>

反对使用非连续Galerkin元素的一个常见论点是，在隐式系统中必须解决大量的全局耦合自由度。  这是因为，与连续有限元不同，在典型的非连续元中，每个顶点有一个自由度<i>for each of the adjacent elements</i>，而不是只有一个，对边和面也是如此。  作为未知数增长速度的例子，请考虑FE_DGPMonomial基础：每个标量解分量都由度数为 $p$ 的多项式表示，每个元素有 $(1/\text{dim}!) \prod_{i=1}^{\text{dim}}(p+i)$ 个自由度。通常，一个元素的所有自由度都与相邻元素的所有自由度相耦合。  由此产生的离散方程会很快产生非常大的线性系统，特别是对于2或3维的方程系统。

<h4> Reducing the size of the linear system </h4>为了减轻解决这种大型线性系统的计算成本，Cockburn和同事们引入了可混合的非连续Galerkin（HDG）方法（见Nguyen和Peraire最近发表的HDG概述文章中的参考资料 @cite Ngu2012 ）。

HDG方法通过使用Dirichlet-to-Neumann映射对数学问题进行表述来实现这一目标。  偏微分方程首先被写成一阶系统，然后每个场通过DG方法进行离散。  在这一点上，网格骨架上的单值 "跟踪 "值，即元素面，被视为独立的未知量。这就产生了离散公式中的未知数，这些未知数分为两类。

- 面的未知数，只与面的两边的单元格未知数耦合。

- 单元未知数只与同一单元内定义的单元和面未知数相耦合。最重要的是，一个单元格的内部自由度不会与另一个单元格的任何内部自由度相耦合。

然后，Dirichlet-to-Neumann地图的概念允许以下解决程序。<ol>  <li>  使用局部元素内部数据来强制执行三角形骨架上的Neumann条件。  然后，全局问题是求解轨迹值，这是唯一全局耦合的未知数。     <li>  使用已知的骨架值作为Dirichlet数据来求解局部元素级的解决方案。  这被称为 "局部求解器"，是一个<i>embarrassingly parallel</i>逐个元素的求解过程。   </ol> 

<h4> Relation with Static Condensation </h4>上述程序也有线性代数的解释--被称为<i>static condensation</i>--被Guyan在连续有限元的背景下 @cite G65 ，以及被Fraeijs de Veubeke用于混合方法 @cite F65 ，用来减少全局线性系统的大小。在后一种情况下（混合公式），系统的减少是通过使用不连续的通量，结合引入一个额外的辅助变量<i>hybrid</i>来实现的，该变量在每个元素的边界上近似于未知数的轨迹。这个过程被称为混合化，并且通过类比，这也是为什么Cockburn、Gopalakrishnan和Lazarov在2009年引入的局部非连续Galerkin方法 @cite CGL2009 ，以及随后由他们的合作者开发，最终被称为<i>hybridizable discontinuous Galerkin</i>（HDG）方法的原因。

让我们把与HDG问题相关的完整线性系统写成一个块状系统，离散DG（单元内部）变量 $U$ 为第一块，骨架（面）变量 $\Lambda$ 为第二块。

@f{eqnarray*}
\begin{pmatrix} A & B \\ C & D \end{pmatrix}
\begin{pmatrix} U \\ \Lambda \end{pmatrix}
=
\begin{pmatrix} F \\ G \end{pmatrix}.


@f}

我们现在的目的是用类似于步骤20的舒尔补码方法来消除 $U$ 块，这导致了以下两个步骤。

@f{eqnarray*}
(D - C A^{-1} B) \Lambda &=& G - C A^{-1} F, \\
A U &=& F - B \Lambda.


@f}

关键是 $A^{-1}$ 的存在不是问题，因为 $A$ 是一个块对角线矩阵，每个块对应一个单元，因此足够容易反转。与其他单元的耦合是由骨架变量上的矩阵 $B$ 和 $C$ 引入的。 $A$ 的块对角性以及 $B$ 和 $C$ 的结构使我们能够逐元反转矩阵 $A$ （迪里希特问题的局部解），并从 $D$ 中减去 $CA^{-1}B$ 。因此，迪里切特到诺曼映射概念的步骤对应于<ol>  <li>  构建舒尔补码矩阵 $D-C A^{-1} B$ 和右手边 $G - C A^{-1} F$  <i>locally on each cell</i>并以通常的方式将贡献插入全局跟踪矩阵， <li> 求解舒尔互补系统 $\Lambda$ ， <li> 使用第二个方程求解 $U$ ，给出 $\Lambda$  。   </ol> 




<h4> Solution quality and rates of convergence</h4> 对传统DG方法的另一个批评是，近似通量的收敛是次优的。  局部HDG解可以被证明是收敛的 $\mathcal{O}(h^{p+1})$  ，即以最优顺序收敛。  此外，还可以利用超级收敛特性对新的近似解进行后处理，使其以  $\mathcal{O}(h^{p+2})$  的速率收敛。




<h4> Alternative approaches </h4>

可混合的非连续Galerkin方法只是解决非连续Galerkin方法的问题的一种方法。另一个想法是所谓的 "弱Galerkin "方法。它在步骤61中进行了探讨。




<h3> HDG applied to the convection-diffusion problem </h3>

本例中使用的HDG公式取自 <br> <b>
  N.C. Nguyen, J. Peraire, B. Cockburn:
  <i>An implicit high-order hybridizable discontinuous Galerkin method
  for linear convection–diffusion equations</i><i>An implicit high-order hybridizable discontinuous Galerkin method
  for linear convection–diffusion equations</i>,
  Journal of Computational Physics, 2009, 228:9, 3232-3254.
  <a href="http://dx.doi.org/10.1016/j.jcp.2009.01.030">[DOI]</a><a href="http://dx.doi.org/10.1016/j.jcp.2009.01.030">[DOI]</a>
</b>。

我们考虑域 $\Omega$ 上的对流-扩散方程，该方程具有迪里切特边界 $\partial \Omega_D$ 和诺伊曼边界 $\partial \Omega_N$  。

@f{eqnarray*}
	\nabla \cdot (\mathbf{c} u) - \nabla \cdot (\kappa \nabla u) &=& f,
	\quad \text{ in } \Omega, \\
	u &=& g_D, \quad \text{ on } \partial \Omega_D, \\
	(\mathbf{c} u - \kappa \nabla u)\cdot \mathbf{n} &=& g_N,
	\quad \text{ on }  \partial \Omega_N.


@f}



引入辅助变量 $\mathbf{q}=-\kappa \nabla u$ ，将上述方程改写为一阶系统。

@f{eqnarray*}
  \mathbf{q} + \kappa \nabla u &=& 0, \quad \text{ in } \Omega, \\
  \nabla \cdot (\mathbf{c} u + \mathbf{q}) &=& f, \quad \text{ in } \Omega, \\
  u &=& g_D, \quad \text{ on } \partial \Omega_D, \\
  (\mathbf{q} + \mathbf{c}u)\cdot\mathbf{n}  &=& g_N,
	\quad \text{ on }  \partial \Omega_N.


@f}



我们将这些方程乘以权重函数 $\mathbf{v}, w$ ，并对每个元素 $K$ 进行分项积分，得到。

@f{eqnarray*}
  (\mathbf{v}, \kappa^{-1} \mathbf{q})_K - (\nabla\cdot\mathbf{v}, u)_K
    + \left<\mathbf{v}\cdot\mathbf{n}, {\hat{u}}\right>_{\partial K} &=& 0, \\


  - (\nabla w, \mathbf{c} u + \mathbf{q})_K
    + \left<w, (\widehat{\mathbf{c} u}+{\hat{\mathbf{q}}})\cdot\mathbf{n}\right>_{\partial K}
    &=& (w,f)_K.


@f}



带帽子的术语表示数值轨迹（通常也被称为数值通量）。  它们是对元素边界上的内部值的近似。  为了确保守恒，这些项在任何给定的元素边上都必须是单值的 $\partial K$ ，尽管对于不连续的形状函数，当然可能有多个值来自界面附近的单元。我们通过使用以下形式的跟踪来消除数字跟踪 $\hat{\mathbf{q}}$ 。

@f{eqnarray*}
  \widehat{\mathbf{c} u}+\hat{\mathbf{q}} = \mathbf{c}\hat{u} + \mathbf{q}
  + \tau(u - \hat{u})\mathbf{n} \quad \text{ on } \partial K.


@f}



变量 $\hat {u}$ 作为一个额外的自变量被引入，是我们最终建立一个全局耦合线性系统的变量。如上所述，它被定义在元素面上，并且在面与面的交汇处（2D中的顶点，3D中的边缘和顶点）不连续。数值跟踪函数中出现的 $u$ 和 $\mathbf{q}$ 的值被认为是限制在边界 $\partial K$ 的单元内部解。

局部稳定参数 $\tau$ 对HDG解决方案的稳定性和准确性有影响；进一步的讨论见文献。据报道，稳定参数为1是给出最佳结果的选择。趋向于无穷大的稳定参数 $\tau$ 禁止解在元素边界上的跳跃，使HDG解接近连续有限元素的近似值。在下面的程序中，我们选择稳定参数为

@f{eqnarray*}
  \tau = \frac{\kappa}{\ell} + |\mathbf{c} \cdot \mathbf{n}|


@f}

其中我们设定扩散 $\kappa=1$ 和扩散长度尺度为 $\ell = \frac{1}{5}$  。

HDG方法中的轨迹/骨架变量在元素面上是单值的。  因此，它们必须强烈地代表 $\partial\Omega_D$ 上的迪里希特数据。  这意味着

@f{equation*}
  \hat{u}|_{\partial \Omega_D} = g_D,


@f}

其中等号实际上是指边界函数 $L_2$ 对脸部变量空间的 $g$ 投射（例如脸部的线性函数）。然后，这个约束被应用于骨架变量 $\hat{u}$ ，使用非均质约束的方法 VectorTools::project_boundary_values. 。

将三角结构中所有元素的贡献相加，强制执行数值通量的法线分量，并对由 $w$ 加权的方程进行分项积分，我们得出问题的最终形式：找到 $(\mathbf{q}_h, u_h, \hat{u}_h) \in
\mathcal{V}_h^p \times \mathcal{W}_h^p \times \mathcal{M}_h^p$ ，以便

@f{align*}
  (\mathbf{v}, \kappa^{-1} \mathbf{q}_h)_{\mathcal{T}}


    - ( \nabla\cdot\mathbf{v}, u_h)_{\mathcal{T}}
    + \left<\mathbf{v}\cdot\mathbf{n}, \hat{u}_h\right>_{\partial\mathcal{T}}
    &= 0,
    \quad &&\forall \mathbf{v} \in \mathcal{V}_h^p,
\\


   - (\nabla w, \mathbf{c} u_h)_{\mathcal{T}}
   + (w, \nabla \cdot \mathbf{q}_h)_{\mathcal{T}}
   + (w, (\mathbf{c}\cdot\mathbf{n}) \hat{u}_h)_{\partial \mathcal{T}}
    + \left<w, \tau (u_h - \hat{u}_h)\right>_{\partial \mathcal{T}}
    &=
    (w, f)_{\mathcal{T}},
    \quad &&\forall w \in \mathcal{W}_h^p,
\\
  \left< \mu, \hat{u}_h\mathbf{c} \cdot \mathbf{n}
  		+ \mathbf{q}_h\cdot \mathbf{n}
  	    + \tau (u_h - \hat{u}_h)\right>_{\partial \mathcal{T}}
    &=
    \left<\mu, g_N\right>_{\partial\Omega_N},
    \quad &&\forall \mu \in \mathcal{M}_h^p.


@f}



未知数 $(\mathbf{q}_h, u_h)$ 被称为局部变量；它们被表示为标准的DG变量。  未知数 $\hat{u}_h$ 是骨架变量，在网格的一维表面（面）上有支持。

我们用符号 $(\cdot, \cdot)_{\mathcal{T}} = \sum_K (\cdot, \cdot)_K$ 表示所有单元的积分之和， $\left<\cdot,
\cdot\right>_{\partial \mathcal{T}} = \sum_K \left<\cdot,
\cdot\right>_{\partial K}$ 表示所有单元的所有面的积分，也就是说，内部面被访问两次，一次来自每侧，并有相应的法向量。当结合共享一个面的两个元素的贡献时，上述方程产生了DG方法中熟悉的条款，解在单元格边界上有跳跃性。

在上述方程中，标量变量  $\mathcal {W}_h^{p}$  的空间  $u_h$  被定义为在每个单元上为张量积多项式  $p$  且在元素边界上不连续的函数空间  $\mathcal Q_{-p}$  ，即由  <code>FE_DGQ<dim>(p)</code>  描述的空间。梯度或通量变量的空间  $\mathbf{q}_i$  是一个矢量元素空间，其中每个分量是局部多项式且不连续  $\mathcal Q_{-p}$  。在下面的代码中，我们将这两个局部部分收集在一个FESystem中，其中第一个 @p dim组件表示梯度部分，最后一个标量组件对应标量变量。对于骨架部分 $\hat{u}_h$ ，我们定义了一个由住在元素面上的不连续张量乘积多项式组成的空间，在deal.II中由FE_FaceQ类实现。这个空间在其他方面与FE_DGQ相似，即解函数在两个相邻的面之间不连续，也可参见下面的结果部分进行说明。

在上面给出的弱形式中，我们可以注意到以下的耦合模式。<ol>  <li>  矩阵 $A$  由局部-局部耦合项组成。  当局部加权函数 $(\mathbf{v}, w)$ 与局部求解项 $(\mathbf{q}_h, u_h)$ 相乘时就会产生这些耦合项。因为这些元素是不连续的， $A$ 是块对角线。     <li>  矩阵 $B$ 代表局部面的耦合。  这些是具有加权函数 $(\mathbf{v}, w)$ 的条款，乘以骨架变量 $\hat{u}_h$  。     <li>  矩阵 $C$ 代表面-本地耦合，它涉及加权函数 $\mu$ 乘以本地解 $(\mathbf{q}_h, u_h)$  。     <li>  矩阵  $D$  是面-面耦合；条款涉及  $\mu$  和  $\hat{u}_h$  。   </ol> 

<h4> Post-processing and super-convergence </h4>

HDG方法的一个特点是，它们通常允许构建一个丰富的解决方案，以提高精度。这种后处理方法以逐个元素的方式获取HDG解决方案，并将其结合起来，从而在使用度数为 $p$ 的多项式时可以获得 $\mathcal O(h^{p+2})$ 的精度。要做到这一点，有两个必要的成分。<ol>  <li>  计算的解梯度  $\mathbf{q}_h$  以最佳速度收敛，即  $\mathcal{O}(h^{p+1})$  。     <li>  解的标量部分的单元平均数， $\frac{(1,u_h)_K}{\text{vol}(K)}$  ，以 $\mathcal{O}(h^{p+2})$  的速度超级收敛。   </ol> 

我们现在引入一个新的变量 $u_h^* \in \mathcal{V}_h^{p+1}$ ，我们通过在约束条件 $\left(1, u_h^*\right)_K = \left(1,
u_h\right)_K$ 下对单元格 $K$ 的表达式进行最小化来找到它。这个约束是必要的，因为最小化函数并不能确定 $u_h^*$ 的常数部分。这就转化为以下方程组。

@f{eqnarray*}
\left(1, u_h^*\right)_K &=& \left(1, u_h\right)_K\\
\left(\nabla w_h^*, \kappa \nabla u_h^*\right)_K &=&


-\left(\nabla w_h^*, \mathbf{q}_h\right)_K
\quad \text{for all } w_h^* \in \mathcal Q^{p+1}.


@f}



由于我们在第二组方程中用度数为 $p+1$ 的张量积多项式空间中的整组基函数进行测试，这是一个过度确定的系统，方程比未知数多一个。我们在下面的代码中通过省略其中一个方程来解决这个问题（因为拉普拉斯的行在代表一个常数函数时是线性依赖的）。正如我们将在下面看到的，这种形式的后处理给出了所需的超级收敛结果，速率为 $\mathcal {O}(h^{p+2})$  。  应该指出的是，在构建 $u_h^*$ 时有一定的自由度，这种从梯度中提取信息的最小化方法不是唯一的方法。特别是，这里定义的后处理方案在任何意义上都不满足对流-扩散方程。作为替代方案，上面引用的Nguyen、Peraire和Cockburn的论文提出了另一个有点复杂的对流-扩散公式，该公式也可以将通量变量后处理为 $H(\Omega,\mathrm{div})$ -符合的变体，并且在扩散较小时更好地表示局部对流-扩散算子。我们把更复杂的后处理的实现作为一个可能的扩展留给感兴趣的读者。

请注意，对于矢量值的问题，后处理的工作原理是类似的。我们只需为每个向量分量的平均值分别设置约束，并将梯度作为主要信息来源。

<h3> Problem specific data </h3>

在这个教程程序中，我们考虑的测试案例与步骤7中的几乎相同。计算域是 $\Omega \dealcoloneq [-1,1]^d$ ，精确的解决方案与步骤7中的解决方案相对应，除了一个缩放比例。我们使用以下源中心 $x_i$ 作为指数 <ul>   <li>  1D： $\{x_i\}^1 = \{ -\frac{1}{3}, 0, \frac{1}{3} \}$  ,  <li>  2D： $\{\mathbf{x}_i\}^2 = \{ (-\frac{1}{2},\frac{1}{2}),
                        		 (-\frac{1}{2},-\frac{1}{2}),
  					 (\frac{1}{2},-\frac{1}{2})
  				   \}$  ,  <li>  3D： $\{\mathbf{x}_i\}^3 = \{ (-\frac{1}{2},\frac{1}{2}, \frac{1}{4}),
  				      (-\frac{3}{5},-\frac{1}{2}, -\frac{1}{8}),
  				      (\frac{1}{2},-\frac{1}{2}, \frac{1}{2})
  				   \}$  。   </ul> 

有了精确的解决方案，我们就可以选择右手边的强制力和诺伊曼边界条件，从而得到这个解决方案（制造的解决方案技术）。在这个例子中，我们选择扩散等于1，对流为

\f[
\mathbf{c} = \begin{cases}
1, & \textrm{dim}=1 \\
(y, -x), & \textrm{dim}=2 \\
(y, -x, 1), & \textrm{dim}=3
\end{cases}
\f] 注意，对流是无发散的，  $\nabla \cdot c = 0$  。

<h3> Implementation </h3>

除了实现上述方程，下面的实现还提供了以下功能。   <ul>   <li>  WorkStream来并行化本地求解器。在步骤9中已经详细介绍了Workstream。     <li>  从跟踪中重构本地DG解。     <li>  对解进行后处理以实现超融合。     <li>  用于直接输出全局骨架解的DataOutFaces。   </ul> 


examples/step-51/doc/results.dox



<h1>Results</h1>

<h3>Program output</h3>

我们首先看一下程序在二维运行时产生的输出。在下面的四张图片中，我们展示了多项式度数 $p=1$ 和程序的周期2、3、4和8的解决方案。在图中，我们将从内部数据（DG部分）产生的数据与骨架部分（ $\hat{u}$ ）叠加到同一图中。我们不得不生成两个不同的数据集，因为单元格和面孔代表不同的几何实体，它们的组合（在同一个文件中）在VTK输出的deal.II中不被支持。

这些图像显示了HDG的明显特征：细胞的解决方案（彩色的表面）在细胞之间是不连续的。骨架变量上的解位于面的位置，并将局部部分联系起来。骨架解决方案在面与面之间的顶点上是不连续的，尽管它的值沿着同一坐标方向的线相当接近。骨架解可以被解释为两边之间的橡胶弹簧，它可以平衡解的跳跃（或者说，通量 $\kappa \nabla u
+ \mathbf{c} u$ ）。从左上角的图片可以看出，大体解经常出现过冲和欠冲，而骨架变量确实是对精确解更好的近似；这解释了为什么我们可以通过后处理步骤得到更好的解。

随着网格的细化，单元之间的跳跃变得很小（我们代表一个平滑的解决方案），骨架解决方案接近内部部分。对于第8周期，两个变量没有明显的区别。我们还看到边界条件是如何弱化实施的，内部变量并不完全满足边界条件。在下部和左侧边界，我们设置了诺伊曼边界条件，而在右侧和顶部边界，我们设置了迪里希特条件。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.sol_2.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.sol_3.png" alt=""></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.sol_4.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.sol_8.png" alt=""></td>
  </tr>
</table> 

接下来，我们看一下后处理的解决方案，还是在周期2、3、4和8。这是一个不连续的解决方案，局部由二阶多项式描述。虽然在第二周期的网格上，解决方案看起来不是很好，但在第三和第四周期，它看起来好得多。正如下面的收敛表所示，我们发现它也更快地收敛到了分析解。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.post_2.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.post_3.png" alt=""></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.post_4.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.post_8.png" alt=""></td>
  </tr>
</table> 

最后，我们看一下 $p=3$ 在第二周期的解。尽管网格较粗，只有64个单元，但经过后处理的解在质量上与第8周期4,096个单元的线性解（未经过后处理）相似。这清楚地表明了高阶方法对于平滑解的优越性。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.sol_q3_2.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.post_q3_2.png" alt=""></td>
  </tr>
</table> 

<h4>Convergence tables</h4>

当程序运行时，它还会输出各自的步骤和收敛表的信息，并在最后输出各部分的误差。在2D中，收敛表看起来如下。

@code
Q1 elements, adaptive refinement:
cells dofs   val L2    grad L2  val L2-post
   16    80 1.804e+01 2.207e+01   1.798e+01
   31   170 9.874e+00 1.322e+01   9.798e+00
   61   314 7.452e-01 3.793e+00   4.891e-01
  121   634 3.240e-01 1.511e+00   2.616e-01
  238  1198 8.585e-02 8.212e-01   1.808e-02
  454  2290 4.802e-02 5.178e-01   2.195e-02
  898  4378 2.561e-02 2.947e-01   4.318e-03
 1720  7864 1.306e-02 1.664e-01   2.978e-03
 3271 14638 7.025e-03 9.815e-02   1.075e-03
 6217 27214 4.119e-03 6.407e-02   9.975e-04


Q1 elements, global refinement:
cells dofs      val L2        grad L2      val L2-post
   16    80 1.804e+01    - 2.207e+01    - 1.798e+01    -
   36   168 6.125e+00 2.66 9.472e+00 2.09 6.084e+00 2.67
   64   288 9.785e-01 6.38 4.260e+00 2.78 7.102e-01 7.47
  144   624 2.730e-01 3.15 1.866e+00 2.04 6.115e-02 6.05
  256  1088 1.493e-01 2.10 1.046e+00 2.01 2.880e-02 2.62
  576  2400 6.965e-02 1.88 4.846e-01 1.90 9.204e-03 2.81
 1024  4224 4.018e-02 1.91 2.784e-01 1.93 4.027e-03 2.87
 2304  9408 1.831e-02 1.94 1.264e-01 1.95 1.236e-03 2.91
 4096 16640 1.043e-02 1.96 7.185e-02 1.96 5.306e-04 2.94
 9216 37248 4.690e-03 1.97 3.228e-02 1.97 1.599e-04 2.96


Q3 elements, global refinement:
cells dofs      val L2        grad L2      val L2-post
   16   160 3.613e-01    - 1.891e+00    - 3.020e-01    -
   36   336 6.411e-02 4.26 5.081e-01 3.24 3.238e-02 5.51
   64   576 3.480e-02 2.12 2.533e-01 2.42 5.277e-03 6.31
  144  1248 8.297e-03 3.54 5.924e-02 3.58 6.330e-04 5.23
  256  2176 2.254e-03 4.53 1.636e-02 4.47 1.403e-04 5.24
  576  4800 4.558e-04 3.94 3.277e-03 3.96 1.844e-05 5.01
 1024  8448 1.471e-04 3.93 1.052e-03 3.95 4.378e-06 5.00
 2304 18816 2.956e-05 3.96 2.104e-04 3.97 5.750e-07 5.01
 4096 33280 9.428e-06 3.97 6.697e-05 3.98 1.362e-07 5.01
 9216 74496 1.876e-06 3.98 1.330e-05 3.99 1.788e-08 5.01
@endcode




我们可以看到网格细化后的误差减少，对于进行全局细化的情况，也可以看到收敛率。在 $L_2$ 准则下，标量变量和梯度变量的Q1元素的二次收敛率很明显，在 $L_2$ 准则下，后处理的标量变量的三次收敛率也是如此。注意HDG解决方案的这一明显特征。在典型的连续有限元中，阶 $p$ 的解的梯度收敛率只有 $p$ ，与实际解的 $p+1$ 相反。即使有限元的超收敛结果也是可用的（例如Zienkiewicz和Zhu首次提出的超收敛补丁恢复），但这些通常只限于结构化网格和其他特殊情况。对于Q3 HDG变量，标量变量和梯度在四阶收敛，后处理的标量变量在五阶收敛。

在3D中观察到相同的收敛率。

@code
Q1 elements, adaptive refinement:
cells   dofs    val L2    grad L2  val L2-post
     8     144 7.122e+00 1.941e+01   6.102e+00
    29     500 3.309e+00 1.023e+01   2.145e+00
   113    1792 2.204e+00 1.023e+01   1.912e+00
   379    5732 6.085e-01 5.008e+00   2.233e-01
  1317   19412 1.543e-01 1.464e+00   4.196e-02
  4579   64768 5.058e-02 5.611e-01   9.521e-03
 14596  199552 2.129e-02 3.122e-01   4.569e-03
 46180  611400 1.033e-02 1.622e-01   1.684e-03
144859 1864212 5.007e-03 8.371e-02   7.364e-04
451060 5684508 2.518e-03 4.562e-02   3.070e-04


Q1 elements, global refinement:
cells   dofs       val L2          grad L2       val L2-post
     8     144 7.122e+00    - 1.941e+01     - 6.102e+00    -
    27     432 5.491e+00 0.64 2.184e+01 -0.29 4.448e+00 0.78
    64     960 3.646e+00 1.42 1.299e+01  1.81 3.306e+00 1.03
   216    3024 1.595e+00 2.04 8.550e+00  1.03 1.441e+00 2.05
   512    6912 6.922e-01 2.90 5.306e+00  1.66 2.511e-01 6.07
  1728   22464 2.915e-01 2.13 2.490e+00  1.87 8.588e-02 2.65
  4096   52224 1.684e-01 1.91 1.453e+00  1.87 4.055e-02 2.61
 13824  172800 7.972e-02 1.84 6.861e-01  1.85 1.335e-02 2.74
 32768  405504 4.637e-02 1.88 3.984e-01  1.89 5.932e-03 2.82
110592 1354752 2.133e-02 1.92 1.830e-01  1.92 1.851e-03 2.87


Q3 elements, global refinement:
cells   dofs       val L2        grad L2      val L2-post
     8     576 5.670e+00    - 1.868e+01    - 5.462e+00    -
    27    1728 1.048e+00 4.16 6.988e+00 2.42 8.011e-01 4.73
    64    3840 2.831e-01 4.55 2.710e+00 3.29 1.363e-01 6.16
   216   12096 7.883e-02 3.15 7.721e-01 3.10 2.158e-02 4.55
   512   27648 3.642e-02 2.68 3.305e-01 2.95 5.231e-03 4.93
  1728   89856 8.546e-03 3.58 7.581e-02 3.63 7.640e-04 4.74
  4096  208896 2.598e-03 4.14 2.313e-02 4.13 1.783e-04 5.06
 13824  691200 5.314e-04 3.91 4.697e-03 3.93 2.355e-05 4.99
 32768 1622016 1.723e-04 3.91 1.517e-03 3.93 5.602e-06 4.99
110592 5419008 3.482e-05 3.94 3.055e-04 3.95 7.374e-07 5.00
@endcode



<h3>Comparison with continuous finite elements</h3>

<h4>Results for 2D</h4>

收敛表验证了介绍中所述的预期收敛率。现在，我们想在本教程的问题上展示一下HDG方法与普通有限元（连续Galkerin）方法相比的计算效率的快速比较。当然，与连续有限元相比，HDG方法对于传输为主的问题的稳定性方面在实践中也很重要，这是在平滑分析解的问题上看不到的方面。在下面的图片中，我们比较了 $L_2$ 误差作为自由度数的函数（左）和线性求解器中花费的计算时间（右），连续有限元（CG）和本教程中介绍的混合非连续Galerkin方法的两个空间维度。相对于教程中我们只使用无条件的BiCGStab，下面的数字中显示的时间使用了 TrilinosWrappers::PreconditionAMG. 中的Trilinos代数多网格预处理器 对于HDG部分，为了利用最细级别的矩阵中的块结构，我们使用了ChunkSparseMatrix周围的跟踪变量的包装器。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.2d_plain.png" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.2dt_plain.png" width="400" alt=""></td>
  </tr>
</table> 

图中的结果显示，HDG方法在 $p=1$ 时比连续有限元慢，对立方体元素的速度差不多，对六阶元素的速度更快。然而，我们在上面已经看到，HDG方法实际上产生的解比原始变量所表示的更准确。因此，在下面两幅图中，我们转而显示HDG的后处理解的误差（例如用 $p=1^*$ 表示）。现在我们看到，对于 $p=3$ 和 $p=6$ ，在相同的工作量下，HDG有明显的优势，而对于 $p=1$ ，质量也差不多。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.2d_post.png" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.2dt_post.png" width="400" alt=""></td>
  </tr>
</table> 

由于HDG方法实际产生的结果收敛为 $h^{p+2}$ ，我们应该将其与具有相同渐进收敛行为的连续Galerkin解决方案进行比较，即程度为 $p+1$ 的FE_Q。如果我们这样做，我们会得到下面的收敛曲线。我们看到，用二阶多项式的CG又明显优于用线型的HDG。然而，HDG对高阶的优势依然存在。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.2d_postb.png" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.2dt_postb.png" width="400" alt=""></td>
  </tr>
</table> 

这些结果与一般的DG方法的特性是一致的。最佳性能通常不是在线性元素上实现的，而是在更高的阶数上，通常在 $p=3$ 左右。这是因为不连续解的体积-表面效应，有太多的解存在于表面，因此当元素为线性时，会出现重复工作。换句话说，尽管DG方法专注于不连续（因此看起来精度不高）的解的表示，但在相对高的阶数上使用时往往是最有效的。

<h4>Results for 3D</h4>

我们现在展示了同样的三维数字：第一行显示了自由度数和计算时间与标量变量 $L_2$ 中的 $u$ 误差的关系，在 $p$ 阶的CG和HDG，第二行显示了后处理的HDG方案，而不是原始方案，第三行比较了后处理的HDG方案与阶 $p+1$ 的CG。在三维中，体积-表面效应使得HDG的成本更高，对于线型来说，CG的解决方案显然比HDG更好。对于立方体，HDG和CG的质量相似，而HDG对于六阶多项式又更有效率。我们也可以使用FE_DGP和FE_FaceP的组合来代替（FE_DGQ, FE_FaceQ），它们不使用 $p$ 度的张量积多项式，而是<i>complete</i>度的Legendre多项式。在给定的网格尺寸下，FE_FaceP的骨架变量的自由度较少，但求解质量（误差与自由度数量的关系）与FE_FaceQ的结果非常相似。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.3d_plain.png" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.3dt_plain.png" width="400" alt=""></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.3d_post.png" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.3dt_post.png" width="400" alt=""></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.3d_postb.png" width="400" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-51.3dt_postb.png" width="400" alt=""></td>
  </tr>
</table> 

关于效率比较的最后一点说明。我们试图使用通用的稀疏矩阵结构和类似的求解器（两者的最佳AMG预处理器，没有对任何一个AMG参数进行特别的调整），在一个玩具的例子上，对两种方法的成本与精度进行公平的描述。然而，应该注意的是，连续有限元的几何多网格（GMG）对于 $p=3$ 和 $p=6$ 来说，大约快了四到五个系数。截至2019年，HDG的最优复杂度迭代求解器仍在研究界开发中。另外，还有其他方面的CG的实现，如步骤37所示的快速无矩阵方法，使高阶连续元素更具竞争力。同样，本教程的作者也不清楚是否可以对HDG做出类似的改进。我们参考<a href="https://dx.doi.org/10.1137/16M110455X">Kronbichler
and Wall (2018)</a>，了解最近的效率评估。




<h3>Possibilities for improvements</h3>

正如在介绍中已经提到的，一种可能性是实施文献中讨论的另一种后处理技术。

第二项没有做得很好的是与这个程序的性能有关，这当然是实际应用中的一个问题（也要权衡(H)DG方法对传输为主的问题有更好的解决质量）。让我们来看看这个教程程序的计算时间和各个部分的份额。

 <table align="center" class="doxtable">
  <tr>
    <th>&nbsp;</th>
    <th>&nbsp;</th>
    <th>Setup</th>
    <th>Assemble</th>
    <th>Solve</th>
    <th>Trace reconstruct</th>
    <th>Post-processing</th>
    <th>Output</th>
  </tr>
  <tr>
    <th>&nbsp;</th>
    <th>Total time</th>
    <th colspan="6">Relative share</th>
  </tr>
  <tr>
    <td align="left">2D, Q1, cycle 9, 37,248 dofs</td>
    <td align="center">5.34s</td>
    <td align="center">0.7%</td>
    <td align="center">1.2%</td>
    <td align="center">89.5%</td>
    <td align="center">0.9%</td>
    <td align="center">2.3%</td>
    <td align="center">5.4%</td>
  </tr>
  <tr>
    <td align="left">2D, Q3, cycle 9, 74,496 dofs</td>
    <td align="center">22.2s</td>
    <td align="center">0.4%</td>
    <td align="center">4.3%</td>
    <td align="center">84.1%</td>
    <td align="center">4.1%</td>
    <td align="center">3.5%</td>
    <td align="center">3.6%</td>
  </tr>
  <tr>
    <td align="left">3D, Q1, cycle 7, 172,800 dofs</td>
    <td align="center">9.06s</td>
    <td align="center">3.1%</td>
    <td align="center">8.9%</td>
    <td align="center">42.7%</td>
    <td align="center">7.0%</td>
    <td align="center">20.6%</td>
    <td align="center">17.7%</td>
  </tr>
  <tr>
    <td align="left">3D, Q3, cycle 7, 691,200 dofs</td>
    <td align="center">516s</td>
    <td align="center">0.6%</td>
    <td align="center">34.5%</td>
    <td align="center">13.4%</td>
    <td align="center">32.8%</td>
    <td align="center">17.1%</td>
    <td align="center">1.5%</td>
  </tr>
</table> 

从表中可以看出，解算器和汇编调用在程序的运行时间中占主导地位。这也清楚地表明，在哪些方面的改进是最有意义的。

<ol>  <li>  更好的线性求解器。我们使用的是BiCGStab迭代求解器，没有预处理程序，迭代次数随着问题大小的增加而增加（Q1元素和全局细化的迭代次数在小尺寸时从35次开始，但在最大尺寸时增加到701次）。为了做得更好，例如可以使用Trilinos的代数多网格预处理程序，或者像<a
  href="https://dx.doi.org/10.1137/16M110455X">Kronbichler and Wall
  (2018)</a>中讨论的一些更高级的变体。对于以扩散为主的问题，比如目前的问题，只要我们不与MPI并行工作，就可以设计这样一个求解器，在最细的层次上使用更高效的ChunkSparseMatrix的矩阵-向量积。对于MPI并行化的计算，可以使用一个标准 TrilinosWrappers::SparseMatrix 。

    <li>  通过预先组装那些不从一个单元改变到另一个单元的部件（那些既不包含可变系数也不包含依赖映射的项）来加快组装速度。   </ol> 


examples/step-52/doc/intro.dox

 <br> 

<i>This program was contributed by Bruno Turcksin and Damien Lebrun-Grandie.</i>

 @note  为了运行这个程序，deal.II必须被配置为使用UMFPACK稀疏直接解算器。请参考<a
href="../../readme.html#umfpack">ReadMe</a>中的说明如何做到这一点。

<a name="Intro"></a>

<h1>Introduction</h1>

这个程序展示了如何使用Runge-Kutta方法来解决一个随时间变化的问题。它解决了首先在步骤26中讨论的热方程的一个小变化，但是由于这个程序的目的只是演示使用更高级的方法与deal.II的时间步进算法对接，所以只解决了一个均匀细化网格上的简单问题。




<h3>Problem statement</h3>

在这个例子中，我们求解中子输运方程的单组时间依赖性扩散近似（关于时间依赖性多组扩散，见步骤28）。这是一个关于中子如何在高散射介质中移动的模型，因此它是时间依赖性扩散方程的一个变体--它只是步骤26中讨论的热方程的一个不同名称，加上一些额外的条款。我们假设介质是不可逆的，因此，中子通量满足以下方程。

@f{eqnarray*}
\frac{1}{v}\frac{\partial \phi(x,t)}{\partial t} = \nabla \cdot D(x) \nabla \phi(x,t)


- \Sigma_a(x) \phi(x,t) + S(x,t)


@f}

通过适当的边界条件增强。这里， $v$ 是中子的速度（为简单起见，我们假设它等于1，这可以通过简单地缩放时间变量来实现）， $D$ 是扩散系数， $\Sigma_a$ 是吸收截面， $S$ 是一个源。因为我们只对时间依赖性感兴趣，我们假设 $D$ 和 $\Sigma_a$ 是常数。

由于这个程序只打算演示如何使用先进的时间步进算法，我们将只寻找相对简单问题的解。具体来说，我们要在一个正方形域 $[0,b]\times[0,b]$ 上寻找一个解，其形式为

@f{eqnarray*}
\phi(x,t) = A\sin(\omega t)(bx-x^2).


@f}

通过使用二次有限元，我们可以在任何特定时间精确地表示这个函数，所有的误差都是由于时间离散化造成的。我们这样做是因为这样就很容易观察到我们将要考虑的各种时间步进方案的收敛顺序，而不需要将空间和时间误差分开。

我们施加以下边界条件：对 $x=0$ 和 $x=b$ 施加同质的迪里希特条件，对 $y=0$ 和 $y=b$ 施加同质的纽曼条件。我们选择源项，以便相应的解决方案实际上是上述的形式。

@f{eqnarray*}
S=A\left(\frac{1}{v}\omega \cos(\omega t)(bx -x^2) + \sin(\omega t)
\left(\Sigma_a (bx-x^2)+2D\right) \right).


@f}

因为解是时间上的正弦，我们知道精确解满足 $\phi\left(x,\frac{\pi}{\omega}\right) = 0$  。因此，时间 $t=\frac{\pi}{\omega}$ 的误差只是数值解的规范，即 $\|e(\cdot,t=\frac{\pi}{\omega})\|_{L_2} = \|\phi_h(\cdot,t=\frac{\pi}{\omega})\|_{L_2}$ ，而且特别容易评估。在代码中，我们评估 $l_2$ 的节点值的规范，而不是相关空间函数的 $L_2$ 规范，因为前者的计算更简单；然而，在均匀网格上，这两者只是由一个常数相关，因此我们可以用其中一个观察时间收敛顺序。




<h3>Runge-Kutta methods</h3>

在deal.II中实现的Runge-Kutta方法假定要解决的方程可以写成。

@f{eqnarray*}
\frac{dy}{dt} = g(t,y).


@f}

另一方面，当使用有限元时，离散化的时间导数总是导致左手边存在一个质量矩阵。这可以很容易地看出，如果上述方程中的解向量 $y(t)$ 实际上是节点系数的向量 $U(t)$ ，其形式为变量

@f{eqnarray*}
  u_h(x,t) = \sum_j U_j(t) \varphi_j(x)


@f}

用空间形状函数 $\varphi_j(x)$ ，然后乘以一个形式的方程

@f{eqnarray*}
  \frac{\partial u(x,t)}{\partial t} = q(t,u(x,t))


@f}

通过测试函数，对 $\Omega$ 进行积分，代入 $u\rightarrow u_h$ 并将测试函数限制在上面的 $\varphi_i(x)$ ，那么这个空间离散方程的形式为

@f{eqnarray*}
M\frac{dU}{dt} = f(t,U),


@f}

其中 $M$ 是质量矩阵， $f(t,U)$ 是 $q(t,u(x,t))$ 的空间离散版本（其中 $q$ 通常是出现空间导数的地方，但鉴于我们只考虑时间导数，这一点目前并不太关心）。换句话说，这种形式符合上面的一般方案，如果我们写成

@f{eqnarray*}
\frac{dy}{dt} = g(t,y) = M^{-1}f(t,y).


@f}



Runk-Kutta方法是一种时间步进方案，通过特定的一步法对 $y(t_n)\approx
y_{n}$ 进行近似。它们通常被写成以下形式

@f{eqnarray*}
y_{n+1} = y_n + \sum_{i=1}^s b_i k_i


@f}

其中对于上面的右手边的形式

@f{eqnarray*}
k_i = h M^{-1} f\left(t_n+c_ih,y_n+\sum_{j=1}^sa_{ij}k_j\right).


@f}

这里 $a_{ij}$ ,  $b_i$ , 和 $c_i$ 是已知的系数，确定你要使用的特定Runge-Kutta方案， $h=t_{n+1}-t_n$ 是使用的时间步长。Runge-Kutta类的不同时间步长方法在级数 $s$ 和系数 $a_{ij}$ 、 $b_i$ 和 $c_i$ 上有所不同，但由于可以查找这些系数的表格值，所以很容易实施。这些表格通常被称为Butcher tableaus）。

在编写本教程时，deal.II中实现的方法可分为三类。<ol>  <li>  显式Runge-Kutta；为了使一个方法成为显式，必须在上述定义 $k_i$ 的公式中， $k_i$ 不出现在右侧。换句话说，这些方法必须满足  $a_{ii}=0, i=1,\ldots,s$  。   <li>  嵌入式（或自适应）Runge-Kutta；我们将在下面讨论其特性。   <li>  隐式Runge-Kutta；这类方法需要解决可能是非线性系统的上述阶段 $k_i$ ，即它们至少有 $a_{ii}\neq 0$  个阶段 $i=1,\ldots,s$  。   </ol>  许多众所周知的时间步进方案，人们通常不会将其与Runge或Kutta的名字联系起来，事实上，它们也可以用这些类别来表达。它们往往代表这些系列的最低阶成员。




<h4>Explicit Runge-Kutta methods</h4>

这些方法，只需要一个函数来评估 $M^{-1}f(t,y)$ ，但不需要（作为隐式方法）来解决涉及 $f(t,y)$ 的 $y$ 的方程。与所有显式时间步长方法一样，当选择的时间步长过大时，它们会变得不稳定。

这一类众所周知的方法包括正向欧拉、三阶Runge-Kutta和四阶Runge-Kutta（通常缩写为RK4）。




<h4>Embedded Runge-Kutta methods</h4>

这些方法同时使用低阶和高阶方法来估计误差，并决定是否需要缩短时间步长或可以增加。术语 "嵌入 "是指低阶方法不需要对函数 $M^{-1}f(\cdot,\cdot)$ 进行额外的评估，而是重复使用那些必须为高阶方法计算的数据。换句话说，它基本上是免费的，而我们得到的误差估计是使用高阶方法的副产品。

这类方法包括Heun-Euler、Bogacki-Shampine、Dormand-Prince（在Matlab中为ode45，通常缩写为RK45，表示这里使用的低阶和高阶方法分别为4阶和5阶Runge-Kutta方法），Fehlberg和Cash-Karp。

在撰写本文时，只有嵌入式的显式方法得到了实现。




<h4>Implicit Runge-Kutta methods</h4>

隐式方法要求在每个（子）时间步中解决 $\alpha y = f(t,y)$ 形式的 $y$ 的（可能是非线性）系统。在内部，这是用牛顿式方法完成的，因此，它们要求用户提供能够评估 $M^{-1}f(t,y)$ 和 $\left(I-\tau M^{-1} \frac{\partial f}{\partial y}\right)^{-1}$ 或等价的 $\left(M - \tau \frac{\partial f}{\partial y}\right)^{-1} M$ 的函数。

这个算子的特殊形式来自于这样一个事实，即每一个牛顿步骤都需要解一个形式的方程

@f{align*}
  \left(M - \tau \frac{\partial f}{\partial y}\right) \Delta y
  = -M h(t,y)


@f}

对于一些（给定的） $h(t,y)$  。无论时间步长如何，隐式方法总是稳定的，但过大的时间步长当然会影响到解的<i>accuracy</i>，即使数值解仍然稳定且有界。

这类方法包括后退欧拉法、隐式中点法、Crank-Nicolson法和两阶段SDIRK法（"单对角隐式Runge-Kutta "的简称，这个术语是用来表示定义时间步进方法的对角线元素 $a_{ii}$ 都是相等的；这个特性使得牛顿矩阵 $I-\tau M^{-1}\frac{\partial f}{\partial y}$ 可以在各阶段之间重复使用，因为 $\tau$ 每次都是相同的）。




<h3>Spatially discrete formulation</h3>

通过扩大我们的模型问题的解决方案，一如既往地使用形状函数 $\psi_j$ 并写出

@f{eqnarray*}
\phi_h(x,t) = \sum_j U_j(t) \psi_j(x),


@f}

我们立即得到扩散方程的空间离散化版本为

@f{eqnarray*}
  M \frac{dU(t)}{dt}
  = -{\cal D} U(t) - {\cal A} U(t) + {\cal S}(t)


@f}

其中

@f{eqnarray*}
  M_{ij}  &=& (\psi_i,\psi_j), \\
  {\cal D}_{ij}  &=& (D\nabla\psi_i,\nabla\psi_j)_\Omega, \\
  {\cal A}_{ij}  &=& (\Sigma_a\psi_i,\psi_j)_\Omega, \\
  {\cal S}_{i}(t)  &=& (\psi_i,S(x,t))_\Omega.


@f}

参见第24步和第26步以了解我们如何到达这里。由于当前问题所选择的边界条件，边界项是没有必要的。为了使用Runge-Kutta方法，我们将其改写如下。

@f{eqnarray*}
f(y) = -{\cal D}y - {\cal A}y + {\cal S}.


@f}

在代码中，我们将需要能够评估这个函数 $f(U)$ 以及它的导数。

@f{eqnarray*}
\frac{\partial f}{\partial y} = -{\cal D} - {\cal A}.


@f}






<h3>Notes on the testcase</h3>

为了简化问题，域是二维的，网格是均匀细化的（不需要调整网格，因为我们使用的是二次有限元，而且精确解是二次的）。从二维域到三维域并不是很有挑战性。然而，如果你打算解决更复杂的问题，必须对网格进行调整（例如在步骤26中），那么就必须记住以下问题。

<ol>  <li>  在改变网格时，你需要将解投影到新的网格上。当然，从每个时间步长的开始到结束，所使用的网格应该是相同的，这个问题的出现是因为Runge-Kutta方法在每个时间步长内使用了多次方程求值。   <li>  每次改变网格时，你都需要更新质量矩阵和它的逆值。   </ol>  这些步骤的技术可以通过查看步骤26轻易获得。


examples/step-52/doc/results.dox



<h1>Results</h1>

这个程序的重点不在于显示特定的结果，而在于显示它是如何做到的。这一点我们已经通过讨论上面的代码证明过了。因此，该程序的输出相对较少，只包括控制台输出和用于可视化的VTU格式的解决方案。

控制台输出既包含错误，也包含对某些方法所执行的步骤数量。

@code
Explicit methods:
   Forward Euler:            error=1.00883
   Third order Runge-Kutta:  error=0.000227982
   Fourth order Runge-Kutta: error=1.90541e-06


Implicit methods:
   Backward Euler:           error=1.03428
   Implicit Midpoint:        error=0.00862702
   Crank-Nicolson:           error=0.00862675
   SDIRK:                    error=0.0042349


Embedded explicit methods:
   Heun-Euler:               error=0.0073012
                   steps performed=284
   Bogacki-Shampine:         error=0.000408407
                   steps performed=181
   Dopri:                    error=0.000836695
                   steps performed=120
   Fehlberg:                 error=0.00248922
                   steps performed=106
   Cash-Karp:                error=0.0787735
                   steps performed=106
@endcode



正如预期的那样，高阶方法给出了（更）准确的解决方案。我们还看到，（相当不准确的）Heun-Euler方法增加了时间步数，以满足公差要求。另一方面，其他嵌入式方法使用的时间步数比规定的要少得多。


examples/step-53/doc/intro.dox

 <br> 

<i>This program was contributed by Wolfgang Bangerth and Luca Heltai, using
data provided by D. Sarah Stamps.</i>

 @note  这个程序阐述了几何学的概念和实现它的类。这些类被归入 @ref
manifold "三角形的流形描述 "的文档模块。其他信息见那里。

 @note  本教程也可作为Jupyter Python笔记本，使用deal.II python接口。该笔记本与原始的C++程序在同一目录下可用。渲染的笔记本也可以在<a
href="https://github.com/dealii/dealii/blob/master/examples/step-53/step-53.ipynb">github</a>上查看。


<a name="Intro"></a>

<h1>Introduction</h1>

现实问题的偏微分方程往往是在具有复杂几何形状的域上提出的。为了提供几个例子，请考虑这些情况。

- 在有限元方法的两个可以说是最重要的工业应用中，空气动力学和更普遍的流体动力学是其中之一。今天，计算机模拟被用于每架飞机、汽车、火车和船舶的设计。在这些情况下，提出偏微分方程的领域是飞机周围的空气，包括机翼、襟翼和发动机；汽车周围的空气，包括车轮、轮井、后视镜，在赛车的情况下，还有各种空气动力设备；火车周围的空气，包括车轮和车厢之间的空隙。在船舶的情况下，该领域是指有船舵和螺旋桨的船舶周围的水。

- 有限元方法的两大应用中的另一个是结构工程，其领域是桥梁、飞机机舱和机翼，以及其他通常形状复杂的固体物体。

- 有限元建模也经常被用来描述地震波的产生和传播。在这些情况下，人们需要准确地表示地壳中断层的几何形状。由于断层相交，有一定的倾角，而且往往不完全是直线，所以域经常是非常复杂的。我们可以举出更多复杂几何形状的例子，在这些例子中，我们要提出和解决一个偏微分方程。这表明，"真实 "世界比我们在这之前的几乎所有教程中所展示的要复杂得多。

因此，这个程序致力于展示如何用具体的应用来处理复杂的几何图形。特别是，它所展示的是我们如何使网格符合我们想要解决的领域。另一方面，该程序没有展示的是如何为一个领域创建一个粗的。获得粗网格的过程被称为 "网格生成"，有许多高质量的程序在这方面做得比我们做得更好。然而，deal.II确实有能力读取由网格生成器生成的多种格式的网格，然后使其适合给定的形状，可以通过变形网格或多次细化网格直至适合。从http://www.dealii.org/ 引用的deal.II常见问题页面提供了网格生成器的资源。




<h3>Where geometry and meshes intersect</h3>

让我们假设你有一个复杂的领域，并且你已经有一个粗略的网格，在某种程度上代表了这个领域的一般特征。那么在两种情况下，有必要向deal.II程序描述你的几何形状的细节。

- 网格细化。每当一个单元被细化时，有必要在三角网中引入新的顶点。在最简单的情况下，我们假设构成三角网的对象是直线段、双线性表面或三线性体。然后，下一个顶点被简单地放在旧顶点的中间。然而，对于弯曲的边界，或者如果我们想解决一个嵌入高维空间的弯曲的低维流形上的PDE，这是不充分的，因为它将不尊重实际的几何。因此，我们将不得不告诉Triangulation在哪里放置新的点。

- 积分。当使用高阶有限元方法时，经常需要使用边界的曲线近似来计算积分，即把单元的每个边缘或面描述为曲线，而不是直线段或双线性补丁。当然，在积分边界条款时也是如此（例如，不均匀的诺伊曼边界条件）。为了整合的目的，各种Mapping类提供了从参考单元到实际单元的转换。

在这两种情况下，我们需要一种方法来提供关于单个单元、其面和边的域的几何信息。这就是Manifold类开始发挥作用的地方。Manifold是一个抽象的基类，它只定义了一个接口，Triangulation和Mapping类可以通过这个接口查询领域的几何信息。从概念上讲，Manifold看待世界的方式与数学分支学科几何学看待世界的方式并无二致：域本质上只是一个点的集合，以某种方式配备了点之间的距离概念，这样我们就可以在其他一些点的 "中间 "获得一个点。

deal.II提供了一些实现Manifold所提供的接口的类，用于各种常见的几何形状。另一方面，在这个程序中，我们将只考虑一种非常常见的、简单得多的情况，即我们要解决的域的（一部分）可以通过转换一个简单得多的域（我们将称之为 "参考域"）来描述的情况。在数学语言中，这意味着该（部分）域是一个<a
href="http://en.wikipedia.org/wiki/Chart_%28topology%29">chart</a>。图表由一个平滑函数描述，该函数从较简单的域映射到图表（"向前推 "函数）及其逆向（"向后拉 "函数）。如果域作为一个整体不是一个图表（例如，球体的表面），那么它通常可以被描述为一个图表的集合（例如，北半球和南半球各自是一个图表），然后域可以被描述为一个<a
href="http://en.wikipedia.org/wiki/Atlas_%28topology%29">atlas</a>。

如果一个域可以被分解成一个图集，那么我们需要做的就是为每个图集提供回拉和推送函数。在deal.II中，这意味着提供一个从ChartManifold派生的类，而这正是我们在这个程序中要做的。




<h3>The example case</h3>

为了说明如何在deal.II中使用图表描述几何形状，我们将考虑一个源于<a
href="https://aspect.geodynamics.org">ASPECT mantle convection code</a>的应用的案例，使用D. Sarah Stamps提供的数据集。在具体应用中，我们对描述<a
href="http://en.wikipedia.org/wiki/East_African_rift">East African Rift</a>下的地幔流动感兴趣，这是一个两个大陆板块漂移的区域。不拐弯抹角，我们想要描述的几何形状看起来是这样的。

 <img src="https://www.dealii.org/images/steps/developer/step-53.topo.png" alt=""> 

特别是，虽然你在这里看不到，但顶部的表面不仅仅是由高程着色，实际上，它是按照正确的地形变形的。虽然实际的应用在这里并不重要，但几何学是相关的。我们感兴趣的领域是地球的一部分，范围从表面到500公里的深度，从格林威治子午线以东26度到35度，从赤道以北5度到南10度。

这种对几何学的描述建议从一个盒子 $\hat U=[26,35]\times[-10,5]\times[-500000,0]$ 开始（以度、度数和米为单位），并提供一个地图 $\varphi$ ，以便 $\varphi^{-1}(\hat U)=\Omega$ 其中 $\Omega$ 是我们寻求的领域。  然后， $(\Omega,\varphi)$ 是一个图表， $\varphi$ 是回拉运算符， $\varphi^{-1}$ 是前推运算符。如果我们需要一个点 $q$ 是其他点 $q_i\in\Omega$ 的 "平均值"，那么ChartManifold类首先应用回拉得到 $\hat q_i=\varphi(q_i)$ ，将其平均到一个点 $\hat p$ ，然后计算出 $p=\varphi^{-1}(\hat p)$ 。

因此，我们这里的目标是实现一个描述 $\varphi$ 和 $\varphi^{-1}$ 的类。如果地球是一个球体，那么这并不困难：如果我们用 $(\hat \phi,\hat \theta,\hat d)$ 表示 $\hat U$ 的点（即经度向东计算，纬度向北计算，海拔相对于零深度），那么

@f[
  \mathbf x = \varphi^{-1}(\hat \phi,\hat \theta,\hat d)
  = (R+\hat d) (\cos\hat \phi\cos\hat \theta, \sin\hat \phi\cos\hat \theta, \sin\hat \theta)^T


@f]

提供直角坐标系中的坐标，其中 $R$ 是球体的半径。然而，地球不是一个球体。

<ol>  <li> 它在两极是扁平的，在赤道是较大的：半主轴比半副轴长约22公里。我们将使用<a href="http://en.wikipedia.org/wiki/WGS84">WGS 84</a>的地球形状参考标准来说明这一点。在WGS 84中，用于从经度、纬度和海拔获得直角坐标位置的公式是

@f[
  \mathbf x = \varphi_\text{WGS84}^{-1}(\phi,\theta,d)
  = \left(
    \begin{array}{c}
     (\bar R(\theta)+d) \cos\phi\cos\theta, \\
     (\bar R(\theta)+d) \sin\phi\cos\theta, \\
     ((1-e^2)\bar R(\theta)+d) \sin\theta
    \end{array}
    \right),


@f]

  其中  $\bar R(\theta)=\frac{R}{\sqrt{1-(e \sin\theta)^2}}$  ，而半径和椭圆度由  $R=6378137\text{m}, e=0.081819190842622$  给出。在这个公式中，我们假设正弦和余弦的参数是以度数而不是弧度来计算的（尽管我们将不得不在代码中改变这个假设）。

 <li>  它的地形是山脉和山谷的形式。我们将使用真实的地形数据来说明这一点（见下文对这些数据来源的描述）。使用这个数据集，我们可以在地球表面的经纬度网格上查找高程。从方框 $\hat U=[26,35]\times[-10,5]\times[-500000,0]$ 开始，我们将首先在垂直方向上拉伸它，然后再把它交给WGS 84函数：如果 $h(\hat\phi,\hat\theta)$ 是经度 $\hat\phi$ 和纬度 $\hat\theta$ 的高度，那么我们定义

@f[
  (\phi,\theta,d) =
  \varphi_\text{topo}^{-1}(\hat\phi,\hat\theta,\hat d)
  = \left(
      \hat\phi,
      \hat\theta,
      \hat d + \frac{\hat d+500000}{500000}h(\hat\phi,\hat\theta)
    \right).


@f]

  使用这个函数，盒子 $\hat U$ 的顶面被移到正确的地形上，底面保持原来的位置，中间的点被线性内插。   </ol> 

利用这两个函数，我们就可以将整个推送函数 $\varphi^{-1}: \hat U \rightarrow \Omega$ 定义为

@f[
  \mathbf x
  =
  \varphi^{-1}(\hat\phi,\hat\theta,\hat d)
  =
  \varphi_\text{WGS84}^{-1}(\varphi_\text{topo}^{-1}(\hat\phi,\hat\theta,\hat d)).


@f]

此外，我们将不得不定义这个函数的逆运算，即回拉运算，我们可以将其写为

@f[
  (\hat\phi,\hat\theta,\hat d)
  =
  \varphi(\mathbf x)
  =
  \varphi_\text{topo}(\varphi_\text{WGS84}(\mathbf x)).


@f]

我们可以通过倒置上面的公式得到这个函数的一个分量。

@f[
  (\hat\phi,\hat\theta,\hat d) =
  \varphi_\text{topo}(\phi,\theta,d)
  = \left(
      \phi,
      \theta,
      500000\frac{d-h(\phi,\theta)}{500000+h(\phi,\theta)}
    \right).


@f]

计算 $\varphi_\text{WGS84}(\mathbf x)$ 也是可能的，不过要笨拙得多。我们不会在这里展示这个公式，而是只提供程序中的实现。




<h3>Implementation</h3>

在这个程序中，我们需要解决一些问题。在最大范围内，我们需要编写一个实现ChartManifold接口的类。这涉及到一个函数 <code>push_forward()</code> ，该函数在参考域 $\hat U$ 中取一个点，并使用上面概述的函数 $\varphi^{-1}$ 将其转换为实空间，以及实现 <code>pull_back()</code> 的反函数 $\varphi$  。我们将在下面的 <code>AfricaGeometry</code> 类中这样做，该类本质上看起来像这样。

@code
  class AfricaGeometry : public ChartManifold<3,3>
  {
  public:
    virtual
    Point<3>
    pull_back(const Point<3> &space_point) const;


    virtual
    Point<3>
    push_forward(const Point<3> &chart_point) const;


  private:
    ... some member variables and other member functions...;
  };
@endcode



上述转换有两个部分：WGS 84转换和地形转换。因此， <code>AfricaGeometry</code> 类将有额外的（非虚拟）成员函数 <code>AfricaGeometry::push_forward_wgs84()</code> 和 <code>AfricaGeometry::push_forward_topo()</code> 来实现这两部分，以及相应的回拉函数。

WGS 84的转换函数并不特别有趣（尽管它们实现的公式令人印象深刻）。更有趣的部分是地形变换。回顾一下，为此我们需要评估高程函数 $h(\hat\phi,\hat\theta)$  。当然，这没有公式。地球就是这样，人们能做的最好的事情就是从一些表格中查找海拔高度。事实上，这就是我们要做的。

我们使用的数据最初是由<a
href="http://en.wikipedia.org/wiki/Shuttle_Radar_Topography_Mission">Shuttle
Radar Topography Mission</a>创建的，是从美国地质调查局（USGS）下载的，并由D. Sarah Stamps处理，他还编写了WGS 84转换函数的初始版本。这样处理过的地形数据被储存在一个文件 <code>topography.txt.gz</code> 中，解压后看起来是这样的。

@code
6.983333 25.000000 700
6.983333 25.016667 692
6.983333 25.033333 701
6.983333 25.050000 695
6.983333 25.066667 710
6.983333 25.083333 702
...


-11.983333 35.950000 707


-11.983333 35.966667 687


-11.983333 35.983333 659
@endcode

数据格式为 <code>latitude longitude elevation</code> ，其中前两栏以赤道以北的度数和格林威治子午线以东的度数提供。最后一列是以WGS84零点以上的米数为单位。

在转换函数中，我们需要对给定的经度 $\hat\phi$ 和纬度 $\hat\theta$ 评估 $h(\hat\phi,\hat\theta)$  。一般来说，这个数据点是不可用的，我们将不得不在相邻的数据点之间进行内插。编写这样一个插值程序并不特别困难，但它有点乏味，而且容易出错。幸运的是，我们可以以某种方式将这个数据集塞进一个现有的类中。   Functions::InterpolatedUniformGridData  .不幸的是，这个类并不完全适合，所以我们需要绕过它。问题来自于我们初始化这个类的方式：在其最简单的形式下，它需要一个数值流，它假设在 $x-y$ 平面（或者，这里是 $\phi-\theta$ 平面）形成一个等距的网格。这就是它们在这里所做的，某种程度上：它们的顺序是纬度第一，经度第二；更尴尬的是，第一列从最大的数值开始往下数，而不是通常的其他方式。

现在，虽然教程程序是为了说明如何用deal.II编码，但它们不一定要满足与生产代码相同的质量标准。在生产代码中，我们会写一个函数来读取数据，并（i）自动确定第一列和第二列的外延，（ii）自动确定每个方向的数据点的数量，（iii）无论数据的排列顺序如何，都要进行插值，如果有必要的话，在读取和呈现给 Functions::InterpolatedUniformGridData 类之间切换顺序。

另一方面，辅导课程最好是短小精悍，展示关键点，而不是纠缠于不重要的方面，从而掩盖了我们真正想要展示的东西。因此，我们将允许自己有一点回旋余地。

- 由于这个程序只针对东非裂谷地区周围的特定几何形状，并且由于这正是数据文件所描述的区域，我们将在程序中硬编码有 $1139\times 660$ 个数据。

- 我们将硬编码数据的边界  $[-11.98333^\circ,6.983333^\circ]\times[25^\circ,35.98333^\circ]$  。

- 我们将对 Functions::InterpolatedUniformGridData 类撒谎：该类将只看到这个数据文件最后一列的数据，我们将假装数据的排列方式是：在第一个坐标方向上有1139个数据点，这些数据点按<i>ascending</i>的顺序排列，但在一个区间 $[-6.983333^\circ,11.98333^\circ]$ （不是否定的边界）。然后，当我们需要查询某个纬度 $\hat\theta$ 的东西时，我们可以向内插表类索取 $-\hat\theta$ 的数值。有了这个小技巧，我们就可以避免在从文件中读取数据的时候切换顺序。

所有这些都需要一个本质上看起来像这样的类。

@code
  class AfricaTopography
  {
  public:
    AfricaTopography ()
      :
      topography_data (...initialize somehow...)
    {}


    double value (const double lon, const double lat) const
    {
      return topography_data.value (Point<2>(-lat * 180/numbers::PI,
                                             lon * 180/numbers::PI));
    }


  private:
    const Functions::InterpolatedUniformGridData<2> topography_data;
  };
@endcode



注意 <code>value()</code> 函数如何否定了纬度。它还将我们在其他地方使用的格式 $\phi,\theta$ 转换为表格中使用的纬度-经度格式。最后，它的参数以弧度为单位，因为我们在程序中的其他地方也是这样做的，但随后将它们转换为用于表格查询的基于度的系统。正如你在下面的实现中所看到的，该函数还有几个（静态）成员函数，我们将在初始化 <code>topography_data</code> 成员变量时调用：该变量的类类型有一个构造函数，允许我们在构造时正确设置一切，而不是在以后填充数据，但这个构造函数需要一些不能就地构造的对象（至少在C++98中不能）。因此，我们要在初始化中传递的每个对象的构造都发生在一些静态成员函数中。

在讨论了我们要实施的事情的大体轮廓之后，让我们去看程序，并展示它在实践中是如何做的。


examples/step-53/doc/results.dox



<h1>Results</h1>

运行程序会产生一个网格文件 <code>mesh.vtu</code> ，我们可以用任何可以读取VTU文件格式的常规可视化程序来进行可视化。如果只看网格本身，实际上很难看到任何不只是看起来像一块完全圆形的球体的东西（尽管如果修改程序，使其确实产生一个球体，并同时看它们，整体球体和WGS 84形状之间的差异是相当明显的）。很明显，地球实际上是一个相当平坦的地方。当然，我们已经从卫星图片中知道了这一点。然而，我们可以通过对细胞的体积进行着色来找出更多的东西。这既产生了沿顶面的轻微色调变化，也为可视化程序提供了应用其着色算法的东西（因为单元的顶面现在不再只是与球体的切线，而是倾斜的）。

 <img src="https://www.dealii.org/images/steps/developer/step-53.mesh.png" alt=""> 

然而，至少就视觉化而言，这仍然不是太令人印象深刻。相反，让我们以一种可视化的方式，使我们显示出沿顶面的实际海拔。换句话说，我们想要一张这样的图片，有难以置信的细节。

 <img src="https://www.dealii.org/images/steps/developer/step-53.topo.png" alt=""> 

这张照片的放大显示了相当清楚的垂直位移（这里，从西-西北方向看裂谷上空，<a href="http://en.wikipedia.org/wiki/Mount_Stanley">Mount Stanley</a>、<a href="http://en.wikipedia.org/wiki/Mount_Speke">Mount Speke</a>和<a href="http://en.wikipedia.org/wiki/Mount_Baker_%28Uganda%29">Mount Baker</a>的三座山峰在<a href="http://en.wikipedia.org/wiki/Rwenzori_Mountains">Rwenzori Range</a>、<a href="http://en.wikipedia.org/wiki/Lake_George_%28Uganda%29">Lake
George</a>和向<a href="http://en.wikipedia.org/wiki/Lake_Victoria">Lake Victoria</a>的巨大平坦处）。

 <img src="https://www.dealii.org/images/steps/developer/step-53.topozoom.png" alt=""> 


这些图片是经过三个小的修改后产生的。<ol>  <li>  在这两张图片中，第一张图片的顶面增加了第七个网格细化，第二张图片总共增加了九个。在第二张图片中，水平方向的网格大小约为1.5km，垂直方向的网格大小略低于1km。(这张图也是用一个更有分辨率的数据集制作的；但是，它太大了，不能作为教程的一部分分发)。

    <li>  增加以下函数，在给定一个点 <code>x</code> 时，通过将该点转换为参考WGS 84坐标并只保留深度变量来计算海拔高度（因此，该函数是 <code>AfricaGeometry::pull_back_wgs84()</code> 函数的简化版本）。

@code
#include <deal.II/fe/fe_q.h>
#include <deal.II/dofs/dof_handler.h>
#include <deal.II/numerics/data_out.h>
#include <deal.II/numerics/vector_tools.h>



double get_elevation (const Point<3> &x)
  {
    const double R           = 6378137;
    const double ellipticity = 8.1819190842622e-2;


    const double b     = std::sqrt(R * R * (1 - ellipticity * ellipticity));
    const double ep    = std::sqrt((R * R - b * b) / (b * b));
    const double p     = std::sqrt(x(0) * x(0) + x(1) * x(1));
    const double th    = std::atan2(R * x(2), b * p);
    const double theta = std::atan2((x(2) + ep * ep * b * std::sin(th) * std::sin(th) * std::sin(th)),
                                      (p - (ellipticity * ellipticity * R  * (std::cos(th) * std::cos(th) * std::cos(th)))));
    const double R_bar = R / (std::sqrt(1 - ellipticity * ellipticity * std::sin(theta) * std::sin(theta)));
    const double R_plus_d = p / std::cos(theta);


    return R_plus_d - R_bar;
  }
@endcode



    <li>  在 <code>run()</code> 函数的底部添加以下一块。

@code
      FE_Q<3>       fe(1);
      DoFHandler<3> dof_handler (triangulation);
      dof_handler.distribute_dofs(fe);


      Vector<double> elevation (dof_handler.n_dofs());
      {
        std::map<unsigned int,double> boundary_values;
        VectorTools::interpolate_boundary_values(dof_handler,
                                                 5,
                                                 ScalarFunctionFromFunctionObject<3>(get_elevation),
                                                 boundary_values);
        for (std::map<unsigned int,double>::const_iterator p = boundary_values.begin();
             p!=boundary_values.end(); ++p)
          elevation[p->first] = p->second;
      }


      DataOut<3>    data_out;
      data_out.attach_dof_handler(dof_handler);
      data_out.add_data_vector (elevation, "elevation");
      data_out.build_patches();


      std::ofstream out ("data.vtu");
      data_out.write_vtu (out);
@endcode

 </ol>  这最后一段代码首先在网格上创建一个 $Q_1$ 有限元空间。然后使用 VectorTools::interpolate_boundary_values() 对顶部边界的每个节点（边界指标为5的节点）进行高程函数的评估。我们在这里用ScalarFunctionFromFunctionObject类来包装对 <code>get_elevation()</code> 的调用，使一个普通的C++函数看起来像一个派生自Function类的对象，我们想在 VectorTools::interpolate_boundary_values(). 中使用。然后像往常一样用DataOut输出这个向量，并可以如上图所示进行可视化。




<h3>Issues with adaptively refined meshes generated this way</h3>

如果你放大上图所示的网格并仔细观察，你会发现在悬空节点处，连接到悬空节点的两条小边与相邻单元的大边的位置不完全相同。这可以通过使用不同的表面描述来更清楚地显示出来，在这种描述中，我们放大了垂直地形以增强效果（由Alexander Grayver提供）。

 <img src="https://www.dealii.org/images/steps/developer/step-53.smooth-geometry.png" alt=""> 

那么这里发生了什么？部分原因是，这只是视觉化的结果，但也有一个潜在的真正原因。

 <ul>   <li>  当你使用任何一个常见的可视化程序对网格进行可视化时，它们真正显示的只是一组在三维空间中被绘制成直线的边缘。这是因为几乎所有用于可视化的数据文件格式都只将六面体单元描述为三维空间中八个顶点的集合，而不允许任何更复杂的描述。这就是为什么 DataOut::build_patches() 需要一个可以设置为大于1的参数的主要原因）。这些线性边缘可能是你进行实际计算的单元格的边缘，也可能不是，这取决于你在使用FEValues进行积分时使用何种映射。当然，在默认情况下，FEValues使用的是线性映射（即MappingQ1类的对象），在这种情况下，一个3D单元确实完全由其8个顶点描述，它所填充的体积是这些点之间的三线插值，从而产生了线性边缘。但是，你也可以使用三次方、三次立方、甚至更高阶的映射，在这些情况下，每个单元的体积将由二次方、三次方或高阶多项式曲线来限定。然而，你只能在可视化程序中看到这些带有线性边缘的曲线，因为如前所述，文件格式不允许描述细胞的真实几何形状。

    <li>  也就是说，为了简单起见，让我们假设你确实在使用三线性映射，那么上面显示的图像就是你形成积分的单元的忠实代表。在这种情况下，一般来说，悬空节点上的小单元并不与大单元紧密贴合，而是留有间隙，或者可能与大单元相交。这是为什么呢？   因为当三角测量需要在它想要细化的边缘上增加一个新的顶点时，它会询问流形描述这个新的顶点应该在哪里，流形描述通过（在从ChartManifold派生的几何体的情况下）将线的相邻点拉回到参考域，平均它们的位置，并将这个新的位置推到真实域，从而适当地返回这样一个点。但是这个新的位置通常不是沿着相邻顶点之间的直线（在实空间），因此，形成精炼边缘的两条小直线并不完全位于形成悬挂节点的未精炼边的一条大直线上。   </ul> 

如果你使用MappingQ类的高阶映射，情况会稍微复杂一些，但没有根本的不同。我们暂且采用二次映射（高阶映射也没有什么根本性的变化）。那么你需要把你所整合的单元格的每条边想象成一条二次曲线，尽管你实际上不会看到可视化程序以这种方式绘制。但请先想象一下。那么，MappingQ采用哪条二次曲线呢？它是经过边缘末端的两个顶点以及中间的一个点的二次曲线，它从流形中查询。在未精炼一侧的长边的情况下，这当然正是悬空节点的位置，所以描述长边的二次曲线确实经过了悬空节点，这与线性映射的情况不同。但是两条小边也是二次曲线；例如，左边的小边会经过长边的左顶点和悬挂节点，再加上它从流形中查询到的一个点。因为如前所述，流形沿左小边中途返回的点很少完全在描述长边的二次曲线上，二次短边通常不会与二次长边的左半边重合，右短边也是如此。换句话说，同样的，大单元格和它在悬挂节点上的小邻居的几何形状并不相依相偎。

这一切引出了两个问题：第一，这是否重要，第二，这是否可以解决。让我们在下文中讨论这些问题。

 <ul>   <li>  这重要吗？几乎可以肯定的是，这取决于你所求解的方程。例如，众所周知，在复杂几何体上求解气体动力学的欧拉方程需要高度精确的边界描述，以确保衡量靠近边界的流动的量的收敛。另一方面，具有椭圆成分的方程（如拉普拉斯方程或斯托克斯方程）通常对这些问题比较宽容：无论如何都要做正交来近似积分，鉴于每个悬空节点的重叠或间隙的体积只有 ${\cal O}(h^d)$ ，进一步近似几何可能不会像人们担心的那样造成伤害。]，即使是线性映射，对于度数为 $p$ 的映射，也只有 ${\cal
  O}(h^{d+p-1})$ 。 (你可以通过考虑到在2D中，间隙/重叠是一个三角形，底 $h$ ，高 ${\cal
  O}(h)$ ；在3D中，它是一个类似金字塔的结构，底面积 $h^2$ ，高 ${\cal O}(h)$  。类似的考虑也适用于高阶映射，其中空隙/重叠的高度为  ${\cal O}(h^p)$  .)换句话说，如果你使用线性元素的线性映射，你所积分的体积的误差已经与使用通常的高斯正交的积分误差处于同一水平。当然，对于更高阶的元素，人们将不得不选择匹配的映射对象。

  关于为什么不值得过分担心这个问题的另一个观点是，在数值分析界肯定没有人说这些问题是使用复杂几何体时需要注意的一个主要问题。如果从业者之间似乎并不经常讨论这个问题，如果有的话，那么它至少不是人们认定的一个普遍问题。

  这个问题与在弯曲的边界上有悬挂的节点没有什么不同，在这种情况下，边界的几何描述通常会将悬挂的节点拉到边界上，而大的边缘仍然是直的，使得相邻的小单元和大单元不能相互匹配。虽然这种行为从一开始就存在于deal.II中，在流形描述出现之前的15年，但在邮件列表的讨论或与同事的交谈中，它从未出现过。

    <li>  能否修复？原则上是的，但这是一个复杂的问题。我们暂且假设我们只会使用MappingQ1类，也就是线性映射。在这种情况下，每当三角化类需要沿着一条将成为悬空节点的边建立一个新的顶点时，它就会直接取相邻顶点的平均值<i>in real
  space</i>，也就是说，不问流形的描述。这样一来，该点就位于长直边上，两条短直边将与一条长直边匹配。只有当所有相邻的单元都被细化，并且该点不再是一个悬挂的节点时，我们才会用通过流形得到的坐标来替换它的坐标。这在实现上可能比较麻烦，但肯定是可行的。

  更复杂的问题出现了，因为人们可能想使用高阶的MappingQ对象。在这种情况下，Triangulation类可以自由选择悬挂节点的位置（因为长边的二次曲线可以选择通过悬挂节点的方式），但是MappingQ类在确定中边点的位置时，必须确保如果该边是相邻的较粗单元的长边的一半，那么中点不能从流形中获得，而必须沿着长二次边选择。对于立方体（和所有其他奇数）映射，这个问题又有点复杂了，因为人们通常安排立方体边沿着边的1/3和2/3点走，因此必然要通过悬挂的节点，但这可能是可以解决的。在任何情况下，即使如此，这也有两个问题。

  - 在细化三角函数时，三角函数类不可能知道将使用什么映射。事实上，在同一个程序中，一个三角函数在不同的情况下被使用的情况并不罕见。如果使用的映射决定了我们是否可以自由选择一个点，那么，三角剖分应该如何定位新的顶点？

  - 映射是纯粹的局部构造：它们只对孤立的单元起作用，而这正是有限元方法的重要特征之一。要问一条边的一个顶点是否是悬空节点，需要查询一个单元的邻域；此外，这样的查询不只是涉及到三维中一个单元的6个面的邻域，而是可能需要遍历与一条边相连的大量的其他单元。即使可以做到这一点，人们仍然需要根据邻域的样子做不同的事情，产生的代码可能非常复杂，难以维护，而且可能很慢。

  因此，至少在目前，这些想法都没有被实施。这导致了不连续的几何形状的不良后果，但是，正如上面所讨论的，这种影响在实际操作中似乎并不构成问题。

 </ul> 


examples/step-54/doc/intro.dox

 <br> 

<i>This program was contributed by Andrea Mola and Luca Heltai.</i>

 @note  这个程序阐述了工业几何的概念，使用与OpenCASCADE库（http://www.opencascade.org）接口的工具，允许指定任意的IGES文件来描述你的几何形状的边界。

 @dealiiTutorialDOI{10.5281/zenodo.546220,https://zenodo.org/badge/DOI/10.5281/zenodo.546220.svg} 

<a name="Intro"></a>

<h1>Introduction</h1>


在之前的一些教程中（第1步、第3步、第5步、第6步和第49步等），我们已经学会了如何使用deal.II中提供的网格细化方法。这些教程展示了如何利用这些工具为一次模拟产生一个精细的网格，如步骤3；或者从一个粗大的网格开始，在自适应细化的网格上进行一系列模拟，如步骤6的情况。无论采取哪种方法，网格细化都需要对计算域边界进行适当的几何描述，以便在每次细化时将新的网格节点放到边界面上。例如，第5步显示了如何创建一个圆形网格，将一个圆形流形对象自动附加到计算域上，从而使位于边界上的面被细化到圆形上。第53步显示了如何用一个由实验获得的数据定义的流形来做这件事。但是，至少就基本边界形状而言，deal.II实际上只提供了圆、球、盒和其他基本组合。在本教程中，我们将展示如何使用一组开发的类来导入任意的CAD几何图形，将它们分配到计算域的所需边界，并在这种复杂的形状上细化计算网格。




<h3> CAD surfaces </h3>

在最常见的工业实践中，任意形状的物体的几何模型是通过计算机辅助设计（CAD）工具实现的。在过去的几十年里，CAD建模器的使用已经普及，因为它们可以为每个设计对象生成一个完整的虚拟模型，通过计算机可以在实物制作之前对其最精细的细节进行可视化、检查和分析。  从数学的角度来看，CAD建模人员的引擎是由分析几何学来代表的，特别是由参数化的曲线和曲面，如B-splines和NURBS，它们足够丰富，可以代表大多数的实际利益的表面。  一旦一个虚拟模型准备好了，所需物体的所有几何特征都被存储在文件中，这些文件实质上包含了构成该物体的参数化曲面和曲线的系数。根据用于定义几何模型的具体CAD工具，当然有几种不同的文件格式，可以组织CAD模型的信息。为了提供一个跨CAD工具交换数据的共同基础，美国国家标准局在1980年发布了初始图形交换代表（IGES）中性文件格式，在本例中使用。

<h3> The CAD boundary projector classes </h3>

为了导入和查询CAD模型，deal.II库为CAD建模的OpenCASCADE开源库实现了一系列的包装函数。这些函数允许将IGES文件导入OpenCASCADE本地对象，并将其包裹在一系列Manifold类中。

一旦从IGES文件导入，模型就被存储在一个 <code>TopoDS_Shape</code> 中，这是OpenCASCADE框架中定义的通用拓扑实体。从 <code>TopoDS_Shape</code> 中，就可以访问构成它的所有子形状（如顶点、边和面），以及它们的几何描述。在deal.II框架中，组成一个形状的拓扑实体被用来创建一个相应的Manifold表示。在步骤6中，我们看到了如何使用 GridGenerator::hyper_sphere() 来创建一个超球体，它自动将一个SphericalManifold附加到所有边界面。这保证了边界面在网格细化过程中保持在球体或圆上。CAD建模界面的功能被设计为保留相同的结构，允许用户使用导入的CAD形状建立一个投影仪对象，保持我们在其他教程程序中使用的相同程序，即把这种投影仪对象分配给粗略网格的单元、面或边。在每个细化周期，新的网格节点将通过将现有对象的中点投影到指定的几何体上而自动生成。

与球形或圆形边界不同，具有复杂几何形状的边界带来的问题是，在规定形状上细化后创建的新节点最好放在哪里。例如，PolarManifold将周围的点转换为极坐标，计算该坐标系中的平均值（对每个坐标单独计算），最后将点转换回直角坐标。

不过，在一个任意的复杂形状的情况下，一个合适的新节点的位置选择不可能那么容易确定。deal.II中的OpenCASCADE封装器提供了几个采用不同投影策略的投影仪类。第一个投影仪，在 OpenCASCADE::ArclengthProjectionLineManifold 类中实现，只用于边缘细化。它的建立是给它分配一个维度为1的拓扑形状，或者是一个 <code>TopoDS_Edge</code> or a <code>TopoDS_Wire</code> （这是一个复合形状，由几个连接的 <code>TopoDS_Edge</code> 组成），并细化网格边缘，找到新的顶点作为点，将CAD曲线部分的曲线长度分成两个偶数部分，位于原始边缘的顶点之间。

 <img src="https://www.dealii.org/images/steps/developer/step-54.CurveSplit.png" alt="" width="500"> 


在 OpenCASCADE::NormalProjectionBoundary 类中实现了一个不同的投影策略。在构造时分配的 <code>TopoDS_Shape</code> 可以是任意的（图形、面、边的集合或单个面或边都可以）。新的单元格节点首先通过对周围的点进行平均计算，方法与FlatManifold相同。在第二步中，所有的新节点将沿着形状的法线方向被投射到 <code>TopoDS_Shape</code> 。如果没有法线投影，则选择最接近形状的点--通常位于形状的边界上--。  如果形状是由几个子形状组成的，则投影到每个子形状上，并选择最近的投影点。

 <img src="https://www.dealii.org/images/steps/developer/step-54.NormalProjectionEdge.png" alt="" width="500">  <img src="https://www.dealii.org/images/steps/developer/step-54.NormalProjection.png" alt="" width="500">  。

正如我们即将体验到的，对于某些形状，将投影方向设置为CAD表面的法线，将不会导致合适质量的表面网格元素。这是因为CAD表面的法线方向原则上与网格需要新节点所在的方向无关。在这种情况下， OpenCASCADE::DirectionalProjectionBoundary 类可以提供帮助。这个类的构造是指定一个 <code>TopoDS_Shape</code> （至少包含一个面）和一个方向，所有的投影将沿着这个方向进行。新的点将被计算出来，首先对周围的点进行平均化（就像FlatManifold的情况一样），然后沿着构造时使用的方向，在拓扑形状和通过所得到的点的线之间取得最近的交点。  这样一来，用户就可以对投影方向有更高的控制，以确保良好的网格质量。

 <img src="https://www.dealii.org/images/steps/developer/step-54.DirectionalProjection.png" alt="" width="500"> 


当然，后一种方法只有在表面的方向相当统一时才有效，这样就可以确定一个单一的投影方向。在表面方向接近投影方向的情况下，甚至有可能找不到方向性的投影。为了克服这些问题， OpenCASCADE::NormalToMeshProjectionBoundary 类实现了第三个投影算法。 OpenCASCADE::NormalToMeshProjectionBoundary 类的建立是将一个 <code>TopoDS_Shape</code> （至少包含一个面）分配给构造函数，其工作方式与 OpenCASCADE::DirectionalProjection. 完全一样。但是，正如该类的名字所暗示的， OpenCASCADE::NormalToMeshProjectionBoundary 试图想出一个合适的对要精化的网格元素的法线方向的估计，并将其用于新节点在CAD面上的投影。如果我们考虑二维空间中的网格边缘，其轴线方向是一个方向，沿着这个方向分割，以产生两个相同长度的新单元。我们在此将这一概念扩展到三维空间，并将所有新节点的投影方向近似于单元格的法线。

在下图中，受本教程中考虑的几何图形的启发，我们尝试比较所考虑的三种投影仪的行为。从左边可以看出，给定原始单元（蓝色），用法线投影找到的新点的位置不允许生成均匀的新元素（红色）。这种情况在进一步的细化步骤中会变得更糟。  由于我们考虑的几何体在某种程度上垂直于水平方向，以水平方向为投影方向的方向性投影（中心图像）在获得新的网格点方面做得相当好。然而，由于图片底部的表面几乎是水平的，我们可以预期在这些区域进行进一步细化步骤时，会出现问题。最后，右边的图片显示，位于单元轴上的节点将导致两个新单元具有相同的长度。当然，三维的情况会比这个简单的二维案例中描述的情况更复杂一些。然而，这个测试的结果证实，当考虑到任意形状的表面时，除非你有一个已知的更具体的方法，否则在测试的三种方法中，法线方向是最佳方法。


 <img src="https://www.dealii.org/images/steps/developer/step-54.ProjectionComparisons.png" alt="" width="700"> 




<h3> The testcase </h3>

在这个程序中，我们将考虑为一个描述船头的真实几何体创建一个表面网格（这个几何体经常被用于CAD和网格生成的比较中，并且可以免费获得）。我们得到的表面网格可以用来解决边界元素方程，以模拟水在船舶周围的流动（类似于step-34的方式），但我们不会在这里尝试这样做。为了让你了解我们所考虑的几何形状，这里有一张图片。

 <img src="https://www.dealii.org/images/steps/developer/step-54.bare.png" alt="" width="500"> 

在程序中，我们从文件中读取几何体和粗略的网格，然后采用上面讨论的几个选项来放置新的顶点，进行一系列的网格细化步骤。


examples/step-54/doc/results.dox



<h1>Results</h1>

程序的执行会产生一系列的网格文件 <code>3d_mesh_*.vtk</code> ，我们可以用任何可以读取VTK文件格式的常用可视化程序来进行可视化。

下表说明了采用正常投影策略得到的结果。表中的前两行显示的是逐步细化的网格的侧视图，覆盖在精确几何体的非常精细的渲染上。深红色和浅红色的区域只是表示当前的网格或精细的几何体更接近观察者；这种区别没有任何特别深刻的意义。最后一排图片描述了第二排中相同网格的正视图（镜像到几何体的两边）。


 <table style="width:90%">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.common_0.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_1.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_2.png" alt="" width="400"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_3.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_4.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_5.png" alt="" width="400"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_front_3.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_front_4.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_front_5.png" alt="" width="400"></td>
  </tr>
</table> 

从图片中可以看出，正如我们所预料的那样，当应用于具有明显曲率变化的表面时，正常的细化策略无法产生良好的形状的元素。这在船体的球体上尤其明显，所有的新点都被放置在球体的上部，而下部则完全没有被解决。

下表的排列方式与上表相同，说明了采用方向性投影方法获得的结果，其中选择的投影方向是Y轴（在每幅图像的左下方用一个小的黄色箭头表示）。


 <table style="width:90%">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.common_0.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_1.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_2.png" alt="" width="400"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_3.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_4.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_5.png" alt="" width="400"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_front_3.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_front_4.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.directional_front_5.png" alt="" width="400"></td>
  </tr>
</table> 

这些图像证实，用定向投影得到的网格质量明显高于沿表面法线投影得到的网格。然而，在球体底部观察到一些在Y方向上拉长的元素，那里的表面几乎与选择的投影方向平行。

最后的测试显示了使用面的法线投影的结果。

 <table style="width:90%">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.common_0.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_1.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_2.png" alt="" width="400"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_3.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_4.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_5.png" alt="" width="400"></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_front_3.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_front_4.png" alt="" width="400"></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-54.normal_to_mesh_front_5.png" alt="" width="400"></td>
  </tr>
</table> 

图片证实了法线投影的方法导致网格在整个细化步骤中保持均匀的间隔。同时，这些网格很好地表现了原始的几何形状，甚至在灯泡的底部区域也是如此，这一点在使用定向投影仪或法线投影仪时并没有得到很好的恢复。


examples/step-55/doc/intro.dox

 <br> 

<i>This program was contributed by Timo Heister. Special thanks to Sander
Rhebergen for the inspiration to finally write this tutorial.


This material is based upon work partially supported by National Science
Foundation grant DMS1522191 and the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation under
Award No. EAR-0949446 and The University of California-Davis.


The authors would like to thank the Isaac Newton Institute for
Mathematical Sciences, Cambridge, for support and hospitality during
the programme Melt in the Mantle where work on this tutorial was
undertaken. This work was supported by EPSRC grant no EP/K032208/1.
</i>




 @note  作为这个程序的前提条件，你需要安装PETSc或Trilinos和p4est库。在<a href="../../readme.html"
target="body">README</a>文件中描述了deal.II与这些附加库的安装情况。

<a name="Intro"></a>

<h1>Introduction</h1>

在第40步的基础上，本教程展示了如何使用MPI与PETSc或Trilinos进行线性代数，并行解决具有多个组件的线性PDEs。为此，我们返回到步骤22中讨论的斯托克斯方程。编写本教程的动机是在第40步（并行拉普拉斯）和第32步（针对时间相关问题的并行耦合斯托克斯与布西尼斯克）之间提供一个中间步骤（双关）。

本教程的学习成果是。

- 你能够并行地解决有多个变量的PDEs，并能将其应用于不同的问题。

- 你了解最佳预处理程序的概念，并能对某一特定问题进行检查。

- 你能够使用免费的计算机algreba系统SymPy（https://sympy.org）来构建制造的解决方案。

- 你可以为并行程序实现各种其他任务：错误计算、编写图形输出等。

- 你可以将矢量场、流线和矢量的轮廓可视化。

我们要解决的是满足斯托克斯方程的速度 $\textbf{u}$ 和压力 $p$ ，其内容为

@f{eqnarray*}


  - \triangle \textbf{u} + \nabla p &=& \textbf{f}, \\


  -\textrm{div}\; \textbf{u} &=& 0.


@f}






<h3>Optimal preconditioners</h3>

请确保你阅读（甚至更好：尝试）步骤22中 "可能的扩展 "部分的 "块舒尔补码预处理 "所描述的内容。就像那里描述的那样，我们将使用Krylov方法和块状预处理程序来解决块状系统。

我们的目标是为线性系统构造一个非常简单的（也许是最简单的）最优预处理。如果预处理系统的迭代次数与网格大小无关，则该预处理程序被称为 "最优 "或 "最优复杂性" $h$  。你可以把这个定义扩展到要求与使用的处理器数量无关（我们将在结果部分讨论这个问题），计算域和网格质量，测试案例本身，有限元空间的多项式程度，等等。

为什么恒定的迭代次数被认为是 "最佳 "的？假设离散化的PDE给出一个有N个未知数的线性系统。因为来自有限元离散化的矩阵是稀疏的，矩阵-向量乘积可以在O(N)时间内完成。先决条件的应用充其量也只能是O(N)（例如可以用多网格方法来做）。如果解决线性系统所需的迭代次数与 $h$ 无关（因此也与N无关），那么解决该系统的总成本将是O(N)。不可能战胜这个复杂度，因为即使是查看右手边的所有条目也已经需要O(N)的时间。更多信息见  @cite elman2005  ，第2.5章（多网格）。

这里描述的预处理程序甚至比步骤22中描述的更简单，通常需要更多的迭代，因此需要更多的时间来解决。在考虑预处理程序时，最优性并不是唯一重要的衡量标准。但是一个最优的、昂贵的预处理程序通常比一个更便宜的、非最优的预处理程序更可取。这是因为，最终，随着网格尺寸越来越小，线性问题越来越大，前者将最终击败后者。

<h3>The solver and preconditioner</h3>

我们对线性系统进行预处理

@f{eqnarray*}
  \left(\begin{array}{cc}
    A & B^T \\ B & 0
  \end{array}\right)
  \left(\begin{array}{c}
    U \\ P
  \end{array}\right)
  =
  \left(\begin{array}{c}
    F \\ 0
  \end{array}\right),


@f}



块状对角线预处理器

@f{eqnarray*}
  P^{-1}
  =
  \left(\begin{array}{cc}
    A & 0 \\ 0 & S
  \end{array}\right) ^{-1},
  =
  \left(\begin{array}{cc}
    A^{-1} & 0 \\ 0 & S^{-1}
  \end{array}\right),


@f}

其中 $S=-BA^{-1} B^T$ 是舒尔补。

对于 $P$ 的这种选择，假设我们准确地处理了 $A^{-1}$ 和 $S^{-1}$ （这是一种 "理想化 "的情况），预处理的线性系统有三个独立于 $h$ 的特征值，因此是 "最优 "的。  见  @cite elman2005  中的6.2.1节（特别是第292页）。作为比较，在第22步中使用理想版的上块三角预处理（也用于第56步）会使所有的特征值都等于1。

我们将使用 $P^{-1}$ 中的逆运算的近似值，它（几乎）独立于 $h$ 。在这种情况下，我们可以再次证明，特征值是独立于 $h$ 的。对于Krylov方法，我们选择MINRES，它对分析很有吸引力（迭代次数被证明与 $h$ 无关，见上述书中第6.2.1章的其余部分），从计算的角度看很好（例如比GMRES更简单、更便宜），而且适用（矩阵和预处理器是对称的）。

对于近似，我们将使用压力空间中的质量矩阵的CG解来近似 $S^{-1}$  的作用。请注意，质量矩阵在光谱上等同于 $S$  。我们可以预期CG迭代的数量与 $h$ 无关，即使使用ILU这样的简单预处理程序。

对于速度块 $A$ 的近似，我们将执行一个单一的AMG V-循环。在实践中，这种选择并不完全独立于 $h$ ，这可以解释迭代数的轻微增加。一个可能的解释是，最粗的层次将被精确解决，而最粗的矩阵的层次数和大小是不可预测的。




<h3>The testcase</h3>

我们将根据经典的Kovasznay问题构建一个制造的解决方案，见  @cite kovasznay1948laminar  。这里是一个由x速度着色的解决方案的图像，包括速度的流线。

   <img src="https://www.dealii.org/images/steps/developer/step-55.solution.png" alt=""> 

不过，我们在这里必须作弊，因为我们不是在解决非线性的纳维-斯托克斯方程，而是解决没有对流项的线性斯托克斯系统。因此，为了重现完全相同的解，我们用科瓦兹内问题的解来制造解的方法。这将有效地把对流项移到右手边  $f$  。

右手边是用脚本 "reference.py "计算的，我们使用精确的解决方案来计算边界条件和误差。


examples/step-55/doc/results.dox



<h1>Results</h1>

正如上面的讨论所预期的那样，迭代次数与处理器的数量无关，只与 $h$ 有非常小的关系。

 <table>
<tr>
  <th colspan="2">PETSc</th>
  <th colspan="8">number of processors</th>
</tr>
<tr>
  <th>cycle</th>
  <th>dofs</th>
  <th>1</th>
  <th>2</th>
  <th>4</th>
  <th>8</th>
  <th>16</th>
  <th>32</th>
  <th>64</th>
  <th>128</th>
</tr>
<tr>
  <td>0</td>
  <td>659</td>
  <td>49</td>
  <td>49</td>
  <td>49</td>
  <td>51</td>
  <td>51</td>
  <td>51</td>
  <td>49</td>
  <td>49</td>
</tr>
<tr>
  <td>1</td>
  <td>2467</td>
  <td>52</td>
  <td>52</td>
  <td>52</td>
  <td>52</td>
  <td>52</td>
  <td>54</td>
  <td>54</td>
  <td>53</td>
</tr>
<tr>
  <td>2</td>
  <td>9539</td>
  <td>56</td>
  <td>56</td>
  <td>56</td>
  <td>54</td>
  <td>56</td>
  <td>56</td>
  <td>54</td>
  <td>56</td>
</tr>
<tr>
  <td>3</td>
  <td>37507</td>
  <td>57</td>
  <td>57</td>
  <td>57</td>
  <td>57</td>
  <td>57</td>
  <td>56</td>
  <td>57</td>
  <td>56</td>
</tr>
<tr>
  <td>4</td>
  <td>148739</td>
  <td>58</td>
  <td>59</td>
  <td>57</td>
  <td>59</td>
  <td>57</td>
  <td>57</td>
  <td>57</td>
  <td>57</td>
</tr>
<tr>
  <td>5</td>
  <td>592387</td>
  <td>60</td>
  <td>60</td>
  <td>59</td>
  <td>59</td>
  <td>59</td>
  <td>59</td>
  <td>59</td>
  <td>59</td>
</tr>
<tr>
  <td>6</td>
  <td>2364419</td>
  <td>62</td>
  <td>62</td>
  <td>61</td>
  <td>61</td>
  <td>61</td>
  <td>61</td>
  <td>61</td>
  <td>61</td>
</tr>
</table> 

 <table>
<tr>
  <th colspan="2">Trilinos</th>
  <th colspan="8">number of processors</th>
</tr>
<tr>
  <th>cycle</th>
  <th>dofs</th>
  <th>1</th>
  <th>2</th>
  <th>4</th>
  <th>8</th>
  <th>16</th>
  <th>32</th>
  <th>64</th>
  <th>128</th>
</tr>
<tr>
  <td>0</td>
  <td>659</td>
  <td>37</td>
  <td>37</td>
  <td>37</td>
  <td>37</td>
  <td>37</td>
  <td>37</td>
  <td>37</td>
  <td>37</td>
</tr>
<tr>
  <td>1</td>
  <td>2467</td>
  <td>92</td>
  <td>89</td>
  <td>89</td>
  <td>82</td>
  <td>86</td>
  <td>81</td>
  <td>78</td>
  <td>78</td>
</tr>
<tr>
  <td>2</td>
  <td>9539</td>
  <td>102</td>
  <td>99</td>
  <td>96</td>
  <td>95</td>
  <td>95</td>
  <td>88</td>
  <td>83</td>
  <td>95</td>
</tr>
<tr>
  <td>3</td>
  <td>37507</td>
  <td>107</td>
  <td>105</td>
  <td>104</td>
  <td>99</td>
  <td>100</td>
  <td>96</td>
  <td>96</td>
  <td>90</td>
</tr>
<tr>
  <td>4</td>
  <td>148739</td>
  <td>112</td>
  <td>112</td>
  <td>111</td>
  <td>111</td>
  <td>127</td>
  <td>126</td>
  <td>115</td>
  <td>117</td>
</tr>
<tr>
  <td>5</td>
  <td>592387</td>
  <td>116</td>
  <td>115</td>
  <td>114</td>
  <td>112</td>
  <td>118</td>
  <td>120</td>
  <td>131</td>
  <td>130</td>
</tr>
<tr>
  <td>6</td>
  <td>2364419</td>
  <td>130</td>
  <td>126</td>
  <td>120</td>
  <td>120</td>
  <td>121</td>
  <td>122</td>
  <td>121</td>
  <td>123</td>
</tr>
</table> 

虽然PETSc的结果显示迭代次数不变，但使用Trilinos时，迭代次数增加。这可能是由于AMG预处理程序的不同设置造成的。出于性能方面的考虑，我们不允许在几千个未知数以下进行粗化。由于粗解器是精确求解（我们默认使用LU），层数的变化将影响V型循环的质量。因此，对于较小的问题规模，V型循环更接近于精确求解器。

<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Investigate Trilinos iterations</h4>

玩弄平滑器、平滑步骤和Trilinos AMG的其他属性，以实现最佳预处理。

<h4>Solve the Oseen problem instead of the Stokes system</h4>

这一变化需要将外部求解器改为GMRES或BiCGStab，因为系统不再是对称的了。

你可以在对流项 $b
\cdot \nabla u$ 中规定精确的流动解，即 $b$  。如果你把右手边设置为零，这应该可以得到与原问题相同的解。

<h4>Adaptive refinement</h4>

到目前为止，这个教程程序在每一步都会对网格进行全局细化。将 StokesProblem::refine_grid() 中的代码替换为如下内容

@code
Vector<float> estimated_error_per_cell(triangulation.n_active_cells());


FEValuesExtractors::Vector velocities(0);
KellyErrorEstimator<dim>::estimate(
  dof_handler,
  QGauss<dim - 1>(fe.degree + 1),
  std::map<types::boundary_id, const Function<dim> *>(),
  locally_relevant_solution,
  estimated_error_per_cell,
  fe.component_mask(velocities));
parallel::distributed::GridRefinement::refine_and_coarsen_fixed_number(
  triangulation, estimated_error_per_cell, 0.3, 0.0);
triangulation.execute_coarsening_and_refinement();
@endcode

使得探索自适应网格细化变得简单。


examples/step-56/doc/intro.dox

<i>This program was contributed by Ryan Grove and Timo Heister.


This material is based upon work partially supported by National Science
Foundation grant DMS1522191 and the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation under
Award No. EAR-0949446 and The University of California-Davis.


The authors would like to thank the Isaac Newton Institute for
Mathematical Sciences, Cambridge, for support and hospitality during
the programme Melt in the Mantle where work on this tutorial was
undertaken. This work was supported by EPSRC grant no EP/K032208/1.
</i>

 @dealiiTutorialDOI{10.5281/zenodo.400995,https://zenodo.org/badge/DOI/10.5281/zenodo.400995.svg} 

<a name="Intro"></a>

<h1>Introduction</h1>

<h3> Stokes Problem </h3>

本教程的目的是为斯托克斯方程创建一个高效的线性求解器，并将其与其他方法进行比较。  在这里，我们将使用带有几何多栅的FGMRES作为预处理速度块，我们将在结果部分显示，这比step-22中使用的线性求解器（包括 "可能的扩展 "中描述的方案）从根本上来说是一种更好的方法。  从根本上说，这是因为只有多网格才有可能得到 $O(n)$ 的求解时间，其中 $n$ 是线性系统的未知数的数量。使用Timer类，我们收集一些统计数据来比较设置时间、求解时间和迭代次数。我们还计算了误差，以确保我们所实现的是正确的。

让  $u \in H_0^1 = \{ u \in H^1(\Omega), u|_{\partial \Omega} = 0 \}$  和  $p \in L_*^2 = \{ p \in L^2(\Omega), \int_\Omega p = 0
\}$  。斯托克斯方程的非维度形式如下。

@f{eqnarray*}


 - 2 \text{div} \frac {1}{2} \left[ (\nabla \textbf{u})
 + (\nabla \textbf{u})^T\right] + \nabla p & =& f \\


 - \nabla \cdot u &=& 0


@f}



请注意，我们使用的是变形张量，而不是 $\Delta u$ （关于两者之间的区别的详细描述可以在步骤22中找到，但总的来说，变形张量的物理性更强，也更昂贵）。

<h3> Linear %Solver and Preconditioning Issues </h3>

离散方程的微弱形式自然导致了以下速度场和压力场的节点值的线性系统。

@f{eqnarray*}
\left(\begin{array}{cc} A & B^T \\ B & 0
\end{array}\right) \left(\begin{array}{c} U \\ P \end{array}\right) =
\left(\begin{array}{c} F \\ 0 \end{array}\right).


@f}



我们的目标是比较几种解决方法。  虽然step-22使用 "Schur补足法 "分两步解决线性系统，但我们本着step-22的 "结果 "部分所概述的方法的精神，使用FMGRES和一个有效的预处理器一次性地攻击块系统。其思路如下：如果我们找到一个块状预处理程序 $P$ ，使矩阵的

@f{eqnarray*}
\left(\begin{array}{cc} A & B^T \\ B & 0 \end{array}\right) P^{-1}


@f}



是简单的，那么使用该预处理的迭代求解器将在几次迭代后收敛。请注意，我们在这里做的是正确的预处理。  使用舒尔补码 $S=BA^{-1}B^T$ ，我们发现

@f{eqnarray*}
P^{-1} = \left(\begin{array}{cc} A & B^T \\ 0 &
 S \end{array}\right)^{-1}


@f}



是一个很好的选择。设 $\widetilde{A^{-1}}$ 是 $A^{-1}$ 的近似值， $\widetilde{S^{-1}}$ 是 $S^{-1}$ 的近似值，我们看到

@f{eqnarray*}
P^{-1} =
\left(\begin{array}{cc} A^{-1} & 0 \\ 0 & I \end{array}\right)
\left(\begin{array}{cc} I & B^T \\ 0 & -I \end{array}\right)
\left(\begin{array}{cc} I & 0 \\ 0 & S^{-1} \end{array}\right)
\approx
\left(\begin{array}{cc} \widetilde{A^{-1}} & 0 \\ 0 & I \end{array}\right)
\left(\begin{array}{cc} I & B^T \\ 0 & -I \end{array}\right)
\left(\begin{array}{cc} I & 0 \\ 0 & \widetilde{S^{-1}} \end{array}\right).
  @f}



由于 $P$ 的目的只是作为一个预处理程序，我们将在上式中使用右边的近似值。

正如步骤22所讨论的， $-M_p^{-1}=:\widetilde{S^{-1}} \approx
S^{-1}$ ，其中 $M_p$ 是压力质量矩阵，通过使用CG与ILU作为预处理程序近似求解， $\widetilde{A^{-1}}$ 是通过多种方法之一得到的：使用CG和ILU作为预处理程序求解线性系统，仅仅使用ILU的一次应用，使用CG和GMG（步骤16中描述的几何多网格）作为预处理程序求解线性系统，或者仅仅执行GMG的一个V-循环。

作为比较，我们也在整个系统上使用直接求解器UMFPACK来比较我们的结果，而不是FGMRES。  如果你想使用直接求解器（如UMFPACK），系统需要是可逆的。为了避免恒定压力给定的一维无效空间，我们将第一个压力未知数固定为零。这对迭代求解器来说是没有必要的。




<h3> Reference Solution </h3>

测试问题是一个 "制造的解决方案"（详见步骤7），我们选择  $u=(u_1,u_2,u_3)=(2\sin (\pi x), - \pi y \cos
(\pi x),- \pi z \cos (\pi x))$  和  $p = \sin (\pi x)\cos (\pi y)\sin
(\pi z)$  。我们在域的整个边界上对速度应用迪里切特边界条件  $\Omega=[0,1]\times[0,1]\times[0,1]$  。为了执行边界条件，我们可以直接使用我们的参考解。

如果你在deal.II手册中查找创建一个从 <code>Function@<dim@></code> 派生的类所需要的东西，你会发现这个类有许多 @p virtual 函数，包括 Function::value(),   Function::vector_value(),   Function::value_list(),  等，所有这些都可以被重载。  deal.II的不同部分将需要这些特定函数中的不同部分。这在一开始会让人感到困惑，但幸运的是，你真正需要实现的只有 @p value(). 。Function类中的其他虚拟函数在里面有默认的实现，会默认调用你对 @p value 的实现。

注意，我们的参考解满足 $\nabla \cdot u = 0$  。此外，压力被选择为平均值为零。  对于步骤7的 "制造解决方案的方法"，我们需要找到 $\bf
f$ ，以便。

@f{align*}
{\bf f} =   - 2 \text{div} \frac {1}{2} \left[ (\nabla \textbf{u}) + (\nabla \textbf{u})^T\right] + \nabla p.


@f}



使用上面的参考解，我们得到。

@f{eqnarray*}
{\bf f} &=& (2 \pi^2 \sin (\pi x),- \pi^3 y \cos(\pi
x),- \pi^3 z \cos(\pi x))\\ & & + (\pi \cos(\pi x) \cos(\pi y)
\sin(\pi z) ,- \pi \sin(\pi y) \sin(\pi x) \sin(\pi z), \pi \cos(\pi
z) \sin(\pi x) \cos(\pi y)) @f}



<h3> Computing Errors </h3>

因为我们在线性系统中没有强制要求平均压力为零，所以我们需要在求解后对解决方案进行后处理。为了做到这一点，我们使用 VectorTools::compute_mean_value() 函数来计算压力的平均值，以从压力中减去它。




<h3> DoF Handlers </h3>

我们在这里实现几何多网格的方式只对速度变量（即上面描述的 $A$ 矩阵）进行执行，而不是压力。我们可以用不同的方法来实现这一点，包括将所有的粗网格操作视为作用于 $2\times
2$ 块系统，我们只考虑左上方的块。另外，我们也可以通过真正只考虑整个有限元离散化的速度部分的线性系统来实现。后者是我们在这里想要使用的方式。

为了实现这一点，我们需要能够提出这样的问题："我可以只拥有一个DoFHandler的一部分吗？"。在编写这个程序的时候，这是不可能的，所以为了满足我们的需求，我们只是为速度创建一个单独的、第二个DoFHandler。然后，我们只基于这个第二DoFHandler为多网格预处理程序建立线性系统，并简单地将第一块（整体）向量转移到整个第二DoFHandler的对应向量中。要做到这一点，我们必须保证两个DoFHandler对象中的（速度）自由度排序的<i>order</i>是相同的。事实上，首先在两个对象上分配自由度，然后在两个对象上使用相同的DoFRenumbering操作序列，就可以做到这一点。




<h3> Differences from the Step 22 tutorial </h3>

第56步和第22步的主要区别是我们使用了块状求解器，而不是第22步中使用的Schur补码方法。这种方法的细节可以在步骤-22的 "可能的扩展 "部分的 "块状Schur补码预处理 "小节中找到。对于速度块的预处理，我们从<a href="https://aspect.geodynamics.org">ASPECT</a>中借用了一个叫做 @p BlockSchurPreconditioner 的类，该类可以选择求解 $A$ 的逆，或者只对其应用一个预处理扫频，这分别为我们提供了一种昂贵和便宜的方法。


examples/step-56/doc/results.dox



<h1>Results</h1>

<h3> Errors </h3>

我们首先运行代码，确认有限元解以混合有限元问题的误差分析所预测的正确速率收敛。考虑到足够平滑的精确解 $u$ 和 $p$ ，Taylor-Hood元素 $Q_k \times Q_{k-1}$ 的误差应该是

@f[
\| u -u_h \|_0 + h ( \| u- u_h\|_1 + \|p - p_h \|_0)
\leq C h^{k+1} ( \|u \|_{k+1} + \| p \|_k )


@f]



例如见Ern/Guermond《有限元的理论与实践》，第4.2.5节第195页。这确实是我们观察到的，以 $Q_2 \times Q_1$ 元素为例（这就是代码中的做法，但在 <code>main()</code> 中很容易改变）。

 <table align="center" class="doxtable">
  <tr>
    <th>&nbsp;</th>
    <th>L2 Velocity</th>
    <th>Reduction</th>
    <th>L2 Pressure</th>
    <th>Reduction</th>
    <th>H1 Velocity</th>
    <th>Reduction</th>
  </tr>
  <tr>
    <td>3D, 3 global refinements</td>
    <td>0.000670888</td>
    <td align="center">-</td>
    <td>0.0036533</td>
    <td align="center">-</td>
    <td>0.0414704</td>
    <td align="center">-</td>
  </tr>
  <tr>
    <td>3D, 4 global refinements</td>
    <td>8.38E-005</td>
    <td>8.0</td>
    <td>0.00088494</td>
    <td>4.1</td>
    <td>0.0103781</td>
    <td>4.0</td>
  </tr>
  <tr>
    <td>3D, 5 global refinements</td>
    <td>1.05E-005</td>
    <td>8.0</td>
    <td>0.000220253</td>
    <td>4.0</td>
    <td>0.00259519</td>
    <td>4.0</td>
</th>
  </tr>
</table> 

<h3> Timing Results </h3>

让我们比较一下使用UMFPACK的直接求解方法和两种方法，其中我们选择 $\widetilde {A^{-1}}=A^{-1}$ 和 $\widetilde{S^{-1}}=S^{-1}$ ，用CG求解 $A,S$ 的线性系统。然后CG的预处理程序是ILU或GMG。下表总结了求解器的迭代、时序和虚拟内存（VM）的峰值使用。

 <table align="center" class="doxtable">
<tr>
  <th></th>
  <th colspan="3">General</th>
  <th colspan="6">GMG</th>
  <th colspan="6">ILU</th>
  <th colspan="3">UMFPACK</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th colspan="2">Timings</th>
  <th colspan="2">Timings</th>
  <th colspan="3">Iterations</th>
  <th></th>
  <th colspan="2">Timings</th>
  <th colspan="3">Iterations</th>
  <th></th>
  <th colspan="2">Timings</th>
  <th></th>
</tr>
<tr>
  <th>Cycle</th>
  <th>DoFs</th>
  <th>Setup</th>
  <th>Assembly</th>
  <th>Setup</th>
  <th>Solve</th>
  <th>Outer</th>
  <th>Inner (A)</th>
  <th>Inner (S)</th>
  <th>VM Peak</th>
  <th>Setup</th>
  <th>Solve</th>
  <th>Outer</th>
  <th>Inner (A)</th>
  <th>Inner (S)</th>
  <th>VM Peak</th>
  <th>Setup</th>
  <th>Solve</th>
  <th>VM Peak</th>
</tr>
<tr>
  <td>0</td>
  <td>15468</td>
  <td>0.1s</td>
  <td>0.3s</td>
  <td>0.3s</td>
  <td>1.3s</td>
  <td>21</td>
  <td>67</td>
  <td>22</td>
  <td>4805</td>
  <td>0.3s</td>
  <td>0.6s</td>
  <td>21</td>
  <td>180</td>
  <td>22</td>
  <td>4783</td>
  <td>2.65s</td>
  <td>2.8s</td>
  <td>5054</td>
</tr>
<tr>
  <td>1</td>
  <td>112724</td>
  <td>1.0s</td>
  <td>2.4s</td>
  <td>2.6s</td>
  <td>14s</td>
  <td>21</td>
  <td>67</td>
  <td>22</td>
  <td>5441</td>
  <td>2.8s</td>
  <td>15.8s</td>
  <td>21</td>
  <td>320</td>
  <td>22</td>
  <td>5125</td>
  <td>236s</td>
  <td>237s</td>
  <td>11288</td>
</tr>
<tr>
  <td>2</td>
  <td>859812</td>
  <td>9.0s</td>
  <td>20s</td>
  <td>20s</td>
  <td>101s</td>
  <td>20</td>
  <td>65</td>
  <td>21</td>
  <td>10641</td>
  <td>27s</td>
  <td>268s</td>
  <td>21</td>
  <td>592</td>
  <td>22</td>
  <td>8307</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
</tr>
</table> 

从表中可以看出。

1.UMFPACK使用了大量的内存，特别是在3D中。另外，UMFPACK的计时并不随问题的大小而变化。

2.因为我们对 $A$ 和 $S$ 使用内部求解器，ILU和GMG需要相同数量的外部迭代。

3.对于ILU来说， $A$ 的（内部）迭代次数随着细化而增加，导致求解时间的线性扩展性较差。相比之下， $A$ 的内部迭代次数在GMG中保持不变，导致求解时间几乎完美的缩放。

4.GMG需要比ILU多一点的内存来存储电平和接口矩阵。

<h3> Possibilities for extensions </h3>

<h4> Check higher order discretizations </h4>

用更高阶的稳定FE对进行实验，检查你是否观察到正确的收敛率。

<h4> Compare with cheap preconditioner </h4>

介绍中还概述了对整个系统进行预处理的另一种选择，即我们不选择上表中的 $\widetilde
{A^{-1}}=A^{-1}$ ，而是选择 $\widetilde{A^{-1}}$ ，只分别用GMG或ILU进行单一预处理的应用。

这实际上是在代码中实现的。目前，布尔值 <code>use_expensive</code> in <code>solve()</code> 被设置为 @p true.  上面提到的选项是通过设置为 @p false. 得到的。

你会发现，如果你用GMG这种方式，FGMRES的迭代次数在细化过程中保持不变。这意味着多重网格是最优的，并且与 $h$ 无关。


examples/step-57/doc/intro.dox

 <br> 

<i>This program was contributed by Liang Zhao and Timo Heister.


This material is based upon work partially supported by National Science
Foundation grant DMS1522191 and the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation under
Award No. EAR-0949446 and The University of California-Davis.
</i>

 @dealiiTutorialDOI{10.5281/zenodo.484156,https://zenodo.org/badge/DOI/10.5281/zenodo.484156.svg} 

<a name="Intro"></a>

<h1>Introduction</h1>

<h3> Navier Stokes Equations </h3>

在本教程中，我们展示了如何用牛顿方法求解不可压缩的纳维尔-斯托克斯方程（NSE）。我们在这里考虑的流动被假定是稳定的。在一个域 $\Omega \subset
\mathbb{R}^{d}$ ， $d=2,3$ ，具有片状光滑边界 $\partial \Omega$ ，和一个给定的力场 $\textbf{f}$ ，我们寻求一个速度场 $\textbf{u}$ 和压力场 $\textbf{p}$ ，满足以下条件

@f{eqnarray*}


- \nu \Delta\textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f}\\


- \nabla \cdot \textbf{u} &=& 0.


@f}



与步骤22中讨论的斯托克斯方程不同，由于对流项的存在，NSE是一个非线性方程组  $(\textbf{u} \cdot
\nabla)\textbf{u}$  。计算数值解的第一步是将系统线性化，这将用牛顿方法完成。在步骤35中讨论了一个随时间变化的问题，其中系统是使用最后一个时间步骤的解来线性化的，没有必要进行非线性解。

<h3> Linearization of Navier-Stokes Equations </h3>

我们定义一个非线性函数，其根是NSE的解，即

@f{eqnarray*}
F(\mathbf{u}, p) =
  \begin{pmatrix}


    - \nu \Delta\mathbf{u} + (\mathbf{u} \cdot \nabla)\mathbf{u} + \nabla p - \mathbf{f} \\


    - \nabla \cdot \mathbf{u}
  \end{pmatrix}.


@f}



假设初始猜测足以保证牛顿迭代的收敛性，并表示 $\textbf{x} = (\textbf{u}, p)$ ，牛顿对向量函数的迭代可以定义为

@f{eqnarray*}
  \textbf{x}^{k+1} = \textbf{x}^{k} - (\nabla F(\textbf{x}^{k}))^{-1} F(\textbf{x}^{k}),


@f}



其中 $\textbf{x}^{k+1}$ 是步骤 $k+1$ 中的近似解， $\textbf{x}^{k}$ 代表上一步的解， $\nabla
F(\textbf{x}^{k})$ 是在 $\textbf{x}^{k}$ 处评估的雅各布矩阵。类似的迭代可以在步骤15中找到。

牛顿迭代公式意味着新的解决方案是通过在旧的解决方案上增加一个更新项而得到的。我们不是评估雅各布矩阵并取其倒数，而是将更新项视为一个整体，即

@f{eqnarray*}
  \delta \textbf{x}^{k} = - (\nabla F(\textbf{x}^{k}))^{-1} F(\textbf{x}^{k}),


@f}



其中  $\textbf{x}^{k+1}=\textbf{x}^{k}+\delta \textbf{x}^{k}$  。

我们可以通过求解系统找到更新项

@f{eqnarray*}
  \nabla F(\textbf{x}^{k}) \delta \textbf{x}^{k} = -F(\textbf{x}^{k}).


@f}



这里，前一个方程的左边代表 $F(\textbf{x})$ 沿 $\delta
\textbf{x}^{k}$ 在 $\textbf{x}^{k}$ 的方向梯度。根据定义，方向性梯度由以下公式给出

@f{eqnarray*}
  & &\nabla F(\mathbf{u}^{k}, p^{k}) (\delta \mathbf{u}^{k}, \delta p^{k}) \\
  \\
  &=& \lim_{\epsilon \to 0} \frac{1}{\epsilon}
      \left(
        F(\mathbf{u}^{k} + \epsilon \delta \mathbf{u}^{k},
          p^{k} + \epsilon \nabla \delta p^{k})


      - F(\mathbf{u}^{k}, p^{k})
      \right)\\
  \\
  &=& \lim_{\epsilon \to 0} \frac{1}{\epsilon}
      \begin{pmatrix}


        - \epsilon \nu \Delta \delta \mathbf{u}^{k}
        + \epsilon \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
        + \epsilon \delta \mathbf{u}^{k} \cdot \nabla \mathbf{u}^{k}
        + \epsilon^{2} \delta \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
        + \epsilon \nabla \delta p^{k}\\


        - \epsilon \nabla \cdot \delta \mathbf{u}^{k}
      \end{pmatrix} \\
  \\
  &=& \begin{pmatrix}


        - \nu \Delta \delta \mathbf{u}^{k}
        + \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
        + \delta \mathbf{u}^{k} \cdot \nabla \mathbf{u}^{k}
        + \nabla \delta p^{k}\\


        - \nabla \cdot \delta \mathbf{u}^{k}
      \end{pmatrix}.


@f}



因此，我们得出了线性化系统。

@f{eqnarray*}


   -\nu \Delta \delta \mathbf{u}^{k}
  + \mathbf{u}^{k} \cdot \nabla \delta \mathbf{u}^{k}
  + \delta \mathbf{u}^{k} \cdot \nabla \mathbf{u}^{k}
  + \nabla \delta p^{k}
  = -F(\mathbf{x}^k), \\


   -\nabla \cdot\delta \mathbf{u}^{k}
  = \nabla \cdot \mathbf{u}^{k},


@f}



其中 $\textbf{u}^k$ 和 $p^k$ 是上一次迭代的解。此外，第二个方程的右边不是零，因为离散解不完全是无发散的（连续解是无发散的）。这里的右手边作为一个修正，导致速度的离散解沿着牛顿的迭代是无发散的。在这个线性系统中，唯一的未知数是更新项 $\delta \textbf{u}^{k}$ 和 $\delta p^{k}$ ，我们可以使用类似于步骤22中的策略（并以同样的方式推导出弱形式）。

现在，可以用牛顿迭代法来解决更新项。

<ol>  <li>  初始化。初始猜测  $u_0$  和  $p_0$  ，公差  $\tau$  ;  </li>   <li>  线性求解计算更新项  $\delta\textbf{u}^{k}$  和  $\delta p^k$  ;  </li>   <li>  更新近似。         $\textbf{u}^{k+1} = \textbf{u}^{k} + \delta\textbf{u}^{k}$  和  $p^{k+1} = p^{k} + \delta p^{k}$  ;  </li>   <li>  检查残差规范。   $E^{k+1} = \|F(\mathbf{u}^{k+1}, p^{k+1})\|$  :  <ul>   <li>  如果  $E^{k+1} \leq \tau$  , 停止。 </li>   <li>  如果  $E^{k+1} > \tau$  ，回到步骤2。 </li>   </ul>   </li>   </ol> 。

<h3> Finding an Initial Guess </h3>

初始猜测需要足够接近解决方案，牛顿方法才能收敛；因此，找到一个好的起始值对非线性求解器来说至关重要。

当粘度 $\nu$ 较大时，通过解决带有粘度 $\nu$ 的斯托克斯方程可以得到一个好的初始猜测。虽然这取决于问题，但对于这里考虑的测试问题，这对 $\nu \geq 1/400$ 有效。

然而，如果粘度较小，对流项 $(\mathbf{u}\cdot\nabla)\mathbf{u}$ 将占主导地位，如测试案例2的 $1/7500$ 。  在这种情况下，我们使用延续法建立一系列的辅助NSE，其粘度接近于目标NSE中的粘度。相应地，我们创建了一个带有 $\{\nu_{i}\}$ 的序列，如果 $\nu_{n}= \nu$ 较小，我们接受两个具有粘度的NSE $\nu_{i}$ 和 $\nu_{i+1}$ 的解是接近的。  然后，我们使用带有粘度的NSE的解 $\nu_{i}$ 作为带有 $\nu_{i+1}$ 的NSE的初始猜测。这可以被认为是一个从斯托克斯方程到我们要解决的NSE的阶梯。

也就是说，我们首先解决一个斯托克斯问题

@f{eqnarray*}


  -\nu_{1} \Delta \textbf{u} + \nabla p &=& \textbf{f}\\


  -\nabla \cdot \textbf{u} &=& 0


@f}



以获得最初的猜测，即

@f{eqnarray*}


  -\nu_{1} \Delta \textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f},\\


  -\nabla \cdot \textbf{u} &=& 0,


@f}



这也是延续法的初始猜测。这里 $\nu_{1}$ 相对较大，这样带粘度的斯托克斯问题的解 $\nu_{1}$ 就可以作为牛顿迭代中NSE的初始猜测。

那么，对

@f{eqnarray*}


  -\nu_{i} \Delta \textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f},\\


  -\nabla \cdot \textbf{u} &=& 0.


@f}



的初始猜测。

@f{eqnarray*}


  -\nu_{i+1} \Delta \textbf{u} + (\textbf{u} \cdot \nabla)\textbf{u} + \nabla p &=& \textbf{f},\\


  -\nabla \cdot \textbf{u} &=& 0.


@f}



这个过程是用实验确定的粘度序列 $\{\nu_i\}$ 来重复的，这样最终的解决方案可以作为牛顿迭代的起始猜测。

<h3>The %Solver and Preconditioner </h3>

在牛顿迭代的每一步，问题的结果是解决一个鞍点系统，其形式为

@f{eqnarray*}
    \begin{pmatrix}
      A & B^{T} \\
      B & 0
    \end{pmatrix}
    \begin{pmatrix}
      U \\
      P
    \end{pmatrix}
    =
    \begin{pmatrix}
      F \\
      0
    \end{pmatrix}.


@f}



这个系统矩阵的块状结构与步骤22中的相同。然而，左上角的矩阵 $A$ 不是对称的，因为有非线性项。我们可以不求解上述系统，而求解等效系统

@f{eqnarray*}
    \begin{pmatrix}
      A + \gamma B^TW^{-1}B & B^{T} \\
      B & 0
    \end{pmatrix}
    \begin{pmatrix}
      U \\
      P
    \end{pmatrix}
    =
    \begin{pmatrix}
      F \\
      0
    \end{pmatrix}


@f}



有一个参数  $\gamma$  和一个可逆矩阵  $W$  。这里 $\gamma B^TW^{-1}B$ 是Augmented Lagrangian项，详见[1]。

用 $G$ 表示新系统的系统矩阵，用 $b$ 表示右手边，我们用右预处理 $P^{-1}$ 反复求解，即 $GP^{-1}y = b$  ，其中

@f{eqnarray*}
P^{-1} =
  \begin{pmatrix}
    \tilde{A} & B^T \\
    0         & \tilde{S}
  \end{pmatrix}^{-1}


@f}



与 $\tilde{A} = A + \gamma B^TW^{-1}B$ ， $\tilde{S}$ 是相应的舒尔补数 $\tilde{S} = B^T \tilde{A}^{-1} B$  。我们让 $W = M_p$ 其中 $M_p$ 是压力质量矩阵，那么 $\tilde{S}^{-1}$ 可以近似为

@f{eqnarray*}
\tilde{S}^{-1} \approx -(\nu+\gamma)M_p^{-1}.


@f}



详见[1]。

我们将 $P^{-1}$ 分解为

@f{eqnarray*}
P^{-1} =
  \begin{pmatrix}
    \tilde{A}^{-1} & 0 \\
    0              & I
  \end{pmatrix}
  \begin{pmatrix}
    I & -B^T \\
    0 & I
  \end{pmatrix}
  \begin{pmatrix}
    I & 0 \\
    0 & \tilde{S}^{-1}
  \end{pmatrix}.


@f}



这里需要两个非精确求解器分别用于 $\tilde{A}^{-1}$ 和 $\tilde{S}^{-1}$ （见[1]）。由于压力质量矩阵是对称的和正定的，用ILU作为预处理程序的CG适合用于 $\tilde{S}^{-1}$ 。为了简单起见，我们对  $\tilde{A}^{-1}$  使用直接求解器UMFPACK。最后一个成分是与  $B^T$  的稀疏矩阵-向量乘积。我们不计算 $\tilde{A}$ 中增强拉格朗日项的矩阵乘积，而是集合Grad-Div稳定化 $(\nabla \cdot \phi _{i}, \nabla \cdot \phi _{j}) \approx (B^T
M_p^{-1}B)_{ij}$ ，如[2]中所解释。

<h3> Test Case </h3>

我们使用盖子驱动的空腔流作为我们的测试案例，详情见[3]。计算域为单位平方，右手边为 $f=0$  。边界条件为

@f{eqnarray*}
  (u(x, y), v(x,y)) &=& (1,0) \qquad\qquad \textrm{if}\ y = 1 \\
  (u(x, y), v(x,y)) &=& (0,0) \qquad\qquad \textrm{otherwise}.


@f}



在解决这个问题时，误差由非线性误差（来自牛顿迭代）和离散化误差（取决于网格大小）组成。非线性部分随着牛顿的每次迭代而减少，离散化误差随着网格的细化而减少。在这个例子中，粗网的解被转移到连续的细网中，并作为初始猜测使用。因此，非线性误差总是低于牛顿迭代的容忍度，离散化误差也随着每次网格细化而减少。

在循环中，我们涉及三个求解器：一个用于 $\tilde{A}^{-1}$ ，一个用于 $M_p^{-1}$ 和一个用于 $Gx=b$  。前两个求解器在预处理程序中被调用，外部求解器给我们提供了更新项。总体收敛性由非线性残差控制；由于牛顿方法不需要精确的雅各布，我们采用FGMRES，外侧线性求解器的相对公差仅为1e-4。事实上，我们对这个系统采用了截断的牛顿解法。如步骤22所述，内部线性求解也不需要做得非常精确。这里我们使用CG，压力质量矩阵的相对公差为1e-6。正如预期的那样，我们仍然看到非线性残差收敛到了1e-14。另外，我们使用一个简单的线搜索算法来实现牛顿方法的全球化。

腔体参考值 $\mathrm{Re}=400$ 和 $\mathrm{Re}=7500$ 分别来自[4]和[5]，其中 $\mathrm{Re}$ 是雷诺数，可以定位在[8]。这里的粘度是由 $1/\mathrm{Re}$ 定义的。尽管我们仍然可以找到 $\mathrm{Re}=10000$ 的解决方案，而且参考文献中也包含了用于比较的结果，但我们在这里的讨论仅限于 $\mathrm{Re}=7500$  。这是因为从 $\mathrm{Re}=8000$ 附近开始，解不再是静止的，而是变成了周期性的，详见[7]。

<h3> References </h3> <醇>

    <li>  An Augmented Lagrangian-Based Approach to the Oseen Problem, M. Benzi and M. Olshanskii, SIAM J. SCI. COMPUT.COMPUT.2006  <li>  Efficient augmented Lagrangian-type preconditioning for the Oseen problem using Grad-Div stabilization, Timo Heister and Gerd Rapin  <li>  http://www.cfd-online.com/Wiki/Lid-driven_cavity_problem  <li>  High-Re solution for incompressible flow using the Navier-Stokes equations and a Multigrid Method, U. Ghia, K. N. Ghia, and C. T. Shin  <li>  E. Erturk, T.C. Corke and C. Gokcol  <li>  三维不可压缩Navier-Stokes方程的隐式加权ENO方案，Yang等人，1998  <li>  二维盖子驱动的空腔问题再探讨，C. Bruneau和M. Saad，2006  <li>  https://en.wikipedia.org/wiki/Reynolds_number  </ol> 


examples/step-57/doc/results.dox



<h1>Results</h1>

现在我们用上面讨论的方法来解决有粘度的纳维尔-斯托克斯方程  $1/400$  和  $1/7500$  。

<h3> Test case 1: Low Reynolds Number </h3>

在第一个测试案例中，粘度被设定为 $1/400$  。正如我们在介绍中所讨论的，初始猜测是相应斯托克斯问题的解。在下面的表格中，显示了每个网格上的牛顿迭代的残差。表中的数据表明，牛顿迭代的收敛性是四等的。

 <table align="center" class="doxtable">
<tr>
    <th>$\mathrm{Re}=400$</th>
    <th colspan="2">Mesh0</th>
    <th colspan="2">Mesh1</th>
    <th colspan="2">Mesh2</th>
    <th colspan="2">Mesh3</th>
    <th colspan="2">Mesh4</th>
</tr>
<tr>
    <th>Newton iter   </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
</tr>
<tr>
  <td>1</td>
  <td>3.7112e-03</td>
  <td>5</td>
  <td>6.4189e-03</td>
  <td>3</td>
  <td>2.4338e-03</td>
  <td>3</td>
  <td>1.0570e-03</td>
  <td>3</td>
  <td>4.9499e-04</td>
  <td>3</td>
</tr>
<tr>
  <td>2</td>
  <td>7.0849e-04</td>
  <td>5</td>
  <td>9.9458e-04</td>
  <td>5</td>
  <td>1.1409e-04</td>
  <td>6</td>
  <td>1.3544e-05</td>
  <td>6</td>
  <td>1.4171e-06</td>
  <td>6</td>
</tr>
<tr>
  <td>3</td>
  <td>1.9980e-05</td>
  <td>5</td>
  <td>4.5007e-05</td>
  <td>5</td>
  <td>2.9020e-08</td>
  <td>5</td>
  <td>4.4021e-10</td>
  <td>6</td>
  <td>6.3435e-11</td>
  <td>6</td>
</tr>
<tr>
  <td>4</td>
  <td>2.3165e-09</td>
  <td>6</td>
  <td>1.6891e-07</td>
  <td>5</td>
  <td>1.2338e-14</td>
  <td>7</td>
  <td>1.8506e-14</td>
  <td>8</td>
  <td>8.8563e-15</td>
  <td>8</td>
</tr>
<tr>
  <td>5</td>
  <td>1.2585e-13</td>
  <td>7</td>
  <td>1.4520e-11</td>
  <td>6</td>
  <td>1.9044e-13</td>
  <td>8</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>6</td>
  <td></td>
  <td></td>
  <td>1.3998e-15</td>
  <td>8</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
</table> 








下面的数字显示了生成网格的顺序。对于 $\mathrm{Re}=400$ 的情况，初始猜测是通过在 $8 \times 8$ 网格上求解斯托克斯得到的，并且网格是自适应细化的。在不同的网格之间，粗网格的解被内插到细网格中，作为初始猜测使用。

 <table align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh0.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh1.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh2.png" width="232px" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh3.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Mesh4.png" width="232px" alt="">
    </td>
  </tr>
</table> 

这张图片是用  $\mathrm{Re}=400$  的盖子驱动的空腔的图形流线结果。   <img src="https://www.dealii.org/images/steps/developer/step-57.Re400_Streamline.png" alt=""> 

然后将该方案与来自[4]的参考方案进行比较，参考方案的数据可以在文件 "ref_2d_ghia_u.txt "中找到。

 <img src="https://www.dealii.org/images/steps/developer/step-57.compare-Re400.svg" style="width:50%" alt=""> 

<h3> Test case 2: High Reynolds Number </h3>

牛顿迭代法需要一个良好的初始猜测。然而，当雷诺数很大时，非线性项占主导地位，因此，斯托克斯方程的解可能与精确解相去甚远。如果斯托克斯方程的解作为初始猜测，收敛性就会丧失。下图显示，非线性迭代被卡住了，在进一步的迭代中，残差不再减少。

 <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_loss_convergence.svg" style="width:50%" alt=""> 

因此，初始猜测必须通过延续法获得，这在导言中已经讨论过了。这里延续法的步长是 $|\nu_{i}-\nu_{i+1}|$ ，是2000，初始网格的大小是 $32 \times 32$ 。在得到一个初始猜测后，如前一个测试案例一样，对网格进行细化。下图显示，在每次细化时，牛顿迭代都有二次收敛性。为解决这个测试案例，共执行了52步牛顿迭代。

 <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_get_convergence.svg" style="width:50%" alt=""> 

我们还显示了每个网格上牛顿迭代的每一步的残差。表格中可以清楚地看到二次收敛的情况。

 <table align="center" class="doxtable">
  <tr>
    <th>$\mathrm{Re}=7500$</th>
    <th colspan="2">Mesh0</th>
    <th colspan="2">Mesh1</th>
    <th colspan="2">Mesh2</th>
    <th colspan="2">Mesh3</th>
    <th colspan="2">Mesh4</th>
  </tr>
  <tr>
    <th>Newton iter   </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
    <th>Residual      </th>
    <th>FGMRES        </th>
  </tr>
<tr>
  <td>1</td>
  <td>1.8922e-06</td>
  <td>6</td>
  <td>4.2506e-03</td>
  <td>3</td>
  <td>1.4299e-03</td>
  <td>3</td>
  <td>4.8793e-04</td>
  <td>2</td>
  <td>1.8998e-04</td>
  <td>2</td>
</tr>
<tr>
  <td>2</td>
  <td>3.1644e-09</td>
  <td>8</td>
  <td>1.3732e-03</td>
  <td>7</td>
  <td>4.1506e-04</td>
  <td>7</td>
  <td>9.1119e-05</td>
  <td>8</td>
  <td>1.3555e-05</td>
  <td>8</td>
</tr>
<tr>
  <td>3</td>
  <td>1.7611e-14</td>
  <td>9</td>
  <td>2.1946e-04</td>
  <td>6</td>
  <td>1.7881e-05</td>
  <td>6</td>
  <td>5.2678e-07</td>
  <td>7</td>
  <td>9.3739e-09</td>
  <td>7</td>
</tr>
<tr>
  <td>4</td>
  <td></td>
  <td></td>
  <td>8.8269e-06</td>
  <td>6</td>
  <td>6.8210e-09</td>
  <td>7</td>
  <td>2.2770e-11</td>
  <td>8</td>
  <td>1.2588e-13</td>
  <td>9</td>
</tr>
<tr>
  <td>5</td>
  <td></td>
  <td></td>
  <td>1.2974e-07</td>
  <td>7</td>
  <td>1.2515e-13</td>
  <td>9</td>
  <td>1.7801e-14</td>
  <td>1</td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>6</td>
  <td></td>
  <td></td>
  <td>4.4352e-11</td>
  <td>7</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>7</td>
  <td></td>
  <td></td>
  <td>6.2863e-15</td>
  <td>9</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
</table> 








生成的网格序列看起来像这样。   <table align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh0.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh1.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh2.png" width="232px" alt="">
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh3.png" width="232px" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Mesh4.png" width="232px" alt="">
    </td>
  </tr>
</table>  我们将我们的解决方案与[5]的参考解决方案进行比较。   <img src="https://www.dealii.org/images/steps/developer/step-57.compare-Re7500.svg" style="width:50%" alt="">  下图是图形结果。   <img src="https://www.dealii.org/images/steps/developer/step-57.Re7500_Streamline.png" alt=""> 

此外，误差由非线性误差和离散化误差组成，前者随着我们进行牛顿迭代而减少，后者则取决于网格大小。这就是为什么我们必须细化网格并在下一个更细的网格上重复牛顿迭代。从上表中，我们可以看到每个网格上的残差（非线性误差）都低于1e-12，但下图向我们展示了随后更细的网格上的解决方案之间的差异。

 <img src="https://www.dealii.org/images/steps/developer/step-57.converge-Re7500.svg" style="width:50%" alt=""> 

<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Compare to other solvers</h4>

比较目前实现的线性求解器和仅仅使用UMFPACK求解整个线性系统是很容易的。你需要去除包含常压的空域，这在第56步中完成。更有趣的是与其他先进的预处理程序如PCD的比较。事实证明，这里的预处理器是非常有竞争力的，在论文[2]中可以看到。

下表显示了我们的迭代方法（FGMRES）与直接求解器（UMFPACK）之间在粘度设置为1/400的情况下对整个系统的计时结果。尽管我们在迭代求解器中的速度块使用了相同的直接求解器，但它的速度要快得多，消耗的内存也少。这在三维中会更加明显。

 <table align="center" class="doxtable">
<tr>
  <th>Refinement Cycle</th>
  <th>DoFs</th>
  <th>Iterative: Total/s (Setup/s)</th>
  <th>Direct: Total/s (Setup/s)</th>
</tr>
<tr>
  <td>5</td>
  <td>9539</td>
  <td>0.10 (0.06)</td>
  <td>0.13 (0.12)</td>
</tr>
<tr>
  <td>6</td>
  <td>37507</td>
  <td>0.58 (0.37)</td>
  <td>1.03 (0.97)</td>
</tr>
<tr>
  <td>7</td>
  <td>148739</td>
  <td>3.59 (2.73)</td>
  <td>7.78 (7.53)</td>
</tr>
<tr>
  <td>8</td>
  <td>592387</td>
  <td>29.17 (24.94)</td>
  <td>(>4GB RAM)</td>
</tr>
</table> 




<h4>3d computations</h4>

该代码被设置为也可以在3D中运行。当然，参考值是不同的，例如，见[6]。在这个例子中，高分辨率的计算是无法做到的，因为速度块的直接求解器在三维中不能很好地工作。相反，需要一个基于代数或几何多网格的并行求解器。见下文。

<h4>Parallelization</h4>

对于较大的计算，特别是三维计算，有必要实现MPI并行求解器和预处理器。一个好的起点是step-55，它对斯托克斯方程的速度块使用代数多重网格。另一个选择是看一下<a href="https://www.dealii.org/code-gallery.html">deal.II code
gallery</a>中的代码列表，其中已经包含了并行的纳维-斯托克斯求解器。


examples/step-58/doc/intro.dox

 <br> 

<i>This program was contributed by Wolfgang Bangerth (Colorado State
University) and Yong-Yong Cai (<a href="http://www.csrc.ac.cn/en/">Beijing
Computational Science Research Center</a><a href="http://www.csrc.ac.cn/en/">Beijing
Computational Science Research Center</a>, CSRC) and is the result of the
first author's time as a visitor at CSRC.


This material is based upon work partially supported by National Science
Foundation grants OCI-1148116, OAC-1835673, DMS-1821210, and EAR-1925595;
and by the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation under
Award No. EAR-1550901 and The University of California-Davis.
</i> 。

<a name="Intro"></a>

<h1>Introduction</h1>

一个函数 $\psi=\psi(\mathbf
x,t)$ 和一个势 $V=V(\mathbf x)$ 的<a
href="https://en.wikipedia.org/wiki/Nonlinear_Schr%C3%B6dinger_equation">Nonlinear
Schr&ouml;dinger Equation (NLSE)</a>是量子力学和非线性光学中经常使用的一个模型。如果用适当的量来测量（以便 $\hbar=1$ ），那么它的内容如下。

@f{align*}{


  - i \frac{\partial \psi}{\partial t}


  - \frac 12 \Delta \psi
  + V \psi
  + \kappa |\psi|^2 \psi
  &= 0
  \qquad\qquad
  &
  \text{in}\; \Omega\times (0,T),
  \\
  \psi(\mathbf x,0) &= \psi_0(\mathbf x)
  &
  \text{in}\; \Omega,
  \\
  \psi(\mathbf x,t) &= 0
  &
  \text{on}\; \partial\Omega\times (0,T).


@f}

如果没有电位，即 $V(\mathbf x)=0$ ，那么它可以用来描述光在光纤中的传播。如果 $V(\mathbf
x)\neq 0$ ，该方程有时也被称为<a
href="https://en.wikipedia.org/wiki/Gross%E2%80%93Pitaevskii_equation">Gross-Pitaevskii
equation</a>，可用于模拟<a
href="https://en.wikipedia.org/wiki/Bose%E2%80%93Einstein_condensate">Bose-Einstein
condensates</a>的时间依赖行为。

对于这个特定的辅导项目，我们对该方程的物理解释并不太关心。相反，我们想把它作为一个模型，让我们解释两个方面。

- 这是一个<b>complex-valued equation</b>的 $\psi \in H^1(\Omega,{\mathbb
  C})$  。我们以前在step-29中看到过复值方程，但那里选择了将方程分成实数和虚数部分，结果是解决了两个实值方程的系统。相比之下，这里的目标是展示如何解决我们保持一切为复数的问题。

- 这个方程是一个很好的模型问题，可以解释<b>operator
  splitting methods</b>如何工作。这是因为它有一些具有根本不同性质的项：一方面， $- \frac 12
  \Delta \psi$ 是一个常规的空间算子，其方式我们以前已经见过多次；另一方面， $\kappa |\psi(\mathbf x,t)|^2
  \psi$ 没有空间或时间导数，也就是说，它是一个纯粹的局部算子。事实证明，我们对这些项中的每一项都有有效的方法（特别是，我们对后者有分析解），而且我们可能最好对这些项进行不同的、单独的处理。我们将在下文中更详细地解释这一点。




<h3>A note about the character of the equations</h3>

乍一看，这些方程似乎是抛物线，与热力方程相似（见步骤26），因为只有一个时间导数和两个空间导数。但这是一种误导。事实上，如果我们暂时假设势 $V=0$ 和 $\kappa=0$ ，这不是正确的解释，更容易看出。那么我们就有这样的方程

@f{align*}{


  - i \frac{\partial \psi}{\partial t}


  - \frac 12 \Delta \psi
  &= 0.


@f}

如果我们把解分成实部和虚部， $\psi=v+iw$  ，与 $v=\textrm{Re}\;\psi,\; w=\textrm{Im}\;\psi$  ，那么我们就可以按照步骤29中的方法，把一个方程分成实部和虚部。

@f{align*}{
  \frac{\partial w}{\partial t}


  - \frac 12 \Delta v
  &= 0,
  \\


  -\frac{\partial v}{\partial t}


  - \frac 12 \Delta w
  &= 0.


@f}

毫不奇怪，时间导数前面的因子 $i$ 耦合了方程的实部和虚部。如果我们想进一步理解这个方程，可以取其中一个方程的时间导数，例如

@f{align*}{
  \frac{\partial^2 w}{\partial t^2}


  - \frac 12 \Delta \frac{\partial v}{\partial t}
  &= 0,


@f}

在这里我们假设，至少在某种正式意义上，我们可以将空间和时间导数进行换算），然后将另一个方程插入其中。

@f{align*}{
  \frac{\partial^2 w}{\partial t^2}
  + \frac 14 \Delta^2 w
  &= 0.


@f}

这个方程是双曲线的，与波浪方程的性质相似。如果你看一下本程序的 "结果 "部分的视频，这一点也会很明显）。此外，我们也可以得出 $v$ 的相同方程。因此，对于NLSE来说，一个更好的假设是把它看成是一个双曲的波传播方程，而不是像热方程那样的扩散方程。你可能会问，算子 $\Delta^2$ 以正号出现，而在波浪方程中， $\Delta$ 有一个负号，这是否正确？这确实是正确的。在与测试函数相乘并通过部分积分后，我们希望得到一个正（半）定式。因此，从 $-\Delta u$ 我们得到 $+(\nabla v,\nabla u)$  。同样，经过两次积分，我们从 $+\Delta^2 u$ 得到 $+(\Delta v,\Delta u)$ 的形式。在这两种情况下，我们都能得到所需的正号）。)

当然，真正的NLSE也有 $V\psi$ 和 $\kappa|\psi|^2\psi$ 等项。然而，这些是空间导数中的低阶项，虽然它们显然很重要，但它们并不改变方程的特征。

在任何情况下，本讨论的目的是要弄清楚什么时间步长方案可能适合于该方程。结论是，作为一个双曲类型的方程，我们需要选择一个满足CFL类型条件的时间步长。如果我们使用显式方法（我们不会这样做），我们将不得不研究与空间算子相对应的矩阵的特征值。如果你跟随视频讲座的讨论(  @dealiiVideoLectureSeeAlso{26,27,28}) ，那么你会记得，模式是需要确保 $k^s \propto h^t$ ，其中 $k$ 是时间步长， $h$ 是网格宽度， $s,t$ 是时间和空间导数的顺序。无论你采取原始方程(  $s=1,t=2$ )还是只对实部或虚部进行重构，其结果是，如果我们要使用显式时间步进方法，我们需要选择 $k \propto h^2$ 。这是不可行的，原因与热方程的步骤26相同。它将产生不切实际的小的时间步长，甚至只对适度精细的网格。相反，我们必须使用隐式时间步进方法，然后可以选择一个更平衡的  $k \propto h$  。事实上，我们将使用隐式的Crank-Nicolson方法，正如我们之前在步骤23中对常规波方程所做的那样。




<h3>The general idea of operator splitting</h3>

 @dealiiVideoLecture{30.25} 

如果我们把NLSE看作是一个普通微分方程，其中的右手边恰好有空间导数，即把它写成

@f{align*}{
  \frac{d\psi}{dt}
  &=
  i\frac 12 \Delta \psi


  -i V \psi


  -i\kappa |\psi|^2 \psi,
  \qquad\qquad
  &
  \text{for}\; t \in (0,T),
  \\
  \psi(0) &= \psi_0,


@f}

人们可能会想通过在时间间隔 $[t_{n},t_{n+1}]$ 上对两边进行积分来 "正式求解"，并得到

@f{align*}{
  \psi(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(
  i\frac 12 \Delta \psi(t)


  -i V \psi(t)


  -i\kappa |\psi(t)|^2 \psi(t)
  \right)
  \;
  dt.


@f}

当然，这不是那么简单的：积分中的 $\psi(t)$ 仍在按照微分方程随时间变化，所以我们不能直接评估积分（或通过正交轻松近似它），因为我们不知道 $\psi(t)$  。但是我们可以把这个写成如下的独立贡献，这将使我们能够分别处理不同的项。

@f{align*}{
  \psi(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(
  i\frac 12 \Delta \psi(t)
  \right)
  \;
  dt
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i V \psi(t)
  \right)
  \;
  dt
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i\kappa |\psi(t)|^2 \,\psi(t)
  \right)
  \;
  dt.


@f}

现在可以将这个方程解读如下。对于每个时间间隔 $[t_{n},t_{n+1}]$ ，溶液中的变化 $\psi(t_{n+1})-\psi(t_{n})$ 由三个贡献组成。

- 拉普拉斯算子的贡献。

- 势的贡献  $V$  。

- 相 "项的贡献  $-i\kappa |\psi(t)|^2\,\psi(t)$  。

<i>Operator splitting</i>现在是一种近似技术，允许我们分别处理这些贡献中的每一个。(如果我们想的话。在实践中，我们将把前两个放在一起处理，而最后一个则分开处理。但这是一个细节，从概念上讲，我们可以以不同的方式处理所有这些贡献）。)为此，让我们介绍三个独立的 "解决方案"。

@f{align*}{
  \psi^{(1)}(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(
  i\frac 12 \Delta \psi^{(1)}(t)
  \right)
  \;
  dt,
\\
  \psi^{(2)}(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i V \psi^{(2)}(t)
  \right)
  \;
  dt,
\\
  \psi^{(3)}(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i\kappa |\psi^{(3)}(t)|^2 \,\psi^{(3)}(t)
  \right)
  \;
  dt.


@f}



这三个 "解决方案 "可以被认为是满足以下微分方程。

@f{align*}{
  \frac{d\psi^{(1)}}{dt}
  &=
  i\frac 12 \Delta \psi^{(1)},
  \qquad
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(1)}(t_n) &= \psi(t_n),
\\
  \frac{d\psi^{(2)}}{dt}
  &=


  -i V \psi^{(2)},
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(2)}(t_n) &= \psi(t_n),
\\
  \frac{d\psi^{(3)}}{dt}
  &=


  -i\kappa |\psi^{(3)}|^2 \,\psi^{(3)},
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(3)}(t_n) &= \psi(t_n).


@f}

换句话说，它们都是以 $\psi(t_n)$ 为起点的轨迹 $\psi^{(k)}$ ，并且正好整合了三个条款中的一个条款的影响。在我们的时间区间内，这些条款中的每一项产生的增量是 $I^{(1)}=\psi^{(1)}(t_{n+1})-\psi(t_n)$ 、 $I^{(2)}=\psi^{(2)}(t_{n+1})-\psi(t_n)$ 和 $I^{(3)}=\psi^{(3)}(t_{n+1})-\psi(t_n)$ 。

现在可以合理地假设（这是一个近似值！），由于所有三个有关的影响而产生的变化很好地近似于三个单独的增量的总和。

@f{align*}{
 \psi(t_{n+1})-\psi(t_n)
 \approx
 I^{(1)} + I^{(2)} + I^{(3)}.


@f}

这种直觉确实是正确的，尽管近似并不精确：精确的左手边和项 $I^{(1)}+I^{(2)}+I^{(3)}$ 之间的差异（即从 $t_n$ 到 $t_{n+1}$ 时，精确解 $\psi(t)$ 的<i>exact</i>增量与右手边三部分组成的增量之间的差异），正比于 $\Delta t=t_{n+1}-t_{n}$  。换句话说，这种方法引入了一个大小为  ${\cal O}(\Delta t)$  的误差。到目前为止，我们所做的一切都没有在时间或空间上离散化，所以<i>overall</i>的误差将是 ${\cal O}(\Delta t)$ 加上我们在近似积分时的任何误差（时间离散化误差）加上我们在近似 $\psi$ 的空间依赖时的任何误差（空间误差）。

在我们继续讨论运算符拆分之前，让我们谈谈为什么要走这条路？答案很简单。对于 $\psi^{(k)}$ 的一些独立方程，我们可能有办法比把所有东西放在一起并试图一次解决它们更有效。例如，在目前的情况下，特别相关的是。 $\psi^{(3)}$ 的方程，即。

@f{align*}{
  \frac{d\psi^{(3)}}{dt}
  &=


  -i\kappa |\psi^{(3)}|^2 \,\psi^{(3)},
  \qquad\qquad
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(3)}(t_n) &= \psi(t_n),


@f}

或等价的。

@f{align*}{
  \psi^{(3)}(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i\kappa |\psi^{(3)}(t)|^2 \,\psi^{(3)}(t)
  \right)
  \;
  dt,


@f}

可以精确求解：方程的解法是

@f{align*}{
  \psi^{(3)}(t) = e^{-i\kappa|\psi(t_n)|^2 (t-t_{n})} \psi(t_n).


@f}

这很容易看出，如果（i）你把这个解插入微分方程，（ii）意识到幅度 $|\psi^{(3)}|$ 是常数，即指数中的项 $|\psi(t_n)|^2$ 实际上等于 $|\psi^{(3)}(t)|^2$  。换句话说， $\psi^{(3)}(t)$ 的ODE的解只是改变了它的<i>phase</i>，但复值函数 $\psi^{(3)}(t)$ 的<i>magnitude</i>保持不变。这使得计算 $I^{(3)}$ 特别方便：我们实际上不需要解决任何ODE，我们可以用手写下解。使用算子拆分方法，计算 $I^{(1)},I^{(2)}$ 的方法都不必处理非线性项和所有相关的不愉快：只要我们允许自己使用算子拆分方法，就可以摆脱只解决<i>linear</i>问题。

其次，如果不同项所描述的不同物理效应具有不同的时间尺度，人们通常会使用算子拆分。例如，想象一下，我们确实有某种扩散方程的情况。扩散作用缓慢，但如果 $\kappa$ 很大，那么 $-i\kappa
|\psi^{(3)}(t)|^2 \,\psi^{(3)}(t)$ 项的 "相位旋转 "就会迅速发挥作用。如果我们把所有的东西放在一起处理，这将意味着必须采取相当小的时间步长。但是有了算子分割，我们可以对扩散采取大的时间步数 $\Delta t=t_{n+1}-t_{n}$ ，并且（假设我们没有分析解）使用具有许多小时间步数的ODE求解器来整合 $\psi^{(3)}$ 从 $t_n$ 到 $t_{n+1}$ 的 "相变 "方程。换句话说，算子分裂允许我们将慢速和快速的时间尺度解耦，并对它们进行不同的处理，方法根据每种情况进行调整。




<h3>Operator splitting: the "Lie splitting" approach</h3>

虽然上述方法允许并行计算三个贡献 $I^{(k)}$ ，但如果我们愿意，如果我们不让 $\psi^{(k)}$ 的轨迹全部从 $\psi(t_n)$ 开始，而是让 $\psi^{(2)}$ 的轨迹从 $\psi^{(1)}$ 的<i>end point</i>开始，可以使该方法稍微准确和容易实现。]，而是让 $\psi^{(2)}$ 的轨迹从 $\psi^{(1)}$ 的轨迹的<i>end point</i>开始，即 $\psi^{(1)}(t_{n+1})$ ；同样，我们将从 $\psi^{(3)}$ 的轨迹的终点开始，即 $\psi^{(2)}(t_{n+1})$ 。这种方法就被称为 "Lie splitting"，其误差顺序与上面的方法相同，即分割误差为 ${\cal O}(\Delta
t)$  。

运算符拆分的这种变化可以写成如下形式（仔细比较上面的初始条件）。

@f{align*}{
  \frac{d\psi^{(1)}}{dt}
  &=
  i\frac 12 \Delta \psi^{(1)},
  \qquad
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(1)}(t_n) &= \psi(t_n),
\\
  \frac{d\psi^{(2)}}{dt}
  &=


  -i V \psi^{(2)},
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(2)}(t_n) &= \psi^{(1)}(t_{n+1}),
\\
  \frac{d\psi^{(3)}}{dt}
  &=


  -i\kappa |\psi^{(3)}|^2 \,\psi^{(3)},
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(3)}(t_n) &= \psi^{(2)}(t_{n+1}).


@f}

显然，虽然上面的公式意味着我们应该以这种特定的顺序来解决这些问题，但首先解决轨迹3，然后是2，然后是1，或任何其他的排列组合也同样有效）。

那么这些方程的综合形式是

@f{align*}{
  \psi^{(1)}(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(
  i\frac 12 \Delta \psi^{(1)}(t)
  \right)
  \;
  dt,
\\
  \psi^{(2)}(t_{n+1})
  &=
  \psi^{(1)}(t_{n+1})
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i V \psi^{(2)}(t)
  \right)
  \;
  dt,
\\
  \psi^{(3)}(t_{n+1})
  &=
  \psi^{(2)}(t_{n+1})
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i\kappa |\psi^{(3)}(t)|^2 \,\psi^{(3)}(t)
  \right)
  \;
  dt.


@f}

从实际的角度来看，这样做的好处是我们需要保持较少的解向量。一旦 $\psi^{(1)}(t_n)$ 被计算出来，我们就不再需要 $\psi(t_n)$ 了；一旦 $\psi^{(2)}(t_n)$ 被计算出来，我们就不再需要 $\psi^{(1)}(t_n)$ 了。而一旦 $\psi^{(3)}(t_n)$ 被计算出来，我们就可以直接称之为 $\psi(t_{n+1})$ ，因为如果你把第一个方程插入第二个方程，然后再插入第三个方程，你会看到 $\psi^{(3)}(t_n)$ 的右边现在包含所有三个物理效应的贡献。

@f{align*}{
  \psi^{(3)}(t_{n+1})
  &=
  \psi(t_n)
  +
  \int_{t_n}^{t_{n+1}}
  \left(
  i\frac 12 \Delta \psi^{(1)}(t)
  \right)
  \;
  dt
  +
  \int_{t_n}^{t_{n+1}}
  \left(


  -i V \psi^{(2)}(t)
  \right)
  \;
  dt+
  \int_{t_n}^{t_{n+1}}
  \left(


  -i\kappa |\psi^{(3)}(t)|^2 \,\psi^{(3)}(t)
  \right)
  \;
  dt.


@f}

(再与 $\psi(t_{n+1})$ 的 "精确 "计算进行比较：它只在我们如何在三个积分中的每一个中近似 $\psi(t)$ 方面有所不同)。换句话说，Lie拆分的实现比上述原始方法要简单得多，因为数据处理要简单得多。




<h3>Operator splitting: the "Strang splitting" approach</h3>

如上所述，Lie拆分只有 ${\cal O}(\Delta t)$ 的准确性。如果我们使用一阶时间离散化，例如使用显式或隐式欧拉方法来解决 $\psi^{(k)}$ 的微分方程，这是可接受的。这是因为这些时间积分方法引入了与 $\Delta t$ 本身成正比的误差，因此分裂误差与我们无论如何都会引入的误差成正比，并不会削弱整体收敛顺序。

但我们通常希望使用高阶的方法--比如，<a href="https://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method">Crank-Nicolson</a>或<a href="https://en.wikipedia.org/wiki/Backward_differentiation_formula">BDF2</a>方法--因为这些方法通常不会比简单的欧拉方法更昂贵。如果我们使用 ${\cal O}(\Delta t^2)$ 的时间步长方法，但由于算子分裂又失去了精度，那就太可惜了。

这就是<a
href="https://en.wikipedia.org/wiki/Strang_splitting">Strang
splitting</a>方法的用处。如果我们只有两部分，就更容易解释了，所以让我们把拉普拉斯算子和势的影响合二为一，把相位旋转合为第二个影响。事实上，这就是我们在代码中要做的事情，因为用拉普拉斯方程求解，不管有没有电势，代价都是一样的--所以我们把这两步合并起来）。上面的Lie拆分方法将做以下工作。它计算出以下两个ODE的解。

@f{align*}{
  \frac{d\psi^{(1)}}{dt}
  &=
  i\frac 12 \Delta \psi^{(1)} -i V \psi^{(1)},
  \qquad
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(1)}(t_n) &= \psi(t_n),
\\
  \frac{d\psi^{(2)}}{dt}
  &=


  -i\kappa |\psi^{(2)}|^2 \,\psi^{(2)},
  &
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad\text{with initial condition}\;
  \psi^{(2)}(t_n) &= \psi^{(1)}(t_{n+1}),


@f}

然后使用近似值  $\psi(t_{n+1}) \approx
\psi^{(2)}(t_{n+1})$  。换句话说，我们首先为物理效应一做一个完整的时间步骤，然后为物理效应二做一个完整的时间步骤。时间步数结束时的解只是分别由这些物理效应引起的增量的总和。

相比之下，<a href="https://en.wikipedia.org/wiki/Gilbert_Strang">Gil Strang</a>（20世纪中期开始的数值分析领域的泰斗之一）发现，先对一个物理效应做一个半步，然后对另一个物理效应做一个完整的时间步骤，再对第一个物理效应做一个半步，这样更准确。哪个是哪个并不重要，但由于做相位旋转非常简单，我们将用这个效应做半步，然后只需要用拉普拉斯算子加势做一次空间解。这种算子拆分方法现在是 ${\cal O}(\Delta
t^2)$ 准确的。写在公式里，这就产生了以下的步骤序列。

@f{align*}{
  \frac{d\psi^{(1)}}{dt}
  &=


  -i\kappa |\psi^{(1)}|^2 \,\psi^{(1)},
  &&
  \text{for}\; t \in (t_n,t_n+\tfrac 12\Delta t),
  \qquad\qquad&\text{with initial condition}\;
  \psi^{(1)}(t_n) &= \psi(t_n),
\\
  \frac{d\psi^{(2)}}{dt}
  &=
  i\frac 12 \Delta \psi^{(2)} -i V \psi^{(2)},
  \qquad
  &&
  \text{for}\; t \in (t_n,t_{n+1}),
  \qquad\qquad&\text{with initial condition}\;
  \psi^{(2)}(t_n) &= \psi^{(1)}(t_n+\tfrac 12\Delta t),
\\
  \frac{d\psi^{(3)}}{dt}
  &=


  -i\kappa |\psi^{(3)}|^2 \,\psi^{(3)},
  &&
  \text{for}\; t \in (t_n+\tfrac 12\Delta t,t_{n+1}),
  \qquad\qquad&\text{with initial condition}\;
  \psi^{(3)}(t_n) &= \psi^{(2)}(t_{n+1}).


@f}

如前所述，对于这个特殊的方程，第一和第三步可以精确计算，得出的结果是

@f{align*}{
  \psi^{(1)}(t_n+\tfrac 12\Delta t) &= e^{-i\kappa|\psi(t_n)|^2 \tfrac
  12\Delta t} \; \psi(t_n),
  \\
  \psi^{(3)}(t_{n+1}) &= e^{-i\kappa|\psi^{(2)}(t_{n+1})|^2 \tfrac
  12\Delta t} \; \psi^{(2)}(t_{n+1}).


@f}



那么这就是我们在这个程序中要实现的事情。在每个时间步骤中，我们执行三个步骤，即

- 通过分析整合相位旋转方程的半个时间步长，更新每个节点的解值。

- 解决与 $\psi^{(2)}$ 的全步骤相对应的时空方程，即 $-i\frac{\partial\psi^{(2)}}{\partial t}


  -
  \frac 12 \Delta \psi^{(2)} + V \psi^{(2)} = 0$ ，初始条件等于上述第一个半步骤的解决方案。

- 通过对相位旋转方程再进行半个时间步长的分析积分，更新每个节点的解值。

这种结构将以明显的方式反映在程序的主时间循环中。




<h3>Time discretization</h3>

从上面的讨论中可以看出，我们在每个时间步骤中要解决的唯一偏微分方程是

@f{align*}{


  -i\frac{\partial\psi^{(2)}}{\partial t}


  -
  \frac 12 \Delta \psi^{(2)} + V \psi^{(2)} = 0.


@f}

这个方程是线性的。此外，我们只需要解决从 $t_n$ 到 $t_{n+1}$ 的问题，也就是说，正好是一个时间步骤。

为了做到这一点，我们将应用二阶精确的Crank-Nicolson方案，我们已经在其他一些时间相关的代码中使用过该方案（具体为：步骤23和步骤26）。它的内容如下。

@f{align*}{


  -i\frac{\psi^{(n,2)}-\psi^{(n,1)}}{k_{n+1}}


  -
  \frac 12 \Delta \left[\frac 12
  \left(\psi^{(n,2)}+\psi^{(n,1)}\right)\right]
  +
  V \left[\frac 12 \left(\psi^{(n,2)}+\psi^{(n,1)}\right)\right] = 0.


@f}

这里，"先前 "的解决方案 $\psi^{(n,1)}$ （或这部分时间步长的 "初始条件"）是第一个阶段旋转半步的输出；当前步骤的输出将用 $\psi^{(n,2)}$ 表示。   $k_{n+1}=t_{n+1}-t_n$ 是时间步骤的长度。人们可以争论 $\psi^{(n,1)}$ 和 $\psi^{(n,1)}$ 是生活在时间步长 $n$ 还是 $n+1$ ，以及它们的上指数应该是什么。这是一个没有实际影响的哲学讨论，人们可以把 $\psi^{(n,1)}$ 看作是 $\psi^{(n+\tfrac 13)}$ ，而把 $\psi^{(n,2)}$ 看作是 $\psi^{(n+\tfrac 23)}$ ，如果这有助于澄清问题的话--不过， $n+\frac 13$ 也不能理解为" $t_n$ 之后的三分之一时间步骤"，而更像是 "我们已经完成了时间步骤 $n+1$ 所需工作的三分之一。")

如果我们将整个方程与 $k_{n+1}$ 相乘，并将未知的 $\psi^{(n+1,2)}$ 项排序到左边，将已知的 $\psi^{(n,2)}$ 项排序到右边，那么我们得到以下（空间）偏微分方程，需要在每个时间步骤中解决。

@f{align*}{


  -i\psi^{(n,2)}


  -
  \frac 14 k_{n+1} \Delta \psi^{(n,2)}
  +
  \frac 12 k_{n+1} V \psi^{(n,2)}
  =


  -i\psi^{(n,1)}
  +
  \frac 14 k_{n+1} \Delta \psi^{(n,1)}


  -
  \frac 12 k_{n+1} V \psi^{(n,1)}.


@f}






<h3>Spatial discretization and dealing with complex variables</h3>

如上所述，之前处理复值解的教程程序（即step-29）将解的实部和虚部分开。因此，它将一切都简化为实数运算。相比之下，我们在这里希望保持复值的东西。

第一部分是我们需要将离散的解决方案定义为 $\psi_h^n(\mathbf x)=\sum_j \Psi^n_j \varphi_j(\mathbf
x) \approx \psi(\mathbf x,t_n)$ ，其中 $\varphi_j$ 是通常的形状函数（是实值的），但在时间步长 $n$ 的扩展系数 $\Psi^n_j$ 现在是复值的。这在deal.II中很容易做到：我们只需要用 Vector<std::complex<double>> 而不是Vector<double>来存储这些系数。

更感兴趣的是如何建立和解决线性系统。很明显，这只对上面讨论的斯特朗分割的第二步有必要，即上一小节的时间离散化。我们通过将 $\psi^n$ 直接替换为 $\psi^n_h$ 并乘以一个测试函数，得到完全离散的版本。

@f{align*}{


  -iM\Psi^{(n,2)}
  +
  \frac 14 k_{n+1} A \Psi^{(n,2)}
  +
  \frac 12 k_{n+1} W \Psi^{(n,2)}
  =


  -iM\Psi^{(n+1,1)}


  -
  \frac 14 k_{n+1} A \Psi^{(n,1)}


  -
  \frac 12 k_{n+1} W \Psi^{(n,1)},


@f}

或以更紧凑的方式书写。

@f{align*}{
  \left[


    -iM
    +
    \frac 14 k_{n+1} A
    +
    \frac 12 k_{n+1} W
  \right] \Psi^{(n,2)}
  =
  \left[


    -iM


    -
    \frac 14 k_{n+1} A


    -
   \frac 12 k_{n+1} W
  \right] \Psi^{(n,1)}.


@f}

在这里，矩阵是以其明显的方式定义的。

@f{align*}{
  M_{ij} &= (\varphi_i,\varphi_j), \\
  A_{ij} &= (\nabla\varphi_i,\nabla\varphi_j), \\
  W_{ij} &= (\varphi_i,V \varphi_j).


@f}

请注意，所有单独的矩阵实际上都是对称的、实值的，而且至少是正半无限的，尽管对于系统矩阵 $C = -iM + \frac 14 k_{n+1} A + \frac 12 k_{n+1} W$ 和右手边的相应矩阵 $R = -iM - \frac 14 k_{n+1} A - \frac 12 k_{n+1} W$ 来说显然不是这样的。




<h3>Linear solvers</h3>

 @dealiiVideoLecture{34} 

关于解决程序的唯一剩下的重要问题是如何解决复值线性系统

@f{align*}{
  C \Psi^{(n+1,2)}
  =
  R \Psi^{(n+1,1)},


@f}

矩阵 $C = -iM + \frac 14 k_{n+1} A + \frac 12 k_{n+1}
W$ ，右手边很容易计算为已知矩阵与上一步骤解决方案的乘积。像往常一样，这归结于矩阵 $C$ 具有什么属性的问题。如果它是对称和正定的，那么我们可以使用共轭梯度法。

不幸的是，该矩阵唯一有用的属性是它是复数对称的，即 $C_{ij}=C_{ji}$ ，通过回顾 $M,A,W$ 都是对称的就很容易看出。然而，它不是<a href="https://en.wikipedia.org/wiki/Hermitian_matrix">Hermitian</a>，这就要求 $C_{ij}=\bar C_{ji}$ ，其中的横杠表示复数共轭。

复杂的对称性可以被用于迭代求解器，正如快速的文献搜索所显示的。我们在这里不会试图变得太复杂（实际上是把这个问题留给下面的<a
href="#extensions">Possibilities for extensions</a>部分），而是简单地用好的老办法来解决没有属性的问题。一个直接的解算器。这不是最好的，特别是对于大问题，但对于一个教程程序来说，这已经足够了。幸运的是，SparseDirectUMFPACK类允许解决复杂值的问题。




<h3>Definition of the test case</h3>

NLSE的初始条件通常被选择来代表特定的物理情况。这超出了本程序的范围，但只要说这些初始条件是（i）位于不同点的粒子的波函数的叠加，以及（ii）因为 $|\psi(\mathbf x,t)|^2$ 对应于一个粒子密度函数，积分

@f[
  N(t) = \int_\Omega |\psi(\mathbf x,t)|^2


@f]

对应于系统中粒子的数量。显然，如果要在物理上正确，如果系统是封闭的， $N(t)$ 最好是一个常数，或者如果有吸收性边界条件， $\frac{dN}{dt}<0$ 最好是常数）。重要的一点是，我们应该选择初始条件，以使

@f[
  N(0) = \int_\Omega |\psi_0(\mathbf x)|^2


@f]

有道理。

我们在这里将使用的，主要是因为它能做出好的图形，是以下内容。

@f[
  \psi_0(\mathbf x) = \sqrt{\sum_{k=1}^4 \alpha_k e^{-\frac{r_k^2}{R^2}}},


@f]

其中 $r_k = |\mathbf x-\mathbf x_k|$ 是与（固定）位置 $\mathbf x_k$ 的距离， $\alpha_k$ 的选择是为了使我们要加起来的每个高斯在 $N(0)$ 中增加整数个粒子。我们通过确保以下几点来实现这一点

@f[
  \int_\Omega \alpha_k e^{-\frac{r_k^2}{R^2}}


@f]

是一个正整数。换句话说，我们需要选择 $\alpha$ 作为一个整数倍的

@f[
  \left(\int_\Omega e^{-\frac{r_k^2}{R^2}}\right)^{-1}
  =
  \left(R^d\sqrt{\pi^d}\right)^{-1},


@f]

暂时假设 $\Omega={\mathbb R}^d$  -- 当然不是这样，但我们将忽略积分的微小差异。

因此，我们选择 $\alpha_k=\left(R^d\sqrt{\pi^d}\right)^{-1}$ 为所有，以及 $R=0.1$  。这个 $R$ 足够小，精确（无限）积分和 $\Omega$ 上的积分之间的差异应该不会太引人注意。我们选择 $\mathbf x_k$ 这四个点作为 $(\pm 0.3, 0), (0, \pm
0.3)$ --也离 $\Omega$ 的边界足够远，以保证我们的安全。

为了简单起见，我们在方形 $[-1,1]^2$ 上提出问题。对于边界条件，我们将使用时间无关的诺依曼条件，其形式为

@f[
  \nabla\psi(\mathbf x,t)\cdot \mathbf n=0 \qquad\qquad \forall \mathbf x\in\partial\Omega.


@f]

这不是一个现实的边界条件选择，但对于我们想在这里展示的东西来说已经足够了。我们将在下面的<a href="#extensions">Possibilities for extensions</a>部分进一步评论这个问题。

最后，我们选择 $\kappa=1$ ，势为

@f[
  V(\mathbf x)
  =
  \begin{cases} 0 & \text{if}\; |\mathbf x|<0.7
                \\
                1000 & \text{otherwise}.
  \end{cases}


@f]

使用一个大的势可以确保波函数 $\psi$ 在半径为0.7的圆圈外保持很小。构成初始条件的所有高斯都在这个圆内，解决方案将主要在这个圆内振荡，有少量的能量辐射到外面。大势的使用也确保了非物理边界条件不会有太大的影响。


examples/step-58/doc/results.dox



<h1>Results</h1>

运行该代码的结果是屏幕输出如下。```活动单元的数量：4096 自由度的数量：16641

时间步数1在t=0 时间步数2在t=0.00390625 时间步数3在t=0.0078125 时间步数4在t=0.0117188 [...] ```运行程序也会产生大量的输出文件，我们将在下面进行可视化。




<h3>Visualizing the solution</h3>

该程序的`output_results()`函数生成的输出文件由若干变量组成。解（分为实部和虚部）、振幅和相位。如果我们将这四个字段可视化，在经过几个时间步骤后（准确地说，在时间 $t=0.242$ ，我们得到如下图像。

<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-58.re.png" alt="t=0.242时溶液的实部" width="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-58.im.png" alt="t=0时溶液的虚部。242" width="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-58.magnitude.png" alt="t=0.242时解决方案的振幅" width="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-58.phase.png" alt="t=0.242时解决方案的相位" width="400"> </div> <div>

虽然上面显示的解决方案的实部和虚部并不特别有趣（因为从物理角度来看，相位的全局偏移以及因此实部和虚部之间的平衡是没有意义的），但将解决方案的振幅 $|\psi(\mathbf x,t)|^2$ 和相位 $\text{arg}(\psi(\mathbf x,t))$ 可视化，特别是它们的演变，则要有趣得多。这就导致了如下的图片。

这里显示的相图显然有一些缺陷。

- 首先，相位是一个 "循环量"，但色标对接近 $-\pi$ 的值和接近 $+\pi$ 的值使用的颜色根本不同。这是一个麻烦--我们需要的是一个 "循环色标"，对相位范围的两个极端使用相同的颜色。这样的颜色图存在，例如见<a href="https://nicoguaro.github.io/posts/cyclic_colormaps/">this
  blog post of Nicolás Guarín-Zapata</a>或<a href="https://stackoverflow.com/questions/23712207/cyclic-colormap-without-visual-distortions-for-use-in-phase-angle-plots">this
  StackExchange post</a>。问题是，笔者最喜欢的两个大的可视化软件包之一VisIt，并没有内置这些颜色图。无奈之下，我只好使用Paraview，因为它已经实现了上面帖子中提到的几种颜色地图。下图使用了`nic_Edge`地图，其中两个极端值都显示为黑色。

- 在相位缠绕的单元中存在一个问题。如果在单元格的某个评估点，相位值接近 $-\pi$ ，而在另一个评估点，它接近 $+\pi$ ，那么我们真正希望发生的是整个单元格的颜色接近极端值。但是，相反，可视化程序产生了一个线性插值，其中单元格内的值，即评估点之间的值，是在这两个值之间线性插值的，基本上涵盖了整个可能的相位值范围，因此，在一个单元格的过程中，从深红色到深绿色的整个彩虹色循环往复。解决这个问题的方法是将每个单元的相位值作为一个片断常数输出。因为对接近 $-\pi$ 和 $+\pi$ 的值进行平均，会产生一个与实际相位角无关的平均值，`ComplexPhase'类只是使用每个单元上遇到的*大相位角。

经过这些修改，现在的相位图看起来如下。

<p align="center"> <img src="https://www.dealii.org/images/steps/developer/step-58.phase-cyclic.png" alt="在t=0.242时解的相位，有一个循环的颜色图" width="400">  </p> 

最后，我们可以从中生成一部电影。准确地说，这个视频又使用了两个全局细化周期，时间步长是上面程序中使用的一半）。这几行字的作者用VisIt制作了这部电影，因为这是他比较熟悉的，并使用了一个黑客的颜色地图，也是循环的--尽管这个颜色地图缺乏上面链接中提到的写帖子的人所使用的所有技巧。然而，如果你看一下半径为0.7的圆以外的域的阴影部分，其中电势为零，它确实显示了解决方案作为一个波浪方程的特征--你可以看到每次一个凸点（显示振幅 $|\psi_h(\mathbf x,t)|^2$ ）撞到电势大的区域时：一个波从那里向外传播。看一下这个视频吧。

@htmlonly
<p align="center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/nraszP3GZHk"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly



那么，为什么我最终会在势能 $V(\mathbf x)$ 较大的区域进行遮蔽？在那个外部区域，解决方案是相对较小的。它也是相对平滑的。因此，在某种近似程度上，该区域的方程简化为

@f[


  - i \frac{\partial \psi}{\partial t}
  + V \psi
  \approx 0,


@f]

或者说更容易阅读。

@f[
  \frac{\partial \psi}{\partial t}
  \approx - i V \psi.


@f]

在这个近似值有效的程度上（除其他外，它消除了你在视频中可以看到的行波），这个方程有一个解

@f[
  \psi(\mathbf x, t) = \psi(\mathbf x, 0) e^{-i V t}.


@f]

因为 $V$ 很大，这意味着相位*旋转得相当快*。如果你把注意力集中在域的半透明的外部，你就可以看到这一点。如果用与域的内部相同的方式给这个区域上色，这个快速闪烁的外部部分可能是迷幻的，但也分散了内部发生的事情；也很难真正看到在视频开始时很容易看到的辐射波。


<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4> Better linear solvers </h4>

这里选择的解算器实在是太简单了。它的效率也不高。我们在这里所做的是在每个时间步骤中把矩阵交给一个稀疏的直接求解器，让它找到线性系统的解。但我们知道，我们可以做得更好。

- 首先，我们应该利用这样一个事实，即矩阵实际上并没有从时间步长到时间步长的变化。这是一个伪命题，因为我们在这里有恒定的边界值，而且我们不改变时间步长--这两个假设在实际应用中可能并不真实。但至少在这种情况下，只对矩阵进行一次因式分解（即计算一次 $L$ 和 $U$ 因子），然后在接下来的所有时间步骤中使用这些因子，直到矩阵 $C$ 发生变化，需要进行新的因式分解。SparseDirectUMFPACK类的接口允许这样做。

- 然而，最终，稀疏直接求解器只对相对较小的问题有效，比如说最多几十万个未知数。除此之外，我们需要迭代求解器，如共轭梯度法（用于对称和正定问题）或GMRES。我们已经在其他教程程序中使用了许多这样的方法。在所有情况下，它们都需要伴随着良好的预处理程序。对于目前的情况，原则上可以使用GMRES--一种不需要矩阵的任何特定属性的方法--但最好实施一种迭代方案，利用我们知道的这个问题的一个结构特征：矩阵是复数对称的（尽管不是赫米特）。




<h4> Boundary conditions </h4>

为了能够用于实际的、现实的问题，非线性Schr&ouml;dinger方程的求解器需要利用对手头的问题有意义的边界条件。我们在这里将自己限制在简单的诺伊曼边界条件上--但这些条件实际上对问题没有意义。事实上，这些方程通常是在一个无限的域上提出的。但是，由于我们不能在无限域上进行计算，我们需要在某处截断它，而提出对这个人为的小域有意义的边界条件。广泛使用的方法是使用<a
href="https://en.wikipedia.org/wiki/Perfectly_matched_layer">Perfectly
Matched Layer</a>方法，它对应于一种特殊的衰减。在不同的背景下，它也用于步骤-62。




<h4> Adaptive meshes </h4>

最后，我们从经验和许多其他教程程序中知道，使用自适应细化网格是值得的，而不是这里使用的均匀网格。事实上，在这里增加这一点并不是很困难。step-26将是一个很好的指南，说明如何实现这一点。


examples/step-59/doc/intro.dox

 <br> 

<i>
This program was contributed by Katharina Kormann and Martin
Kronbichler.


This work was partly supported by the German Research Foundation (DFG) through
the project "High-order discontinuous Galerkin for the exa-scale" (ExaDG)
within the priority program "Software for Exascale Computing" (SPPEXA). </i>

<a name="Intro"></a>

<h1>Introduction</h1>

无矩阵算子评估使高阶多项式基的离散化得到了非常有效的实现，这是由于一种叫做和因子化的方法。这个概念已经在step-37和step-48教程程序中介绍过。在这个教程程序中，我们将这些概念扩展到包括面积分的非连续Galerkin（DG）方案，这是一类高阶特别普遍的方法。

无矩阵评估的基本思想与连续元素的评估是一样的。迭代求解器或多网格平滑器中出现的矩阵-向量乘积不是由经典的稀疏矩阵核来实现的，而是通过对基础积分的实时评估来隐含地应用。对于用张量积正交规则集成的张量积形状函数，通过使用和-因子化技术，这种评估特别有效，它将最初涉及 $(k+1)^{2d}$ 的插值操作与相关形状函数在 $k$ 度的 $d$ 维的张量积正交点分解为 $d$ 的一维操作，每个成本 $(k+1)^{d+1}$ 。在三维中，这将复杂度降低了 $k$ 的两个次方。当以每个自由度的复杂度来衡量时，复杂度是 $\mathcal O(k)$ 的多项式程度。由于DG中存在面积分，也由于对正交点的操作涉及更多的内存传输，这两者的规模为 $\mathcal O(1)$ ，观察到的复杂度通常是中等 $k\leq 10$ 的常数。这意味着，以每秒自由度计算，高阶方法的评估吞吐量与低阶方法相同。

关于算法的更多信息可参见Martin Kronbichler和Katharina Kormann的预印本 <br>  <a href="https://arxiv.org/abs/1711.03590">Fast matrix-free evaluation of
discontinuous Galerkin finite element operators</a>，arXiv:1711.03590。

<h3>The symmetric interior penalty formulation for the Laplacian</h3>

在本教程中，我们以无矩阵的DG框架为例，对拉普拉斯进行内部惩罚离散化，即与Step-39教程中使用的方案相同。拉普拉斯的离散化是由以下弱形式给出的

@f{align*}
&\sum_{K\in\text{cells}} \left(\nabla v_h, \nabla u_h\right)_{K}+\\
&\sum_{F\in\text{faces}}\Big(-\left<\jump{v_h}, \average{\nabla u_h}\right>_{F} - \left<\average{\nabla v_h}, \jump{u_h}\right>_{F} + \left<\jump{v_h}, \sigma \jump{u_h}\right>_{F}\Big) \\
&= \sum_{K\in\text{cells}}\left(v_h, f\right)_{K},


@f}

其中 $\jump{v} = v^- \mathbf{n}^- + v^+ \mathbf{n}^+ = \mathbf n^{-}
\left(v^- - v^+\right)$ 表示数量 $v$ 从两个相关单元 $K^-$ 和 $K^+$ 的定向跳跃， $\average{v}=\frac{v^- + v^+}{2}$ 是两边的平均值。

方程中的项代表分项积分后的单元积分，由于分项积分和插入平均通量而在元素界面产生的原始一致性项，为恢复基础矩阵的对称性而添加的邻接一致性项，以及系数为 $\sigma$ 的惩罚项，其大小等于单元在面的法线方向的长度乘以 $k(k+1)$  ，见步骤39。惩罚项的选择是为了使逆向估计成立，并且最终的弱形式是强制性的，即在离散设置中是正定的。邻接一致性项和惩罚项涉及元素界面上的跳跃 $\jump{u_h}$ ，这在解析解中消失了 $u$  。因此，这些项与原始PDE一致，保证了该方法可以保留最佳收敛顺序。

在下面的实现中，我们通过将法向量 $\mathbf{n}^-$ 从跳跃项移到导数中来实现上面的弱形式，形成<i>normal</i>形式的导数。这使得在正交点上的实现稍微有效一些，因为我们只需要处理标量项而不是张量，而且在数学上是等价的。

对于边界条件，我们使用所谓的镜像原理，通过从内部解 $u^-$ 结合给定的边界数据进行外推来定义<i>artificial</i>外部值 $u^+$ ，在迪里希特边界设置 $u^+ = -u^- + 2
g_\text{D}$ 和 $\mathbf{n}^-\cdot \nabla u^+ = \mathbf{n}^-\cdot \nabla u^-$ ，在纽曼边界设置 $u^+=u^-$ 和 $\mathbf{n}^-\cdot \nabla u^+ =


-\mathbf{n}^-\cdot \nabla u^- + 2 g_\text{N}$ ，对于给定的迪里希特值 $g_\text{D}$ 和纽曼值 $g_\text{N}$  。然后将这些表达式插入上述弱形式中。涉及已知量 $g_\text{D}$ 和 $g_\text{N}$ 的贡献最终被移到右手边，而未知值 $\varepsilon(\Delta \mathbf{u}^n(\mathbf{x}_q))$ 被保留在左手边，对矩阵项的贡献与内部面类似。经过这些操作，得到了与步骤39中相同的弱形式。

<h3>Face integration support in MatrixFree and FEFaceEvaluation</h3>

deal.II的无矩阵框架为实现上述离散化方程的作用提供了必要的基础设施。相对于我们在步骤37和步骤48中使用的 MatrixFree::cell_loop() ，我们现在用 MatrixFree::loop() 建立一个代码，它需要三个函数指针，一个用于单元积分，一个用于内面积分，一个用于边界面积分（与步骤39教程程序中使用的MeshWorker的设计相类似）。在这三个函数中的每一个，我们都会在正交点上实现各自的条款。对于向量条目和正交点上的值和梯度之间的插值，我们使用FEEvaluation类来处理单元贡献，FEFaceEvaluation类来处理面的贡献。这些函数的基本用法已经在step-37教程程序中得到了广泛的讨论。

在 MatrixFree::loop(), 中，所有内部面都正好被访问一次，所以必须确保计算来自测试函数 $v_h^-$ 和 $v_h^+$ 的贡献。考虑到两边的测试函数确实是独立的，上面的弱形式实际上意味着我们在用测试函数的法向导数进行测试时，向名为`phi_inner`和`phi_outer`的FEFaceEvaluation对象提交相同的贡献，而在用测试函数的值进行测试时，则提交相反符号的值，因为后者由于跳跃项而涉及相反符号。对于不同细化程度的单元之间的面，从细化的一侧进行整合，FEFaceEvaluation自动执行内插到粗略一侧的子面。因此，一个悬空的节点永远不会明确地出现在用户实现的弱形式中。

每个面被精确访问一次的事实也适用于用MPI并行化时不同处理器之间的子域边界的那些面，其中一个单元属于一个处理器，一个属于另一个。 MatrixFree::reinit() 中的设置将面分成了两边，最终只报告了 MatrixFree::n_inner_face_batches() 和 MatrixFree::n_boundary_face_batches(), 中分别实际处理的面。注意，与步骤37中讨论的单元积分相类似，deal.II在几个面上应用矢量化，以使用SIMD，在我们称之为<i>batch of faces</i>的东西上用一条指令工作。面的批次与单元的批次是独立的，尽管处理面的积分的时间与处理各自单元的积分的时间保持一致，以增加数据定位。

这个程序中的另一个新东西是，我们不再像 FEEvaluation::read_dof_values() 或 FEEvaluation::distribute_local_to_global() 那样将向量访问从求值和积分步骤中分割出来，而是分别调用组合函数 FEEvaluation::gather_evaluate() 和 FEEvaluation::integrate_scatter(), 。这对面积分很有用，因为根据面的评估内容，并非所有单元的向量项都必须首先被触及。例如，想想节点元素FE_DGQ的情况，节点点在元素表面。如果我们对面的形状函数值感兴趣，只有 $(k+ 1)^{d-1}$ 个自由度以非显著的方式对它们做出贡献（用更专业的方式来说，只有 $(k+1)^{d-1}$ 个形状函数在面有非零支持，并对 FiniteElement::has_support_on_face()). 个自由度返回真值。 当与单元的 $(k+1)^d$ 个自由度相比，这要少一个幂。

现在，我们当然不只对函数值感兴趣，而且对单元格上的导数也感兴趣。幸运的是，在deal.II中，有一个元素将这种减少访问的属性也扩展到面的导数上，即FE_DGQHermite元素。

<h3>The FE_DGQHermite element</h3>

FE_DGQHermite元素属于FE_DGQ元素家族，即其形状函数是一维多项式的张量乘积，该元素是完全不连续的。与通常的FE_DGQ元素中的节点特征相反，FE_DGQHermite元素是一个基于Hermite-like概念的节点贡献和导数贡献的混合物。基本的多项式类是 Polynomials::HermiteLikeInterpolation ，可以总结为以下几点。对于三次多项式，我们用两个多项式来表示单位区间左端的函数值和第一次导数， $x=0$  ，用两个多项式来表示函数值和第一次导数以及单位区间的右端， $x=1$  。在相反的两端，形状函数的值和一阶导数都是零，确保四个基础函数中只有两个对各自端部的值和导数有贡献。然而，我们偏离了经典的Hermite内插法，没有严格地为值和一导数指定一个自由度，而是允许一导数是第一和第二形状函数的线性组合。这样做是为了改善插值的调节。另外，当度数超过三时，我们以类似拉格朗日的方式在元素内部增加节点点，在 $x=0$ 和 $x=1$ 这两个点上结合双零。这些额外节点的位置是由一些雅可比多项式的零点决定的，在类的描述中解释过  Polynomials::HermiteLikeInterpolation.  。

使用这个元素，我们只需要访问 $2(k+1)^{d-1}$ 自由度来计算一个面的值和导数。检查是否满足Hermite属性是在 FEFaceEvaluation::gather_evaluate() 和 FEFaceEvaluation::integrate_scatter() 中透明地完成的，它们检查基础的类型，并尽可能地减少对数据的访问。显然，如果我们将 FEFaceEvaluation::read_dof_values() 与 FEFaceEvaluation::evaluate(), 分开，这将是不可能的，因为我们需要读取的条目数量取决于导数的类型（只有值，一阶导数，等等），因此必须交给`read_dof_values()`。

这种优化不仅对计算面的积分有用，而且对MPI的鬼层交换也有用。在一个天真的交换中，如果一个单元的所有自由度由另一个处理器负责计算面的贡献，我们就需要把这个单元的所有自由度发送给另一个处理器。由于我们知道在用FEFaceEvaluation进行的评估中只有部分自由度被触及，所以自然只交换相关的自由度。 MatrixFree::loop() 函数在与 LinearAlgebra::distributed::Vector. 结合时支持选定的数据交换。为了实现这一点，我们需要告诉循环我们要对脸部做什么样的评价，使用 MatrixFree::DataAccessOnFaces, 类型的参数，正如在下面 `LaplaceOperator::vmult()` 的实现中可以看到。在这种情况下，数据交换的方式是如下的。矢量中的幽灵层数据仍然假装代表所有的自由度，这样，FEFaceEvaluation可以继续读取数值，就像单元格是本地拥有的一样。数据交换例程负责将数据打包和解包成这种格式的任务。虽然这听起来很复杂，但我们将在下面的结果部分显示，通过与不指定面孔上的数据访问的基线代码进行性能比较，这确实得到了回报。

<h3>An approximate block-Jacobi smoother using the fast diagonalization method</h3>

按照step-37程序的传统，我们再次用共轭梯度求解器内的几何多网格预处理器解决泊松问题。在这个教程程序中，我们没有计算对角线并使用基本的PreconditionChebyshev作为平滑器，而是选择了一种不同的策略。我们实现了一个块状Jacobi预处理程序，其中块状指的是一个单元上的所有自由度。我们没有在预处理程序中建立完整的单元格矩阵并应用它的LU因子化（或逆），这种操作将受到严重的内存带宽限制，因此相当缓慢；我们通过一种称为快速对角化法的特殊技术对块的逆进行近似处理。

该方法的思路是利用单元矩阵的结构。对于在笛卡尔网格上离散的恒定系数的拉普拉斯，单元矩阵 $L$ 可以写为

@f{align*}{
L &= A_1 \otimes M_0 + M_1 \otimes A_0


@f}

在二维和

@f{align*}{
L &= A_2 \otimes M_1 \otimes M_0 + M_2 \otimes A_1 \otimes M_0 + M_2 \otimes M_1 \otimes A_0


@f}

在三维中。矩阵 $A_0$ 和 $A_1$ 表示一维拉普拉斯矩阵（包括与当前单元值 $u^-_h$ 和 $v^-_h$ 相关的单元和面项）， $M_0$ 和 $M_1$ 是质量矩阵。请注意，一旦单元上有非恒定系数或几何形状不再恒定，这种简单的张量乘积结构就会消失。我们提到，类似的设置也可以用来用这个最终的张量积形式的矩阵来替代计算的积分，这将把算子评估的操作减少到一半以下。然而，考虑到这只适用于直角坐标单元和恒定系数的情况，这是一个相当狭窄的情况，我们避免继续探讨这个想法。

有趣的是，由于1964年<a
href="http://dl.acm.org/citation.cfm?id=2716130">R. E. Lynch, J. R. Rice,
D. H. Thomas, Direct solution of partial difference equations by tensor
product methods, Numerische Mathematik 6, 185-199</a>引入的方法，矩阵 $L$ 的精确逆值可以通过张量积找到。

@f{align*}{
L^{-1} &= S_1 \otimes S_0 (\Lambda_1 \otimes I + I \otimes \Lambda_0)^{-1}
S_1^\mathrm T \otimes S_0^\mathrm T,


@f}

其中  $S_d$  是给定张量方向上广义特征值问题的特征向量矩阵  $d$  。

@f{align*}{
A_d s  &= \lambda M_d s, \quad d = 0, \ldots,\mathrm{dim-1},


@f}

和 $\Lambda_d$ 是代表广义特征值 $\lambda$ 的对角矩阵。请注意，向量 $s$ 是这样的：它们同时对角化 $A_d$ 和 $M_d$ ，即 $S_d^{\mathrm T} A_d S_d =
\Lambda_d$ 和 $S_d^{\mathrm T} M_d S_d = I$  。

deal.II库使用这个概念实现了一个类，叫做TensorProductMatrixSymmetricSum。

为了这个程序，我们坚持使用常数系数和直角坐标系网格，尽管基于张量积的近似版本对于更一般的网格仍然是可能的，而且算子评估本身当然是通用的。另外，我们也不关心自适应网格，因为多网格算法需要获得不同细化边缘的通量矩阵，如步骤39所解释的。然而，我们做的一件事是仍然将我们的块状Jacobi预处理包在PreconditionChebyshev里面。这个类使我们不必寻找适当的松弛参数（对于块-雅各比平滑器来说，二维的松弛参数约为0.7，三维的松弛参数约为0.5），而且通常比普通的雅各比平滑器提高了一些平滑效率，因为当设置切比雪夫多项式的度数为1或2时，它可以降低解的时间。

请注意，块状Jacobi平滑器有一个额外的好处：快速对角线化方法也可以解释为从FE_DGQHermite的Hermite-like多项式转变为一个单元拉普拉斯是对角线的基础。因此，它抵消了基础的影响，无论我们使用FE_DGQHermite还是FE_DGQ，都会得到相同的迭代次数。这与使用只有对角线的PreconditionChebyshev类（点Jacobi方案）相比，FE_DGQ和FE_DGQHermite确实表现不同，FE_DGQ需要的迭代次数比FE_DGQHermite少2-5次，尽管对类似Hermite的形状函数做了修改以确保良好的调节。


examples/step-59/doc/results.dox



<h1>Results</h1>

<h3>Program output</h3>

与第37步一样，我们在运行时间方面评估多网格求解器。  在两个空间维度的8度元素中，一个可能的输出可能如下。

@code
Running with 12 MPI processes, element FE_DGQHermite<2>(8)


Cycle 0
Number of degrees of freedom: 5184
Total setup time              0.0282445 s
Time solve (14 iterations)    0.0110712 s
Verification via L2 error:    1.66232e-07


Cycle 1
Number of degrees of freedom: 20736
Total setup time              0.0126282 s
Time solve (14 iterations)    0.0157021 s
Verification via L2 error:    2.91505e-10


Cycle 2
Number of degrees of freedom: 82944
Total setup time              0.0227573 s
Time solve (14 iterations)    0.026568 s
Verification via L2 error:    6.64514e-13


Cycle 3
Number of degrees of freedom: 331776
Total setup time              0.0604685 s
Time solve (14 iterations)    0.0628356 s
Verification via L2 error:    5.57513e-13


Cycle 4
Number of degrees of freedom: 1327104
Total setup time              0.154359 s
Time solve (13 iterations)    0.219555 s
Verification via L2 error:    3.08139e-12


Cycle 5
Number of degrees of freedom: 5308416
Total setup time              0.467764 s
Time solve (13 iterations)    1.1821 s
Verification via L2 error:    3.90334e-12


Cycle 6
Number of degrees of freedom: 21233664
Total setup time              1.73263 s
Time solve (13 iterations)    5.21054 s
Verification via L2 error:    4.94543e-12
@endcode



与第37步一样，随着问题大小的增加，CG的迭代次数保持不变。迭代次数要高一些，这是因为我们使用的切比雪夫多项式的度数较低（步骤37中为2比5），而且内部惩罚离散化的特征值分布也比较大。尽管如此，13次迭代将残差减少了12个数量级，或者说每次迭代几乎是9个系数，这表明总体上是一种非常有效的方法。特别是，当使用12个核心时，我们可以在5秒内解决一个具有2100万自由度的系统，这是一个非常好的效率。当然，在二维中，我们很好地进入了8级多项式的四舍五入体系；事实上，大约83000个自由度或0.025秒就足以完全收敛这个（简单的）分析解。

如果我们在三个空间维度上运行程序，并没有太大的变化，只是我们现在用做更高的多项式度数和不断增加的网格大小来做一些更有用的事情，因为舍入误差只在最细的网格上获得。尽管如此，令人瞩目的是，我们可以在一台12核的机器上非常容易地解决一个具有三个周期的波浪的三维拉普拉斯问题，达到四舍五入的精度--对于24m DoFs的第二至最大的情况，总共使用约3.5GB的内存，花费不超过8秒。最大的案例使用了30GB的内存，有1.91亿个DoFs。

@code
Running with 12 MPI processes, element FE_DGQHermite<3>(8)


Cycle 0
Number of degrees of freedom: 5832
Total setup time              0.0210681 s
Time solve (15 iterations)    0.0956945 s
Verification via L2 error:    0.0297194


Cycle 1
Number of degrees of freedom: 46656
Total setup time              0.0452428 s
Time solve (15 iterations)    0.113827 s
Verification via L2 error:    9.55733e-05


Cycle 2
Number of degrees of freedom: 373248
Total setup time              0.190423 s
Time solve (15 iterations)    0.218309 s
Verification via L2 error:    2.6868e-07


Cycle 3
Number of degrees of freedom: 2985984
Total setup time              0.627914 s
Time solve (15 iterations)    1.0595 s
Verification via L2 error:    4.6918e-10


Cycle 4
Number of degrees of freedom: 23887872
Total setup time              2.85215 s
Time solve (15 iterations)    8.30576 s
Verification via L2 error:    9.38583e-13


Cycle 5
Number of degrees of freedom: 191102976
Total setup time              16.1324 s
Time solve (15 iterations)    65.57 s
Verification via L2 error:    3.17875e-13
@endcode



<h3>Comparison of efficiency at different polynomial degrees</h3>

在介绍和代码中的评论中，多次提到用FEEvaluation和FEFaceEvaluation评估器可以非常有效地处理高阶。现在，我们想通过观察三维多网格求解器在不同多项式程度下的吞吐量来证实这些说法。我们收集的时间如下。我们首先在问题大小接近一千万的情况下运行求解器，如表前四行所示，并记录时间。然后，我们通过记录每秒解决的百万自由度数（MDoFs/s）来规范吞吐量，以便能够比较不同程度的效率，计算方法是自由度数除以求解器时间。

 <table align="center" class="doxtable">
  <tr>
   <th>degree</th>
   <th>1</th>
   <th>2</th>
   <th>3</th>
   <th>4</th>
   <th>5</th>
   <th>6</th>
   <th>7</th>
   <th>8</th>
   <th>9</th>
   <th>10</th>
   <th>11</th>
   <th>12</th>
  </tr>
  <tr>
   <th>Number of DoFs</th>
   <td>2097152</td>
   <td>7077888</td>
   <td>16777216</td>
   <td>32768000</td>
   <td>7077888</td>
   <td>11239424</td>
   <td>16777216</td>
   <td>23887872</td>
   <td>32768000</td>
   <td>43614208</td>
   <td>7077888</td>
   <td>8998912</td>
  </tr>
  <tr>
   <th>Number of iterations</th>
   <td>13</td>
   <td>12</td>
   <td>12</td>
   <td>12</td>
   <td>13</td>
   <td>13</td>
   <td>15</td>
   <td>15</td>
   <td>17</td>
   <td>19</td>
   <td>18</td>
   <td>18</td>
  </tr>
  <tr>
   <th>Solver time [s]</th>
   <td>0.713</td>
   <td>2.150</td>
   <td>4.638</td>
   <td>8.803</td>
   <td>2.041</td>
   <td>3.295</td>
   <td>5.723</td>
   <td>8.306</td>
   <td>12.75</td>
   <td>19.25</td>
   <td>3.530</td>
   <td>4.814</td>
  </tr>
  <tr>
   <th>MDoFs/s</th>
   <td>2.94</td>
   <td>3.29</td>
   <td>3.62</td>
   <td>3.72</td>
   <td>3.47</td>
   <td>3.41</td>
   <td>2.93</td>
   <td>2.88</td>
   <td>2.57</td>
   <td>2.27</td>
   <td>2.01</td>
   <td>1.87</td>
  </tr>
</table> 

我们清楚地看到每个DoF的效率最初是如何提高的，直到它达到多项式度数的最大值  $k=4$  。这种效果是令人惊讶的，不仅是因为较高的多项式度数通常会产生一个好得多的解决方案，而且特别是当考虑到基于矩阵的方案时，在较高的度数下更密集的耦合会导致单调的吞吐量下降（在3D中是一个急剧的下降， $k=4$ 比 $k=1$ 慢十倍以上！）。对于更高的度数，吞吐量减少了一些，这既是由于迭代次数的增加（从 $k=2,3,4$ 的12次增加到 $k=10$ 的19次），也是由于运算符评估的 $\mathcal O(k)$ 复杂性。尽管如此，对于更高的多项式度数，作为求解时间的效率仍然会更好，因为它们有更好的收敛率（至少对于像这个问题一样简单的问题）。对于 $k=12$ ，我们在100万个DoFs的情况下已经达到了舍入精度（求解时间不到一秒），而对于 $k=8$ ，我们需要2400万个DoFs和8秒钟。对于 $k=5$ ，误差约为 $10^{-9}$ 的5700万个DoFs，因此，尽管花了16秒，但离舍入还很远。

请注意，上述数字有点悲观，因为它们包括切比雪夫平滑器计算特征值估计的时间，这大约是求解器时间的10%。如果系统被多次求解（例如在流体力学中很常见），这个特征值的成本只需支付一次，更快的时间就可以得到。

<h3>Evaluation of efficiency of ingredients</h3>

最后，我们来看一下本教程程序中提出的一些特殊成分，即特别是FE_DGQHermite基础和 MatrixFree::DataAccessOnFaces. 的规格。 在下面的表格中，第三行显示了上面的优化求解器，第四行显示了只将 MatrixFree::DataAccessOnFaces 设置为 "未指定 "而不是最优的 "网格"，最后一行是用基本的FE_DGQ元素代替FE_DGQHermite，其中MPI交换更加昂贵，由 FEFaceEvaluation::gather_evaluate() 和 FEFaceEvaluation::integrate_scatter(). 完成的操作

 <table align="center" class="doxtable">
  <tr>
   <th>degree</th>
   <th>1</th>
   <th>2</th>
   <th>3</th>
   <th>4</th>
   <th>5</th>
   <th>6</th>
   <th>7</th>
   <th>8</th>
   <th>9</th>
   <th>10</th>
   <th>11</th>
   <th>12</th>
  </tr>
  <tr>
   <th>Number of DoFs</th>
   <td>2097152</td>
   <td>7077888</td>
   <td>16777216</td>
   <td>32768000</td>
   <td>7077888</td>
   <td>11239424</td>
   <td>16777216</td>
   <td>23887872</td>
   <td>32768000</td>
   <td>43614208</td>
   <td>7077888</td>
   <td>8998912</td>
  </tr>
  <tr>
   <th>Solver time optimized as in tutorial [s]</th>
   <td>0.713</td>
   <td>2.150</td>
   <td>4.638</td>
   <td>8.803</td>
   <td>2.041</td>
   <td>3.295</td>
   <td>5.723</td>
   <td>8.306</td>
   <td>12.75</td>
   <td>19.25</td>
   <td>3.530</td>
   <td>4.814</td>
  </tr>
  <tr>
   <th>Solver time MatrixFree::DataAccessOnFaces::unspecified [s]</th>
   <td>0.711</td>
   <td>2.151</td>
   <td>4.675</td>
   <td>8.968</td>
   <td>2.243</td>
   <td>3.655</td>
   <td>6.277</td>
   <td>9.082</td>
   <td>13.50</td>
   <td>20.05</td>
   <td>3.817</td>
   <td>5.178</td>
  </tr>
  <tr>
   <th>Solver time FE_DGQ [s]</th>
   <td>0.712</td>
   <td>2.041</td>
   <td>5.066</td>
   <td>9.335</td>
   <td>2.379</td>
   <td>3.802</td>
   <td>6.564</td>
   <td>9.714</td>
   <td>14.54</td>
   <td>22.76</td>
   <td>4.148</td>
   <td>5.857</td>
  </tr>
</table> 

表中的数据显示，不使用 MatrixFree::DataAccessOnFaces 对于较高的多项式度数来说，成本增加了10%左右。对于较低的度数，差异显然没有那么明显，因为体积与表面的比例更有利，需要交换的数据更少。如果只看矩阵-向量乘积，而不是这里显示的完整的多网格求解器，差异会更大，仅仅因为MPI通信，时间就会差20%左右。

对于 $k=1$ 和 $k=2$ ，类似Hermite的基函数显然没有真正得到回报（事实上，对于 $k=1$ ，多项式与FE_DGQ完全相同），其结果与FE_DGQ基函数相似。然而，对于从3开始的度数，我们看到FE_DGQHermite的优势越来越大，显示了这些基函数的有效性。

<h3>Possibilities for extension</h3>

正如介绍中提到的，快速对角线化方法与具有恒定系数的直角坐标网相联系。如果我们想解决可变系数的问题，我们就需要在平滑参数的设计上投入更多的时间，选择适当的泛函（例如，在最近的箱形元素上近似反演）。

另一种扩展程序的方式是包括对自适应网格的支持，对于这种支持，在不同细化水平的边缘进行接口操作是必要的，如步骤39所讨论的。


examples/step-6/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{15,16,17,17.25,17.5,17.75} 

这个程序最后是关于deal.II的主要特征之一：使用自适应（局部）细化网格。这个程序仍然是基于步骤4和步骤5的，而且，正如你将看到的，实际上不需要花太多的代码来实现自适应性。事实上，虽然我们做了大量的解释，但自适应网格可以被添加到一个现有的程序中，几乎不需要十几行额外的代码。该程序显示了这些行是什么，以及自适应网格细化（AMR）的另一个重要成分：一个标准，可以用来确定是否有必要细化一个单元，因为它上面的误差很大，是否可以粗化这个单元，因为它上面的误差特别小，或者我们是否应该让这个单元保持原样。我们将在下文中讨论所有这些问题。




<h3> What adaptively refined meshes look like </h3>

有许多方法可以自适应地细化网格。整个算法的基本结构总是相同的，由以下步骤的循环组成。

- 在当前网格上求解PDE。

- 用一些能说明误差的标准来估计每个单元格的误差。

- 把那些误差大的单元格标记为细化，把那些误差特别小的单元格标记为粗化，其余的就不用管了。

- 细化和粗化如此标记的单元，得到一个新的网格。

- 在新的网格上重复上述步骤，直到整体误差足够小。

由于一些可能被历史遗忘的原因（也许是这些函数过去是用FORTRAN语言实现的，这种语言并不关心某个东西是用小写字母还是大写字母拼写的，程序员经常习惯性地选择大写字母），上述循环在关于网格适应性的出版物中经常被称为SOLVE-ESTIMATE-MARK-REFINE循环（用这种拼法）。

然而，在这个结构之外，有多种方法可以实现这一点。从根本上说，它们的区别在于究竟如何从前一个网格中生成一个网格。

如果要使用三角形（deal.II没有这样做），那么就有两种基本的可能性。

- 最长边细化。在这个策略中，通过从最长边的中点到对面的顶点引入一条新的边，将一个标记为细化的三角形切成两段。当然，来自最长边的中点必须以某种方式通过*也*完善该边另一侧的单元格（如果有的话）来平衡。如果有问题的边也是相邻单元的最长边，那么我们可以直接运行一条新的边穿过相邻单元到对面的顶点；否则就需要一个稍微复杂的结构，在相邻单元的至少一条其他边上增加更多的新顶点，然后可能传播到相邻单元的邻居，直到算法终止。这很难用语言描述，而且因为deal.II不使用三角形，不值得在这里花时间。   但如果你很好奇，你可以随时在本介绍顶部显示的链接中观看视频讲座15。

- 红-绿细化。另一个选择是所谓的 "红绿细化"。   这种策略甚至更难描述（但在视频讲座中也讨论过），其优点是细化不会传播到我们想要细化的单元的近邻之外。然而，它的实施难度要大得多。

这些方法还有其他的变化，但重要的一点是，它们总是产生一个网格，其中两个单元的接触线是两个相邻单元的整个边缘。只要稍加努力，这种策略就可以很容易地适用于由四面体构成的三维网格。

这两种方法对2D的四边形和3D的六面体都不起作用，或者至少不容易。原因是要精化的四边形单元的四边形邻居所产生的过渡元素将是三角形，而我们不希望这样。因此，在deal.II中选择的适应性方法是使用网格，其中相邻的单元在细化水平上可能相差一个。这就导致在单元的界面上出现属于一方的节点，但在另一方是不平衡的。这些节点的通用术语是&ldquo;悬挂节点&rdquo;，这些网格在非常简单的情况下看起来是这样的。

 @image html hanging_nodes.png "A simple mesh with hanging nodes" 

一个更复杂的二维网格看起来是这样的（并在下面的 "结果 "部分讨论）。

<img src="https://www.dealii.org/images/steps/developer/step_6_grid_5_ladutenko.svg" alt="第五个自适应细化的拉杜腾科网格：单元格沿着内圈聚拢。" width="300" height="300">

最后，这里展示了一个具有这种悬挂节点的三维网格（来自步骤-43）。

<img src="https://www.dealii.org/images/steps/developer/step-43.3d.mesh.png" alt="" width="300" height="300">

第一个和第三个网格当然是基于一个正方形和一个立方体，但正如第二个网格所显示的，这不是必要的。重要的一点是，我们可以独立于其邻居来细化一个网格（受制于一个单元只能比其邻居多细化一次的约束），但如果我们这样做，最终会出现这些&ldquo;悬空节点&rdquo;。




<h3> Why adapatively refined meshes? </h3>

现在你已经看到了这些自适应细化网格的样子，你应该问<i>why</i>我们为什么要这样做。毕竟，我们从理论上知道，如果我们对网格进行全局细化，误差会下降到零，因为

@f{align*}{
  \|\nabla(u-u_h)\|_{\Omega} \le C h_\text{max}^p \| \nabla^{p+1} u \|_{\Omega},


@f}

其中 $C$ 是独立于 $h$ 和 $u$ 的一些常数， $p$ 是使用中的有限元的多项式程度， $h_\text{max}$ 是最大单元的直径。那么，如果<i>largest</i>单元很重要，那么为什么我们要在域的某些部分将网格做得很细，而不是全部？

答案在于观察到上面的公式不是最佳的。事实上，一些更多的工作表明，以下是一个更好的估计（你应该与上述估计的平方进行比较）。

@f{align*}{
  \|\nabla(u-u_h)\|_{\Omega}^2 \le C \sum_K h_K^{2p} \| \nabla^{p+1} u \|^2_K.


@f}

(因为 $h_K\le h_\text{max}$ ，如果你只是把网格大小从总和中拉出来，这个公式立即暗示了前一个公式)。这个公式所暗示的是，没有必要把<i>largest</i>单元格做得很小，而单元格真正只需要做小的<i>where $\| \nabla^{p+1} u \|_K$ is large</i>!换句话说。网格实际上只需要在解有较大变化的地方做得很细，正如 $p+1$ st导数所表明的。这是有直观意义的：例如，如果我们使用一个线性元素 $p=1$ ，那么即使网格很粗，那些解几乎是线性的地方（如 $\nabla^2 u$ 所示的小地方）也会被很好地解决。只有那些二阶导数大的地方才会被大元素解决得很差，因此我们应该把网格做得很小。

当然，这个<i>a priori estimate</i>在实践中不是很有用，因为我们不知道问题的精确解 $u$ ，因此，我们不能计算 $\nabla^{p+1}u$  。但是，这也是通常采取的方法，我们可以只根据之前计算的离散解 $u_h$ 来计算 $\nabla^{p+1}u$ 的数值近似值。我们将在下面稍微详细地讨论这个问题。这将有助于我们确定哪些单元具有较大的 $p+1$ st导数，然后这些单元将成为细化网格的候选单元。




<h3> How to deal with hanging nodes in theory </h3>

上面提到的使用三角形网格的方法，都是为了确保每个顶点都是所有相邻单元的顶点--也就是说，没有悬空节点。这就自动确保了我们能够以这样的方式定义形状函数，即它们是全局连续的（如果我们使用到目前为止在教程程序中一直使用的常见的 $Q_p$ 拉格朗日有限元方法，如FE_Q类所代表的）。

另一方面，如果我们在有悬挂节点的网格上定义形状函数，我们最终可能得到不连续的形状函数。要看到这一点，请想一下上面的情况，即右上角的单元没有被细化，并考虑一下使用双线性有限元的情况。在这种情况下，与悬挂节点相关的形状函数是以明显的方式定义在与每个悬挂节点相邻的两个小单元上。但我们如何将它们扩展到相邻的大单元呢？显然，函数对大单元的扩展不能是双线性的，因为那样的话，它需要沿着大单元的每条边线性化，这意味着它在整条边上需要为零，因为它需要在大单元的两个顶点上为零。但从小单元一侧看，它在悬挂节点本身并不是零--所以它不是连续的。下面三幅图显示了沿着有关边缘的三个形状函数，当以通常的方式简单地根据它们相邻的单元格来定义时，这些形状函数变成了不连续的。

<div class="threecolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center">  @image html hanging_nodes_shape_functions_1.png "A discontinuous shape function adjacent to a hanging node"  </div> </div> <div class="parent"> <div class="img" align="center">  @image html hanging_nodes_shape_functions_2.png "A discontinuous shape function at a hanging node"  </div> </div> <div class="parent"> <div class="img" align="center">  @image html hanging_nodes_shape_functions_3.png "A discontinuous shape function adjacent to a hanging node"  </div> </div></div>


但我们确实希望有限元解是连续的，这样我们就有了&ldquo;符合要求的有限元方法&rdquo;，其中离散有限元空间是我们寻求拉普拉斯方程解的 $H^1$ 函数空间的一个适当子集。为了保证全局解在这些节点上也是连续的，我们必须对这些节点上的解的值提出一些额外的约束。诀窍是要认识到，虽然上面显示的形状函数是不连续的（因此它们的<i>arbitrary</i>线性组合也是不连续的），但形状函数加起来为 $u_h(\mathbf x)=\sum_j U_j \varphi_j(\mathbf x)$ 的线性组合可以是连续的<i>if the coefficients $U_j$ satisfy certain relationships</i>。换句话说，系数 $U_j$ 不能任意选择，而必须满足某些约束条件，这样，函数 $u_h$ 实际上是连续的。这些约束条件在概念上相对容易理解，但在软件中的实现却很复杂，需要几千行的代码。另一方面，在用户代码中，在处理挂起的节点时，你只需要添加大约半打的行。

在下面的程序中，我们将展示如何从deal.II中获得这些约束，以及如何在线性方程组的求解中使用它们。在了解下面程序的细节之前，你可能想看看 @ref constraints 文件模块，它解释了这些约束如何计算以及deal.II中哪些类对它们起作用。




<h3> How to deal with hanging nodes in practice </h3>

悬挂节点约束的实践比我们上面概述的理论更简单。实际上，你只需要在step-4这样的程序中增加半打额外的代码，就可以使它在有悬挂节点的自适应网格中工作。有趣的是，这与你要解决的方程完全无关。这些约束的代数性质与方程无关，只取决于对有限元的选择。因此，处理这些约束的代码完全包含在deal.II库本身，你不需要担心细节问题。

你需要使其发挥作用的步骤基本上是这样的。

- 你必须创建一个AffineConstraints对象，（顾名思义）它将存储有限元空间的所有约束。在目前的情况下，这些约束是由于我们希望保持解空间的连续，甚至在有悬空节点的情况下。(下面我们还将简要地提到，我们还将把边界值放到这个对象中，但这是一个单独的问题)。

- 你必须使用函数 DoFTools::make_hanging_node_constraints() 来填充这个对象，以确保有限元空间的元素的连续性。

- 当你通过使用 AffineConstraints::distribute_local_to_global(). 将矩阵和右手边的局部贡献复制到全局对象时，你必须使用这个对象。 到目前为止，我们已经自己完成了这个工作，但现在有了约束，这就是神奇的地方，我们将约束应用到线性系统中。这个函数所做的是确保位于悬空节点的自由度事实上不是真正的自由。相反，通过将它们的行和列设置为零，并在对角线上放置一些东西以确保矩阵保持可反转，它们实际上被从线性系统中消除了。   对于我们在这里解决的拉普拉斯方程来说，这个过程产生的矩阵仍然是对称和正定的，所以我们可以继续使用共轭梯度法来解决。

- 然后你像往常一样求解线性系统，但在这一步结束时，你需要确保位于悬挂节点上的 "自由度 "得到正确的（约束的）值，这样你随后可视化的或以其他方式评估的解决方案实际上是连续的。这可以通过在求解后立即调用 AffineConstraints::distribute() 来实现。

这四个步骤实际上是所有必要的--从用户的角度来看就是这么简单。事实上，在上面提到的函数调用中，你将运行几千行并不复杂的代码，这一点完全不重要。在用户代码中，实际上只有四个额外的步骤。




<h3> How we obtain locally refined meshes </h3>

下一个问题是，既然我们知道如何<i>deal</i>处理有这些悬挂节点的网格，那么我们如何<i>obtain</i>它们。

一个简单的方法已经在步骤1中展示过了：如果你<i>know</i>哪里需要细化网格，那么你可以手工创建一个。但是在现实中，我们并不知道这些。我们不知道PDE的解在前面（因为，如果我们知道，我们就不必使用有限元方法），因此，我们不知道哪里需要增加局部网格细化来更好地解决解有强烈变化的区域。但是上面的讨论表明，也许我们可以用一个网格上的离散解 $u_h$ 来估计导数 $\nabla^{p+1} u$ ，然后用这个来确定哪些单元太大，哪些已经足够小。然后，我们可以使用局部网格细化技术从当前的网格中生成一个新的网格。如果有必要，这个步骤会重复进行，直到我们对我们的数值解决方案感到满意--或者，更常见的是，直到我们耗尽了计算资源或耐心。

所以这正是我们要做的。局部细化网格是使用一个<i>error estimator</i>产生的，它可以估计拉普拉斯算子的数值解的能量误差。由于它是由Kelly和他的同事开发的，我们经常在库、文档和邮件列表中把它称为&ldquo;Kelly细化指标&rdquo;。实现它的类被称为KellyErrorEstimator，在该类的文档中可以找到大量的信息，这里不需要重复。然而，总结起来就是，该类计算出一个具有与 @ref GlossActive "活动单元 "一样多的条目的向量，其中每个条目包含对该单元的误差估计。这个估计值然后被用来细化网格的单元：那些有大误差的单元将被标记为细化，那些有特别小估计值的单元将被标记为粗化。我们不需要用手去做这些。一旦我们获得了误差估计矢量，命名空间GridRefinement中的函数将为我们完成这一切。

值得注意的是，虽然Kelly误差估计器是为拉普拉斯方程开发的，但它已被证明是为广泛的方程生成局部细化网格的合适工具，甚至不限于只针对椭圆问题。尽管它对其他方程会产生非最优网格，但它往往是快速产生网格的好方法，能很好地适应解的特征，如大变化区域或不连续性。




<h3> Boundary conditions </h3>

事实证明，人们可以把迪里希特边界条件看作是对自由度的另一种约束。这的确是一个特别简单的约束。如果 $j$ 是边界上的一个自由度，其位置为 $\mathbf x_j$ ，那么在 $\partial\Omega$ 上施加边界条件 $u=g$ 就会产生约束 $U_j=g({\mathbf x}_j)$  。

AffineConstraints类也可以处理这样的约束，这使得我们可以方便地让我们用于悬挂节点约束的同一个对象也处理这些Dirichlet边界条件。这样一来，我们就不需要在装配后应用边界条件（就像我们在前面的步骤中做的那样）。所有需要的是我们调用 VectorTools::interpolate_boundary_values() 的变体，该变体在AffineConstraints对象中返回其信息，而不是我们在以前的教程程序中使用的 `std::map` 。


<h3> Other things this program shows </h3>


由于用于局部细化网格的概念非常重要，我们在这个例子中没有展示很多其他材料。最重要的例外是，我们展示了如何使用双二次元而不是之前所有例子中使用的双线性元素。事实上，使用高阶元素只需替换程序中的三行，即在本程序主类的构造函数中初始化 <code>fe</code> 成员变量，以及在两个地方使用适当的正交公式。程序的其他部分没有变化。

其他唯一的新东西是在 <code>main</code> 函数中捕捉异常的方法，以便在程序因某种原因崩溃时输出一些信息。下面将详细讨论这个问题。


examples/step-6/doc/results.dox



<h1>Results</h1>


程序的输出看起来如下。

@code
Cycle 0:
   Number of active cells:       20
   Number of degrees of freedom: 89
Cycle 1:
   Number of active cells:       44
   Number of degrees of freedom: 209
Cycle 2:
   Number of active cells:       92
   Number of degrees of freedom: 449
Cycle 3:
   Number of active cells:       200
   Number of degrees of freedom: 921
Cycle 4:
   Number of active cells:       440
   Number of degrees of freedom: 2017
Cycle 5:
   Number of active cells:       956
   Number of degrees of freedom: 4425
Cycle 6:
   Number of active cells:       1916
   Number of degrees of freedom: 8993
Cycle 7:
   Number of active cells:       3860
   Number of degrees of freedom: 18353
@endcode






正如预期的那样，在每个周期中，单元格的数量大约增加了一倍。度数略多于单元数的四倍；人们期望在无限网格的两个空间维度上的系数正好是四（因为自由度之间的间隔是单元宽度的一半：每个边缘有一个额外的自由度，每个单元的中间有一个），但由于网格的有限尺寸和由悬挂节点和局部细化引入的额外自由度，它大于这个系数。




程序在细化循环的每个周期都输出解决方案和网格。解决方案看起来如下。

 <img src="https://www.dealii.org/images/steps/developer/step-6.solution.9.2.png" alt=""> 

关注该程序如何得出最终的网格是很有趣的。

<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_0.svg" alt="初始网格：具有一个全局细化的五格圆形网格。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_1.svg" alt="第一个网格：具有两个全局细化的五格圆形网格。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_2.svg" alt="第二个网格：有一个自适应细化的五格圆形网格。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_3.svg" alt="第三个网格：有两个自适应细化的五格圆形网格，显示围绕内圆的聚类。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_4.svg" alt="第四个网格：具有三个自适应细化的五格圆形网格，显示了围绕内圈的聚类。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_5.svg" alt="第五个网格：具有四个自适应细化的五格圆形网格，显示了围绕内圈的聚类。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_6.svg" alt="第六个网格：具有五个自适应细化的五格圆形网格，显示了围绕内圈的聚类。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_7.svg" alt="最后一个网格：有六个自适应细化的五格圆形网格，显示大多数单元都聚集在内圆周围。" width="300" height="300"> </div> </div>


可以清楚地看到，在解有扭结的区域，也就是离中心0.5的径向距离的圆，被精炼得最多。此外，解非常光滑和几乎平坦的中心区域几乎完全没有被细化，但这是由于我们没有考虑到那里的系数很大的事实。外面的区域被任意细化，因为那里的二阶导数是恒定的，因此细化主要是基于单元的大小和它们与最佳方形的偏差。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Solvers and preconditioners</h4>


如果一个人要解决相当大的问题（比我们这里的问题大得多），有一件事总是值得一试的，那就是尝试不同的求解器或预处理器。在目前的情况下，线性系统是对称的和正定的，这使得CG算法几乎成了求解的典型选择。然而，我们在 <code>solve()</code> 函数中使用的SSOR预处理器是可以争夺的。

在deal.II中，改变预处理程序是比较简单的。例如，通过改变现有的几行代码

@code
  PreconditionSSOR<SparseMatrix<double>> preconditioner;
  preconditioner.initialize(system_matrix, 1.2);
@endcode

进入

@code
  PreconditionSSOR<SparseMatrix<double>> preconditioner;
  preconditioner.initialize(system_matrix, 1.0);
@endcode

我们可以尝试SSOR的不同放松参数。通过使用

@code
  PreconditionJacobi<SparseMatrix<double>> preconditioner;
  preconditioner.initialize(system_matrix);
@endcode

我们可以使用Jacobi作为预处理程序。而通过使用

@code
  SparseILU<double> preconditioner;
  preconditioner.initialize(system_matrix);
@endcode

我们可以使用一个简单的不完全LU分解，不需要任何阈值处理或加强对角线（要使用这个预处理程序，你还必须把头文件 <code>deal.II/lac/sparse_ilu.h</code> 添加到文件顶部的包含列表中）。

使用这些不同的预处理程序，我们可以比较所需的CG迭代次数（可通过 <code>solver_control.last_step()</code> 调用，见步骤4）以及所需的CPU时间（使用Timer类，例如在步骤28中讨论的），得到如下结果（左：迭代次数；右：CPU时间）。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-6.q2.dofs_vs_iterations.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-6.q2.dofs_vs_time.png" alt="">
    </td>
  </tr>
</table> 

我们可以看到，在这个简单的问题上，所有的预处理程序的表现都差不多，迭代次数的增长是 ${\cal
O}(N^{1/2})$ ，由于每次迭代需要大约 ${\cal
O}(N)$ 次操作，总的CPU时间增长是 ${\cal
O}(N^{3/2})$ （对于几个最小的网格，CPU时间小到没有记录）。请注意，尽管它是最简单的方法，但对于这个问题，雅可比是最快的。

当有限元不是本程序构造函数中设定的双二次元，而是双线性的时候，情况会有一些变化。如果做此改变，结果如下。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-6.q1.dofs_vs_iterations.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-6.q1.dofs_vs_time.png" alt="">
    </td>
  </tr>
</table> 

换句话说，虽然迭代次数和CPU时间的增加与以前一样，但Jacobi现在是需要迭代次数最多的方法；不过，由于它必须执行的操作很简单，所以它仍然是最快的方法。这并不是说Jacobi实际上是一个好的预处理方法--对于规模可观的问题来说，它绝对不是，其他方法会好得多--而实际上只是因为它的实现非常简单，可以补偿更多的迭代次数，所以它的速度很快。

从这里得到的信息并不是预处理程序的简单性总是最好的。虽然这对目前的问题可能是正确的，但一旦我们转向更复杂的问题（弹性或斯托克斯，例如第8步或第22步），就绝对不是这样了。其次，所有这些预处理程序仍然会导致迭代次数随着自由度数 $N$ 的增加而增加，例如 ${\cal O}(N^\alpha)$ ；这反过来又会导致总工作量增加为 ${\cal O}(N^{1+\alpha})$ ，因为每次迭代都需要 ${\cal O}(N)$ 的工作。这种行为是不可取的：我们真的希望用 $N$ 个未知数解决线性系统，总工作量为 ${\cal O}(N)$ 个；有一类预处理程序可以实现这一点，即几何（step-16、step-37、step-39）或代数多网格（step-31、step-40和其他几个）预处理程序。然而，它们要比上述的预处理程序复杂得多。

最后，要带回家的最后一个信息是，当上面显示的数据产生时（2018年），有10万个未知数的线性系统在台式机上很容易在大约一秒钟内解决，使相对简单的2d问题的解决甚至达到非常高的精度，甚至在过去也不是一个大任务。当时，三维问题的情况完全不同，但即使是这样，在过去的时间里也发生了很大的变化--尽管在三维中解决高精度的问题仍然是一个挑战。




<h4>A better mesh</h4>

如果你看一下上面的网格，你会发现即使域是单位盘，系数的跳动是沿着圆的，构成网格的单元也不能很好地跟踪这个几何体。原因在步骤1中已经暗示过了，在没有其他信息的情况下，Triangulation类只看到一堆粗略的网格单元，但当然不知道它们在一起看时可能代表什么样的几何形状。出于这个原因，我们需要告诉Triangulation在一个单元被细化时应该做什么：边缘中点和单元中点的新顶点应该位于哪里，以便子单元比父单元更好地代表所需的几何图形。

为了直观地了解三角计算对几何体的实际了解，仅仅输出顶点的位置和为每条边画一条直线是不够的；相反，我们必须将内部线和边界线都输出为多段线，使它们看起来是弯曲的。我们可以通过对 <code>output_results</code> 的gnuplot部分做一个改变来做到这一点。

@code
{
  GridOut       grid_out;
  std::ofstream output("grid-" + std::to_string(cycle) + ".gnuplot");
  GridOutFlags::Gnuplot gnuplot_flags(false, 5, /*curved_interior_cells*/true);
  grid_out.set_flags(gnuplot_flags);
  MappingQGeneric<dim> mapping(3);
  grid_out.write_gnuplot(triangulation, output, &mapping);
}
@endcode



在上面的代码中，我们已经对位于边界的面做了这个处理：由于我们使用了 GridGenerator::hyper_ball, ，它将一个SphericalManifold附着在域的边界上，所以这是自动发生的。为了使网格<i>interior</i>也能追踪到一个圆形域，我们需要更努力一些。首先，回顾一下我们的粗略网格由一个中心的方形单元和周围的四个单元组成。现在首先考虑一下，如果我们不仅将SphericalManifold对象连接到四个外部面，而且还连接到周边的四个单元以及它们的所有面，会发生什么。我们可以通过添加下面的片段来实现（测试一个单元的中心是否大于单元直径的一个小倍数，比如说十分之一，远离网格中心的单元直径，只对网格中心的正方形失效）。

@code
GridGenerator::hyper_ball(triangulation);
// after GridGenerator::hyper_ball is called the Triangulation has
// a SphericalManifold with id 0. We can use it again on the interior.
const Point<dim> mesh_center;
for (const auto &cell : triangulation.active_cell_iterators())
  if (mesh_center.distance (cell->center()) > cell->diameter()/10)
    cell->set_all_manifold_ids(0);


triangulation.refine_global(1);
@endcode



经过几个全局细化的步骤，这将导致以下类型的网格。


  <div class="onecolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_bad_grid_4.svg" alt="一些中央单元格几乎呈三角形的网格。" width="300" height="300"> </div> </div>

这不是一个好的网格：中心单元已经被细化，位于原始中心单元<i>degenerate</i>的四个角的子单元：随着网格细化的继续，它们都倾向于三角形。这意味着从参考单元到实际单元的转换的Jacobian矩阵对这些单元来说是退化的，由于有限元解的所有误差估计都包含Jacobian矩阵的反值，你会在这些单元上得到非常大的误差，而且随着网格细化的极限，收敛顺序的损失，因为这些角落的单元在网格细化下变得越来越差。

所以我们需要更聪明的东西。为此，考虑以下最初由Konstantin Ladutenko开发的解决方案。我们将使用以下代码。

@code
GridGenerator::hyper_ball(triangulation);


const Point<dim> mesh_center;
const double core_radius  = 1.0/5.0,
             inner_radius = 1.0/3.0;


// Step 1: Shrink the inner cell
//
// We cannot get a circle out of the inner cell because of
// the degeneration problem mentioned above. Rather, shrink
// the inner cell to a core radius of 1/5 that stays
// sufficiently far away from the place where the
// coefficient will have a discontinuity and where we want
// to have cell interfaces that actually lie on a circle.
// We do this shrinking by just scaling the location of each
// of the vertices, given that the center of the circle is
// simply the origin of the coordinate system.
for (const auto &cell : triangulation.active_cell_iterators())
  if (mesh_center.distance(cell->center()) < 1e-5)
    {
      for (const auto v : cell->vertex_indices())
        cell->vertex(v) *= core_radius/mesh_center.distance(cell->vertex(v));
    }


// Step 2: Refine all cells except the central one
for (const auto &cell : triangulation.active_cell_iterators())
  if (mesh_center.distance(cell->center()) >= 1e-5)
    cell->set_refine_flag();
triangulation.execute_coarsening_and_refinement();


// Step 3: Resize the inner children of the outer cells
//
// The previous step replaced each of the four outer cells
// by its four children, but the radial distance at which we
// have intersected is not what we want to later refinement
// steps. Consequently, move the vertices that were just
// created in radial direction to a place where we need
// them.
for (const auto &cell : triangulation.active_cell_iterators())
  for (const auto v : cell->vertex_indices())
    {
      const double dist = mesh_center.distance(cell->vertex(v));
      if (dist > core_radius*1.0001 && dist < 0.9999)
        cell->vertex(v) *= inner_radius/dist;
    }


// Step 4: Apply curved manifold description
//
// As discussed above, we can not expect to subdivide the
// inner four cells (or their faces) onto concentric rings,
// but we can do so for all other cells that are located
// outside the inner radius. To this end, we loop over all
// cells and determine whether it is in this zone. If it
// isn't, then we set the manifold description of the cell
// and all of its bounding faces to the one that describes
// the spherical manifold already introduced above and that
// will be used for all further mesh refinement.
for (const auto &cell : triangulation.active_cell_iterators())
  {
    bool is_in_inner_circle = false;
    for (const auto v : cell->vertex_indices())
      if (mesh_center.distance(cell->vertex(v)) < inner_radius)
        {
          is_in_inner_circle = true;
          break;
        }


    if (is_in_inner_circle == false)
    // The Triangulation already has a SphericalManifold with
    // manifold id 0 (see the documentation of
    // GridGenerator::hyper_ball) so we just attach it to the outer
    // ring here:
      cell->set_all_manifold_ids(0);
  }
@endcode



然后，这段代码生成了以下更好的网格序列。

<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_0_ladutenko.svg" alt="初始网格：带有一个全局细化的Ladutenko网格。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_1_ladutenko.svg" alt="第一个自适应细化的Ladutenko网格。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_2_ladutenko.svg" alt="第二个自适应细化的Ladutenko网格。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_3_ladutenko.svg" alt="第三个自适应细化Ladutenko网格。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_4_ladutenko.svg" alt="第四个自适应细化Ladutenko网格。细胞沿着内圈聚集。" width="300" height="300"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step_6_grid_5_ladutenko.svg" alt="第五个自适应改进的拉杜腾科网格：细胞沿着内圈聚集。" width="300" height="300"> </div> </div>

创建好的网格，特别是使它们适合你想要的几何形状，本身就是一个复杂的话题。你可以在步骤49、步骤53和步骤54中找到更多关于这个问题的内容，以及其他涉及这个问题的教程程序。步骤65展示了另一个不那么手动的方法来实现一个很适合这里的问题的网格。关于弯曲域的信息也可以在 @ref manifold "流形描述 "的文档模块中找到。

为什么选择一个跟踪内部界面的网格是有意义的？有很多原因，但最重要的原因是我们在双线性表格中实际整合的内容。从概念上讲，我们想把 $A_{ij}^K=\int_K
a(\mathbf x) \nabla \varphi_i(\mathbf x) \nabla \varphi_j(\mathbf x) ; dx$ 作为单元格 $K$ 对矩阵条目 $A_{ij}$ 的贡献来整合。我们无法精确计算，只能求助于正交法。我们知道，如果积分是平滑的，正交是准确的。这是因为正交法实质上是计算积分的多项式近似值，与积分在正交点上重合，然后计算这个多项式下的体积，作为原始积分下体积的近似值。如果积分在一个单元上是平滑的，这个多项式插值是准确的，但如果积分在一个单元上是不连续的，它通常是相当不准确的。

因此，值得将细胞排列成这样的方式，使系数不连续的界面与细胞界面对齐。这样一来，系数在每个单元上都是恒定的，之后积分将是平滑的，其多项式近似和积分的正交近似都将是准确的。请注意，这样的排列方式在许多实际案例中很常见，因此deal.II提供了一些函数（如 @ref GlossMaterialId "material_id"）来帮助管理这种情况。请参考步骤28和步骤46，了解如何应用material ids的例子。

最后，让我们考虑一个在空间中具有平滑和非均匀分布的系数的情况。我们可以再一次重复上面关于用正交法表示这种函数的所有讨论。所以，为了准确地模拟它，有几个现成的选择：你可以减少单元格的大小，增加正交公式中使用的多项式的阶数，选择一个更合适的正交公式，或进行这些步骤的组合。关键是，用正交多项式提供系数的空间依赖性的最佳拟合将导致PDE的更精确的有限元解。

最后说明一下：前面几段的讨论表明，我们在这里有一种非常具体的方式来说明我们认为的好的网格--它应该与系数中的跳跃相一致。但人们也可以在一个更普遍的环境中提出这样的问题。给定一些具有光滑解和光滑系数的方程，我们能说一个好的网格是什么样子的吗？这个问题的答案在直觉上比数学上更容易表述。一个好的网格，其单元格大体上都像正方形（或立方体，在三维空间）。一个不好的网格会包含一些在某些方向上非常细长的单元，或者，更广泛地说，其中有一些单元的边缘既短又长。有很多方法可以给每个单元分配一个数字质量指数，以衡量该单元是 "好 "还是 "坏"；其中一些经常被选择，因为它们便宜且容易计算，而另一些则是基于收敛性证明中的内容。前者的一个例子是一个单元格的最长边与最短边的比率。在理想的情况下，这个比率是1；不好的单元格的值远远大于1。后者的例子是考虑从参考单元 $\hat K=[0,1]^d$ 到实际单元 $K$ 的映射的梯度（"Jacobian"）；这个梯度是一个矩阵，进入误差估计的一个量是参考单元上所有点的最大值，即这个矩阵的最大和最小的特征值的比率。同样不难看出，如果单元格 $K$ 是 $\hat K$ 的仿生图像，这个比率是恒定的，对于正方形和长方体来说是一个。

在实践中，将这种质量衡量标准可视化可能是很有趣的。函数 GridTools::compute_aspect_ratio_of_cells() 提供了一种获得这种信息的方法。更好的是，可视化工具，如VisIt，通常允许你在可视化软件中对各种措施进行可视化；在VisIt的情况下，只需添加一个 "伪色 "图，并选择一个网格质量措施，而不是解决方案领域。




<h4>Playing with the regularity of the solution</h4>

从数学的角度来看，拉普拉斯方程的解决方案

@f[


  -\Delta u = f


@f]

在光滑有界的凸域上，已知其本身是光滑的。确切的光滑程度，即解所处的函数空间，取决于域的边界到底有多光滑，以及右手边的光滑程度。边界处可能会失去解的某些规律性，但一般来说，在域的紧凑子集中，解的可微性比右手边多一倍。特别是如果右手边满足 $f\in C^\infty(\Omega)$ ，那么 $u \in C^\infty(\Omega_i)$ ，其中 $\Omega_i$ 是 $\Omega$ 的任何紧凑子集（ $\Omega$ 是一个开放域，所以紧凑子集需要与 $\partial\Omega$ 保持一个正距离）。

然而，我们为目前的例子选择的情况是不同的：我们看的是一个具有非常数系数的方程  $a(\mathbf x)$  。

@f[


  -\nabla \cdot (a \nabla u) = f.


@f]

这里，如果 $a$ 不光滑，那么无论 $f$ 如何，解也不会光滑。特别是，我们希望在 $a$ 沿直线（或沿三维平面）不连续的地方，解会有一个结点。这很容易看出来：例如，如果 $f$ 是连续的，那么 $f=-\nabla \cdot (a \nabla u)$ 也需要是连续的。这意味着 $a \nabla u$ 必须是可连续微分的（不存在扭结）。因此，如果 $a$ 有一个不连续，那么 $\nabla u$ 必须有一个相反的不连续，从而使两者完全抵消，它们的乘积得到一个没有不连续的函数。但是要使 $\nabla u$ 有一个不连续， $u$ 必须有一个结点。当然，这正是当前例子中所发生的情况，在解的图片中也很容易观察到。

一般来说，如果系数 $a(\mathbf x)$ 沿着2D的直线或3D的平面是不连续的，那么解可能有一个结点，但解的梯度不会到无限大。这意味着，解至少还在<a href="https://en.wikipedia.org/wiki/Sobolev_space">Sobolev space</a> $W^{1,\infty}$ 中（也就是说，大致上是在导数有界的函数空间中）。另一方面，我们知道，在最极端的情况下--即域有重入角，右手边只满足 $f\in H^{-1}$ ，或者系数 $a$ 只在 $L^\infty$ 中--我们所能期望的是， $u\in H^1$ （即导数是可平方整除的函数的<a
href="https://en.wikipedia.org/wiki/Sobolev_space#Sobolev_spaces_with_integer_k">Sobolev
space</a>），是比 $W^{1,\infty}$ 大很多的空间 。要创造出解在空间 $H^{1+s}$ 中的案例并不十分困难，我们可以让 $s$ 变得像我们想要的那样小。这样的情况经常被用来测试自适应有限元方法，因为网格要解决导致解不再在 $W^{1,\infty}$ 中的奇异点。

人们为此使用的典型例子叫做<i>Kellogg problem</i>（指 @cite Kel74 ），在常用的形式中，它的系数 $a(\mathbf x)$ 在平面的四个象限有不同的值（或在 ${\mathbb R}^3$ 的八个象限有不同的值）。确切的规则性程度（上述索博列夫空间索引中的 $s$ ）取决于 $a(\mathbf x)$ 的值在原点处聚集，通过选择足够大的跳跃，可以使解的规则性尽可能地接近 $H^1$  。

为了实现这样的东西，可以用以下方法来代替系数函数（这里只显示2d情况）。

@code
template <int dim>
double coefficient (const Point<dim> &p)
{
  if ((p[0] < 0) && (p[1] < 0))           // lower left quadrant
    return 1;
  else if ((p[0] >= 0) && (p[1] < 0))     // lower right quadrant
    return 10;
  else if ((p[0] < 0) && (p[1] >= 0))     // upper left quadrant
    return 100;
  else if ((p[0] >= 0) && (p[1] >= 0))    // upper right quadrant
    return 1000;
  else
    {
      Assert(false, ExcInternalError());
      return 0;
    }
}
@endcode

(在结尾处添加 <code>Assert</code> ，以确保在我们到达那个点时，要么抛出一个异常，要么程序中止。

--当然我们不应该这样做，但这是给自己上保险的好方法：我们都会犯错，因为有时没有想到所有的情况，例如检查 <code>p[0]</code> 是否小于和大于零，而不是大于或等于零，从而忘记了一些情况，否则会导致难以发现的错误。最后的 <code>return 0;</code> 只是为了避免编译器警告说函数没有在 <code>return</code> 语句中结束 -- 编译器无法看到由于前面的 <code>Assert</code> 语句，函数实际上永远不会到达那个点）。)

通过玩弄这种四个或更多的扇形聚集在一起，并且在这些扇形上的系数有不同的值的情况，我们可以构造出解在原点有奇异点的情况。我们还可以看到在这种情况下网格是如何被细化的。


examples/step-60/doc/intro.dox

 <br> 

<i>This program was contributed by Luca Heltai and Giovanni Alzetta, SISSA, Trieste.
</i>

 @dealiiTutorialDOI{10.5281/zenodo.1243280,https://zenodo.org/badge/DOI/10.5281/zenodo.1243280.svg} 




<h1>Introduction</h1>

<h3>Non-matching grid constraints through distributed Lagrange multipliers</h3>


在本教程中，我们考虑两个域的情况， $\Omega$ 在 $R^{\text{spacedim}}$ 和 $\Gamma$ 在 $R^{\text{dim}}$ ，其中 $\Gamma$ 嵌入在 $\Omega$ （ $\Gamma \subseteq \Omega$  ）。我们想在 $\Omega$ 上解决一个偏微分方程，对问题的解决*在嵌入域* $\Gamma$ 上强制执行一些条件。

有两种有趣的情况。

- 嵌入域 $\Gamma$ 的几何维度`dim`与域 $\Omega$ 相同（`spacedim`），也就是说， $\Gamma$ 的spacedim维度不为零，或

- 嵌入域 $\Gamma$ 的内在维度`dim`小于 $\Omega$ 的维度（`spacedim`），因此其spacedim维度为零；例如，它是一条嵌入二维域的曲线，或一个嵌入三维域的曲面。

在这两种情况下，定义限制算子 $\gamma$ 为算子，给定 $\Omega$ 上的一个连续函数，返回其在 $\Gamma$ 上的（连续）限制，即：。

\f[
\gamma : C^0(\Omega) \mapsto C^0(\Gamma), \quad \text{ s.t. } \gamma u = u|_{\Gamma} \in C^0(\Gamma),
\quad \forall u \in C^0(\Omega).
\f]

众所周知，当 $\gamma$ 的内在维度与 $\Omega$ 相同时，算子 $\gamma$ 可以扩展为 $H^1(\Omega)$ 上的连续算子，将 $H^1(\Omega)$ 的函数映射为 $H^1(\Gamma)$ 的函数。

同样的道理，在一个不太规则的范围空间（即 $H^{1/2}(\Gamma)$ ）中，当 $\Gamma$ 的维度相对于 $\Omega$ 少一个，并且 $\Gamma$ 没有边界。在这第二种情况下，算子 $\gamma$ 也被称为*轨迹*算子，对于嵌入 $\Omega$ 中的Lipschitz同维度曲线和曲面 $\Gamma$ ，它有很好的定义（阅读<a
href="https://en.wikipedia.org/wiki/Trace_operator">this wikipedia article</a>了解关于轨迹算子的进一步细节）。

同维度的情况要复杂一些，一般来说，不可能构造一个连续的跟踪算子，甚至不可能从 $H^1(\Omega)$ 到 $L^2(\Gamma)$ ，当 $\Gamma$ 的维度在二维和三维中分别为零或一的时候。

在本教程中，我们对 $\gamma$ 的进一步细节不感兴趣：我们认为扩展 $\gamma$ 是理所当然的，假设嵌入域的尺寸（`dim`）总是比嵌入域的尺寸（`spacedim`）小一或相等。

我们要解决以下微分问题：给定 $g$ 上的一个足够规则的函数 $\Gamma$ ，找到 $u$ 的解。

@f{eqnarray*}{


- \Delta u + \gamma^T \lambda &=& 0  \text{ in } \Omega\\
\gamma u &=& g  \text{ in } \Gamma \\
u & = & 0 \text{ on } \partial\Omega.


@f}



这是一个约束问题，我们正在寻找一个谐波函数 $u$ ，满足 $\partial\Omega$ 上的同质边界条件，受制于使用拉格朗日乘法器的约束 $\gamma u = g$ 。

这个问题有一个物理解释：谐波函数，即满足拉普拉斯方程的函数，可以被认为是边界值被规定的膜的位移。那么，目前的情况相当于找到一个膜的形状，对于这个膜来说，不仅边界上的位移，而且 $\Gamma$ 上的位移也是规定的。例如，如果 $\Gamma$ 是二维空间中的一条封闭曲线，那么这将是一个肥皂膜的模型，它被沿 $\partial \Omega$ 的一个线环以及沿 $\Gamma$ 的第二个线环固定住。在 $\Gamma$ 是整个区域的情况下，你可以把它看成是在障碍物上伸展的膜，其中 $\Gamma$ 是接触区域。如果接触面积不知道，我们就有一个不同的问题--称为 "障碍物问题"--在步骤41中进行建模）。

作为第一个例子，我们研究 $\partial\Omega$ 上的零迪里切特边界条件。如果我们在 $\partial\Omega$ 上应用零诺伊曼边界条件或两者的混合，同样的方程也适用。

通过引入两个无限维空间 $V(\Omega)$ 和 $Q^*(\Gamma)$ ，可以得出变分公式，分别用于解 $u$ 和拉格朗日乘子 $\lambda$ 。

将第一个方程乘以 $v \in V(\Omega)$ ，第二个方程乘以 $q \in
Q(\Gamma)$ ，在可能的情况下进行部分积分，并利用 $\partial\Omega$ 的边界条件，我们得到以下变量问题。

给出 $g$ 上的一个足够规则的函数 $\Gamma$ ，求 $u$ 的解

@f{eqnarray*}{
(\nabla u, \nabla v)_{\Omega} + (\lambda, \gamma v)_{\Gamma} &=& 0 \qquad \forall v \in V(\Omega) \\
(\gamma u, q)_{\Gamma} &=& (g,q)_{\Gamma} \qquad \forall q \in Q(\Gamma),


@f}



其中 $(\cdot, \cdot)_{\Omega}$ 和 $(\cdot, \cdot)_{\Gamma}$ 分别代表 $L^2$ 中的标量积和 $\Gamma$ 中的标量积 。

对变量公式的检查告诉我们，空间 $V(\Omega)$ 可以被认为是 $H^1_0(\Omega)$ 。空间 $Q(\Gamma)$ ，在同维度为零的情况下，应取为 $H^1(\Gamma)$ ，而在同维度为一的情况下应取为 $H^{1/2}(\Gamma)$ 。

因此函数 $g$ 应该在 $H^1(\Gamma)$ （对于同维度零的情况）或者 $H^{1/2}(\Gamma)$ （对于同维度一的情况）。这使得我们在 $Q^*(\Gamma)$ 中有一个拉格朗日乘数 $\lambda$ ，它是 $H^{-1}(\Gamma)$ 或 $H^{-1/2}(\Gamma)$ 。

对于上述问题的离散化，有两种选择。可以选择匹配的离散化，即 $\Gamma$ 的三角化与 $\Omega$ 的三角化一致，也可以选择以完全独立的方式离散化这两个域。

对于我们上面提出的简单问题，第一种选择显然更有意义：对 $\Omega$ 使用一个单一的三角形就足够了，然后根据 $\Gamma$ 施加某些约束。在步骤40中研究了这种方法的一个例子，解决方案必须保持在一个障碍物之上，这是在 $\Omega$ 上施加约束实现的。

为了解决更复杂的问题，例如域 $\Gamma$ 与时间有关的问题，第二个选项可能是一个更可行的解决方案。处理不对齐的网格本身就很复杂：为了说明如何做，我们研究一个简单的问题。

我们在此描述的技术在文献中使用了许多名称之一：<b>immersed finite element method</b>、<b>fictitious boundary method</b>、<b>distributed Lagrange multiplier method</b>等。其主要原理是，两个网格的离散化和两个有限元空间的离散化保持完整。完全独立。这种技术对于模拟流体与结构的相互作用问题特别有效，其中嵌入结构的配置是问题本身的一部分，人们要解决一个（可能是非线性）弹性问题，以确定 $\Gamma$ 的（与时间有关的）配置，以及 $\Omega
\setminus \Gamma$ 的（可能是非线性）流动问题，加上流体和固体之间界面上的耦合条件。

在这个教程程序中，我们把事情弄得简单一些，我们假设嵌入式领域的配置是以两种可能的方式之一给出的。

- 作为一个变形映射 $\psi: \Gamma_0 \mapsto \Gamma \subseteq \Omega$ ，定义在 $\Gamma_0$ 的连续有限维空间上，对于任何一个点 $x \in \Gamma_0$ ，代表其在 $\Omega$ 的坐标 $\psi(x)$ 。

- 作为 $x\in \Gamma_0$ 的位移映射 $\delta \psi(x) = \psi(x)-x$ ，代表任何一点 $x$ 的位移矢量，以使 $x$ 变形为其实际配置 $\psi(x) = x +\delta\psi(x)$ 。

我们定义嵌入式参考域 $\Gamma_0$  `embedded_grid`：在这个三角形上，我们构建一个有限维空间（`embedded_configuration_dh`），通过FE_Q对象的有限元系统（`embedded_configuration_fe`）描述变形或位移。这个有限维度空间仅用于插值用户提供的函数（`embedded_configuration_function`），代表 $\psi$ （如果参数`use_displacement`被设置为 @p false) 或 $\delta\psi$ （如果参数`use_displacement`被设置为 @p true). 

拉格朗日乘数 $\lambda$ 和用户提供的函数 $g$ 是通过另一个有限维度空间`embedded_dh`和另一个有限元素`embedded_fe`定义的，使用相同的参考域。为了考虑到域的变形，MappingFEField或MappingQEulerian对象被初始化为`embedded_configuration`向量。

在嵌入空间中，一个标准的有限维空间`space_dh`被构建在嵌入网格`space_grid`上，使用有限元素`space_fe`，几乎逐字逐句地遵循步骤6中的方法。

我们用以下方法表示空间 $V$ 和 $Q$ 的离散化

\f[
V_h(\Omega) = \text{span} \{v_i\}_{i=1}^n
\f] 和

\f[
Q_h(\Gamma) = \text{span} \{q_i\}_{i=1}^m
\f]，其中 $n$ 是`空间_dh`的尺寸， $m$ 是`嵌入_dh`的尺寸。

一旦所有的有限维空间都被定义，上述问题的变异表述给我们留下了以下有限维方程组。

\f[
\begin{pmatrix}
K & C^T \\
C & 0
\end{pmatrix}
\begin{pmatrix}
u \\
\lambda
\end{pmatrix}
=
\begin{pmatrix}
0 \\
G
\end{pmatrix}
\f]

其中

@f{eqnarray*}{
K_{ij} &\dealcoloneq& (\nabla v_j, \nabla v_i)_\Omega   \qquad i,j=1,\dots,n \\
C_{\alpha j} &\dealcoloneq& (v_j, q_\alpha)_\Gamma  \qquad j=1,\dots,n, \alpha = 1,\dots, m \\\\
G_{\alpha} &\dealcoloneq& (g, q_\alpha)_\Gamma \qquad \alpha = 1,\dots, m.


@f}



虽然矩阵 $K$ 是 $\Omega$ 上泊松问题的标准刚度矩阵，而向量 $G$ 是 $g$ 上带有强制项的有限元问题的标准右手向量。矩阵 $C$ 或其转置 $C^T$ 是非标准的，因为它们是两个不匹配的网格上的信息。

特别是，在计算 $C$ 的一个条目时出现的积分，是在 $\Gamma$ 上计算的。在有限元中，我们通常将这个积分分成来自用于离散化 $\Gamma$ 的三角形的所有单元的贡献，我们将 $K$ 上的积分转换为参考元素 $\hat K$ 上的积分，其中 $F_{K}$ 是从 $\hat K$ 到 $K$ 的映射，并且使用正交公式计算 $\hat K$ 上的积分。

\f[
C_{\alpha j} \dealcoloneq (v_j, q_\alpha)_\Gamma  = \sum_{K\in \Gamma} \int_{\hat K}
\hat q_\alpha(\hat x) (v_j \circ F_{K}) (\hat x) J_K (\hat x) \mathrm{d} \hat x =
\sum_{K\in \Gamma} \sum_{i=1}^{n_q}  \big(\hat q_\alpha(\hat x_i)  (v_j \circ F_{K}) (\hat x_i) J_K (\hat x_i) w_i \big)
\f]

计算这个和是不容易的，因为我们必须评估 $(v_j \circ F_{K})
(\hat x_i)$  。一般来说，如果 $\Gamma$ 和 $\Omega$ 没有对齐，那么 $F_{K}(\hat x_i)$ 这个点相对于 $\Omega$ 来说是完全任意的，除非我们想出一个办法，在 $\Omega$ 上的任意点上插值 $V_h(\Omega)$ 的所有基函数，否则我们无法计算出矩阵 $C$ 的一个条目需要的积分。

要评估 $(v_j \circ F_{K}) (\hat x_i)$ ，需要采取以下步骤（如下图所示）。

- 对于 $\Gamma$ 中的一个给定单元 $K$ ，计算实点 $y_i \dealcoloneq F_{K} (\hat
x_i)$ ，其中 $x_i$ 是用于 $K
\subseteq \Gamma$ 上的积分的正交点之一。

- 找到 $\Omega$ 中 $y_i$ 所在的单元。我们将称这个元素为 $T$  。

- 为了评估基函数，使用映射 $G_T$ 的逆映射，将参考元素 $\hat T$ 转换为元素 $T$  :  $v_j(y_i) = \hat
v_j \circ G^{-1}_{T} (y_i)$  。

<p align="center"> <img src="https://www.dealii.org/images/steps/developer/step-60.C_interpolation.png" alt="">  </p> 

上述三个步骤可以通过依次调用来计算。

-  GridTools::find_active_cell_around_point(),  后面是

-  Mapping::transform_real_to_unit_cell().  然后我们

- 构建一个自定义的正交公式，包含参考单元格中的点，然后

- 构建一个FEValues对象，具有给定的正交公式，并以第一步中获得的单元格为初始化。

这就是deal.II函数 VectorTools::point_value() 在任意点上评估有限元场（而不仅仅是单个形状函数）时的做法；但在这种情况下，这将是低效的。

一个更好的解决方案是使用一个方便的包装器来对一个点的集合执行前三个步骤。   GridTools::compute_point_locations(). 如果人们实际上对计算完整的耦合矩阵感兴趣，那么可以调用方法 NonMatching::create_coupling_mass_matrix(), ，该方法以有效的方式执行上述步骤，重复使用所有可能的数据结构，并将昂贵的步骤聚集在一起。这就是我们在本教程后面要使用的函数。

我们通过迭代求解器来解决最终的鞍点问题，应用于Schur补数 $S$ （其构造例如在步骤20中描述），我们使用LinearOperator类构造 $S$ 。




<h3>The testcase</h3>

我们在这里解决的问题与步骤4相同，不同的是我们对一个嵌入域施加了一些约束  $\Gamma$  。该教程是以独立于维度的方式编写的，在结果部分我们展示了如何改变`dim`和`spacedim`。

本教程是为`dim`等于1和`spacedim`等于2而编译的。如果你想在嵌入维度`spacedim`等于3的情况下运行程序，你很可能想改变 $\Gamma$ 的参考域，例如，你从文件中读到的东西，或者你后来变形为更有趣的封闭球体。

在默认情况下， $\Gamma$ 的共维为1，本教程程序实现的是虚构边界法。事实证明，同样的技术也用在了变量沉浸式有限元方法中，上面定义的耦合算子 $C$ 在几乎所有这些非匹配方法中都是一样的。

嵌入域被假定包括在 $\Omega$ 中，我们把它当作单位平方 $[0,1]^2$ 。虚域 $\Gamma$ 的定义可以通过参数文件修改，可以给出从参考区间 $[0,1]$ 到 $\Omega$ 中的一条曲线的映射。

如果曲线是封闭的，那么结果将类似于在边界为 $\Gamma$ 的网格上运行同一问题。在非封闭的 $\Gamma$ 的情况下，程序也能愉快地运行，尽管在这些情况下，问题的数学表述更加困难，因为 $\Gamma$ 本身就有一个边界，相对于域 $\Omega$ 来说是二维的。




<h3>References</h3>

 <ul>   <li>  Glowinski, R., T.-W.Pan, T.I. Hesla, and D.D. Joseph.1999."分布式拉格朗日乘数/虚构域方法用于颗粒物流"。   International Journal of Multiphase Flow 25 (5).Pergamon: 755-94.

 <li>  Boffi, D., L. Gastaldi, L. Heltai, and C.S. Peskin。2008."关于沉浸边界法的超弹性公式"。应用力学和工程中的计算机方法197（25-28）。

 <li>  Heltai, L., and F. Costanzo.2012."浸没式有限元方法的变量实现"。应用力学和工程中的计算机方法》229-232。   </ul> 


examples/step-60/doc/results.dox



<h1>Results</h1>

运行该程序的目录中默认不包含参数文件。另一方面，这个程序想从一个叫parameters.prm的文件中读取它的参数 -- 因此，当你第一次执行它时，你会得到一个异常，即找不到这样的文件。

@code


----------------------------------------------------
Exception on processing:


--------------------------------------------------------
An error occurred in line <74> of file <../source/base/parameter_acceptor.cc> in function
    static void dealii::ParameterAcceptor::initialize(const std::string &, const std::string &, const ParameterHandler::OutputStyle, dealii::ParameterHandler &)
The violated condition was:
    false
Additional information:
    You specified <parameters.prm> as input parameter file, but it does not exist. We created it for you.


--------------------------------------------------------


Aborting!


----------------------------------------------------
@endcode



然而，正如错误信息已经指出的那样，触发该异常的代码也将生成一个参数.prm文件，该文件仅仅包含该程序所关心的所有参数的默认值。通过对参数文件的检查，我们看到以下内容。

@code
# Listing of Parameters
# ---------------------
subsection Distributed Lagrange<1,2>
  set Coupling quadrature order                    = 3
  set Embedded configuration finite element degree = 1
  set Embedded space finite element degree         = 1
  set Embedding space finite element degree        = 1
  set Homogeneous Dirichlet boundary ids           = 0, 1, 2, 3
  set Initial embedded space refinement            = 7
  set Initial embedding space refinement           = 4
  set Local refinements steps near embedded domain = 3
  set Use displacement in embedded interface       = false
  set Verbosity level                              = 10



  subsection Embedded configuration
    # Sometimes it is convenient to use symbolic constants in the expression
    # that describes the function, rather than having to use its numeric value
    # everywhere the constant appears. These values can be defined using this
    # parameter, in the form `var1=value1, var2=value2, ...'.
    #
    # A typical example would be to set this runtime parameter to
    # `pi=3.1415926536' and then use `pi' in the expression of the actual
    # formula. (That said, for convenience this class actually defines both
    # `pi' and `Pi' by default, but you get the idea.)
    set Function constants  = R=.3, Cx=.4, Cy=.4                 # default:


    # The formula that denotes the function you want to evaluate for
    # particular values of the independent variables. This expression may
    # contain any of the usual operations such as addition or multiplication,
    # as well as all of the common functions such as `sin' or `cos'. In
    # addition, it may contain expressions like `if(x>0, 1, -1)' where the
    # expression evaluates to the second argument if the first argument is
    # true, and to the third argument otherwise. For a full overview of
    # possible expressions accepted see the documentation of the muparser
    # library at http://muparser.beltoforion.de/.
    #
    # If the function you are describing represents a vector-valued function
    # with multiple components, then separate the expressions for individual
    # components by a semicolon.
    set Function expression = R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy # default: 0


    # The names of the variables as they will be used in the function,
    # separated by commas. By default, the names of variables at which the
    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in
    # 3d) for spatial coordinates and `t' for time. You can then use these
    # variable names in your function expression and they will be replaced by
    # the values of these variables at which the function is currently
    # evaluated. However, you can also choose a different set of names for the
    # independent variables at which to evaluate your function expression. For
    # example, if you work in spherical coordinates, you may wish to set this
    # input parameter to `r,phi,theta,t' and then use these variable names in
    # your function expression.
    set Variable names      = x,y,t
  end


  subsection Embedded value
    # Sometimes it is convenient to use symbolic constants in the expression
    # that describes the function, rather than having to use its numeric value
    # everywhere the constant appears. These values can be defined using this
    # parameter, in the form `var1=value1, var2=value2, ...'.
    #
    # A typical example would be to set this runtime parameter to
    # `pi=3.1415926536' and then use `pi' in the expression of the actual
    # formula. (That said, for convenience this class actually defines both
    # `pi' and `Pi' by default, but you get the idea.)
    set Function constants  =


    # The formula that denotes the function you want to evaluate for
    # particular values of the independent variables. This expression may
    # contain any of the usual operations such as addition or multiplication,
    # as well as all of the common functions such as `sin' or `cos'. In
    # addition, it may contain expressions like `if(x>0, 1, -1)' where the
    # expression evaluates to the second argument if the first argument is
    # true, and to the third argument otherwise. For a full overview of
    # possible expressions accepted see the documentation of the muparser
    # library at http://muparser.beltoforion.de/.
    #
    # If the function you are describing represents a vector-valued function
    # with multiple components, then separate the expressions for individual
    # components by a semicolon.
    set Function expression = 1     # default: 0


    # The names of the variables as they will be used in the function,
    # separated by commas. By default, the names of variables at which the
    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in
    # 3d) for spatial coordinates and `t' for time. You can then use these
    # variable names in your function expression and they will be replaced by
    # the values of these variables at which the function is currently
    # evaluated. However, you can also choose a different set of names for the
    # independent variables at which to evaluate your function expression. For
    # example, if you work in spherical coordinates, you may wish to set this
    # input parameter to `r,phi,theta,t' and then use these variable names in
    # your function expression.
    set Variable names      = x,y,t
  end


  subsection Schur solver control
    set Log frequency = 1
    set Log history   = false
    set Log result    = true
    set Max steps     = 1000   # default: 100
    set Reduction     = 1.e-12 # default: 1.e-2
    set Tolerance     = 1.e-12 # default: 1.e-10
  end


end
@endcode



如果你现在运行该程序，你将得到一个名为`used_parameters.prm`的文件，其中包含上述参数的简短版本（没有注释和文档），记录了所有用于运行你的程序的参数。

@code
# Parameter file generated with
# DEAL_II_PACKAGE_VERSION = 9.0.0
subsection Distributed Lagrange<1,2>
  set Coupling quadrature order                    = 3
  set Embedded configuration finite element degree = 1
  set Embedded space finite element degree         = 1
  set Embedding space finite element degree        = 1
  set Homogeneous Dirichlet boundary ids           = 0, 1, 2, 3
  set Initial embedded space refinement            = 7
  set Initial embedding space refinement           = 4
  set Local refinements steps near embedded domain = 3
  set Use displacement in embedded interface       = false
  set Verbosity level                              = 10
  subsection Embedded configuration
    set Function constants  = R=.3, Cx=.4, Cy=.4
    set Function expression = R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy
    set Variable names      = x,y,t
  end
  subsection Embedded value
    set Function constants  =
    set Function expression = 1
    set Variable names      = x,y,t
  end
  subsection Schur solver control
    set Log frequency = 1
    set Log history   = false
    set Log result    = true
    set Max steps     = 1000
    set Reduction     = 1.e-12
    set Tolerance     = 1.e-12
  end
end
@endcode



首先创建`parameters.prm`文件（第一次运行程序），然后创建`used_parameters.prm`（每隔一段时间运行程序），其理由是你可能想让大多数参数保持默认值，而只修改其中的一小部分。

例如，你可以在这个教程程序中使用以下（完全有效的）参数文件。

@code
subsection Distributed Lagrange<1,2>
  set Initial embedded space refinement            = 7
  set Initial embedding space refinement           = 4
  set Local refinements steps near embedded domain = 3
  subsection Embedded configuration
    set Function constants  = R=.3, Cx=.4, Cy=.4
    set Function expression = R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy
    set Variable names      = x,y,t
  end
  subsection Embedded value
    set Function constants  =
    set Function expression = 1
    set Variable names      = x,y,t
  end
end
@endcode



你会得到与下面测试案例1完全相同的结果。

<h3> Test case 1: </h3>

对于默认问题， $u$ 在 $\Gamma$ 上的值被设置为常数 $1$ ：这就像在 $\Gamma$ 上施加了一个常数迪里希特边界条件，被视为 $\Omega$ 在 $\Gamma$ 内的部分的边界。同样，在 $\partial
\Omega$ 上，我们有零的迪里切特边界条件。


<div class="twocolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-60.1_no_grid.png" alt = "" width="500"> </div> </div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-60.1_grid.png" alt = "" width="500"> </div> </div></div>

程序的输出将如下所示。

@code
DEAL::Embedded dofs: 129
DEAL::Embedding minimal diameter: 0.0110485, embedded maximal diameter: 0.00781250, ratio: 0.707107
DEAL::Embedding dofs: 2429
DEAL:cg::Starting value 0.166266
DEAL:cg::Convergence step 108 value 7.65958e-13



+---------------------------------------------+------------+------------+
| Total CPU time elapsed since start          |     0.586s |            |
|                                             |            |            |
| Section                         | no. calls |  CPU time  | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble coupling system        |         1 |     0.132s |        23% |
| Assemble system                 |         1 |    0.0733s |        12% |
| Output results                  |         1 |     0.087s |        15% |
| Setup coupling                  |         1 |    0.0244s |       4.2% |
| Setup grids and dofs            |         1 |    0.0907s |        15% |
| Solve system                    |         1 |     0.178s |        30% |
+---------------------------------+-----------+------------+------------+





+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.301s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble coupling system        |         1 |    0.0385s |        13% |
| Assemble system                 |         1 |    0.0131s |       4.3% |
| Output results                  |         1 |    0.0736s |        24% |
| Setup coupling                  |         1 |    0.0234s |       7.7% |
| Setup grids and dofs            |         1 |    0.0679s |        23% |
| Solve system                    |         1 |    0.0832s |        28% |
+---------------------------------+-----------+------------+------------+


@endcode



你可能会注意到，就CPU时间而言，组装耦合系统的成本是组装标准泊松系统的两倍，尽管矩阵更小。这是由于离散化的非匹配性造成的。这是否可以接受，取决于应用。

如果问题被设置在三维环境中，并且浸入式网格与时间有关，那么在每一步重新创建网格要比使用我们这里介绍的技术要昂贵得多。此外，你也许可以在一个均匀细化的正方形或立方体网格上创建一个非常快速和优化的求解器，并在你想进行计算的地方嵌入这里的技术。这就要求你只需要有一个领域的表面代表（一个更便宜和更容易制作的网格）。

为了玩一玩，我们要把虚构的领域以及我们强加给它的边界条件复杂化一点。

<h3> Test case 2 and 3: </h3>

如果我们使用以下参数文件。

@code
subsection Distributed Lagrange<1,2>
  set Coupling quadrature order                    = 3
  set Embedded configuration finite element degree = 1
  set Embedded space finite element degree         = 1
  set Embedding space finite element degree        = 1
  set Homogeneous Dirichlet boundary ids           = 0,1,2,3
  set Initial embedded space refinement            = 8
  set Initial embedding space refinement           = 4
  set Local refinements steps near embedded domain = 4
  set Use displacement in embedded interface       = false
  set Verbosity level                              = 10
  subsection Embedded configuration
    set Function constants  = R=.3, Cx=.5, Cy=.5, r=.1, w=12
    set Function expression = (R+r*cos(w*pi*x))*cos(2*pi*x)+Cx; (R+r*cos(w*pi*x))*sin(2*pi*x)+Cy
    set Variable names      = x,y,t
  end
  subsection Embedded value
    set Function constants  =
    set Function expression = x-.5
    set Variable names      = x,y,t
  end
  subsection Schur solver control
    set Log frequency = 1
    set Log history   = false
    set Log result    = true
    set Max steps     = 100000
    set Reduction     = 1.e-12
    set Tolerance     = 1.e-12
  end
end
@endcode



我们得到了一个看起来很 "花 "的域，在这里我们施加了一个线性边界条件  $g=x-.5$  。这个测试表明，该方法在从边界条件中恢复一个完全线性的函数方面实际上是相当准确的，即使网格没有对齐，我们也得到了一个相当好的结果。

用 $2(x-.5)^2-2(y-.5)^2$ 替换 $x-.5$ ，即修改参数文件，使我们有

@code
  ...
  subsection Embedded value
    set Function constants  =
    set Function expression = 2*(x-.5)^2-2*(y-.5)^2
    set Variable names      = x,y,t
  end
@endcode

生产右边的马鞍。

<div class="twocolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-60.3_grid.png" alt = "" width="500"> </div> </div> <div class="parent"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-60.4_grid.png" alt = "" width="500"> </div> </div></div>

<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4> Running with `spacedim` equal to three</h4>

虽然目前的教程程序是为`spacedim`等于2而写的，但为了使程序在不同的尺寸组合中运行，你只需要做一些小的改动。

如果你想在`spacedim`等于3，`dim`等于2的情况下运行，那么你几乎肯定要进行以下修改。

- 使用不同的参考域来嵌入网格，也许可以从一个文件中读取它。不可能用一个正方形域的单一参数化来构造一个光滑的封闭表面，因此你很可能想用一个拓扑学上等同于球体边界的参考域。

- 用位移代替变形，将 $\Gamma_0$ 映射为 $\Gamma$ 。

<h4> More general domains </h4>

我们在其他教程中看到（例如在第5步和第54步）如何从输入文件中读取网格。这个教程程序的一个很好的概括是允许用户选择从参数文件本身读取网格，而不是在教程程序本身硬编码网格类型。

<h4> Preconditioner</h4>

目前，我们没有关于Schur补数的预处理程序。这对于二维问题来说是可以的，几百次迭代就可以把残差降低到机器的精度，但在三维问题上是行不通的。

在这里，一个好的预处理程序是什么并不明显。我们用舒尔补码解决的物理问题是将Dirichlet数据 $g$ 与Lagrange乘数 $\lambda$ 的值联系起来。   $\lambda$ 可以解释为法线梯度的*跳跃，需要强加在 $u$ 上，跨越 $\Gamma$ ，以获得迪里切特数据 $g$ 。

所以 $S$ 是某种诺伊曼到迪里切特的映射，我们希望有一个迪里切特到诺伊曼映射的良好近似。一种可能性是使用 $\Gamma$ 上的问题的边界元素近似，并构建一个与 $\Gamma$ 相关的泊松问题的超星形算子的粗略近似，这正是迪里切特到诺依曼的映射。

<h4> Parallel Code </h4>

这里提出的简单代码可以作为更复杂问题的起点，要解决这些问题，需要在并行代码上运行，可能使用分布式网格（见步骤17、步骤40，以及 parallel::shared::Triangulation 和 parallel::distributed::Triangulation). 的文档）。

当并行使用非匹配网格时，会出现一个问题：为了计算矩阵 $C$ ，一个进程需要关于实空间同一部分的两个网格的信息，但是，当使用分布式网格时，这种信息可能无法获得，因为存储在特定处理器上的 $\Omega$ 三角形的本地所有部分可能与存储在同一处理器上的 $\Gamma$ 三角形的本地所有部分不在同一地点。

可以实施各种策略来解决这个问题。

- 分布这两个网格，以便满足这个约束条件。

- 对现实空间中不满足约束的部分使用通信。

- 对嵌入空间使用分布式三角法，对模拟配置使用共享三角法。

后一种策略显然是最容易实现的，因为本教程程序中使用的大多数函数在并行情况下也能不变地工作。当然，我们可以使用反转策略（即有一个分布式嵌入三角法和一个共享嵌入三角法）。

然而，这种策略很可能会更加昂贵，因为根据定义，嵌入网格比嵌入网格要大，而且分配两个网格中最大的网格更有意义，保持最小的网格由所有处理器共享。


examples/step-61/doc/intro.dox

 <br> 

<i>
This program was contributed by Zhuoran Wang.
Some more information about this program, as well as more numerical
results, are presented in @cite Wang2019 .
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

本教程程序介绍了泊松方程的 "弱加勒金 "有限元方法的实现。从某种意义上说，考虑这种方法的动机与步骤51中的动机相同：我们想考虑不连续的形状函数，但又需要解决这样一个事实：与通常的连续Galerkin方法相比，所产生的问题有更多的自由度（因为，例如，每个顶点携带的自由度与相邻单元一样多）。我们还必须解决这样一个事实：与连续Galerkin方法不同，<i>every</i>一个单元上的自由度与它的每个面邻单元上的所有自由度相耦合。因此，从 "传统的 "非连续Galerkin方法得到的矩阵既大又相对密集。

step-51中的混合非连续Galerkin方法（HDG）和本教程中的弱Galerkin（WG）方法都是通过引入额外的自由度来解决耦合问题的，这些自由度的形状函数只存在于单元间的一个面上（即网格的 "骨架 "上），因此它们将相邻单元上的自由度相互 "隔离"：单元自由度只与同一单元上的其他单元自由度以及面自由度耦合，而与相邻单元上的单元自由度不耦合。因此，这些细胞自由度的形状函数的耦合确实正好耦合在一个细胞和定义在其面上的自由度上。

对于一个给定的方程，例如二阶泊松方程，HDG和WG方法的区别在于如何精确地制定连接所有这些不同形状函数的问题。事实上，对于某些WG和HDG的表述，有可能表明它们是等价的）。HDG的做法是用一阶方程系统重新表述二阶问题，然后在概念上把面的自由度看作是这个一阶系统的 "通量"。相比之下，WG方法保持二阶形式，并将面的自由度视为与主解变量相同的类型，只是限制在低维的面。为了方程的目的，在定义对其应用微分算子的含义时，人们需要以某种方式将这些形状函数 "扩展 "到单元的内部。与HDG相比，该方法的优势在于它不会因为将方程重写为一阶系统而导致未知数的增加，但它也不太容易实现。然而，正如我们在下文中所看到的，这种额外的努力并不可怕。




<h3> Weak Galerkin finite element methods </h3>

弱加勒金有限元方法（WGFEMs）使用离散的弱函数来近似标量未知数，使用离散的弱梯度来近似经典梯度。该方法最初是由王俊平和叶秀在论文<a href="https://doi.org/10.1016/j.cam.2012.10.003">
<i>A weak Galerkin finite element method for second order elliptic problems</i><i>A weak Galerkin finite element method for second order elliptic problems</i>,
J. Comput. Appl. Math., 103-115, 2013</a>中提出。与连续Galerkin方法相比，弱Galerkin方法满足重要的物理特性，即局部质量守恒和体法通量连续。它的结果是一个SPD线性系统，并且通过网格细化可以获得最佳收敛率。




<h3> The equation to solve </h3> 该程序使用弱加尔金有限元法求解泊松方程。

@f{align*}{
  \nabla \cdot \left( -\mathbf{K} \nabla p \right)
    &= f,
    \qquad \mathbf{x} \in \Omega, \\
  p &=  p_D,\qquad \mathbf{x} \in \Gamma^D, \\
  \mathbf{u} \cdot \mathbf{n} &= u_N,
  \qquad \mathbf{x} \in \Gamma^N,


@f}

其中 $\Omega \subset \mathbb{R}^n (n=2,3)$ 是一个有界域。在流体流经多孔介质的背景下， $p$ 是压力， $\mathbf{K}$ 是渗透性张量， $f$ 是源项， $p_D, u_N$ 代表Dirichlet和Neumann边界条件。我们可以引入一个通量， $\mathbf{u} = -\mathbf{K} \nabla p$ ，对应于达西速度（以我们在步骤20中的方式），这个变量在下面的考虑中很重要。

在这个程序中，我们将考虑一个测试案例，即在单位平方域上的确切压力为 $p = \sin \left( \pi x\right)\sin\left(\pi y \right)$ ，具有同质Dirichelet边界条件和 $\mathbf{K}$ 身份矩阵。然后我们将计算压力、速度和通量的 $L_2$ 误差。




<h3> Weak Galerkin scheme </h3>

上面的泊松方程有一个解 $p$ ，需要满足问题的弱表述。

@f{equation*}
\mathcal{A}\left(p,q \right) = \mathcal{F} \left(q \right),


@f}

为所有测试函数  $q$  ，其中

@f{equation*}
\mathcal{A}\left(p,q\right)
  \dealcoloneq \int_\Omega \left(\mathbf{K} \nabla p\right) \cdot \nabla q \;\mathrm{d}x,


@f}

和

@f{equation*}
\mathcal{F}\left(q\right)
  \dealcoloneq \int_\Omega f \, q \;\mathrm{d}x


  - \int_{\Gamma^N} u_N q \; \mathrm{d}x.


@f}

在这里，我们以双线性形式进行了部分积分，我们在内部评估 $p,p$ 的梯度，在域的边界评估 $q$ 的值。所有这些都是很好的定义，因为我们假设解是在 $H^1$ 中，对它来说，取梯度和评估边界值是有效的操作。

弱Galerkin方法的想法是用一个<i>discontinuous function</i> $p_h$ 来近似精确的 $p$ 解。这个函数可能只在单元格之间的界面上不连续，由于我们也想沿着界面评估这个函数，我们不仅要规定它在单元格内部应该有什么值，还要规定它在界面上的值。我们通过说 $p_h$ 实际上是一个元组， $p_h=(p^\circ,p^\partial)$ ，尽管它实际上只是一个单一的函数，它要么等于 $p^\circ(x)$ ，要么等于 $p^\partial(x)$ ，这取决于它是在位于细胞内部还是在细胞界面的某一点 $x$ 上被评估。

然后我们想把这个近似值简单地贴到上面的双线性表格中。这适用于我们必须在边界上评估测试函数 $q_h$ 的情况（我们只需取其界面部分 $q_h^\partial$ ），但我们必须小心处理梯度，因为它只在单元格内部定义。因此，泊松方程的弱Galerkin方案被定义为

@f{equation*}
\mathcal{A}_h\left(p_h,q \right) = \mathcal{F} \left(q_h \right),


@f}

对于所有离散测试函数  $q_h$  ，其中

@f{equation*}
\mathcal{A}_h\left(p_h,q_h\right)
  \dealcoloneq \sum_{K \in \mathbb{T}}
    \int_K \mathbf{K} \nabla_{w,d} p_h \cdot \nabla_{w,d} q_h \;\mathrm{d}x,


@f}

和

@f{equation*}
\mathcal{F}\left(q_h\right)
  \dealcoloneq \sum_{K \in \mathbb{T}} \int_K f \, q_h^\circ \;\mathrm{d}x


  - \sum_{\gamma \in \Gamma_h^N} \int_\gamma u_N q_h^\partial \;\mathrm{d}x,


@f}

关键的一点是，在这里，我们用<i>discrete weak gradient</i>算子 $\nabla_{w,d} p_h$ 代替了梯度 $\nabla p_h$ ，这对于我们特殊定义的近似 $p_h$ 是有意义的。

那么问题是该算子如何工作。为此，让我们首先说说我们是如何看待压力的离散近似值 $p_h$ 的。如上所述，"函数" $p_h$ 实际上由两部分组成：单元内部的值 $p_h^\circ$ 和界面上的 $p_h^\partial$ 。我们必须为这两部分定义离散的（有限维）函数空间；在这个程序中，我们将用FE_DGQ来表示 $p_h^\circ$ 作为细胞内部的空间（在每个细胞上定义，但一般沿界面是不连续的），用FE_FaceQ表示 $p_h^\partial$ 作为界面上的空间。

那么让我们只考虑一个单元（因为上面的积分都是逐个单元定义的，而且弱离散梯度是逐个单元定义的）。 $p_h$ 对 $K$ , $p_h|_K$ 的限制由一对 $(p_h^\circ|_K,p_h^\partial|_{\partial K})$ 组成。从本质上讲，我们可以认为 $\nabla_{w,d} p_h$ 是定义在 $K$ 上的某个函数，它近似于梯度；特别是，如果 $p_h|_K$ 是一个可微函数的限制（对 $K$ 的内部和边界--这将使它在内部和边界之间连续），那么 $\nabla_{w,d} p_h$  将只是精确梯度 $\nabla p_h$  。但是，由于 $p_h|_K$ 在 $K$ 的内部和边界之间不连续，我们需要一个更一般的定义；此外，我们不能处理任意函数，因此要求 $\nabla_{w,d} p_h$ 也在一个有限元空间中（由于梯度是一个矢量，必须是矢量值，而且由于弱梯度是在每个单元上单独定义的，因此在单元之间也将是不连续的）。

这样做的方法是以下列方式定义这个弱梯度算子 $\nabla_{w,d}|_K :
DGQ_k(K) \times DGQ_r(\partial K) \rightarrow RT_s(K)$ （其中 $RT_s(K)$ 是单元格 $K$ 上阶为 $s$ 的矢量值Raviart-Thomas空间）。

@f{equation*}{
  \int_K \mathbf v_h \cdot (\nabla_{w,d} p_h)
  =


  -\int_K (\nabla \cdot \mathbf v_h) p_h^\circ
  +\int_{\partial K} (\mathbf v_h \cdot \mathbf n) p_h^\partial,


@f}

为所有测试函数  $\mathbf v_h \in RT_s(K)$  。从本质上讲，这只是一个逐部积分公式的应用。换句话说，对于一个给定的 $p_h=(p^\circ_h,p^\partial_h)$ ，我们需要把 $\nabla_{w,d} p_h|_K$ 看作是度数为 $s$ 的Raviart-Thomas函数，对于这个函数，左手边和右手边在所有测试函数中是相等的。

那么，需要说明的一个关键点是以下几点。通常的梯度 $\nabla$ 是一个*本地*算子，它仅仅根据一个函数在某一点及其（无限小）邻域的值来计算导数，而弱离散梯度 $\nabla_{w,d}$ 却没有这个特性。它取决于它所应用的函数在整个单元上的值，包括单元的边界。然而，两者都是线性算子，从上面 $\nabla_{w,d}$ 的定义可以看出，这将允许我们在下面的讨论中通过矩阵来表示 $\nabla_{w,d}$ 。

 @note  值得指出的是，虽然弱的离散梯度是Raviart-Thomas空间 $RT_s(K)$ 在每个单元 $K$ 的一个元素，但它在单元之间是不连续的。另一方面，定义在整个网格上并由FE_RaviartThomas类实现的Raviart-Thomas空间 $RT_s=RT_s({\mathbb T})$ 代表在单元间界面上具有连续法线分量的函数。这意味着<i>globally</i>,  $\nabla_{w,d} p_h$ 不在 $RT_s$ 中，尽管它在 $K$ 中的每个单元上。   相反，它是在一个 "破碎的 "拉维-托马斯空间中，下面我们将用符号 $DGRT_s$ 来表示。 这里的术语 "破碎 "指的是 "把东西打碎 "的过程，而不是表达 "没有功能 "的同义词。因此，人们可能会（理所当然地）争辩说，在弱加尔金文献中使用的符号有点误导，但这往往取决于使用某种符号的背景--在目前的背景下，对Raviart-Thomas空间或元素的提及总是被理解为对 "破碎 "空间的提及。

 @note  deal.II恰好有一个实现了这个破碎的Raviart-Thomas空间。FE_DGRT类。因此，在本教程中，我们将简单地一直使用FE_DGRT类，尽管在所有那些我们必须计算单元格本地矩阵和向量的地方，它没有任何区别。




<h3> Representing the weak gradient </h3>

由于 $p_h$ 是有限元空间的一个元素，我们可以像往常一样在一个基础上展开它，也就是说，我们可以写出

@f{equation*}{
  p_h(\mathbf x) = \sum_j P_j \varphi_j(\mathbf x).


@f}

这里，由于 $p_h$ 有两个分量（内部分量和界面分量），对于基函数 $\varphi_j(\mathbf x)$ 也必须如此，我们可以写成 $\varphi_j = (\varphi_j^\circ,\varphi_j^\partial)$  。如果你按照步骤8、步骤20和 @ref vector_valued "向量值问题文件模块 "中的描述，就不会感到奇怪，对于 $j$ 的某些值， $\varphi_j^\circ$ 将为零，而对于 $j$ 的其他值， $\varphi_j^\partial$ 将为零--也就是说，形状函数将是一种或另一种类型。然而，这在这里并不重要。重要的是，我们需要思考如何表示 $\nabla_{w,d} \varphi_j$ ，因为当我们想实现双线性形式时，这显然是问题中会出现的东西

@f{equation*}
\mathcal{A}_h\left(p_h,q_h\right)
  = \sum_{K \in \mathbb{T}}
    \int_K \mathbf{K} \nabla_{w,d} p_h \cdot \nabla_{w,d} q_h \;\mathrm{d}x,


@f}



关键的一点是，已知 $\nabla_{w,d} \varphi_j$ 是 "破碎的 "Raviart-Thomas空间 $DGRT_s$ 的一个成员。这意味着我们可以（在每个单元 $K$ 上分别表示

@f{equation*}
\nabla_{w,d} \varphi_j|_K
  = \sum_k C_{jk}^K \mathbf v_k|_K


@f}

其中，函数 $\mathbf v_k \in DGRT_s$ ，以及 $C^K$ 是一个维数的矩阵

@f{align*}{
 \text{dim}\left(DGQ_k(K) \times DGQ_r(K)\right) &\times \text{dim}\left(RT_s(K)\right)
  \\
 &=
 \left(\text{dim}(DGQ_k(K)) + \text{dim}(DGQ_r(K))\right) \times \text{dim}\left(RT_s(K)\right).


@f}

弱离散梯度可以被表示为一个矩阵，这不应该是一个惊喜：它是一个从一个有限维空间到另一个有限维空间的线性算子。如果为这两个空间都选择基数，那么<i>every linear operator</i>当然可以写成一个矩阵，将与算子的域空间的基数有关的扩展系数向量映射到与图像空间的基数有关的扩展系数向量）。)

利用这个扩展，我们可以很容易地使用上面的弱离散梯度的定义来定义矩阵要做什么。

@f{equation*}{
  \int_K \mathbf v_i \cdot \left(\sum_k C_{jk}^K \mathbf v_k\right)
  =


  -\int_K (\nabla \cdot \mathbf v_i) \varphi_j^\circ
  +\int_{\partial K} (\mathbf v_i \cdot \mathbf n) \varphi_j^\partial,


@f}

对于所有的测试功能  $\mathbf v_i \in DGRT_s$  。

这显然导致了一个线性系统，其形式为

@f{equation*}{
  \sum_k M_{ik}^K C_{jk}^K
  =
  G_{ij}^K


@f}

与

@f{equation*}{
  M_{ik}^K = \int_K \mathbf v_i \cdot \mathbf v_k,
  \qquad\qquad
  G_{ij}^K = -\int_K (\nabla \cdot \mathbf v_i) \varphi_j^\circ
             +\int_{\partial K} (\mathbf v_i \cdot \mathbf n) \varphi_j^\partial,


@f}

因此

@f{equation*}{
  \left(C^K\right)^T = \left(M^K\right)^{-1} G^K.


@f}

(在这最后一步中，我们假设指数 $i,j,k$ 只涉及在单元 $K$ 上活动的自由度，从而确保空间 $RT_s(K)$ 上的质量矩阵是可逆的。)等价地，利用矩阵 $M$ 的对称性，我们可以看到

@f{equation*}{
  C^K = \left(G^K\right)^{T} \left(M^K\right)^{-1}.


@f}

另外值得指出的是，矩阵 $C^K$ 和 $G^K$ 当然不是正方形而是长方形。




<h3> Assembling the linear system </h3>

在解释了弱离散梯度是如何定义的之后，我们现在可以回到有关方程的线性系统应该如何组装的问题上。具体来说，利用上面显示的双线性形式 ${\cal A}_h$ 的定义，我们就需要计算局部对全局矩阵的贡献元素。

@f{equation*}{
  A^K_{ij} = \int_K \left({\mathbf K} \nabla_{w,d} \varphi_i\right) \cdot \nabla_{w,d} \varphi_j.


@f}

如上所述，我们可以用Raviart-Thomas基础在每个单元格上展开 $\nabla_{w,d} \varphi_i$ ，同样，对于 $\nabla_{w,d} \varphi_j$ 也是如此。

@f{equation*}{
  A^K_{ij} = \int_K
    \left(
      {\mathbf K}
      \sum_k C_{ik}^K \mathbf v_k|_K
    \right)
    \cdot
    \sum_l C_{jl}^K \mathbf v_l|_K.


@f}

通过重新排列和，可以得到以下表达式。

@f{equation*}{
  A^K_{ij} =
    \sum_k \sum_l C_{ik}^K C_{jl}^K
     \int_K
    \left(
      {\mathbf K}
      \mathbf v_k|_K
    \right)
    \cdot
    \mathbf v_l|_K.


@f}

因此，如果我们有每个单元格 $K$ 的矩阵 $C^K$ ，那么我们可以很容易地计算出单元格 $K$ 对矩阵 $A$ 的贡献 $A^K$ ，如下所示。

@f{equation*}{
  A^K_{ij} =
    \sum_k \sum_l C_{ik}^K C_{jl}^K
    H^K_{kl}
    =
    \sum_k \sum_l C_{ik}^K H^K_{kl} C_{jl}^K
    =
    \left(C^K H^K (C^K)^T \right)_{ij}.


@f}

在这里。

@f{equation*}{
  H^K_{kl} =
  \int_K
    \left(
      {\mathbf K}
      \mathbf v_k|_K
    \right)
    \cdot
    \mathbf v_l|_K,


@f}

这实际上只是单元 $K$ 上的质量矩阵，使用Raviart-Thomas基础并通过渗透性张量 $\mathbf K$ 加权。这里的推导表明，弱加尔金法实际上只需要我们计算每个单元 $C^K$ 和 $H^K$ 的矩阵，然后再计算 $A^K = C^K H^K (C^K)^T$ ，这很容易计算出来。下面要显示的代码正是这样做的。

在计算出单元格 $A^K$ 对全局矩阵的贡献后，我们要做的就是将这些局部贡献 "分配 "到全局矩阵中。如何做到这一点，首先显示在步骤3和步骤4中。在目前的程序中，这将通过调用 AffineConstraints::distribute_local_to_global(). 来促进。

一个线性系统当然也需要一个右手边。除了我们只需要对每个形状函数 $\varphi_i^\circ$ 使用单元格内部部分外，这里没有与计算右手边有关的困难。




<h3> Post-processing and <i>L<sub>2</sub></i><i>L<sub>2</sub></i>-errors </h3> 。

前面几节的讨论已经给了我们一个线性系统，我们可以求解数值压力 $p_h$  。我们可以用它来计算变量 $\mathbf u = -{\mathbf K}\nabla p$ 的近似值，如果这是我们要解决的模型，它对应于介质在多孔介质中的流动速度。这种步骤--从离散问题的解中计算一个派生量--通常被称为 "后处理"。

这里，我们不使用 $p_h$ 的精确梯度，而是使用 $p_h$ 的离散弱梯度来计算每个元素上的速度。如上所述，在每个元素上，数值压力 $\nabla p$ 的梯度可以用离散弱梯度 $ \nabla_{w,d}\phi_i$ 来近似。

@f{equation*}
\nabla_{w,d} p_h
= \nabla_{w,d} \left(\sum_{i} P_i \phi_i\right)
= \sum_{i} P_i \nabla_{w,d}\phi_i.


@f}



在单元格 $K$ 上，数值速度 $ \mathbf{u}_h = -\mathbf{K} \nabla_{w,d}p_h$ 可写为

@f{align*}{
  \mathbf{u}_h
  &= -\mathbf{K} \nabla_{w,d} p_h
   = -\mathbf{K}\sum_{i} \sum_{j} P_i C^K_{ij}\mathbf{v}_j,


@f}

其中 $C^K$ 是上面的扩展矩阵， $\mathbf{v}_j$ 是 $RT$ 空间在一个单元上的基函数。

不幸的是， $\mathbf{K} \mathbf{v}_j$ 可能不在 $RT$ 空间中（当然，除非如果 $\mathbf K$ 是常数乘以身份矩阵）。因此，为了在有限元程序中表示它，我们需要把它投射回我们可以处理的有限维空间。在这里，我们将使用 $L_2$ 投影法将其投影回（破碎的） $RT$ 空间。

我们将每个单元格  $K$  上的投影定义为  $ \mathbf{Q}_h \left( \mathbf{K}\mathbf{v}_j \right) =
\sum_{k} d_{jk}\mathbf{v}_k$  。对于任何  $j$  ,  $\left( \mathbf{Q}_h \left( \mathbf{Kv}_j \right),\mathbf{v}_k \right)_K =
\left( \mathbf{Kv}_j,\mathbf{v}_k \right)_K.$  所以，与其说是上面的公式，不如说是  $K$  单元上的数字速度变成了

@f{equation*}
\mathbf{u}_h = \mathbf{Q}_h \left( -\mathbf{K}\nabla_{w,d}p_h \right) =


-\sum_i \sum_j P_i B^K_{ij}\mathbf{Q}_h \left( \mathbf{K}\mathbf{v}_j \right),


@f}

我们有以下系统来解决系数问题  $d_{jk}$  。

@f{equation*}
 \sum_j
  \left(\mathbf{v}_i,\mathbf{v}_j\right)
   d_{jk}
   =
    \left( \mathbf{Kv}_j,\mathbf{v}_k \right).


@f}

在下面的实现中，元素为 $
   d_{jk}
$ 的矩阵被称为 <code>cell_matrix_D</code>  ，而元素为 $
      \left( \mathbf{Kv}_j,\mathbf{v}_k \right)
$ 的矩阵被称为 <code>cell_matrix_E</code> 。

那么元素速度为

@f{equation*}
\mathbf{u}_h = -\sum_{i} \sum_{j}P_ic_{ij}\sum_{k}d_{jk}\mathbf{v}_k =
\sum_{k}- \left(\sum_{j} \sum_{i} P_ic_{ij}d_{jk} \right)\mathbf{v}_k,


@f}

其中 $-\sum_{j} \sum_{i} P_ic_{ij}d_{jk}$ 在代码中被称为`细胞速度'。

利用这个通过 "后处理 "得到的速度，我们可以通过以下公式定义压力、速度和通量的 $L_2$ 误差。

@f{align*}{
\|p-p_h^\circ\|^2
  &= \sum_{K \in \mathbb{T}} \|p-p_h^\circ\|_{L_2(K)}^2, \\
 \|\mathbf{u}-\mathbf{u}_h\|^2
  &= \sum_{K \in \mathbb{T}} \|\mathbf{u}-\mathbf{u}_h\|_{L_2(K)^2}^d,\\
\|(\mathbf{u}-\mathbf{u}_h) \cdot \mathbf{n}\|^2
  &= \sum_{K \in \mathbb{T}} \sum_{\gamma \subset \partial K}
    \frac{|K|}{|\gamma|} \|\mathbf{u} \cdot \mathbf{n} - \mathbf{u}_h \cdot \mathbf{n}\|_{L_2(\gamma)}^2,


@f}

其中 $| K |$ 为元素的面积， $\gamma$ 为元素的面， $\mathbf{n}$ 为每个面的单位法向量。这些规范中的最后一条衡量了网格单元之间界面上速度向量的法向分量的精度。缩放因子 $|K|/|\gamma|$ 的选择是为了随着网格大小的变化，缩放出界面集合的长度（或面积）的差异。

上面的第一个错误很容易用 VectorTools::integrate_difference. 计算出来，其他的需要多做一些工作，在下面的代码中实现。


examples/step-61/doc/results.dox



<h1>Results</h1>

我们在运行程序时，右手边会产生解  $p = \sin(\pi x) \sin(\pi y)$  ，并且在域  $\Omega = (0,1)^2$  中具有同质的迪里希特边界条件。此外，我们选择微分算子 $\mathbf{K}$ 中的系数矩阵作为身份矩阵。我们使用 $\mbox{WG}(Q_0,Q_0;RT_{[0]})$ 、 $\mbox{WG}(Q_1,Q_1;RT_{[1]})$ 和 $\mbox{WG}(Q_2,Q_2;RT_{[2]})$ 元素组合测试这一设置，可以通过使用`main()`中`WGDarcyEquation`对象的适当构造参数来选择。然后我们将可视化单元内部和面上的压力值。随着网格的细化，压力、速度和流量的收敛率对于 $\mbox{WG}(Q_0,Q_0;RT_{[0]})$ 应该是1，对于 $\mbox{WG}(Q_1,Q_1;RT_{[1]})$ 是2，对于 $\mbox{WG}(Q_2,Q_2;RT_{[2]})$ 是3。




<h3>Test results on <i>WG(Q<sub>0</sub>,Q<sub>0</sub>;RT<sub>[0]</sub>)</i><i>WG(Q<sub>0</sub>,Q<sub>0</sub>;RT<sub>[0]</sub>)</i></h3> 。

下面的数字显示了使用 $\mbox{WG}(Q_0,Q_0;RT_{[0]})$ 元素的内部压力和表面压力。网格分别细化了2倍（顶部）和4倍（底部）。(这个数字可以在`make_grid()`函数中调整)。当网格较粗时，可以看到面压 $p^\partial$ 整齐地位于两个相邻单元的内压 $p^\circ$ 的数值之间。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg000_2d_2.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg000_3d_2.png" alt=""></td>
  </tr>
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg000_2d_4.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg000_3d_4.png" alt=""></td>
  </tr>
</table> 

从图中我们可以看出，随着网格的细化，最大和最小的压力值正在接近我们的预期值。由于网格是一个矩形网格，每个方向的单元数是偶数，所以我们有对称的解决方案。从右边的三维图中，我们可以看到在 $\mbox{WG}(Q_0,Q_0;RT_{[0]})$ 上，压力在单元的内部是一个常数，正如预期的那样。

<h4>Convergence table for <i>k=0</i><i>k=0</i></h4> 。

我们用不同的细化网格（在 "make_grid() "函数中选择）运行代码，得到压力、速度和通量（如引言中定义的）的以下收敛率。

 <table align="center" class="doxtable">
  <tr>
   <th>number of refinements </th><th>  $\|p-p_h^\circ\|$  </th><th>  $\|\mathbf{u}-\mathbf{u}_h\|$ </th><th> $\|(\mathbf{u}-\mathbf{u}_h) \cdot \mathbf{n}\|$ </th>
  </tr>
  <tr>
   <td>   2                  </td><td>    1.587e-01        </td><td>        5.113e-01               </td><td>   7.062e-01 </td>
  </tr>
  <tr>
   <td>   3                  </td><td>    8.000e-02        </td><td>        2.529e-01               </td><td>   3.554e-01 </td>
  </tr>
  <tr>
   <td>   4                  </td><td>    4.006e-02        </td><td>        1.260e-01               </td><td>   1.780e-01 </td>
  </tr>
  <tr>
   <td>   5                  </td><td>    2.004e-02        </td><td>        6.297e-02               </td><td>   8.902e-02 </td>
  </tr>
  <tr>
   <th>Conv.rate             </th><th>      1.00           </th><th>          1.00                  </th><th>      1.00   </th>
  </tr>
</table> 

我们可以看到， $\mbox{WG}(Q_0,Q_0;RT_{[0]})$ 的收敛率在1左右。当然，这与我们的理论预期相符。




<h3>Test results on <i>WG(Q<sub>1</sub>,Q<sub>1</sub>;RT<sub>[1]</sub>)</i><i>WG(Q<sub>1</sub>,Q<sub>1</sub>;RT<sub>[1]</sub>)</i></h3> 。

我们可以用下一个更高的多项式度数重复上面的实验。下面的数字是使用 $\mbox{WG}(Q_1,Q_1;RT_{[1]})$ 实现的内部压力和表面压力。网格被细化了4次。  与之前使用 $\mbox{WG}(Q_0,Q_0;RT_{[0]})$ 的数字相比，在每个单元上，解决方案不再是恒定的，因为我们现在使用双线性多项式来做近似。因此，在一个内部有4个压力值，在每个面上有2个压力值。

 <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg111_2d_4.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg111_3d_4.png" alt=""></td>
  </tr>
</table> 

与 $\mbox{WG}(Q_0,Q_0;RT_{[0]})$ 组合的相应图像相比，现在的解决方案大大增加了准确性，特别是在界面上如此接近于连续，以至于我们不再能够区分相邻单元上的界面压力 $p^\partial$ 和内部压力 $p^\circ$ 。

<h4>Convergence table for <i>k=1</i><i>k=1</i></h4> 。

以下是我们使用 $\mbox{WG}(Q_1,Q_1;RT_{[1]})$ 元素组合得到的压力、速度和通量的收敛率。

 <table align="center" class="doxtable">
  <tr>
   <th>number of refinements </th><th>  $\|p-p_h^\circ\|$  </th><th>  $\|\mathbf{u}-\mathbf{u}_h\|$ </th><th> $\|(\mathbf{u}-\mathbf{u}_h) \cdot \mathbf{n}\|$ </th>
  </tr>
  <tr>
    <td>  2           </td><td>           1.613e-02      </td><td>          5.093e-02     </td><td>             7.167e-02   </td>
  </tr>
  <tr>
    <td>  3           </td><td>           4.056e-03      </td><td>          1.276e-02     </td><td>             1.802e-02    </td>
  </tr>
  <tr>
    <td>  4           </td><td>           1.015e-03      </td><td>          3.191e-03     </td><td>             4.512e-03  </td>
  </tr>
  <tr>
    <td>  5           </td><td>           2.540e-04      </td><td>          7.979e-04     </td><td>             1.128e-03  </td>
  </tr>
  <tr>
    <th>Conv.rate     </th><th>              2.00        </th><th>             2.00       </th><th>                 2.00    </th>
  </tr>
</table> 

 $WG(Q_1,Q_1;RT_{[1]})$ 的收敛率在2左右，符合预期。




<h3>Test results on <i>WG(Q<sub>2</sub>,Q<sub>2</sub>;RT<sub>[2]</sub>)</i><i>WG(Q<sub>2</sub>,Q<sub>2</sub>;RT<sub>[2]</sub>)</i></h3> 。

让我们再提高一个多项式等级。以下是使用 $WG(Q_2,Q_2;RT_{[2]})$ 实现的内部压力和表面压力，网格大小为 $h = 1/32$ （即5个全局网格细化步骤）。在程序中，我们在生成图形输出时使用`data_out_face.build_patches(fe.degree)`（参见 DataOut::build_patches()), 的文档，这里意味着我们将每个2d单元内部分成4个子单元，以便提供更好的二次多项式的可视化。   <table align="center">
  <tr>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg222_2d_5.png" alt=""></td>
    <td><img src="https://www.dealii.org/images/steps/developer/step-61.wg222_3d_5.png" alt=""></td>
  </tr>
</table> 




<h4>Convergence table for <i>k=2</i><i>k=2</i></h4> 。

和以前一样，我们可以使用 $L_2$ 组合生成压力、速度和流量的 $\mbox{WG}(Q_2,Q_2;RT_{[2]})$ 误差的收敛数据。

 <table align="center" class="doxtable">
  <tr>
   <th>number of refinements </th><th>  $\|p-p_h^\circ\|$  </th><th>  $\|\mathbf{u}-\mathbf{u}_h\|$ </th><th> $\|(\mathbf{u}-\mathbf{u}_h) \cdot \mathbf{n}\|$ </th>
  </tr>
  <tr>
     <td>  2               </td><td>       1.072e-03       </td><td>         3.375e-03       </td><td>           4.762e-03   </td>
  </tr>
  <tr>
    <td>   3               </td><td>       1.347e-04       </td><td>         4.233e-04       </td><td>           5.982e-04    </td>
  </tr>
  <tr>
    <td>   4               </td><td>       1.685e-05      </td><td>          5.295e-05       </td><td>           7.487e-05  </td>
  </tr>
  <tr>
    <td>   5               </td><td>       2.107e-06      </td><td>          6.620e-06       </td><td>           9.362e-06  </td>
  </tr>
  <tr>
    <th>Conv.rate          </th><th>         3.00         </th><th>            3.00          </th><th>              3.00    </th>
  </tr>
</table> 

再一次， $\mbox{WG}(Q_2,Q_2;RT_{[2]})$ 的收敛率符合预期，其数值在3左右。


examples/step-62/doc/intro.dox

 <br> 

<i>This program was contributed by Daniel Garcia-Sanchez.</i> <br>  。




 @note  作为这个程序的前提条件，你需要安装HDF5、复杂的PETSc和p4est库。在<a
href="../../readme.html" target="body">README</a>文件中描述了deal.II与这些附加库的安装情况。

<h1>Introduction</h1> 声子晶体是一种周期性的纳米结构，可以改变机械振动或[声子]的运动（https://en.wikipedia.org/wiki/Phonon）。声子结构可用于分散、引导和限制机械振动。这些结构在[量子信息](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.1391)方面有潜在的应用，并已被用于研究[宏观量子现象](https://science.sciencemag.org/content/358/6360/203)。声子晶体通常是在[洁净室]中制造的(https://en.wikipedia.org/wiki/Cleanroom)。

在本教程中，我们展示了如何设计一个[声子超晶格空腔](https://doi.org/10.1103/PhysRevA.94.033813)，这是一种特殊类型的声子晶体，可用于限制机械振动。声子超晶格空腔是由两个[分布式布拉格反射器](https://en.wikipedia.org/wiki/Distributed_Bragg_reflector)、镜子和一个 $\lambda/2$ 空腔组成，其中 $\lambda$ 是声学波长。声学DBRs是周期性结构，其中一组具有对比物理特性（声速指数）的双层堆栈被重复 $N$ 次。超晶格空腔通常通过[分子束外延](https://en.wikipedia.org/wiki/Molecular-beam_epitaxy)在[砷化镓](https://en.wikipedia.org/wiki/Gallium_arsenide)晶片上生长。双层对应于砷化镓/砷化铝镜像对。如下图所示，镜像层（棕色和绿色）的厚度为 $\lambda/4$ ，空腔（蓝色）的厚度为 $\lambda/2$  。

 <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.01.svg" height="200" /> 

在本教程中，我们计算了[带隙](https://en.wikipedia.org/wiki/Band_gap)和声子超晶格空腔的机械共振，但这里介绍的代码可以很容易地用于设计和计算其他类型的[声子晶体](https://science.sciencemag.org/content/358/6360/203)。

该装置是一个波导，其中的波从左到右。本教程的模拟是在二维进行的，但代码是独立于维度的，可以很容易地用于三维模拟。波导的宽度等于域的 $y$ 维，波导的长度等于域的 $x$ 维。有两个取决于波导宽度的制度。

- 单一模式。在这种情况下，结构的宽度要比波长小得多。   这种情况可以用有限元法（我们在这里采取的方法）或用简单的半分析法[一维转移矩阵形式]（https://en.wikipedia.org/wiki/Transfer_matrix）来解决。

- 多模。在这种情况下，结构的宽度比波长大。   这种情况可以用有限元法或[散射矩阵形式主义]（https://doi.org/10.1103/PhysRevA.94.033813）来解决。   尽管我们在本教程中没有研究这种情况，但通过增加波导宽度参数（jupyter笔记本中的`dimension_y'），很容易达到多模制度。

本教程的模拟是在频域进行的。为了计算传输频谱，我们使用了时域[FDTD](https://meep.readthedocs.io/en/latest/Python_Tutorials/Resonant_Modes_and_Transmission_in_a_Waveguide_Cavity/)模拟中常用的一个[程序]。在结构的左侧产生一个特定频率的脉冲，在结构的右侧测量传输的能量。仿真运行了两次。首先，我们运行声子结构的模拟并测量传输能量。

 <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.02.svg" height="200" /> 

然后，我们运行没有声子结构的模拟，并测量传输的能量。我们使用没有结构的模拟来进行校准。

 <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.03.svg" height="200" /> 

传输系数相当于第一次模拟的能量除以校准能量。我们对每个频率步骤重复这一程序。




<h3>Elastic equations</h3> 我们在这里要模拟的是弹性波的传输。因此，对问题的正确描述使用了弹性方程，在时域中，弹性方程由以下几项给出

@f[
\rho\partial_{tt} u_i - \partial_j (c_{ijkl} \varepsilon_{kl}) = f_i,
\qquad i=0,1,2


@f]

其中刚度张量 $c_{ijkl}$ 取决于空间坐标，应变是位移的对称梯度，由以下公式给出

@f[
\varepsilon_{kl} =\frac{1}{2}(\partial_k u_l + \partial_l u_k)


@f]



[完美匹配层（PML）](https://en.wikipedia.org/wiki/Perfectly_matched_layer)可以用来在边界处截断解决方案。PML是一种导致复杂坐标拉伸的变换。

本教程程序没有采用时域方法，而是通过对时间变量进行傅里叶变换，将上述方程转换为频域。频域中的弹性方程的内容如下

@f{eqnarray*}
\nabla\cdot(\boldsymbol{\bar\sigma} \xi \boldsymbol{\Lambda})&=&-\omega^2\rho\xi\mathbf{\bar u}\\
\boldsymbol{\bar \sigma} &=&\mathbf{C}\boldsymbol{\bar\varepsilon}\\
\boldsymbol{\bar\varepsilon}&=&\frac{1}{2}[(\nabla\mathbf{\bar{u}}\boldsymbol{\Lambda}+\boldsymbol{\Lambda}^\mathrm{T}(\nabla\mathbf{\bar{u}})^\mathrm{T})]\\
\xi &=&\prod_i^\textrm{dim}s_i\\
\boldsymbol{\Lambda} &=& \operatorname{diag}(1/s_0,1/s_1,1/s_2)\qquad\textrm{for 3D}\\
\boldsymbol{\Lambda} &=& \operatorname{diag}(1/s_0,1/s_1)\qquad\textrm{for 2D}


@f}

其中系数 $s_i = 1+is_i'(x,y,z)$ 说明了吸收情况。3D中有3个 $s_i$ 系数，2D中有2个。 $s_i$ 的虚部在PML外等于零。PML仅对精确的波浪方程是无反射的。当方程组被离散化时，PML就不再是无反射的了。只要介质是缓慢变化的，反射就可以变得任意小，见[绝热定理](https://doi.org/10.1103/PhysRevE.66.066608)。在代码中，已经使用了PML的二次开启。线性和立方开启也是[已知可行的](https://doi.org/10.1364/OE.16.011376)。这些方程可以扩展为

@f[


-\omega^2\rho \xi  u_m - \partial_n \left(\frac{\xi}{s_n}c_{mnkl}
\varepsilon_{kl}\right) = f_m


@f]



@f[
\varepsilon_{kl} =\frac{1}{2}\left(\frac{1}{s_k}\partial_k u_l
+ \frac{1}{s_l}\partial_l u_k\right)


@f]

其中对重复指数（这里是 $n$ ，以及 $k$ 和 $l$ ）的求和一如既往地隐含着。请注意，应用PML的复数坐标拉伸后，应变不再是对称的。这组方程可以写成

@f[


-\omega^2\rho \xi  u_m - \partial_n \left(\frac{\xi c_{mnkl}}{2s_n s_k} \partial_k u_l
+ \frac{\xi c_{mnkl}}{2s_n s_l} \partial_l u_k\right) = f_m


@f]



与应变一样，应力张量在PML内也不是对称的（ $s_j\neq 0$ ）。事实上，PML内部的场不是物理的。介绍张量 $\alpha_{mnkl}$ 和 $\beta_{mnkl}$ 是有用的。

@f[


-\omega^2\rho \xi  u_m - \partial_n \left(\alpha_{mnkl}\partial_k u_l
+  \beta_{mnkl}\partial_l u_k\right) = f_m


@f]



我们可以乘以 $\varphi_m$ 并在 $\Omega$ 域上进行积分，并进行部分积分。

@f{eqnarray*}


-\omega^2\int_\Omega\rho\xi\varphi_m u_m + \int_\Omega\partial_n\varphi_m \left(\frac{\xi c_{mnkl}}{2s_n s_k} \partial_k u_l
+ \frac{\xi c_{mnkl}}{2s_n s_l} \partial_l u_k\right) = \int_\Omega\varphi_m f_m


@f}

正是这组方程，我们要解决一组频率 $\omega$ ，以计算传输系数与频率的关系。这个线性系统变成

@f{eqnarray*}
AU&=&F\\
A_{ij} &=& -\omega^2\int_\Omega\rho \xi\varphi_m^i \varphi_m^j + \int_\Omega\partial_n\varphi_m^i \left(\frac{\xi c_{mnkl}}{2s_n s_k} \partial_k \varphi_l^j
+ \frac{\xi c_{mnkl}}{2s_n s_l} \partial_l \varphi_k^j\right)\\
F_i &=& \int_\Omega\varphi_m^i f_m


@f}



<h3>Simulation parameters</h3> 在本教程中，我们使用python [jupyter notebook](https://github.com/dealii/dealii/blob/master/example/step-62/step-62.ipynb)来设置参数和运行模拟。首先，我们创建一个HDF5文件，在其中存储参数和模拟的结果。

每个模拟（位移和校准）都存储在一个单独的HDF5组中。

@code{.py}
import numpy as np
import h5py
import matplotlib.pyplot as plt
import subprocess
import scipy.constants as constants
import scipy.optimize


# This considerably reduces the size of the svg data
plt.rcParams['svg.fonttype'] = 'none'


h5_file = h5py.File('results.h5', 'w')
data = h5_file.create_group('data')
displacement = data.create_group('displacement')
calibration = data.create_group('calibration')


# Set the parameters
for group in [displacement, calibration]:
    # Dimensions of the domain
    # The waveguide length is equal to dimension_x
    group.attrs['dimension_x'] = 2e-5
    # The waveguide width is equal to dimension_y
    group.attrs['dimension_y'] = 2e-8


    # Position of the probe that we use to measure the flux
    group.attrs['probe_pos_x']   = 8e-6
    group.attrs['probe_pos_y']   = 0
    group.attrs['probe_width_y'] = 2e-08


    # Number of points in the probe
    group.attrs['nb_probe_points'] = 5


    # Global refinement
    group.attrs['grid_level'] = 1


    # Cavity
    group.attrs['cavity_resonance_frequency'] = 20e9
    group.attrs['nb_mirror_pairs']            = 15


    # Material
    group.attrs['poissons_ratio'] = 0.27
    group.attrs['youngs_modulus'] = 270000000000.0
    group.attrs['material_a_rho'] = 3200
    if group == displacement:
        group.attrs['material_b_rho'] = 2000
    else:
        group.attrs['material_b_rho'] = 3200
    group.attrs['lambda'] = (group.attrs['youngs_modulus'] * group.attrs['poissons_ratio'] /
                           ((1 + group.attrs['poissons_ratio']) *
                           (1 - 2 * group.attrs['poissons_ratio'])))
    group.attrs['mu']= (group.attrs['youngs_modulus'] / (2 * (1 + group.attrs['poissons_ratio'])))


    # Force
    group.attrs['max_force_amplitude'] = 1e26
    group.attrs['force_sigma_x']       = 1e-7
    group.attrs['force_sigma_y']       = 1
    group.attrs['max_force_width_x']   = 3e-7
    group.attrs['max_force_width_y']   = 2e-8
    group.attrs['force_x_pos']         = -8e-6
    group.attrs['force_y_pos']         = 0


    # PML
    group.attrs['pml_x']            = True
    group.attrs['pml_y']            = False
    group.attrs['pml_width_x']      = 1.8e-6
    group.attrs['pml_width_y']      = 5e-7
    group.attrs['pml_coeff']        = 1.6
    group.attrs['pml_coeff_degree'] = 2


    # Frequency sweep
    group.attrs['center_frequency']    = 20e9
    group.attrs['frequency_range']     = 0.5e9
    group.attrs['start_frequency']     = group.attrs['center_frequency'] - group.attrs['frequency_range'] / 2
    group.attrs['stop_frequency']      = group.attrs['center_frequency'] + group.attrs['frequency_range'] / 2
    group.attrs['nb_frequency_points'] = 400


    # Other parameters
    if group == displacement:
        group.attrs['simulation_name'] = 'phononic_cavity_displacement'
    else:
        group.attrs['simulation_name'] = 'phononic_cavity_calibration'
    group.attrs['save_vtu_files'] = False


h5_file.close()
@endcode




examples/step-62/doc/results.dox



<h1>Results</h1>

<h3>Resonance frequency and bandgap</h3>

在[jupyter notebook](https://github.com/dealii/dealii/blob/master/example/step-62/step-62.ipynb)中用以下代码分析了结果

@code{.py}
h5_file = h5py.File('results.h5', 'r')
data = h5_file['data']


# Gaussian function that we use to fit the resonance
def resonance_f(freq, freq_m, quality_factor, max_amplitude):
    omega = 2 * constants.pi * freq
    omega_m = 2 * constants.pi * freq_m
    gamma = omega_m / quality_factor
    return max_amplitude * omega_m**2 * gamma**2 / (((omega_m**2 - omega**2)**2 + gamma**2 * omega**2))


frequency = data['displacement']['frequency'][...]
# Average the probe points
displacement = np.mean(data['displacement']['displacement'], axis=0)
calibration_displacement = np.mean(data['calibration']['displacement'], axis=0)
reflection_coefficient = displacement / calibration_displacement
reflectivity = (np.abs(np.mean(data['displacement']['displacement'][...]**2, axis=0))/
                np.abs(np.mean(data['calibration']['displacement'][...]**2, axis=0)))


try:
    x_data = frequency
    y_data = reflectivity
    quality_factor_guess = 1e3
    freq_guess = x_data[np.argmax(y_data)]
    amplitude_guess = np.max(y_data)
    fit_result, covariance = scipy.optimize.curve_fit(resonance_f, x_data, y_data,
                                                      [freq_guess, quality_factor_guess, amplitude_guess])
    freq_m = fit_result[0]
    quality_factor = np.abs(fit_result[1])
    max_amplitude = fit_result[2]
    y_data_fit = resonance_f(x_data, freq_m, quality_factor, max_amplitude)


    fig = plt.figure()
    plt.plot(frequency / 1e9, reflectivity, frequency / 1e9, y_data_fit)
    plt.xlabel('frequency (GHz)')
    plt.ylabel('amplitude^2 (a.u.)')
    plt.title('Transmission\n' + 'freq = ' + "%.7g" % (freq_guess / 1e9) + 'GHz Q = ' + "%.6g" % quality_factor)
except:
    fig = plt.figure()
    plt.plot(frequency / 1e9, reflectivity)
    plt.xlabel('frequency (GHz)')
    plt.ylabel('amplitude^2 (a.u.)')
    plt.title('Transmission')


fig = plt.figure()
plt.plot(frequency / 1e9, np.angle(reflection_coefficient))
plt.xlabel('frequency (GHz)')
plt.ylabel('phase (rad)')
plt.title('Phase (transmission coefficient)\n')


plt.show()
h5_file.close()
@endcode



一个声腔的特点是[共振频率](https://en.wikipedia.org/wiki/Resonance)和[品质因子](https://en.wikipedia.org/wiki/Q_factor)。质量因子等于谐振器中储存的能量与每周期耗散的能量之间的比率，这大约相当于谐振频率与[半满宽度（FWHM）](https://en.wikipedia.org/wiki/Full_width_at_half_maximum)之间的比率。FWHM等于振动功率大于谐振频率的一半的带宽。

@f[
Q = \frac{f_r}{\Delta f} = \frac{\omega_r}{\Delta \omega} =
2 \pi \times \frac{\text{energy stored}}{\text{energy dissipated per cycle}}


@f]



机械共振 $a^2$ 的振幅的平方作为频率的函数有一个高斯形状

@f[
a^2 = a_\textrm{max}^2\frac{\omega^2\Gamma^2}{(\omega_r^2-\omega^2)^2+\Gamma^2\omega^2}


@f]

其中 $f_r = \frac{\omega_r}{2\pi}$ 是共振频率， $\Gamma=\frac{\omega_r}{Q}$ 是耗损率。我们在jupyter笔记本中使用前面的方程式来拟合机械共振。

鉴于我们所选择的参数值，人们可以通过分析来估计谐振频率。事实上，我们在这个程序中得到的结果证实了这一点：声子超晶格空腔在20GHz时表现出机械共振，质量系数为5046。下面的图片显示了在共振频率附近的传输振幅和相位与频率的关系。

 <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.05.png" height="400" />  <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.06.png" height="400" />  。

上面的图片表明，周期性结构有其预期的效果：它实际上只让一个非常特定频率的波通过，而所有其他的波都被反射。当然，这正是人们建造这类设备的目的。但这并不十分容易。在实践中，实际上只有一个 "带隙"，也就是说，该设备只在一定的频率范围内阻止20GHz频率以外的波。事实上，要想知道这个被阻挡的 "间隙 "有多大，我们可以通过输入文件中的适当参数将频率范围扩大到16GHz。然后我们得到以下图像。

 <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.07.png" height="400" /> 

这张图片表明的是，在18到22GHz左右的范围内，确实只有频率为20GHz的波被允许通过，但在这个范围之外，还有很多其他频率可以通过该设备。

<h3>Mode profile</h3>

我们可以用Paraview或VisIt检查模态轮廓。正如我们所讨论的，在共振时，所有的机械能都被传递，运动的振幅在腔内被放大。可以看出，PML对于截断解决方案是非常有效的。下图显示了共振时的模式轮廓。

 <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.08.png" height="400" /> 

另一方面，在共振之外，所有的机械能都被反射。下面的图片显示了19.75GHz时的轮廓。注意力脉冲和反射波在位置 $x=-8\mu\textrm{m}$ 的干扰。

 <img alt="Phononic superlattice cavity" src="https://www.dealii.org/images/steps/developer/step-62.09.png" height="400" /> 

<h3>Experimental applications</h3>

声波超晶格空腔在[量子光学机械学](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.1391)中找到了应用。这里我们介绍了二维超晶格空腔的模拟，但这个代码也可以用来模拟 "现实世界 "的三维设备，如[微柱超晶格空腔](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.99.060101)，它是研究宏观量子现象的有希望的候选者。微柱超晶格空腔的20GHz模式本质上是一个机械谐波振荡器，与环境隔离得非常好。如果该装置在稀释冰箱中被冷却到20mK，那么该模式就会成为一个宏观的量子谐波振荡器。




<h3>Possibilities for extensions</h3>

我们可以不在C++文件中设置参数，而是用一个Python脚本来设置参数，并将其保存在HDF5文件中，我们将使用该文件进行模拟。然后deal.II程序将从HDF5文件中读取参数。

@code{.py}
import numpy as np
import h5py
import matplotlib.pyplot as plt
import subprocess
import scipy.constants as constants
import scipy.optimize


# This considerably reduces the size of the svg data
plt.rcParams['svg.fonttype'] = 'none'


h5_file = h5py.File('results.h5', 'w')
data = h5_file.create_group('data')
displacement = data.create_group('displacement')
calibration = data.create_group('calibration')


# Set the parameters
for group in [displacement, calibration]:
    # Dimensions of the domain
    # The waveguide length is equal to dimension_x
    group.attrs['dimension_x'] = 2e-5
    # The waveguide width is equal to dimension_y
    group.attrs['dimension_y'] = 2e-8


    # Position of the probe that we use to measure the flux
    group.attrs['probe_pos_x']   = 8e-6
    group.attrs['probe_pos_y']   = 0
    group.attrs['probe_width_y'] = 2e-08


    # Number of points in the probe
    group.attrs['nb_probe_points'] = 5


    # Global refinement
    group.attrs['grid_level'] = 1


    # Cavity
    group.attrs['cavity_resonance_frequency'] = 20e9
    group.attrs['nb_mirror_pairs']            = 15


    # Material
    group.attrs['poissons_ratio'] = 0.27
    group.attrs['youngs_modulus'] = 270000000000.0
    group.attrs['material_a_rho'] = 3200
    if group == displacement:
        group.attrs['material_b_rho'] = 2000
    else:
        group.attrs['material_b_rho'] = 3200
    group.attrs['lambda'] = (group.attrs['youngs_modulus'] * group.attrs['poissons_ratio'] /
                           ((1 + group.attrs['poissons_ratio']) *
                           (1 - 2 * group.attrs['poissons_ratio'])))
    group.attrs['mu']= (group.attrs['youngs_modulus'] / (2 * (1 + group.attrs['poissons_ratio'])))


    # Force
    group.attrs['max_force_amplitude'] = 1e26
    group.attrs['force_sigma_x']       = 1e-7
    group.attrs['force_sigma_y']       = 1
    group.attrs['max_force_width_x']   = 3e-7
    group.attrs['max_force_width_y']   = 2e-8
    group.attrs['force_x_pos']         = -8e-6
    group.attrs['force_y_pos']         = 0


    # PML
    group.attrs['pml_x']            = True
    group.attrs['pml_y']            = False
    group.attrs['pml_width_x']      = 1.8e-6
    group.attrs['pml_width_y']      = 5e-7
    group.attrs['pml_coeff']        = 1.6
    group.attrs['pml_coeff_degree'] = 2


    # Frequency sweep
    group.attrs['center_frequency']    = 20e9
    group.attrs['frequency_range']     = 0.5e9
    group.attrs['start_frequency']     = group.attrs['center_frequency'] - group.attrs['frequency_range'] / 2
    group.attrs['stop_frequency']      = group.attrs['center_frequency'] + group.attrs['frequency_range'] / 2
    group.attrs['nb_frequency_points'] = 400


    # Other parameters
    if group == displacement:
        group.attrs['simulation_name'] = 'phononic_cavity_displacement'
    else:
        group.attrs['simulation_name'] = 'phononic_cavity_calibration'
    group.attrs['save_vtu_files'] = False


h5_file.close()
@endcode



为了读取HDF5参数，我们必须使用 HDF5::File::FileAccessMode::open 标志。

@code{.py}
      HDF5::File data_file("results.h5",
                           HDF5::File::FileAccessMode::open,
                           MPI_COMM_WORLD);
      auto       data = data_file.open_group("data");
@endcode




examples/step-63/doc/intro.dox

 <br> 

<i>This program was contributed by Thomas C. Clevenger and Timo Heister.


The creation of this tutorial was partially supported by NSF Award
DMS-1522191, DMS-1901529, OAC-1835452, by the Computational
Infrastructure in Geodynamics initiative (CIG), through the NSF under
Award EAR-0949446 and EAR-1550901 and The University of California -
Davis.
</i>

 @dealiiTutorialDOI{10.5281/zenodo.3382899,https://zenodo.org/badge/DOI/10.5281/zenodo.3382899.svg} 

<a name="Intro"></a>

<h1>Introduction</h1>

该程序使用几何多网格（GMG）预处理程序来解决一个平流-扩散问题。在步骤16中讨论了该预处理程序的基本原理；这里我们讨论了非对称PDE所需的必要变化。此外，我们还介绍了块平滑的概念（与步骤16中的点平滑相比），并检查了加法和乘法平滑器的DoF重新编号的效果。

<h3>Equation</h3> 平流-扩散方程由以下公式给出

@f{align*}{


-\varepsilon \Delta u + \boldsymbol{\beta}\cdot \nabla u & = f &
\text{ in } \Omega\\
u &= g & \text{ on } \partial\Omega


@f}

其中 $\varepsilon>0$  ， $\boldsymbol{\beta}$ 是<i>advection
direction</i>，而 $f$ 是一个来源。有几个注意事项。

1.如果 $\boldsymbol{\beta}=\boldsymbol{0}$ ，这就是在步骤16（以及其他许多地方）解决的拉普拉斯方程。

2.如果 $\varepsilon=0$ ，那么这就是步骤9中解决的静止平流方程。

3.人们可以为这个问题定义一个无尺寸的数字，称为<i>Peclet number</i>。   $\mathcal{P} \dealcoloneq \frac{\|\boldsymbol{\beta}\|
L}{\varepsilon}$  ，其中 $L$  是领域的长度尺度。它描述了我们所考虑的那种方程的特点。如果 $\mathcal{P}>1$ ，我们说问题是<i>advection-dominated</i>，否则如果 $\mathcal{P}<1$ 我们将说问题是<i>diffusion-dominated</i>。

在本教程的讨论中，我们将关注以对流为主的流动。这是很复杂的情况。我们知道，对于扩散主导的问题，标准的Galerkin方法可以很好地工作，我们也知道简单的多网格方法，如步骤16中定义的方法是非常有效的。另一方面，对于平流主导的问题，标准Galerkin方法会导致振荡和不稳定的离散，而简单的求解器往往不是很有效。因此，本教程程序旨在解决这两个问题。




<h4>Streamline diffusion</h4>

使用标准的Galerkin有限元方法，对于合适的测试函数 $v_h$ ，PDE的离散弱形式将为

@f{align*}{
a(u_h,v_h) = F(v_h)


@f}

其中

@f{align*}{
a(u_h,v_h) &= (\varepsilon \nabla v_h,\, \nabla u_h) +
(v_h,\,\boldsymbol{\beta}\cdot \nabla u_h),\\
F(v_h) &= (v_h,\,f).


@f}



不幸的是，用这种方法通常会得到震荡解。事实上，对于这种表述，可以显示出以下误差估计。

@f{align*}{
\|\nabla (u-u_h)\| \leq (1+\mathcal{P}) \inf_{v_h} \|\nabla (u-v_h)\|.


@f}

如果精确解足够平滑，右边的下限可以按如下方式估计。

@f{align*}{
  \inf_{v_h} \|\nabla (u-v_h)\|.
  \le
  \|\nabla (u-I_h u)\|
  \le
  h^k
  C
  \|\nabla^k u)\|


@f}

其中 $k$ 是所用有限元的多项式程度。因此，我们得到的估计是

@f{align*}{
\|\nabla (u-u_h)\|
\leq (1+\mathcal{P}) C h^k
  \|\nabla^k u)\|.


@f}

换句话说，数值解会收敛。另一方面，鉴于上述 $\mathcal{P}$ 的定义，我们不得不期待当 $\varepsilon \ll
\|\boldsymbol{\beta}\| L$ 时，即如果问题只有少量的扩散时，数值解会很差，而且误差很大。

为了解决这个问题，我们将考虑新的弱形式

@f{align*}{
a(u_h,\,v_h) + \sum_K (-\varepsilon \Delta u_h +
\boldsymbol{\beta}\cdot \nabla u_h-f,\,\delta_K
\boldsymbol{\beta}\cdot \nabla v_h)_K = F(v_h)


@f}

其中，对所有单元进行求和  $K$  ，对每个单元进行内积， $\delta_K$  是定义在  @cite john2006discontinuity  中的逐个单元的常数稳定参数。

从本质上讲，加入离散的强形式残差会增强双线性形式 $a(\cdot,\cdot)$ 的矫捷性，从而增加离散解的稳定性。这种方法通常被称为<i>streamline
diffusion</i>或<i>SUPG</i>（流线上风/Petrov-Galerkin）。




<h3>Smoothers</h3>

本教程的目标之一是从使用一个简单的（point-wise）高斯-赛德尔（SOR）平滑器开始扩展，该平滑器在步骤16（类PreconditionSOR）中用于多网格层次结构的每一层。术语 "point-wise "传统上用于求解器，表示每次在一个 "网格点 "求解；对于标量问题，这意味着使用一个求解器，每次更新线性系统的一个未知数，保持所有其他未知数固定不变；然后在问题中的所有未知数上进行迭代，一旦完成，从第一个未知数开始重新进行，直到这些 "扫频 "收敛。雅可比、高斯-赛德尔和SOR迭代都可以用这种方式解释。在多网格的背景下，人们不认为这些方法是 "求解器"，而是 "平滑器"。因此，人们对实际解决线性系统不感兴趣。为了使多网格方法发挥作用，只需去除残差的高频部分即可，因为这样可以将解限制在更粗的网格中。  因此，我们只需对所有未知数进行少量的、固定数量的 "扫频"。在本教程的代码中，这是由 "平滑步骤 "参数控制的。

但众所周知，这些方法在作为求解器时收敛得相当慢。虽然作为多网格平滑器，它们出乎意料地好，但它们也可以被改进。特别是，我们在这里也考虑 "基于单元的 "平滑器。这些方法一次解决一个单元上的所有未知数，保持所有其他未知数的固定；然后它们转到下一个单元，如此反复。我们可以把它们看作是雅可比（Jacobi）、高斯-赛德尔（Gauss-Seidel）或SOR的 "区块 "版本，但由于自由度是在多个单元中共享的，这些区块是重叠的，实际上这些方法最好在加法和乘法施瓦兹方法的框架内解释。

与step-16相比，我们的测试问题包含一个平流项。特别是在小的扩散常数 $\varepsilon$ 下，信息会沿着给定的平流方向的流线进行传输。这意味着，如果平滑器允许信息在单一平滑器应用中沿下游方向传播，那么平滑器可能会更有效。如果我们想按照这些未知数（或未知数块）的列举顺序一次解决一个未知数（或未知数块），那么这个信息传播特性需要相应地重新排列自由度或单元（对于基于单元的平滑器），以便更上游的自由度被提前处理（指数较低），更下游的自由度被推迟处理（指数较大）。排序的影响将在结果部分可见。

现在让我们简单地定义一下本教程中使用的平滑器。关于更详细的介绍，我们参考  @cite KanschatNotesIterative  和书籍  @cite smith2004domain  和  @cite toselli2006domain  。施瓦兹预处理器需要一个分解

@f{align*}{
V = \sum_{j=1}^J V_j


@f}

的有限元空间  $V$  。每个子问题  $V_j$  也有一个基于双线性形式  $a(\cdot,\cdot)$  的 Ritz 投影  $P_j: V \rightarrow V_j$  。这个投影对每个子问题 $A_j$ 诱导出一个局部算子 $V_j$  。如果 $\Pi_j:V\rightarrow V_j$ 是对 $V_j$ 的正交投影，可以证明 $A_jP_j=\Pi_j^TA$  。

有了这个，我们可以为算子 $A$ 定义一个<i>additive Schwarz preconditioner</i>为

@f{align*}{
 B^{-1} = \sum_{j=1}^J P_j A^{-1} = \sum_{j=1}^J A_j^{-1} \Pi_j^T.


@f}

换句话说，我们将我们的解决方案投射到每个子问题中，应用子问题的逆向 $A_j$ ，并将所有 $j$ 的贡献加起来。

请注意，我们可以通过为每个自由度定义一个子问题 $V_j$ ，将逐点（一次一个未知数）的雅可比方法解释为加性施瓦兹方法。然后， $A_j^{-1}$ 成为与 $A$ 的对角线项的逆数相乘的方法。

对于本教程中使用的 "块状雅可比 "方法，我们为当前层次上的网格的每个单元定义一个子问题 $V_j$ 。注意，我们使用的是连续有限元，所以这些块是重叠的，因为两个单元之间的界面上的自由度都属于两个子问题。对子问题（在deal.II中它们被称为 "块"）进行操作的施瓦茨算子的逻辑在RelaxationBlock类中实现。块状雅可比 "方法是在RelaxationBlockJacobi类中实现的。该类的许多方面（例如如何定义块以及如何反转局部子问题 $A_j$ ）可以在平滑器数据中配置，详见 RelaxationBlock::AdditionalData 和 DoFTools::make_cell_patches() 。

到目前为止，我们讨论了加法平滑器，其中更新可以独立应用，并且在单个平滑器应用中没有信息流动。A<i>multiplicative Schwarz preconditioner</i>解决了这个问题，其定义为

@f{align*}{
 B^{-1} = \left( I- \prod_{j=1}^J \left(I-P_j\right) \right) A^{-1}.


@f}

与上面不同的是，对子问题 $V_j$ 的更新是按顺序应用的。这意味着在颠倒子问题 $A_j$ 时得到的更新立即被用于 $A_{j+1}$ 。这在写出项目的时候就可以看到。

@f{align*}{
 B^{-1}
 =
 \left(
   I


   -
   \left(I-P_1\right)\left(I-P_2\right)\cdots\left(I-P_J\right)
 \right)
 A^{-1}
 =
   A^{-1}


   -
   \left[ \left(I-P_1\right)
   \left[ \left(I-P_2\right)\cdots
     \left[\left(I-P_J\right) A^{-1}\right] \cdots \right] \right]


@f}



当把子空间 $V_j$ 定义为整个自由度块时，这个方法在RelaxationBlockSOR类中实现，当你在本教程中选择 "块SOR "时使用。RelaxationBlockSOR类也是从RelaxationBlock派生的。因此，加法和乘法的施瓦兹方法都在一个统一的框架内实现。

最后，让我们注意到，标准的高斯-赛德尔（或SOR）方法可以被看作是一个乘法施瓦茨方法，每个DoF都有一个子问题。




<h3>Test problem</h3>

我们将考虑以下测试问题： $\Omega =
[-1,\,1]\times[-1,\,1]\backslash B_{0.3}(0)$  ，即一个以原点为圆心的半径为0.3的正方形被移除。此外，我们使用 $\varepsilon=0.005$ ,  $\boldsymbol{\beta} =
[-\sin(\pi/6),\,\cos(\pi/6)]$ ,  $f=0$ , 和迪里希特边界值

@f{align*}{
g = \left\{\begin{array}{ll} 1 & \text{if } x=-1 \text{ or } y=-1,\,x\geq 0.5 \\
0 & \text{otherwise} \end{array}\right.


@f}



下面的数字描述了有（左）和无（右）流线扩散的解决方案。在没有流线扩散的情况下，我们看到边界层周围有很大的振荡，这表明标准的Galerkin有限元方法对这个问题的不稳定性。

 <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-63-solution.png" alt="">
    </td>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-63-solution-no-sd.png" alt="">
    </td>
  </tr>
</table> 


examples/step-63/doc/results.dox



<h1>Results</h1>

<h3> GMRES Iteration Numbers </h3>

GMG的主要优势在于它是一种 $\mathcal{O}(n)$ 方法，也就是说，问题的复杂性随着问题的大小而线性增加。为了证明本教程中介绍的线性求解器实际上是 $\mathcal{O}(n)$ ，我们只需要证明GMRES求解的迭代次数在我们细化网格时保持大致不变。

以下每个表格都给出了GMRES的迭代次数，以减少初始残差的系数 $10^8$  。我们选择了足够数量的平滑步骤（基于该方法），以获得与网格大小无关的迭代数。从下面的表格可以看出，该方法确实是  $\mathcal{O}(n)$  。

<h4> DoF/Cell Renumbering </h4>

逐点平滑器（"Jacobi "和 "SOR"）是按照每层的DoFs的编号顺序来应用的。我们可以使用DoFRenumbering命名空间来影响这一点。块平滑器的应用是基于我们在`setup_smoother()`中设置的顺序。我们可以直观地看到这个编号。下面的图片显示了在下游、随机和上游编号中的活动单元的编号（从左到右）。

 <img src="https://www.dealii.org/images/steps/developer/step-63-cell-order.png" alt=""> 

让我们从加性平滑器开始。下表显示了从GMRES获得收敛的必要迭代次数。

 <table align="center" class="doxtable">
<tr>
  <th></th>
  <th></th>
  <th colspan="1">$Q_1$</th>
  <th colspan="7">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">Jacobi (6)</th>
  <th></th>
  <th colspan="3">Block Jacobi (3)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
</tr>
<tr>
  <th>Cells</th>
  <th></th>
  <th>DoFs</th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
  <th></th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
</tr>
<tr>
  <th>32</th>
  <th></th>
  <th>48</th>
  <td>3</th>
  <td>3</th>
  <td>3</th>
  <th></th>
  <td>3</th>
  <td>3</th>
  <td>3</th>
</tr>
<tr>
  <th>128</th>
  <th></th>
  <th>160</th>
  <td>6</th>
  <td>6</th>
  <td>6</th>
  <th></th>
  <td>6</th>
  <td>6</th>
  <td>6</th>
</tr>
<tr>
  <th>512</th>
  <th></th>
  <th>576</th>
  <td>11</th>
  <td>11</th>
  <td>11</th>
  <th></th>
  <td>9</th>
  <td>9</th>
  <td>9</th>
</tr>
<tr>
  <th>2048</th>
  <th></th>
  <th>2176</th>
  <td>15</th>
  <td>15</th>
  <td>15</th>
  <th></th>
  <td>13</th>
  <td>13</th>
  <td>13</th>
</tr>
<tr>
  <th>8192</th>
  <th></th>
  <th>8448</th>
  <td>18</th>
  <td>18</th>
  <td>18</th>
  <th></th>
  <td>15</th>
  <td>15</th>
  <td>15</th>
</tr>
<tr>
  <th>32768</th>
  <th></th>
  <th>33280</th>
  <td>20</th>
  <td>20</th>
  <td>20</th>
  <th></th>
  <td>16</th>
  <td>16</th>
  <td>16</th>
</tr>
<tr>
  <th>131072</th>
  <th></th>
  <th>132096</th>
  <td>20</th>
  <td>20</th>
  <td>20</th>
  <th></th>
  <td>16</th>
  <td>16</th>
  <td>16</th>
</tr>
</table> 

我们看到，重新编号的DoF/单元对收敛速度没有影响。这是因为这些平滑器独立计算每个DoF（点平滑器）或单元（块平滑器）的操作，并将结果相加。由于我们可以将这些平滑器定义为矩阵之和的应用，而矩阵加法是交换性的，所以我们对不同组件进行加法的顺序不会影响最终结果。

另一方面，乘法平滑器的情况则不同。

 <table align="center" class="doxtable">
<tr>
  <th></th>
  <th></th>
  <th colspan="1">$Q_1$</th>
  <th colspan="7">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">SOR (3)</th>
  <th></th>
  <th colspan="3">Block SOR (1)</th>
</tr>
<tr>
  <th></th>
  <th></th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
  <th></th>
  <th colspan="3">Renumbering Strategy</th>
</tr>
<tr>
  <th>Cells</th>
  <th></th>
  <th>DoFs</th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
  <th></th>
  <th>Downstream</th>
  <th>Random</th>
  <th>Upstream</th>
</tr>
<tr>
  <th>32</th>
  <th></th>
  <th>48</th>
  <td>2</th>
  <td>2</th>
  <td>3</th>
  <th></th>
  <td>2</th>
  <td>2</th>
  <td>3</th>
</tr>
<tr>
  <th>128</th>
  <th></th>
  <th>160</th>
  <td>5</th>
  <td>5</th>
  <td>7</th>
  <th></th>
  <td>5</th>
  <td>5</th>
  <td>7</th>
</tr>
<tr>
  <th>512</th>
  <th></th>
  <th>576</th>
  <td>7</th>
  <td>9</th>
  <td>11</th>
  <th></th>
  <td>7</th>
  <td>7</th>
  <td>12</th>
</tr>
<tr>
  <th>2048</th>
  <th></th>
  <th>2176</th>
  <td>10</th>
  <td>12</th>
  <td>15</th>
  <th></th>
  <td>8</th>
  <td>10</th>
  <td>17</th>
</tr>
<tr>
  <th>8192</th>
  <th></th>
  <th>8448</th>
  <td>11</th>
  <td>15</th>
  <td>19</th>
  <th></th>
  <td>10</th>
  <td>11</th>
  <td>20</th>
</tr>
<tr>
  <th>32768</th>
  <th></th>
  <th>33280</th>
  <td>12</th>
  <td>16</th>
  <td>20</th>
  <th></th>
  <td>10</th>
  <td>12</th>
  <td>21</th>
</tr>
<tr>
  <th>131072</th>
  <th></th>
  <th>132096</th>
  <td>12</th>
  <td>16</th>
  <td>19</th>
  <th></th>
  <td>11</th>
  <td>12</th>
  <td>21</th>
</tr>
</table> 

在这里，我们可以通过在平流方向上对DoFs/单元进行重新编号来加快收敛速度，同样，如果我们在相反的方向上进行重新编号，我们可以减缓收敛速度。这是因为平流主导的问题有一个定向的信息流（在平流方向），如果对DoFs/单元进行正确的重新编号，乘法就能够捕捉到这些信息。

然而，乘法的这一特点取决于 $\varepsilon$ 的值。当我们增加 $\varepsilon$ ，问题变得更加以扩散为主时，我们的信息在网格上的传播更加均匀，在平流方向上重新编号的优势就会减弱。相反，在 $\varepsilon=0$ 的极端情况下（仅有平流），我们有一个一阶PDE，具有正确重编号的乘法成为有效的求解器。正确的下游编号可能导致方法只需要一次迭代，因为信息可以从流入边界向下游传播，而没有相反方向的信息传输。然而，请注意，在 $\varepsilon=0$ 的情况下，必须对这种情况下的边界条件给予特别关注）。




<h4> %Point vs. block smoothers </h4>

我们将把结果限制在使用下游重新编号的运行上。下面是对 $Q_1$ 和 $Q_3$ 元素的所有四个平滑器的交叉比较。

 <table align="center" class="doxtable">
<tr>
  <th></th>
  <td></th>
  <th colspan="1">$Q_1$</th>
  <th colspan="4">Smoother (smoothing steps)</th>
  <th></th>
  <th colspan="1">$Q_3$</th>
  <th colspan="4">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th colspan="1">Cells</th>
  <td></th>
  <th colspan="1">DoFs</th>
  <th colspan="1">Jacobi (6)</th>
  <th colspan="1">Block Jacobi (3)</th>
  <th colspan="1">SOR (3)</th>
  <th colspan="1">Block SOR (1)</th>
  <th></th>
  <th colspan="1">DoFs</th>
  <th colspan="1">Jacobi (6)</th>
  <th colspan="1">Block Jacobi (3)</th>
  <th colspan="1">SOR (3)</th>
  <th colspan="1">Block SOR (1)</th>
</tr>
<tr>
  <th>32</th>
  <td></th>
  <th>48</th>
  <td>3</th>
  <td>3</th>
  <td>2</th>
  <td>2</th>
  <td></th>
  <th>336</th>
  <td>15</th>
  <td>14</th>
  <td>15</th>
  <td>6</th>
</tr>
<tr>
  <th>128</th>
  <td></th>
  <th>160</th>
  <td>6</th>
  <td>6</th>
  <td>5</th>
  <td>5</th>
  <td></th>
  <th>1248</th>
  <td>23</th>
  <td>18</th>
  <td>21</th>
  <td>9</th>
</tr>
<tr>
  <th>512</th>
  <td></th>
  <th>576</th>
  <td>11</th>
  <td>9</th>
  <td>7</th>
  <td>7</th>
  <td></th>
  <th>4800</th>
  <td>29</th>
  <td>21</th>
  <td>28</th>
  <td>9</th>
</tr>
<tr>
  <th>2048</th>
  <td></th>
  <th>2176</th>
  <td>15</th>
  <td>13</th>
  <td>10</th>
  <td>8</th>
  <td></th>
  <th>18816</th>
  <td>33</th>
  <td>22</th>
  <td>32</th>
  <td>9</th>
</tr>
<tr>
  <th>8192</th>
  <td></th>
  <th>8448</th>
  <td>18</th>
  <td>15</th>
  <td>11</th>
  <td>10</th>
  <td></th>
  <th>74496</th>
  <td>35</th>
  <td>22</th>
  <td>34</th>
  <td>10</th>
</tr>
<tr>
  <th>32768</th>
  <td></th>
  <th>33280</th>
  <td>20</th>
  <td>16</th>
  <td>12</th>
  <td>10</th>
  <td></th>
</tr>
<tr>
  <th>131072</th>
  <td></th>
  <th>132096</th>
  <td>20</th>
  <td>16</th>
  <td>12</th>
  <td>11</th>
  <td></th>
</tr>
</table> 

我们看到，对于 $Q_1$ ，两个乘法平滑器需要的平滑步骤和迭代次数的组合都比任何一个加法平滑器小。然而，当我们将度数增加到 $Q_3$ 元素时，在平滑步骤和迭代次数方面，块平滑器有明显的优势。具体来说，块状SOR平滑器在度数上给出了恒定的迭代次数，而块状Jacobi平滑器的迭代次数只增加了约38%，而Jacobi和SOR的迭代次数分别为75%和183%。

<h3> Cost </h3>

迭代次数并不能完全说明一个平滑器对另一个平滑器的最优性。很明显，我们必须检查迭代的成本。块状平滑器在这里处于不利地位，因为它们必须为每个单元构建和反转一个单元矩阵。下面是一个具有74,496个DoF的 $Q_3$ 元素的求解时间的比较。

 <table align="center" class="doxtable">
<tr>
  <th colspan="1">$Q_3$</th>
  <th colspan="4">Smoother (smoothing steps)</th>
</tr>
<tr>
  <th colspan="1">DoFs</th>
  <th colspan="1">Jacobi (6)</th>
  <th colspan="1">Block Jacobi (3)</th>
  <th colspan="1">SOR (3)</th>
  <th colspan="1">Block SOR (1)</th>
</tr>
<tr>
  <th>74496</th>
  <td>0.68s</th>
  <td>5.82s</th>
  <td>1.18s</th>
  <td>1.02s</th>
</tr>
</table> 

需要最多迭代的平滑器（Jacobi）实际上需要最短的时间（大约是下一个最快方法的2/3）。这是因为应用雅可比平滑步骤所需要的只是乘以一个对角线矩阵，这是非常便宜的。另一方面，虽然SOR比块SOR需要超过3倍的迭代（每个迭代有3倍的平滑步骤），但时间大致相当，这意味着块SOR的一个平滑步骤比SOR的一个平滑步骤大约慢9倍。最后，Jacobi块的成本比SOR块高6倍，这在直觉上是有道理的，因为每种方法的1个步骤都有相同的成本（反转单元格矩阵并将其相加或相乘），而Jacobi块每次迭代的平滑步骤是3倍，迭代次数是2倍。




<h3> Additional points </h3>

还有几个重要的点需要提及。

<ol>  <li>  对于平行分布的网格，乘法不能在整个领域内执行。这是因为它们一次操作一个单元，而下游的单元只有在上游的单元已经完成后才能被处理。这在单个处理器上是没有问题的。处理器只是一个接一个地浏览单元的列表。然而，在并行的情况下，这将意味着一些处理器是空闲的，因为上游处理器还没有完成对当前处理器所拥有的上游单元的工作。一旦上游处理器完成工作，下游处理器就可以开始工作，但那时上游处理器已经没有工作了。换句话说，在这些平稳的步骤中，大部分时间，大多数处理器实际上是空闲的。这不是获得良好的并行可扩展性的方法!

我们可以使用一种混合方法，即在每个子域上应用乘法平滑器，但是当你增加子域的数量时，该方法接近于加法的行为。这是这些方法的一个主要缺点。   </li> 

 <li> 目前对块平滑器的研究表明，很快我们将能够计算单元矩阵的逆，比目前在deal.II里面做的要便宜得多。这项研究是基于快速对角线化方法（可以追溯到20世纪60年代），在光谱界已经使用了大约20年（例如，见<a
href="https://doi.org/10.1007/s10915-004-4787-3"> Hybrid
Multigrid/Schwarz Algorithms for the Spectral Element Method by Lottes
and Fischer</a>）。目前，人们正在努力将这些方法推广到DG，并使其更加强大。此外，人们似乎应该能够利用无矩阵的实现，以及在域的内部，单元矩阵往往看起来非常相似的事实，允许更少的矩阵逆计算。   </li>   </ol> 。

结合1.和2.，我们有充分的理由期待像块状雅可比这样的方法在未来变得非常强大，尽管目前对这些例子来说它是相当缓慢的。




<h3> Possibilities for extensions </h3>

<h4> Constant iterations for Q<sub>5</sub> </h4>

改变平滑步骤的数量和平滑器放松参数（在 <code>Smoother::AdditionalData()</code> 中设置在 <code>create_smoother()</code> 里面，只对点平滑器有必要），以便我们对一个 $Q_5$ 元素保持一个恒定的迭代次数。

<h4> Effectiveness of renumbering for changing epsilon </h4>

增加/减少乘法的`.prm`文件中的参数 "Epsilon"，观察哪些数值的重编号不再影响收敛速度。

<h4> Mesh adaptivity </h4>

这段代码被设置为可以在自适应细化的网格中正常工作（接口矩阵被创建和设置）。设计一个合适的细化标准或尝试KellyErrorEstimator类。


examples/step-64/doc/intro.dox

 <br> 

<i>
This program was contributed by Bruno Turcksin and Daniel Arndt, Oak Ridge National Laboratory.
</i>




<h1>Introduction</h1>

这个例子展示了如何使用CUDA在GPU上实现超立方体上系数可变的亥姆霍兹方程的无矩阵方法。该线性系统将使用共轭梯度法进行求解，并通过MPI进行并行化。

在过去的几年里，一般的异构计算，特别是GPU，已经获得了很多的青睐。这是因为在给定的功率预算下，GPU比CPU提供更好的计算能力和内存带宽。在2019年初的架构中，对于PDE相关的任务，GPU的功率效率约为服务器CPU的2-3倍，宽<a
href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>。GPU也是机器学习中最受欢迎的架构。另一方面，GPU并不容易编程。这个程序探索了deal.II的能力，看看这样的程序可以如何有效地实现。

虽然我们试图让CPU和GPU的无矩阵类的接口尽可能接近，但还是有一些区别。当在GPU上使用无矩阵框架时，人们必须编写一些CUDA代码。然而，其数量相当少，而且CUDA的使用仅限于几个关键词。




<h3>The test case</h3>

在这个例子中，我们考虑亥姆霍兹问题@f{eqnarray*} - \nabla \cdot
\nabla u + a(\mathbf x) u &=&1,\\ u &=& 0 \quad \text{on } \partial \Omega @f} 。

其中 $a(\mathbf x)$ 是一个可变系数。

我们选择 $\Omega=[0,1]^3$ 和 $a(\mathbf x)=\frac{10}{0.05 +
2\|\mathbf x\|^2}$ 作为域。由于系数是围绕原点对称的，但域却不是，我们最终会得到一个非对称的解决方案。

如果你在本教程中读到这里，你就会知道这个问题的弱式表述是怎样的，以及原则上是怎样为它组建线性系统的。当然，在这个程序中，我们实际上不会形成矩阵，而只是表示它与之相乘时的作用。




<h3>Moving data to and from the device</h3>

GPU（我们从现在开始用 "设备 "一词来指代GPU）有自己的内存，与CPU（我们从现在开始用 "主机 "一词）可访问的内存分开。设备上的正常计算可以分为三个独立的步骤。

-# 数据从主机移到设备上。

-#计算是在设备上完成的。

-# 结果从设备移回主机。

数据移动可以由用户代码显式完成，也可以使用UVM（统一虚拟内存）自动完成。在deal.II中，只支持第一种方法。虽然这意味着用户有额外的负担，但这可以更好地控制数据移动，更重要的是可以避免在主机而不是设备上错误地运行重要的内核。

deal.II中的数据移动是使用 LinearAlgebra::ReadWriteVector. 完成的，这些向量可以被看作是主机上的缓冲区，用于存储从设备接收的数据或向设备发送数据。有两种类型的向量可以在设备上使用。

-  LinearAlgebra::CUDAWrappers::Vector, ，它类似于更常见的Vector<Number>，和

-  LinearAlgebra::distributed::Vector<Number,   MemorySpace::CUDA>, 这是一个普通的 LinearAlgebra::distributed::Vector ，我们已经指定了要使用哪个内存空间。

如果没有指定内存空间，默认为 MemorySpace::Host. 。

接下来，我们展示如何使用 LinearAlgebra::CUDAWrappers::Vector: 将数据移入/移出设备。

@code
  unsigned int size = 10;
  LinearAlgebra::ReadWriteVector<double> rw_vector(size);


  ...do something with the rw_vector...


  // Move the data to the device:
  LinearAlgebra::CUDAWrappers::Vector<double> vector_dev(size);
  vector_dev.import(rw_vector, VectorOperations::insert);


  ...do some computations on the device...


  // Move the data back to the host:
  rw_vector.import(vector_dev, VectorOperations::insert);
@endcode

这里使用的两个向量类都只在一台机器上工作，也就是说，一个内存空间在主机上，一个在设备上。

但在有些情况下，人们希望在一些机器上的多个MPI进程之间运行并行计算，而每个机器都配备了GPU。在这种情况下，人们希望使用 `LinearAlgebra::distributed::Vector<Number,MemorySpace::CUDA>`, ，它是类似的，但`import()`阶段可能涉及MPI通信。

@code
  IndexSet locally_owned_dofs, locally_relevant_dofs;
  ...fill the two IndexSet objects...


  // Create the ReadWriteVector using an IndexSet instead of the size
  LinearAlgebra::ReadWriteVector<double> owned_rw_vector(locally_owned_dofs);


  ...do something with the rw_vector...


  // Move the data to the device:
  LinearAlgebra::distributed::Vector<double, MemorySpace::CUDA>
    distributed_vector_dev(locally_owned_dofs, MPI_COMM_WORLD);
  distributed_vector_dev.import(owned_rw_vector, VectorOperations::insert);


  ...do something with the dev_vector...


  // Create a ReadWriteVector with a different IndexSet:
  LinearAlgebra::ReadWriteVector<double>
    relevant_rw_vector(locally_relevant_dofs);


  // Move the data to the host, possibly using MPI communication:
  relevant_rw_vector.import(distributed_vector_dev, VectorOperations::insert);
@endcode

`relevant_rw_vector`是一个存储向量所有元素的子集的对象。通常情况下，这些是 @ref GlossLocallyRelevantDof "本地相关的DoF"，这意味着它们在不同的MPI进程之间是重叠的。因此，一台机器上存储在该向量中的元素可能与该机器上的GPU存储的元素不一致，需要MPI通信来导入它们。

在所有这些情况下，在导入矢量时，可以插入数值（使用 VectorOperation::insert) 或添加到矢量的先前内容中（使用 VectorOperation::add).  ）。




<h3>Matrix-vector product implementation</h3>

在设备上评估无矩阵算子所需的代码与主机上的代码非常相似。然而，也有一些区别，主要是Step-37中的`local_apply()`函数和正交点的循环都需要封装在自己的函数中。


examples/step-64/doc/results.dox



<h1>Results</h1>

由于本教程的主要目的是演示如何使用 CUDAWrappers::MatrixFree 接口，而不是计算任何有用的东西本身，所以我们在这里只是显示预期的输出。

@code
Cycle 0
   Number of active cells:       8
   Number of degrees of freedom: 343
  Solved in 27 iterations.
  solution norm: 0.0205439


Cycle 1
   Number of active cells:       64
   Number of degrees of freedom: 2197
  Solved in 60 iterations.
  solution norm: 0.0205269


Cycle 2
   Number of active cells:       512
   Number of degrees of freedom: 15625
  Solved in 114 iterations.
  solution norm: 0.0205261


Cycle 3
   Number of active cells:       4096
   Number of degrees of freedom: 117649
  Solved in 227 iterations.
  solution norm: 0.0205261
@endcode



在这里，我们可以做两个观察。首先，数值解的准则在收敛，大概是收敛到精确（但未知）解的准则。其次，每次细化网格时，迭代次数大约增加一倍。这与CG迭代次数随矩阵条件数的平方根增长的预期一致；而且我们知道二阶微分运算的矩阵条件数的增长方式是 ${\cal O}(h^{-2})$  。这当然是相当低效的，因为一个最佳解算器的迭代次数与问题的大小无关。但是要有这样一个求解器，就需要使用比我们在这里使用的身份矩阵更好的预处理。


<a name="extensions"></a>

<h3> Possibilities for extensions </h3>

目前，这个程序完全没有使用预处理程序。这主要是因为构建一个高效的无矩阵预处理程序是不容易的。  然而，只需要相应矩阵的对角线的简单选择是很好的选择，这些也可以用无矩阵的方式计算。另外，也许更好的是，我们可以扩展教程，使用类似步骤37的切比雪夫平滑器的多重网格。


examples/step-65/doc/intro.dox



 <br> 

<i>
This program was contributed by Martin Kronbichler.
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

本教程程序介绍了一个高级流形类--TransfiniteInterpolationManifold，以及如何解决其主要缺点--相对较高的成本。

<h3>Working with manifolds</h3>

<h4>What we want</h4>

在许多应用中，有限元网格必须能够表示一个相对复杂的几何体。在step-1、step-49和step-53教程程序中，已经介绍了deal.II库中可用的一些生成网格的技术。给定一个基础网格，deal.II能够通过将单元格均匀地或仅在计算域的选定部分细分为子单元来创建一个更细的网格。除了GridGenerator命名空间中的基本网格划分功能外，deal.II还提供了一些接口，可以使用命名空间GridIn的功能读入由（仅四边形和六边形）网格生成器生成的网格，例如在步骤5中演示。外部生成的网格的一个基本限制是，网格中生成的单元所提供的信息只包括顶点的位置和它们的连接性，而没有最初创建这个网格的网格生成器所提供的底层几何体的背景。一旦网格在deal.II中被细化，需要放置更多的点，这就成了问题。第54步教程程序显示了如何通过使用OpenCASCADE库方面的CAD曲面来克服这个限制，第53步通过在源代码内以编程方式提供同类信息。

在deal.II中，网格细化过程中新点的放置或高阶映射的定义由流形对象控制，详见 @ref manifold  "流形模块"。举个例子，考虑以下二维环形的情况（图片取自流形模块）。如果我们从10个单元的初始网格开始，在不附加任何流形的情况下全局细化网格三次，我们将得到以下网格。

 @image html hypershell-nothing.png "" 

图片看起来是这样的，因为在默认情况下，deal.II只知道通过平均父单元的顶点位置来放置子单元的顶点。这就产生了一个多边形域，其面是原始（粗略的网格）单元的边缘。很明显，我们必须对三角形的边界面附加一个曲线描述，以便在网格细化时重现圆形，就像下图一样。

 @image html hypershell-boundary-only.png "" 

这样就好多了。如果我们继续细化网格，至少现在的内外边界已经接近真实的圆了。然而，这幅图中的网格对于环形来说仍然不是最佳的，因为从一个单元到下一个单元的<i>interior</i>线在某些顶点上有扭结，人们宁愿使用下面的网格。

 @image html hypershell-all.png "" 

在这最后一种（最佳）情况下，也是由 GridGenerator::hyper_shell(), 产生的默认情况，曲线流形描述（在这种情况下是极地流形描述）不仅适用于边界面，而且适用于整个域。每当三角化要求一个新的点，例如，当它将一个单元细化为四个子单元时，边缘或单元的中点，它将沿着极坐标系统中各自的中点来放置它们。相比之下，上面那种只有边界受制于极地流形的情况，只有沿边界的中点会沿着曲线描述放置，而内部的中点会通过直角坐标系中周围点的合适平均值来计算（更多细节见 @ref manifold  "流形模块"）。

在这一点上，人们可能会认为曲线形的体积描述是一种方式。这一般来说是不会错的，尽管有时并不那么容易描述这到底应该如何工作。这里有几个例子。

- 想象一下，上面的网格实际上是一个圆盘，而不只是一个环。   在这种情况下，极地流形会在原点退化，不会产生合理的新点。事实上，为那些应该 "看起来是圆的 "但可能在原点或接近原点的东西定义流形描述是令人惊讶的非常困难的。

- 当人们试图将球形流形附加到整个体积上时，类似的事情也会发生在三维球的原点；在这种情况下，新流形点的计算会因异常而中止。

- CAD几何体通常只描述域的边界，就像我们在上面第二张图中只把流形附在边界上一样。同样地，Step-54只使用CAD几何体来生成表面网格（也许是因为这是解决相关问题所需要的），但是如果想解决那里描述的水或船周围空气中的问题，我们就需要有一个体积网格。那么问题来了，我们应该如何准确地描述域的内部应该发生什么。

这些简单的例子清楚地表明，对于许多有趣的情况，我们必须从对全体积的分析性曲率描述的愿望中退一步。将需要有<i>some</i>种导致曲率也在内部的信息，但必须有可能做到这一点，而不需要实际写下描述那种几何的明确公式。

那么，如果我们不在内部做任何事情，只把表面描述为流形，会发生什么呢？有时，如上图所示的环，结果并不可怕。但有时却很糟糕。考虑一个环状体的情况（例如用 GridGenerator::torus()) 生成的环状体，只在表面附加一个TorusManifold对象，内部单元和面没有附加流形，细化前有六个单元在环状方向。如果对网格进行一次细化，我们将得到如下的网格，图中显示的是网格的上半部分被剪切掉了。

 @image html torus_no_inner_manifold.png "" 

这显然是次优的。事实上，如果我们从少于上面显示的环形方向的六个单元开始，映射在某些区域实际上是倒置的，因为沿着内部单元放置的新点与边界相交，因为它们不是沿着环形方向的圆形。环形的简单情况仍然可以被固定下来，因为我们知道环形方向是沿着圆柱坐标系的，所以在曲面上附加一个TorusManifold，结合CylindricalManifold，在环形方向上有适当的周期性，应用于所有的内部实体，将产生一个高质量的网格，如下所示，现在有两个顶部的单元被隐藏起来。

 @image html torus_cylindrical_inner_manifold.png "" 

这个网格是相当不错的，但显然它与对体积的良好描述有关，而我们在其他情况下缺乏这种描述。实际上，在这种情况下也有一个不完美之处，因为我们可以看到域的内部的两个相邻单元的一些不自然的扭结，这些扭结被顶部的两个边界单元所隐藏，与下面的设置相反（由 GridGenerator::torus() 应用的默认流形并使用TransfiniteInterpolationManifold）。

 @image html torus_transfinite_manifold.png "" 

<h3>The class TransfiniteInterpolationManifold</h3>

为了找到一个更好的策略，让我们再看看二维圆盘（这也是沿环形方向旋转的环形实体的基础）。正如我们上面所学到的，我们只能将弯曲的极坐标描述应用于边界（或离原点足够远的单元的边缘），但最终必须过渡到对圆盘中心的直线描述。如果我们在单元的内部使用平坦的流形（也就是说，新的顶点是通过相邻的现有顶点的平均化而产生的），而极地流形只用于圆盘的边界，那么在进行四次全局细化之后，我们会得到以下网格。

 @image html circular_mesh_only_boundary_manifold.png "" 

这并不是一个可怕的网格。同时，如果你知道最初的粗略网格是由中间的一个正方形和周围的四个盖子组成的，那么就不难看出这个网格的每一个细化步骤都是为了得到上面的图片。

虽然deal.II的三角测量类在创建新点时试图将信息从边界传播到内部，但这种算法的影响范围是有限的。

 @image html circular_mesh_boundary_cells.png "" 

上图突出了盘面上那些触及边界的单元，在当时只看一个单元的情况下，原则上可以考虑边界信息。显然，随着网格的细化，可以考虑到一些曲率的区域变得更加有限，因此在网格中形成了看似不规则的点。当计算最左边图片中任何一个边界单元的中心时，理想的位置是外圈和中间的单元之间的中点。这正是三角剖分类中第一个细化步骤所使用的内容。然而，对于第二次细化，所有的内部边缘以及内部单元格层只能根据平面流形描述来加点。

在这一点上，我们意识到需要什么来创建一个更好的网格。对于<i>all</i>子单元中的<i>any</i>新点，即在最左边的红色阴影层内创建的单元，我们要计算相对于各自粗单元覆盖区域内的曲率的插值。这可以通过在上图最左边面板的粗略网格的高亮单元中添加TransfiniteInterpolationManifold类来实现。该类遵守一般流形接口，即在其定义域内给定任何一组点，它可以计算符合流形的加权平均数（使用的公式将在一分钟后给出）。这些加权平均数在细化网格的时候，或者在给定单元上评估符合该流形的高阶映射（如MappingQGeneric或MappingC1）的时候都会用到。在圆盘粗网格的阴影单元上使用该流形（即不仅仅是最外层的单元），在经过四个全局步骤的细化后产生以下网格。

 @image html circular_mesh_transfinite_interpolation.png "" 

这个网格的线条仍有一些扭结，但它们仅限于粗大的网格单元之间的面，而网格的其他部分则如人们所希望的那样平滑。事实上，给定一个直边的中心单元，这个表示法是最好的，因为所有的网格单元都遵循一个平滑的过渡，从内部的方形块的直边到边界的圆形。(我们可以做得更好一些，在中心的方形块中也允许一些曲率，随着中心的接近，这些曲率最终会消失)。




<h4>How it works</h4>

在一个有一条曲线和三条直线的圆盘的简单情况下，我们可以明确写下如何实现形状的混合。为此，将物理单元（如顶部的单元）映射回参考坐标系 $(\xi,\eta)\in (0,1)^2$ 是很有用的，在那里我们计算某些点之间的平均数。如果我们使用一个由四个顶点 $(x_0,y_0), (x_1,y_1), (x_2,y_2), (x_3, y_3)$ 跨越的简单双线性地图，一个点 $(\xi, \eta)\in (0,1)^2$ 的图像将是

@f{align*}{
(x,y) = (1-\xi)(1-\eta) (x_0,y_0) + \xi(1-\eta) (x_1,y_1) +
       (1-\xi)\eta  (x_2,y_2) + \xi\eta  (x_3,y_3).


@f}



对于曲面的情况，我们要修改这个公式。对于圆盘粗略网格的顶部单元，我们可以假设点 $(x_0,y_0)$ 和 $(x_1,y_1)$ 位于下端的直线上，点 $(x_2,y_2)$ 和 $(x_3,y_3)$ 沿顶部由一个四分之一圆连接。然后我们将点 $(\xi, \eta)$ 映射为

@f{align*}{
(x,y) = (1-\eta) \big[(1-\xi) (x_0,y_0) + \xi (x_1,y_1)\big] +
      \eta \mathbf{c}_3(\xi),


@f}

其中 $\mathbf{c}_3(\xi)$ 是一条曲线，用一个arclength参数 $\xi\in (0,1)$ 来描述四分之一圆的 $(x,y)$ 坐标。这代表了单元格的直线下边缘和曲线上边缘之间的线性插值，也是上图的基础。

这个公式很容易被推广到所有四条边都由曲线而不是直线描述的情况。我们称这四个函数为 $\xi$ 或 $\eta$ ，在水平和垂直方向上，分别为四边形的左、右、下和上边缘的参数。然后，内插法为

@f{align*}{
(x,y) =& (1-\xi)\mathbf{c}_0(\eta) + \xi \mathbf{c}_1(\eta)
        +(1-\eta)\mathbf{c}_2(\xi) + \eta \mathbf{c}_3(\xi)\\
       &-\big[(1-\xi)(1-\eta) (x_0,y_0) + \xi(1-\eta) (x_1,y_1) +
        (1-\xi)\eta  (x_2,y_2) + \xi\eta  (x_3,y_3)\big].


@f}



这个公式假设边界曲线与顶点 $(x_0,y_0), (x_1,y_1), (x_2,y_2), (x_3, y_3)$ ，例如 $\mathbf{c}_0(0)
= (x_0,y_0)$ 或 $\mathbf{c}_0(1) = (x_2,y_2)$ 匹配和重合。公式第二行的双线性插值的减法确保了在边界上完全遵循规定的曲线：沿着四条边中的每一条，我们需要减去在角上评估的两条相邻边的贡献，这时的贡献只是一个顶点位置。很容易检查出，如果四条曲线中的三条 $\mathbf{c}_i$ 是直的，从而与双线性插值重合，那么上面的圆的公式就再现了。

这个公式被称为转折内插，由<a
href="https://doi.org/10.1002%2Fnme.1620070405">Gordon and Hall</a>在1973年提出。尽管转义插值本质上只表示边界曲线的线性混合，但插值完全遵循每个实数 $\xi\in (0,1)$ 或 $\eta\in (0,1)$ 的边界曲线，也就是说，它插值的点数是无限的，这也是Gordon和Hall将这种插值的变体称为转义插值的最初动机。另一种解释是，无限插值从左右和上下线性插值，我们需要从中减去双线性插值，以确保在域的内部有一个单位重量。

无限插值很容易被推广到三个空间维度。在这种情况下，插值允许为一个三维单元的任何一个四边形混合6种不同的表面描述，为一个单元的线混合12种边缘描述。同样，为了确保地图的一致性，有必要减去边缘的贡献，再加上顶点的贡献，使曲线遵循规定的表面或边缘描述。在三维的情况下，也可以使用从曲线边缘到相邻面和相邻单元的转折插值。

在处理.II中的转置插值是通用的，因为它可以处理任意的曲线。它将以 $d$ -维空间的原始坐标来评估曲线，但有一个（或两个，在三维的边缘情况下）坐标固定在 $0$ 或 $1$ ，以确保任何其他流形类，包括CAD文件（如果需要），都可以应用于开箱。无限插值是网格生成器的标准成分，因此在deal.II库中集成这一功能的主要优势是在自适应细化和粗化网格时启用，以及用于创建更高程度的映射，使用流形来插入网格顶点以外的额外点。

关于无限插值的最后一句话，我们提到在没有体积流形描述的情况下，deal.II中的网格细化策略也是基于无限插值的权重，在这个意义上是最优的。不同的是，默认算法一次只看到一个单元，因此将只对那些接触曲面流形的单元应用最优算法。相反，在整个<i>patches</i>个单元上使用转义映射（源于一个较粗的单元），可以用转义插值法，将信息从边界传播到远处的单元。




<h3>Transfinite interpolation is expensive and how to deal with it</h3>

一个具有无限流形描述的网格通常分两步建立。第一步是创建一个粗略的网格（或者从文件中读入），并在一些网格实体上附加一个曲面流形。对于上面的圆盘例子，我们将极坐标流形附加到沿外圆的面（这是由 GridGenerator::hyper_ball()). 自动完成的）在我们开始细化网格之前，我们再为网格的所有内部单元和边缘分配一个TransfiniteInterpolationManifold，当然，这需要基于我们分配给这些实体的一些流形ID（除了边界上的圆以外的一切）。我们是否也给圆盘的内部正方形分配一个TransfiniteInterpolationManifold并不重要，因为对具有直边（或3D中的平坦面）的粗单元进行Transfinite插值，只是产生具有直边（平坦面）的细分子。

之后，当网格被细化或基于此网格建立高阶映射时，单元将查询底层流形对象的新点。这个过程需要一组周围的点，例如一个二维单元的四个顶点，以及一组对这些点的权重，用于定义一个新的点。对于一个单元格的中间点，四个顶点中的每一个都将得到0.25的权重。对于无限插值流形，建立加权和的过程需要一些严肃的工作。根据结构，我们要根据周围点的参考坐标 $\xi$ 和 $\eta$ （或三维的 $\xi, \eta, \zeta$ ）来组合这些点。然而，deal.II中流形类的接口并没有得到周围点的参考坐标（因为它们不是全局存储的），而只是物理坐标。因此，无限插值流形必须做的第一步是反转映射，并在无限插值的一个粗网格单元内找到参考坐标（例如，上述磁盘网格的四个阴影粗网格单元之一）。这种反演是通过牛顿迭代（或者说，基于有限差分的牛顿方案与布罗伊登方法相结合）完成的，并根据上述公式多次查询无限期插值。这些查询中的每一次都可能依次调用一个昂贵的流形，例如球的球形描述，并且本身就很昂贵。由于deal.II的Manifold接口类只提供了一组点，所以转置插值最初甚至不知道周围的点集属于哪个粗大的网格单元，需要根据一些启发式方法在几个单元中搜索。就<a
href="https://en.wikipedia.org/wiki/Atlas_(topology)#Charts">charts</a>而言，我们可以把无限插值的实现描述为基于<a
href="https://en.wikipedia.org/wiki/Atlas_(topology)">atlas</a>的实现。三角形初始粗网格的每个单元都代表一个有自己参考空间的图表，而周围的流形提供了一种从图表空间（即参考单元）到物理空间的转换方式。粗网格单元的图表的集合是一个图集，像往常一样，在图集中查找东西时，人们做的第一件事就是找到正确的图表。

一旦找到周围点的参考坐标，参考坐标系中的新点将通过简单的加权和计算出来。最后，参考点被插入到无限插值的公式中，这就得到了所需的新点。

在许多情况下，曲面流形不仅在网格细化过程中使用，而且还用于确保计算域单元内边界的曲面表示。这对于保证复杂几何上的高阶多项式的高阶收敛性是必须的，但有时对于线性形状函数也需要一个精确的几何。这通常是通过对单元的多项式描述来实现的，如果表示曲面网格元素的多项式程度与数值解的多项式程度相同，则称为等参数概念。如果几何体的度数高于或低于解的度数，则分别称为超参数或次参数的几何体表示。在deal.II中，多项式表示的标准类是MappingQGeneric。例如，如果在三维中使用这个类的多项式度数 $4$ ，总共需要125个（即 $(4+1)^3$ ）点来进行内插。在这些点中，8个是单元的顶点，已经可以从网格中获得，但其他117个点需要由流形提供。如果使用无限插值流形，我们可以想象，通过回拉到一些尚未确定的粗略单元的参考坐标，然后在117个点中的每个点上进行后续的前推，是一个大量的工作，可能非常耗时。

更糟糕的是，许多程序的结构是这样的：对于同一个单元，映射被独立地查询了几次。它的主要用途是组装线性系统，即通过FEValues对象的`mapping`参数计算系统矩阵和右手边。然而，边界值的插值、数值误差的计算、输出的写入以及误差估计器的评估也必须涉及相同的映射，以确保对解向量的一致解释。因此，即使是解决一次的线性静止问题，也会多次评估映射的点。对于上面提到的三维案例，这意味着通过昂贵的算法多次计算每个单元的117个点。对于非线性或随时间变化的问题，情况更加紧迫，这些操作要反复进行。

由于通过无限插值进行流形描述的成本比对平流形的类似查询要高几百倍，所以只计算一次额外的点并在所有后续调用中使用这些点是有意义的。deal.II库提供的MappingQCache类正是为了这个目的。与系统矩阵所消耗的内存相比，这个缓存通常不会太大，在看这个教程程序的结果时就会明白。MappingQCache的用法很简单。一旦网格被设置好（或在细化过程中被改变），我们就调用 MappingQCache::initialize() ，将所需的三角形以及所需的映射作为参数。然后，初始化会遍历网格的所有单元，并查询给定映射的附加点。这些点会被保存为单元的标识符，以便以后当映射计算一些与单元相关的量（如参考坐标和物理坐标之间的映射的Jacobian）时，它们可以被返回。

最后，我们提到，TransfiniteInterpolationManifold也使得网格的细化变得更加昂贵。在这种情况下，MappingQCache无济于事，因为它将计算随后不能再使用的点；目前在deal.II中不存在一个更有效的机制。然而，网格细化也包含许多其他昂贵的步骤，所以与其他计算相比，它并不是一个大问题。它在每个时间步长或非线性迭代中也最多只发生一次。

<h3>The test case</h3>

在这个教程程序中，TransfiniteInterpolationManifold与MappingQCache的结合被举例说明。这个测试案例相对简单，占用了许多典型程序中涉及的解决阶段，例如步骤6的教程程序。作为一个几何体，我们选择了TransfiniteInterpolationManifold的一个使用原型，即涉及一个球形的设置，而这个球形又被一个立方体所包围。例如，这样的设置将用于嵌入背景介质中的球形包容物，如果该包容物具有不同的材料特性，需要通过元素界面来跟踪两种材料之间的界面。这里给出了一个可视化的网格。

 <img src="https://www.dealii.org/images/steps/developer/step-65-mesh.png" alt=""> 

对于这种情况，我们要在域内的表面附加一个球形描述，并使用转折插值来平滑地切换到外部立方体的直线和球中心的立方体。

在该程序中，我们将遵循有限元程序的典型流程，从DoFHandler和稀疏模式的设置开始，组装一个线性系统来解决带有跳跃系数的泊松方程，用一个简单的迭代方法解决，用 VectorTools::integrate_difference() 计算一些数值误差以及误差估计器。我们记录了每个部分的时间，并运行了两次代码。在第一次运行中，我们将一个MappingQGeneric对象分别交给程序的每个阶段，在这些阶段中，点被反复计算。在第二次运行中，我们用MappingQCache代替。


examples/step-65/doc/results.dox



<h1>Results</h1>

<h3>Program output</h3>

如果我们用三度的多项式运行这个程序的三维版本，我们会得到以下程序输出。

@code
> make run
Scanning dependencies of target \step-65
[ 33%] Building CXX object CMakeFiles/\step-65.dir/\step-65.cc.o
[ 66%] Linking CXX executable \step-65
[ 66%] Built target \step-65
[100%] Run \step-65 with Release configuration


====== Running with the basic MappingQGeneric class ======


   Number of active cells:       6656
   Number of degrees of freedom: 181609
   Number of solver iterations:  285
   L2 error vs exact solution:   8.99339e-08
   H1 error vs exact solution:   6.45341e-06
   Max cell-wise error estimate: 0.00743406



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      49.4s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble linear system          |         1 |       5.8s |        12% |
| Compute constraints             |         1 |     0.109s |      0.22% |
| Compute error estimator         |         1 |      16.5s |        33% |
| Compute error norms             |         1 |      9.11s |        18% |
| Solve linear system             |         1 |      9.92s |        20% |
| Write output                    |         1 |      4.85s |       9.8% |
+---------------------------------+-----------+------------+------------+


====== Running with the optimized MappingQCache class ======


   Memory consumption cache:     22.9981 MB
   Number of active cells:       6656
   Number of degrees of freedom: 181609
   Number of solver iterations:  285
   L2 error vs exact solution:   8.99339e-08
   H1 error vs exact solution:   6.45341e-06
   Max cell-wise error estimate: 0.00743406



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      18.4s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble linear system          |         1 |      1.44s |       7.8% |
| Compute constraints             |         1 |   0.00336s |         0% |
| Compute error estimator         |         1 |     0.476s |       2.6% |
| Compute error norms             |         1 |     0.505s |       2.7% |
| Initialize mapping cache        |         1 |      4.96s |        27% |
| Solve linear system             |         1 |      9.95s |        54% |
| Write output                    |         1 |     0.875s |       4.8% |
+---------------------------------+-----------+------------+------------+


[100%] Built target run
@endcode



在讨论时序之前，我们看一下MappingQCache对象的内存消耗。我们的程序打印出它占用了23MB的内存。如果我们把这个数字与单个（解或右侧）向量的内存消耗联系起来，即1.5MB（即181,609个元素乘以每条8字节的双精度），或者与系统矩阵和稀疏模式所消耗的内存联系起来（274MB），我们就会发现，考虑到它的好处，这并不是一个过于沉重的数据结构。

在计时器方面，我们看到程序的整体运行时间明显改善了2.7倍。如果我们不考虑迭代求解器，它在两种情况下都是一样的（考虑到我们使用的简单预处理程序，以及稀疏矩阵-向量乘积对立方多项式的操作浪费的事实，它并不是最佳的），优势是几乎5倍。这对于一个线性静止问题来说是相当令人印象深刻的，而对于时间依赖性和非线性问题来说，成本的节省确实要突出得多，因为在这些问题上，会多次调用装配。如果我们研究一下各个组件，我们就会更清楚地了解发生了什么，以及为什么缓存会如此高效。在MappingQGeneric的情况下，基本上每一个涉及到映射的操作都需要至少5秒的时间来运行。规范的计算运行了两个 VectorTools::integrate_difference() 函数，每个都需要5秒。(约束条件的计算比较便宜，因为它只在边界的单元格中评估映射，用于边界条件的插值)。如果我们将这5秒与填充MappingQCache的时间相比较，即5.2秒（对于所有单元，而不仅仅是活动单元），很明显，在MappingQGeneric的情况下，映射支持点的计算比其他一切都重要。也许最引人注目的结果是误差估计器的时间，标记为 "计算误差估计器"，其中MappingQGeneric的实现需要17.3秒，而MappingQCache的变体不到0.5秒。前者如此昂贵的原因（比如说，比装配贵三倍）是误差估计涉及到对面的量的评估，其中网格中的每个面都要求映射的额外点，而这些点又要经过非常昂贵的TransfiniteInterpolationManifold类。由于每个单元有六个面，这种情况比在装配中发生得更频繁。同样，MappingQCache很好地消除了重复评估，将所有涉及流形的昂贵步骤汇总到一个被重复使用的初始化调用中。


examples/step-66/doc/intro.dox

 <br> 

<i>
This program was contributed by Fabian Castelli.


A version of this code was presented and discussed in
@cite castelli2021numerical
G.F. Castelli: Numerical Investigation of Cahn-Hilliard-Type Phase-Field
Models for Battery Active Particles, PhD thesis, Karlsruhe Institute of
Technology (KIT), 2021. (To be published)


Fabian Castelli acknowledges financial support by the German Research
Foundation (DFG) through the Research Training Group 2218 SiMET -- Simulation
of mechano-electro-thermal processes in lithium-ion batteries, project number
281041241.


Finally Fabian Castelli would like to thank Timo Heister for the encouragement
and advice in writing this tutorial.
</i>


<a name="Intro"></a>

<h1>Introduction</h1>

本教程程序的目的是演示如何在无矩阵框架内使用牛顿方法解决一个非线性问题。本教程结合了在步骤15、步骤16、步骤37、步骤48和其他中已经介绍的几种技术。




<h3>Problem formulation</h3>在单位圆 $\Omega = \bigl\{ x \in \mathbb{R}^2 : \|x\| \leq 1 \bigr\}$ 上，我们考虑以下非线性椭圆边界值问题，受制于同质狄里奇边界条件。找到一个函数 $u\colon\Omega\to\mathbb{R}$ ，使其成立。

@f{align*}


    - \Delta u &= \exp(u) & \quad & \text{in } \Omega,\\
             u &= 0       & \quad & \text{on } \partial\Omega.


@f}

这个问题也被称为 <i>Gelfand problem</i> ，是燃烧理论问题的一个典型例子，例如见  @cite bebernes1989mathematical  。




<h3>Discretization with finite elements</h3> 像往常一样，我们首先推导出这个问题的弱式公式，用一个光滑的测试函数 $v\colon\Omega\to\mathbb{R}$ 乘以边界条件，在域 $\Omega$ 上积分。通过部分积分，并将右边的项放到左边，就得到了弱式计算。找到一个函数 $u\colon\Omega\to\mathbb{R}$ ，使其对所有测试函数 $v$ 都成立。

@f{align*}{
 \int_\Omega \nabla v \cdot \nabla u \,\mathrm{d}x


 -
 \int_\Omega v \exp(u) \,\mathrm{d}x
 =
 0.


@f}



选择拉格朗日有限元空间 $V_h \dealcoloneq
\bigl\{ v \in C(\overline{\Omega}) : v|_Q \in \mathbb{Q}_p \text{ for all }
Q \in \mathcal{T}_h \bigr\} \cap H_0^1(\Omega)$ ，它直接包含了同质Dirichlet边界条件，我们可以定义一个基 $\{\varphi_i\}_{i=1,\dots,N}$ ，因此只需用这些基函数进行测试。因此离散的问题如下。找到 $u_h\in V_h$ ，使得对所有 $i=1,\dots,N$ 都成立。

@f{align*}{
 F(u_h)
 \dealcoloneq
 \int_\Omega \nabla \varphi_i \cdot \nabla u_h \,\mathrm{d}x


 -
 \int_\Omega \varphi_i \exp(u_h) \,\mathrm{d}x \stackrel{!}{=} 0.


@f}

由于每个有限元函数是基函数 $\{\varphi_i\}_{i=1,\dots,N}$ 的线性组合，我们可以通过 $\mathbb{R}^N$ 中由每个自由度（DOF）中的未知值组成的向量来确定有限元解决方案。因此，我们定义非线性函数 $F\colon\mathbb{R}^N\to\mathbb{R}^N$ 代表离散非线性问题。

为了解决这个非线性问题，我们使用牛顿方法。因此，给定一个初始猜测 $u_h^0\in V_h$ ，它已经满足了Dirichlet边界条件，我们通过连续应用以下方案确定一连串的牛顿步骤 $\bigl( u_h^n \bigr)_n$ 。

@f{align*}{
 &\text{Solve for } s_h^n\in V_h: \quad & F'(u_h^n)[s_h^n] &= -F(u_h^n),\\
 &\text{Update: }                       & u_h^{n+1} &= u_h^n + s_h^n.


@f}

因此，在每个牛顿步骤中，我们必须解决一个线性问题  $A\,x = b$  ，其中系统矩阵  $A$  由雅各布  $F'(u_h^n)[\,\cdot\,]\colon\mathbb{R}^N\to\mathbb{R}^N$  表示，右手  $b$  由负残差  $-F(u_h^n)$  表示。在这种情况下，解向量 $x$ 是 $n$ 的第1个牛顿步骤的牛顿更新。注意，我们假设初始猜测 $u_h^0$ ，它已经满足了问题公式中的迪里希特边界条件（事实上这也可能是一个不均匀的迪里希特边界条件），因此牛顿更新 $s_h$ 满足一个均匀的迪里希特条件。

到目前为止，我们只测试了基函数，然而，我们也可以将 $V_h$ 的任何函数表示为基函数的线性组合。在数学上，这意味着 $V_h$ 的每个元素都可以通过表示公式与向量 $U\in\mathbb{R}^N$ 相识别。   $u_h = \sum_{i=1}^N U_i \varphi_i$  .因此，利用这一点我们可以给出离散雅各布和残差的表达式。

@f{align*}{
 A_{i,j} = \bigl( F'(u_h^n) \bigr)_{i,j}
 &=
 \int_\Omega \nabla\varphi_i \cdot \nabla \varphi_j \,\mathrm{d} x


 -
 \int_\Omega \varphi_i \, \exp( u_h ) \varphi_j \,\mathrm{d} x,\\
 b_{i} = \bigl( F(u_h^n) \bigr)_{i}
 &=
 \int_\Omega \nabla\varphi_i \cdot \nabla u_h^n \,\mathrm{d} x


 -
 \int_\Omega \varphi_i \, \exp( u_h^n ) \,\mathrm{d} x.


@f}

与第15步相比，我们也可以形成与问题的强表述相对应的非线性函数的Frech{'e}t导数，并在之后将其离散化。然而，最终我们会得到相同的离散方程组。




<h3>Numerical linear algebra</h3> 注意，系统矩阵，实际上是Jacobian，如何取决于前一个牛顿步骤  $A = F'(u^n)$  。因此，我们需要告诉计算系统矩阵的函数关于最后一个牛顿步骤的解决方案。在一个经典的 <code>assemble_system()</code> 函数的实现中，我们将通过使用成员函数 FEValuesBase::get_function_values() 和 FEValuesBase::get_function_gradients(). 从装配过程中的最后一个牛顿步骤中收集这些信息，然后 <code>assemble_system()</code> 函数看起来像。

@code
template <int dim>
void GelfandProblem<dim>::assemble_system()
{
  system_matrix = 0;
  system_rhs    = 0;


  const QGauss<dim> quadrature_formula(fe.degree + 1);
  FEValues<dim>     fe_values(fe,
                          quadrature_formula,
                          update_values | update_gradients | update_JxW_values);


  const unsigned int n_q_points    = fe_values.n_quadrature_points;
  const unsigned int dofs_per_cell = fe_values.dofs_per_cell;


  FullMatrix<double>                   cell_matrix(dofs_per_cell);
  Vector<double>                       cell_rhs(dofs_per_cell);
  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);


  std::vector<Tensor<1, dim>> newton_step_gradients(n_q_points);
  std::vector<double>         newton_step_values(n_q_points);



  for (const auto &cell : dof_handler.active_cell_iterators())
    {
      cell_matrix = 0.0;
      cell_rhs    = 0.0;


      fe_values.reinit(cell);


      fe_values.get_function_values(solution, newton_step_values);
      fe_values.get_function_gradients(solution, newton_step_gradients);


      for (unsigned int q = 0; q < n_q_points; ++q)
        {
          const double nonlinearity = std::exp(newton_step_values[q]);
          const double dx           = fe_values.JxW(q);


          for (unsigned int i = 0; i < dofs_per_cell; ++i)
            {
              const double         phi_i      = fe_values.shape_value(i, q);
              const Tensor<1, dim> grad_phi_i = fe_values.shape_grad(i, q);


              for (unsigned int j = 0; j < dofs_per_cell; ++j)
                {
                  const double         phi_j      = fe_values.shape_value(j, q);
                  const Tensor<1, dim> grad_phi_j = fe_values.shape_grad(j, q);


                  cell_matrix(i, j) +=
                    (grad_phi_i * grad_phi_j - phi_i * nonlinearity * phi_j) *
                    dx;
                }


              cell_rhs(i) += (-grad_phi_i * newton_step_gradients[q] +
                              phi_i * newton_step_values[q]) *
                             dx;
            }
        }


      cell->get_dof_indices(local_dof_indices);


      constraints.distribute_local_to_global(
        cell_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);
    }
}
@endcode



由于我们想在不存储矩阵的情况下解决这个问题，我们需要在使用之前告诉无矩阵算子这些信息。因此在派生类 <code>JacobianOperator</code> 中，我们将实现一个名为 <code>evaluate_newton_step</code> 的函数，它将在使用矩阵-向量实现之前处理最后一个牛顿步骤的信息。此外，我们想对线性求解器使用几何多网格（GMG）预处理，所以为了应用多级算子，我们需要将最后一个牛顿步骤也传递给这些算子。这是一项棘手的任务，因为包含最后一个牛顿步骤的向量必须被插值到三角形的所有层面。在代码中，这项任务将由函数 MGTransferMatrixFree::interpolate_to_mg(). 完成。注意，与之前的案例有一个根本的区别，即我们设置并使用了一个几何多网格预处理程序，我们可以重复使用MGTransferMatrixFree对象来计算所有牛顿步。所以我们在这里可以通过定义一个类变量，使用已经设置好的MGTransferMatrixFree对象 <code>mg_transfer</code> ，并在 <code>setup_system()</code> 函数中初始化，从而节省一些工作。

@code
template <int dim, int fe_degree>
void GelfandProblem<dim, fe_degree>::compute_update()
{
  TimerOutput::Scope t(computing_timer, "compute update");


  solution.update_ghost_values();


  system_matrix.evaluate_newton_step(solution);


  mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);



  // Set up options for the multilevel preconditioner
  // ...


  for (unsigned int level = 0; level < triangulation.n_global_levels(); ++level)
    {
      mg_matrices[level].evaluate_newton_step(mg_solution[level]);
    }


  // Define the actual preconditioner
  // ...


  // Solve the linear system
  // ...
}
@endcode



评估非线性的函数与评估系数函数的步骤37的函数 <code>evaluate_coefficient</code> 的工作方式基本相同。我们的想法是使用一个FEEvaluation对象来评估牛顿步骤，并将所有单元和所有正交点的表达式存储在一个表中。

@code
template <int dim, int fe_degree, typename number>
void JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(
  const LinearAlgebra::distributed::Vector<number> &newton_step)
{
  const unsigned int n_cells = this->data->n_cell_batches();


  FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi(*this->data);


  nonlinear_values.reinit(n_cells, phi.n_q_points);


  for (unsigned int cell = 0; cell < n_cells; ++cell)
    {
      phi.reinit(cell);
      phi.read_dof_values_plain(newton_step);
      phi.evaluate(EvaluationFlags::values);


      for (unsigned int q = 0; q < phi.n_q_points; ++q)
        {
          nonlinear_values(cell, q) = std::exp(phi.get_value(q));
        }
    }
}
@endcode






<h3>Triangulation</h3> 正如在步骤37中所说，如果我们选择高阶有限元空间，无矩阵方法会变得更有效率。由于我们想在 $d$ 维的单位球上解决问题，最好有一个适当的边界近似来克服收敛问题。出于这个原因，我们使用MappingQGeneric类的等参数方法来恢复平滑边界以及内单元的映射。此外，为了得到一个好的三角形，我们使用了TransfiniteInterpolationManifold。


examples/step-66/doc/results.dox



<h1>Results</h1>

这个教程步骤的目的是演示用无矩阵框架解决一个非线性PDE。




<h3>Program output</h3> 在两个进程上以释放模式运行程序，通过

@code
cmake . && make release && make && mpirun -n 2 ./step-66
@endcode

在控制台给出了以下输出

@code
================================================================================
START DATE: 2021/5/18, TIME: 16:25:48


--------------------------------------------------------------------------------
Running with 2 MPI processes
Vectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2
Finite element space: FE_Q<2>(4)
================================================================================


--------------------------------------------------------------------------------
Cycle 0


--------------------------------------------------------------------------------
Set up system...
   Triangulation: 20 cells
   DoFHandler:    337 DoFs


Solve using Newton's method...
   Nstep 1, errf = 0.00380835, errx = 3.61904, it = 7
   Nstep 2, errf = 3.80167e-06, errx = 0.104353, it = 6
   Nstep 3, errf = 3.97939e-12, errx = 0.00010511, it = 4
   Nstep 4, errf = 2.28859e-13, errx = 1.07726e-10, it = 1
Convergence step 4 value 2.28859e-13 (used wall time: 0.0096409 s)


Time for setup+solve (CPU/Wall) 0.015617/0.0156447 s


Output results...
  H1 seminorm: 0.773426





+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |    0.0286s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assemble right hand side        |         4 |  9.71e-05s |      0.34% |
| compute residual                |         4 |  0.000137s |      0.48% |
| compute update                  |         4 |   0.00901s |        32% |
| make grid                       |         1 |   0.00954s |        33% |
| setup system                    |         1 |   0.00585s |        20% |
| solve                           |         1 |   0.00966s |        34% |
+---------------------------------+-----------+------------+------------+


.
.
.


--------------------------------------------------------------------------------
Cycle 6


--------------------------------------------------------------------------------
Set up system...
   Triangulation: 81920 cells
   DoFHandler:    1311745 DoFs


Solve using Newton's method...
   Nstep 1, errf = 5.90478e-05, errx = 231.427, it = 9
   Nstep 2, errf = 5.89991e-08, errx = 6.67102, it = 6
   Nstep 3, errf = 4.28813e-13, errx = 0.0067188, it = 4
Convergence step 3 value 4.28813e-13 (used wall time: 4.82953 s)


Time for setup+solve (CPU/Wall) 6.25094/6.37174 s


Output results...
  H1 seminorm: 0.773426





+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      9.04s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assemble right hand side        |         3 |    0.0827s |      0.91% |
| compute residual                |         3 |    0.0909s |         1% |
| compute update                  |         3 |      4.65s |        51% |
| setup system                    |         1 |      1.54s |        17% |
| solve                           |         1 |      4.83s |        53% |
+---------------------------------+-----------+------------+------------+


================================================================================
START DATE: 2021/5/18, TIME: 16:26:00


--------------------------------------------------------------------------------
Running with 2 MPI processes
Vectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2
Finite element space: FE_Q<3>(4)
================================================================================


.
.
.


--------------------------------------------------------------------------------
Cycle 5


--------------------------------------------------------------------------------
Set up system...
   Triangulation: 229376 cells
   DoFHandler:    14729857 DoFs


Solve using Newton's method...
   Nstep 1, errf = 6.30096e-06, errx = 481.74, it = 8
   Nstep 2, errf = 4.25607e-10, errx = 4.14315, it = 6
   Nstep 3, errf = 7.29563e-13, errx = 0.000321775, it = 2
Convergence step 3 value 7.29563e-13 (used wall time: 133.793 s)


Time for setup+solve (CPU/Wall) 226.809/232.615 s


Output results...
  H1 seminorm: 0.588667





+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |       390s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assemble right hand side        |         3 |      2.06s |      0.53% |
| compute residual                |         3 |      2.46s |      0.63% |
| compute update                  |         3 |       129s |        33% |
| setup system                    |         1 |      98.8s |        25% |
| solve                           |         1 |       134s |        34% |
+---------------------------------+-----------+------------+------------+
@endcode



我们在下图中展示了二维和三维问题的解决方案。

<div class="twocolumn" style="width: 80%; text-align: center;"> <div> <img src="https://www.dealii.org/images/steps/developer/step-66.solution-2d.png" alt="二维格尔凡德问题的解决方案。" width = "100%"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-66.solution-3d.png" alt="三维格尔凡德问题的解决方案。" width = "100%"> </div> </div>




<h3>Newton solver</h3> 在上面的程序输出中，我们发现一些关于牛顿迭代的有趣信息。每个细化周期的终端输出显示了牛顿方法的详细诊断，首先显示了牛顿步骤的数量和每一步的残差规范  $\|F(u_h^{n+1})\|$  ，牛顿更新的规范  $\|s_h^n\|$  ，和CG迭代的数量  <code>it</code>  。

我们观察到，对于所有的情况，牛顿方法大约在三到四步内收敛，这显示了牛顿方法的全步长的二次收敛  $\alpha = 1$  。然而，请注意，对于一个选择不好的初始猜测 $u_h^0$ ，牛顿方法也会出现二次发散。通常情况下，如果你没有合适的初始猜测，你可以尝试几个阻尼的牛顿步骤，减少步长 $\alpha < 1$ ，直到牛顿步骤再次进入二次收敛域。这种阻尼和放松的牛顿步长确实需要一个更复杂的牛顿方法的实现，我们指定给你作为本教程的可能扩展。

此外，我们看到，随着连续的网格细化和DoF数量的增加，CG迭代的数量近乎恒定。这当然是由于几何多棱镜的预处理，而且与其他使用这种方法的教程中的观察结果相似，例如步骤16和步骤37。仅举一例，在三维案例中，经过五次细化后，我们有大约1470万个分布式DoFs的四阶拉格朗日有限元，但CG迭代的次数仍然少于10次。

此外，我们还应用了一个非常有用的优化，应该在此提及。在 <code>compute_update()</code> 函数中，我们在将持有牛顿更新的向量作为输出向量传递给求解器之前，明确地重置了它。在这种情况下，我们为CG方法使用了一个零的起始值，这比之前的牛顿更新、 <code>newton_update</code> 的实际内容在重置之前更合适，因此减少了几步CG迭代的次数。




<h3>Possibilities for extensions</h3> 有几个可能的扩展是关于本代码的小更新fo以及对Gelfand问题更深入的数值调查。

<h4>More sophisticated Newton iteration</h4> 除了步骤15中提到的牛顿迭代的步长控制版本外，我们还可以为牛顿迭代实施一个更灵活的停止标准。例如，我们可以取代残差的固定公差 <code>TOLf</code> and for the Newton updated <code>TOLx</code> ，并实现一个具有给定绝对和相对公差的混合误差控制，这样牛顿迭代就会成功，例如。

@f{align*}{
  \|F(u_h^{n+1})\| \leq \texttt{RelTol} \|u_h^{n+1}\| + \texttt{AbsTol}.


@f}

对于有许多非线性系统需要解决的更高级的应用，例如，在时间依赖性问题的每个时间步骤，事实证明，没有必要在每一个牛顿步骤甚至每个时间步骤中重新设置和组装雅各布系数。相反，在牛顿迭代中可以使用前一个步骤中的现有的Jacobian。然后，只有在例如牛顿迭代收敛过慢的情况下，才会重新建立雅各布系数。这样的想法产生了一个<a href="https://en.wikipedia.org/wiki/Quasi-Newton_method">quasi-Newton
method</a>。诚然，当使用无矩阵框架时，无论如何都会省略雅各布式的组装，但通过这种方式，可以尝试优化几何多网格预处理的重新组装。请记住，每次来自旧牛顿步骤的解决方案必须分布到所有层面，并且必须重新初始化多重网格预处理器。

<h4>Parallel scalability and thread parallelism</h4> 在step-37等人的结果部分，无矩阵框架在大量处理器上的并行可扩展性已经得到了非常令人印象深刻的证明。在我们这里考虑的非线性情况下，我们注意到瓶颈之一可能成为无矩阵雅可比算子及其多阶段算子在前一个牛顿步骤中的转移和评估，因为我们需要在每个步骤的所有阶段转移旧的解决方案。 @cite castelli2021numerical 中的第一个并行可扩展性分析显示，当问题规模足够大时，有相当好的强可扩展性。然而，为了得到可靠的结果，还需要进行更详细的分析。此外，到目前为止，这个问题只用MPI来解决，没有使用线程的共享内存并行化的可能性。因此，对于这个例子，你可以尝试用MPI和线程的混合并行化，如步骤-48中所述。

<h4>Comparison to matrix-based methods</h4> 类似于步骤50和提到的步骤75的可能扩展，你可以说服自己哪个方法更快。

<h4>Eigenvalue problem</h4> 我们可以考虑相应的特征值问题，这被称为布拉图问题。例如，如果我们定义一个固定的特征值  $\lambda\in[0,6]$  ，我们可以计算相应的离散特征函数。你会注意到，牛顿步骤的数量将随着 $\lambda$ 的增加而增加。为了减少牛顿步数，你可以使用以下技巧：从某个 $\lambda$ 开始，计算特征函数，增加 $\lambda=\lambda +
\delta_\lambda$ ，然后使用之前的解作为牛顿迭代的初始猜测。最后你可以画出 $H^1(\Omega)$ 在特征值 $\lambda \mapsto \|u_h\|_{H^1(\Omega)}$ 上的正负值。对于进一步增加  $\lambda>7$  你观察到什么？


examples/step-67/doc/intro.dox



 <br> 

<i>
This program was contributed by Martin Kronbichler. Many ideas presented here
are the result of common code development with Niklas Fehn, Katharina Kormann,
Peter Munch, and Svenja Schoeder.


This work was partly supported by the German Research Foundation (DFG) through
the project "High-order discontinuous Galerkin for the exa-scale" (ExaDG)
within the priority program "Software for Exascale Computing" (SPPEXA).
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

本教程程序使用显式时间积分器求解流体力学的欧拉方程，其无矩阵框架应用于空间的高阶非连续Galerkin离散化。关于欧拉系统的细节和另一种隐式方法，我们也参考了第33步教程程序。你可能还想看看第69步，看看解决这些方程的另一种方法。




<h3>The Euler equations</h3>

欧拉方程是一个守恒定律，描述了一个可压缩的无粘性气体的运动。

@f[
\frac{\partial \mathbf{w}}{\partial t} + \nabla \cdot \mathbf{F}(\mathbf{w}) =
\mathbf{G}(\mathbf w),


@f]

其中解向量的 $d+2$ 分量为 $\mathbf{w}=(\rho, \rho
u_1,\ldots,\rho u_d,E)^{\mathrm T}$  。这里， $\rho$  表示流体密度， ${\mathbf u}=(u_1,\ldots, u_d)^\mathrm T$  表示流体速度， $E$  表示气体的能量密度。速度不直接求解，而是用变量 $\rho \mathbf{u}$ ，即线性动量（因为这是一个守恒量）。

欧拉通量函数是一个 $(d+2)\times d$ 矩阵，定义为

@f[
  \mathbf F(\mathbf w)
  =
  \begin{pmatrix}
  \rho \mathbf{u}\\
  \rho \mathbf{u} \otimes \mathbf{u} + \mathbb{I}p\\
  (E+p)\mathbf{u}
  \end{pmatrix}


@f]

其中 $\mathbb{I}$ 为 $d\times d$ 身份矩阵， $\otimes$ 为外积；其组成部分分别表示质量、动量和能量通量。右手边的强制力由以下公式给出

@f[
  \mathbf G(\mathbf w)
  =
  \begin{pmatrix}
  0\\
  \rho\mathbf{g}\\
  \rho \mathbf{u} \cdot \mathbf{g}
  \end{pmatrix},


@f]

其中矢量 $\mathbf g$ 表示重力的方向和大小。然而，它也可以表示作用于流体的任何其他单位质量的外力。例如，想想外部电场对带电粒子所施加的静电力）。

这三块方程，第二块涉及 $d$ 成分，描述了质量、动量和能量的守恒。压力不是一个解决方案的变量，但需要通过其他变量的 "闭合关系 "来表达；我们在此选择适合由两个原子组成的分子的气体的关系，在中等温度下，由 $p=(\gamma - 1) \left(E-\frac 12 \rho
\mathbf{u}\cdot \mathbf{u}\right)$ 和常数 $\gamma = 1.4$ 给出。




<h3>High-order discontinuous Galerkin discretization</h3>

对于空间离散化，我们使用高阶非连续加勒金（DG）离散化，使用的解扩展形式为

@f[
\mathbf{w}_h(\mathbf{x}, t) =
\sum_{j=1}^{n_\mathbf{dofs}} \boldsymbol{\varphi}_j(\mathbf{x}) {w}_j(t).


@f]

这里， $\boldsymbol{\varphi}_j$ 表示第 $j$ 个基函数，以矢量形式写出不同成分的独立形状函数，让 $w_j(t)$ 分别通过密度、动量和能量变量。在这种形式下，空间依赖性包含在形状函数中，时间依赖性包含在未知系数中  $w_j$  。与连续有限元方法中一些形状函数跨越元素边界不同，在DG方法中，形状函数是单个元素的局部，从一个元素到下一个元素是不连续的。从一个单元到其相邻单元的解的连接是由下面规定的数值通量来实现的。这允许一些额外的灵活性，例如，在数值方法中引入方向性，例如，上卷。

DG方法是解决传输特性问题的流行方法，因为它们结合了低分散误差和勉强解决的尺度上的可控耗散。这使得它们在流体动力学领域的模拟中特别有吸引力，因为在这个领域中，需要代表广泛的活动尺度，不充分解决的特征很容易干扰重要的良好解决的特征。此外，高阶DG方法非常适用于现代硬件的正确实施。同时，DG方法也不是万能的。特别是当解出现不连续（冲击）时，就像欧拉方程在某些流态下的典型情况一样，高阶DG方法容易出现振荡解，就像所有不使用通量或坡度限制器的高阶方法一样。这是<a
href="https://en.wikipedia.org/wiki/Godunov%27s_theorem">Godunov's theorem</a>的结果，即任何线性的总变差（TVD）方案（如基本的DG离散化）最多只能达到一阶精度。换句话说，由于DG方法的目标是高阶精度，因此它们不可能对出现冲击的解进行TVD。尽管有些人声称DG方法中的数值通量可以控制耗散，但除非问题中的<b>all</b>冲击与单元边界对齐，否则这一点的价值有限。任何穿过单元内部的冲击都会因为高阶多项式而再次产生振荡分量。在有限元和DG界，存在许多不同的方法来处理冲击，例如在有问题的单元上引入人工扩散（使用基于解的模态分解等的有问题单元指标），在子网格上转换为耗散性低阶有限体积方法，或者增加一些限制程序。考虑到这种情况下的大量可能性，再加上相当大的实施努力，我们在这里不考虑带有明显冲击的欧拉方程系统，而是集中在带有波浪状现象的亚音速流动系统。对于一个能很好地处理冲击的方法（但每个未知数的成本较高），我们可以参考step-69教程程序。

对于DG公式的推导，我们将欧拉方程与测试函数 $\mathbf{v}$ 相乘，并对单个单元进行积分 $K$ ，从而得到

@f[
\left(\mathbf{v}, \frac{\partial \mathbf{w}}{\partial t}\right)_{K}
+ \left(\mathbf{v}, \nabla \cdot \mathbf{F}(\mathbf{w})\right)_{K} =
\left(\mathbf{v},\mathbf{G}(\mathbf w)\right)_{K}.


@f]



然后我们对第二项进行分项积分，将分歧从解槽移到测试函数槽，并产生一个元素边界上的积分。

@f[
\left(\mathbf{v}, \frac{\partial \mathbf{w}}{\partial t}\right)_{K}


- \left(\nabla \mathbf{v}, \mathbf{F}(\mathbf{w})\right)_{K}
+ \left<\mathbf{v}, \mathbf{n} \cdot \widehat{\mathbf{F}}(\mathbf{w})
\right>_{\partial K} =
\left(\mathbf{v},\mathbf{G}(\mathbf w)\right)_{K}.


@f]

在表面积分中，我们用术语 $\widehat{\mathbf{F}}(\mathbf w)$ 代替了术语 $\mathbf{F}(\mathbf w)$ ，即数值通量。数字通量的作用是连接相邻元素上的解，并弱化解的连续性。这保证了PDE的全局耦合反映在离散化中，尽管单元上有独立的基函数。通过将数值通量定义为来自内部面两侧的解的函数 $\widehat{\mathbf{F}}(\mathbf w^-,
\mathbf w^+)$ 和 $\mathbf w^+$ ，包括与邻居的连接。我们要求的一个基本属性是，数值通量需要是<b>conservative</b>。也就是说，我们希望所有的信息（即质量、动量和能量）在一个面上离开一个单元时，都能完整地进入邻近的单元，反之亦然。这可以表示为 $\widehat{\mathbf{F}}(\mathbf w^-, \mathbf w^+) =
\widehat{\mathbf{F}}(\mathbf w^+, \mathbf w^-)$ ，也就是说，数值通量从任何一边都评估为相同的结果。结合数值通量与所考虑的面的单位外法向量相乘的事实，即从两边指向相反的方向，我们看到守恒被满足了。数值通量的另一个观点是作为一个单值的中间状态，从两边微弱地连接解决方案。

有大量的数值通量函数可用，也称为黎曼解算器。对于欧拉方程，存在所谓的精确黎曼求解器--意味着来自双方的状态以一种与欧拉方程沿线不连续的方式结合起来--以及近似黎曼求解器，它违反了一些物理特性，并依靠其他机制来使方案总体上准确。近似黎曼求解器的优点是计算起来比较便宜。大多数通量函数都起源于有限体积界，它们类似于单元（称为体积）内的多项式0度的DG方法。由于欧拉算子 $\mathbf{F}$ 的体积积分对于恒定解和检验函数会消失，所以数值通量必须完全代表物理算子，这也解释了为什么该界有大量的研究。对于DG方法，一致性是由单元内的高阶多项式保证的，这使得数值通量不再是一个问题，通常只影响收敛率，例如，对于度数为 $\mathcal O(h^p)$ 的多项式，解是否收敛为 $\mathcal O(h^{p+1/2})$ 或 $\mathcal
O(h^{p+1})$ 的准则。因此，数值通量可以被看作是一种机制，用于选择更有利的耗散/分散特性或关于离散化和线性化算子的极值特征，这影响到显式时间积分器中最大的可接受的时间步长。

在这个教程程序中，我们实现了两种通量的变体，可以通过程序中的开关来控制（当然，要使它们成为通过输入文件控制的运行时参数也很容易）。第一个通量是本地的Lax--Friedrichs通量

@f[
\hat{\mathbf{F}}(\mathbf{w}^-,\mathbf{w}^+) =
\frac{\mathbf{F}(\mathbf{w}^-)+\mathbf{F}(\mathbf{w}^+)}{2} +
   \frac{\lambda}{2}\left[\mathbf{w}^--\mathbf{w}^+\right]\otimes
   \mathbf{n^-}.


@f]



在Lax--Friedrichs通量的原始定义中，使用了一个系数 $\lambda =
\max\left(\|\mathbf{u}^-\|+c^-, \|\mathbf{u}^+\|+c^+\right)$ （对应于信息在界面两边移动的最大速度），说明两个状态之间的差异， $[\![\mathbf{w}]\!]$ 被欧拉通量中的最大特征值惩罚，即 $\|\mathbf{u}\|+c$  ，其中 $c=\sqrt{\gamma p / \rho}$  是音速。在下面的实现中，我们对惩罚项进行了一些修改，因为无论如何惩罚都是近似的。我们使用

@f{align*}{
\lambda
&=
\frac{1}{2}\max\left(\sqrt{\|\mathbf{u^-}\|^2+(c^-)^2},
                     \sqrt{\|\mathbf{u}^+\|^2+(c^+)^2}\right)
\\
&=
\frac{1}{2}\sqrt{\max\left(\|\mathbf{u^-}\|^2+(c^-)^2,
                           \|\mathbf{u}^+\|^2+(c^+)^2\right)}.


@f}

额外的因子 $\frac 12$ 降低了惩罚强度（这导致特征值的负实部减少，从而增加了可接受的时间步长）。使用和内的平方允许我们减少昂贵的平方根操作的数量，对于原始的Lax--Friedrichs定义是4个，现在只需要一个。这种简化导致参数 $\lambda$ 的减少最多为2倍，因为 $\|\mathbf{u}\|^2+c^2 \leq
\|\mathbf{u}\|^2+2 c |\mathbf{u}\| + c^2 = \left(\|\mathbf{u}\|+c\right)^2
\leq 2 \left(\|\mathbf{u}\|^2+c^2\right)$ ，最后一个不等式来自杨氏不等式。

第二个数值通量是由Harten、Lax和van Leer提出的，称为HLL通量。它考虑到欧拉方程的不同传播方向，取决于声速。它利用一些中间状态  $\bar{\mathbf{u}}$  和  $\bar{c}$  来定义两个分支  $s^\mathrm{p} = \max\left(0, \bar{\mathbf{u}}\cdot \mathbf{n} +
\bar{c}\right)$  和  $s^\mathrm{n} = \min\left(0, \bar{\mathbf{u}}\cdot
\mathbf{n} - \bar{c}\right)$  。从这些分支中，人们再定义出通量

@f[
\hat{\mathbf{F}}(\mathbf{w}^-,\mathbf{w}^+) =
\frac{s^\mathrm{p} \mathbf{F}(\mathbf{w}^-)-s^\mathrm{n} \mathbf{F}(\mathbf{w}^+)}
                   {s^\mathrm p - s^\mathrm{n} } +
\frac{s^\mathrm{p} s^\mathrm{n}}{s^\mathrm{p}-s^\mathrm{n}}
\left[\mathbf{w}^--\mathbf{w}^+\right]\otimes \mathbf{n^-}.


@f]

关于中间状态的定义  $\bar{\mathbf{u}}$  和  $\bar{c}$  ，已经提出了几个变种。最初提出的变体使用密度平均的速度定义，  $\bar{\mathbf{u}}
= \frac{\sqrt{\rho^-} \mathbf{u}^- + \sqrt{\rho^+}\mathbf{u}^+}{\sqrt{\rho^-}
+ \sqrt{\rho^+}}$  。由于我们考虑的是没有冲击的欧拉方程，因此在本教程程序中，我们简单地使用算术平均值， $\bar{\mathbf{u}} = \frac{\mathbf{u}^- +
\mathbf{u}^+}{2}$ 和 $\bar{c} = \frac{c^- + c^+}{2}$ ，与 $c^{\pm} =
\sqrt{\gamma p^{\pm} / \rho^{\pm}}$ ，而把其他变体留给可能的扩展。我们还注意到，HLL通量在文献中被扩展为所谓的HLLC通量，其中C代表表示接触不连续的能力。

在没有邻接状态 $\mathbf{w}^+$ 的边界上，通常的做法是从边界条件中推导出合适的外部值（详见关于DG方法的一般文献）。在这个教程程序中，我们考虑三种类型的边界条件，即<b>inflow boundary conditions</b>，其中所有分量都是规定的。

@f[
\mathbf{w}^+ = \begin{pmatrix} \rho_\mathrm{D}(t)\\
(\rho \mathbf u)_{\mathrm D}(t) \\ E_\mathrm{D}(t)\end{pmatrix} \quad
 \text{(Dirichlet)},


@f]

<b>subsonic outflow boundaries</b>，在这里我们不规定外部解，因为流场要离开域，而使用内部值；我们仍然需要规定能量，因为欧拉通量中还有一个传入特性。

@f[
\mathbf{w}^+ = \begin{pmatrix} \rho^-\\
(\rho \mathbf u)^- \\ E_\mathrm{D}(t)\end{pmatrix} \quad
 \text{(mixed Neumann/Dirichlet)},


@f]

和<b>wall boundary condition</b>，它们描述了无渗透配置。

@f[
\mathbf{w}^+ = \begin{pmatrix} \rho^-\\
(\rho \mathbf u)^- - 2 [(\rho \mathbf u)^-\cdot \mathbf n] \mathbf{n}
 \\ E^-\end{pmatrix}.


@f]



解的多项式展开最后被插入到弱形式，测试函数被基函数取代。这就得到了一个空间上离散、时间上连续的非线性系统，其未知系数的数量有限  $w_j$  ,  $j=1,\ldots,n_\text{dofs}$  。关于DG方法中多项式度数的选择，截至2019年，文献中并没有关于什么多项式度数最有效的共识，决定取决于问题。高阶多项式可以确保更好的收敛率，因此对于中等到高精确度要求的<b>smooth</b>解来说，高阶多项式更有优势。同时，自由度所在的体积与表面的比率，随着高阶的增加而增加，这使得数值通量的影响变弱，通常会减少耗散。然而，在大多数情况下，解决方案是不平滑的，至少与可以承受的分辨率相比是不平滑的。例如，在不可压缩流体力学、可压缩流体力学以及与之相关的波浪传播课题中都是如此。在这个前渐进制度中，误差大约与数值分辨率成正比，而其他因素，如分散误差或耗散行为变得更加重要。非常高阶的方法往往被排除在外，因为它们带有根据未知数衡量的更多限制性的CFL条件，而且当涉及到表示复杂几何形状时，它们也不那么灵活。因此，2到6的多项式度数在实践中是最受欢迎的，例如见 @cite FehnWallKronbichler2019 中的效率评估和其中引用的参考文献。

<h3>Explicit time integration</h3>

为了进行时间离散化，我们稍微重新排列了弱的形式，并在所有单元上求和。

@f[
\sum_{K \in \mathcal T_h} \left(\boldsymbol{\varphi}_i,
\frac{\partial \mathbf{w}}{\partial t}\right)_{K}
=
\sum_{K\in \mathcal T_h}
\left[
\left(\nabla \boldsymbol{\varphi}_i, \mathbf{F}(\mathbf{w})\right)_{K}


-\left<\boldsymbol{\varphi}_i,
\mathbf{n} \cdot \widehat{\mathbf{F}}(\mathbf{w})\right>_{\partial K} +
\left(\boldsymbol{\varphi}_i,\mathbf{G}(\mathbf w)\right)_{K}
\right],


@f]

其中 $\boldsymbol{\varphi}_i$ 贯穿了从1到 $n_\text{dofs}$ 的所有基函数。

我们现在用 $\mathcal M$ 表示质量矩阵，其条目为 $\mathcal M_{ij} =
\sum_{K} \left(\boldsymbol{\varphi}_i,
\boldsymbol{\varphi}_j\right)_K$ ，并用

@f[
\mathcal L_h(t,\mathbf{w}_h) = \left[\sum_{K\in \mathcal T_h}
\left[
\left(\nabla \boldsymbol{\varphi}_i, \mathbf{F}(\mathbf{w}_h)\right)_{K}


- \left<\boldsymbol{\varphi}_i,
\mathbf{n} \cdot \widehat{\mathbf{F}}(\mathbf{w}_h)\right>_{\partial K}
+ \left(\boldsymbol{\varphi}_i,\mathbf{G}(\mathbf w_h)\right)_{K}
\right]\right]_{i=1,\ldots,n_\text{dofs}}.


@f]

给定一个与全局未知数矢量和使用中的有限元相关的函数 $\mathbf{w}_h$ ，对欧拉算子的右手边进行评估的算子。这个函数 $\mathcal L_h$ 是明确随时间变化的，因为在边界上评估的数值通量将涉及边界某些部分的随时间变化的数据 $\rho_\mathrm{D}$ 、 $(\rho \mathbf{u})_\mathrm{D}$ 和 $E_\mathbf{D}$ ，取决于边界条件的分配。有了这个符号，我们可以把空间上的离散、时间上的连续系统紧凑地写为

@f[
\mathcal M \frac{\partial \mathbf{w}_h}{\partial t} =
\mathcal L_h(t, \mathbf{w}_h),


@f]

其中我们冒昧地用 $\mathbf{w}_h$ 表示全局解矢量（除了相应的有限元函数外）。等价地，上述系统的形式为

@f[
\frac{\partial \mathbf{w}_h}{\partial t} =
\mathcal M^{-1} \mathcal L_h(t, \mathbf{w}_h).


@f]



对于用高阶非连续Galerkin方法离散的双曲系统，该系统的显式时间积分非常流行。这是由于质量矩阵 $\mathcal M$ 是块对角线的（每个块只对应于定义在同一单元上的同类变量），因此很容易倒置。在每个时间步长--或Runge-Kutta方案的阶段--我们只需要用给定的数据评估一次微分算子，然后应用质量矩阵的逆。另一方面，对于隐式时间步进，人们首先必须将方程线性化，然后迭代解决线性系统，这涉及到几个残差评估和至少十几个线性化算子的应用，正如在步骤33教程程序中所展示的那样。

当然，显式时间步长的简单性是有代价的，即由于所谓的Courant-Friedrichs-Lewy（CFL）条件而产生的条件稳定性。它指出，时间步长不能大于离散微分算子的最快信息传播速度。用更现代的术语来说，传播速度对应于离散算子的最大特征值，反过来又取决于网格大小、多项式程度 $p$ 和欧拉算子的物理学，即 $\mathbf F(\mathbf w)$ 相对于 $\mathbf{w}$ 的线性化的特征值。在这个程序中，我们设定的时间步长如下。

@f[
\Delta t = \frac{\mathrm{Cr}}{p^{1.5}}\left(\frac{1}
           {\max\left[\frac{\|\mathbf{u}\|}{h_u} + \frac{c}{h_c}\right]}\right),


@f]



在所有正交点和所有单元中取最大值。无量纲数 $\mathrm{Cr}$ 表示库朗数，可以选择最大稳定数 $\mathrm{Cr}_\text{max}$ ，其值取决于所选择的时间步进方法及其稳定性。用于多项式缩放的幂 $p^{1.5}$ 是启发式的，代表1到8之间的多项式度数最接近，例如，见 @cite SchoederKormann2018 。在更高的度数限制下， $p>10$ ， $p^2$ 的比例更准确，与通常用于内部惩罚方法的逆向估计有关。关于公式中使用的<i>effective</i>网格尺寸 $h_u$ 和 $h_c$ ，我们注意到对流传输是定向的。因此，一个合适的比例是使用速度方向的元素长度  $\mathbf u$  。下面的代码从参考单元到实际单元的雅各布系数的倒数得出这个比例，也就是说，我们近似于  $\frac{\|\mathbf{u}\|}{h_u} \approx \|J^{-1} \mathbf
u\|_{\infty}$  。相反，声波具有各向同性的特点，这就是为什么我们使用最小的特征尺寸，由 $J$ 的最小奇异值代表，用于声学缩放  $h_c$  。最后，我们需要增加对流和声学限制，因为欧拉方程可以以速度传输信息  $\|\mathbf{u}\|+c$  。

在这个教程程序中，我们使用<a
href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods">explicit
Runge--Kutta methods</a>的一个特定变体，一般来说，它使用以下更新程序，从时间 $t^n$ 的状态 $\mathbf{w}_h^{n}$ 到新时间 $t^{n+1}$ 的 $\Delta t = t^{n+1}-t^n$  。

@f[
\begin{aligned}
\mathbf{k}_1 &= \mathcal M^{-1} \mathcal L_h\left(t^n, \mathbf{w}_h^n\right),
\\
\mathbf{k}_2 &= \mathcal M^{-1} \mathcal L_h\left(t^n+c_2\Delta t,
                       \mathbf{w}_h^n + a_{21} \Delta t \mathbf{k}_1\right),
\\
&\vdots \\
\mathbf{k}_s &= \mathcal M^{-1} \mathcal L_h\left(t^n+c_s\Delta t,
  \mathbf{w}_h^n + \sum_{j=1}^{s-1} a_{sj} \Delta t \mathbf{k}_j\right),
\\
\mathbf{w}_h^{n+1} &= \mathbf{w}_h^n + \Delta t\left(b_1 \mathbf{k}_1 +
b_2 \mathbf{k}_2 + \ldots + b_s \mathbf{k}_s\right).
\end{aligned}


@f]

在 $\mathbf{k}_i$ 、 $i=1,\ldots,s$ 的阶段性方案中，向量 $s$ 是算子在某个中间状态下的评价，并通过某种线性组合用于定义阶段性结束值 $\mathbf{w}_h^{n+1}$ 。该方案中的标量系数 $c_i$ 、 $a_{ij}$ 和 $b_j$ 的定义，使得高阶方案满足某些条件，最基本的是 $c_i = \sum_{j=1}^{i-1}a_{ij}$  。参数通常以所谓的<a
href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#Explicit_Runge%E2%80%93Kutta_methods">Butcher
tableau</a>的形式收集，它收集了定义该方案的所有系数。对于一个五级方案，它看起来是这样的。

@f[
\begin{array}{c|ccccc}
0 \\
c_2 & a_{21} \\
c_3 & a_{31} & a_{32} \\
c_4 & a_{41} & a_{42} & a_{43} \\
c_5 & a_{51} & a_{52} & a_{53} & a_{54} \\
\hline
& b_1 & b_2 & b_3 & b_4 & b_5
\end{array}


@f]



在这个教程程序中，我们使用显式Runge--Kutta方法的一个子集，即所谓的低存储Runge--Kutta方法（LSRK），它假定了系数的额外结构。在参考文献 @cite KennedyCarpenterLewis2000 所使用的变体中，假设使用的是Butcher tableaus的形式

@f[
\begin{array}{c|ccccc}
0 \\
c_2 & a_1 \\
c_3 & b_1 & a_2 \\
c_4 & b_1 & b_2 & a_3 \\
c_5 & b_1 & b_2 & b_3 & a_4 \\
\hline
& b_1 & b_2 & b_3 & b_4 & b_5
\end{array}


@f]

有了这样的定义，对  $\mathbf{w}_h^n$  的更新与中间值  $\mathbf{k}_i$  的信息共享存储。从 $\mathbf{w}^{n+1}=\mathbf{w}^n$ 和 $\mathbf{r}_1 = \mathbf{w}^n$ 开始，每个 $s$ 阶段的更新都简化为

@f[
\begin{aligned}
\mathbf{k}_i &=
\mathcal M^{-1} \mathcal L_h\left(t^n+c_i\Delta t, \mathbf{r}_{i} \right),\\
\mathbf{r}_{i+1} &= \mathbf{w}_h^{n+1} + \Delta t \, a_i \mathbf{k}_i,\\
\mathbf{w}_h^{n+1} &= \mathbf{w}_h^{n+1} + \Delta t \, b_i \mathbf{k}_i.
\end{aligned}


@f]

除了连续更新的向量 $\mathbf w_h^{n+1}$ ，这个方案只需要两个辅助向量，即保存微分算子的评估的向量 $\mathbf{k}_i$ ，以及保存微分算子应用的右手边的向量 $\mathbf{r}_i$ 。在后续阶段  $i$  ，值  $\mathbf{k}_i$  和  $\mathbf{r}_i$  可以使用相同的存储。

低存储量变体的主要优点是一方面减少了内存消耗（如果必须在内存中装入非常多的未知数，持有所有的 $\mathbf{k}_i$ 来计算随后的更新，对于 $s$ 来说已经是一个极限，在5到8之间--记得我们使用的是显式方案，所以我们不需要存储任何通常比几个向量大很多的矩阵），另一方面是减少内存访问。在这个程序中，我们对后一个方面特别感兴趣。由于运算符评估的成本只是简单地从内存中流转输入和输出向量的一小部分，我们必须考虑向量更新的成本，而低存储的变体可以提供传统显式Runge--Kutta方法两倍的吞吐量，原因就在于此，例如，见 @cite SchoederKormann2018 中的分析。

除了参考文献 @cite KennedyCarpenterLewis2000 中的三阶、四阶和五阶精度的三个变体外，我们还使用了一个四阶精度的七级变体，该变体是为声学设置而优化的 @cite TseliosSimos2007  。声学问题是欧拉方程的亚音速制度的有趣方面之一，其中可压缩性导致了声波的传播；通常，人们使用围绕背景状态的线性化欧拉方程的进一步简化，或围绕固定框架的声波方程。




<h3>Fast evaluation of integrals by matrix-free techniques</h3>

这个程序中使用的主要成分是我们用来评估算子  $\mathcal L_h$  和反质量矩阵  $\mathcal M$  的快速无矩阵技术。实际上，<i>matrix-free</i>这个术语有点名不副实，因为我们是在处理一个非线性算子，并没有将反过来可以用矩阵表示的算子线性化。然而，作为稀疏矩阵-向量乘积的替代品，积分的快速评估已经变得很流行，如步骤-37和步骤-59所示，为此我们在交易二中创造了这个基础设施<i>matrix-free functionality</i>。此外，反质量矩阵确实是以无矩阵的方式应用的，详见下文。

无矩阵基础设施使我们能够快速评估弱形式的积分。其成分是将解系数快速插值为正交点的值和导数，在正交点进行逐点运算（在这里我们实现了上述的微分算子），以及与所有测试函数相乘和对正交点求和。第一和第三部分利用了和因子化，并在步骤37的单元积分教程和步骤59的面积分教程中进行了广泛的讨论。唯一的区别是，我们现在处理的是一个 $d+2$ 分量的系统，而不是以前教程程序中的标量系统。在代码中，所有的变化是FEEvaluation和FEFaceEvaluation类的一个模板参数，即设置分量的数量。对向量的访问和以前一样，都由评价器透明地处理。我们还注意到，下面的代码中选择的带有单一评价器的变体并不是唯一的选择--我们也可以为单独的组件 $\rho$ 、 $\rho \mathbf u$ 和 $E$ 使用单独的评价器；鉴于我们对所有组件的处理是类似的（也反映在我们把方程作为一个矢量系统的方式），这里会更复杂。和以前一样，FEEvaluation类通过结合对几个单元（和面）的操作来提供显式的矢量化，涉及的数据类型称为VectorizedArray。由于这种类型的算术运算都是重载的，所以我们不必为它费心，除了通过函数接口对函数进行评估，我们需要同时为几个正交点的位置提供特殊的<i>vectorized</i>评估。

这个程序中更大的变化是在正交点的操作。在这里，多分量评估器为我们提供了之前没有讨论过的返回类型。 FEEvaluation::get_value() 将为第37步的拉普拉斯返回一个标量（更准确地说，由于跨单元的矢量化，是一个VectorizedArray类型），现在它返回的类型是`Tensor<1,dim+2,VectorizedArray<Number>'。同样，梯度类型现在是`张量<1,dim+2,张量<1,dim,矢量化数组<Number>>`，其中外部张量收集了欧拉系统的`dim+2'分量，内部张量是各个方向的偏导数。例如，欧拉系统的通量 $\mathbf{F}(\mathbf{w})$ 就属于这种类型。为了减少我们为拼出这些类型而写的代码量，我们尽可能使用C++的`自动'关键字。

从实施的角度来看，非线性并不是一个很大的困难。它是在我们表达欧拉弱形式的条款时自然引入的，例如以动量条款的形式  $\rho \mathbf{u}
\otimes \mathbf{u}$  。为了得到这个表达式，我们首先从动量变量  $\rho \mathbf{u}$  推导出速度  $\mathbf{u}$  。鉴于 $\rho
\mathbf{u}$ 和 $\rho$ 一样被表示为 $p$ 度的多项式，速度 $\mathbf{u}$ 是参考坐标 $\hat{\mathbf{x}}$ 的一个有理表达。当我们进行乘法 $(\rho
\mathbf{u})\otimes \mathbf{u}$ 时，我们得到一个表达式，它是两个多项式的比值，分子中的多项式程度 $2p$ 和分母中的多项式程度 $p$ 。结合测试函数的梯度，分子中的积分度为 $3p$ ，分母中的积分度为 $p$ ，对于仿生单元，即平行四边形/平行四边形，已经有了积分。对于弧形单元，当积分乘以映射的雅各布系数时，会出现额外的多项式和有理表达式。在这一点上，人们通常需要放弃坚持精确的积分，而采取高斯（更确切地说，高斯-勒格伦德）正交提供的任何精度。这时的情况与拉普拉斯方程的情况类似，积分项包含非affince单元上的有理表达式，也只能进行近似积分。由于这些公式只对多项式进行精确积分，我们不得不以积分错误的形式忍受<a
href="https://mathoverflow.net/questions/26018/what-are-variational-crimes-and-who-coined-the-term">variational
crime</a>的影响。

虽然对于椭圆问题来说，不精确的积分通常是可以容忍的，但对于双曲问题来说，不精确的积分会引起一些令人头痛的效应，这种效应称为<b>aliasing</b>。这个术语来自于信号处理，表达了不适当的、过于粗糙的采样情况。就正交而言，不适当的采样意味着我们使用的正交点与准确采样变系数积分所需的点相比太少。在DG文献中已经表明，别离误差会在<i>barely</i>解析模拟的数值解中引入非物理性的振荡。别名主要影响到粗略的分辨率--而采用相同方案的更细的网格则工作良好--这一事实并不令人惊讶，因为分辨率高的模拟往往在一个单元的长度尺度上是平滑的（即，它们在较高的多项式程度上有小的系数，由于正交点太少而被遗漏，而在较低的多项式程度上的主要解贡献仍然被很好地捕获--这只是泰勒定理的一个结果）。为了解决这个问题，DG文献中提出了各种方法。一种技术是过滤，它可以抑制与高次多项式度数有关的解成分。由于所选择的节点基不是分层的，这就意味着要从节点基转化为分层基（例如，基于Legendre多项式的模态基），其中单元内的贡献是按多项式程度划分的。在这个基础上，我们可以将与高度数相关的求解系数乘以一个小数，保持低度数不变（以避免破坏一致性），然后再转换回节点基础。然而，过滤器会降低该方法的准确性。另一个在某种意义上更简单的策略是使用更多的正交点来更准确地捕捉非线性项。每个坐标方向使用超过 $p+1$ 个正交点有时被称为过度积分或一致积分。后者在不可压缩的Navier-Stokes方程中最为常见，其中 $\mathbf{u}\otimes \mathbf{u}$ 非线性导致 $3p$ 度的多项式积分（当同时考虑测试函数时），只要元素的几何形状是仿生的，每个方向的 $\textrm{floor}\left(\frac{3p}{2}\right)+1$ 正交点就可以精确积分。在非多项式积分的欧拉方程的背景下，选择就不那么明确了。根据各种变量的变化， $\textrm{floor}\left(\frac{3p}{2}\right)+1$ 或 $2p+1$ 点（分别精确积分度为 $3p$ 或 $4p$ 的多项式）都很常见。

为了反映程序中正交选择的这种可变性，我们把正交点的数量作为一个变量来指定，就像多项式的度数一样，并注意到人们会根据流量配置做出不同的选择。默认选择是 $p+2$ 点--比最小可能的 $p+1$ 点多一点。FEEvaluation和FEFaceEvaluation类允许通过模板参数无缝地改变点的数量，这样程序就不会因此而变得更复杂。




<h3>Evaluation of the inverse mass matrix with matrix-free techniques</h3>

最后一个要素是反质量矩阵的评估  $\mathcal
M^{-1}$  。在具有显式时间积分的DG方法中，质量矩阵是块状对角线，因此很容易反转--人们只需要反转对角线块。然而，考虑到无矩阵的积分评估在成本上更接近于只访问向量，即使应用块对角矩阵（例如通过LU因子数组）也会比评估 $\mathcal L_h$ 贵几倍，仅仅是因为对于高阶有限元来说，仅仅存储和加载大小为`dofs_per_cell`x`dofs_per_cell`的矩阵是昂贵的。由于这显然是不可取的，部分社区已经转移到质量矩阵是对角线的基础，例如<i>L<sub>2</sub></i>正交Legendre基础，使用分层多项式或高斯四分法点上的拉格朗日多项式（这只是利用Legendre信息的另一种方式）。虽然对角线属性对于变形元素来说是失效的，但通过采取对角线质量矩阵而忽略其余部分（质量包络的变种，尽管不是步骤-48中利用的具有额外积分误差的变种）所产生的误差已被证明不会改变离散化精度。高斯正交点中的拉格朗日基础有时也被称为同位设置，因为多项式的结点与正交点重合（="同位"），避免了一些内插操作。鉴于我们想在 $\mathcal L_h$ 中对非线性项使用更多的正交点，然而，拼合属性就失去了。(更确切地说，在改变基础后，它仍然用于FEEvaluation和FEFaceEvaluation，见无矩阵论文  @cite KronbichlerKormann2019  。)

在这个教程程序中，我们使用拼合思想来应用反质量矩阵，但有一个小的转折。与其在高斯四分法的点上通过拉格朗日多项式使用配位，我们更倾向于在高斯-洛巴托点上使用传统的拉格朗日基础，因为那些使面积分的评估变得便宜。这是因为对于高斯-洛巴托点来说，一些节点点位于单元格的面上，而且不难证明，在任何给定的面上，唯一具有非零值的形状函数正是其节点点实际上位于该面上的那些。当然，我们也可以像步骤48那样使用高斯-洛巴托正交（有一些额外的积分误差），但我们不想牺牲精度，因为这些正交公式通常比一般的高斯正交公式的阶数低。相反，我们使用参考文献 @cite KronbichlerSchoeder2016 中描述的一个想法，其中提出为了应用反质量矩阵而改变基础。让我们用 $S$ 表示在正交点评价的形状函数矩阵，形状函数在矩阵的行中，正交点在列中。那么，单元格 $K$ 上的质量矩阵由以下公式给出

@f[
\mathcal M^K = S J^K S^\mathrm T.


@f]

这里， $J^K$ 是以雅各布系数乘以正交权重（JxW）的行列式作为条目的对角矩阵。矩阵 $S$ 被构造为一维矩阵的克朗克积（张量积），例如，在三维中为

@f[
S = S_{\text{1D}}\otimes S_{\text{1D}}\otimes S_{\text{1D}},


@f]

这是基函数是一维形状函数的张量积，正交公式是一维正交公式的张量积的结果。对于多项式的数量等于正交点的数量的情况， $S J^K S^\mathrm T$ 中的所有矩阵都是方形的，同样，克朗克积中的 $S$ 的成分也是方形的。因此，人们可以对每个矩阵进行反转，形成整体的逆。

@f[
\left(\mathcal M^K\right)^{-1} = S_{\text{1D}}^{-\mathrm T}\otimes
S_{\text{1D}}^{-\mathrm T}\otimes S_{\text{1D}}^{-\mathrm T}
\left(J^K\right)^{-1}
S_{\text{1D}}^{-1}\otimes S_{\text{1D}}^{-1}\otimes S_{\text{1D}}^{-1}.


@f]

这个公式的结构与用和因子化技术对积分进行正向评价的步骤完全相同（即交易.II的FEEvaluation和MatrixFree框架）。因此，我们可以利用相同的代码路径，采用不同的插值矩阵， $S_{\mathrm{1D}}^{-\mathrm{T}}$ 而不是 $S_{\mathrm{1D}}$  。

类 MatrixFreeOperators::CellwiseInverseMassMatrix 实现了这个操作。它从有限元中包含的基（在这里是FE_DGQ）改变为高斯正交点中的拉格朗日基。在这里，可以评估对角线质量矩阵的逆值，这只是`JxW`因子的逆值（即正交权重乘以从参考坐标到实坐标的雅各布系数）。一旦这样做了，我们就可以变回标准的节点高斯-洛巴托基础。

这种应用反质量矩阵的特殊方式的优点是成本类似于质量矩阵的正向应用，这比用超积分和面积分评估空间算子 $\mathcal L_h$ 更便宜。(我们将在<a href="#Results">results section</a>中用详细的时间信息证明这一点)。事实上，它是如此便宜，以至于在大多数现代架构上，它被读取源向量、读取对角线和写入目的向量的带宽所限制。用于结果部分的硬件可以使计算的速度至少比从内存流向量的速度快一倍。




<h3>The test case</h3>

在这个教程程序中，我们实现了两个测试案例。第一个案例是限于两个空间维度的收敛性测试。它运行一个所谓的等熵涡旋，它通过一个背景流场进行传输。第二个案例使用了一个更令人兴奋的设置。我们从一个浸在通道中的圆柱体开始，使用 GridGenerator::channel_with_cylinder() 函数。在这里，我们强加一个马赫数为 $\mathrm{Ma}=0.307$ 的亚音速初始场，在 $x$ 方向上速度不变。在顶壁和底壁以及圆柱体上，我们施加了一个无穿透（即切向流动）的条件。与初始条件相比，这种设置迫使气流重新定向，从而导致大的声波从圆柱体上传播出去。在上游方向，波的传播速度较慢（因为它必须逆着迎面而来的气体移动），包括密度和压力的不连续。在下游方向，由于声音的传播和流体的流动方向相同，传输速度较快，这在一定程度上抹去了不连续性。一旦声波碰到上下壁，声音就会被反射回来，形成一些漂亮的形状，如下图<a href="#Results">results section</a>所示。


examples/step-67/doc/results.dox



<h1>Results</h1>

<h3>Program output</h3>

在一台有40个进程的机器上以默认设置运行该程序，会产生以下输出。

@code
Running with 40 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 147,456 ( = 4 [vars] x 1,024 [cells] x 36 [dofs/cell/var] )
Time step size: 0.00689325, minimal h: 0.3125, initial transport scaling: 0.102759


Time:       0, dt:   0.0069, error rho:   2.76e-07, rho * u:  1.259e-06, energy: 2.987e-06
Time:    1.01, dt:   0.0069, error rho:   1.37e-06, rho * u:  2.252e-06, energy: 4.153e-06
Time:    2.01, dt:   0.0069, error rho:  1.561e-06, rho * u:   2.43e-06, energy: 4.493e-06
Time:    3.01, dt:   0.0069, error rho:  1.714e-06, rho * u:  2.591e-06, energy: 4.762e-06
Time:    4.01, dt:   0.0069, error rho:  1.843e-06, rho * u:  2.625e-06, energy: 4.985e-06
Time:    5.01, dt:   0.0069, error rho:  1.496e-06, rho * u:  1.961e-06, energy: 4.142e-06
Time:       6, dt:   0.0083, error rho:  1.007e-06, rho * u:  7.119e-07, energy: 2.972e-06
Time:       7, dt:   0.0095, error rho:  9.096e-07, rho * u:  3.786e-07, energy: 2.626e-06
Time:       8, dt:   0.0096, error rho:  8.439e-07, rho * u:  3.338e-07, energy:  2.43e-06
Time:       9, dt:   0.0096, error rho:  7.822e-07, rho * u:  2.984e-07, energy: 2.248e-06
Time:      10, dt:   0.0096, error rho:  7.231e-07, rho * u:  2.666e-07, energy: 2.074e-06


+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              |     2.249s    30 |     2.249s |     2.249s     8 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |        11 |  0.008066s    13 |   0.00952s |   0.01041s    20 |
| compute transport speed       |       258 |   0.01012s    13 |   0.05392s |   0.08574s    25 |
| output                        |        11 |    0.9597s    13 |    0.9613s |    0.9623s     6 |
| rk time stepping total        |      1283 |    0.9827s    25 |     1.015s |      1.06s    13 |
| rk_stage - integrals L_h      |      6415 |    0.8803s    26 |    0.9198s |    0.9619s    14 |
| rk_stage - inv mass + vec upd |      6415 |   0.05677s    15 |   0.06487s |   0.07597s    13 |
+-------------------------------------------+------------------+------------+------------------+
@endcode



程序输出显示，所有的误差都很小。这是由于我们使用了一个相对较细的 $32^2$ 单元的网格，用5度的多项式来求得一个平滑的解决方案。一个有趣的模式显示在时间步长上：虽然在时间5之前是0.0069，但在后来的时间里增加到0.0096。在时间5和6.5之间，一旦在声速之上有一些运动的旋涡（因此传播速度更快）离开计算域，步长就会增加。在这之后，气流只是在同一方向上是均匀的，与之前均匀速度被漩涡覆盖的状态相比，气体的最大速度有所下降。我们的时间步长公式认识到了这种影响。

最后一块输出显示了关于程序各个部分时间的详细信息；它通过显示最快和最慢的处理器所花费的时间以及平均时间将其分解开来--这在非常大的计算中通常很有用，可以发现是否有处理器持续过热（并因此节制其时钟速度）或因其他原因持续过慢。总结显示，在1.02秒内完成了1283个时间步骤（看所有MPI进程的平均时间），而11个文件的输出又花了0.96秒。将每个时间步数和五个Runge--Kutta阶段分解开来，每次评估的计算时间为0.16毫秒。这种高性能是无矩阵评估器的典型表现，也是显式时间积分对隐式求解器非常有竞争力的原因，特别是对于大规模模拟。程序运行结束时的计算时间细分显示， $\mathcal L_h$ 中的积分评估贡献了大约0.92秒，反质量矩阵的应用贡献了0.06秒。此外，对时间步长计算的运输速度的估计又贡献了0.05秒的计算时间。

如果我们再使用三个级别的全局细化和总共940万个DoF，最终的统计数据如下（对于修改后的Lax--Friedrichs通量， $p=5$  ，和同一系统的40个核心的双插槽Intel Xeon Gold 6230）。

@code
+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              |     244.9s    12 |     244.9s |     244.9s    34 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |        11 |    0.4239s    12 |    0.4318s |    0.4408s     9 |
| compute transport speed       |      2053 |     3.962s    12 |     6.727s |     10.12s     7 |
| output                        |        11 |     30.35s    12 |     30.36s |     30.37s     9 |
| rk time stepping total        |     10258 |     201.7s     7 |     205.1s |     207.8s    12 |
| rk_stage - integrals L_h      |     51290 |     121.3s     6 |     126.6s |     136.3s    16 |
| rk_stage - inv mass + vec upd |     51290 |     66.19s    16 |     77.52s |     81.84s    10 |
+-------------------------------------------+------------------+------------+------------------+
@endcode



每个时间步长，求解器现在需要0.02秒，大约是147k未知数的小问题的25倍。鉴于该问题涉及64倍的未知数，计算时间的增加并不令人惊讶。由于我们也做了8倍的时间步数，计算时间在理论上应该增加512倍。实际增加的时间是205秒/1.02秒=202。这是因为由于通信开销的原因，小问题的规模不能充分利用40个核心。如果我们研究一下每个时间步长所做操作的细节，这一点就很清楚了。带有近邻通信的微分算子 $\mathcal L_h$ 的评估时间从0.92秒到127秒，也就是说，它增加了138倍。另一方面，应用反质量矩阵和向量更新的成本，完全不需要在MPI进程之间通信，增加了1195倍。这一增长超过了理论上的512倍，因为对于较大的尺寸，操作受限于RAM内存的带宽，而对于较小的尺寸，所有的矢量都适合于CPU的缓存。数字显示，尽管使用了低存储量的Runge-Kutta积分器和合并矢量操作，但质量矩阵评估和矢量更新部分几乎消耗了Runge-Kutta阶段所花费的40%的时间。而且尽管对 $\mathcal L_h$ 算子使用了过度积分。对于更简单的微分算子和更昂贵的时间积分器，花费在质量矩阵和矢量更新部分的比例也可以达到70%。如果我们以每秒处理的DoFs和Runge--Kutta阶段计算一个吞吐量数字，我们得到@f[ \text{throughput} =
\frac{n_\mathrm{time steps} n_\mathrm{stages}
n_\mathrm{dofs}}{t_\mathrm{compute}} = \frac{10258 \cdot 5 \cdot
9.4\,\text{MDoFs}}{205s} = 2360\, \text{MDoFs/s} @f]这个吞吐量数字非常高，因为简单地将一个向量复制到另一个向量的运行速度只有大约10,000 MDoFs/s。

如果我们进入下一个更大的规模，有3770万个DoF，总的模拟时间是2196秒，其中1978秒用于时间步进。L_h算子的运行时间增加了9.3倍（1179秒对127秒），反质量矩阵和向量更新增加了10.3倍（797秒对77.5秒）。运行时间非最佳增长的原因可以追溯到给定硬件上的缓存效应（有40MB的二级缓存和55MB的三级缓存）。虽然不是所有的相关数据都适合940万DoF的缓存（一个向量需要75MB，我们有三个向量加上MatrixFree中的一些额外数据），但还是有能力满足一个半向量的需求。考虑到现代的缓存比天真的最近使用的策略更复杂（在这种情况下，我们几乎没有重复使用，因为数据是以类似流的方式使用的），我们可以假设，在940万DoFs的情况下，确实有相当一部分数据可以从缓存中交付。在更大的情况下，即使有最佳的缓存，也只有不到10%的数据可以放入缓存中，而且会有相关的性能损失。




<h3>Convergence rates for the analytical test case</h3>

对于修改后的Lax--Friedrichs通量和测量动量变量的误差，我们得到以下收敛表（密度和能量变量的速率非常相似）。

 <table align="center" class="doxtable">
  <tr>
    <th>&nbsp;</th>
    <th colspan="3"><i>p</i>=2</th>
    <th colspan="3"><i>p</i>=3</th>
    <th colspan="3"><i>p</i>=5</th>
  </tr>
  <tr>
    <th>n_cells</th>
    <th>n_dofs</th>
    <th>error mom</th>
    <th>rate</th>
    <th>n_dofs</th>
    <th>error mom</th>
    <th>rate</th>
    <th>n_dofs</th>
    <th>error mom</th>
    <th>rate</th>
  </tr>
  <tr>
    <td align="right">16</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td align="right">2,304</td>
    <td align="center">1.373e-01</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td align="right">64</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td align="right">4,096</td>
    <td align="center">9.130e-02</td>
    <td>&nbsp;</td>
    <td align="right">9,216</td>
    <td align="center">8.899e-03</td>
    <td>3.94</td>
  </tr>
  <tr>
    <td align="right">256</td>
    <td align="right">9,216</td>
    <td align="center">5.577e-02</td>
    <td>&nbsp;</td>
    <td align="right">16,384</td>
    <td align="center">7.381e-03</td>
    <td>3.64</td>
    <td align="right">36,864</td>
    <td align="center">2.082e-04</td>
    <td>5.42</td>
  </tr>
  <tr>
    <td align="right">1024</td>
    <td align="right">36,864</td>
    <td align="center">4.724e-03</td>
    <td>3.56</td>
    <td align="right">65,536</td>
    <td align="center">3.072e-04</td>
    <td>4.59</td>
    <td align="right">147,456</td>
    <td align="center">2.625e-06</td>
    <td>6.31</td>
  </tr>
  <tr>
    <td align="right">4096</td>
    <td align="right">147,456</td>
    <td align="center">6.205e-04</td>
    <td>2.92</td>
    <td align="right">262,144</td>
    <td align="center">1.880e-05</td>
    <td>4.03</td>
    <td align="right">589,824</td>
    <td align="center">3.268e-08</td>
    <td>6.33</td>
  </tr>
  <tr>
    <td align="right">16,384</td>
    <td align="right">589,824</td>
    <td align="center">8.279e-05</td>
    <td>2.91</td>
    <td align="right">1,048,576</td>
    <td align="center">1.224e-06</td>
    <td>3.94</td>
    <td align="right">2,359,296</td>
    <td align="center">9.252e-10</td>
    <td>5.14</td>
  </tr>
  <tr>
    <td align="right">65,536</td>
    <td align="right">2,359,296</td>
    <td align="center">1.105e-05</td>
    <td>2.91</td>
    <td align="right">4,194,304</td>
    <td align="center">7.871e-08</td>
    <td>3.96</td>
    <td align="right">9,437,184</td>
    <td align="center">1.369e-10</td>
    <td>2.77</td>
  </tr>
  <tr>
    <td align="right">262,144</td>
    <td align="right">9,437,184</td>
    <td align="center">1.615e-06</td>
    <td>2.77</td>
    <td align="right">16,777,216</td>
    <td align="center">4.961e-09</td>
    <td>3.99</td>
    <td align="right">37,748,736</td>
    <td align="center">7.091e-11</td>
    <td>0.95</td>
  </tr>
</table> 

如果我们改用Harten-Lax-van Leer通量，结果如下。   <table align="center" class="doxtable">
  <tr>
    <th>&nbsp;</th>
    <th colspan="3"><i>p</i>=2</th>
    <th colspan="3"><i>p</i>=3</th>
    <th colspan="3"><i>p</i>=5</th>
  </tr>
  <tr>
    <th>n_cells</th>
    <th>n_dofs</th>
    <th>error mom</th>
    <th>rate</th>
    <th>n_dofs</th>
    <th>error mom</th>
    <th>rate</th>
    <th>n_dofs</th>
    <th>error mom</th>
    <th>rate</th>
  </tr>
  <tr>
    <td align="right">16</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td align="right">2,304</td>
    <td align="center">1.339e-01</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td align="right">64</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td align="right">4,096</td>
    <td align="center">9.037e-02</td>
    <td>&nbsp;</td>
    <td align="right">9,216</td>
    <td align="center">8.849e-03</td>
    <td>3.92</td>
  </tr>
  <tr>
    <td align="right">256</td>
    <td align="right">9,216</td>
    <td align="center">4.204e-02</td>
    <td>&nbsp;</td>
    <td align="right">16,384</td>
    <td align="center">9.143e-03</td>
    <td>3.31</td>
    <td align="right">36,864</td>
    <td align="center">2.501e-04</td>
    <td>5.14</td>
  </tr>
  <tr>
    <td align="right">1024</td>
    <td align="right">36,864</td>
    <td align="center">4.913e-03</td>
    <td>3.09</td>
    <td align="right">65,536</td>
    <td align="center">3.257e-04</td>
    <td>4.81</td>
    <td align="right">147,456</td>
    <td align="center">3.260e-06</td>
    <td>6.26</td>
  </tr>
  <tr>
    <td align="right">4096</td>
    <td align="right">147,456</td>
    <td align="center">7.862e-04</td>
    <td>2.64</td>
    <td align="right">262,144</td>
    <td align="center">1.588e-05</td>
    <td>4.36</td>
    <td align="right">589,824</td>
    <td align="center">2.953e-08</td>
    <td>6.79</td>
  </tr>
  <tr>
    <td align="right">16,384</td>
    <td align="right">589,824</td>
    <td align="center">1.137e-04</td>
    <td>2.79</td>
    <td align="right">1,048,576</td>
    <td align="center">9.400e-07</td>
    <td>4.08</td>
    <td align="right">2,359,296</td>
    <td align="center">4.286e-10</td>
    <td>6.11</td>
  </tr>
  <tr>
    <td align="right">65,536</td>
    <td align="right">2,359,296</td>
    <td align="center">1.476e-05</td>
    <td>2.95</td>
    <td align="right">4,194,304</td>
    <td align="center">5.799e-08</td>
    <td>4.02</td>
    <td align="right">9,437,184</td>
    <td align="center">2.789e-11</td>
    <td>3.94</td>
  </tr>
  <tr>
    <td align="right">262,144</td>
    <td align="right">9,437,184</td>
    <td align="center">2.038e-06</td>
    <td>2.86</td>
    <td align="right">16,777,216</td>
    <td align="center">3.609e-09</td>
    <td>4.01</td>
    <td align="right">37,748,736</td>
    <td align="center">5.730e-11</td>
    <td>-1.04</td>
  </tr>
</table> 

表中显示，我们对两种数值通量都得到了最佳的 $\mathcal O\left(h^{p+1}\right)$ 收敛率。对于 $p=2$ 的Lax--Friedrichs通量，误差略小，但对于 $p=3$ 的情况则相反；在任何情况下，这个测试案例的差异都相对较小。

对于 $p=5$ ，我们在最细的网格上用两种通量达到了 $10^{-11}$ 的舍入精度。还要注意的是，误差是绝对的，域长为 $10^2$ ，所以相对误差低于 $10^{-12}$ 。HLL通量对于最高度数来说要好一些，这是由于Lax--Friedrichs通量的轻微不准确造成的。Lax--Friedrichs通量对离开域的解设置了一个Dirichlet条件，这导致了一个小的人工反射，这在Lax--Friedrichs通量中被凸显出来。除此之外，我们看到数值通量的影响很小，因为元素内部的多项式部分是引起反射的主要动力。当试图用高阶DG设置来接近更具挑战性的设置时，通量的有限影响也会产生影响。以第33步的参数和网格为例，一旦高质部分接近边界，我们就会在两种通量下得到振荡（这反过来会使密度为负值，并使解决方案爆炸），这与低阶有限体积情况不同（ $p=0$ ）。因此，任何导致溶液中出现冲击的情况都需要某种形式的限制性或人工耗散。对于另一种选择，请参见step-69教程程序。




<h3>Results for flow in channel around cylinder in 2D</h3>

对于渠道中圆柱体周围的流动测试案例，我们需要将第一行代码改为

@code
  constexpr unsigned int testcase = 1;
@endcode

这个测试案例从一个马赫数为0.31的恒定速度和恒定的初始密度的背景场开始；气流必须绕过一个圆柱体形式的障碍物。由于我们对圆柱体壁施加了一个无穿透的条件，最初迎面撞上圆柱体的气流必须重新排列，这就产生了一个大的声波。下面的图片显示了二维情况下5级全局细化时0.1、0.25、0.5和1.0（左上至右下）的压力，使用了102,400个单元，多项式程度为5，所有4个求解变量的自由度为1470万。我们清楚地看到，在时间0.1的第一个快照中，不连续现象在上游方向传播缓慢，在下游方向传播较快。在时间0.25，声波已经到达顶部和底部的墙壁并反射到内部。从下壁和上壁反射波的不同距离，我们可以看到以 GridGenerator::channel_with_cylinder() 为代表的Sch&auml;fer-Turek试验案例的轻微不对称性，圆柱体上方的空间与下方相比要多一些。在后来的时间里，画面更加混乱，到处都是许多声波。

 <table align="center" class="doxtable" style="width:85%">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_010.png" alt="" width="100%">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_025.png" alt="" width="100%">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_050.png" alt="" width="100%">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_100.png" alt="" width="100%">
    </td>
  </tr>
</table> 

下一张图片显示了在相同分辨率下，从通道入口向出口看，时间为1.0时的压力仰角图--在这里，我们可以看到大量的反射。在该图中，可以看到两种类型的波。较大振幅的波对应于初始不连续物撞击墙壁时发生的各种反射，而与元素大小相似的小振幅波则对应于数值伪影。它们起源于方案的有限分辨率，并在不连续面通过高阶多项式的元素时出现。这种效应可以通过提高分辨率来治愈。除了这种效应之外，丰富的波浪结构是高阶DG方法的传输精度的结果。

 <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_elevated.jpg" alt="" width="40%"> 

通过2级全局细化，1,600个单元，网格及其在40个MPI进程上的划分情况如下。

 <img src="https://www.dealii.org/images/steps/developer/step-67.grid-owner.png" alt="" width="70%"> 

当我们在40个核心上运行具有4级全局细化的代码时，我们得到以下输出。

@code
Running with 40 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 3,686,400 ( = 4 [vars] x 25,600 [cells] x 36 [dofs/cell/var] )
Time step size: 7.39876e-05, minimal h: 0.001875, initial transport scaling: 0.00110294


Time:       0, dt:  7.4e-05, norm rho:   4.17e-16, rho * u:  1.629e-16, energy: 1.381e-15
Time:    0.05, dt:  6.3e-05, norm rho:    0.02075, rho * u:    0.03801, energy:   0.08772
Time:     0.1, dt:  5.9e-05, norm rho:    0.02211, rho * u:    0.04515, energy:   0.08953
Time:    0.15, dt:  5.7e-05, norm rho:    0.02261, rho * u:    0.04592, energy:   0.08967
Time:     0.2, dt:  5.8e-05, norm rho:    0.02058, rho * u:    0.04361, energy:   0.08222
Time:    0.25, dt:  5.9e-05, norm rho:    0.01695, rho * u:    0.04203, energy:   0.06873
Time:     0.3, dt:  5.9e-05, norm rho:    0.01653, rho * u:     0.0401, energy:   0.06604
Time:    0.35, dt:  5.7e-05, norm rho:    0.01774, rho * u:    0.04264, energy:    0.0706


...


Time:    1.95, dt:  5.8e-05, norm rho:    0.01488, rho * u:    0.03923, energy:   0.05185
Time:       2, dt:  5.7e-05, norm rho:    0.01432, rho * u:    0.03969, energy:   0.04889


+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              |     273.6s    13 |     273.6s |     273.6s     0 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |        41 |   0.01112s    35 |    0.0672s |    0.1337s     0 |
| compute transport speed       |      6914 |     5.422s    35 |     15.96s |     29.99s     1 |
| output                        |        41 |     37.24s    35 |      37.3s |     37.37s     0 |
| rk time stepping total        |     34564 |     205.4s     1 |     219.5s |     230.1s    35 |
| rk_stage - integrals L_h      |    172820 |     153.6s     1 |     164.9s |     175.6s    27 |
| rk_stage - inv mass + vec upd |    172820 |     47.13s    13 |     53.09s |     64.05s    33 |
+-------------------------------------------+------------------+------------+------------------+
@endcode



这里显示的各种数量的规范是对背景场（即初始条件）的偏差 $\rho'$ 、 $(\rho u)'$ 和 $E'$ 。运行时间的分布总体上与之前的测试案例相似。唯一略有不同的是，与反质量矩阵和矢量更新相比，在 $\mathcal L_h$ 中花费的时间比例较大。这是因为几何体是变形的，无矩阵框架需要从内存中加载额外的几何体阵列，这些阵列在仿生网格的情况下是被压缩的。

将全局细化的数量增加到5，输出就变成了。

@code
Running with 40 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 14,745,600 ( = 4 [vars] x 102,400 [cells] x 36 [dofs/cell/var] )


...


+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              |      2693s    32 |      2693s |      2693s    23 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |        41 |   0.04537s    32 |     0.173s |    0.3489s     0 |
| compute transport speed       |     13858 |     40.75s    32 |     85.99s |     149.8s     0 |
| output                        |        41 |     153.8s    32 |     153.9s |     154.1s     0 |
| rk time stepping total        |     69284 |      2386s     0 |      2450s |      2496s    32 |
| rk_stage - integrals L_h      |    346420 |      1365s    32 |      1574s |      1718s    19 |
| rk_stage - inv mass + vec upd |    346420 |     722.5s    10 |     870.7s |      1125s    32 |
+-------------------------------------------+------------------+------------+------------------+
@endcode



对性能的影响与分析性测试案例相似--理论上，计算时间应该增加8倍，但我们实际上看到时间步骤增加了11倍（219.5秒对2450秒）。这可以追溯到缓存，小的情况下大多适合缓存。一个有趣的效果，是典型的本地通信（积分 $\mathcal L_h$ ）和全局通信（计算运输速度）混合的程序，有一些负载不平衡，可以通过查看分别遇到不同阶段的最小和最大时间的MPI等级来观察。级别0报告了 "rk时间步进总数 "部分的最快吞吐量。同时，对于 "计算传输速度 "部分，它似乎是最慢的，几乎比平均水平慢了2倍，与较快的等级相比几乎是4倍。由于后者涉及到全局通信，我们可以将这部分的缓慢归因于本地Runge--Kutta阶段在这个等级上推进得更快，需要等到其他处理器跟上。在这一点上，人们可以怀疑这种不平衡的原因。在所有的MPI进程中，单元格的数量几乎是相同的。然而，无矩阵框架在位于通道出口处的仿生和笛卡尔单元上速度更快，较低的MPI等级被分配到这些单元。另一方面，报告Runga--Kutta阶段最高运行时间的等级32拥有靠近圆柱体的弯曲单元，对于这些单元不可能有数据压缩。为了提高吞吐量，我们可以在划分 parallel::distributed::Triangulation 对象时给不同的单元类型分配不同的权重，甚至可以测量几个时间步骤的运行时间，然后尝试重新平衡。

对于1470万DoFs的测试案例，在346000个Runge--Kutta阶段中，每个Runge--Kutta阶段的吞吐量可以计算到2085 MDoFs/s，比上面报告的2360 MDoFs/s的笛卡尔网格吞吐量略慢。

最后，如果我们增加一个额外的细化，我们会记录以下输出。

@code
Running with 40 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 58,982,400 ( = 4 [vars] x 409,600 [cells] x 36 [dofs/cell/var] )


...


Time:    1.95, dt:  1.4e-05, norm rho:    0.01488, rho * u:    0.03923, energy:   0.05183
Time:       2, dt:  1.4e-05, norm rho:    0.01431, rho * u:    0.03969, energy:   0.04887


+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              | 2.166e+04s    26 | 2.166e+04s | 2.166e+04s    24 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |        41 |    0.1758s    30 |     0.672s |     1.376s     1 |
| compute transport speed       |     27748 |     321.3s    34 |     678.8s |      1202s     1 |
| output                        |        41 |     616.3s    32 |     616.4s |     616.4s    34 |
| rk time stepping total        |    138733 | 1.983e+04s     1 | 2.036e+04s | 2.072e+04s    34 |
| rk_stage - integrals L_h      |    693665 | 1.052e+04s    32 | 1.248e+04s | 1.387e+04s    19 |
| rk_stage - inv mass + vec upd |    693665 |      6404s    10 |      7868s | 1.018e+04s    32 |
+-------------------------------------------+------------------+------------+------------------+
@endcode



rk时间步数总数 "部分对应的是2010 MDoFs/s的吞吐量。执行139k时间步长的总体运行时间是20k秒（5.7小时）或每秒7个时间步长--对于有近6000万个未知数来说还不错。通过在计算中添加更多的内核，可以实现更多的吞吐量。




<h3>Results for flow in channel around cylinder in 3D</h3>

将通道测试案例切换到3D，并进行3次全局细化，输出结果是

@code
Running with 40 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 221,184,000 ( = 5 [vars] x 204,800 [cells] x 216 [dofs/cell/var] )


...


Time:    1.95, dt:  0.00011, norm rho:    0.01131, rho * u:    0.03056, energy:   0.04091
Time:       2, dt:  0.00011, norm rho:     0.0119, rho * u:    0.03142, energy:   0.04425


+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              | 1.734e+04s     4 | 1.734e+04s | 1.734e+04s    38 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |        41 |    0.6551s    34 |     3.216s |     7.281s     0 |
| compute transport speed       |      3546 |       160s    34 |     393.2s |     776.9s     0 |
| output                        |        41 |      1350s    34 |      1353s |      1357s     0 |
| rk time stepping total        |     17723 | 1.519e+04s     0 | 1.558e+04s | 1.582e+04s    34 |
| rk_stage - integrals L_h      |     88615 | 1.005e+04s    32 | 1.126e+04s |  1.23e+04s    11 |
| rk_stage - inv mass + vec upd |     88615 |      3056s    11 |      4322s |      5759s    32 |
+-------------------------------------------+------------------+------------+------------------+
@endcode



物理原理与二维情况类似，由于引力的作用，在Z方向有轻微的运动。在这种情况下，每个Runge-Kutta阶段的吞吐量为

@f[
\text{throughput} = \frac{n_\mathrm{time steps} n_\mathrm{stages}
n_\mathrm{dofs}}{t_\mathrm{compute}} =
\frac{17723 \cdot 5 \cdot 221.2\,\text{M}}{15580s} = 1258\, \text{MDoFs/s}.


@f]



吞吐量低于二维，因为 $\mathcal L_h$ 项的计算更加昂贵。这是由于 "度+2 "点的过度积分和较大比例的面积分（更差的体积-表面比率），以及更昂贵的通量计算。如果我们只考虑反质量矩阵和矢量更新部分，我们记录到等熵涡旋的二维案例的吞吐量为4857 MDoFs/s，有3770万个未知数，而三维案例的运行速度为4535 MDoFs/s。性能是相似的，因为这两种情况实际上都受到内存带宽的限制。

如果我们进行四级全局细化，我们需要增加进程的数量以在内存中容纳所有的东西--在这种情况下，计算需要大约350GB的RAM内存。另外，通过增加额外的资源，完成35k个时间步骤所需的时间也变得更容易忍受。因此，我们使用了6个节点，每个节点有40个核心，从而使计算有240个MPI进程。

@code
Running with 240 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 1,769,472,000 ( = 5 [vars] x 1,638,400 [cells] x 216 [dofs/cell/var] )


...


Time:    1.95, dt:  5.6e-05, norm rho:    0.01129, rho * u:     0.0306, energy:   0.04086
Time:       2, dt:  5.6e-05, norm rho:    0.01189, rho * u:    0.03145, energy:   0.04417


+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              | 5.396e+04s   151 | 5.396e+04s | 5.396e+04s     0 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |        41 |     2.632s   178 |     7.221s |     16.56s     0 |
| compute transport speed       |      7072 |       714s   193 |      1553s |      3351s     0 |
| output                        |        41 |      8065s   176 |      8070s |      8079s     0 |
| rk time stepping total        |     35350 |  4.25e+04s     0 |  4.43e+04s | 4.515e+04s   193 |
| rk_stage - integrals L_h      |    176750 | 2.936e+04s   134 | 3.222e+04s |  3.67e+04s    99 |
| rk_stage - inv mass + vec upd |    176750 |      7004s    99 | 1.207e+04s |  1.55e+04s   132 |
+-------------------------------------------+------------------+------------+------------------+
@endcode

这个模拟有近20亿个未知数--确实是一个相当大的计算量，而每个时间步长仍然只需要大约1.5秒。




<h3>Possibilities for extensions</h3>

这里介绍的代码可以直接扩展到自适应网格，给定适当的指标来设置细化标志。在声波方程的背景下，类似求解器的大规模适应性已经由<a href="https://github.com/kronbichler/exwave">exwave
project</a>实现。然而，在目前的情况下，自适应性的好处往往只限于靠近声波起源的早期时间和效果，因为波最终会反射和衍射。这就导致了到处都是陡峭的梯度，类似于湍流，以及或多或少的全局细化网格。

我们在结果部分没有讨论的另一个话题是不同时间积分方案的比较。该程序提供了四种低存储量的Runga--Kutta积分器的变体，每一种都有轻微不同的精度和稳定性行为。在这里实现的方案中，高阶方案提供了额外的精度，但在违反CFL条件之前，每级步长的效率略低。一个有趣的扩展是将这里提出的低存储变体与标准的Runge--Kutta积分器进行比较，或者使用与质量矩阵运算分开运行的矢量运算，并比较性能。




<h4>More advanced numerical flux functions and skew-symmetric formulations</h4>

正如介绍中提到的，本程序中采用的修改的Lax--Friedrichs通量和HLL通量只是文献中关于欧拉方程的大量数值通量中的两个变种。一个例子是HLLC通量（Harten-Lax-van Leer-Contact）通量，它增加了HLL通量或Roe通量中缺少的稀疏波效应。正如介绍中提到的，数值通量对高阶DG方案的影响是有争议的（与低阶离散的情况不同）。

为了提高求解器的稳定性，一个相关的改进是也要考虑空间积分项。上面使用的相当幼稚的实现方式的一个缺点是，原始欧拉方程的能量守恒（在没有冲击的情况下）只适用于离散化误差。如果解决方案的分辨率不足，离散化误差会引起数值能量的增加，并最终导致离散化的不稳定。这是因为欧拉方程中的项的不精确数值积分，其中包含有理非线性和弯曲单元的高阶内容。摆脱这种困境的方法是所谓的倾斜对称公式，见 @cite Gassner2013 的一个简单变体。倾斜对称意味着在弱式中切换解 $\mathbf{w}$ 和检验函数 $\mathbf{v}$ 的作用，除了一些边界项外，产生原始量的精确负值。在离散设置中，挑战在于当积分只被近似计算时也要保持这种倾斜对称性（在连续情况下，倾斜对称性是部分积分的结果）。偏斜对称的数值方案平衡了保守形式的空间导数  $(\nabla \mathbf v, \mathbf{F}(\mathbf w))_{K}$  和对流形式的贡献  $(\mathbf v, \tilde{\mathbf{F}}(\mathbf w)\nabla
\mathbf{w})_{K}$  ，对于某些  $\tilde{\mathbf{F}}$  。准确的条款取决于方程和积分公式，在某些情况下可以通过特殊的倾斜对称有限差分方案来理解。

要想开始，有兴趣的读者可以看看https://github.com/kronbichler/advection_miniapp，其中用deal.II对一个简单的平流方程实现了倾斜对称的DG公式。

<h4>Equipping the code for supersonic calculations</h4>

正如介绍中提到的，欧拉方程的解随着马赫数的增加而产生冲击，这需要额外的机制来稳定方案，例如限制器的形式。除了实际实施限制器或人工粘性方法外，主要的挑战是如何平衡计算，因为在有问题的单元中限制震荡所涉及的额外计算会使它们比没有限制的普通DG单元更昂贵。此外，更好地应对不连续情况的额外数值通量也是一种选择。

对于超音速流动来说，有一个因素也是必要的，那就是适当的边界条件。与介绍中讨论的并在程序中实现的亚音速流出边界相反，所有的特性都是超音速流出边界的外在表现，所以我们不想规定任何外部数据。

@f[
\mathbf{w}^+ = \mathbf{w}^- = \begin{pmatrix} \rho^-\\
(\rho \mathbf u)^- \\ E^-\end{pmatrix} \quad
 \text{(Neumann)}.


@f]



在代码中，我们将简单地添加额外的语句

@code
            else if (supersonic_outflow_boundaries.find(boundary_id) !=
                     supersonic_outflow_boundaries.end())
              {
                w_p        = w_m;
                at_outflow = true;
              }
@endcode

在 "local_apply_boundary_face() "函数中。

<h4>Extension to the linearized Euler equations</h4>

当对欧拉解的兴趣主要在于声波的传播时，围绕一个背景状态，即一个给定的密度、速度和能量（或压力）场，将欧拉方程线性化，只计算针对这些场的变化，往往是合理的。这就是航空声学的广泛领域的设置。即使有时分辨率要求大大降低，但由于线性化引起了额外的条款，实施起来就变得有些复杂了。从代码的角度来看，在算子评估中，我们还需要为代码配备要线性化的状态。这一信息可以由分析函数（根据正交点的位置进行评估）或由类似于解决方案的矢量提供。基于该矢量，我们将创建一个额外的FEEvaluation对象，从中读取并提供正交点的场值。如果背景速度为零，密度为常数，线性化的欧拉方程进一步简化，可以等效地写成声波方程的形式。

在声音传播的背景下，一个挑战往往是边界条件的定义，因为计算域需要是有限的，而实际模拟往往跨越无限的（或至少大得多）物理域。传统的Dirichlet或Neumann边界条件会引起声波的反射，最终传播到感兴趣的区域，破坏了解决方案。因此，各种非反射边界条件或海绵层的变体，通常以<a
href="https://en.wikipedia.org/wiki/Perfectly_matched_layer">perfectly
matched layers</a>的形式出现--其中解决方案被阻尼，没有反射

--是很常见的。




<h4>Extension to the compressible Navier-Stokes equations</h4>

如 @cite FehnWallKronbichler2019 所述，本教程程序中的求解器也可以通过添加粘性项扩展到可压缩的Navier-Stokes方程。为了尽量保持这里获得的性能，尽管有额外的椭圆项的成本，例如通过内部惩罚方法，我们可以像步骤59的教程程序一样，将基础从FE_DGQ切换到FE_DGQHermite。




<h4>Using cell-centric loops and shared memory</h4>

在本教程中，我们使用了以面为中心的循环。在这里，单元和面的积分在不同的循环中处理，导致对结果向量的多次写入访问，这在现代硬件上是比较昂贵的，因为写入操作通常也会导致隐含的读操作。另一方面，以元素为中心的循环是在处理一个单元的同时直接处理其所有的2d面。虽然这种循环意味着通量必须计算两次（对于一个内部面的每一面），但结果向量只需访问一次的事实--以及由此产生的算法没有竞赛条件，因此完全适合共享内存的事实--已经带来了性能的提升。如果你对这些高级主题感兴趣，你可以看一下步骤76，在那里我们对本教程进行了修改，以便我们能够使用这些功能。


examples/step-68/doc/intro.dox

 <br> 

<i>
This program was contributed by
Bruno Blais (Polytechnique Montréal),
Toni El Geitani Nehme (Polytechnique Montréal),
Rene Gassmöller (University of California Davis),
and Peter Munch (Technical University of Munich and Helmholtz-Zentrum Geesthacht).
Bruno Blais was supported by NSERC Discovery grant
RGPIN-2020-04510, by Compute Canada and Calcul Québec.
</i>

<h1>Introduction</h1>

<h3>Simulation of the motion of massless tracer particles in a vortical flow</h3>

粒子在大量应用的数值模型中发挥着重要作用。粒子通常被用作无质量追踪器，以显示瞬时流动的动态。它们也可以作为更复杂的有限元模型的一部分发挥固有的作用，如颗粒在细胞中（PIC）方法 @cite GLHPW2018 ，或者它们甚至可以用来模拟颗粒物质的运动，如离散元素法（DEM） @cite Blais2019  。在DEM的情况下，所产生的模型不再与有限元方法有关，而只是导致了一个描述颗粒运动和它们碰撞动态的常微分方程系统。所有这些模型都可以用deal.II的粒子处理能力来建立。

在本步骤中，我们使用粒子作为无质量的追踪器来说明涡流的动态。由于粒子是无质量追踪器，每个粒子 $i$ 的位置由以下常微分方程（ODE）描述。

@f[
\frac{d \textbf{x}_i}{dt} =\textbf{u}(\textbf{x}_i)


@f]



其中 $\textbf{x}_i$ 是粒子 $i$ 的位置， $\textbf{u}(\textbf{x}_i)$ 是其位置上的流速。在本步骤中，该ODE使用显式欧拉方法进行求解。由此产生的方案是。

@f[
\textbf{x}_{i}^{n+1} = \textbf{x}_{i}^{n} + \Delta t \; \textbf{u}(\textbf{x}_{i}^{n})


@f]



其中 $\textbf{x}_{i}^{n+1}$ 和 $\textbf{x}_{i}^{n}$ 分别是粒子 $i$ 在时间 $t+\Delta t$ 和 $t$ 的位置，其中 $\Delta t$ 是时间步骤。在本步骤中，粒子位置的速度以两种不同的方式获得。

- 通过在粒子的位置评估速度函数。

- 通过在背景三角图上评估速度函数，并使用有限元支持，在粒子的位置上进行插值。

第一种方法是不实际的，因为速度曲线一般是不知道的分析。第二种方法，基于在粒子位置的内插解，完全模仿了在现实的计算流体动力学模拟中的做法，这也是我们在步骤19中对粒子位置的有限元解进行评估的方式。在这一步中，我们说明了这两种策略。

我们注意到，通过使用四阶Runge-Kutta方法或其他适当的方案对粒子的运动进行时间积分，可以获得更大的精度。  实施一个更先进的时间积分方案将是这一步骤的直接延伸。

<h3>Particles in deal.II</h3>

在deal.II中， Particles::Particle 是非常简单和灵活的实体，可以用来建立PIC、DEM或任何类型的基于粒子的模型。粒子在现实空间中有一个位置，在它们所在的元素的参考空间中有一个位置，还有一个唯一的ID。在大多数情况下，包含粒子的模拟需要大量的粒子。因此，通过一个聚集所有粒子的实体来处理所有的粒子变得很有趣。在deal.II中，这是通过使用 Particles::ParticleHandler 类来实现的。

默认情况下，粒子没有直径、质量或任何其他我们通常期望的物理粒子的物理属性。然而，通过ParticleHandler，粒子可以访问一个 Particles::PropertyPool. PropertyPool是一个数组，可以用来存储与粒子相关的任意数量的属性。因此，用户可以建立自己的粒子解算器，并将所需的属性归属于粒子（例如，质量、电荷、直径、温度等）。在本教程中，这被用来存储流体速度的值和粒子所属的过程ID。

<h3>Challenges related to distributed particle simulations</h3>

尽管本步骤不是计算密集型的，但包括许多粒子的模拟可能对计算要求很高，需要并行化。本步骤展示了deal.II对粒子的分布式并行能力。一般来说，在包括粒子的平行分布式模拟中，有三个主要挑战。

- 在分布式三角图上生成粒子。

- 在处理器之间交换离开本地域的粒子。

- 对模拟进行负载平衡，使每个处理器都有类似的计算负载。这些挑战及其在交易.II中的解决方案已经在 @cite GLHPW2018 中进行了更详细的讨论，但我们将在下面进行总结。

当然也有关于简单设置使用粒子的代码的问题。这些问题在第19步中已经基本解决了。一些更高级的技术也将在第70步中讨论。

<h4>Parallel particle generation</h4>

以可扩展的方式生成分布式粒子并不简单，因为在找到它们所在的单元之前，必须首先确定它们所属的处理器。 deal.II通过 Particles::Generator 命名空间提供了许多生成粒子的能力。  其中一些粒子生成器只在本地拥有的子域上创建粒子。例如， Particles::Generators::regular_reference_locations() 在本地子域的每个单元内的相同参考位置创建粒子， Particles::Generators::probabilistic_locations() 使用全局定义的概率密度函数来确定本地生成粒子的数量和位置。

在其他情况下，如本步骤，粒子必须在单元格上的特定位置生成，而这些单元格可能只由处理器的一个子集拥有。在大多数这些情况下，粒子的插入是在非常有限的时间步长内完成的，因此，不构成计算成本的很大一部分。对于这些情况，deal.II提供了方便的 Particles::Generators ，可以在全局范围内插入粒子，即使粒子不在启动创建粒子的调用的并行进程所拥有的单元中。生成器首先定位粒子位于哪个子域上，确定它们位于哪个单元中，并在处理器之间交换必要的信息，以确保生成的粒子具有正确的属性。因此，这种类型的粒子生成可能是通信密集型的。 Particles::Generators::dof_support_points 和 Particles::Generators::quadrature_points 分别使用三角法和相关DoFHandler或正交的点来生成粒子。用于生成粒子的三角形可以是用于背景网格的同一三角形，在这种情况下，这些函数与上一段中描述的 Particles::Generators::regular_reference_locations() 函数非常相似。然而，用于生成粒子的三角法也可以与背景网格的三角法不同（不匹配），这对于生成特定形状的粒子（如本例），或者在两个不同的计算网格之间传输信息（如步骤-70）是很有用的。  此外， Particles::ParticleHandler 类提供了 Particles::ParticleHandler::insert_global_particles() 函数，可以从任意点的矢量和边界框的全局矢量中插入粒子。在本步骤中，我们在非匹配三角形上使用 Particles::Generators::quadrature_points() 函数来插入位于圆盘形状位置的粒子。

<h4>Particle exchange</h4>

当粒子在平行分布式计算中移动时，它们可能会离开本地拥有的子域，需要转移到它们的新主人进程中。这种情况可能以两种非常不同的方式出现。首先，如果先前拥有的进程知道丢失的粒子的新主人（例如，因为粒子从一个处理器的本地拥有的单元移动到分布式三角形的相邻的幽灵单元），那么转移可以作为每个进程和新主人之间的点对点通信有效处理。每当粒子被分类到新单元时，这种转移就会自动发生。其次，以前的所有者可能不知道粒子被转移到哪个进程。在这种情况下，粒子被默认丢弃，因为全局搜索所有者的成本很高。步骤19显示了这样一个被丢弃的粒子仍然可以被收集、解释，并可能被用户重新插入。在本例中，我们通过在时间步长上施加一个CFL准则来防止第二种情况，以确保粒子最多会移动到本地进程的幽灵层，因此可以自动发送到邻近的进程。

<h4>Balancing mesh and particle load</h4>

在使用粒子的并行分布式计算中出现的最后一个挑战是平衡计算负荷，即在网格上完成的工作，例如解决有限元问题，和在粒子上完成的工作，例如移动粒子或计算粒子之间或粒子与网格之间的力。默认情况下，例如在步骤40中，deal.II尽可能均匀地将背景网格分配给可用的进程，也就是说，它平衡每个进程上的单元数量。然而，如果一些单元拥有比其他单元多得多的粒子，或者一个单元的粒子比其他单元的粒子计算成本高得多，那么这个问题就不再有效地扩展了（关于我们认为的 "可扩展 "程序的讨论，见 @ref GlossParallelScaling "这个词汇条"）。因此，我们必须应用一种 "负载平衡 "的形式，这意味着我们估计与每个单元及其粒子相关的计算负载。然后，重新划分网格就会考虑到这个综合的计算负荷，而不是单元数的简化假设  @cite GLHPW2018  。

在本节中，我们只讨论了分布式计算中针对粒子的挑战。粒子与有限元解决方案共享的并行挑战（并行输出，网格细化过程中的数据传输）可以用其他例子中已经讨论过的有限元问题的解决方案来解决。

<h3>The testcase</h3>

在本步骤中，我们使用粒子作为无质量的追踪器来说明一个特殊的涡流的动力学：Rayleigh--Kothe涡流。这种流动模式通常被用作界面跟踪方法（如流体体积法和水平集法）的复杂测试案例，因为它导致了流体的强烈旋转和伸长  @cite Blais2013  。

这个Rayleigh-Kothe涡流的流函数 $\Psi$ 被定义为。

@f[
\Psi = \frac{1}{\pi} \sin^2 (\pi x) \sin^2 (\pi y) \cos \left( \pi \frac{t}{T} \right)


@f]

其中 $T$ 为流动的一半周期。二维的速度曲线 (  $\textbf{u}=[u,v]^T$  ) 是 :

@f{eqnarray*}
   u &=&  - \frac{\partial\Psi}{\partial y} = -2 \sin^2 (\pi x) \sin (\pi y) \cos (\pi y)  \cos \left( \pi \frac{t}{T} \right)\\
   v &=&  \frac{\partial\Psi}{\partial x} = 2 \cos(\pi x) \sin(\pi x) \sin^2 (\pi y) \cos \left( \pi \frac{t}{T} \right)


@f}



速度曲线在下面的动画中得到说明。

@htmlonly
<p align="center">
  <iframe width="560" height="500" src="https://www.youtube.com/embed/m6hQm7etji8"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly



可以看出，由于项 $\cos \left( \pi \frac{t}{T} \right)$ 的存在，这个速度会周期性地逆转，材料在每一个长度为 $t=2T$ 的周期后都会结束在其起始位置。我们将正好运行这个教程程序一个周期，并将最终的粒子位置与初始位置进行比较，以说明这一流动特性。这个例子使用测试案例产生了两个模型，它们对粒子的处理略有不同。第一个模型将精确的分析速度解作为每个粒子的速度。因此，在这个模型中，分配给粒子的速度没有错误，而在给定时间内，粒子位置与分析位置的任何偏差都是由于使用时间步进法不准确地求解粒子运动方程的错误造成的。在第二个模型中，分析速度场首先被内插到一个有限元矢量空间（以模拟速度是通过求解有限元问题得到的情况，与步骤19中每个粒子的ODE取决于有限元解的方式相同）。然后在粒子的位置上评估这个有限元 "解决方案"，以解决其运动方程。这两种情况之间的差异允许评估所选择的有限元空间是否足够精确，以所选择的粒子平流方案的最佳收敛率来平流粒子，这个问题在实践中对确定组合算法的精度很重要（例如，见 @cite Gassmoller2019  ）。


examples/step-68/doc/results.dox



<h1>Results</h1>

运行该程序的目录中默认包含一个参数文件的例子。如果你没有在命令行中指定参数文件作为参数，程序将默认尝试读取文件 "参数.prm"，并执行代码。

在任何数量的核心上，模拟输出将看起来像。

@code
bash$ mpirun -np 4 ./step-68 parameters.prm
Number of particles inserted: 606
Repartitioning triangulation after particle generation
Writing particle output file: analytical-particles-0
Writing particle output file: analytical-particles-10
Writing particle output file: analytical-particles-20
Writing particle output file: analytical-particles-30
...
Number of particles inserted: 606
Repartitioning triangulation after particle generation
Writing particle output file: interpolated-particles-0
Writing background field file: background-0
Writing particle output file: interpolated-particles-10
Writing background field file: background-10
Writing particle output file: interpolated-particles-20
Writing background field file: background-20
Writing particle output file: interpolated-particles-30
Writing background field file: background-30
...
Writing particle output file: interpolated-particles-1980
Writing background field file: background-1980
Writing particle output file: interpolated-particles-1990
Writing background field file: background-1990
Writing particle output file: interpolated-particles-2000
Writing background field file: background-2000
@endcode



我们注意到，在默认情况下，模拟以分析速度运行粒子跟踪2000次，然后从头开始，以相同的时间运行速度插值的粒子跟踪。每隔10次迭代就会写出结果。

<h3> Motion of the particles </h3>

下面的动画显示了粒子在被流场吸引时的轨迹。我们看到，在流动的整个过程中，粒子又回到了它们的初始配置，这是预料之中的事。

@htmlonly
<p align="center">
  <iframe width="560" height="500" src="https://www.youtube.com/embed/EbgS5Ch35Xs"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly



<h3> Dynamic load balancing </h3>

下面的动画显示了动态负载平衡的影响。我们清楚地看到，子域自我调整以平衡每个子域的粒子数量。然而，完美的负载平衡并没有达到，部分原因是由于背景网格的粗糙性。

@htmlonly
<p align="center">
  <iframe width="560" height="500" src="https://www.youtube.com/embed/ubUcsR4ECj4"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly






<h3>Possibilities for extensions</h3>

这个程序强调了在deal.II中处理粒子的一些主要能力，特别是它们用于分布式并行模拟的能力。然而，这一步骤可以以多种方式进行扩展。

- 可以使用高阶时间积分（例如使用Runge-Kutta 4方法）来提高精度，或者在相同精度下允许更大的时间步长。

- 完整的运动方程（含惯性）可以为粒子求解。在这种情况下，粒子将需要有额外的属性，例如它们的质量，如步骤19，如果想考虑与流体的相互作用，还需要考虑它们的直径。

- 耦合到流动求解器。这一步可以直接与任何解决斯托克斯方程（第32步，第70步）或纳维-斯托克斯方程（例如第57步）的并行程序相耦合。

- 计算两个模型之间最终粒子位置的差异，可以量化内插误差对粒子运动的影响。


examples/step-69/doc/intro.dox

<i>
  This program was contributed by Matthias Maier (Texas A&M University),
  and Ignacio Tomas (Sandia National Laboratories$^{\!\dagger}$).
</i>

 $^\dagger$   <em>  桑迪亚国家实验室是一个多任务实验室，由霍尼韦尔国际公司的全资子公司桑迪亚国家技术与工程解决方案有限公司根据合同DE-NA0003525为美国能源部国家核安全局管理和运营。本文件描述了客观的技术结果和分析。文件中可能表达的任何主观观点或意见，不一定代表美国能源部或美国政府的观点。 </em> 

 @note  本教程步骤实现了一个基于一阶精确<i>guaranteed
maximum wavespeed method</i>的求解欧拉气体动力学方程 @cite GuermondPopov2016  。因此，它主要为教育目的而提出。对于实际的研究计算，你可能要考虑探索相应的<a href="https://github.com/conservation-laws/ryujin">high-performance
implementation of a second-order accurate scheme</a>，它使用<i>convex
limiting</i>技术，以及强保稳（SSP）时间积分，见 @cite GuermondEtAl2018  （<a href="https://conservation-laws.43-1.org/">website</a>）。

 @dealiiTutorialDOI{10.5281/zenodo.3698223,https://zenodo.org/badge/DOI/10.5281/zenodo.3698223.svg} 

<a name="Intro"></a>

<h1>Introduction</h1>

本教程提出了一个用于求解可压缩欧拉方程的一阶方案，该方案基于三个要素：在有限元背景下对欧拉方程进行<i>collocation</i>型离散化；基于局部波速的<i>guaranteed</i>上限的图粘性稳定；以及显式时间步进。因此，本教程步骤中提出的观点和技术与步骤33中的观点和技术有很大的不同，后者主要是使用自动微分。从编程的角度来看，本教程将关注在大规模计算中发现的一些技术：混合线程-MPI并行化；自由度的有效局部编号；使用工作线程进行并发的后处理和结果的写出；以及检查点和重启。

应该注意的是，双曲守恒定律背景下的一阶方案需要太多的自由度来解决模拟流体的某些关键特征，因此，通常只能作为高阶方案的基本构建块  @cite GuermondEtAl2018  。然而，我们希望读者在跳入完整的研究代码（如  @cite GuermondEtAl2018  中讨论的二阶方案）之前，仍然认为教程步骤是一个很好的起点（特别是在编程技术方面）。


<a name="eulerequations"></a>

<h3>Euler's equations of gas dynamics</h3>

可压缩的欧拉气体动力学方程以保守的形式写成如下。

@f{align}
\mathbf{u}_t + \text{div} \, \mathbb{f}(\mathbf{u}) = \boldsymbol{0} ,


@f}

其中 $\mathbf{u}(\textbf{x},t):\mathbb{R}^{d} \times \mathbb{R}
\rightarrow \mathbb{R}^{d+2}$  ，和 $\mathbb{f}(\mathbf{u}):\mathbb{R}^{d+2}
\rightarrow \mathbb{R}^{(d+2) \times d}$  ，以及 $d \geq 1$  是空间维度。我们说 $\mathbf{u} \in \mathbb{R}^{d+2}$ 是状态， $\mathbb{f}(\mathbf{u}) \in  \mathbb{R}^{(d+2) \times d}$ 是系统的通量。在欧拉方程的情况下，状态由 $\textbf{u} = [\rho, \textbf{m},E]^{\top}$ 给出：其中 $\rho \in \mathbb{R}^+$ 表示密度， $\textbf{m} \in \mathbb{R}^d$ 是动量，而 $E
\in \mathbb{R}^+$ 是系统的总能量。系统的通量 $\mathbb{f}(\mathbf{u})$ 被定义为

@f{align*}
\mathbb{f}(\textbf{u})
=
\begin{bmatrix}
  \textbf{m}^\top \\
  \rho^{-1} \textbf{m} \otimes \textbf{m} + \mathbb{I} p\\
  \tfrac{\textbf{m}^\top}{\rho} (E + p)
\end{bmatrix},


@f}

其中 $\mathbb{I} \in \mathbb{R}^{d \times d}$ 是身份矩阵， $\otimes$ 表示张量积。在这里，我们介绍了压力 $p$ ，一般来说，它是由一个封闭式的状态方程定义的。在本教程中，我们将讨论限制在多晶体理想气体的范畴内，对于这些气体，压力由以下公式给出

@f{align*}
p = p(\textbf{u}) := (\gamma -1) \Big(E -
\tfrac{|\textbf{m}|^2}{2\,\rho}
\Big),


@f}

其中因子 $\gamma \in (1,5/3]$ 表示<a
href="https://en.wikipedia.org/wiki/Heat_capacity_ratio">ratio of specific
heats</a>。




<h4>Solution theory</h4>

双曲守恒定律，如

@f{align*}
\mathbf{u}_t + \text{div} \, \mathbb{f}(\mathbf{u}) = \boldsymbol{0},


@f}

对解理论构成了重大挑战。一个明显的现象是，以变分形式重写方程并以解本身进行检验并不能导致能量估计，因为配对 $\langle \text{div} \, \mathbb{f}(\mathbf{u}), \mathbf{u}\rangle$ （理解为 $L^2(\Omega)$ 内积或对偶性配对）不能保证是非负的。在这种情况下，诸如能量稳定性或 $L^2(\Omega)$ 稳定性的概念（一般来说）是没有意义的。

历史上，为了加深对双曲守恒定律的理解而采取的最有成效的步骤是假设解被正式定义为 $\mathbf{u} := \lim_{\epsilon \rightarrow
0^+} \mathbf{u}^{\epsilon}$ ，其中 $\mathbf{u}^{\epsilon}$ 是抛物线正化的解

@f{align}
\mathbf{u}_t^{\epsilon} + \text{div} \, \mathbb{f}(\mathbf{u}^{\epsilon})


- {\epsilon} \Delta \mathbf{u}^{\epsilon} = 0.


@f}

这样的解决方案，被理解为在零粘度极限下恢复的解决方案，通常被称为<i>viscosity solutions</i>。这是因为，从物理上看 $\epsilon$ 可以理解为与流体的粘度有关，也就是说，一个表示以不同速度运动的相邻气体粒子对彼此施加的摩擦力大小的量）。欧拉方程本身是在无摩擦的假设下得出的，但在物理上可以预期描述摩擦或粘度消失的极限情况。)这种解决方案的全球存在和唯一性是一个开放的问题。然而，我们至少知道，如果这种粘度解存在，它们必须满足 $\textbf{u}(\mathbf{x},t) \in \mathcal{B}$ 对所有 $\mathbf{x} \in \Omega$ 和 $t \geq 0$ 的约束条件，其中

@f{align}
  \mathcal{B} = \big\{ \textbf{u} =
  [\rho, \textbf{m},E]^{\top} \in \mathbb{R}^{d+2} \, \big |
  \
  \rho > 0 \, ,
  \
  \ E - \tfrac{|\textbf{m}|^2}{2 \rho} > 0 \, ,
  \
  s(\mathbf{u}) \geq \min_{x \in \Omega} s(\mathbf{u}_0(\mathbf{x}))
  \big\}.


@f}

这里， $s(\mathbf{u})$ 表示比熵值

@f{align}
  s(\mathbf{u}) = \ln \Big(\frac{p(\mathbf{u})}{\rho^{\gamma}}\Big).


@f}

我们将把 $\mathcal{B}$ 称为欧拉方程的不变量集。换句话说，状态 $\mathbf{u}(\mathbf{x},t)\in\mathcal{B}$ 服从密度的正性，内能的正性，以及比熵的局部最小原则。这个条件是精确（粘性）解所满足的一类点式稳定性约束的简化版本。我们所说的 "点 "是指该约束必须在域的每一点上得到满足，而不仅仅是在平均（积分，或高阶矩）意义上。

在数值逼近的背景下，违反这样的约束有可怕的后果：它几乎肯定会导致数值方案的灾难性失败，失去双曲性，以及总体上，失去（离散）问题的良好解决性。这也意味着我们已经计算了一些不能从物理上解释的东西。例如，我们该如何看待一个具有负密度的计算结果？下面我们将制定一个方案，确保 $\mathbf{u}(\mathbf{x},t)$ 的离散近似仍在 $\mathcal{B}$ 中。




<h4>Variational versus collocation-type discretizations</h4>

在步骤9、步骤12、步骤33和步骤67之后，在这一点上，将欧拉方程的离散化建立在一个（半离散的）变分公式上看起来很诱人。

@f{align*}
  (\partial_t\mathbf{u}_{h},\textbf{v}_h)_{L^2(\Omega)}


  - ( \mathbb{f}(\mathbf{u}_{h}) ,\text{grad} \, \textbf{v}_{h})_{L^2(\Omega)}
  + s_h(\mathbf{u}_{h},\textbf{v}_h)_{L^2(\Omega)} = \boldsymbol{0}
  \quad\forall \textbf{v}_h \in \mathbb{V}_h.


@f}

这里， $\mathbb{V}_h$ 是一个适当的有限元空间， $s_h(\cdot,\cdot)_{L^2(\Omega)}$ 是一些线性稳定方法（可能辅以一些特殊的冲击捕捉技术，例如见 @cite GuermondErn2004 的第五章和其中的参考文献）。在deal.II教程中描述的大多数随时间变化的离散化方法都是基于这样一种（半离散的）变量方法。从根本上说，从分析的角度来看，变分离散化被认为是为了提供某种全局（积分）稳定性的概念，也就是说，一种估计形式为

@f{align*}
  |\!|\!| \mathbf{u}_{h}(t) |\!|\!| \leq |\!|\!| \mathbf{u}_{h}(0) |\!|\!|


@f}

成立，其中 $|\!|\!| \cdot |\!|\!| $ 可以代表 $L^2(\Omega)$ 准则，或者更广泛地代表一些离散的（可能与网格有关）能量准则。自80年代中期以来，双曲守恒定律的变异离散化非常流行，特别是与SUPG型稳定化和/或上卷技术相结合（见 @cite Brooks1982 和 @cite Johnson1986 的早期工作）。它们已被证明是在亚音速无冲击系统和类似的良性情况下进行模拟的一些最佳方法。

<！--特别是，教程Step-67侧重于使用dG技术研究亚音速体系中的欧拉气体动力学方程。-->

然而，在跨音速和超音速阶段，以及冲击-流体力学应用中，使用变量方案可能是值得怀疑的。事实上，在写这篇文章的时候，大多数冲击-流体力学代码仍然是以有限体积方法为基础的。变分方案在这种极端状态下失败的主要原因是缺乏点状稳定性。这是因为<i>a priori</i>对积分量（如矩积分）的约束一般来说对解的点定性没有影响。虽然其中一些问题可能会通过对正确的冲击捕捉方案的（永久）追逐而得到缓解，但类似有限差分的方案和有限体积方案在许多方面仍有优势。

因此，在这一教程步骤中，我们偏离了变分方案。我们将提出一个完全代数化的表述（具有拼合型方案的味道），该表述在点上保留了约束，即：。

@f{align*}
  \textbf{u}_h(\mathbf{x}_i,t) \in \mathcal{B}
  \;\text{at every node}\;\mathbf{x}_i\;\text{of the mesh}.


@f}

与有限差分/体积方案相反，本步骤实现的方案最大限度地利用了有限元软件的基础设施，在任何空间维度的任何网格上都能工作，并且理论上保证始终工作，没有例外。这说明deal.II的使用范围远远超出了希尔伯特空间中的变分方案，deal.II中的大量类、模块和命名空间都可以适用于这种目的。




<h3>Description of the scheme </h3>

让 $\mathbb{V}_h$ 为标量值的有限维空间，由基 $\{\phi_i\}_{i \in \mathcal{V}}$ 跨越，其中。   $\phi_i:\Omega \rightarrow
\mathbb{R}$ 和 $\mathcal{V}$ 是识别网格中每个标量自由度（DOF）的所有指数（非负整数）的集合。因此，标量有限元函数 $u_h \in \mathbb{V}_h$ 可以写成 $u_h = \sum_{i \in \mathcal{V}} U_i \phi_i$ 与 $U_i \in
\mathbb{R}$  。我们引入矢量值近似空间的符号  $\pmb{\mathbb{V}}_h := \{\mathbb{V}_h\}^{d+2}$  。设 $\mathbf{u}_h
\in \pmb{\mathbb{V}}_h$  ，则可以写成 $\mathbf{u}_h = \sum_{i
\in \mathcal{V}} \mathbf{U}_i \phi_i$  ，其中 $\mathbf{U}_i \in
\mathbb{R}^{d+2}$ 和 $\phi_i$ 是标量值的形状函数。

 @note  我们特意避免在我们的符号中使用矢量值的有限元空间。矢量值有限元空间对于PDE系统（如Navier-Stokes）的变分公式是自然的。在这种情况下，必须计算的相互作用描述了<i>interactions between DOFs</i>：通过对矢量值DoFHandler的适当重新编号（即用FESystem初始化），可以相对容易地计算块矩阵（为了推进解决方案而需要）。然而，在时间明确的搭配型方案（如有限差分和/或本教程中提出的方案）的背景下，必须计算的相互作用可以更好地描述为<i>interactions between nodes</i>（不是在DOF之间）。此外，在我们的案例中，我们不解决线性方程，以推进解决方案。这使得在理论和/或实践中使用矢量值有限元空间的理由非常少。

我们将使用通常的拉格朗日有限元：让 $\{\mathbf{x}_i\}_{i \in
\mathcal{V}}$ 表示所有支持点的集合（见 @ref GlossSupport "本词汇条"），其中 $\mathbf{x}_i \in \mathbb{R}^d$  。那么每个索引 $i \in
\mathcal{V}$ 都能唯一识别一个支持点 $\mathbf{x}_i$ ，以及一个标量值的形状函数 $\phi_i$ 。有了这个符号在手，我们可以将（显式时间步进）方案定义为。

@f{align*}{
  m_i \frac{\mathbf{U}_i^{n+1} - \mathbf{U}_i^{n}}{\tau}
  + \sum_{j \in \mathcal{I}(i)} \mathbb{f}(\mathbf{U}_j^{n})\cdot
  \mathbf{c}_{ij} - \sum_{j \in \mathcal{I}(i)}
  d_{ij} \mathbf{U}_j^{n} = \boldsymbol{0} \, ,


@f}

其中

  -  $m_i \dealcoloneq \int_{\Omega} \phi_i \, \mathrm{d}\mathbf{x}$ 是肿块质量矩阵

  -  $\tau$ 是时间步长。

  -  $\mathbf{c}_{ij} \dealcoloneq \int_{\Omega} \nabla\phi_j\phi_i \,
    \mathrm{d}\mathbf{x}$ （注意， $\mathbf{c}_{ij}\in \mathbb{R}^d$ ）是一个矢量值矩阵，被用来在弱意义上近似通量的发散。

  -  $\mathcal{I}(i) \dealcoloneq \{j \in \mathcal{V} \ | \ \mathbf{c}_{ij}
    \not \equiv \boldsymbol{0}\} \cup \{i\}$ 是包含与索引 $i$ 耦合的所有自由度的邻接列表。换句话说， $\mathcal{I}(i)$ 包含行索引i的所有非零列索引。 $\mathcal{I}(i)$ 也将被称为 "模版"。

  -  $\mathbb{f}(\mathbf{U}_j^{n})$ 是针对与支持点 $\mathbf{x}_j$ 相关的状态 $\mathbf{U}_j^{n}$ 所评估的双曲系统的通量 $\mathbb{f}$ 。

  - 如果 $d_{ij} \dealcoloneq \max \{ \lambda_{\text{max}}
    (\mathbf{U}_i^{n},\mathbf{U}_j^{n}, \textbf{n}_{ij}),
    \lambda_{\text{max}} (\mathbf{U}_j^{n}, \mathbf{U}_i^{n},
    \textbf{n}_{ji}) \} \|\mathbf{c}_{ij}\|$ 是所谓的<i>graph viscosity</i>。图形粘度作为一个稳定项，它在某种程度上是 $\epsilon \Delta \mathbf{u}$ 的离散对应物，出现在上述的粘度解的概念中。我们将把 $d_{ij}$ 的构造建立在最大局部波速 $\lambda_{\text{max}}$ 的估计上，稍后将详细解释。

  - 粘度矩阵的对角线项被定义为  $d_{ii} = - \sum_{j \in \mathcal{I}(i)\backslash \{i\}} d_{ij}$  。

  -  $\textbf{n}_{ij} = \frac{\mathbf{c}_{ij}}{ \|\mathbf{c}_{ij}\| }$ 是 $\textbf{c}_{ij}$ 矩阵的归一化，它进入了近似黎曼求解器，我们用它来计算本地波速的近似值 $\lambda_{\text{max}}$ 。这将在下文中进一步解释）。

 $\lambda_{\text{max}} (\mathbf{U},\mathbf{V},
\textbf{n})$ 的定义远非微不足道，我们将推迟精确的定义，以便首先关注一些算法和实现问题。我们注意到

  -  $m_i$ 和 $\mathbf{c}_{ij}$ 不随时间变化（只要我们保持离散化固定）。因此，将这些矩阵/向量在所谓的<i>offline computation</i>中组装一次，并在每个时间步长中重复使用是有意义的。它们是我们将称之为离线数据的一部分。

  - 在每个时间步骤中，我们必须评估 $\mathbb{f}(\mathbf{U}_j^{n})$ 和 $d_{ij} \dealcoloneq \max \{ \lambda_{\text{max}}
    (\mathbf{U}_i^{n},\mathbf{U}_j^{n}, \textbf{n}_{ij}),
    \lambda_{\text{max}} (\mathbf{U}_j^{n}, \mathbf{U}_i^{n},
    \textbf{n}_{ji}) \} \|\mathbf{c}_{ij}\| $ ，这将构成大部分的计算成本。

考虑下面的伪代码，说明在一个新的时间 $\textbf{U}^{n+1}$ 计算解决方案 $t_{n+1} = t_n + \tau_n$ 的可能的直接策略，给定一个在时间 $t_n$ 的已知状态 $\textbf{U}^{n}$  。

@f{align*}
&\textbf{for } i \in \mathcal{V} \\
&\ \ \ \  \{\mathbf{c}_{ij}\}_{j \in \mathcal{I}(i)} \leftarrow
\mathtt{gather\_cij\_vectors} (\textbf{c}, \mathcal{I}(i)) \\
&\ \ \ \ \{\textbf{U}_j^n\}_{j \in \mathcal{I}(i)} \leftarrow
\mathtt{gather\_state\_vectors} (\textbf{U}^n, \mathcal{I}(i)) \\
&\ \ \ \ \ \textbf{U}_i^{n+1} \leftarrow \mathbf{U}_i^{n} \\
&\ \ \ \ \textbf{for } j \in \mathcal{I}(i)\backslash\{i\} \\
&\ \ \ \ \ \ \ \  \texttt{compute } d_{ij} \\
&\ \ \ \ \ \ \ \  \texttt{compute } \mathbb{f}(\mathbf{U}_j^{n}) \\
&\ \ \ \ \ \ \ \  \textbf{U}_i^{n+1} \leftarrow \textbf{U}_i^{n+1} - \frac{\tau_n}{m_i}
 \mathbb{f}(\mathbf{U}_j^{n})\cdot \mathbf{c}_{ij} + d_{ij} \mathbf{U}_j^{n} \\
&\ \ \ \ \textbf{end} \\
&\ \ \ \ \mathtt{scatter\_updated\_state} (\textbf{U}_i^{n+1}) \\
&\textbf{end}


@f}



我们在此注意到，。

- 这种 "装配 "不需要任何形式的正交或单元环。

- 这里 $\textbf{c}$ 和 $\textbf{U}^n$ 是一个全局矩阵和一个全局向量，分别包含所有向量 $\mathbf{c}_{ij}$ 和所有状态 $\mathbf{U}_j^n$ 。

-  $\mathtt{gather\_cij\_vectors}$ 、 $\mathtt{gather\_state\_vectors}$ 和 $\mathtt{scatter\_updated\_state}$ 是假设的实现，它们要么收集（来自）全局矩阵和向量，要么写入（进入）。

- 如果我们假设一个二维空间的笛卡尔网格，一阶多项式空间  $\mathbb{Q}^1$  ，并且  $\mathbf{x}_i$  是一个内部节点（即  $\mathbf{x}_i$  不在域的边界上），那么。   $\{\textbf{U}_j^n\}_{j \in \mathcal{I}(i)}$ 应该包含九个状态矢量元素（即与形状函数 $\phi_i$ 相关的补丁/宏元素中的所有状态）。这是与通常基于单元的循环的主要区别之一，在这种循环中，收集功能（在deal.II的情况下编码为FEValuesBase<dim, spacedim>.get_function_values()）只收集本地单元（只是补丁的一个子集）的值。

实际执行将在一个关键方面偏离上述代码：时间步长 $\tau$ 必须根据CFL条件来选择

@f{align*}
  \tau_n = c_{\text{cfl}}\,\min_{
  i\in\mathcal{V}}\left(\frac{m_i}{-2\,d_{ii}^{n}}\right),


@f}

其中 $0<c_{\text{cfl}}\le1$ 是一个选定的常数。这就需要在实际执行上述更新之前，在一个单独的步骤中计算所有的 $d_{ij}$ 。不过，核心原则没有改变：我们不是在单元格上循环，而是在稀疏图的所有边上循环。

 @note 在有限元界之外，在更广泛的CFD界，遇到这种全代数方案（即没有双线性形式，没有单元环，也没有正交）并不罕见。这类方案有丰富的应用历史，也被称为<i>edge-based</i>或<i>graph-based</i>有限元方案（例如，见 @cite Rainald2008 的历史概述）。然而，需要强调的是，该方案的代数结构（在本教程中介绍）和节点循环并不只是一个性能上的噱头。实际上，这个方案的结构是出于理论上的需要：该方案的点稳定性证明取决于该方案的特定代数结构。此外，使用单元环不可能计算代数粘性 $d_{ij}$ ，因为它们非线性地依赖于跨越多个单元的信息（叠加不成立：将不同单元的贡献相加不会导致正确结果）。

<h3>Stable boundary conditions and conservation properties.</h3>

在本教程步骤中考虑的例子中，我们使用了三种不同类型的边界条件：本质类边界条件（我们在域的左侧边界规定了一个状态），域的右侧边界的流出边界条件（也称为 "无 "边界条件），以及障碍物顶部、底部和表面的 "反射 "边界条件 $\mathbf{m} \cdot
\boldsymbol{\nu} = 0$ （也称为 "滑动 "边界条件）。我们不会过多地讨论基本的和 "无为 "的边界条件，因为它们的实现相对容易，读者可以直接从（有记录的）源代码中获取实现。在这部分介绍中，我们将只关注 "反射 "边界条件，这在某种程度上是比较棘手的。

 @note  在写这篇文章的时候（2020年初），说双曲守恒定律系统的稳定边界条件的分析和实现都是一个开放的问题，这不是没有道理的。对于变分公式的情况，稳定的边界条件是那些导致良好的（胁迫的）双线性形式。但是对于一般的双曲守恒定律系统（以及本教程中所使用的代数式），胁迫性作为稳定性的一个概念没有适用性和/或意义。在本教程的步骤中，我们将使用不变集的保存作为我们主要的稳定性概念，它（至少）保证了离散问题的良好处理。

对于反射边界条件的情况，我们将按以下步骤进行。

- 对于每一个时间步骤的推进，完全不满足边界条件。

- 让 $\partial\Omega^r$ 成为我们想要强制执行反射边界条件的边界部分。在时间步骤结束时，我们在一个后处理步骤中强烈地执行反射边界条件，在这个步骤中我们执行投影@f{align*}
    \mathbf{m}_i \dealcoloneq \mathbf{m}_i - (\widehat{\boldsymbol{\nu}}_i
    \cdot \mathbf{m}_i)  \widehat{\boldsymbol{\nu}}_i \ \
    \text{where} \ \
    \widehat{\boldsymbol{\nu}}_i \dealcoloneq
    \frac{\int_{\partial\Omega} \phi_i \widehat{\boldsymbol{\nu}} \,
    \, \mathrm{d}\mathbf{s}}{\big|\int_{\partial\Omega} \phi_i
    \widehat{\boldsymbol{\nu}} \, \mathrm{d}\mathbf{s}\big|}
    \ \ \text{for all }\mathbf{x}_i \in \partial\Omega^r
    \ \ \ \ \boldsymbol{(1)}
    @f} 。

  去掉了 $\mathbf{m}$ 的法线成分。这是一个有点天真的想法，它保留了PDE的一些基本属性，我们在下面解释。

这种方法通常被称为 "边界条件的明确处理"。经验丰富的有限元人可能会发现这种方法值得怀疑。毫无疑问，在求解抛物线或椭圆方程时，我们通常通过使它们成为近似空间的一部分来强制执行基本（类似于Dirichlet）边界条件  $\mathbb{V}$  ，并将自然（例如Neumann）边界条件作为变分公式的一部分。我们也知道，边界条件的明确处理（在抛物线PDEs的背景下）几乎肯定会导致灾难性的后果。然而，在非线性双曲方程的背景下，我们有。

- 证明（对于反映边界条件的情况）边界条件的显式处理不仅是保守的，而且还能保证对所有 $i \in \mathcal{V}$ 的属性 $\mathbf{U}_i \in \mathcal{B}$ 的保存（良好处理性）是比较容易的。这也许是使用显式执行边界条件的最重要原因。

- 就我们所知：我们不知道有任何数学结果证明，在使用边界条件直接执行到近似空间，或者使用Nitsche惩罚方法（例如广泛用于非连续Galerkin方案）的弱执行时，有可能保证所有 $\mathbf{U}_i \in
\mathcal{B}$ 的属性。此外，其中一些传统的想法导致了相当严格的时间步长约束。

- 有足够的数值证据表明，在CFL条件下，对类似于Dirichlet的边界条件的明确处理是稳定的，不会带来任何精度上的损失。

如果 $\mathbf{u}_t + \text{div} \, \mathbb{f}(\mathbf{u}) = \boldsymbol{0}$ 代表欧拉方程，在整个边界上反映边界条件（即 $\partial\Omega^r \equiv \partial\Omega$ ），我们在空间和时间 $\int_{\Omega}\int_{t_1}^{t_2}$ 中进行积分，我们将得到

@f{align*}
\int_{\Omega} \rho(\mathbf{x},t_2) \, \mathrm{d}\mathbf{x} =
\int_{\Omega} \rho(\mathbf{x},t_1) \, \mathrm{d}\mathbf{x} \ , \ \
\int_{\Omega} \mathbf{m}(\mathbf{x},t_2) \, \mathrm{d}\mathbf{x}
+ \int_{t_1}^{t_2} \! \int_{\partial\Omega} p \boldsymbol{\nu} \,
\mathrm{d}\mathbf{s} \mathrm{d}t =
\int_{\Omega} \mathbf{m}(\mathbf{x},t_1) \,
\mathrm{d}\mathbf{x} \ , \ \
\int_{\Omega} E(\mathbf{x},t_2) \, \mathrm{d}\mathbf{x} =
\int_{\Omega} E(\mathbf{x},t_1) \, \mathrm{d}\mathbf{x} \ \ \ \
\boldsymbol{(2)}


@f}

请注意，动量不是一个守恒量（与墙的相互作用导致动量的增加/减少）：然而 $\mathbf{m}$ 必须满足动量平衡。尽管我们不会在整个域中使用反射边界条件，但我们想知道我们对反射边界条件的实现与上述的守恒特性是一致的。特别是，如果我们在整个域中使用投影 $\boldsymbol{(1)}$ ，可以保证以下离散质量平衡。

@f{align*}
\sum_{i \in \mathcal{V}} m_i \rho_i^{n+1} =
\sum_{i \in \mathcal{V}} m_i \rho_i^{n} \ , \ \
\sum_{i \in \mathcal{V}} m_i \mathbf{m}_i^{n+1}
+ \tau_n \int_{\partial\Omega} \Big(\sum_{i \in \mathcal{V}} p_i^{n} \phi_i\Big)
\widehat{\boldsymbol{\nu}} \mathrm{d}\mathbf{s} =
\sum_{i \in \mathcal{V}} m_i \mathbf{m}_i^{n} \ , \ \
\sum_{i \in \mathcal{V}} m_i E_i^{n+1} = \sum_{i \in \mathcal{V}} m_i
E_i^{n} \ \ \ \
\boldsymbol{(3)}


@f}

其中 $p_i$ 是位于边界的节点上的压力。显然， $\boldsymbol{(3)}$ 是 $\boldsymbol{(2)}$ 的离散对应物。身份 $\boldsymbol{(3)}$ 的证明被省略了，但我们简要地提到，它取决于 $\boldsymbol{(1)}$ 中提供的<i>nodal normal</i> $\widehat{\boldsymbol{\nu}}_i$ 的定义。我们还注意到，这种反映边界条件的执行方式与最初在  @cite GuermondEtAl2018  中提出的方式不同。


examples/step-69/doc/results.dox

<a name="Results"></a>

<h1>Results</h1>

在释放模式下，用默认参数运行程序，在4核机器上（带超线程）大约需要1分钟。

@verbatim
# mpirun -np 4 ./step-69 | tee output
Reading parameters and allocating objects... done


    ####################################################
    #########                                  #########
    #########       create triangulation       #########
    #########                                  #########
    ####################################################


Number of active cells:       36864


    ####################################################
    #########                                  #########
    #########       compute offline data       #########
    #########                                  #########
    ####################################################


Number of degrees of freedom: 37376


    ####################################################
    #########                                  #########
    #########         set up time step         #########
    #########                                  #########
    ####################################################


    ####################################################
    #########                                  #########
    #########    interpolate initial values    #########
    #########                                  #########
    #########                                  #########
    ####################################################


TimeLoop<dim>::interpolate_initial_values(t = 0)
TimeLoop<dim>::output(t = 0, checkpoint = 0)


    ####################################################
    #########                                  #########
    #########         enter main loop          #########
    #########                                  #########
    #########                                  #########
    ####################################################


    ####################################################
    #########                                  #########
    #########      Cycle  000001  (0.0%)       #########
    #########      at time t = 0.00000000      #########
    #########                                  #########
    ####################################################


[...]


    ####################################################
    #########                                  #########
    #########     Cycle  007553  (100.0%)      #########
    #########      at time t = 3.99984036      #########
    #########                                  #########
    ####################################################


TimeLoop<dim>::output(t = 4.00038, checkpoint = 1)


+------------------------------------------------------------------------+------------+------------+
| Total CPU time elapsed since start                                     |       357s |            |
|                                                                        |            |            |
| Section                                                    | no. calls |  CPU time  | % of total |
+------------------------------------------------------------+-----------+------------+------------+
| discretization - setup                                     |         1 |     0.113s |         0% |
| offline_data - assemble lumped mass matrix, and c_ij       |         1 |     0.167s |         0% |
| offline_data - compute |c_ij|, and n_ij                    |         1 |   0.00255s |         0% |
| offline_data - create sparsity pattern and set up matrices |         1 |    0.0224s |         0% |
| offline_data - distribute dofs                             |         1 |    0.0617s |         0% |
| offline_data - fix slip boundary c_ij                      |         1 |    0.0329s |         0% |
| schlieren_postprocessor - compute schlieren plot           |       201 |     0.811s |      0.23% |
| schlieren_postprocessor - prepare scratch space            |         1 |   7.6e-05s |         0% |
| time_loop - setup scratch space                            |         1 |     0.127s |         0% |
| time_loop - stalled output                                 |       200 |  0.000685s |         0% |
| time_step - 1 compute d_ij                                 |      7553 |       240s |        67% |
| time_step - 2 compute d_ii, and tau_max                    |      7553 |      11.5s |       3.2% |
| time_step - 3 perform update                               |      7553 |       101s |        28% |
| time_step - 4 fix boundary states                          |      7553 |     0.724s |       0.2% |
| time_step - prepare scratch space                          |         1 |   0.00245s |         0% |
+------------------------------------------------------------+-----------+------------+------------+
@endverbatim



一个明显的事实是，程序花了三分之二的执行时间计算图形粘度d_ij，大约三分之一的执行时间用于执行更新，其中计算通量 $f(U)$ 是昂贵的操作。预设的默认分辨率约为37k个网格点，相当于二维空间自由度约148k。解决方案的动画斯利安图看起来如下。

 <img src="https://www.dealii.org/images/steps/developer/step-69.coarse.gif" alt="" height="300"> 

很明显，一阶方法的37k个网格点远远不能满足解决任何流动特征的需要。作为比较，这里有一个使用二阶方法和大约9.5M网格点的 "参考 "计算（<a href="https://github.com/conservation-laws/ryujin">github
project page</a>）。

 <img src="https://www.dealii.org/images/steps/developer/step-69.2nd-order.t400.jpg" alt="" height="300"> 

因此，我们给了一阶方法第二次机会，在一个小型计算服务器上用大约240万个网格点运行它。

@verbatim
# mpirun -np 16 ./step-69 | tee output


[...]


    ####################################################
    #########                                  #########
    #########     Cycle  070216  (100.0%)      #########
    #########      at time t = 3.99999231      #########
    #########                                  #########
    ####################################################


TimeLoop<dim>::output(t = 4.00006, checkpoint = 1)


[...]


+------------------------------------------------------------------------+------------+------------+
| Total wallclock time elapsed since start                               |  6.75e+03s |            |
|                                                                        |            |            |
| Section                                                    | no. calls |  wall time | % of total |
+------------------------------------------------------------+-----------+------------+------------+
| discretization - setup                                     |         1 |      1.97s |         0% |
| offline_data - assemble lumped mass matrix, and c_ij       |         1 |      1.19s |         0% |
| offline_data - compute |c_ij|, and n_ij                    |         1 |    0.0172s |         0% |
| offline_data - create sparsity pattern and set up matrices |         1 |     0.413s |         0% |
| offline_data - distribute dofs                             |         1 |      1.05s |         0% |
| offline_data - fix slip boundary c_ij                      |         1 |     0.252s |         0% |
| schlieren_postprocessor - compute schlieren plot           |       201 |      1.82s |         0% |
| schlieren_postprocessor - prepare scratch space            |         1 |  0.000497s |         0% |
| time_loop - setup scratch space                            |         1 |      1.45s |         0% |
| time_loop - stalled output                                 |       200 |   0.00342s |         0% |
| time_step - 1 compute d_ij                                 |     70216 |  4.38e+03s |        65% |
| time_step - 2 compute d_ii, and tau_max                    |     70216 |       419s |       6.2% |
| time_step - 3 perform update                               |     70216 |  1.87e+03s |        28% |
| time_step - 4 fix boundary states                          |     70216 |        24s |      0.36% |
| time_step - prepare scratch space                          |         1 |    0.0227s |         0% |
+------------------------------------------------------------+-----------+------------+------------+
@endverbatim



并有以下结果。

 <img src="https://www.dealii.org/images/steps/developer/step-69.fine.gif" alt="" height="300"> 

这大大改善了，当然代价是在16个核心上运行了大约2小时的代码。




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

如上所述，这里展示的程序实际上只是一阶精确。上面的图片说明了这引入了多少扩散，以及该解决方案离真正解决我们所关心的特征还有多远。

这一点是可以解决的，但这将超出一个*教程*的内容。尽管如此，还是值得展示一下通过添加二阶方案可以实现的效果。例如，这里有一段用<a
href=https://conservation-laws.43-1.org/>the following research code</a>计算的视频，显示了（用不同的颜色方案）对应于上述情况的2d模拟。

@htmlonly
<p align="center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/xIwJZlsXpZ4"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly



这个模拟是用解矢量的每个分量3800万个自由度（连续 $Q_1$ 有限元素）完成的。对于这类模拟来说，解决方案的精致细节是显著的，包括在障碍物后面的亚声速区域。

人们还可以相对容易地进一步将其扩展到三维案例。

@htmlonly
<p align="center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/vBCRAF_c8m8"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly



然而，解决这个问题变得很昂贵。仿真是以每个部件18.17亿个自由度（连续 $Q_1$ 有限元）进行的（总共90.9亿个空间自由度），在30,720个MPI等级上运行。该代码达到了平均每秒969万个网格点的吞吐量（每个CPU每秒0.04万个网格点）。前面和后面的墙显示了一个 "Schlieren图"：密度的梯度大小在一个从白色（低）到黑色（高）的指数级上。所有其他切面和障碍物表面都显示了白色（低）-黄色（中）-红色（高）尺度上的涡度大小。各个切割面的比例已经被调整，以获得更好的视觉效果）。


examples/step-7/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

在这个程序中，我们将主要考虑两个方面。<ol>  <li>  验证程序的正确性和生成收敛表；  <li>  亥姆霍兹方程的非均质诺伊曼边界条件。   </ol>  除了这些主题，还将再次展示各种改进和技巧。




<h3>Verification of correctness</h3>

可能从来没有一个非琐碎的有限元程序从一开始就能正常工作。因此有必要找到方法来验证计算出的解是否正确。通常，这是通过选择模拟的设置来完成的，我们知道准确的连续解，并评估连续解和计算的离散解之间的差异。如果这个差值以正确的收敛顺序收敛为零，这已经是正确性的一个很好的指示，尽管可能还有其他的误差源持续存在，而这些误差对总误差的贡献很小，或者是更高阶的。在有限元模拟的背景下，这种通过选择适当的右手边和边界条件来选择解决方案的技术通常被称为<i>Method of Manufactured Solution</i>。

在这个例子中，我们不会去研究系统性软件验证的理论，这是一个非常复杂的问题。相反，我们将展示deal.II在这方面所能提供的工具。这基本上是围绕着一个单一的函数的功能， VectorTools::integrate_difference(). 这个函数计算一个给定的连续函数和每个单元上不同规范的有限元场之间的差值。当然，像其他积分一样，我们只能用正交公式来评估这些规范；因此，选择正确的正交公式对准确评估误差至关重要。这一点对于 $L_\infty$ 规范尤其成立，我们只在正交点评估数值和精确解的最大偏差；那么就不应该尝试使用正交规则，其评估只发生在[超级收敛](https://en.wikipedia.org/wiki/Superconvergence)可能发生的点上，例如最低阶高斯正交公式的高斯点，对于该矩阵的装配中的积分是正确的（例如，对于线性元素，不要使用QGauss（2）正交公式）。事实上，这通常也是对其他规范的好建议：如果你的正交点偶然选择在由于超收敛而恰好误差特别小的位置，那么计算出来的误差看起来会比实际情况小得多，甚至可能表明收敛阶数更高。因此，我们将为这些误差准则的积分选择不同的正交公式，而不是线性系统的装配。

函数 VectorTools::integrate_difference() 对三角形的每个单元 $K$ 进行所需规范的评估，并返回一个持有每个单元的这些值的向量。从局部值中，我们可以得到全局误差。例如，如果所有单元 $K$ 的元素为 $e_K$ 的向量 $\mathbf e$ 包含本地 $L_2$ 规范 $\|u-u_h\|_K$ ，那么

@f[
  E = \| {\mathbf e} \| = \left( \sum_K e_K^2 \right)^{1/2}


@f]

是全球  $L_2$  误差  $E=\|u-u_h\|_\Omega$  。

在程序中，我们将展示如何评估和使用这些量，并且我们将监测它们在网格细化下的值。当然，我们必须选择手头的问题，使我们能够明确地说明解决方案及其导数，但由于我们要评估程序的正确性，这才是合理的。如果我们知道程序对一个（或者，如果想真正确定：许多）特别选择的右手边产生了正确的解决方案，我们可以相当有信心，它也将计算出我们不知道确切数值的问题的正确解决方案。

除了简单地计算这些数量之外，我们将展示如何从这个程序产生的数据中生成格式良好的表格，自动计算收敛率等。此外，我们还将比较不同的网格细化策略。




<h3>Non-homogeneous Neumann boundary conditions</h3>

本例程序的第二个完全不相关的主题是使用非均质边界条件。这些条件包括在使用边界积分的变异形式中，我们必须在组装右手边的矢量时进行数值评估。

在我们进入编程之前，让我们简单看看数学公式。我们在这里要解决的方程是亥姆霍兹方程，"带有漂亮的符号"。

@f[


  -\Delta u + \alpha u = f,


@f]

在 $[-1,1]^2$ 与 $\alpha=1$ 的正方形上，用迪里希特边界条件来增强。

@f[
  u = g_1


@f]

在边界 $\Gamma_1$ 的某些部分 $\Gamma$ ，以及诺伊曼条件

@f[
  {\mathbf n}\cdot \nabla u = g_2


@f]

对其余的 $\Gamma_2 = \Gamma \backslash \Gamma_1$ 。在我们特定的测试案例中，我们将使用 $\Gamma_1=\Gamma \cap\{\{x=1\}
\cup \{y=1\}\}$  。 我们说这个方程有 "漂亮的符号"，因为算子 $-\Delta + \alpha I$ 与身份 $I$ 和 $\alpha>0$ 是一个正定算子；<a
href="https://en.wikipedia.org/wiki/Helmholtz_equation">equation with
the "bad sign"</a>是 $-\Delta u - \alpha u$ ，由时间谐波过程建模产生。如果 $\alpha>0$ 很大的话，该算子就不是正定的，这就导致了我们在这里不需要讨论的各种问题。如果 $\alpha$ 恰好是 $-\Delta$ 的特征值之一，那么算子也可能不是可逆的--即方程没有唯一的解--)

因为我们想验证我们的数字解  $u_h$  的收敛性，我们想要一个设置，以便我们知道精确的解  $u$  。这就是 "人造解法 "的作用。为此，让我们选择一个函数

@f[
  \bar u(x) = \sum_{i=1}^3 \exp\left(-\frac{|x-x_i|^2}{\sigma^2}\right)


@f]

其中指数的中心 $x_i$ 为 $x_1=(-\frac 12,\frac 12)$ ， $x_2=(-\frac 12,-\frac 12)$ ，和 $x_3=(\frac 12,-\frac 12)$ ，半宽设为 $\sigma=\frac {1}{8}$ 。然后，制造解的方法说：选择

@f{align*}
  f &= -\Delta \bar u + \bar u, \\
  g_1 &= \bar u|_{\Gamma_1}, \\
  g_2 &= {\mathbf n}\cdot \nabla\bar u|_{\Gamma_2}.


@f}

有了这个特殊的选择，我们就可以推断出原始问题的解恰好是 $u=\bar u$  。换句话说，通过以特定的方式选择方程的右边和边界条件，我们已经为自己制造了一个我们知道其解决方案的问题。这使我们能够计算出我们的数字解决方案的误差。在下面的代码中，我们用 <code>Solution</code> 类来表示 $\bar u$ ，其他类将用于表示 $\bar u|_{\Gamma_1}=g_1$ 和 ${\mathbf n}\cdot \nabla\bar u|_{\Gamma_2}=g_2$  。

利用上述定义，我们可以陈述方程的弱表述，即：找到 $u\in H^1_g=\{v\in H^1: v|_{\Gamma_1}=g_1\}$ ，以便

@f[
  {(\nabla v, \nabla u)}_\Omega + {(v,u)}_\Omega
  =
  {(v,f)}_\Omega + {(v,g_2)}_{\Gamma_2}


@f]

为所有测试函数  $v\in H^1_0=\{v\in H^1: v|_{\Gamma_1}=0\}$  。边界项 ${(v,g_2)}_{\Gamma_2}$ 是通过部分积分和使用 $\partial_n u=g_2$ 对 $\Gamma_2$ 和 $v=0$ 的方式出现的。因此，在离散公式中，我们用来建立全局矩阵和右侧向量的单元矩阵和向量看起来是这样的。

@f{eqnarray*}
  A_{ij}^K &=& \left(\nabla \varphi_i, \nabla \varphi_j\right)_K
              +\left(\varphi_i, \varphi_j\right)_K,
  \\
  F_i^K &=& \left(\varphi_i, f\right)_K
           +\left(\varphi_i, g_2\right)_{\partial K\cap \Gamma_2}.


@f}

由于域积分的生成已经在前面的例子中多次展示过，这里只对轮廓积分的生成感兴趣。它的工作原理如下：对于域积分，我们有一个 <code>FEValues</code> 类，它提供了形状值和梯度，以及雅各布行列式和其他信息，并指定了单元格中的正交点；同样，还有一个 <code>FEFaceValues</code> 类，为单元格面上的积分执行这些任务。我们向它提供一个流形的正交公式，该流形的维数比域的维数少一，以及我们想在其上进行积分的单元格和其面的数量。然后，该类将计算该面的正交点的值、梯度、法向量、权重等，然后我们可以以与域积分相同的方式使用这些值。下面的程序显示了这样做的细节。




<h3>A note on good programming practice</h3>

除了上面概述的数学主题外，我们还想用这个程序来说明良好编程实践的一个方面，即命名空间的使用。在为deal.II库编程时，我们非常注意不要为类和全局函数使用过于通用的名称，例如 <code>f(), sz(), rhs()</code> 等。此外，我们把所有的东西都放到了名字空间  <code>dealii</code>  中。但当一个人写的应用程序不是为了给别人使用时，就不一定会注意这么多。如果你遵循步骤1到步骤6的编程风格，这些函数就会最终进入全局命名空间，不幸的是，很多其他的东西也在那里（基本上是C语言提供的所有东西，以及你通过头文件从操作系统得到的所有东西）。更糟糕的是，C语言的设计者在避免使用通用名称方面也不总是很小心；例如，符号<code>j1, jn</code>在C头文件中被定义（它们表示贝塞尔函数）。

为了避免不同函数或变量的名称相撞时产生的问题（经常出现混乱的错误信息），把你所做的一切放到<a
href="http://en.wikipedia.org/wiki/Namespace_(computer_science)">namespace</a>中是一个好的做法。按照这种风格，我们将在程序的顶部打开一个名字空间 <code>Step7</code> ，将deal.II名字空间导入其中，将本程序特有的一切（除了 <code>main()</code> ，它必须在全局名字空间中）放入其中，并且只在文件的底部关闭它。换句话说，这个程序的结构是这样的

@code
  #includes ...


  namespace Step7
  {
    using namespace dealii;


    ...everything to do with the program...
  }


  int main ()
  {
    ...do whatever main() does...
  }
@endcode

我们将在整个交易.II教程的剩余部分遵循这一方案。


examples/step-7/doc/results.dox



<h1>Results</h1>


该程序产生了两种输出。第一种是输出文件  <code>solution-adaptive-q1.vtk</code>  ,  <code>solution-global-q1.vtk</code>  , 和  <code>solution-global-q2.vtk</code>  。我们在此展示后者的三维视图。


 <img src="https://www.dealii.org/images/steps/developer/step-7.solution.png" alt=""> 





其次，该程序不仅将表格写入磁盘，而且在运行时也写入屏幕。输出结果如下（记得标为" <code>H1</code> "的列实际上显示的是错误的 $H^1$ <i>semi-</i>规范，而不是完整的 $H^1$ 规范）。




@code
examples/\step-7> make run
Solving with Q1 elements, adaptive refinement
=============================================


Cycle 0:
   Number of active cells:       64
   Number of degrees of freedom: 81
Cycle 1:
   Number of active cells:       124
   Number of degrees of freedom: 157
Cycle 2:
   Number of active cells:       280
   Number of degrees of freedom: 341
Cycle 3:
   Number of active cells:       577
   Number of degrees of freedom: 690
Cycle 4:
   Number of active cells:       1099
   Number of degrees of freedom: 1264
Cycle 5:
   Number of active cells:       2191
   Number of degrees of freedom: 2452
Cycle 6:
   Number of active cells:       4165
   Number of degrees of freedom: 4510
Cycle 7:
   Number of active cells:       7915
   Number of degrees of freedom: 8440
Cycle 8:
   Number of active cells:       15196
   Number of degrees of freedom: 15912


cycle cells dofs     L2        H1      Linfty
    0    64    81 1.840e+00 2.858e+00 1.835e+00
    1   124   157 5.190e-02 1.200e+00 1.344e-01
    2   280   341 1.439e-02 7.892e-01 7.554e-02
    3   577   690 8.627e-03 5.061e-01 2.805e-02
    4  1099  1264 3.217e-03 3.030e-01 1.073e-02
    5  2191  2452 1.445e-03 2.097e-01 5.073e-03
    6  4165  4510 8.387e-04 1.460e-01 2.013e-03
    7  7915  8440 7.051e-04 1.053e-01 1.804e-03
    8 15196 15912 2.774e-04 7.463e-02 6.911e-04


Solving with Q1 elements, global refinement
===========================================


Cycle 0:
   Number of active cells:       64
   Number of degrees of freedom: 81
Cycle 1:
   Number of active cells:       256
   Number of degrees of freedom: 289
Cycle 2:
   Number of active cells:       1024
   Number of degrees of freedom: 1089
Cycle 3:
   Number of active cells:       4096
   Number of degrees of freedom: 4225
Cycle 4:
   Number of active cells:       16384
   Number of degrees of freedom: 16641


cycle cells dofs     L2        H1      Linfty
    0    64    81 1.840e+00 2.858e+00 1.835e+00
    1   256   289 3.570e-02 1.199e+00 1.307e-01
    2  1024  1089 1.192e-02 7.565e-01 7.168e-02
    3  4096  4225 3.047e-03 3.823e-01 2.128e-02
    4 16384 16641 7.660e-04 1.917e-01 5.554e-03


n cells         H1                   L2
0    64 2.858e+00    -    - 1.840e+00     -    -
1   256 1.199e+00 2.38 1.25 3.570e-02 51.54 5.69
2  1024 7.565e-01 1.58 0.66 1.192e-02  2.99 1.58
3  4096 3.823e-01 1.98 0.98 3.047e-03  3.91 1.97
4 16384 1.917e-01 1.99 1.00 7.660e-04  3.98 1.99


Solving with Q2 elements, global refinement
===========================================


Cycle 0:
   Number of active cells:       64
   Number of degrees of freedom: 289
Cycle 1:
   Number of active cells:       256
   Number of degrees of freedom: 1089
Cycle 2:
   Number of active cells:       1024
   Number of degrees of freedom: 4225
Cycle 3:
   Number of active cells:       4096
   Number of degrees of freedom: 16641
Cycle 4:
   Number of active cells:       16384
   Number of degrees of freedom: 66049


cycle cells dofs     L2        H1      Linfty
    0    64   289 1.606e-01 1.278e+00 3.029e-01
    1   256  1089 7.638e-03 5.248e-01 4.816e-02
    2  1024  4225 8.601e-04 1.086e-01 4.827e-03
    3  4096 16641 1.107e-04 2.756e-02 7.802e-04
    4 16384 66049 1.393e-05 6.915e-03 9.971e-05


n cells         H1                   L2
0    64 1.278e+00    -    - 1.606e-01     -    -
1   256 5.248e-01 2.43 1.28 7.638e-03 21.03 4.39
2  1024 1.086e-01 4.83 2.27 8.601e-04  8.88 3.15
3  4096 2.756e-02 3.94 1.98 1.107e-04  7.77 2.96
4 16384 6.915e-03 3.99 1.99 1.393e-05  7.94 2.99


Solving with Q2 elements, adaptive refinement
===========================================


Cycle 0:
   Number of active cells:       64
   Number of degrees of freedom: 289
Cycle 1:
   Number of active cells:       124
   Number of degrees of freedom: 577
Cycle 2:
   Number of active cells:       289
   Number of degrees of freedom: 1353
Cycle 3:
   Number of active cells:       547
   Number of degrees of freedom: 2531
Cycle 4:
   Number of active cells:       1057
   Number of degrees of freedom: 4919
Cycle 5:
   Number of active cells:       2059
   Number of degrees of freedom: 9223
Cycle 6:
   Number of active cells:       3913
   Number of degrees of freedom: 17887
Cycle 7:
   Number of active cells:       7441
   Number of degrees of freedom: 33807
Cycle 8:
   Number of active cells:       14212
   Number of degrees of freedom: 64731


cycle cells dofs     L2        H1      Linfty
    0    64   289 1.606e-01 1.278e+00 3.029e-01
    1   124   577 7.891e-03 5.256e-01 4.852e-02
    2   289  1353 1.070e-03 1.155e-01 4.868e-03
    3   547  2531 5.962e-04 5.101e-02 1.876e-03
    4  1057  4919 1.977e-04 3.094e-02 7.923e-04
    5  2059  9223 7.738e-05 1.974e-02 7.270e-04
    6  3913 17887 2.925e-05 8.772e-03 1.463e-04
    7  7441 33807 1.024e-05 4.121e-03 8.567e-05
    8 14212 64731 3.761e-06 2.108e-03 2.167e-05
@endcode




我们可以看到网格细化后的误差减少，对于进行全局细化的情况，也可以看到收敛率。可以清楚地看到Q1和Q2元素在 $H^1$ 半规范下的线性和二次收敛率，以及 $L_2$ 规范下的二次和三次收敛率。





最后，该程序还生成了LaTeX版本的表格（此处未显示），这些表格被写入一个文件中，以便可以复制粘贴到LaTeX文件中。




<h4> When is the error "small"? </h4>

我们上面展示的是如何在一些不同的规范中确定误差 $\|u-u_h\|$ 的大小。我们这样做主要是因为我们对测试我们的解决方案是否*融合感兴趣。但是从工程的角度来看，这个问题往往更实际：我的网格要做得多细才能使误差 "足够小"？换句话说，如果在上表中， $H^1$ 的半规范已经减少到`4.121e-03`，这是否足以让我在蓝图上签字，宣布我们的数值模拟显示桥梁足够坚固？

在实践中，我们很少遇到这种情况，因为我通常不能在重要的情况下将数值解 $u_h$ 与精确解 $u$ 进行比较--如果我知道 $u$ ，我就不必计算 $u_h$  。但即使我可以，一般情况下要问的问题是。`4.121e-03`是什么？解决方案将有物理单位，例如公斤-米-平方，我在域上积分一个单位为上述平方的函数，然后取其平方根。因此，如果域是二维的， $\|u-u_h\|_{L_2}$ 的单位是公斤-米-立方。那么问题来了。 $4.121\times 10^{-3}$ 的单位是kg-times-mubed小吗？这取决于你要模拟的是什么。如果你是一个天文学家，习惯于以太阳质量为单位的质量和以光年为单位的距离，那么是的，这是一个小得惊人的数字。但是如果你是做原子物理的，那就不是：这并不小，而且你的误差肯定也不够小；你需要一个更细的网格。

换句话说，当我们看这些数字的时候，我们通常需要与一个 "尺度 "进行比较。做到这一点的一个方法是，不看任何规范中的*绝对*误差 $\|u-u_h\|$ ，而是看*相对*误差 $\|u-u_h\|/\|u\|$  。如果这个比率是 $10^{-5}$ ，那么你就知道，*平均而言， $u$ 和 $u_h$ 之间的差异是0.001%--对于工程而言可能足够小。

我们如何计算 $\|u\|$ ？我们只需要在所有的单元格上做一个积分循环，在这些单元格上做正交点，然后把东西加起来，最后取平方根。但有一个更简单的方法经常使用。你可以调用

@code
    Vector<double> zero_vector (dof_handler.n_dofs());
    Vector<float> norm_per_cell(triangulation.n_active_cells());
    VectorTools::integrate_difference(dof_handler,
                                      zero_vector,
                                      Solution<dim>(),
                                      norm_per_cell,
                                      QGauss<dim>(fe->degree + 1),
                                      VectorTools::L2_norm);
@endcode

来计算  $\|u-0\|_{L_2}$  。另外，如果你特别懒，不喜欢创建`零_向量'，你可以使用，如果网格不是太粗，那么 $\|u\| \approx \|u_h\|$  ，我们可以通过调用 $\|u\| \approx \|u_h\|=\|0-u_h\|$ 来计算。

@code
    Vector<float> norm_per_cell(triangulation.n_active_cells());
    VectorTools::integrate_difference(dof_handler,
                                      solution,
                                      ZeroFunction<dim>(),
                                      norm_per_cell,
                                      QGauss<dim>(fe->degree + 1),
                                      VectorTools::L2_norm);
@endcode

在这两种情况下，我们只需要像在程序中一样，通过调用以下命令将单元格准则的向量合并为一个全局准则

@code
    const double L2_norm =
      VectorTools::compute_global_error(triangulation,
                                        norm_per_cell,
                                        VectorTools::L2_norm);
@endcode






<h3> Possibilities for extensions </h3>

<h4> Higher Order Elements </h4>

继续运行具有高阶元素的程序（ $Q_3$  ,  $Q_4$  , ...）。你会注意到，代码的几个部分的断言将被触发（例如，在为数据输出生成文件名时）。你可能必须解决这些问题，但要使程序正常工作应该不是很难

<h4> Convergence Comparison </h4>

Q1或Q2更好吗？自适应细化与全局细化又如何呢？比较它们的一个（有些不公平，但很典型）指标是看误差与未知数的关系。

要看到这一点，以对数风格创建一个图，未知数在 $x$ 轴上， $L_2$ 误差在 $y$ 轴上。你可以为 $h^2=N^{-1}$ 和 $h^3=N^{-3/2}$ 添加参考线，并检查全局和适应性细化是否遵循这些。如果我们做一个（并非完全不合理的）假设，即对于一个好的线性求解器，计算工作量与未知数 $N$ 成正比，那么很明显， ${\cal O}(N^{-3/2})$ 的误差减少比 ${\cal O}(N^{-1})$ 形式的减少要好得多：也就是说，与使用全局细化相比，自适应细化以更少的计算工作量给我们带来了期望的误差等级。这并不是一个特别令人惊讶的结论，但是值得在实践中检查这类假设。

当然，更公平的比较是在 $x$ 轴上绘制运行时间（先切换到发布模式！）而不是未知数的数量。如果你通过对每个细化步骤进行计时（例如，使用Timer类）来绘制运行时间与未知数数量的关系，你会发现线性求解器并不完美--其运行时间的增长速度超过了与线性系统大小成正比的速度--挑选一个更好的线性求解器可能适合这种比较。


examples/step-70/doc/intro.dox

 <br> 

<i>This program was contributed by Luca Heltai (International School for
Advanced Studies, Trieste), Bruno Blais (Polytechnique Montréal),
and Rene Gassmöller (University of California Davis)
</i>

 @dealiiTutorialDOI{10.5281/zenodo.3829064,https://zenodo.org/badge/DOI/10.5281/zenodo.3829064.svg} 




<h1>Introduction</h1>

<h3>Massively parallel non-matching grid simulations of fluid structure interaction problems</h3>

在本教程中，我们考虑了层流体系中的混合问题。这类问题出现在从化学工程到发电（如涡轮机械）等广泛的应用中。混合问题特别难以用数值来解决，因为它们通常涉及一个容器（有固定的边界，可能还有复杂的几何形状，如挡板），由域 $\Omega$ 表示，和一个（或多个）浸入和旋转的叶轮（由域 $\Omega^{\text{imp}}$ 表示）。我们希望解决流动方程的域是两个域之间的（与时间有关的）差值，即。   $\Omega\setminus\Omega^{\text{imp}}$  .

对于旋转叶轮，使用任意拉格朗日欧拉公式（其中流体域--连同网格！）是不可能的，除非只考虑小时间（即小的流体域变形）。-- 是不可能的，除非只考虑小时间（即小的流域变形）。如果想跟踪叶轮多次旋转时的流动演变，所产生的变形网格就会过于扭曲而无用。

在这种情况下，一个可行的替代策略是使用非匹配方法（类似于我们在step-60中所做的），其中一个背景固定网格（可能在时间上进行局部细化以更好地捕捉实体运动）与一个旋转的、独立的网格相耦合。

为了保持步骤60中使用的相同符号，我们使用 $\Omega$ 来表示 ${\mathbb R}^{\text{spacedim}}$ 中的域，代表流体和叶轮的容器，我们使用 $\Gamma$ 在 ${\mathbb R}^{\text{dim}}$ 来表示整个叶轮（当它的`spacedim`度量非负值时，也就是说，当我们可以把它表示为维数`dim`等于`spacedim`的网格时），薄叶轮的同维度表示，或者只是整个叶轮的边界。

域 $\Gamma$ 被嵌入到 $\Omega$ （ $\Gamma \subseteq \Omega$ ）中，它是不匹配的：一般来说，它不与任何体积网格的特征对齐。我们在 $\Omega$ 上求解一个偏微分方程，通过一些惩罚技术在嵌入域 $\Gamma$ 上强制执行一些问题的解决条件。在当前情况下，条件是流体在 $\Gamma$ 上各点的速度等于固体叶轮在该点的速度。

我们在此描述的技术在文献中使用了许多名称之一：<b>immersed finite element method</b>和<b>fictitious boundary
method</b>等。  其主要原理是两个网格的离散化保持完全独立。在本教程中，这种方法被用来求解由斯托克斯方程描述的粘性流体的运动，该流体被一个刚性的非变形叶轮搅动。

因此， $\Omega$ 中求解的方程是蠕动流的斯托克斯方程（即 $\text{Re}\rightarrow 0$ ），并且在与叶轮相关的移动*嵌入域* $\Gamma$ 上应用无滑动边界条件。然而，这个教程可以很容易地扩展到其他方程（例如，纳维-斯托克斯方程、线性弹性方程等）。它可以被看作是Step-60的一个自然扩展，它可以通过MPI使用分布式并行计算架构解决大型问题。

然而，与第60步相反， $\Gamma$ 上的迪里希特边界条件是弱加的，而不是通过使用拉格朗日乘法器，而且我们集中处理两个完全分布的三角形的耦合（这种组合在第60步的实施中是不可能的）。

当人们想在嵌入域上执行条件时，有两种有趣的情况发生  $\Gamma$  。

- 嵌入域 $\Gamma$ 的几何维度`dim`与域 $\Omega$ 相同（`spacedim`），也就是说， $\Gamma$ 的spacedim-维度不为零。在这种情况下，对 $\Gamma$ 施加Dirichlet边界的边界条件是通过体积惩罚完成的。如果施加的惩罚只取决于速度，这通常被称为 $\mathcal{L}^2$ 惩罚，而如果惩罚同时取决于速度及其梯度，则是 $\mathcal{H}^1$ 惩罚。 $\mathcal{L}^2$  惩罚的情况与Darcy型方法非常相似。对 $\mathcal{L}^2$ 和 $\mathcal{H}^1$ 两种惩罚方法都进行了广泛的分析（例如，见 @cite Angot1999 ）。

- 嵌入域 $\Gamma$ 的内在维度`dim`小于 $\Omega$ 的维度（`spacedim`），因此其spacedim维度为零；例如，它是一条嵌入二维域的曲线，或一个嵌入三维域的表面。当然，这在物理上是不可能的，但是如果金属片的厚度可以忽略不计的话，我们可以把在流体中运动的非常薄的金属片视为本质上的低维。在这种情况下，通过应用<a href="https://en.wikipedia.org/wiki/Joachim_Nitsche">Nitsche</a>方法（见 @cite Freund1995 ）对 $\Gamma$ 施加弱边界条件。

这两种方法都有非常相似的要求，并导致高度相似的公式。因此，我们几乎以同样的方式对待它们。

在本教程中，我们对 $\Gamma$ 的进一步细节不感兴趣：我们假设嵌入域的尺寸（`dim`）总是比嵌入域的尺寸 $\Omega$ （`spacedim`）小一或相等。

我们要解决以下微分问题：给定 $g$ 上的一个足够规则的函数 $\Gamma$ ，找到 $(\textbf{u},p)$ 的解。

@f{eqnarray*}


  -\Delta \mathbf{u} + \nabla p &=& 0,\\


  -\nabla \cdot \textbf{u} &=& 0,\\
  \textbf{u} &=& \textbf{g}  \text{ in } \Gamma,\\
  \textbf{u} &=& 0 \text{ on } \partial\Omega.


@f}



这个方程，我们通过缩放时间单位的方式将其规范化，使粘度的数值为1，描述了缓慢的粘性流动，如蜂蜜或岩浆。本教程的主要目的是展示如何用惩罚方法，以弱的方式将速度场条件 $\mathbf{u} = \mathbf{g}$ 强加于非匹配的 $\Gamma$ 。关于斯托克斯问题的更广泛的讨论，包括体力、不同的边界条件和解决策略，可以在步骤22中找到。

让我们开始单独考虑整个域 $\Omega$ 中的斯托克斯问题。我们寻找一个速度场 $\mathbf{u}$ 和一个压力场 $p$ ，满足斯托克斯方程和 $\partial\Omega$ 上的同质边界条件。

斯托克斯方程的微弱形式首先通过将其写成矢量形式而得到

@f{eqnarray*}
  \begin{pmatrix}
    {-\Delta \textbf{u} + \nabla p}
    \\
    {-\textrm{div}\;\textbf{u}}
  \end{pmatrix}
  =
  \begin{pmatrix}
  0
  \\
  0
  \end{pmatrix},


@f}

从左边开始与一个矢量值测试函数 $\phi = \begin{pmatrix}\textbf{v} \\ q\end{pmatrix}$ 形成点积，并在域 $\Omega$ 上进行积分，得到以下一组方程。

@f{eqnarray*}
  (\mathrm v,


   -\Delta \textbf{u} + \nabla p)_{\Omega}


  -
  (q,\textrm{div}\; \textbf{u})_{\Omega}
  =
  0


@f}

这对所有的测试函数都必须成立  $\phi = \begin{pmatrix}\textbf{v}
\\ q\end{pmatrix}$  。


通过部分积分并利用 $\partial\Omega$ 的边界条件，我们得到以下变分问题。

@f{eqnarray*}{
(\nabla \textbf{v}, \nabla \textbf{u})_{\Omega} - (\textrm{div}\; \textbf{v}, p)_{\Omega}


 - (q, \textrm{div}\; \textbf{u})_{\Omega}&=& 0


@f}



其中 $(\cdot, \cdot)_{\Omega}$ 代表 $L^2$ 标量积。这也是步骤22中使用的变异形式。

这个变分公式没有考虑到嵌入域。与step-60相反，我们并不强行执行 $\textbf{u}$ 对 $\Gamma$ 的约束，而是通过惩罚项弱行执行这些约束。

对这种弱强加边界条件的分析取决于 $\Gamma$ 的spacedim-dimensional度量是正的（如果`dim`等于`spacedim`）或零（如果`dim`小于`spacedim`）。我们讨论这两种情况。




<h4>Co-dimension one case</h4>

在这种情况下，我们假设 $\Gamma$ 是实际叶轮的边界，即嵌入二维域的封闭曲线或三维域的封闭表面。这种方法的思路首先是考虑在 $\Gamma$ 上弱加迪里切特边界条件，遵循尼采方法。这是通过在流体域上使用以下修改后的公式来实现的，其中没有对 $\Gamma$ 上的测试函数施加强条件。

@f{multline*}{
(\nabla \textbf{v}, \nabla \textbf{u})_{\Omega\setminus\Omega^{\text{imp}}} - (\textrm{div}\;  \textbf{v}, p)_{\Omega\setminus\Omega^{\text{imp}}}


  - (q, \textrm{div}\; \textbf{u})_{\Omega\setminus\Omega^{\text{imp}}} \\


  - (\textbf{v},\nabla \textbf{u} \cdot \textbf{n})_{\Gamma}
  + (\textbf{v}\cdot \textbf{n},p)_{\Gamma} \\


 -  (\nabla\textbf{v}\cdot \textbf{n},\textbf{u})_{\Gamma}
 + (q, \textbf{u} \cdot \textbf{n})_{\Gamma}
 + \beta (\textbf{v},\textbf{u})_{\Gamma} \\
=  - (\nabla\textbf{v}\cdot \textbf{n},\textbf{g})_{\Gamma} + (q, \textbf{g} \cdot \textbf{n})_{\Gamma}
 + \beta (\textbf{v},\textbf{g})_{\Gamma}.


@f}



过 $\Gamma$ 的积分是低维积分。可以证明（见 @cite Freund1995 ），存在一个正的常数 $C_1$ ，所以如果 $\beta > C_1$ ，边界的弱强加将是一致和稳定的。在 $\Gamma$ 上的前两个附加积分（上式中的第二行）在通过部分积分后自然出现，此时我们不假设 $\mathbf{v}$ 在 $\Gamma$ 上是零。

上述方程中的第三行包含两个项，是为了确保弱形式的一致性而添加的，还有一个稳定项，是为了强制执行边界条件，其误差与近似误差一致。一致性项和稳定项是用实际的边界数据添加到右手边的  $\mathbf{g}$  。

当 $\mathbf{u}$ 满足 $\Gamma$ 上的条件 $\mathbf{u}=\mathbf{g}$ 时， $\Gamma$ 上的所有一致性和稳定性积分都被抵消，就剩下斯托克斯流的通常弱形式，也就是说，上述表述是一致的。

我们注意到，可以使用另一种（非对称的）表述方式。

@f{multline*}{
(\nabla \textbf{v}, \nabla \textbf{u})_{\Omega\setminus\Omega^{\text{imp}}} -  (\textrm{div}\;  \textbf{v}, p)_{\Omega\setminus\Omega^{\text{imp}}}


  - (q, \textrm{div}\; \textbf{u})_{\Omega\setminus\Omega^{\text{imp}}} \\


  -(\textbf{v},\nabla \textbf{u} \cdot \textbf{n})_{\Gamma}
  + (\textbf{v}\cdot \textbf{n},p)_{\Gamma} \\
   +(\nabla\textbf{v}\cdot \textbf{n},\textbf{u})_{\Gamma}


 - (q, \textbf{u} \cdot \textbf{n})_{\Gamma}
 + \beta (\textbf{v},\textbf{u})_{\Gamma} \\
=   (\nabla\textbf{v}\cdot \textbf{n},\textbf{g})_{\Gamma} - (q, \textbf{g} \cdot \textbf{n})_{\Gamma}
 + \beta (\textbf{v},\textbf{g})_{\Gamma}.


@f}

注意第三行和第四行的第一项的不同符号。在这种情况下，稳定性和一致性条件成为 $\beta > 0$  。在对称情况下， $\beta$ 的值取决于 $h$ ，一般来说，它被选择为 $\beta = C h^{-1} $ ， $h$ 是衡量被整合面的大小， $C$ 是一个常数，以便 $1 \leq C \leq 10$  。这就像人们通常使用Nitsche惩罚方法来执行Dirichlet边界条件一样。

另一方面，非对称方法与非连续Galerkin方法的非对称内部惩罚方法（"NIPG "方法 @cite Riviere1999 ）的连续性的执行方式有关。即使非对称情况在稳定参数的可能选择方面似乎更有优势，我们还是选择了对称离散化，因为在这种情况下，可以证明对偶问题也是一致的，导致解决方案不仅能量准则以正确的顺序收敛，而且其 $L^2$ 准则也是如此。此外，得到的矩阵仍然是对称的。

上述表述是在假设领域被精确离散的情况下进行的。然而，如果叶轮的变形是一个刚体运动，就有可能人为地将斯托克斯问题的解扩展到螺旋桨本身，因为刚体运动也是斯托克斯问题的解。我们的想法是在 $\Omega^{\text{imp}}$ 内解决同样的问题，在 $\Gamma$ 上施加同样的边界条件，使用同样的惩罚技术，并用在 $\Omega$ 上全局连续的测试函数 $\mathbf{v}$ 来测试。

这导致了以下（中间）配方。

@f{multline*}{
(\nabla \textbf{v}, \nabla \textbf{u})_{\Omega} - (\textrm{div}\;  \textbf{v}, p)_{\Omega}


  - (q, \textrm{div}\; \textbf{u})_{\Omega} \\


  - (\textbf{v},  \lbrack \nabla \textbf{u} \rbrack \cdot \textbf{n})_{\Gamma}
  + (\textbf{v}\cdot \textbf{n},\lbrack p \rbrack )_{\Gamma} \\


 -  (\lbrack \nabla\textbf{v} \rbrack \cdot \textbf{n},\textbf{u})_{\Gamma}
 + (\lbrack q \rbrack, \textbf{u} \cdot n)_{\Gamma}
 + 2\beta (\textbf{v},\textbf{u})_{\Gamma} \\
=  - (\lbrack \nabla\textbf{v}\rbrack\cdot \textbf{n},\textbf{g})_{\Gamma} + (\lbrack q\rbrack, \textbf{g} \cdot n)_{\Gamma}
 + 2\beta (\textbf{v},\textbf{g})_{\Gamma},


@f}

其中跳跃项，用 $\lbrack \cdot \rbrack$ 表示，是相对于法向量 $\textbf{n}$ 的一个固定方向计算的。2的因子出现在 $\beta$ 前面，因为我们看到 $\Gamma$ 的每一部分两次，一次来自流体内部，一次来自在其中移动的障碍物。对于 $\Gamma$ 上的所有其他积分，我们对 $\Gamma$ 的每一部分都访问了两次，但符号相反，因此得到的是跳跃项）。

这里我们注意到，与不连续的Galerkin方法不同，测试和试验函数在 $\Gamma$ 中是连续的。此外，如果 $\Gamma$ 不与单元边界对齐，所有的跳跃项也是零，因为一般来说，有限元函数空间在每个单元内都是平滑的，如果 $\Gamma$ 只在有限的几个点上切过一个单元与它的边界相交，除了稳定化的贡献外， $\Gamma$ 上的所有贡献都可以从公式中忽略掉，导致以下变量公式的最终形式。

@f{multline*}{
(\nabla \textbf{v}, \nabla \textbf{u})_{\Omega} - (\textrm{div}\;  \textbf{v}, p)_{\Omega}


  - (q, \textrm{div}\; \textbf{u})_{\Omega}  + 2\beta (\textbf{v},\textbf{u})_{\Gamma} \\
=  2\beta (\textbf{v},\textbf{g})_{\Gamma}.


@f}



在step-60中，约束条件的施加需要以拉格朗日乘数的形式增加新的变量。本教程程序不存在这种情况。使用Nitsche方法施加边界条件只修改了系统矩阵和右手边，没有增加额外的未知数。然而，嵌入域上的速度矢量 $\textbf{u}$ 不会与规定的速度 $\textbf{g}$ 完全匹配，而只是达到一个数值误差，这个误差与有限元方法的插值误差相同。此外，与第60步一样，我们仍然需要在不匹配的嵌入网格上进行积分，以构建对 $\Gamma$ 施加边界条件的必要边界项。




<h4>Co-dimension zero case</h4>

在这种情况下， $\Gamma$ 具有相同的尺寸，但被嵌入到 $\Omega$ 中。我们可以把它看作是一个在流体中移动的厚物体。在 $\mathcal{L}^2$ 惩罚的情况下，额外的惩罚项可以被解释为 $\Gamma$ 内的达西项，结果是。

@f{eqnarray*}
(\nabla \textbf{v}, \nabla \textbf{u})_{\Omega} - & (\textrm{div}\;  \textbf{v}, p)_{\Omega}


  - (q, \textrm{div}\; \textbf{u})_{\Omega}  + \beta (\textbf{v},\textbf{u})_{\Gamma}
=  \beta (\textbf{v},\textbf{g})_{\Gamma}.


@f}



这里，对 $\Gamma$ 的积分只是对部分体积的积分。因此， $\mathcal{L}^2$ 的惩罚包括增加一个体积项，约束流体的速度与 $\Gamma$ 内刚体的速度保持一致。在这种情况下， $\beta$ 必须被选择得足够大，以确保 $\Gamma$ 中的迪里希特边界条件得到充分尊重，但也不能太高，以保持系统矩阵的适当调节。

一个 $\mathcal{H}^1$ 的惩罚可以用类似的方式构建，在惩罚中加入一个粘性成分，以阻尼 $\Gamma$ 内的速度梯度。

@f{eqnarray*}{
(\nabla \textbf{v}, \nabla \textbf{u})_{\Omega} - & (\textrm{div}\;  \textbf{v}, p)_{\Omega}


  - (q, \textrm{div}\; \textbf{u})_{\Omega}
  + \beta_1 (\textbf{v},\textbf{u})_{\Gamma}
  + \beta_2 (\nabla \textbf{v}, \nabla \textbf{u})_{\Gamma}
=  \beta_1 (\textbf{v},\textbf{g})_{\Gamma}
+ \beta_2 (\nabla \textbf{v}, \nabla \textbf{g})_{\Gamma}.


@f}



请注意， $L^2$ 的惩罚（`dim`等于`spacedim`）和Nitsche的惩罚（`dim`等于`spacedim-1`）导致了完全相同的数值实现，这要感谢deal.II的独立维度能力。




<h4>Representation of Ω and Γ</h4>

在本教程中，嵌入网格 $\Gamma$ 和嵌入网格都是用 parallel::distributed::Triangulation. 来描述的。这两个三角形可以通过GridGenerator命名空间中的函数来建立，或者通过读取其他应用程序（例如GMSH，见步骤-49的讨论）产生的网格文件来建立。这比之前在第60步中的做法略微通用了一些。

无论是在 "dim=spacedim "还是 "dim<spacedim "的情况下，增加沉没边界法，只是在系统矩阵和系统的右手边引入了额外的项，这些项是在 $\Gamma$ 上积分的结果。这并没有改变必须解决的问题的变量数量。因此，挑战与必须进行的积分有关  $\Gamma$  。

在有限元中，我们将这个积分分成来自用于离散化 $\Gamma$ 的所有单元的贡献，我们将 $K$ 上的积分转换为参考元素 $\hat K$ 上的积分，其中 $F_{K}$ 是 $\hat K$ 到 $K$ 的映射，并使用正交公式计算 $\hat K$ 上的积分。比如说。

\f[
\beta (\textbf{v},\textbf{u})_{\Gamma} =  \sum_{K\in \Gamma} \int_{\hat K}
\hat{\textbf{u}}(\hat x) (\textbf{v} \circ F_{K}) (\hat x) J_K (\hat x) \mathrm{d} \hat x =
\sum_{K\in \Gamma} \sum_{i=1}^{n_q}  \big(\hat{\textbf{u}}(\hat x_i)  (\textbf{v} \circ F_{K}) (\hat x_i) J_K (\hat x_i) w_i \big)
\f]

计算这个和是不容易的，因为我们必须评估 $(v_j \circ F_{K})
(\hat x_i)$  。一般来说，如果 $\Gamma$ 和 $\Omega$ 没有对齐，那么 $y_i = F_{K}(\hat x_i)$ 这个点相对于 $\Omega$ 来说是完全任意的，除非我们想出一个办法，将 $V_h(\Omega)$ 的所有基函数插在 $\Omega$ 上的一个任意点上，否则我们无法计算出需要的积分。


要评估 $(v_j \circ F_{K}) (\hat x_i)$ ，需要采取以下步骤（如下图所示）。

- 对于 $\Gamma$ 中的一个给定单元 $K$ ，计算实点 $y_i \dealcoloneq F_{K} (\hat
x_i)$ ，其中 $x_i$ 是用于 $K
\subseteq \Gamma$ 上的积分的正交点之一。这是最容易的部分。   FEValues::quadrature_point() 给了我们所有正交点的实空间位置。

- 找到 $\Omega$ 中 $y_i$ 所在的单元。我们将称这个元素为 $T$  。

- 找到 $T$ 内 $y_i$ 的参考坐标。为此，我们需要将参考元素 $\hat T$ 转换为元素 $T$ ： $\hat y_i = G^{-1}_{T} (y_i)$ 的映射 $G_T$ 的逆映射。

- 评估  $v_j$  网格在此点  $\hat y_i$  的基函数  $\Omega$  。这也是比较简单的，使用FEValues。


<p align="center"> <img src="https://www.dealii.org/images/steps/developer/step-60.C_interpolation.png" alt="">  </p> 

在步骤60中，上述第二至第四步是通过依次调用来计算的。

-  GridTools::find_active_cell_around_point(),  后面是

-  Mapping::transform_real_to_unit_cell().  然后我们

- 构建一个自定义的正交公式，包含参考单元格中的点，然后

- 构建一个FEValues对象，具有给定的正交公式，并以第一步中获得的单元格为初始化。

虽然这种方法对目前的情况是可行的，但它并不适合于使用分布式三角形的平行模拟。事实上，由于嵌入域 $\Gamma$ 单元上的正交点的位置与嵌入三角形的位置不一致，而且 $\Gamma$ 是不断移动的，这就要求代表 $\Gamma$ 的三角形被完整地存储在所有处理器中。随着处理器的数量和 $\Gamma$ 中单元格数量的增加，这将导致内存方面的严重瓶颈。因此，在这一步骤中寻求一种替代策略。




<h4>Using particles to track Γ</h4>

请记住，对于惩罚法（ $\mathcal{L}^2$ 或 $\mathcal{H}^1$ ）和尼采法，我们要计算的是由正交近似的积分。也就是说，我们需要计算

\f[
\beta (\textbf{v},\textbf{u})_{\Gamma} =
\sum_{K\in \Gamma} \sum_{i=1}^{n_q}  \big(\hat{\textbf{u}}(\hat x_i)  (\textbf{v} \circ F_{K}) (\hat x_i) J_K (\hat x_i) w_i \big)
\f] 如果你跟随上面的讨论，那么你会记得  $\textbf{u}$  和  $\textbf{v}$  是定义在流体网格上的形状函数。唯一定义在实体网格上的东西是。   $F_K(\hat x_i)$  ，是实体单元上正交点的位置，是 $\Gamma$ 的一部分， $J_K$ 是其雅各布系数的行列式， $w_i$ 是相应的正交权值。

现在要认识到的重要部分是这样的。   $w_i$ 是正交公式的一个属性，不随时间变化。此外， $F_K$ 的雅各布矩阵本身随着固体障碍物在流体中的移动而变化，但由于固体被认为是非变形的（它只是平移和旋转，但不扩张），雅各布矩阵的行列式保持不变。因此，乘积 $J_K(\hat x_i) w_i$ （我们通常用`JxW`表示）在每个正交点上都保持不变。因此，我们唯一需要跟踪的是位置 $x_i=F_K(\hat x_i)$ --但这些位置随着实体域的速度移动。

换句话说，我们实际上根本不需要保留实体网格。我们所需要的只是位置 $x_i(t)$ 和相应的`JxW`值。由于这两个属性都是附着在实体材料上的点属性（或点向量），它们可以被理想化为一组不相连的无限小的 "粒子"，它们随着实体的运动携带所需的`JxW`信息。deal.II有能力以ParticleHandler类的形式在大规模并行计算中分配和存储这样一组粒子（关于实现的细节见 @cite GLHPW2018  ），我们将在本教程中使用这一功能。

因此，本步骤采取的方法如下。

- 为域名  $\Gamma$  创建一个  parallel::distributed::Triangulation  。

- 在 Particles::Particle 上的正交点位置创建 $\Gamma$  。

- 调用 Particles::ParticleHandler::insert_global_particles() 函数，将粒子分配到各个处理器上，*遵循实体三角形*的做法。

- 将 "JxW "值作为一个 "属性 "附加到每个 Particles::Particle 对象。

这种结构的生成相对来说比较昂贵，但是每次模拟必须只生成一次。一旦 Particles::ParticleHandler 被生成，并且所需的信息被附加到粒子上，就可以利用粒子在ParticleHandler内按单元分组的事实，对 $\Gamma$ 进行积分，使我们能够。

- 在 $\Omega$ 中至少包含一个粒子的所有单元格上循环操作

- 循环处理给定单元中的所有粒子

- 计算积分并填充全局矩阵。

由于 Particles::ParticleHandler 可以管理粒子从一个处理器到另一个处理器的交换，嵌入的三角形可以通过位移粒子而被移动或变形。与这种位移相关的唯一约束是，颗粒的位移距离不应大于一个单元的大小。这是因为这是 Particles::ParticleHandler 能够追踪离开当前单元的粒子现在所处的单元的极限。

一旦整个问题（斯托克斯问题和沉没边界施加）被集合起来，最后的鞍点问题由迭代求解器解决，应用于舒尔补数 $S$ （其构造例如在步骤22中描述），我们使用LinearOperator类构造 $S$ 。




<h3>The testcase</h3>

我们在这里解决的问题是对斯托克斯流的时间可逆性的证明。这在科学教育实验中经常用泰勒-库伊特流和染料液滴来说明，在流体以周期性的方式位移后，染料液滴又恢复到原来的形状。

@htmlonly


<iframe width="560" height="315" src="https://www.youtube.com/embed/p08_KlTKP50" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


@endhtmlonly



在目前的问题中，一个非常粘稠的流体被一个叶轮的旋转所搅动，在二维中，叶轮被一个矩形网格所模拟。叶轮旋转了一定的圈数，之后流动被逆转，从而在相反的方向上进行相同圈数的旋转。我们回顾一下，由于斯托克斯方程是自交的，蠕动流是可逆的。因此，如果叶轮运动在相反的方向上被逆转，流体应该回到其原来的位置。在本例中，我们通过插入一圈被动示踪剂颗粒来说明这一点，这些颗粒被流体平移并返回到原来的位置，从而证明了流动的时间可逆性。




<h3> More references</h3>

本教程程序使用了一些关于对流体内部的非匹配界面施加速度条件的技术。要了解更多的背景材料，你可能要查阅以下参考资料。   @cite Freund1995  ,  @cite Angot1999  ,  @cite Glowinski1999  ,  @cite Boffi2008  ,  @cite Heltai2012  。


examples/step-70/doc/results.dox



<h1>Results</h1>

运行该程序的目录中包含一些样本参数文件，你可以用它们来重现本节介绍的结果。如果你没有在命令行中指定参数文件作为参数，程序将默认尝试读取文件"`parameters.prm`"，并执行二维版本的代码。正如在源代码的讨论中所解释的那样，如果你的文件名包含字符串 "23"，那么程序将运行一个三维问题，即共维度为1的沉入式实体。如果文件名包含字符串 "3"，它将运行一个三维问题，同维度的沉浸实体为零，否则它将运行一个二维问题，同维度的沉浸实体为零。

无论具体的参数文件名是什么，如果指定的文件不存在，当你执行程序时，你会得到一个异常，即找不到这样的文件。

@code


----------------------------------------------------
Exception on processing:


--------------------------------------------------------
An error occurred in line <74> of file <../source/base/parameter_acceptor.cc> in function
    static void dealii::ParameterAcceptor::initialize(const std::string &, const std::string &, const ParameterHandler::OutputStyle, dealii::ParameterHandler &)
The violated condition was:
    false
Additional information:
    You specified <parameters.prm> as input parameter file, but it does not exist. We created it for you.


--------------------------------------------------------


Aborting!


----------------------------------------------------
@endcode



然而，正如错误信息已经指出的，触发异常的代码也将生成指定的文件（"`parameters.prm`"在这种情况下），该文件仅仅包含这个程序关心的所有参数的默认值（对于正确的尺寸和辅助尺寸，根据文件名中是否包含字符串 "23 "或 "3"）。通过检查默认参数文件，我们看到以下内容。

@code
# Listing of Parameters
# ---------------------
subsection Stokes Immersed Problem
  set Final time                            = 1
  # Extraction level of the rtree used to construct global bounding boxes
  set Fluid bounding boxes extraction level = 1


  # Boundary Ids over which homogeneous Dirichlet boundary conditions are
  # applied
  set Homogeneous Dirichlet boundary ids    = 0


  # Initial mesh refinement used for the fluid domain Omega
  set Initial fluid refinement              = 5


  # Initial mesh refinement used for the solid domain Gamma
  set Initial solid refinement              = 5
  set Nitsche penalty term                  = 100
  set Number of time steps                  = 501
  set Output directory                      = .
  set Output frequency                      = 1


  # Refinement of the volumetric mesh used to insert the particles
  set Particle insertion refinement         = 3
  set Velocity degree                       = 2
  set Viscosity                             = 1



  subsection Angular velocity
    # Sometimes it is convenient to use symbolic constants in the expression
    # that describes the function, rather than having to use its numeric value
    # everywhere the constant appears. These values can be defined using this
    # parameter, in the form `var1=value1, var2=value2, ...'.
    #
    # A typical example would be to set this runtime parameter to
    # `pi=3.1415926536' and then use `pi' in the expression of the actual
    # formula. (That said, for convenience this class actually defines both
    # `pi' and `Pi' by default, but you get the idea.)
    set Function constants  =


    # The formula that denotes the function you want to evaluate for
    # particular values of the independent variables. This expression may
    # contain any of the usual operations such as addition or multiplication,
    # as well as all of the common functions such as `sin' or `cos'. In
    # addition, it may contain expressions like `if(x>0, 1, -1)' where the
    # expression evaluates to the second argument if the first argument is
    # true, and to the third argument otherwise. For a full overview of
    # possible expressions accepted see the documentation of the muparser
    # library at http://muparser.beltoforion.de/.
    #
    # If the function you are describing represents a vector-valued function
    # with multiple components, then separate the expressions for individual
    # components by a semicolon.
    set Function expression = t < .500001 ? 6.283185 : -6.283185 # default: 0


    # The names of the variables as they will be used in the function,
    # separated by commas. By default, the names of variables at which the
    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in
    # 3d) for spatial coordinates and `t' for time. You can then use these
    # variable names in your function expression and they will be replaced by
    # the values of these variables at which the function is currently
    # evaluated. However, you can also choose a different set of names for the
    # independent variables at which to evaluate your function expression. For
    # example, if you work in spherical coordinates, you may wish to set this
    # input parameter to `r,phi,theta,t' and then use these variable names in
    # your function expression.
    set Variable names      = x,y,t
  end


  subsection Grid generation
    set Fluid grid generator              = hyper_cube
    set Fluid grid generator arguments    = -1: 1: false
    set Particle grid generator           = hyper_ball
    set Particle grid generator arguments = 0.3, 0.3: 0.1: false
    set Solid grid generator              = hyper_rectangle
    set Solid grid generator arguments    = -.5, -.1: .5, .1: false
  end


  subsection Refinement and remeshing
    set Maximum number of cells        = 20000
    set Refinement coarsening fraction = 0.3
    set Refinement fraction            = 0.3
    set Refinement maximal level       = 8
    set Refinement minimal level       = 5
    set Refinement step frequency      = 5
    set Refinement strategy            = fixed_fraction
  end


  subsection Right hand side
    # Sometimes it is convenient to use symbolic constants in the expression
    # that describes the function, rather than having to use its numeric value
    # everywhere the constant appears. These values can be defined using this
    # parameter, in the form `var1=value1, var2=value2, ...'.
    #
    # A typical example would be to set this runtime parameter to
    # `pi=3.1415926536' and then use `pi' in the expression of the actual
    # formula. (That said, for convenience this class actually defines both
    # `pi' and `Pi' by default, but you get the idea.)
    set Function constants  =


    # The formula that denotes the function you want to evaluate for
    # particular values of the independent variables. This expression may
    # contain any of the usual operations such as addition or multiplication,
    # as well as all of the common functions such as `sin' or `cos'. In
    # addition, it may contain expressions like `if(x>0, 1, -1)' where the
    # expression evaluates to the second argument if the first argument is
    # true, and to the third argument otherwise. For a full overview of
    # possible expressions accepted see the documentation of the muparser
    # library at http://muparser.beltoforion.de/.
    #
    # If the function you are describing represents a vector-valued function
    # with multiple components, then separate the expressions for individual
    # components by a semicolon.
    set Function expression = 0; 0; 0


    # The names of the variables as they will be used in the function,
    # separated by commas. By default, the names of variables at which the
    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in
    # 3d) for spatial coordinates and `t' for time. You can then use these
    # variable names in your function expression and they will be replaced by
    # the values of these variables at which the function is currently
    # evaluated. However, you can also choose a different set of names for the
    # independent variables at which to evaluate your function expression. For
    # example, if you work in spherical coordinates, you may wish to set this
    # input parameter to `r,phi,theta,t' and then use these variable names in
    # your function expression.
    set Variable names      = x,y,t
  end


end
@endcode



如果你现在运行该程序，你会在参数`Output directory`（默认为当前目录）指定的目录下得到一个名为`parameters_22.prm`的文件，其中包含上述参数的简短版本（没有注释和文档），记录了所有用于运行程序的参数。

@code
subsection Stokes Immersed Problem
  set Final time                            = 1
  set Fluid bounding boxes extraction level = 1
  set Homogeneous Dirichlet boundary ids    = 0
  set Initial fluid refinement              = 5
  set Initial solid refinement              = 5
  set Nitsche penalty term                  = 100
  set Number of time steps                  = 501
  set Output directory                      = .
  set Output frequency                      = 1
  set Particle insertion refinement         = 3
  set Velocity degree                       = 2
  set Viscosity                             = 1
  subsection Angular velocity
    set Function constants  =
    set Function expression = t < .500001 ? 6.283185 : -6.283185
    set Variable names      = x,y,t
  end
  subsection Grid generation
    set Fluid grid generator              = hyper_cube
    set Fluid grid generator arguments    = -1: 1: false
    set Particle grid generator           = hyper_ball
    set Particle grid generator arguments = 0.3, 0.3: 0.1: false
    set Solid grid generator              = hyper_rectangle
    set Solid grid generator arguments    = -.5, -.1: .5, .1: false
  end
  subsection Refinement and remeshing
    set Maximum number of cells        = 20000
    set Refinement coarsening fraction = 0.3
    set Refinement fraction            = 0.3
    set Refinement maximal level       = 8
    set Refinement minimal level       = 5
    set Refinement step frequency      = 5
    set Refinement strategy            = fixed_fraction
  end
  subsection Right hand side
    set Function constants  =
    set Function expression = 0; 0; 0
    set Variable names      = x,y,t
  end
end
@endcode



首先创建 "parameters.prm "文件（程序第一次运行时），然后创建 "output/parameters_22.prm "文件（每次使用现有的输入文件运行程序时），这是因为你可能想把大多数参数保留为默认值，只修改其中的一小部分，同时仍然能够重现结果，检查特定模拟使用了哪些参数。一般来说，将用于模拟的参数文件与模拟输出一起保存起来是很好的科学做法，这样你就可以在以后的时间里重复相同的运行。

另一个原因是输入文件可能只包含那些与默认值不同的参数。例如，你可以在本教程程序中使用以下（完全有效的）参数文件。

@code
subsection Stokes Immersed Problem
  set Final time                         = 1
  set Nitsche penalty term               = 10
  set Number of time steps               = 101
  set Velocity degree                    = 3
end
@endcode

你将使用Q3/Q2 Taylor-Hood有限元运行程序，进行101步，使用Nitsche惩罚为`10`，并将所有其他参数保持为默认值。输出目录不仅包含了这些参数的记录，而且包含了仿真中使用的所有参数。你可以在生成的文件`parameters_22.prm`中查看所有其他参数。




<h3> Two dimensional test case </h3>

默认问题产生了一个同维度的零叶轮，由一个旋转的矩形网格组成，在一个方向上旋转半个时间单位，在相反方向上旋转半个时间单位，恒定的角速度等于 $\approx 2\pi \frac{\text{rad}}{\text{time unit}}$  。因此，叶轮做了半个旋转，并返回到原来的位置。下面的动画显示了速度的大小，固体叶轮和示踪粒子的运动。


<p align="center"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-70.2d_tracing.gif" alt="" width="500"> </div>  </p> 

在一个核心上，程序的输出将看起来像下面这样。

@code
bash$ mpirun -np 1 ./step-70 test.prm
Running StokesImmersedProblem<2> using Trilinos.
Cycle 0:
Time : 0, time step: 0.002
   Number of degrees of freedom: 9539 (8450+1089 -- 0+0)
Tracer particles: 337
Solid particles: 9216
   Solved in 158 iterations.
   Number of degrees of freedom: 9845 (8722+1123 -- 9216+337)
Cycle 1:
Time : 0.002, time step: 0.002
   Solved in 142 iterations.
Cycle 2:
Time : 0.004, time step: 0.002
   Solved in 121 iterations.
Cycle 3:
Time : 0.006, time step: 0.002
   Solved in 121 iterations.


...


Cycle 499:
Time : 0.998, time step: 0.002
   Solved in 199 iterations.
Cycle 500:
Time : 1, time step: 0.002
   Solved in 196 iterations.


+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |       302s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble Nitsche terms          |       501 |      43.3s |        14% |
| Assemble Stokes terms           |       501 |      21.5s |       7.1% |
| Initial setup                   |         1 |  0.000792s |         0% |
| Output fluid                    |       502 |      31.8s |        11% |
| Output solid particles          |       502 |      32.2s |        11% |
| Output tracer particles         |       502 |      0.61s |       0.2% |
| Refine                          |       100 |      4.68s |       1.5% |
| Set solid particle position     |       500 |      3.34s |       1.1% |
| Set tracer particle motion      |       501 |     0.729s |      0.24% |
| Setup dofs                      |       101 |       2.2s |      0.73% |
| Solve                           |       501 |       164s |        54% |
+---------------------------------+-----------+------------+------------+
@endcode



你可能会注意到，组装耦合系统比组装斯托克斯部分更昂贵。这在很大程度上取决于用于应用Nitsche限制的高斯点（固体粒子）的数量。在目前的情况下，所使用的示踪粒子的数量相对较少。因此，跟踪它们的运动是相对便宜的。

下面的影片显示了解决方案随时间的演变。

@htmlonly
<p align="center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/y4Gypj2jpXw"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly



这部电影显示了灰色的旋转障碍物（实际上是用足够大的点绘制的固体粒子的叠加，使它们重叠），浅色的<a
href="https://en.wikipedia.org/wiki/Streamlines,_streaklines,_and_pathlines">streamlines
of the fluid flow</a>（包括在模拟过程中特定时间形成的角顶点），以及蓝色色调的示踪粒子。

模拟结果显示，在结束的时候，示踪剂颗粒已经在一定程度上回到了原来的位置，尽管它们已经被流场扭曲了。下面的图片比较了粒子在一个时间单位的流动后的初始和最终位置。

<p align="center"> <div class="img" align="center"> <img src="https://www.dealii.org/images/steps/developer/step-70.tracer_comparison.png" alt="" width="500"> </div>  </p> 

在这种情况下，我们看到在叶轮扫过的体积之外的示踪剂颗粒已经非常接近它们的初始位置，而在扫过的体积内的示踪剂颗粒的变形略大。这种变形是非物理性的。它是由用于平移粒子的显式欧拉方案引起的数值误差、由虚构领域引起的精度损失以及最后由斯托克斯方程的离散化误差引起的。前两个错误是造成这种变形的主要原因，它们可以通过使用更细的网格和更小的时间步长来缓解。




<h3> Three dimensional test case </h3>

为了玩一玩，我们将虚构的领域复杂化（取自https://grabcad.com/library/lungstors-blower-1），并在三个空间维度上运行共维一模拟，使用以下"`参数_23.prm`"文件。

@code
subsection Stokes Immersed Problem
  set Final time                            = 1
  set Homogeneous Dirichlet boundary ids    = 0
  set Fluid bounding boxes extraction level = 1
  set Initial fluid refinement              = 3
  set Initial solid refinement              = 0
  set Nitsche penalty term                  = 10
  set Number of time steps                  = 101
  set Output frequency                      = 1
  set Particle insertion refinement         = 3
  set Velocity degree                       = 2
  set Viscosity                             = 1
  subsection Angular velocity
    set Function constants  =
    set Function expression = t < .500001 ? 5 : -5
    set Variable names      = x,y,z,t
  end
  subsection Grid generation
    set Fluid grid generator              = hyper_rectangle
    set Fluid grid generator arguments    = -50,-50, -10: 50, 50, 40: false
    set Solid grid generator              = impeller.vtk
    set Solid grid generator arguments    = 1:impeller.step
    set Particle grid generator           = hyper_ball
    set Particle grid generator arguments = 30, 30, 20: 10: false
  end
  subsection Refinement and remeshing
    set Maximum number of cells        = 100000
    set Refinement coarsening fraction = 0.3
    set Refinement fraction            = 0.3
    set Refinement maximal level       = 6
    set Refinement step frequency      = 5
    set Refinement strategy            = fixed_fraction
  end
  subsection Right hand side
    set Function constants  =
    set Function expression = 0; 0; 0; 0
    set Variable names      = x,y,z,t
  end
end
@endcode



在这种情况下，定时输出有点不同。

@code
+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |  5.54e+03s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble Nitsche terms          |       101 |       111s |         2% |
| Assemble Stokes terms           |       101 |       208s |       3.8% |
| Initial setup                   |         1 |   0.00187s |         0% |
| Output fluid                    |       102 |      15.5s |      0.28% |
| Output solid particles          |       102 |      2.63s |         0% |
| Output tracer particles         |       102 |      2.49s |         0% |
| Refine                          |        20 |      18.4s |      0.33% |
| Set solid particle position     |       100 |       6.1s |      0.11% |
| Set tracer particle motion      |       101 |      10.8s |       0.2% |
| Setup dofs                      |        21 |      13.9s |      0.25% |
| Solve                           |       101 |  5.16e+03s |        93% |
+---------------------------------+-----------+------------+------------+
@endcode



现在，求解器在三维空间中占用了大部分的求解时间，就运行时间而言，粒子运动和Nitsche装配仍然相对不重要。




@htmlonly
<p align="center">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/Srwq7zyR9mg"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

目前的教程程序显示了流体和固体之间的单向耦合，其中固体运动是强加的（而不是求解的），并通过利用固体正交点的位置和权重在固体域中读取。

代码的结构已经允许人们通过利用读取实体网格正交点上流体速度值的可能性来实现双向耦合。为了提高MPI通信模式的效率，我们应该将正交点的所有权保持在实体处理器上，该处理器拥有创建这些正交点的单元。在目前的代码中，通过使用实体分区而不是初始流体分区来定义用于交换正交点信息的向量索引集就足够了。

这使得本教程程序中使用的技术与教程步骤-60中提出的技术相结合，以解决带有分布式拉格朗日乘数的流体结构交互问题，在 parallel::distributed::Triangulation 对象上。

上面的时间显示，目前的预处理策略对Nitsche惩罚的效果并不好，如果我们想瞄准更大的问题，我们应该想出一个更好的预处理方法。此外，应该实施检查点重启策略，以允许较长的模拟被中断和恢复，例如在step-69教程中就是这样做的。


examples/step-71/doc/intro.dox

 <br> 

<i>This program was contributed by Jean-Paul Pelteret.
</i>




<h1>Introduction</h1>

本教程的目的很简单，就是介绍[自动](https://en.wikipedia.org/wiki/Automatic_differentiation)和[符号微分](https://en.wikipedia.org/wiki/Computer_algebra)（分别缩写为AD和SD）的基本原理。人们可以在源代码中描述一个函数 $\mathbf f(\mathbf x)$ ，并自动获得导数 $\nabla \mathbf f(\mathbf x)$ （"Jacobian"）、 $\nabla^2 \mathbf f(\mathbf x)$ （"Hessian"）等的表示方法，而无需编写额外的代码行。这样做对解决非线性或优化问题很有帮助，因为人们希望在代码中只描述非线性方程或目标函数，而不必同时提供它们的导数（这对解决非线性问题的牛顿方法或寻找最小化器是必要的）。

由于AD和SD工具在某种程度上独立于有限元和边界值问题，本教程将与你之前可能读过的其他教程不同。它将特别关注这些框架是如何工作的，以及它们背后的原理和思想，并放弃在有限元模拟的直接背景下看待它们。

事实上，我们将研究两组不同的问题，它们的复杂程度大不相同，但当框架正确时，有足够的相似性，同样的AD和SD框架可以被利用。通过这些例子，我们的目的是建立起对使用AD和SD工具所需步骤的理解，以及它们之间的区别，并希望能找出它们可以立即用于改进或简化现有代码的地方。

你想知道什么是AD和SD，这是可信的，首先。好吧，这个问题很容易回答，但如果没有上下文，就没有很好的洞察力。因此，我们不打算在这个介绍中涉及这个问题，而是将其推迟到第一个介绍性的例子中，在这个例子的展开过程中，我们将列出关键点。作为补充，我们应该提到，这两个框架的核心理论在 @ref auto_symb_diff 模块中都有广泛的讨论，所以在此不需要重复。

由于我们必须挑选*个足够有趣的课题来研究，并确定AD和SD在哪里可以有效地使用，所以在教程的后半部分实现的主要问题是对一个耦合的构成法进行建模，特别是一个磁活性材料（具有滞后效应）。作为一种介绍的手段，在介绍的后面将介绍该类材料的一些基础理论。自然，这不是一个广泛受众感兴趣的领域（甚至不是一类材料）。因此，作者希望在前面表示，这个理论和任何后续的推导都不能被认为是本教程的重点。相反，请牢记从相对无害的构成法则描述中产生的问题的复杂性，以及我们可能（在边界值问题的背景下）需要从中推导出什么。我们将在一个有代表性的连续体点的水平上用这些构成法则进行一些计算（所以，仍然是在连续体力学的领域），并将产生一些基准结果，我们可以围绕这些结果对计算性能的主题进行最后讨论。

一旦我们有了可以建立进一步概念的基础，我们将看到如何在有限元（而不是连续体）水平上特别利用AD：这是在步骤-72和步骤-33中涉及的一个主题。但在此之前，让我们花点时间思考一下为什么我们可能要考虑使用这些工具，以及它们可能给你带来什么好处。




<h3>A motivation: Why would I use these tools?</h3>

使用AD或SD的主要驱动力通常是，有一些情况需要进行区分，而且这样做有足够的挑战性，使得使用外部工具来执行该特定任务的前景具有吸引力。对AD或SD最有用的情况进行广泛分类，包括（但可能不限于）以下情况。

- <b>Rapid prototyping:</b>对于一类新的问题，你试图快速实现一个解决方案，并希望去除一些复杂的细节（在数学以及代码本身的组织结构方面）。你可能愿意证明任何额外的计算成本是合理的，这将被重组你的代码或修改问题中引入一些复杂的非线性的部分的敏捷性所抵消，只需最小的努力。

- <b>Complex problems:</b>很可能有些问题恰好有一个非线性，对线性化或手工制定有极大的挑战。   让一个在大多数情况下稳健、可靠和准确的工具来为你解决这个挑战，可能会减轻实现某些问题的痛苦。这方面的例子包括第15步，我们解决的非线性PDE的导数并不难推导，但足够繁琐，以至于人们在手工操作时必须注意，而且实现牛顿步骤的相应有限元公式所需的时间不仅仅是实现双线性形式一般所需的几行；第33步（我们实际使用AD）是一个更极端的例子。

- <b>Verification:</b> 对于表现出非线性响应的材料和模拟，准确而非近似的材料切线（机械工程师对材料定律的导数使用的术语）可能是收敛和发散行为之间的区别，特别是在高外部（或耦合）载荷下。   随着问题复杂性的增加，引入细微的（或者，也许不是那么细微的）错误的机会也在增加，这些错误会产生可预见的负面结果。   此外，通过验证实现是完全正确的，也有很多好处。例如，某些类别的问题已知会表现出不稳定性，因此，当你在非线性求解器（例如牛顿方法）中开始失去二次收敛时，那么这对研究者来说可能不是一个巨大的惊喜。然而，很难（如果不是不可能）区分以下两种收敛行为：一种是你接近不稳定的解时产生的收敛行为，另一种是你在材料或有限元线性化中出现了错误，并因此开始偏离最佳收敛路径。例如，拥有一种验证构成法线性化实现的正确性的方法，也许是你用来捕捉这种错误的唯一有意义的方法，假设你没有其他人来检查你的代码。   值得庆幸的是，通过一些战术性的编程，可以很直接地将代码结构化以便重复使用，这样你就可以在生产代码中使用相同的类，并直接在例如单元测试框架中验证它们。

这个教程程序将有两个部分。一部分，我们只是用一组简单的例子来介绍deal.II中自动和符号微分支持的基本思想；另一部分，我们将其应用于一个现实的但更复杂的案例。对于这后半部分，下一节将提供一些关于磁性机械材料的背景--如果你想了解的只是AD和SD的实际情况，你可以跳过这一节，但如果你对如何将AD和SD应用于具体的情况感兴趣，你可能想读完这一节。




<h3>Theory for magneto-mechanical materials</h3>

<h4>Thermodynamic principles</h4>

作为介绍我们将用来为磁活性聚合物建模的磁-机械耦合材料法的前奏，我们将首先对这些构成法则必须认同的突出的热力学进行非常简洁的总结。这里总结的理论基础，由Truesdell和Toupin  @cite Truesdell1960a  以及Coleman和Noll  @cite Coleman1963a  详细描述，并遵循Holzapfel  @cite Holzapfel2007a  所提出的逻辑。

从热力学第一定律出发，并遵循一些技术假设，可以证明动能加内能率与外部来源提供给系统的功率之间的平衡是由以下关系给出的，即左边是一个（任意）体积 $V$ 的能量变化率，右边是作用于该体积的力的总和。

@f[
  D_{t} \int\limits_{V} \left[
    \frac{1}{2} \rho_{0} \mathbf{v} \cdot \mathbf{v}
    + U^{*}_{0} \right] dV
= \int\limits_{V} \left[
  \rho_{0} \mathbf{v} \cdot \mathbf{a}
  + \mathbf{P}^{\text{tot}} : \dot{\mathbf{F}}
  + \boldsymbol{\mathbb{H}} \cdot \dot{\boldsymbol{\mathbb{B}}}
  + \mathbb{E} \cdot \dot{\mathbb{D}}


  - D_{t} M^{*}_{0}


  - \nabla_{0} \cdot \mathbf{Q}
  + R_{0} \right] dV .


@f]

这里 $D_{t}$ 代表总的时间导数， $\rho_{0}$ 是在拉格朗日参考框架下测量的材料密度， $\mathbf{v}$ 是材料速度， $\mathbf{a}$ 是其加速度， $U^{*}_{0}$ 是每单位参考体积的内能， $\mathbf{P}^{\text{tot}}$ 是总皮拉应力张量， $\dot{\mathbf{F}}$ 是变形梯度张量的时间速率， $\boldsymbol{\mathbb{H}}$ 和 $\boldsymbol{\mathbb{B}}$ 分别是磁场向量和磁感应（或磁通密度）向量， $\mathbb{E}$ 和 $\mathbb{D}$ 是电场向量和电位移向量， $\mathbf{Q}$ 和 $R_{0}$ 代表参考热通向量和热源。材料微分算子 $\nabla_{0} (\bullet) \dealcoloneq \frac{d(\bullet)}{d\mathbf{X}}$ ，其中 $\mathbf{X}$ 是材料位置向量。通过一些条款的重排，引用积分体积 $V$ 的任意性，总的内部能量密度率 $\dot{E}_{0}$ 可以被确定为

@f[
  \dot{E}_{0}
= \mathbf{P}^{\text{tot}} : \dot{\mathbf{F}}
  + \boldsymbol{\mathbb{H}} \cdot \dot{\boldsymbol{\mathbb{B}}}
  + \mathbb{E} \cdot \dot{\mathbb{D}}


  - \nabla_{0} \cdot \mathbf{Q}
  + R_{0} .


@f]

总的内能不仅包括由于机械变形（第一项）、热通量和热源（第四项和第五项）而产生的贡献，还包括由于储存在磁场和电场本身的内在能量（分别为第二项和第三项）。

热力学第二定律，也被称为熵不平等原则，告诉我们某些热力学过程是不可逆的。在考虑了总熵和熵输入的速度后，可以得出克劳修斯-杜姆不等式。在局部形式下（以及在物质配置中），其内容为

@f[
  \theta \dot{\eta}_{0}


  - R_{0}
  + \nabla_{0} \cdot \mathbf{Q}


  - \frac{1}{\theta} \nabla_{0} \theta \cdot \mathbf{Q}
  \geq 0 .


@f]

量 $\theta$ 是绝对温度， $\eta_{0}$ 代表每单位参考体积的熵值。

用它来代替热力学第一定律结果中的 $R_{0} - \nabla_{0} \cdot \mathbf{Q}$ ，我们现在有了这样的关系

@f[
  \mathbf{P}^{\text{tot}} : \dot{\mathbf{F}}
  + \boldsymbol{\mathbb{H}} \cdot \dot{\boldsymbol{\mathbb{B}}}
  + \mathbb{E} \cdot \dot{\mathbb{D}}
  + \theta \dot{\eta}_{0}


  - \dot{E}_{0}


  - \frac{1}{\theta} \nabla_{0} \theta \cdot \mathbf{Q}
  \geq 0 .


@f]

傅里叶定律告诉我们，热量从高温区域流向低温区域，根据这一定律，最后一项总是正的，可以忽略不计。这使得局部耗散的不等式变成了

@f[
  \mathbf{P}^{\text{tot}} : \dot{\mathbf{F}}
  + \boldsymbol{\mathbb{H}} \cdot \dot{\boldsymbol{\mathbb{B}}}
  + \mathbb{E} \cdot \dot{\mathbb{D}}


  - \left[ \dot{E}_{0} - \theta \dot{\eta}_{0}  \right]
  \geq 0 .


@f]

据推测 @cite Holzapfel2007a ，Legendre变换

@f[
  \psi^{*}_{0}
= \psi^{*}_{0} \left( \mathbf{F}, \boldsymbol{\mathbb{B}}, \mathbb{D}, \theta \right)
= E_{0} - \theta \eta_{0} ,


@f]

从中我们可以定义具有所述参数化的自由能密度函数 $\psi^{*}_{0}$ ，它存在并且有效。取此方程的材料速率并将其代入局部耗散不等式，结果是通用表达式

@f[
  \mathcal{D}_{\text{int}}
  = \mathbf{P}^{\text{tot}} : \dot{\mathbf{F}}
  + \boldsymbol{\mathbb{H}} \cdot \dot{\boldsymbol{\mathbb{B}}}
  + \mathbb{E} \cdot \dot{\mathbb{D}}


  - \dot{\theta} \eta_{0}


  - \dot{\psi}^{*}_{0} \left( \mathbf{F}, \boldsymbol{\mathbb{B}}, \mathbb{D}, \theta \right)
  \geq 0 .


@f]

在等温条件的假设下，并且电场不会以一种被认为是不可忽视的方式激发材料，那么这个耗散不等式就会简化为

@f[
  \mathcal{D}_{\text{int}}
  = \mathbf{P}^{\text{tot}} : \dot{\mathbf{F}}
  + \boldsymbol{\mathbb{H}} \cdot \dot{\boldsymbol{\mathbb{B}}}


  - \dot{\psi}^{*}_{0} \left( \mathbf{F}, \boldsymbol{\mathbb{B}} \right)
  \geq 0 .


@f]



<h4>Constitutive laws</h4>

当考虑到表现出机械耗散行为的材料时，可以证明这可以通过用代表内部变量的额外参数增加材料自由能密度函数的方式在耗散不等式中得到体现  @cite Holzapfel1996a  。因此，我们把它写成

@f[
  \mathcal{D}_{\text{int}}
  = \mathbf{P}^{\text{tot}} : \dot{\mathbf{F}}
  + \boldsymbol{\mathbb{H}} \cdot \dot{\boldsymbol{\mathbb{B}}}


  - \dot{\psi}^{*}_{0} \left( \mathbf{F}, \mathbf{F}_{v}^{i}, \boldsymbol{\mathbb{B}} \right)
  \geq 0 .


@f]

其中 $\mathbf{F}_{v}^{i} = \mathbf{F}_{v}^{i} \left( t \right)$ 代表与第i个机械耗散（粘性）机制相关的内部变量（其作用类似于变形梯度的测量）。从它的参数化可以推断出，这些内部参数中的每一个都被认为是在时间中演变的。目前，自由能密度函数 $\psi^{*}_{0}$ 是以磁感应 $\boldsymbol{\mathbb{B}}$ 为参数的。这是自然的参数化，是所考虑的平衡法的结果。如果这样一类材料被纳入到有限元模型中，将确定需要采用某种磁问题的表述，即磁矢量势表述。这有它自己的一套挑战，所以在可能的情况下，更简单的磁标量势表述可能是首选。在这种情况下，磁性问题需要在磁场方面进行参数化  $\boldsymbol{\mathbb{H}}$  。为了进行这种重新参数化，我们执行最后的Legendre变换

@f[
  \tilde{\psi}_{0} \left( \mathbf{F}, \mathbf{F}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  = \psi^{*}_{0} \left( \mathbf{F}, \mathbf{F}_{v}^{i}, \boldsymbol{\mathbb{B}} \right)


  - \boldsymbol{\mathbb{H}} \cdot \boldsymbol{\mathbb{B}} .


@f]

同时，我们可以利用材料框架无所谓的原则，以便用对称的变形措施来表达能量密度函数。

@f[
  \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  = \tilde{\psi}_{0} \left( \mathbf{F}, \mathbf{F}_{v}^{i}, \boldsymbol{\mathbb{H}} \right) .


@f]

这两个转换的结果（撇开相当多的明确和隐藏的细节）使减少耗散不等式的最终表达式为

@f[
  \mathcal{D}_{\text{int}}
  = \mathbf{S}^{\text{tot}} : \frac{1}{2} \dot{\mathbf{C}}


  - \boldsymbol{\mathbb{B}} \cdot \dot{\boldsymbol{\mathbb{H}}}


  - \dot{\psi}_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  \geq 0 .


@f]

注意右侧第二项的符号变化，以及时间导数向磁感应矢量的转移）。应力量 $\mathbf{S}^{\text{tot}}$ 被称为总Piola-Kirchhoff应力张量，其能量共轭物 $\mathbf{C} = \mathbf{F}^{T} \cdot \mathbf{F}$ 是右Cauchy-Green变形张量， $\mathbf{C}_{v}^{i} = \mathbf{C}_{v}^{i} \left( t \right)$ 是与`i`th机械耗散（粘性）机制相关的重新参数化内部变量。

对能量密度函数的材料速率进行扩展，并对各种项进行重排，得出的表达式是

@f[
  \mathcal{D}_{\text{int}}
  = \left[ \mathbf{S}^{\text{tot}} - 2 \frac{\partial \psi_{0}}{\partial \mathbf{C}} \right] : \frac{1}{2} \dot{\mathbf{C}}


  - \sum\limits_{i}\left[ 2 \frac{\partial \psi_{0}}{\partial \mathbf{C}_{v}^{i}} \right] : \frac{1}{2} \dot{\mathbf{C}}_{v}^{i}
  + \left[ - \boldsymbol{\mathbb{B}} - \frac{\partial \psi_{0}}{\partial \boldsymbol{\mathbb{H}}} \right] \cdot \dot{\boldsymbol{\mathbb{H}}}
  \geq 0 .


@f]

在这一点上，值得注意的是[偏导数](https://en.wikipedia.org/wiki/Partial_derivative)  $\partial \left( \bullet \right)$  的使用。这是一个重要的细节，对于本教程中的某个设计选择是很重要的。简单提醒一下这意味着什么，一个多变量函数的偏导返回该函数相对于其中一个变量的导数，而其他变量保持不变。

@f[
  \frac{\partial f\left(x, y\right)}{\partial x}
  = \frac{d f\left(x, y\right)}{d x} \Big\vert_{y} .


@f]

更具体到耗散不等式所编码的内容（用非常普遍的自由能密度函数 $\psi_{0}$ ，其参数化尚待正式确定），如果输入变量之一是另一个变量的函数，它也被保持不变，链式规则不再传播，而计算总导数将意味着明智地使用链式规则。通过比较以下两个语句可以更好地理解这一点。

@f{align*}
  \frac{\partial f\left(x, y\left(x\right)\right)}{\partial x}
  &= \frac{d f\left(x, y\left(x\right)\right)}{d x} \Big\vert_{y} \\
  \frac{d f\left(x, y\left(x\right)\right)}{d x}
  &= \frac{d f\left(x, y\left(x\right)\right)}{d x} \Big\vert_{y}
   + \frac{d f\left(x, y\left(x\right)\right)}{d y} \Big\vert_{x} \frac{d y\left(x\right)}{x} .


@f}



回到问题的热力学，我们接下来利用数量的任意性  $\dot{\mathbf{C}}$  和  $\dot{\boldsymbol{\mathbb{H}}}$  ，通过应用科尔曼-诺尔程序  @cite Coleman1963a  ，  @cite Coleman1967a  。这导致了对动力学共轭量的识别

@f[
  \mathbf{S}^{\text{tot}}
  = \mathbf{S}^{\text{tot}} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  \dealcoloneq 2 \frac{\partial \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)}{\partial \mathbf{C}} , \\
  \boldsymbol{\mathbb{B}}
  = \boldsymbol{\mathbb{B}} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  \dealcoloneq - \frac{\partial \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)}{\partial \boldsymbol{\mathbb{H}}} .


@f]

(再次注意，在这个广义的设置中，使用偏导数来定义应力和磁感应)。从耗散功率中剩下的条款（即那些与机械耗散机制有关的条款）来看，如果假定它们是相互独立的，那么，对于每个机制`i`。

@f[
  \frac{\partial \psi_{0}}{\partial \mathbf{C}_{v}^{i}} : \dot{\mathbf{C}}_{v}^{i}
  \leq 0 .


@f]

这一约束必须通过适当选择自由能函数以及仔细考虑内部变量的演化规律来满足。

在构成模型中没有耗散机制的情况下（例如，如果要建模的材料是磁超弹性的），那么自由能密度函数 $\psi_{0} = \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)$ 减少到存储能量密度函数，总应力和磁感应可以被简化

@f{align*}{
  \mathbf{S}^{\text{tot}}
  = \mathbf{S}^{\text{tot}} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
  &\dealcoloneq 2 \frac{d \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)}{d \mathbf{C}} , \\
  \boldsymbol{\mathbb{B}}
  = \boldsymbol{\mathbb{B}} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
  &\dealcoloneq - \frac{d \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)}{d \boldsymbol{\mathbb{H}}} ,


@f}

其中算子 $d$ 表示总导数操作。

为了完整起见，应力张量和磁感应的线性化在四阶总参考弹性张量 $\mathcal{H}^{\text{tot}} $ 、二阶磁静力张量 $\mathbb{D}$ 和三阶总参考磁弹性耦合张量 $\mathfrak{P}^{\text{tot}}$ 中得到体现。无论 $\mathbf{S}^{\text{tot}}$ 和 $\boldsymbol{\mathbb{B}}$ 的参数化如何，这些量都可以通过以下方式计算出来

@f{align*}{
  \mathcal{H}^{\text{tot}}
  &= 2 \frac{d \mathbf{S}^{\text{tot}}}{d \mathbf{C}} , \\
  \mathbb{D}
  &= \frac{d \boldsymbol{\mathbb{B}}}{d \boldsymbol{\mathbb{H}}} , \\
  \mathfrak{P}^{\text{tot}}
  &= - \frac{d \mathbf{S}^{\text{tot}}}{d \boldsymbol{\mathbb{H}}} , \\
  \left[ \mathfrak{P}^{\text{tot}} \right]^{T}
  &= 2 \frac{d \boldsymbol{\mathbb{B}}}{d \mathbf{C}} .


@f}

对于速率依赖性材料的情况，这扩展为

@f{align*}{
  \mathcal{H}^{\text{tot}} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  &= 4 \frac{d^{2} \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)}{\partial \mathbf{C} \otimes d \mathbf{C}} , \\
  \mathbb{D} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  &= -\frac{d^{2} \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)}{\partial \boldsymbol{\mathbb{H}} \otimes d \boldsymbol{\mathbb{H}}} , \\
  \mathfrak{P}^{\text{tot}} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)
  &= - 2 \frac{d^{2} \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)}{\partial \boldsymbol{\mathbb{H}} \otimes d \mathbf{C}} , \\
  \left[ \mathfrak{P}^{\text{tot}} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)  \right]^{T}
  &= - 2 \frac{d^{2} \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}^{i}, \boldsymbol{\mathbb{H}} \right)}{\partial \mathbf{C} \otimes d \boldsymbol{\mathbb{H}}} ,


@f}

而对于与速率无关的材料，其线性化为

@f{align*}{
  \mathcal{H}^{\text{tot}} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
  &= 4 \frac{d^{2} \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)}{d \mathbf{C} \otimes d \mathbf{C}} , \\
  \mathbb{D} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
  &= -\frac{d^{2} \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)}{d \boldsymbol{\mathbb{H}} \otimes d \boldsymbol{\mathbb{H}}} , \\
  \mathfrak{P}^{\text{tot}} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
  &= - 2 \frac{d^{2} \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)}{d \boldsymbol{\mathbb{H}} \otimes d \mathbf{C}} , \\
  \left[ \mathfrak{P}^{\text{tot}} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)  \right]^{T}
  &= - 2 \frac{d^{2} \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)}{d \mathbf{C} \otimes d \boldsymbol{\mathbb{H}}} .


@f}

它们之间的微妙区别是在计算第一个导数时应用了偏导。我们稍后会看到这对这个具体应用中AD与SD的选择有什么影响。现在，我们将简单介绍在本教程中实现的两种具体材料。

<h5>Magnetoelastic constitutive law</h5>

我们要考虑的第一种材料是受磁超弹性构成法支配的材料。这种材料对变形和浸泡在磁场中都有反应，但没有表现出时间或历史相关的行为（如通过粘性阻尼或磁滞的耗散，等等）。这种材料的*存储能量密度函数*只以（当前）场变量为参数，而不是它们的时间导数或过去的值。

我们将选择能量密度函数，它既能捕捉到由于变形和磁化而储存在材料中的能量，也能捕捉到储存在磁场本身的能量，它是

@f[
  \psi_{0} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
= \frac{1}{2} \mu_{e} f_{\mu_{e}} \left( \boldsymbol{\mathbb{H}} \right)
    \left[ \text{tr}(\mathbf{C}) - d - 2 \ln (\text{det}(\mathbf{F}))
    \right]
+ \lambda_{e} \ln^{2} \left(\text{det}(\mathbf{F}) \right)


- \frac{1}{2} \mu_{0} \mu_{r} \text{det}(\mathbf{F})
    \left[ \boldsymbol{\mathbb{H}} \cdot \mathbf{C}^{-1} \cdot
    \boldsymbol{\mathbb{H}} \right]


@f]

与

@f[
  f_{\mu_{e}} \left( \boldsymbol{\mathbb{H}} \right)
= 1 + \left[ \frac{\mu_{e}^{\infty}}{\mu_{e}} - 1 \right]
    \tanh \left( 2 \frac{\boldsymbol{\mathbb{H}} \cdot
    \boldsymbol{\mathbb{H}}}
      {\left(h_{e}^{\text{sat}}\right)^{2}} \right)


@f]

其中变量 $d = \text{tr}(\mathbf{I})$ （ $\mathbf{I}$ 是秩-2身份张量）代表空间维度， $\mathbf{F}$ 是变形梯度张量。为了给 $\psi_{0}$ 的各个组成部分提供一些简单的背景，前两个项与（超弹性）Neohookean材料的储能密度函数非常相似。这里使用的东西与Neohookean材料的唯一区别是弹性剪切模量被磁场敏感的饱和函数 $f_{\mu_{e}}
\left( \boldsymbol{\mathbb{H}} \right)$ 缩放（见 @cite Pelteret2018a ，公式29）。这个函数实际上将导致材料在强磁场的存在下变硬。由于它受一个sigmoid型函数的支配，剪切模量将渐进地收敛于指定的饱和剪切模量。还可以证明， $\psi_{0}$ 中的最后一项是磁场的储能密度函数（从第一原理中得出），由相对渗透率常数缩放。这个定义共同意味着材料是线性磁化的，也就是说，磁化矢量和磁场矢量是对齐的。(这在以电流形式陈述的磁能中当然不明显，但当磁感应和磁化从 $\psi_{0}$ 中导出，并且所有磁场都以 <em> 的电流配置 </em> 表示时，这种关联性就变得很清楚了)。至于磁感应、应力张量和各种材料切线的具体内容，我们将把这些内容推迟到教程正文中介绍，在那里定义了构成法的完整、无辅助的实施。

<h5>Magneto-viscoelastic constitutive law</h5>

我们将制定的第二个材料是一个具有单一耗散机制`i`的磁-粘弹性材料。我们将考虑的*自由能量密度函数*被定义为

@f{align*}{
  \psi_{0} \left( \mathbf{C}, \mathbf{C}_{v}, \boldsymbol{\mathbb{H}}
  \right)
&= \psi_{0}^{ME} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
+ \psi_{0}^{MVE} \left( \mathbf{C}, \mathbf{C}_{v},
\boldsymbol{\mathbb{H}} \right)
\\ \psi_{0}^{ME} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)
&= \frac{1}{2} \mu_{e} f_{\mu_{e}^{ME}} \left( \boldsymbol{\mathbb{H}}
\right)
    \left[ \text{tr}(\mathbf{C}) - d - 2 \ln (\text{det}(\mathbf{F}))
    \right]
+ \lambda_{e} \ln^{2} \left(\text{det}(\mathbf{F}) \right)


- \frac{1}{2} \mu_{0} \mu_{r} \text{det}(\mathbf{F})
    \left[ \boldsymbol{\mathbb{H}} \cdot \mathbf{C}^{-1} \cdot
    \boldsymbol{\mathbb{H}} \right]
\\ \psi_{0}^{MVE} \left( \mathbf{C}, \mathbf{C}_{v},
\boldsymbol{\mathbb{H}} \right)
&= \frac{1}{2} \mu_{v} f_{\mu_{v}^{MVE}} \left( \boldsymbol{\mathbb{H}}
\right)
    \left[ \mathbf{C}_{v} : \left[
      \left[\text{det}\left(\mathbf{F}\right)\right]^{-\frac{2}{d}}
      \mathbf{C} \right] - d - \ln\left(
      \text{det}\left(\mathbf{C}_{v}\right) \right)  \right]


@f}

与

@f[
  f_{\mu_{e}}^{ME} \left( \boldsymbol{\mathbb{H}} \right)
= 1 + \left[ \frac{\mu_{e}^{\infty}}{\mu_{e}} - 1 \right]
    \tanh \left( 2 \frac{\boldsymbol{\mathbb{H}} \cdot
    \boldsymbol{\mathbb{H}}}
      {\left(h_{e}^{\text{sat}}\right)^{2}} \right)


@f]



@f[
  f_{\mu_{v}}^{MVE} \left( \boldsymbol{\mathbb{H}} \right)
= 1 + \left[ \frac{\mu_{v}^{\infty}}{\mu_{v}} - 1 \right]
    \tanh \left( 2 \frac{\boldsymbol{\mathbb{H}} \cdot
    \boldsymbol{\mathbb{H}}}
      {\left(h_{v}^{\text{sat}}\right)^{2}} \right)


@f]

和进化法

@f[
  \dot{\mathbf{C}}_{v} \left( \mathbf{C} \right)
= \frac{1}{\tau} \left[
      \left[\left[\text{det}\left(\mathbf{F}\right)\right]^{-\frac{2}{d}}
        \mathbf{C}\right]^{-1}


    - \mathbf{C}_{v} \right]


@f]

为内部粘性变量。我们已经选择了能量的磁弹性部分 $\psi_{0}^{ME} \left( \mathbf{C}, \boldsymbol{\mathbb{H}} \right)$ 来匹配我们探索的第一个材料模型，所以这部分不需要进一步解释。至于粘性部分 $\psi_{0}^{MVE}$ ，自由能的这一部分（与粘性变形张量的演化规律一起）取自 @cite Linder2011a （由 @cite Pelteret2018a 中描述的粘性饱和函数进行额外缩放）。它是在一个热力学上一致的框架中得出的，其核心是在微观层面上模拟聚合物链的运动。

要超越这一点，我们还需要考虑进化规律的时间离散化。选择隐式一阶逆向差分方案，那么

@f[
  \dot{\mathbf{C}}_{v}
\approx \frac{\mathbf{C}_{v}^{(t)} - \mathbf{C}_{v}^{(t-1)}}{\Delta t}
= \frac{1}{\tau} \left[
      \left[\left[\text{det}\left(\mathbf{F}\right)\right]^{-\frac{2}{d}}
        \mathbf{C}\right]^{-1}


    - \mathbf{C}_{v}^{(t)} \right]


@f]

其中上标 $(t)$ 表示该数量是在当前时间步长中提取的， $(t-1)$ 表示在前一时间步长中提取的数量（即历史变量）。时间段大小 $\Delta t$ 是当前时间与上一时间段的差。将这些条款重新排列，使当前时间的所有内部变量量都在方程的左侧，我们可以得到

@f[
\mathbf{C}_{v}^{(t)}
= \frac{1}{1 + \frac{\Delta t}{\tau_{v}}} \left[
    \mathbf{C}_{v}^{(t-1)}
  + \frac{\Delta t}{\tau_{v}}
    \left[\left[\text{det}\left(\mathbf{F}\right)\right]^{-\frac{2}{d}}
    \mathbf{C} \right]^{-1}
  \right]


@f]

匹配 @cite Linder2011a 公式54。

<h3>Rheological experiment</h3>

现在我们已经展示了所有这些关于热力学和磁力学理论以及构成模型的公式，让我们概述一下这个程序将对所有这些做什么。我们希望对我们制定的材料定律做一些*有意义的事情，因此将它们置于一些机械和磁载荷条件下是有意义的，这些条件在某种程度上代表了在应用或实验室环境中可能发现的一些条件。实现这一目标的方法之一是将这些构成法则嵌入到有限元模型中，以模拟一个设备。不过，在这个例子中，我们将保持简单（毕竟我们关注的是自动和符号微分概念），并将找到一种简明的方法，使用加载条件的分析表达式忠实地复制工业标准的流变学实验。

我们将重现的流变学实验，它理想化了一个用于表征磁活性聚合物的实验室实验，详见 @cite Pelteret2018a （以及 @cite Pelteret2019a ，其中与真实世界的实验一起记录）。下面的图片提供了对问题设置的直观描述。

 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
    <td align="center">
        <img
        src="https://www.dealii.org/images/steps/developer/step-71.parallel_plate-geometry.png"
        alt="" height="300">
  <p align="center">
        The basic functional geometry of the parallel-plate rotational
        rheometer. The smooth rotor (blue) applies a torque to an
        experimental sample (red) of radius $r$ and height $H$ while an
        axially aligned magnetic field generated by a a
        magneto-rheological device. Although the time-dependent
        deformation profile of the may be varied, one common experiment
        would be to subject the material to a harmonic torsional
        deformation of constant amplitude and frequency $\omega$.
  </p>
    </td>
    <td align="center">
        <img
        src="https://www.dealii.org/images/steps/developer/step-71.parallel_plate-kinematics.png"
        alt="" height="300">
  <p align="center">
        Schematic of the kinematics of the problem, assuming no
        preloading or compression of the sample. A point $\mathbf{P}$
        located at azimuth $\Theta$ is displaced to location $\mathbf{p}$
        at azimuth $\theta = \Theta + \alpha$.
  </p>
    </td>
  </tr>
</table> 

假设正在测试的是不可压缩的介质，并且通过样品厚度的变形曲线是线性的，那么在样品内某个测量点 $\mathbf{X}$ 的位移，用径向坐标表示，就是

@f{align*}
  r(\mathbf{X})
  &= \frac{R(X_{1}, X_{2})}{\sqrt{\lambda_{3}}} , \\
  \theta(\mathbf{X})
  & = \Theta(X_{1}, X_{2}) + \underbrace{\tau(t)
       \lambda_{3} X_{3}}_{\alpha(X_{3}, t)} , \\
  z(\mathbf{X})
  &= \lambda_{3} X_{3}


@f}

其中 $R(X_{1}, X_{2})$ 和 $\Theta(X_{1}, X_{2})$ 是半径在

-- 的角度， $\lambda_{3}$ 是（恒定的）轴向变形， $\tau(t) = \frac{A}{RH} \sin\left(\omega t\right)$ 是每单位长度的随时间变化的扭转角，将使用固定振幅的正弦波重复振荡 $A$ 来规定。磁场是轴向排列的，即在 $X_{3}$ 方向。

这总结了我们在流变样品内任何一点上全面描述理想化载荷所需的一切。我们将以这样的方式设置问题，即我们在这个样品中 "挑选 "一个有代表性的点，并使其在恒定的轴向变形（默认为压缩载荷）和恒定的、轴向施加的磁场中受到谐波剪切变形。我们将记录该点的应力和磁感应强度，并将数据输出到文件中进行后处理。尽管对这个特定的问题来说没有必要，我们也将计算切线。尽管它们没有直接用于这个特定的工作，但这些二阶导数是在有限元模型中嵌入构成法所需要的（这项工作的一个可能的扩展）。因此，我们将利用这个机会，用辅助微分框架来检查我们的手工计算是否正确。

<h3>Suggested literature</h3>

除了已经提到的 @ref auto_symb_diff 模块外，以下是一些更详细讨论的参考资料

- 磁力学，以及自动分化框架的某些方面。   @cite Pao1978a  ,  @cite Pelteret2019a  , 和

- 使用AD和/或SD实现有限元框架的自动化：  @cite Logg2012a  ,  @cite Korelc2016a  。

 <br> 


examples/step-71/doc/results.dox



<h1>Results</h1>

<h3>Introductory example</h3>

第一个探索性的例子产生了以下输出。经核实，这三种实现方式产生的结果是相同的。

@code
> ./step-71
Simple example using automatic differentiation...
... all calculations are correct!
Simple example using symbolic differentiation.
... all calculations are correct!
@endcode



<h3>Constitutive modelling</h3>

为了帮助总结虚拟实验本身的结果，下面是一些图表，显示了材料样品内选定位置的剪切应力，与剪切应变的关系。这些图表显示了在三种不同的磁载荷下的应力-应变曲线，以及（机械）载荷曲线的最后一个周期，当速率依赖型材料达到可重复（"稳态"）响应时。这些类型的图表通常被称为[Lissajous plots](https://en.wikipedia.org/wiki/Lissajous_curve)。粘弹性材料的曲线所呈现的椭圆面积提供了某种衡量材料耗散能量多少的方法，其椭圆度表明粘性反应相对于弹性反应的相位变化。

 <table align="center" class="tutorial" cellspacing="3" cellpadding="3">
  <tr>
     <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-71.lissajous_plot-me.png" alt="" width="400">
	<p align="center">
        Lissajous plot for the magneto-elastic material.
	</p>
    </td>
    <td align="center">
        <img src="https://www.dealii.org/images/steps/developer/step-71.lissajous_plot-mve.png" alt="" width="400">
	<p align="center">
        Lissajous plot for the magneto-viscoelastic material.
	</p>
    </td>
  </tr>
</table> 

看到磁弹性材料的反应有一个与加载曲线相匹配的卸载曲线并不奇怪--毕竟该材料是非耗散性的。但在这里可以清楚地注意到，随着施加磁场的增加，曲线的梯度是如何增加的。沿着这条曲线任何一点的切线都与瞬时剪切模量有关，由于能量密度函数的定义方式，我们预计剪切模量会随着磁场强度的增加而增加。我们观察到磁-粘弹性材料的行为大致相同。由加载-卸载曲线追踪的椭圆的主轴有一个斜率，随着施加更大的磁载荷而增加。同时，材料耗散的能量也越多。

至于代码输出，这是打印到控制台的与磁弹性材料进行的流变学实验有关的部分的内容。

@code
Coupled magnetoelastic constitutive law using automatic differentiation.
Timestep = 0 @ time = 0s.
Timestep = 125 @ time = 0.314159s.
Timestep = 250 @ time = 0.628318s.
Timestep = 375 @ time = 0.942477s.
...
Timestep = 12250 @ time = 30.7876s.
Timestep = 12375 @ time = 31.1018s.
Timestep = 12500 @ time = 31.4159s.
... all calculations are correct!
@endcode



而这部分输出与用磁涡流材料进行的实验有关。

@code
Coupled magneto-viscoelastic constitutive law using symbolic differentiation.
Using LLVM optimizer.
Timestep = 0 @ time = 0s.
Timestep = 125 @ time = 0.314159s.
Timestep = 250 @ time = 0.628318s.
Timestep = 375 @ time = 0.942477s.
...
Timestep = 12250 @ time = 30.7876s.
Timestep = 12375 @ time = 31.1018s.
Timestep = 12500 @ time = 31.4159s.
... all calculations are correct!
@endcode



计时器的输出也被发射到控制台，因此我们可以比较进行手工计算和辅助计算所需的时间，并对使用AD和SD框架的开销有一些了解。下面是使用AD框架的磁弹性实验的时间，基于Trilinos库的Sacado组件。

@code
+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |       3.2s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assisted computation            |     12501 |      3.02s |        95% |
| Hand calculated                 |     12501 |    0.0464s |       1.5% |
+---------------------------------+-----------+------------+------------+
@endcode

关于使用自动微分进行的计算（作为提醒，这是使用Sacado库结合动态前向自动微分类型进行的两级微分），我们观察到辅助计算需要大约 $65 \times$ 的时间来计算所需的数量。这看起来确实是一个相当大的开销，但是，正如介绍中提到的，这是否可以接受，完全是主观的，取决于环境的。在对导数进行必要的手工计算、验证其正确性、实现它们以及验证实现的正确性方面，你是否更看重计算机时间而不是人的时间？如果你开发的研究代码只在相对较少的实验中运行，你可能更看重自己的时间。如果你开发的是一个将在万核集群上反复运行数小时的生产代码，你的考虑可能就不同了。在任何情况下，AD方法的一个很好的特点是，当函数和类在标量类型上被模板化时，有 "滴入 "能力。这意味着开始使用它需要付出最小的努力。

相比之下，使用准时制（JIT）编译的符号代数实现的磁涡弹材料的时间表明，在初始化过程中付出一些不可忽视的代价，计算本身的执行效率要高得多。

@code
+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      1.34s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assisted computation            |     12501 |     0.376s |        28% |
| Hand calculated                 |     12501 |     0.368s |        27% |
| Initialize symbolic CL          |         1 |     0.466s |        35% |
+---------------------------------+-----------+------------+------------+
@endcode

由于初始化阶段很可能只需要在每个线程中执行一次，这个初始的昂贵阶段可以通过重复使用一个 Differentiation::SD::BatchOptimizer 实例来抵消。尽管与磁弹性构成法相比，磁弹性构成法有更多的条款需要计算，但它在执行动能变量和切线的计算方面仍然快了一个数量级。而与使用缓存方案的手工计算变量相比，计算时间几乎相等。因此，尽管使用符号框架需要在如何实现和操作符号表达方面进行范式转变，但它可以提供AD框架所缺乏的良好性能和灵活性。

在数据缓存这一点上，事实上，在用这种材料进行的数值实验中，与使用中间值的实现相比，磁涡流材料实现的数值缓存所增加的成本大约是 $6\times$ ，在`update_internal_data()`中花费的时间增加。下面是删除缓存数据结构时为 "手工计算 "变体提取的时间比较样本输出。

@code
+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      1.01s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assisted computation            |     12501 |     0.361s |        36% |
| Hand calculated                 |     12501 |    0.0562s |       5.6% |
| Initialize symbolic CL          |         1 |     0.469s |        47% |
+---------------------------------+-----------+------------+------------+
@endcode



通过一些小的调整，我们可以很容易地测试批量优化器的不同优化方案。因此，让我们比较一下与 "LLVM "批处理优化器设置相关的计算费用和其他方案。下面是 "lambda "优化方法的时间报告（保留了CSE的使用）。

@code
+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      3.87s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assisted computation            |     12501 |      3.12s |        81% |
| Hand calculated                 |     12501 |     0.394s |        10% |
| Initialize symbolic CL          |         1 |     0.209s |       5.4% |
+---------------------------------+-----------+------------+------------+
@endcode

这里的主要观察结果是，与 "LLVM "方法相比，在 "辅助计算 "部分花费的时间要多一个数量级。

最后，我们将测试 "字典 "替换与CSE的结合情况。字典替换只是在本地CAS框架内进行了所有的评估，没有对底层数据结构进行任何转换。在这种情况下，只有使用缓存中间结果的CSE才能提供任何 "加速"。考虑到这一点，下面是这个选择的结果。

@code
+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |  1.54e+03s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assisted computation            |     12501 |  1.54e+03s |     1e+02% |
| Hand calculated                 |     12501 |     0.563s |         0% |
| Initialize symbolic CL          |         1 |     0.184s |         0% |
+---------------------------------+-----------+------------+------------+
@endcode

不用说，与其他两种方法相比，这些结果花了相当多的时间来产生......字典 "替换方法也许只适用于简单的表达式，或者当调用的数量足够少的时候。

<h1>So, which framework should I use?</h1>

也许你已经相信这些工具有一些优点，并能对你有直接的帮助或用途。现在明显的问题是要使用哪一个。特别是在连续点水平上，你将使用这些框架来计算构成法的导数，我们可以说以下几点。

- 自动区分可能提供了进入辅助区分世界的最简单的切入点。

- 考虑到一个构成框架的足够通用的实现，AD通常可以被用作内在标量类型的替代品，然后可以利用辅助类来计算一阶（以及可能的高阶）导数，只需付出最小的努力。

- 作为对上述观点的限定，"直接替换 "并不意味着你必须对这些数字所通过的算法不持争议态度。有可能在不经意间进行的操作，在进行区分时，会返回一个错误的结果。   所以这绝对是一个人应该注意的事情。   一个具体的例子。当计算一个张量的特征值时，如果该张量是对角线的，那么得到结果的捷径就是直接返回对角线条目（从输入张量中提取的）。就计算特征值本身而言，这是完全正确的，但是不通过算法来计算非对角线张量的特征值会产生意想不到的副作用，即特征值看起来（对AD框架而言）是完全相互脱钩的，它们的交叉敏感度没有被编码在返回的结果中。在进行微分时，导数张量的许多条目将被丢失。为了解决这个问题，我们必须确保使用标准的特征值求解算法，这样返回的特征值对彼此的敏感性就会在结果中得到编码。

- 涉及AD数字类型的计算可能很昂贵。随着微分运算顺序的增加，费用也会增加（有时相当可观）。这可能会被周围操作的计算复杂性所缓解（例如线性求解），但最终还是要看具体问题。

- AD被限制在只需要总导数的情况下。如果一个微分运算需要相对于自变量的偏导，那么使用它是不合适的。

- 每个AD库都有自己的怪癖（说起来很悲哀，但根据作者的经验，是真的），所以可能需要一些试验和错误来找到合适的库和选择AD号来满足你的目的。这些 "怪癖 "的原因往往归结于库背后的整体理念（数据结构、模板元编程的使用等）以及导数计算的数学实现（例如，使用对数函数改变基础的结果操作可能会限制输入值的域--当然，细节都是对用户隐藏的）。   此外，一个库可能比另一个库能更快地计算出所需的结果，所以在这方面进行一些初步探索可能是有益的。

- 符号微分（好吧，一般来说，使用CAS）提供了最灵活的框架，可以进行辅助计算。

- SD框架可以做AD框架能做的所有事情，还有一个好处是可以对何时进行某些操纵和操作进行低层次控制。

- 加速表达式的评估是可能的，与一些手工实现相比，有可能导致SD框架接近原生的性能（当然，这种比较取决于整个程序设计），但代价是初始优化调用。

- 巧妙地使用 Differentiation::SD::BatchOptimizer 可以将优化依赖表达式的昂贵调用的费用降到最低。   对 Differentiation::SD::BatchOptimizer 进行序列化的可能性，往往（但不总是）这种昂贵的调用可以做一次，然后在以后的模拟中重复使用。

- 例如，如果两个或更多的材料法只因其材料参数而不同，那么只要这些材料参数被认为是象征性的，就可以在它们之间共享一个批次优化器。这意味着你可以 "区分一次，在许多情况下评估"。

- SD框架可以部分地被用作标量类型的 "直接替换"，但人们（至少）必须在它周围增加一些框架来执行值替换步骤，将符号类型转换为它们的数字对应物。

- 在一些专门的算法中可能无法使用SD数字。   例如，如果一个算法的退出点或代码分支是基于（符号）输入参数应该采取的一些具体的数值，那么显然这是不可能的。我们要么重新实现专门针对SD数字类型的算法（有点不方便，但经常是可能的，因为 Differentiation::SD::Expression 类支持条件反射），要么必须使用创造性的手段来解决这个具体问题（例如，引入一个符号表达式来表示这个算法返回的结果，如果在要使用它的环境中是有意义的，也许可以将它声明为一个[符号函数]（https://dealii.org/developer/doxygen/deal.II/namespaceDifferentiation_1_1SD.html#a876041f6048705c7a8ad0855cdb1bd7a）。这以后可以用它的数值来替代，如果宣布为符号函数，那么它的递延导数也可以作为替代的结果纳入计算中。)

- 使用SD的最大缺点是，使用它需要一个范式的转变，人们必须以不同的方式来构建大多数问题，以便充分利用它。仔细考虑如何使用和重用数据结构也是让它有效工作的关键）。这可能意味着，人们需要对它进行一番玩耍，并建立起对典型操作顺序的理解，以及每一步在操作基础数据方面的具体作用。如果人们有时间和意愿这样做，那么使用这个工具的好处可能是巨大的。

<h1>Possibilities for extension</h1>

有几个合乎逻辑的方法可以扩展这个计划。

- 也许最明显的扩展是实施和测试其他构成模型。   这可能仍然属于磁-机械耦合问题的范畴，也许可以考虑替代能量函数的 "Neo-Hookean "型弹性部分，改变耗散能量的构成法则（及其相关的演化法则），或者包括磁滞效应或这些材料试图模拟的复合聚合物的损坏模型。

- 当然，所实现的模型可以被修改或完全替换为专注于物理学其他方面的模型，如电活性聚合物、生物力学材料、弹塑性介质等。

- 对粘弹性演化法实施不同的时间微调方案。

- 与其直接从能量密度函数推导出一切，不如使用 Differentiation::AD::VectorFunction 直接线性化动力学量。   这将意味着只需要一个可微分的自动微分的数字类型，并且肯定会大大改善性能。   这种方法也为耗散材料提供了机会，比如这里考虑的磁涡弹材料，可以与AD结合起来实现。这是因为线性化调用了因变量相对于场变量的总导数，这正是AD框架所能提供的。

- 调查使用其他可自动微分的数字类型和框架（如ADOL-C）。由于每个AD库都有自己的实现，选择使用哪个库可能会导致性能的提高，在最不幸的情况下，计算也会更加稳定。至少可以说，对于deal.II支持的AD库，结果的准确性应该基本不受这个决定的影响。

- 在有限元模拟中嵌入这些构成法则中的一个。

如果不费吹灰之力，人们可以考虑重新编写非线性问题求解器，比如在步骤15中实现的使用AD或SD方法来计算牛顿矩阵的求解器。事实上，这在第72步中已经完成。


examples/step-72/doc/intro.dox

 <br> 

<i>This program was contributed by Jean-Paul Pelteret and Wolfgang Bangerth.


Wolfgang Bangerth's work is partially supported by National Science
Foundation grants OCI-1148116, OAC-1835673, DMS-1821210, and EAR-1925595;
and by the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation under
Award No. EAR-1550901 and The University of California-Davis.
</i>




<h1>Introduction</h1>

<h3>Motivation</h3>

这个程序解决的问题与步骤15相同，即求解[最小表面方程](https://en.wikipedia.org/wiki/Minimal_surface) @f{align*}
    F(u) \dealcoloneq -\nabla \cdot \left( \frac{1}{\sqrt{1+|\nabla u|^{2}}}\nabla u \right) &= 0 \qquad
    \qquad &&\textrm{in} ~ \Omega
    \\
    u&=g \qquad\qquad &&\textrm{on} ~ \partial \Omega.
  @f}



我们在那里发现的问题（见<a href="step_15#extensions">Possibilities for extensions</a>部分）是，当想要使用牛顿迭代时，我们需要计算方程残差对解的导数 $u$ （这里，因为右手边是零，残差只是左手边）。对于我们这里的方程来说，这很麻烦，但并非不可能 -- 但我们很容易想象出更复杂的方程，仅仅正确实现残差本身就是一个挑战，更不用说为计算雅各布矩阵所需的导数而这样做。我们将在这个程序中解决这个问题。使用在步骤-71中详细讨论的自动微分技术，我们将想出一个办法，我们只需要实现残差，就可以免费得到雅各布矩阵。

事实上，我们甚至可以更进一步。虽然在第15步中，我们只是把方程作为一个给定值，但最小表面方程实际上是最小化一个能量的产物。具体来说，最小曲面方程是对应于最小化能量的欧拉-拉格朗日方程@f[
    E(u) = \int_\Omega \Psi \left( u \right)
  @f]

其中*能量密度*由@f[
    \Psi \left( u \right) = \sqrt{1+|\nabla u|^{2}}.
  @f]给出。

这等于说，我们寻求找到能量函数变化的静止点@f[
    \min\limits_{u} E \left( u \right)
      \quad \rightarrow \quad
      \delta E \left( u, \varphi \right) \dealcoloneq
      \left(\varphi, F(u)\right) = 0
      \qquad
      \forall \varphi,
  @f] 。

因为这是边界值问题的平衡解所在。

那么关键的一点是，也许，我们甚至不需要实现残差，但实现更简单的能量密度 $\Psi(u)$ 可能实际上已经足够了。

那么我们的目标是这样的。当使用牛顿迭代时，我们需要反复解决线性偏微分方程@f{align*}
    F'(u^{n},\delta u^{n}) &=- F(u^{n})
  @f}。

这样我们就可以计算出更新@f{align*}
    u^{n+1}&=u^{n}+\alpha^n \delta u^{n}
  @f}。

与牛顿步骤的解 $\delta u^{n}$ 。正如步骤15所讨论的，我们可以用手计算导数 $F'(u,\delta u)$ ，得到@f[
  F'(u,\delta u)
  =


  - \nabla \cdot \left( \frac{1}{\left(1+|\nabla u|^{2}\right)^{\frac{1}{2}}}\nabla
  \delta u \right) +
  \nabla \cdot \left( \frac{\nabla u \cdot
  \nabla \delta u}{\left(1+|\nabla u|^{2}\right)^{\frac{3}{2}}} \nabla u
  \right).
  @f]。



那么，这里就是这个计划的内容。它是关于可以帮助我们计算 $F'(u,\delta u)$ 的技术，而不必明确地实现它，要么提供 $F(u)$ 的实现，要么提供 $E(u)$  的实现。更确切地说，我们将实现三种不同的方法，并在运行时间方面进行比较，但同时--也许更重要的是--实现这些方法需要多少人力。

- 第15步中使用的方法，形成雅各布矩阵。

- 从残差 $F(u)$ 的实现中计算雅各布矩阵，使用自动微分法。

- 从能量函数 $E(u)$ 的实现中计算残差和雅各布矩阵，也使用自动微分法。

对于这些方法中的第一个，与步骤15相比，没有任何概念上的变化。




<h3> Computing the Jacobian from the residual </h3>

对于第二种方法，让我们概述一下我们将如何利用自动微分来计算残差向量的线性化。为此，让我们暂时改变一下符号，用 $F(U)$ 表示的不是微分方程的残差，而实际上是*残差向量*，即*离散残差。我们这样做是因为当我们在给定的网格上对问题进行离散时，这就是我们*实际*做的事情。我们解决 $F(U)=0$ 问题，其中 $U$ 是未知数的矢量。

更准确地说，残差的 $i$ th分量由以下公式给出

@f[
  F(U)_i \dealcoloneq
  \int\limits_{\Omega}\nabla \varphi_i \cdot \left[ \frac{1}{\sqrt{1+|\nabla
  u|^{2}}} \nabla u \right] \, dV ,


@f]

其中 $u(\mathbf x)=\sum_j U_j \varphi_j(\mathbf x)$  。鉴于此，单元格 $K$ 的贡献是

@f[
  F(U)_i^K \dealcoloneq
  \int\limits_K\nabla \varphi_i \cdot \left[ \frac{1}{\sqrt{1+|\nabla
  u|^{2}}} \nabla u \right] \, dV ,


@f]

它的一阶泰勒展开为

@f[
  F(U + \delta U)_i^K
  \approx F(U)_i^K
  + \sum_{j}^{n_{\textrm{dofs}}} \left[ \frac{\partial F(U)_i^K}{\partial
  U_j} \delta U_j \right],


@f]

因此我们可以计算出 $K$ 单元格对雅各布矩阵 $J$ 的贡献为 $J(U)_{ij}^K = \frac{\partial F(U)_i^K}{\partial U_j}$  。这里重要的一点是，在单元格 $K$ 上，我们可以表示为

@f[
  F(U)_i^K \dealcoloneq
  \int\limits_K\nabla \varphi_i \cdot \left[ \frac{1}{\sqrt{1+\left|
  \sum_{j'}^{n_\textrm{dofs}} U_{j'} \nabla \varphi_{j'}\right|^{2}}}
  \left(\sum_{j''}^{n_\textrm{dofs}} U_{j''} \nabla \varphi_{j''}\right)\right] \, dV.


@f]

为了清楚起见，我们用 $j'$ 和 $j''$ 作为计数索引，以明确它们彼此之间以及与上述 $j$ 的区别。因为在这个公式中， $F(U)$ 只取决于系数 $U_j$ ，我们可以通过自动微分 $F(U)_i^K$ 来计算导数 $J(U)_{ij}^K$ 作为一个矩阵。通过我们一直使用的相同论证，很明显 $F(U)^K$ 实际上并不依赖于*所有*未知数 $U_j$ ，而只是依赖于 $j$ 是住在单元格 $K$ 的形状函数的那些未知数。] ，因此在实践中，我们将 $F(U)^K$ 和 $J(U)^K$ 限制为矢量和矩阵中对应于*本地*DoF指数的部分，然后从本地单元 $K$ 分布到全球对象。

使用所有这些实现，然后的方法将是在程序中实现 $F(U)^K$ ，并让自动微分机械从中计算导数 $J(U)^K$ 。




<h3> Computing the Jacobian and the residual from the energy functional </h3>

对于装配过程的最终实现，我们将比残差高一个层次：我们的整个线性系统将直接由支配这个边界值问题的物理学的能量函数决定。我们可以利用这样一个事实：我们可以直接从局部贡献中计算出域中的总能量，即。

@f[
  E \left( U \right) \dealcoloneq \int\limits_{\Omega} \Psi \left( u
  \right) \, dV .


@f]

在离散设置中，这意味着在每个有限元上我们有

@f[
   E \left( U \right)^K
    \dealcoloneq \int\limits_{K} \Psi \left( u \right) \, dV
    \approx \sum\limits_{q}^{n_{\textrm{q-points}}} \Psi \left( u \left(
    \mathbf{x}_{q} \right) \right) \underbrace{\vert J_{q} \vert \times W_{q}}_{\text{JxW(q)}} .


@f]

如果我们实现细胞能量，它取决于场解，我们可以计算它的第一个（离散）变化

@f[
  F(U)^K_i
    = \frac{\partial E(U)^K}{\partial U_i}


@f]

此后，它的第二个（离散）变化

@f[
  J(U)^K_{ij}
    = \frac{\partial^{2}  E(U)^K}{\partial U_i \partial U_j}.


@f]

因此，从单元格对总能量函数的贡献来看，只要我们能够提供局部能量的实现，我们就可以期望为我们生成近似的残差和正切贡献  $E(U)^K$  。同样，由于本教程中使用的自动微分变量的设计，在实践中，这些对残差向量和正切矩阵贡献的近似值实际上是精确到机器精度的。


examples/step-72/doc/results.dox



<h1>Results</h1>

由于在步骤15中首先分析的问题的物理学没有变化，所以没有什么可报告的。它们之间唯一外显的区别是，在默认情况下，这个程序只运行9个网格细化步骤（相对于第15步，执行11个细化）。这可以从模拟状态中观察到，该状态出现在打印出正在使用的装配方法的标题文本和最终的时间。下面报告的所有时间都是在发布模式下获得的）。

@code
Mesh refinement step 0
  Initial residual: 1.53143
  Residual: 1.08746
  Residual: 0.966748
  Residual: 0.859602
  Residual: 0.766462
  Residual: 0.685475


...


Mesh refinement step 9
  Initial residual: 0.00924594
  Residual: 0.00831928
  Residual: 0.0074859
  Residual: 0.0067363
  Residual: 0.00606197
  Residual: 0.00545529
@endcode



因此，我们感兴趣的是比较三种不同实现方式的装配过程需要多长时间，并把它放到更大的背景中。下面是手部线性化的输出结果（在2012年左右的四核八线程笔记本电脑上计算的结果--但我们真正感兴趣的只是不同实现方式之间的相对时间）。

@code
******** Assembly approach ********
Unassisted implementation (full hand linearization).


...


+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      35.1s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble                        |        50 |      1.56s |       4.5% |
| Solve                           |        50 |      30.8s |        88% |
+---------------------------------+-----------+------------+------------+
@endcode

而对于使用萨卡多动态正向AD数字类型，以自动方式将残差线性化的实施。

@code
******** Assembly approach ********
Automated linearization of the finite element residual.


...


+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      40.1s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble                        |        50 |       8.8s |        22% |
| Solve                           |        50 |      28.6s |        71% |
+---------------------------------+-----------+------------+------------+
@endcode

最后，对于直接从能量函数（使用嵌套的Sacado动态前向AD数）计算残差和其线性化的实现。

@code
******** Assembly approach ********
Automated computation of finite element residual and linearization using a variational formulation.


...


+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      48.8s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble                        |        50 |      16.7s |        34% |
| Solve                           |        50 |      29.3s |        60% |
+---------------------------------+-----------+------------+------------+
@endcode



很明显，交给自动分化框架执行的工作越多，在装配过程中花费的时间就越多。在所有细化步骤中累积起来，与无辅助装配相比，使用一级自动微分导致在装配阶段花费了 $5.65 \times$ 的计算时间，而直接从能量函数推导时，装配离散线性系统花费了 $10.7 \times$ 的时间。不足为奇的是，解决线性系统的总体时间保持不变。这意味着，随着在有限元水平上进行自动微分的次数的增加，花在求解阶段的时间与装配阶段的时间比例发生了明显的转变。对许多人来说，这可能意味着在生产代码中利用高阶微分（在有限元水平）会导致不可接受的开销，但在原型设计阶段，它可能仍然有用。因此，两者之间的一个很好的折衷办法是有限元残差的自动线性化，它以可衡量的、但也许不是不可接受的成本提供了很多便利。另外，我们可以考虑不在每一步中重新建立牛顿矩阵--这个主题在步骤77中有大量的深入探讨。

当然，在实践中，实际的开销在很大程度上取决于被评估的问题（例如，解决方案中有多少成分，被微分的函数的性质是什么，等等）。因此，这里提出的确切结果应该仅在这个标量问题的背景下进行解释，当涉及到其他问题时，用户肯定需要进行一些初步调查。




<h3> Possibilities for extensions </h3>

与步骤-71一样，有几个与自动区分有关的项目可以进一步评估。

- 应调查其他AD框架的使用情况，并展望其他实施方式可能提供性能优势。

- 除了本教程中硬编码的数字类型外，还值得对AD数字类型进行评估。关于在有限元水平上采用的两次微分类型，混合微分模式（"RAD-FAD"）原则上应该比这里采用的单一模式（"FAD-FAD"）类型的计算效率更高。RAD-FAD类型没有被默认选择的原因是，在撰写本文时，在Sacado库中，它的实现仍然存在一些错误，导致内存泄漏。   这在 @ref auto_symb_diff 模块中有所记载。

- 也许使用低精度类型（即 "浮动"）作为AD数字的标量类型可以减少装配时的计算费用。使用 "float "作为矩阵和残差的数据类型并不是不合理的，因为牛顿更新只是为了让我们更接近解决方案，而不是实际*到解决方案；因此，考虑使用降低精度的数据类型来计算这些更新，然后将这些更新累积到使用全 "双 "精度的解决方案向量中，是有意义的。

- 在装配过程中可能减少资源的另一个方法是将AD的实现作为一个构成模型。这类似于步骤71中采用的方法，并将自动微分的起点推到了计算链的上一级。这反过来意味着AD库跟踪的操作更少，从而降低了微分的成本（尽管我们会在每个单元的正交点进行微分）。

- 第77步是第15步的另一个变化，解决了问题的一个非常不同的部分：直线搜索以及是否有必要在每次非线性迭代中重新建立牛顿矩阵。鉴于上述结果表明，使用自动微分是有代价的，第77步的技术有可能在一定程度上抵消这些代价。因此，将目前的程序与第77步中的技术结合起来是相当有趣的。对于生产代码来说，这肯定是个好办法。


examples/step-74/doc/intro.dox

 <br> 

<i>
This program was contributed by Timo Heister and Jiaqi Zhang.
<br>
This material is based upon work partly supported by the National
Science Foundation Award DMS-2028346, OAC-2015848, EAR-1925575, by the Computational
Infrastructure in Geodynamics initiative (CIG), through the NSF under Award
EAR-0949446 and EAR-1550901 and The University of California -- Davis.
</i>


<a name="Intro"></a>

<h1><em>Symmetric interior penalty Galerkin</em> (SIPG) method for Poisson's equation</h1>

<h3>Overview</h3> 在本教程中，我们展示了FEInterfaceValues类的用法，该类是为组装由不连续加尔金（DG）方法产生的面项而设计的。FEInterfaceValues类提供了一种简单的方法来获得形状函数的跳变和平均值以及跨单元面的解。本教程包括以下内容。<ol>  <li>  泊松方程的SIPG方法，在步骤39和步骤59中已经使用过。     <li>  使用FEInterfaceValues组装面项，使用 MeshWorker::mesh_loop(), 组装系统矩阵，这与步骤12类似。     <li>  使用误差估计器进行自适应网格细化。     <li>  两个测试案例：平滑函数的收敛测试和奇异解的适应性网格细化测试。   </ol> 

<h3>The equation</h3> 在这个例子中，我们考虑泊松方程

@f[


- \nabla \cdot \left( \nu  \nabla u\right) = f  \qquad   \mbox{in } \Omega,


@f]

受制于边界条件

@f[
u = g_D \qquad \mbox{on } \partial \Omega.


@f]

为了简单起见，我们假设扩散系数 $\nu$ 在这里是常数。注意，如果 $\nu$ 是不连续的，我们在计算单元面的跳跃项时需要考虑到这一点。

我们用 ${\mathbb T}_h$ 表示网格， $K\in{\mathbb T}_h$ 是一个网格单元。内部和边界面的集合分别用  ${\mathbb F}^i_h$  和  ${\mathbb F}^b_h$  表示。让 $K^0$ 和 $K^1$ 是共享一个面 $f\in F_h^i$ 的两个单元， $\mathbf n$ 是 $K^0$ 的外法向量。那么跳跃算子由 "这里减去那里 "公式给出。

@f[
\jump{v} = v^0 - v^1


@f]

和平均运算符为

@f[
\average{v} = \frac{v^0 + v^1}{2}


@f]

分别。请注意，当 $f\subset \partial \Omega$ 时，我们定义 $\jump{v} = v$ 和 $\average{v}=v$  。使用SIPG的离散化由以下弱式给出（更多细节可以在 @cite di2011mathematical 和其中的参考文献中找到）。

@f{align*}
&\sum_{K\in {\mathbb T}_h} (\nabla v_h, \nu \nabla u_h)_K\\
&-\sum_{F \in F_h^i} \left\{
    \left< \jump{v_h}, \nu\average{ \nabla u_h} \cdot  \mathbf n \right>_F
   +\left<\average{ \nabla v_h }\cdot \mathbf n,\nu\jump{u_h}\right>_F


   -\left<\jump{v_h},\nu \sigma \jump{u_h} \right>_F
  \right\}\\
&-\sum_{F \in F_h^b} \left\{
    \left<v_h, \nu  \nabla u_h\cdot \mathbf n \right>_F
  + \left< \nabla v_h \cdot \mathbf n , \nu u_h\right>_F


  - \left< v_h,\nu \sigma u_h\right>_F
  \right\}\\
&=(v_h, f)_\Omega


  - \sum_{F \in F_h^b} \left\{
    \left< \nabla v_h \cdot \mathbf n, \nu g_D\right>_F - \left<v_h,\nu \sigma g_D\right>_F
  \right\}.


@f}






<h3>The penalty parameter</h3> 惩罚参数定义为  $\sigma = \gamma/h_f$  ，其中  $h_f$  是与细胞面相关的局部长度尺度；这里我们选择细胞在面的法线方向的长度近似值。   $\frac 1{h_f} = \frac 12 \left(\frac 1{h_K} + \frac 1{h_{K'}}\right)$  ，其中 $K,K'$ 是与面相邻的两个单元 $f$ ，我们我们计算 $h_K = \frac{|K|}{|f|}$  。

在上述公式中， $\gamma$  是惩罚常数。为了确保离散矫捷性，惩罚常数必须足够大  @cite ainsworth2007posteriori  。对于文献中提出的哪些公式应该被使用，人们并没有真正达成共识。这与第47步的 "结果 "部分讨论的情况类似）。人们可以直接挑选一个大的常数，而其他选择可以是 $(p+1)^2$ 或 $p(p+1)$ 的倍数。在这段代码中，我们遵循步骤39，使用 $\gamma = p(p+1)$  。




<h3>A posteriori error estimator</h3> 在这个例子中，稍作修改，我们使用Karakashian和Pascal的误差估计器 @cite karakashian2003posteriori  。

@f[
\eta^2 = \sum_{K \in {\mathbb T}_h} \eta^2_{K} +  \sum_{f_i \in {\mathbb F}^i_h}  \eta^2_{f_i} + \sum_{f_b \in F^i_b}\eta^2_{f_b}


@f]

其中

@f{align*}{
\eta^2_{K} &= h_K^2 \left\| f + \nu \Delta u_h \right\|_K^2,
\\
\eta^2_{f_i} &= \sigma \left\| \jump{u_h}  \right\|_f^2   +  h_f \left\|  \jump{\nu \nabla u_h} \cdot \mathbf n   \right\|_f^2,
\\
\eta_{f_b}^2 &=  \sigma \left\| u_h-g_D \right\|_f^2.


@f}

这里我们用 $\sigma = \gamma/h_f$ 代替 $\gamma^2/h_f$ 来表示 $u_h$ 的跳跃项（ $\eta^2_{f_i}$ 和 $\eta_{f_b}^2$ 的第一个项）。

为了计算这个估计值，在每个单元格 $K$ 中，我们计算出

@f{align*}{
\eta_{c}^2 &= h_K^2 \left\| f + \nu \Delta u_h \right\|_K^2,
\\
\eta_{f}^2 &= \sum_{f\in \partial K}\lbrace \sigma \left\| \jump{u_h}  \right\|_f^2   +  h_f \left\|  \jump{\nu \nabla u_h} \cdot \mathbf n  \right\|_f^2 \rbrace,
\\
\eta_{b}^2 &= \sum_{f\in \partial K \cap \partial \Omega}  \sigma \left\| (u_h -g_D)  \right\|_f^2.


@f}

那么每个单元的误差估计的平方是

@f[
\eta_\text{local}^2 =\eta_{c}^2+0.5\eta_{f}^2+\eta_{b}^2.


@f]

 $0.5$ 的系数是由于整体误差估计器只包括每个内部面一次，所以每个单元的估计器对它的计算是相邻两个单元的一半系数。注意，我们计算 $\eta_\text{local}^2$ 而不是 $\eta_\text{local}$ 以简化实现。然后，每个单元的误差估计方被存储在一个全局向量中，其 $l_1$ 准则等于 $\eta^2$  。

<h3>The test case</h3> 在第一个测试问题中，我们使用二维的 $\nu =1$ 平滑制造的解决方案来进行收敛测试

@f{align*}{
u&=\sin(2\pi x)\sin(2\pi y), &\qquad\qquad &(x,y)\in\Omega=(0,1)\times (0,1),
\\
u&=0,                        &\qquad\qquad &\text{on } \partial \Omega,


@f}

和 $f= 8\pi^2 u$  。我们针对制造的解决方案计算误差并评估收敛率。

在第二个测试中，我们在二维的L形域 Functions::LSingularityFunction 上选择 (GridGenerator::hyper_L) 。该解在极坐标中由 $u(r,\phi) = r^{\frac{2}{3}}\sin \left(\frac{2}{3}\phi \right)$ 给出，它在原点有一个奇点。构建了一个误差估计器来检测有大误差的区域，根据这个估计器来自适应地细化网格。


examples/step-74/doc/results.dox



<h1>Results</h1>

该程序的输出包括控制台输出和vtu格式的解决方案。

在第一个测试案例中，当你运行程序时，屏幕输出应该如下。

@code
Cycle 0
  Number of active cells       : 16
  Number of degrees of freedom : 256
  Error in the L2 norm         : 0.00193285
  Error in the H1 seminorm     : 0.106087
  Error in the energy norm     : 0.150625


Cycle 1
  Number of active cells       : 64
  Number of degrees of freedom : 1024
  Error in the L2 norm         : 9.60497e-05
  Error in the H1 seminorm     : 0.0089954
  Error in the energy norm     : 0.0113265


Cycle 2
.
.
.
@endcode



当使用多项式度数为3的光滑情况时，收敛表会是这样的。   <table align="center" class="doxtable">
  <tr>
    <th>cycle</th>
    <th>n_cellss</th>
    <th>n_dofs</th>
    <th>L2 </th>
    <th>rate</th>
    <th>H1</th>
    <th>rate</th>
    <th>Energy</th>
  </tr>
  <tr>
    <td align="center">0</td>
    <td align="right">16</td>
    <td align="right">256</td>
    <td align="center">1.933e-03</td>
    <td>&nbsp;</td>
    <td align="center">1.061e-01</td>
    <td>&nbsp;</td>
    <td align="center">1.506e-01</td>
  </tr>
  <tr>
    <td align="center">1</td>
    <td align="right">64</td>
    <td align="right">1024</td>
    <td align="center">9.605e-05</td>
    <td align="center">4.33</td>
    <td align="center">8.995e-03</td>
    <td align="center">3.56</td>
    <td align="center">1.133e-02</td>
  </tr>
  <tr>
    <td align="center">2</td>
    <td align="right">256</td>
    <td align="right">4096</td>
    <td align="center">5.606e-06</td>
    <td align="center">4.10</td>
    <td align="center">9.018e-04</td>
    <td align="center">3.32</td>
    <td align="center">9.736e-04</td>
  </tr>
  <tr>
    <td align="center">3</td>
    <td align="right">1024</td>
    <td align="right">16384</td>
    <td align="center">3.484e-07</td>
    <td align="center">4.01</td>
    <td align="center">1.071e-04</td>
    <td align="center">3.07</td>
    <td align="center">1.088e-04</td>
  </tr>
  <tr>
    <td align="center">4</td>
    <td align="right">4096</td>
    <td align="right">65536</td>
    <td align="center">2.179e-08</td>
    <td align="center">4.00</td>
    <td align="center">1.327e-05</td>
    <td align="center">3.01</td>
    <td align="center">1.331e-05</td>
  </tr>
  <tr>
    <td align="center">5</td>
    <td align="right">16384</td>
    <td align="right">262144</td>
    <td align="center">1.363e-09</td>
    <td align="center">4.00</td>
    <td align="center">1.656e-06</td>
    <td align="center">3.00</td>
    <td align="center">1.657e-06</td>
  </tr>
</table> 

理论上，对于多项式度数 $p$ ， $L_2$ 规范和 $H^1$ 半规范的收敛顺序应该是 $p+1$ 和 $p$ ，分别。我们的数值结果与理论有很好的一致性。

在第二个测试案例中，当你运行该程序时，屏幕输出应该如下。

@code
Cycle 0
  Number of active cells       : 192
  Number of degrees of freedom : 3072
  Error in the L2 norm         : 0.000323585
  Error in the H1 seminorm     : 0.0296202
  Error in the energy norm     : 0.0420478
  Estimated error              : 0.136067


Cycle 1
  Number of active cells       : 249
  Number of degrees of freedom : 3984
  Error in the L2 norm         : 0.000114739
  Error in the H1 seminorm     : 0.0186571
  Error in the energy norm     : 0.0264879
  Estimated error              : 0.0857186


Cycle 2
.
.
.
@endcode



下图提供了L型域上该测试案例的误差与自由度数的对数图。为了解释它，让 $n$ 为自由度数，那么在均匀细化的网格上， $h$ 在二维中为 $1/\sqrt{n}$ 阶。结合前面的理论结果，我们可以看到，如果解足够光滑，我们可以预期 $L_2$ 准则的误差为 $O(n^{-\frac{p+1}{2}})$ 阶， $H^1$ 半准则的误差为 $O(n^{-\frac{p}{2}})$  。先验地，我们并不清楚在像我们用于第二个测试案例的自适应细化网格上是否会得到与 $n$ 的函数相同的行为，但我们当然可以希望。事实上，从图中我们看到，带有自适应网格细化的SIPG产生了渐进式的希望的结果。

 <img width="600px" src="https://www.dealii.org/images/steps/developer/step-74.log-log-plot.png" alt=""> 

此外，我们观察到误差估计器的下降速度几乎与能量准则和 $H^1$ 半准则的误差相同，并且比 $L_2$ 的误差低一阶。这表明它有能力预测具有较大误差的区域。

虽然本教程侧重于实现，但step-59教程程序在计算时间上用无矩阵求解技术实现了一个高效的大规模求解器。需要注意的是，step-59教程目前不能用于包含悬空节点的网格，因为多网格界面矩阵不那么容易确定，但这仅仅是deal.II中一些界面的缺乏，没有什么根本性的问题。


examples/step-75/doc/intro.dox

 <br> 

<i>This program was contributed by Marc Fehling, Peter Munch and
Wolfgang Bangerth.
<br>
This material is based upon work partly supported by the National
Science Foundation under Award No. DMS-1821210, EAR-1550901, and
OAC-1835673. Any opinions, findings, and conclusions or recommendations
expressed in this publication are those of the authors and do not
necessarily reflect the views of the National Science Foundation.
<br>
Peter Munch would like to thank Timo Heister, Martin Kronbichler, and
Laura Prieto Saavedra for many very interesting discussions.
</i>




 @note  作为这个程序的先决条件，你需要安装p4est库和Trilinos库。在<a
href="../../readme.html" target="body">README</a>文件中描述了deal.II与这些附加库的安装情况。




<a name="Intro"></a>

<h1>Introduction</h1>

在有限元背景下，更多的自由度通常会产生一个更精确的解决方案，但也需要更多的计算工作。

在以前的整个教程中，我们找到了通过将网格分辨率与解的复杂性进行局部调整来有效分配自由度的方法（自适应网格细化，步骤6）。如果我们不仅单独调整网格，而且还局部调整每个单元上相关有限元的多项式程度，这种方法就特别有效（hp-adaptation，第27步）。

此外，分配更多的进程同时运行你的程序有助于在更短的时间内解决计算工作量。根据你的机器的硬件结构，你的程序必须为所有进程都能访问相同的内存（共享内存，第18步），或者进程被托管在几个独立的节点上（分布式内存，第40步）这种情况做好准备。

在高性能计算部分，内存访问变成了当前超级计算机的瓶颈。我们可以通过使用MatrixFree方法（第37步）来计算矩阵-向量乘积的效果，从而完全避免存储矩阵。它们可以用于几何多网格方法（步骤50），也可以用于多项式多网格方法，以极大地加快方程组的求解速度。

本教程结合所有这些特点，介绍了如何解决一个简单的拉普拉斯问题的最先进的方法：在具有分布式内存的机器上利用hp-适应和无矩阵混合多网格方法。




<h3>Load balancing</h3>

对于有限元的并行应用，我们将网格划分为子域（又称域分解），这些子域被分配给进程。这种划分发生在deal.II的活动单元上，如步骤40所示。在那里，每个单元都有相同的有限元和相同的自由度分配，以及大致相同的工作负荷。为了平衡所有进程的工作负荷，我们必须平衡所有参与进程上的单元数量。

在hp-adaptive方法中，情况不再如此：有限元类型可能因单元而异，因此自由度的数量也不同。匹配单元的数量并不能产生一个平衡的工作量。在无矩阵的情况下，可以假设工作量与每个过程的自由度数量成正比，因为在最好的情况下，只有源和目的向量需要被加载。

我们可以通过给每个单元分配权重来平衡工作量，这些权重与自由度的数量成正比，并平衡所有进程之间的所有权重之和。给每个单元分配单独的权重可以通过我们后面要使用的 parallel::CellWeights 类来实现。




<h3>hp-decision indicators</h3>

使用hp-adaptive方法，我们不仅要决定哪些单元需要细化或粗化，而且还可以选择如何做：要么调整网格分辨率，要么调整有限元的多项式程度。

我们将再次根据当前解决方案的（后验）计算误差估计值来决定哪些单元需要调整，例如，使用KellyErrorEstimator。我们将同样决定如何用（事后）计算的平滑度估计值进行调整：大的多项式度数对解决方案的平滑部分效果最好，而细的网格分辨率对不规则部分是有利的。在第27步中，我们提出了一种基于傅里叶系数衰减的平滑度估计的计算方法。让我们利用这个机会，提出一种遵循相同思路的替代方法，但采用Legendre系数。

我们将简要介绍这种新技术的思路，但为了简单起见，将其描述限制在一维。假设 $u_\text{hp}(x)$ 是一个有限元函数，在单元格 $K$ 上定义为

@f[
u_\text{hp}(x) = \sum c_i \varphi_i(x)


@f]

其中每个 $\varphi_i(x)$ 是一个形状函数。我们可以用Legendre多项式 $P_k$ 的基础等价表示 $u_\text{hp}(x)$ 为

@f[
u_\text{hp}(x) = \sum l_k P_k(x).


@f]

我们的目标是获得有限元系数 $c_i$ 和Legendre系数 $l_k$ 之间的映射。我们将通过把问题写成 $L^2$ 对 $u_\text{hp}(x)$ 在Legendre基础上的投影来实现这一目标。每个系数 $l_k$ 可以通过以下方式计算

@f[
l_k = \int_K u_\text{hp}(x) P_k(x) dx.


@f]

根据结构，Legendre多项式在 $L^2$ 上的内积下是正交的。此外，我们假设它们已经被归一化，所以它们的内积可以写成

@f[
\int_K P_i(x) P_j(x) dx = \det(J_K) \, \delta_{ij}


@f]

其中 $\delta_{ij}$ 是克朗克三角洲， $J_K$ 是 $\hat{K}$ 到 $K$ 的映射的雅各布，（在本教程中）假定它是常数（即，映射必须是仿射的）。

因此，结合所有这些假设，在Legendre基础上表达 $u_\text{hp}(x)$ 的投影矩阵只是 $\det(J_K) \,
\mathbb{I}$  -- 即 $\det(J_K)$ 乘以身份矩阵。让 $F_K$ 成为从 $K$ 到其参考单元 $\hat{K}$ 的映射。因此，投影系统中右侧的条目为：。

@f[
\int_K u_\text{hp}(x) P_k(x) dx
= \det(J_K) \int_\hat{K} u_\text{hp}(F_K(\hat{x})) P_k(F_K(\hat{x})) d\hat{x}.


@f]

回顾 $u_\text{hp}(x)$ 的形状函数表示，我们可以把它写成 $\det(J_K) \, \mathbf{C} \, \mathbf{c}$ ，其中 $\mathbf{C}$ 是改变基础的矩阵，条目是

@f[
\int_K P_i(x) \varphi_j(x) dx
= \det(J_K) \int_{\hat{K}} P_i(F_K(\hat{x})) \varphi_j(F_K(\hat{x})) d\hat{x}
= \det(J_K) \int_{\hat{K}} \hat{P}_i(\hat{x}) \hat{\varphi}_j(\hat{x}) d\hat{x}
\dealcoloneq \det(J_K) \, C_{ij}


@f]

所以 $\mathbf{C}$ 的值可以写成 <em> 独立于 </em> 的 $K$ ，在转换为参考坐标后，将 $\det(J_K)$ 从前面因式分解。因此，把这一切放在一起，投影问题可以写为

@f[
\det(J_K) \, \mathbb{I} \, \mathbf{l} = \det(J_K) \, \mathbf{C} \, \mathbf{c}


@f]

可以简单改写为

@f[
\mathbf{l} = \mathbf{C} \, \mathbf{c}.


@f]



在这一点上，我们需要强调的是，大多数有限元应用都使用非结构化网格，对于这些网格的映射几乎总是非affine的。换句话说： $J_K$ 在整个单元中是恒定的这一假设对于一般的网格来说是不正确的。因此， $l_k$ 的正确计算不仅要求我们为每一个单元计算相应的变换矩阵 $\mathbf{C}$ ，而且还要求我们在可能具有任意和非常复杂的几何形状的单元 $K$ 上定义一组类Legendre正交函数。特别是第二部分，在计算上非常昂贵。目前FESeries变换类的实现依赖于具有恒定雅各布系数所带来的简化，以提高性能，因此只对仿射映射产生正确结果。变换只用于平滑度估计的目的，以决定适应的类型，这不是有限元程序的一个关键组成部分。除此之外，这种情况对本教程不构成问题，因为我们只使用方形的单元。

Eibner和Melenk  @cite eibner2007hp  认为，当且仅当Legendre系数的绝对值随指数增加而衰减时，一个函数是解析的，即可以用幂级数表示  $k$  。

@f[
\exists C,\sigma > 0 : \quad \forall k \in \mathbb{N}_0 : \quad |l_k|
\leq C \exp\left( - \sigma k \right) .


@f]

衰减率 $\sigma$ 可以被解释为衡量该函数的平滑度。我们可以把它看成是转化系数的线性回归拟合的斜率。

@f[
\ln(|l_k|) \sim \ln(C) - \sigma k .


@f]



我们将对每个单元 $K$ 进行这种拟合，以获得对有限元近似的平滑度的局部估计。然后，衰减率 $\sigma_K$ 作为hp-adaptation的决策指标。对于单元上的有限元 $K$ 的多项式程度 $p$ ，计算 $k \leq (p+1)$ 的系数被证明是估计平稳性的合理选择。你可以在  @cite fehling2020  中找到更详细和独立于维度的描述。

以上所有内容已经在 FESeries::Legendre 类和 SmoothnessEstimator::Legendre 命名空间中实现。有了误差估计和平滑度指标，我们就可以对单元格进行实际细化和粗化了。来自 parallel::distributed::GridRefinement 和 hp::Refinement 命名空间的一些函数将在后面帮助我们完成这个任务。




<h3>Hybrid geometric multigrid</h3>

有限元矩阵通常是非常稀疏的。此外，hp-adaptive方法对应于每行非零项数量变化很大的矩阵。一些最先进的预处理程序，如Step-40中使用的代数多重网格（AMG），在这些情况下表现不佳。

因此，我们将依靠一个无矩阵的混合多网格预处理程序。Step-50已经证明了几何多网格方法与MatrixFree框架结合时的优越性。在hp-adaptive FEM上的应用需要一些额外的工作，因为一个单元的子代可能有不同的多项式程度。作为补救措施，我们首先对线性元素进行p松弛（类似于Mitchell @cite mitchell2010hpmg ），然后以常规方式进行h松弛。在最粗的层次上，我们应用代数多网格求解器。p-多栅、h-多栅和AMG的结合使求解器成为一个混合多栅求解器。

我们将通过使用MGTransferGlobalCoarsening，在现有的全局粗化基础设施的帮助下，创建一个具有上述特殊水平要求的自定义混合多网格预处理器。




<h3>The test case</h3>

对于椭圆方程来说，每个再入角通常会引出一个奇点  @cite brenner2008  。我们可以利用这种情况对我们的HP决策算法进行测试：在所有要适应的单元上，我们倾向于在奇点附近采用精细的网格，而在其他情况下采用高的多项式程度。

作为在这些条件下要解决的最简单的椭圆问题，我们选择了L型域中的拉普拉斯方程，其再入角位于坐标系的原点。

为了能够确定实际的误差，我们制造一个有已知解的边界值问题。在上述领域，拉普拉斯方程的一个解是，在极坐标中， $(r, \varphi)$  。

@f[
u_\text{sol} = r^{2/3} \sin(2/3 \varphi).


@f]



参见  @cite brenner2008  或  @cite mitchell2014hp  。解决方案看起来如下。

<div style="text-align:center;"> <img src="https://www.dealii.org/images/steps/developer/step-75.solution.svg" alt="分析性解决方案。"> </div>

通过研究再入角附近的解决方案的梯度，即原点，奇异性变得很明显了。

@f[
\left\| \nabla u_\text{sol} \right\|_{2} = 2/3 r^{-1/3} , \quad
\lim\limits_{r \rightarrow 0} \left\| \nabla u_\text{sol} \right\|_{2} =
\infty .


@f]



由于我们知道奇点的位置，我们希望我们的hp-decision算法在这个特定的区域内决定采用精细的网格分辨率，而在其他地方采用高多项式程度。

因此，让我们看看情况是否真的如此，以及hp-adaptation与纯h-adaptation相比表现如何。但首先让我们详细看看实际的代码。


examples/step-75/doc/results.dox



<h1>Results</h1>

当你在释放模式下，在四个进程上用给定的参数运行该程序时，你的终端输出应该是这样的。

@code
Running with Trilinos on 4 MPI rank(s)...
Calculating transformation matrices...
Cycle 0:
   Number of active cells:       3072
     by partition:               768 768 768 768
   Number of degrees of freedom: 12545
     by partition:               3201 3104 3136 3104
   Number of constraints:        542
     by partition:               165 74 138 165
   Frequencies of poly. degrees: 2:3072
   Solved in 7 iterations.



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.598s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| calculate transformation        |         1 |    0.0533s |       8.9% |
| compute indicators              |         1 |    0.0177s |         3% |
| initialize grid                 |         1 |    0.0397s |       6.6% |
| output results                  |         1 |    0.0844s |        14% |
| setup system                    |         1 |    0.0351s |       5.9% |
| solve system                    |         1 |     0.362s |        61% |
+---------------------------------+-----------+------------+------------+



Cycle 1:
   Number of active cells:       3351
     by partition:               875 761 843 872
   Number of degrees of freedom: 18223
     by partition:               4535 4735 4543 4410
   Number of constraints:        1202
     by partition:               303 290 326 283
   Frequencies of poly. degrees: 2:2523 3:828
   Solved in 7 iterations.



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.442s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| adapt resolution                |         1 |    0.0189s |       4.3% |
| compute indicators              |         1 |    0.0135s |         3% |
| output results                  |         1 |     0.064s |        14% |
| setup system                    |         1 |    0.0232s |       5.2% |
| solve system                    |         1 |     0.322s |        73% |
+---------------------------------+-----------+------------+------------+



...



Cycle 7:
   Number of active cells:       5610
     by partition:               1324 1483 1482 1321
   Number of degrees of freedom: 82062
     by partition:               21116 19951 20113 20882
   Number of constraints:        14383
     by partition:               3825 3225 3557 3776
   Frequencies of poly. degrees: 2:1130 3:1283 4:2727 5:465 6:5
   Solved in 7 iterations.



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.932s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| adapt resolution                |         1 |    0.0182s |       1.9% |
| compute indicators              |         1 |    0.0173s |       1.9% |
| output results                  |         1 |    0.0572s |       6.1% |
| setup system                    |         1 |    0.0252s |       2.7% |
| solve system                    |         1 |     0.813s |        87% |
+---------------------------------+-----------+------------+------------+
@endcode



当用更多的进程运行代码时，你会注意到活动单元和自由度的数量有轻微的差异。这是由于求解器和预处理程序取决于问题的分区，这可能会导致最后一位数的解决方案的微小差异，并最终产生不同的适应行为。

此外，尽管有hp-adaptation，求解器的迭代次数在所有周期中都保持不变，这表明所提出的算法的稳健性，并有望在更大的问题规模和更多的进程中具有良好的可扩展性。

让我们看一下程序的图形输出。在给定参数配置的所有细化循环之后，实际离散的函数空间看起来如下，左边是其在12个进程上的分区，右边是有限元的多项式程度。在左图中，每种颜色代表一个独特的子域。在右图中，最浅的颜色对应于多项式的2度，最深的对应于6度。

<div class="twocolumn" style="width: 80%; text-align: center;"> <div> <img src="https://www.dealii.org/images/steps/developer/step-75.subdomains-07.svg" alt="七次细化后的分区。"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-75.fedegrees-07.svg" alt="七次细化后的局部近似度。"> </div> <div>




<a name="extensions"></a>

<h3>Possibilities for extensions</h3>

<h4>Different hp-decision strategies</h4>

deal.II库提供了多种策略来决定对单元格施加哪种类型的适应：要么调整网格分辨率，要么改变多项式程度。我们在本教程中只介绍了<i>Legendre
coefficient decay</i>策略，而Step-27则演示了相同想法的<i>Fourier</i>等值。

有关这些策略的概述，请参见步骤27的 "扩展的可能性 "部分，或相应的文件的详细描述。

在这里，提到了另一个迄今为止还没有在任何教程中展示过的策略：基于<i>refinement history</i>的策略。这种方法在并行分布式应用中的使用比其他方法更棘手，所以我们将强调随之而来的挑战。我们需要有关细化标志的最终状态的信息，并且我们需要在细化的网格之间转移解决方案。对于前者，我们需要将 hp::Refinement::predict_error() 函数附加到 Triangulation::Signals::post_p4est_refinement 信号上，其方式是将<i>after</i>的 hp::Refinement::limit_p_level_difference() 函数调用。在这个阶段，所有的细化标志和未来的FE指数都被终止设置，并且可以对误差进行可靠预测。然后，预测的误差需要借助于 parallel::distributed::CellDataTransfer. 在细化网格之间进行转移。

试着在本教程中实现这些策略之一，并观察结果的微妙变化。你会注意到，所有的策略都能够识别出重心角附近的奇点，并且会在这些区域进行 $h$ -精化，而在体域中更倾向于 $p$ -精化。这些策略的详细比较见于  @cite fehling2020  。




<h4>Solve with matrix-based methods</h4>

本教程只关注无矩阵策略。然而，所有的hp自适应算法在并行分布式背景下也可以使用基于矩阵的方法。

为了创建一个系统矩阵，你可以使用 LaplaceOperator::get_system_matrix() 函数，或者使用类似于步骤27的 <code>assemble_system()</code> 函数。然后你可以像往常一样将系统矩阵传递给求解器。

你可以对基于矩阵和无矩阵的实现结果进行计时，量化速度提升，并说服自己哪种变体更快。




<h4>Multigrid variants</h4>

为了简单起见，我们将自己限制在单一类型的粗网格求解器（带AMG的CG）、平滑器（带点Jacobi预处理的Chebyshev平滑器）以及多网格算法中的几何粗化方案（全局粗化）。请自由尝试替代方案并调查其性能和稳健性。


examples/step-76/doc/intro.dox



 <br> 

<i>
This program was contributed by Martin Kronbichler, Peter Munch, and David
Schneider. Many of the features shown here have been added to deal.II during
and for the development of the deal.II-based, efficient, matrix-free
finite-element library for high-dimensional partial differential equations
hyper.deal (see https://github.com/hyperdeal/hyperdeal). For more details and
for applications of the presented features in slightly different contexts
(high-dimensional advection equation and Vlasov-Poisson equations) see the release
paper @cite munch2020hyperdeal.


This work was partly supported by the German Research Foundation (DFG) through
the project "High-order discontinuous Galerkin for the exa-scale" (ExaDG)
within the priority program "Software for Exascale Computing" (SPPEXA) and
by the Bavarian government through the project "High-order matrix-free finite
element implementations with hybrid parallelization and improved data locality"
within the KONWIHR program.
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

本教程程序求解流体力学的欧拉方程，使用显式时间积分器和无矩阵框架应用于空间的高阶非连续Galerkin离散化。这里使用的数值方法与step-67中使用的相同，但是，我们利用不同的高级MatrixFree技术来达到更高的吞吐量。

本教程的两个主要特点是。

- 使用MPI-3.0中的共享内存特性和

- 使用以单元为中心的循环，它只允许向全局向量写入一次，因此，是使用共享内存的理想选择。

我们在本教程中讨论的其他主题是模板参数VectorizedArrayType的用法和好处（而不是简单地使用VectorizedArray<Number>），以及向MatrixFree循环传递lambdas的可能性。

关于数字的细节，我们参考步骤-67的文件。我们在这里只集中讨论关键的差异。

<h3>Shared-memory and hybrid parallelization with MPI-3.0</h3>

<h4>Motivation</h4>

存在许多基于线程的共享内存库，如TBB、OpenMP或TaskFlow。将这些库集成到现有的MPI程序中，就可以使用共享内存。然而，这些库对程序员来说有一定的开销，因为所有可并行的代码部分都必须根据所使用的库进行查找和转换，包括当一些第三方数值库，如迭代求解器包，只依赖MPI时的困难。

考虑到一个纯粹的MPI并行化的有限元应用，我们可以发现，使用共享内存的主要时间和内存优势来自于访问同一计算节点上的进程所拥有的解决方案矢量的部分，而不需要进行明确的复制和缓冲。因此，MPI-3.0提供了基于所谓窗口的共享内存功能，进程可以直接访问同一共享内存域中的邻居的数据。

<h4>Basic MPI-3.0 commands</h4>

有几个相关的MPI-3.0命令值得详细讨论。一个新的MPI通信器 <code>comm_sm</code>  ，由通信器 <code>comm</code> 的进程组成，这些进程可以访问相同的共享内存，可以通过以下方式创建。

@code
MPI_Comm_split_type(comm, MPI_COMM_TYPE_SHARED, rank, MPI_INFO_NULL, &comm_sm);
@endcode



下面的代码片断显示了共享内存的简化分配例程，包括值类型  <code>T</code>  和大小  <code>local_size</code>  ，以及如何查询属于同一共享内存域的进程的数据指针。

@code
MPI_Win          win;         // window
T *              data_this;   // pointer to locally-owned data
std::vector<T *> data_others; // pointers to shared data


// configure shared memory
MPI_Info info;
MPI_Info_create(&info);
MPI_Info_set(info, "alloc_shared_noncontig", "true");


// allocate shared memory
MPI_Win_allocate_shared(local_size * sizeof(T), sizeof(T), info, comm_sm, &data_this, &win);


// get pointers to the shared data owned by the processes in the same sm domain
data_others.resize(size_sm);
int disp_unit = 0; // displacement size - an output parameter we don't need right now
MPI_Aint ssize = 0; // window size - an output parameter we don't need right now
for (int i = 0; i < size_sm; ++i)
  MPI_Win_shared_query(win, i, &ssize, &disp_unit, &data_others[i]);


Assert(data_this == data_others[rank_sm], ExcMessage("Something went wrong!"));
@endcode



一旦不再需要这些数据，窗口就必须被释放，这也释放了本地拥有的数据。

@code
MPI_Win_free(&win);
@endcode



<h4>MPI-3.0 and LinearAlgebra::distributed::Vector</h4>

上一节提到的命令被整合到了 LinearAlgebra::distributed::Vector 中，如果为reinit()函数提供了可选的（第二个）通信器，那么这些命令就被用来分配共享内存。

例如，可以用一个分区器（包含全局通信器）和一个子通信器（包含同一计算节点上的进程）来设置一个向量。

@code
vec.reinit(partitioner, comm_sm);
@endcode



本地拥有的值和幽灵值可以像往常一样被处理。然而，现在用户也可以通过该函数读取共享内存邻居的值。

@code
const std::vector<ArrayView<const Number>> &
LinearAlgebra::distributed::Vector::shared_vector_data() const;
@endcode



<h4>MPI-3.0 and MatrixFree</h4>

虽然 LinearAlgebra::distributed::Vector 提供了分配共享内存和以协调的方式访问相邻进程的共享内存值的选项，但它实际上并没有利用共享内存的使用本身的好处。

然而，MatrixFree的基础设施确实如此。

- 一方面，在无矩阵循环 MatrixFree::loop(),  MatrixFree::cell_loop(), 和 MatrixFree::loop_cell_centric(), 中，只有需要更新的幽灵值 <em> 被 </em> 更新。来自共享内存邻居的幽灵值可以被直接访问，这使得缓冲，即把值复制到矢量的幽灵区域可能是多余的。   为了处理可能的竞赛条件，在MatrixFree中进行了必要的同步。在数值必须被缓冲的情况下，数值被直接从邻近的共享内存进程中复制，绕过了基于  <code>MPI_ISend</code>  和  <code>MPI_IRecv</code>  的更昂贵的MPI操作。

- 另一方面，像FEEvaluation和FEFaceEvaluation这样的类可以直接从共享内存中读取，所以在某些情况下确实不需要缓冲值。

为了能够使用MatrixFree的共享内存功能，MatrixFree必须通过提供用户创建的子通信器进行适当的配置。

@code
typename MatrixFree<dim, Number>::AdditionalData additional_data;


// set flags as usual (not shown)


additional_data.communicator_sm = comm_sm;


data.reinit(mapping, dof_handler, constraint, quadrature, additional_data);
@endcode






<h3>Cell-centric loops</h3>

<h4>Motivation: FCL vs. CCL</h4>

"以面为中心的循环"（简称FCL）在单独的循环中访问单元和面（内部和边界的）。因此，每个实体只被访问一次，单元之间的通量只被评估一次。如何在 MatrixFree::loop() 的帮助下，通过提供三个函数（一个用于细胞积分，一个用于内部，一个用于边界面）来执行以面为中心的循环，已经在步骤59和步骤67中提出。

与此相反，"以单元为中心的循环"（在hyper.deal发布的论文中简称CCL或ECL（代表以元素为中心的循环），处理一个单元并直接连续处理其所有面（即访问所有面两次）。在文献 @cite KronbichlerKormann2019 中，它们的好处对于现代CPU处理器架构来说已经很清楚了，尽管这种循环意味着通量必须被计算两次（对于内部面的每一面）。CCL有两个主要优点。

- 一方面，在CCL的情况下，解向量中的条目正好被写回主内存一次，而在FCL的情况下，尽管高速缓存有效地调度了单元和面环，但由于高速缓存容量的错过，至少有一次。

- 另一方面，由于解向量的每个条目只被访问一次，在CCL的情况下，访问解向量时不需要线程间的同步。在写入目标向量的过程中不存在竞赛条件，这使得CCL特别适用于共享内存并行化。

我们还应该注意到，尽管在CCL的情况下通量被计算了两次，但这并不自动转化为计算量的翻倍，因为已经内插到单元正交点的值可以用简单的一维内插法内插到一个面上。

<h4>Cell-centric loops and MatrixFree</h4>

对于以单元为中心的循环实现，可以使用函数 MatrixFree::loop_cell_centric() ，用户可以向其传递一个应该在每个单元上执行的函数。

为了得出一个适当的函数，可以在 MatrixFree::loop_cell_centric(), 中传递，原则上可以转换/合并以下三个函数，它们可以传递给 MatrixFree::loop(): 。

@code
matrix_free.template loop<VectorType, VectorType>(
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    // operation performed on cells


    FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);
    for (unsigned int cell = range.first; cell < range.second; ++cell)
      {
        phi.reinit(cell);
        phi.gather_evaluate(src, cell_evaluation_flags);


        // some operations on the cell quadrature points


        phi.integrate_scatter(cell_evaluation_flags, dst);
      }
  },
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    // operation performed inner faces


    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);
    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_p(data, /*is_interior_face=*/false);


    for (unsigned int face = range.first; face < range.second; ++face)
      {
        phi_m.reinit(face);
        phi_m.gather_evaluate(src, face_evaluation_flags);
        phi_p.reinit(face);
        phi_p.gather_evaluate(src, face_evaluation_flags);


        // some operations on the face quadrature points


        phi_m.integrate_scatter(face_evaluation_flags, dst);
        phi_p.integrate_scatter(face_evaluation_flags, dst);
      }
  },
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    // operation performed boundary faces


    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);


    for (unsigned int face = range.first; face < range.second; ++face)
      {
        phi_m.reinit(face);
        phi_m.gather_evaluate(src, face_evaluation_flags);


        // some operations on the face quadrature points


        phi_m.integrate_scatter(face_evaluation_flags, dst);
      }
  },
  dst,
  src);
@endcode



以下列方式进行。

@code
matrix_free.template loop_cell_centric<VectorType, VectorType>(
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    FEEvaluation<dim, degree, degree + 1, 1, Number>     phi(data);
    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);
    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_p(data, /*is_interior_face=*/false);


    for (unsigned int cell = range.first; cell < range.second; ++cell)
      {
        phi.reinit(cell);
        phi.gather_evaluate(src, cell_evaluation_flags);


        // some operations on the cell quadrature points


        phi.integrate_scatter(cell_evaluation_flags, dst);


        // loop over all faces of cell
        for (unsigned int face = 0; face < GeometryInfo<dim>::faces_per_cell; ++face)
          {
            if (data.get_faces_by_cells_boundary_id(cell, face)[0] ==
                numbers::internal_face_boundary_id)
              {
                // internal face
                phi_m.reinit(cell, face);
                phi_m.gather_evaluate(src, face_evaluation_flags);
                phi_p.reinit(cell, face);
                phi_p.gather_evaluate(src, face_evaluation_flags);


                // some operations on the face quadrature points


                phi_m.integrate_scatter(face_evaluation_flags, dst);
              }
            else
              {
                // boundary face
                phi_m.reinit(cell, face);
                phi_m.gather_evaluate(src, face_evaluation_flags);


                // some operations on the face quadrature points


                phi_m.integrate_scatter(face_evaluation_flags, dst);
              }
          }
      }
  },
  dst,
  src);
@endcode



应该注意的是，FEFaceEvaluation现在是用两个数字初始化的，即单元号和本地面孔号。给出的例子只是强调了如何将以面为中心的循环转化为以单元为中心的循环，而且绝非高效，因为数据要从全局向量中多次读写，而且计算也是重复进行的。下面，我们将讨论针对这些问题的高级技术。

为了能够使用 MatrixFree::loop_cell_centric(), ，必须启用 MatrixFree::AdditionalData 的下列标志。

@code
typename MatrixFree<dim, Number>::AdditionalData additional_data;


// set flags as usual (not shown)


additional_data.hold_all_faces_to_owned_cells       = true;
additional_data.mapping_update_flags_faces_by_cells =
  additional_data.mapping_update_flags_inner_faces |
  additional_data.mapping_update_flags_boundary_faces;


data.reinit(mapping, dof_handler, constraint, quadrature, additional_data);
@endcode



特别是，这些标志使内部数据结构能够为所有单元格的面设置。

目前，deal.II中以单元为中心的循环只适用于均匀细化的网格，并且不应用任何约束条件（这是通常使用的DG的标准情况）。




<h3>Providing lambdas to MatrixFree loops</h3>

上面给出的例子已经使用了lambdas，它已经被提供给无矩阵循环。下面的简短例子介绍了如何在使用类和指向其方法之一的指针的版本和利用lambdas的变体之间转换函数。

在下面的代码中，一个类和它的一个方法的指针被传递给了 MatrixFree::loop(): ，这个方法应该被解释为单元格积分。

@code
void
local_apply_cell(const MatrixFree<dim, Number> &              data,
                 VectorType &                                 dst,
                 const VectorType &                           src,
                 const std::pair<unsigned int, unsigned int> &range) const
{
  FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);
  for (unsigned int cell = range.first; cell < range.second; ++cell)
    {
      phi.reinit(cell);
      phi.gather_evaluate(src, cell_evaluation_flags);


      // some operations on the quadrature points


      phi.integrate_scatter(cell_evaluation_flags, dst);
    }
}
@endcode



@code
matrix_free.cell_loop(&Operator::local_apply_cell, this, dst, src);
@endcode



然而，也可以通过lambda函数传递匿名函数，结果是一样的。

@code
matrix_free.template cell_loop<VectorType, VectorType>(
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);
    for (unsigned int cell = range.first; cell < range.second; ++cell)
      {
        phi.reinit(cell);
        phi.gather_evaluate(src, cell_evaluation_flags);


        // some operations on the quadrature points


        phi.integrate_scatter(cell_evaluation_flags, dst);
      }
  },
  dst,
  src);
@endcode



<h3>VectorizedArrayType</h3>

VectorizedArray<Number>类是实现deal.II中无矩阵算法的高节点级性能的一个关键组件。它是一个围绕Number类型的 $n$ 条目的短向量的包装类，并通过内在函数将算术操作映射到适当的单指令/多数据（SIMD）概念。向量的长度可以通过 VectorizedArray::size() 查询，其底层数字类型可以通过 VectorizedArray::value_type. 查询。

在默认情况下（ <code>VectorizedArray<Number></code> ），向量长度在库的编译时被设置为与给定的处理器架构所支持的最高值相匹配。然而，也可以指定第二个可选的模板参数，如 <code>VectorizedArray<Number, size></code>, where <code>size</code> 明确控制特定指令集能力范围内的向量长度。下表列出了支持的向量长度的完整列表。

 <table align="center" class="doxtable">
  <tr>
   <th>double</th>
   <th>float</th>
   <th>ISA</th>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 1></code></td>
   <td><code>VectorizedArray<float, 1></code></td>
   <td>(auto-vectorization)</td>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 2></code></td>
   <td><code>VectorizedArray<float, 4></code></td>
   <td>SSE2/AltiVec</td>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 4></code></td>
   <td><code>VectorizedArray<float, 8></code></td>
   <td>AVX/AVX2</td>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 8></code></td>
   <td><code>VectorizedArray<float, 16></code></td>
   <td>AVX-512</td>
  </tr>
</table> 

这允许用户选择矢量长度/ISA，因此，在无矩阵算子评估中一次处理的单元数，可能会减少对缓存的压力，这对非常高的度数（和尺寸）来说是一个严重的问题。

减少填充通道数量的另一个可能的原因是为了简化调试：不用看例如8个单元，而是可以集中在一个单元上。

VectorizedArray的接口也能够被任何具有匹配接口的类型所替代。具体来说，这为deal.II准备了 <code>std::simd</code> 类，它计划成为C++23标准的一部分。下表比较了deal.II特定的SIMD类和相应的C++23类。


 <table align="center" class="doxtable">
  <tr>
   <th>VectorizedArray (deal.II)</th>
   <th>std::simd (C++23)</th>
  </tr>
  <tr>
   <td><code>VectorizedArray<Number></code></td>
   <td><code>std::experimental::native_simd<Number></code></td>
  </tr>
  <tr>
   <td><code>VectorizedArray<Number, size></code></td>
   <td><code>std::experimental::fixed_size_simd<Number, size></code></td>
  </tr>
</table> 


examples/step-76/doc/results.dox



<h1>Results</h1>

在一台有40个进程的机器上以默认设置运行该程序，会产生以下输出。

@code
Running with 40 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 27.648.000 ( = 5 [vars] x 25.600 [cells] x 216 [dofs/cell/var] )
Time step size: 0.000295952, minimal h: 0.0075, initial transport scaling: 0.00441179
Time:       0, dt:   0.0003, norm rho:  5.385e-16, rho * u:  1.916e-16, energy: 1.547e-15
+--------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed         |     17.52s    10 |     17.52s |     17.52s    11 |
|                                      |                  |                               |
| Section                  | no. calls |   min time  rank |   avg time |   max time  rank |
+--------------------------------------+------------------+------------+------------------+
| compute errors           |         1 |  0.009594s    16 |  0.009705s |  0.009819s     8 |
| compute transport speed  |        22 |    0.1366s     0 |    0.1367s |    0.1368s    18 |
| output                   |         1 |     1.233s     0 |     1.233s |     1.233s    32 |
| rk time stepping total   |       100 |     8.746s    35 |     8.746s |     8.746s     0 |
| rk_stage - integrals L_h |       500 |     8.742s    36 |     8.742s |     8.743s     2 |
+--------------------------------------+------------------+------------+------------------+
@endcode



和以下视觉输出。

 <table align="center" class="doxtable" style="width:85%">
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_010.png" alt="" width="100%">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_025.png" alt="" width="100%">
    </td>
  </tr>
  <tr>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_050.png" alt="" width="100%">
    </td>
    <td>
        <img src="https://www.dealii.org/images/steps/developer/step-67.pressure_100.png" alt="" width="100%">
    </td>
  </tr>
</table> 

作为参考，使用FCL的步骤-67的结果是。

@code
Running with 40 MPI processes
Vectorization over 8 doubles = 512 bits (AVX512)
Number of degrees of freedom: 27.648.000 ( = 5 [vars] x 25.600 [cells] x 216 [dofs/cell/var] )
Time step size: 0.000295952, minimal h: 0.0075, initial transport scaling: 0.00441179
Time:       0, dt:   0.0003, norm rho:  5.385e-16, rho * u:  1.916e-16, energy: 1.547e-15
+-------------------------------------------+------------------+------------+------------------+
| Total wallclock time elapsed              |     13.33s     0 |     13.34s |     13.35s    34 |
|                                           |                  |                               |
| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |
+-------------------------------------------+------------------+------------+------------------+
| compute errors                |         1 |  0.007977s    10 |  0.008053s |  0.008161s    30 |
| compute transport speed       |        22 |    0.1228s    34 |    0.2227s |    0.3845s     0 |
| output                        |         1 |     1.255s     3 |     1.257s |     1.259s    27 |
| rk time stepping total        |       100 |     11.15s     0 |     11.32s |     11.42s    34 |
| rk_stage - integrals L_h      |       500 |     8.719s    10 |     8.932s |     9.196s     0 |
| rk_stage - inv mass + vec upd |       500 |     1.944s     0 |     2.377s |      2.55s    10 |
+-------------------------------------------+------------------+------------+------------------+
@endcode



通过本教程中的修改，我们能够使Runge-Kutta阶段的速度提高27%。

<h3>Possibilities for extensions</h3>

这些算法很容易扩展到更高的维度：高维的<a href="https://github.com/hyperdeal/hyperdeal/blob/a9e67b4e625ff1dde2fed93ad91cdfacfaa3acdf/include/hyper.deal/operators/advection/advection_operation.h#L219-L569">advection operator based on cell-centric loops</a>是hyper.deal库的一部分。以单元为中心的循环扩展到局部细化的网格则涉及更多。

<h4>Extension to the compressible Navier-Stokes equations</h4>

本教程中提出的求解器也可以通过增加粘性项来扩展到可压缩的Navier-Stokes方程，这也是步骤67中的建议。为了尽量保持这里获得的性能，尽管有额外的椭圆项的成本，例如通过内部惩罚方法，该教程建议将基础从FE_DGQ切换到FE_DGQHermite，就像步骤59的教程程序一样。这种转换背后的原因是，在FE_DGQ的情况下，需要相邻单元的所有值（即 $k+1$ 层），而在FE_DGQHermite的情况下，只需要2层，这使得后者明显更适合于高度数。额外的层一方面要在通量计算过程中从主内存加载，另一方面要进行通信。利用本教程介绍的共享内存能力，第二点可以在单个计算节点上消除，或者在混合环境下减少其影响。

<h4>Block Gauss-Seidel-like preconditioners</h4>

以单元为中心的循环可用于创建块状高斯-赛德尔预处理，在一个过程中是乘法的，在整个过程中是加法的。这些类型的预处理器在通量计算过程中使用，与雅可比型预处理器相反，已经从相邻的单元中更新了数值。下面的伪代码直观地说明了这在原则上是如何实现的。

@code
// vector monitor if cells have been updated or not
Vector<Number> visit_flags(data.n_cell_batches () + data.n_ghost_cell_batches ());


// element centric loop with a modified kernel
data.template loop_cell_centric<VectorType, VectorType>(
  [&](const auto &data, auto &dst, const auto &src, const auto cell_range) {


    for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)
      {
        // cell integral as usual (not shown)


        for (unsigned int face = 0; face < GeometryInfo<dim>::faces_per_cell; ++face)
          {
            const auto boundary_id = data.get_faces_by_cells_boundary_id(cell, face)[0];


            if (boundary_id == numbers::internal_face_boundary_id)
              {
                phi_p.reinit(cell, face);


                const auto flags = phi_p.read_cell_data(visit_flags);
                const auto all_neighbors_have_been_updated =
                  std::min(flags.begin(),
                           flags().begin() + data.n_active_entries_per_cell_batch(cell) == 1;


                if(all_neighbors_have_been_updated)
                  phi_p.gather_evaluate(dst, EvaluationFlags::values);
                else
                  phi_p.gather_evaluate(src, EvaluationFlags::values);


                // continue as usual (not shown)
              }
            else
              {
                // boundary integral as usual (not shown)
              }
          }


        // continue as above and apply your favorite algorithm to invert
        // the cell-local operator (not shown)


        // make cells as updated
        phi.set_cell_data(visit_flags, VectorizedArrayType(1.0));
      }
  },
  dst,
  src,
  true,
  MatrixFree<dim, Number, VectorizedArrayType>::DataAccessOnFaces::values);
@endcode



为此，我们可以利用MatrixFree的单元数据向量能力和VectorizedArray的基于范围的迭代能力。

请注意，在给定的例子中，我们处理 <code>VectorizedArrayType::size()</code> 个块，因为每个通道对应一个块。如果一个矢量寄存器处理的所有块都被更新了，我们就认为块被更新了。在笛卡尔网格的情况下，这是一个合理的方法，然而，对于一般的非结构化网格，这种保守的方法可能会导致预处理程序的效率下降。通过明确减少 <code>VectorizedArrayType</code> 使用的通道数量来减少并行处理的单元可能会提高预处理器的质量，但代价是每次迭代可能会更昂贵。这种两难境地把我们引向另一种 "扩展的可能性"：元素内的矢量化。


examples/step-77/doc/intro.dox

 <br> 

<i>
This program was contributed by Wolfgang Bangerth, Colorado State University.


This material is based upon work partially supported by National Science
Foundation grants OAC-1835673, DMS-1821210, and EAR-1925595;
and by the Computational Infrastructure in
Geodynamics initiative (CIG), through the National Science Foundation under
Award No. EAR-1550901 and The University of California-Davis.
</i> <br>  。

<a name="Intro"></a>

<h1>Introduction</h1>

第15步程序解决了以下描述最小表面问题的非线性方程。

@f{align*}{


    -\nabla \cdot \left( \frac{1}{\sqrt{1+|\nabla u|^{2}}}\nabla u \right) &= 0 \qquad
    \qquad &&\textrm{in} ~ \Omega
    \\
    u&=g \qquad\qquad &&\textrm{on} ~ \partial \Omega.


@f}

step-15使用的是牛顿方法，牛顿方法的工作原理是反复求解一个更新 $\delta u_k$ 的*线性化*问题--称为 "搜索方向"--计算 "步长" $\alpha_k$ ，然后将它们结合起来，通过以下方式计算出新的猜测解。

@f{align*}{
    u_{k+1} = u_k + \alpha_k \, \delta u_k.


@f}



在步骤15的讨论过程中，我们发现计算步长是很尴尬的，所以只是解决了简单的选择。总是选择 $\alpha_k=0.1$  。这当然是没有效率的。我们知道，只有当我们最终能够选择 $\alpha_k=1$ 时，我们才能实现牛顿的二次收敛率，尽管在最初的几次迭代中，我们可能不得不选择较小的步长，因为我们离使用这么长的步长还很遥远。

因此，本方案的目标之一是解决这一缺陷。由于行搜索算法的实现并不完全是微不足道的，因此人们无论如何都要做自己应该做的事。从外部库中导入复杂的功能。为此，我们将利用deal.II与大型非线性求解器包之一的接口，即[SUNDIALS](https://computing.llnl.gov/projects/sundials)套件的[KINSOL](https://computing.llnl.gov/projects/sundials/kinsol)子包。%SUNDIALS的核心是一个用于解决复杂的常微分方程（ODE）和微分代数方程（DAE）的软件包，deal.II接口允许通过SUNDIALS命名空间的类来实现。特别是 SUNDIALS::ARKode 和 SUNDIALS::IDA 类。但是，由于这是用隐式方法解决ODE和DAE的一个重要步骤，%SUNDIALS也有一个非线性问题的求解器，叫做KINSOL，deal.II有一个接口，以 SUNDIALS::KINSOL 类的形式与之连接。这就是我们将用于解决我们的问题的方法。

但是%SUNDIALS不仅仅是一个方便我们避免编写线搜索算法的方法。一般来说，非线性问题的解决是相当昂贵的，人们通常希望尽可能地节省计算时间。一个可以实现这个目标的方法是如下的。第15步中的算法将问题离散化，然后在每次迭代中求解形式为的线性系统

@f{align*}{
  J_k \, \delta U_k = -F_k


@f}

其中 $F_k$ 是使用当前节点值矢量 $U_k$ 计算的残差矢量， $J_k$ 是其导数（称为 "雅各布"），而 $\delta U_k$ 是对应于上述函数 $\delta u_k$ 的更新矢量。步骤15中已经彻底讨论了 $J_k,F_k$ 的构造，以及在每个牛顿迭代中解决线性系统的方法。因此，让我们关注一下非线性求解过程的另一个方面。计算 $F_k$ 是昂贵的，而组装矩阵 $J_k$ 更是如此。我们真的需要在每次迭代中都这样做吗？事实证明，在许多应用中，这实际上是没有必要的。即使我们用近似值 $\tilde J_k$ 代替 $J_k$ ，这些方法通常也能收敛，并解决了

@f{align*}{
  \tilde J_k \, \widetilde{\delta U}_k = -F_k


@f}

代替，然后更新

@f{align*}{
    U_{k+1} = U_k + \alpha_k \, \widetilde{\delta U}_k.


@f}

这可能需要多一两个迭代，因为我们的更新 $\widetilde{\delta U}_k$ 并不像 $\delta U_k$ 那样好，但它可能仍然是一个胜利，因为我们不必经常组装 $J_k$ 。

对于 $J_k$ ，我们希望得到什么样的近似值 $\tilde J_k$ ？理论上说，由于 $U_k$ 收敛于精确解 $U^\ast$ ，我们需要确保 $\tilde J_k$ 需要收敛于 $J^\ast = \nabla F(U^\ast)$  。特别是，由于  $J_k\rightarrow J^\ast$  ，有效的选择是  $\tilde J_k = J_k$  。但是每一次，比如说，第五次迭代选择 $\tilde J_k = J_k$ 也是如此，对于其他的迭代，我们选择 $\tilde J_k$ 等于最后计算的 $J_{k'}$  。这就是我们在这里要做的：我们将只是重新使用前一次迭代中的 $\tilde J_{k-1}$ ，这可能又是我们在之前的迭代中使用的， $\tilde J_{k-2}$  。

如果对于带有 $J_k$ 的线性系统的求解，我们不只是要组装一个矩阵，还要计算一个好的预处理程序，那么这个方案就变得更加有趣。例如，如果我们要通过SparseDirectUMFPACK类使用稀疏LU分解，或者使用几何或代数多重网格。在这些情况下，我们也不必更新预处理程序，因为预处理程序的计算时间可能和当初组装矩阵的时间一样长，甚至更长。事实上，在这种心态下，我们也许应该考虑使用我们能想到的*好的前置条件器，尽管它们的构造通常相当昂贵。我们希望通过将其应用于不止一个线性求解，来摊销计算这个预处理程序的成本。

当然，最大的问题是。我们根据什么标准来决定我们是否可以摆脱基于先前计算的雅各布矩阵 $J_{k-s}$ 的近似 $s$ 步，或者我们是否需要--至少在这个迭代中--实际重新计算雅各布 $J_k$ 和相应的前置条件器？这就像行搜索的问题一样，需要大量的代码来监控整个算法的收敛性。我们*可以*自己实现这些东西，但我们可能*不应该*。KINSOL已经为我们做了这些。它将告诉我们的代码何时要 "更新 "雅各布矩阵。

如果我们要使用迭代求解器而不是上面提到的稀疏直接求解器，还有最后一个考虑。在求解更新 $\delta U_k$ 时，不仅有可能用一些近似值 $J_k$ 代替 $\tilde J_k$ ，而且还可以问是否有必要求解线性系统

@f{align*}{
  \tilde J_k \widetilde{\delta U}_k = -F_k


@f}

准确度高。其思路是这样的。虽然我们目前的解决方案 $U_k$ 离 $U^\ast$ 还很远，但我们为什么要特别精确地解决这个线性系统？更新后的 $U_{k+1}=U_k + \widetilde{\delta U}_k$ 很可能仍然离精确的解决方案很远，那么为什么要花很多时间来解决这个线性系统的精确性？这就是 "Eisenstat-Walker技巧" @cite eiwa96 等算法的基础思维，在该算法中，人们被赋予一个公差，在迭代 $k$ 中必须解决上述线性系统，该公差取决于整个非线性求解器的进展。像以前一样，我们可以尝试自己实现，但是KINSOL已经为我们提供了这种信息--尽管我们不会在这个程序中使用它，因为我们使用的是直接求解器，不需要求解器的容忍度，只是精确求解线性系统到舍入。

作为对所有这些考虑的总结，我们可以说以下几点。没有必要重新发明轮子。就像deal.II提供了大量的有限元功能一样，%SUNDIALS的KINSOL软件包提供了大量的非线性求解器功能，我们最好使用它。




<h3> How deal.II interfaces with KINSOL </h3>

KINSOL，像许多类似的软件包一样，以一种相当抽象的方式工作。在其核心部分，它看到了一个非线性问题，其形式为

@f{align*}{
    F(U) = 0


@f}

并构建一个迭代序列  $U_k$  ，一般来说，迭代序列是与函数返回的向量相同长度的向量  $F$  。要做到这一点，它需要从用户那里得到一些东西。

- 将一个给定的向量调整到正确大小的方法。

- 对于一个给定的向量 $U$ ，评估函数 $F(U)$ 的一种方法。这个函数通常被称为 "剩余 "操作，因为目标当然是找到一个点 $U^\ast$ ，对于这个点 $F(U^\ast)=0$ ；如果 $F(U)$ 返回一个非零向量，那么这就是<a href="https://en.wikipedia.org/wiki/Residual_(numerical_analysis)">"residual"</a>（即 "剩余"，或任何 "剩余"）。做到这一点的函数在本质上与步骤15中的右手边向量的计算相同，但有一个重要区别。   在那里，右手边表示的是残差的*负数，所以我们必须换一个符号。

- 计算矩阵 $J_k$ 的方法，如果这在当前迭代中是必要的，同时可能还有一个预处理程序或其他数据结构（例如，通过SparseDirectUMFPACK进行稀疏分解，如果我们选择用它来解决一个线性系统）。这个操作通常被称为 "设置 "操作。

- 用最后计算的任何矩阵 $\tilde J_k$ 来解决一个线性系统 $\tilde J_k x = b$ 的方法。这个操作一般被称为 "求解 "操作。

所有这些操作都需要由 [std::function](https://en.cppreference.com/w/cpp/utility/functional/function) 对象提供给KINSOL，这些对象接受适当的参数集，通常返回一个表示成功（返回值为零）或失败（返回值为非零）的整数。具体来说，我们要访问的对象是 SUNDIALS::KINSOL::reinit_vector,   SUNDIALS::KINSOL::residual,   SUNDIALS::KINSOL::setup_jacobian,  和  SUNDIALS::KINSOL::solve_jacobian_system  成员变量。(详见这些变量的文档。)在我们的实现中，我们将使用[lambda functions](https://en.cppreference.com/w/cpp/language/lambda)来实现这些 "回调"，反过来可以调用成员函数；然后KINSOL将在其内部算法认为有用时调用这些回调。




<h3> Details of the implementation </h3>

本教程程序的大部分代码与步骤15一样，我们将不作过多评论。实际上只有一个方面需要注意，即一方面给定一个向量 $U$ ，另一方面给定一个向量 $J(U)$ ，如何计算 $U$ 。起初，这似乎很简单：我们只需使用`assemble_system()`函数，在一种情况下抛出所有处理矩阵的代码，在另一种情况下抛出右手边的向量。就这样。问题解决了。

但它并不那么简单。这是因为如果我们有非零的Dirichlet边界值，这两者并不独立，就像我们在这里做的那样。我们要解决的线性系统包含内部和边界自由度，当从那些真正 "自由 "的自由度中消除这些自由度时，使用例如 AffineConstraints::distribute_local_to_global(), ，我们在组装右手边的向量时需要知道矩阵。

当然，这完全违背了原意。如果我们可以不组装矩阵，就不要*组装。我们解决这个问题的方法如下。

- 我们将解向量的起始猜测， $U_0$ ，设定为边界自由度已经有了正确的值。

- 这意味着所有的更新都可以有这些自由度的零更新，我们可以建立残差向量 $F(U_k)$ 和雅各布矩阵 $J_k$ ，对应于线性系统的解在这些向量分量中为零。对于这种特殊情况，矩阵和右手边向量的组装是独立的，可以分解成不同的函数。

这里有一个假设，即每当KINSOL要求用雅各布的（近似值）进行线性求解时，这将是为了更新 $\delta U$ （其边界值为零），其倍数将被添加到解决方案（其已经有正确的边界值）。  这可能不是真的，如果是的话，我们可能要重新考虑我们的方法。也就是说，事实证明，在实践中，这正是KINSOL在使用牛顿方法时的表现，因此我们的方法是成功的。


examples/step-77/doc/results.dox



<h1>Results</h1>

当运行该程序时，你得到的输出看起来像这样。

@code
Mesh refinement step 0
  Target_tolerance: 0.001


  Computing residual vector... norm=0.231202
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.231202
  Computing residual vector... norm=0.171585
  Solving linear system
  Computing residual vector... norm=0.171585
  Computing residual vector... norm=0.127245
  Computing residual vector... norm=0.0796471
  Solving linear system
  Computing residual vector... norm=0.0796471
  Computing residual vector... norm=0.0625301
  Solving linear system
  Computing residual vector... norm=0.0625301
  Computing residual vector... norm=0.0498864
  Solving linear system
  Computing residual vector... norm=0.0498864
  Computing residual vector... norm=0.0407765
  Solving linear system
  Computing residual vector... norm=0.0407765
  Computing residual vector... norm=0.0341589
  Solving linear system
  Computing residual vector... norm=0.0341589
  Computing residual vector... norm=0.0292867
  Solving linear system
  Computing residual vector... norm=0.0292867
  Computing residual vector... norm=0.0256309
  Computing residual vector... norm=0.0223448
  Solving linear system
  Computing residual vector... norm=0.0223448
  Computing residual vector... norm=0.0202797
  Computing residual vector... norm=0.0183817
  Solving linear system
  Computing residual vector... norm=0.0183817
  Computing residual vector... norm=0.0170464
  Computing residual vector... norm=0.0157967
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.0157967
  Computing residual vector... norm=0.0141572
  Computing residual vector... norm=0.012657
 Solving linear system
  Computing residual vector... norm=0.012657
  Computing residual vector... norm=0.0116863
  Computing residual vector... norm=0.0107696
  Solving linear system
  Computing residual vector... norm=0.0107696
  Computing residual vector... norm=0.0100986
  Computing residual vector... norm=0.00944829
  Computing residual vector... norm=0.00822576
  Solving linear system
  Computing residual vector... norm=0.00822576
  Computing residual vector... norm=0.00781983
  Computing residual vector... norm=0.00741619
  Computing residual vector... norm=0.00661792
  Solving linear system
  Computing residual vector... norm=0.00661792
  Computing residual vector... norm=0.00630571
  Computing residual vector... norm=0.00599457
  Computing residual vector... norm=0.00537663
  Solving linear system
  Computing residual vector... norm=0.00537663
  Computing residual vector... norm=0.00512813
  Computing residual vector... norm=0.00488033
  Computing residual vector... norm=0.00438751
  Computing residual vector... norm=0.00342052
  Solving linear system
  Computing residual vector... norm=0.00342052
  Computing residual vector... norm=0.00326581
  Computing residual vector... norm=0.00311176
  Computing residual vector... norm=0.00280617
  Computing residual vector... norm=0.00220992
  Solving linear system
  Computing residual vector... norm=0.00220992
  Computing residual vector... norm=0.00209976
  Computing residual vector... norm=0.00199943
  Solving linear system
  Computing residual vector... norm=0.00199942
  Computing residual vector... norm=0.00190953
  Computing residual vector... norm=0.00182005
  Computing residual vector... norm=0.00164259
  Computing residual vector... norm=0.00129652



+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.192s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assembling the Jacobian         |         2 |    0.0141s |       7.4% |
| assembling the residual         |        61 |     0.168s |        88% |
| factorizing the Jacobian        |         2 |    0.0016s |      0.83% |
| graphical output                |         1 |   0.00385s |         2% |
| linear system solve             |        19 |    0.0013s |      0.68% |
+---------------------------------+-----------+------------+------------+



Mesh refinement step 1
  Target_tolerance: 0.0001


  Computing residual vector... norm=0.0883422
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.0883422
  Computing residual vector... norm=0.0607066
  Solving linear system
  Computing residual vector... norm=0.0607066
  Computing residual vector... norm=0.0437266
  Solving linear system
  Computing residual vector... norm=0.0437266
  Computing residual vector... norm=0.0327999
  Solving linear system
  Computing residual vector... norm=0.0327999
  Computing residual vector... norm=0.0255418
  Solving linear system
  Computing residual vector... norm=0.0255417
  Computing residual vector... norm=0.0206042
  Solving linear system
  Computing residual vector... norm=0.0206042
  Computing residual vector... norm=0.0171602
  Solving linear system
  Computing residual vector... norm=0.0171602
  Computing residual vector... norm=0.014689
  Solving linear system


[...]
@endcode



通过查看第一个网格上的输出的前几行，应该最容易解释这种方式。

@code
Mesh refinement step 0
Mesh refinement step 0
  Target_tolerance: 0.001


  Computing residual vector... norm=0.231202
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.231202
  Computing residual vector... norm=0.171585
  Solving linear system
  Computing residual vector... norm=0.171585
  Computing residual vector... norm=0.127245
  Computing residual vector... norm=0.0796471
  Solving linear system
  Computing residual vector... norm=0.0796471
  ...
@endcode

现在的情况是这样的。

- 在第一次残差计算中，KINSOL计算残差以查看是否达到了所需的公差。答案是否定的，所以它要求用户程序计算雅各布矩阵（然后该函数还通过SparseDirectUMFPACK对矩阵进行因子化）。

- 然后KINSOL指示我们用这个矩阵和之前计算的残差向量来解决一个形式为 $J_k \, \delta U_k = -F_k$ 的线性系统。

- 然后就是确定我们要在这个方向上走多远，也就是做线搜索。为此，KINSOL要求我们计算不同步长 $\alpha_k$ 的残差向量 $F(U_k + \alpha_k \delta U_k)$  。对于上面的第一步，它在尝试了两次后找到了一个可接受的 $\alpha_k$ ，第二次则需要尝试三次。

- 在找到一个合适的更新解 $U_{k+1}$ 之后，这个过程被重复，只是现在KINSOL对当前的雅各布矩阵很满意，没有指示我们重新建立矩阵和它的因式分解，而是要求我们用同一个矩阵解决一个线性系统。

在每个网格细化周期结束时，程序也会将解决方案写入VTU文件，它看起来如下。   <table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-77.solution.png" alt="">
    </td>
  </tr>
</table> 


该计划的主要收获信息如下。

- 这个解和我们在步骤15中计算的解是一样的，也就是说，%SUNDIALS的KINSOL包的接口确实做了它们应该做的事。这不应该是一个惊喜，但重要的一点是，我们不必自己花时间去实现高级非线性求解器所依据的复杂算法。

- KINSOL能够避免各种操作，比如在实际上没有必要的时候重建雅各布矩阵。将上述输出中的线性求解次数与我们重建雅各布矩阵和计算其因式分解的次数相比较，应该可以清楚地看到，这在计算时间上带来了非常可观的节省，而我们却不需要实现复杂的算法来确定何时需要重建这些信息。

<a name="extensions"></a>

<h3> Possibilities for extensions </h3>

除了我们在这里考虑的小问题之外，稀疏的直接求解器需要太多的时间和内存--我们需要一个迭代求解器，就像我们在许多其他程序中使用的那样。然而，在目前的情况下，构建一个昂贵的预处理程序（例如，一个几何或代数多重网格方法）的权衡是不同的。由于我们可以在许多线性求解中重复使用同一个矩阵，我们也可以对预处理程序做同样的处理，与我们只在单一线性求解中使用预处理程序相比，在构建一个好的预处理程序上投入更多的工作更容易被证明，就像在许多其他情况下一样。

但迭代求解器也提供了其他机会。例如（正如在介绍中简要讨论的那样），只要我们离实际的解还很远，我们可能不需要在早期的非线性迭代中解到非常高的精度（小公差）。这就是那里提到的Eisenstat-Walker技巧的基础。

KINSOL提供了做线性解的函数，有一个需要达到的目标公差。我们在上面的程序中忽略了它，因为我们使用的直接求解器不需要公差，而是精确地求解线性系统（当然是四舍五入），但是迭代求解器可以利用这种信息--事实上也应该如此。


examples/step-78/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

布莱克-斯科尔斯方程是一个偏微分方程，它有点不符合普通的方案。它描述了一个 "欧洲看涨 "股票期权的公平价格是多少。不用说得太详细，股票 "期权 "是一个人可以从银行购买的合同，它允许我，但不要求我，在未来某个固定的时间 $T$ 以固定的价格 $K$ 购买特定股票。那么，作为这种期权的买方要回答的问题是："我认为这样的合约值多少钱？"，或者作为卖方，"我需要为这个合约收取多少钱？"，这既是合约在时间 $t<T$ 前的函数，也是股票价格 $S$ 的函数。费舍尔-布莱克和迈伦-斯科尔斯在假设股票价格表现出随机的价格波动，具有一定的 "波动性"，再加上背景的指数价格上涨（可以认为是通货膨胀率，随着时间的推移，所有货币都会贬值）的情况下，得出了这种期权的公平价格 $V(S,t)$ 的偏微分方程。由于他们的工作，布莱克和斯科尔斯在1997年获得了诺贝尔经济科学奖，这使得这是第一个处理有人获得诺贝尔奖的问题的教程程序  @cite black1973pricing  。

该公式如下。

@f{align*}{
    &\frac{\partial V}{\partial t} + \frac{\sigma^2S^2}{2} \
    \frac{\partial^2 V}{\partial S^2} + \
    rS\frac{\partial V}{\partial S} - rV = 0, \
    \quad\quad &&\forall S\in \Omega, t \in (0,T)
    \\
    &V(0,t) = 0, \
    &&\forall t \in (0,T)
    \\
    &V(S,t) \rightarrow S, \
    && \text{as } S \rightarrow \infty, \forall t \in (0,T)
    \\
    &V(S,T) = \max(S-K,0) \
    &&\forall S \in \Omega


@f}

其中

@f{align*}{
    V(S,t): && \text{Value of call option at time t and asset price S} \\
    \sigma: && \text{Volatility of the underlying asset} \\
    r: && \text{Risk free interest rate} \\
    K : && \text{Strike price for purchasing asset}


@f}



我们应该这样解释这个方程，它是一个时间依赖的偏微分方程，一个 "空间 "变量  $S$  是股票的价格， $V(S,t)$  是时间  $t$  的期权价格，如果当时的股票价格是  $S$  。

<h3>Particularities of the equation system</h3>

在继续讨论其数值解法之前，这个方程中存在一些值得讨论的怪异现象。首先，"空间 "域 $\Omega\subset\mathbb{R}$ 是无界的，因此 $S$ 的值也可以是无界的。这是因为股票价格可能有一个实际的上限，但没有一个概念上的上限。那么边界条件 $V(S,t)\rightarrow S$ 作为 $S\rightarrow \infty$ 可以解释如下。如果股票价格（今天或 $t=T$ 时）是 $S\gg K$ ，那么允许我以价格 $K$ 购买股票的期权的价值是多少？人们期望它是 $V\approx S-K$ 加上一些通货膨胀的调整，或者，如果我们真的真正考虑到 $S$ 的巨大价值，我们可以忽略 $K$ ，得出无限边界的边界值应该是上面所说的 $V\rightarrow S$ 形式。

在实践中，对于我们使用有限元方法来解决这个问题，我们需要对 $\Omega$ 进行约束。由于这个方程描述的是价格，而谈论价格为负值是没有意义的，我们将设定 $\Omega$ 的下限为0。然后，对于上限，我们将选择一个非常大的数字，一个 $S$ 不太可能达到的数字。我们将称其为 $S_\text{max}$ 。所以， $\Omega=[0,S_\text{max}]$  。

第二，在截断域之后，我们需要问在这个现在的有限边界上我们应该摆出什么边界值。为了解决这个问题，我们使用 "看跌-看涨 "平价  @cite stoll1969relationship  。一个 "拉动期权 "是指我们被允许，但不是必须，在未来的某个时间以价格  $K$  向某人出售*股票  $T$  。这说明

@f{align*}{
    V(S,t)+Ke^{-r(T-t)}=P(S,t)+S


@f}

其中 $V(S,t)$ 是看涨期权的价值，而 $P(S,t)$ 是看跌期权的价值。由于我们预计 $P(S,t) \rightarrow 0$ 为 $S \rightarrow \infty$ ，这说明

@f{align*}{
    V(S,t) \rightarrow S-Ke^{-r(T-t)},


@f}

而我们可以用这个作为我们的有限点的合理边界条件  $S_\text{max}$  。

Block-Scholes 方程的第二个复杂之处在于，我们得到的是一个最终条件，而不是初始条件。这是因为我们知道期权在 $t=T$ 时的价值：如果 $T$ 时的股票价格是 $S<K$ ，那么我们就没有动力使用我们的期权买入价格 $K$ ，因为我们可以在公开市场上以更低的价格买入该股票。所以 $V(S,T)=0$ 为 $S<K$  。另一方面，如果在 $T$ 时我们有 $S>K$ ，那么我们可以通过期权以 $K$ 的价格买入股票，并立即在市场上以 $S$ 的价格再次卖出，给我带来 $S-K$ 的利润。换句话说， $V(S,T)=S-K$ 换取 $S>K$  。因此，我们只知道在*结束时间*的 $V$ 的值，而不知道初始时间--事实上，找出当前时间的公平价格（传统上被认为是 $t=0$ ）是解决这些方程的关键所在。

这意味着这不是一个在时间上向前推进的方程，实际上是在时间上*向后推进的。因此，通过改变变量 $\tau=T-t$ 来反向解决这个问题是有意义的，现在 $\tau$ 表示打击时间 $T$ 之前的时间。

有了这一切，我们最终得到了以下问题。

@f{align*}{
    &-\frac{\partial V}{\partial \tau} + \frac{\sigma^2S^2}{2} \
    \frac{\partial^2 V}{\partial S^2} + rS\frac{\partial V}{\partial S} - rV=0\
    , \quad\quad &&\forall S\in [0,S_\text{max}], \tau \in [0,T]
    \\
    &V(0,\tau) = 0, \
    &&\forall \tau \in [0,T]
    \\
    &V(S_\text{max},\tau)=S_\text{max}-Ke^{-r\tau}, \
    &&\forall \tau \in [0,T]
    \\
    &V(S,0) = \max(S-K,0) \
    &&\forall S \in [0,S_\text{max}]


@f}



从概念上讲，这是一个变量 $V$ 的平流-扩散-反应问题：有一个二阶导数的扩散项，一个一阶导数的平流项，以及一个零阶反应项。我们可以预期这个问题在实践中会有一些宽容，因为对于现实中的系数值，它是扩散主导的。但是，由于问题中的平流项，我们将不得不小心地进行网格细化和时间步长的选择。还有一个问题是，扩散项是以非保守的形式写的，因此按部分积分并不明显。这将在下一节中讨论。

<h3>Scheme for the numerical solution</h3>

我们将使用IMEX方法解决这个问题。特别是，我们首先用theta方法进行时间离散，随后将为平流和扩散项选择不同的theta值。让 $V^n(S)$ 近似于 $V(S,\tau_n)$  。

@f{align*}{
    0=&-\frac{V^n(S)-V^{n-1}(S)}{k_n} \\
    &+\frac{\sigma^2S^2}{2}\left[(1-\theta)\frac{d^2V^{n-1}(S)}{dS^2} + \
    \theta \frac{d^2V^{n}(S)}{dS^2}\right] \\
    &+rS\left[(1-\theta)\frac{dV^{n-1}(S)}{dS} + \
    \theta\frac{dV^{n}(S)}{dS}\right]  \\
    &-r\left[(1-\theta)V^{n-1}(S) + \theta V^n(S)\right]


@f}

这里， $k_n=\tau_n-\tau_{n-1}$ 是时间步长。鉴于这种时间离散化，我们可以通过与测试函数相乘，然后通过部分积分来进行空间离散化。因为其中有一些有趣的细节，由于这个方程中的平流和非平流项，这个过程将被详细解释。

因此，我们首先用测试函数相乘， $\{\phi_i(S)\}_{i\in\mathbb{N}}$  。

@f{align*}{
    0=&-\int_0^{S_\text{max}}\phi_i(S)\left[V^n(S)-V^{n-1}(S)\right]dS \\
    &+k_n\int_0^{S_\text{max}}\phi_i(S)\left[\frac{\sigma^2S^2}{2} \
    \left[(1-\theta)\frac{d^2V^{n-1}(S)}{dS^2} + \
     \theta \frac{d^2V^{n}(S)}{dS^2}\right]\right]dS \\
    &+k_n\int_0^{S_\text{max}}\phi_i(S)\left[rS\left[(1-\theta)
     \frac{dV^{n-1}(S)}{dS}\
     + \theta\frac{dV^{n}(S)}{dS}\right]\right]dS  \\
    &-k_n\int_0^{S_\text{max}}\phi_i(S)\left[r\left[(1-\theta)V^{n-1}(S)\
     + \theta V^n(S)\right]\right]dS


@f}




像往常一样，（1）变成 $-\textbf{M}V^n+\textbf{M}V^{n-1}$ ，（4）变成 $k_n\left[-r(1-\theta)\textbf{M}V^{n-1} - \theta r\textbf{M}V^n\right]$ ，其中 $\textbf{M}_{i,j}=\left(\phi_i(S),\phi_j(S)\right)$ ，我们不仅用 $V$ 表示函数 $V(S)$ ，而且用离散化后的节点值向量表示。

有趣的部分来自于（2）和（3）。


对于（2），我们有。

@f{align*}{
    &k_n\int_0^{S_\text{max}}\phi_i(S)\left[\frac{\sigma^2S^2}{2} \
     \left[(1-\theta)\frac{d^2V^{n-1}(S)}{dS^2} + \
     \theta \frac{d^2V^{n}(S)}{dS^2}\right]\right]dS \\
    &=k_n(1-\theta)\int_0^{S_\text{max}}\phi_i(S)\frac{\sigma^2S^2}{2} \
     \frac{d^2V^{n-1}(S)}{dS^2} \
    +k_n\theta\int_0^{S_\text{max}}\phi_i(S)\frac{\sigma^2S^2}{2} \
     \frac{d^2V^{n}(S)}{dS^2}


@f}



这里有两个积分，或多或少都是一样的，区别在于积分前面的系数略有不同，以及V的时间步骤不同。因此，考虑一般的积分，我们将用部分积分的方法来解决这个问题。

@f{align*}{
    &\int_{0}^{S_\text{max}} \phi_i(S)\frac{\sigma^2S^2}{2}
        \frac{d^2V^n(S)}{dS^2}dS \\
    &= \phi_i(S)\frac{1}{2}\sigma^2S^2\frac{dV^n(S)}{dS}\Bigg|_0^{S_{max}} - \
    \int_0^{S_\text{max}} \phi_i(S)\sigma^2S\frac{dV^n(S)}{dS}dS - \
    \int_0^{S_\text{max}} \frac{d\phi_i(S)}{dS}\frac{1}{2}\sigma^2S^2 \
    \frac{dV^n(S)}{dS}dS \\
    &= -\int_0^{S_\text{max}} \phi_i(S)\sigma^2S\frac{dV^n(S)}{dS}dS - \
    \int_0^{S_\text{max}} \frac{d\phi_i(S)}{dS}\frac{1}{2}\sigma^2S^2 \
    \frac{dV^n(S)}{dS}dS \\
    &= -\int_0^{S_\text{max}} \phi_i(S)\sigma^2S \sum_j V_j^n
        \frac{d\phi_j(S)}{dS}dS \


    -\int_0^{S_\text{max}} \frac{d\phi_i(S)}{dS}\frac{1}{2} \
    \sigma^2S^2  \sum_k V_k^n \frac{d\phi_k(S)}{dS}dS \\
    &= -\sum_j \sigma^2 \int_0^{S_\text{max}} \phi_i(S)S
        \frac{d\phi_j(S)}{dS}dS V_j^n\


    - \sum_k \frac{1}{2}\sigma^2 \int_0^{S_\text{max}} \frac{d\phi_i(S)}{dS}S^2\
    \frac{d\phi_k}{dS}dS V_k^n \\
    &= -\sum_j \sigma^2 \left(\phi_i(S)S, \frac{d\phi_j(S)}{dS}\right) V_j^n \


    - \sum_k \frac{1}{2}\sigma^2 \left(\frac{d\phi_i(S)}{dS}S^2,\
    \frac{d\phi_k(S)}{dS}\right) V_k^n \\
    &= -\sigma^2\textbf{B}V^n - \frac{1}{2}\sigma^2\textbf{D}V^n, \quad\quad \
    \textbf{B}_{i,j} = \left(\phi_i(S)S, \frac{d\phi_j(S)}{dS}\right),\
    \textbf{D}_{i,j} = \left(\frac{d\phi_i(S)}{dS}S^2,\frac{d\phi_j(S)}{dS}\right)


@f}



因此，在加入常数并将 $V^n$ 换成 $V^{n-1}$ （如适用）后，我们对（2）得出如下结论。

@f{align*}{
    &k_n\int_0^{S_\text{max}}\phi_i(S)\left[\frac{\sigma^2S^2}{2}
        \left[(1-\theta)\
    \frac{d^2V^{n-1}(S)}{dS^2} + \
    \theta \frac{d^2V^{n}(S)}{dS^2}\right]\right]dS \\
    &= k_n\left[-(1-\theta)\sigma^2\textbf{B}V^{n-1}\


     -(1-\theta)\frac{1}{2}\sigma^2\textbf{D}V^{n-1} \


    -\theta\sigma^2\textbf{B}V^{n}


     -\theta\frac{1}{2}\sigma^2\textbf{D}V^{n}\right]


@f}

但是，由于矩阵 $\textbf{B}$ 涉及一个平流项，我们将在那里选择 $\theta=0$ --换句话说，我们使用显式欧拉方法来处理平流问题。相反，由于矩阵 $\textbf{D}$ 涉及扩散项，我们将在那里选择 $\theta=1/2$ --即我们用二阶Crank-Nicolson方法处理扩散。

因此，我们得出以下结论。

@f{align*}{
    k_n\left[-\frac{1}{4}\sigma^2\textbf{D}V^{n-1} \


    -\frac{1}{4}\sigma^2\textbf{D}V^n \


    - \sigma^2\textbf{B}V^{n-1}\right]


@f}



现在，要处理（3）。为此，我们将再次通过考虑上述的一般情况来进行。

@f{align*}{
    &\int_{0}^{S_\text{max}} \phi_i(S)rS\frac{dV^n}{dS}dS \\
    &= \phi_i(S)rSV^n\Bigg|_0^{S_\text{max}} - \int_0^{S_\text{max}}
        \left[r\phi_i(S) \
    + r\frac{d\phi_i(S)}{dS}S \right]V^ndS \\
    &= -\int_0^{S_\text{max}} r\phi_i(S)V^ndS - \
    \int_0^{S_\text{max}} r\frac{d\phi_i(S)}{dS}SV^ndS \\
    &= -\int_0^{S_\text{max}} r\phi_i(S) \sum_j V_j^n\phi_j(S)dS \


    -\int_0^{S_\text{max}} rS\frac{d\phi_i(S)}{dS} \sum_k V_k\phi_k(S)dS \\
    &= -\sum_j r\left(\phi_i(S), \phi_j(S)\right) V_j^n -\
     \sum_k r\left(S\frac{d\phi_i(S)}{dS}, \phi_k(S)\right)V_k^n \\
    &= -r\textbf{M}V^n -r\textbf{A}V^n, \quad\quad\
    \textbf{M}_{i,j} = \left(\phi_i(S), \phi_j(S)\right),\
    \textbf{A}_{i,j} = \left(S\frac{d\phi_i(S)}{dS}, \phi_j(S)\right)


@f}



因此，在加入常数并将 $V^n$ 换成 $V^{n-1}$ （如适用）后，我们对（3）得出如下结论。

@f{align*}{
    &k_n\int_0^{S_\text{max}}\phi_i(S)\left[rS\left[(1-\theta)
        \frac{dV^{n-1}(S)}{dS} +\
     \theta\frac{dV^{n}(S)}{dS}\right]\right]dS \\
    &= k_n\left[-(1-\theta)r\textbf{M}V^{n-1} -(1-\theta)r\textbf{A}V^{n-1}\


    -\theta r\textbf{M}V^n -\theta r\textbf{A}V^n\right]


@f}

就像以前一样，我们将用 $\theta=0$ 来表示矩阵 $\textbf{A}$ ，用 $\theta=\frac{1}{2}$ 表示矩阵 $\textbf{M}$  。因此，我们对（3）得出以下结果。

@f{align*}{
    k_n\left[-\frac{1}{2}r\textbf{M}V^{n-1} - \frac{1}{2}r\textbf{M}V^n \


    -r\textbf{A}V^{n-1}\right]


@f}



现在，把所有的东西放在一起，我们得到以下布莱克-斯科尔斯方程的离散形式。

@f{align*}{
    0&= \\
    &-\textbf{M}V^n+\textbf{M}V^{n-1} \\
    & +k_n\left[-\frac{1}{4}\sigma^2\textbf{D}V^{n-1} \


    -\frac{1}{4}\sigma^2\textbf{D}V^n \


    - \sigma^2\textbf{B}V^n \


     -\frac{1}{2}r\textbf{M}V^{n-1} - \frac{1}{2}r\textbf{M}V^n \


    -r\textbf{A}V^n \


     -r\frac{1}{2}\textbf{M}V^{n-1} - \frac{1}{2} r\textbf{M}V^n\right] \\
    &= -\textbf{M}V^n + \textbf{M}V^{n-1} +\
    k_n\left[- \frac{1}{4}\sigma^2\textbf{D}V^{n-1} -\
    \frac{1}{4}\sigma^2\textbf{D}V^n - r\textbf{M}V^{n-1} -\
    r\textbf{M}V^n  - \sigma^2\textbf{B}V^{n-1} - r\textbf{A}V^{n-1}\right]


@f}

因此，我们总共有。

@f{equation}{
    0 = \textbf{M}V^n - \textbf{M}V^{n-1} +\
    k_n\left[ \frac{1}{4}\sigma^2\textbf{D}V^{n-1} +\
    \frac{1}{4}\sigma^2\textbf{D}V^n + r\textbf{M}V^{n-1} + r\textbf{M}V^n  +\
    \sigma^2\textbf{B}V^{n-1} + r\textbf{A}V^{n-1}\right]\tag{*}


@f}



像往常一样，我们可以把未知量写在左边，把已知量写在右边。这就导致了在每个时间步骤中必须解决的以下线性系统。

@f{align*}{
    \left[\textbf{M}+\frac{1}{4}k_n\sigma^2\textbf{D}+k_nr\textbf{M}\right]V^n\
     =\
    \left[-\frac{1}{4}k_n\sigma^2\textbf{D}-\
    k_nr\textbf{M}+k_n\sigma^2\textbf{B}-\
    k_nr\textbf{A}+\textbf{M}\right]V^{n-1}


@f}









<h3>Test Case</h3> 对于这个程序，我们将使用制造解决方案的方法（MMS）来测试它是否正确工作。这意味着，我们将选择我们的解决方案是类似于步骤7的某个函数。对于我们的案例，我们将使用。

@f{align*}{
    V(S,\tau) = -\tau^2 - S^2 + 6\tag{**}


@f}

这意味着，利用我们的PDE，我们得出了以下问题。

@f{align*}{
    &-\frac{\partial V}{\partial \tau} +\
    \frac{\sigma^2S^2}{2}\frac{\partial^2 V}{\partial S^2} +\
    rS\frac{\partial V}{\partial S} - rV = f(S,\tau) \\
    &V(0,\tau) = -\tau^2 + 6 \\
    &V(S_\text{max}, \tau) = -S_\text{max}^2 - \tau^2 + 6 \\
    &V(S, 0) = -S^2 + 6


@f}

其中， $f(S,\tau) = 2\tau - \sigma^2S^2 - 2rS^2 - r(-\tau^2 - S^2 + 6)$  。这个设置现在有方程本身和 $S=0$ 处的边界条件的右手边，这是我们以前没有的，同时还有不符合实际情况的 "最终 "条件（或者，用 $\tau$ -时间 "初始条件"）。我们将以这样的方式在代码中实现这一点，以便于交换 -- 上述变化的引入只是为了能够使用制造的解决方案。

如果程序工作正常，那么它应该产生（**）作为解决方案。这确实意味着我们需要在一定程度上修改我们的变异形式，以考虑到非零的右手边。

首先，我们定义如下。

@f{align*}{
    F^n_i = \left(\phi_i(S), f^n(S)\right), && \text{where } f^n(S) =\
     f(S,\tau_n)


@f}

因此，我们得出了新的方程式。

@f{align*}{
    \left[\textbf{M}+\frac{1}{4}k_n\sigma^2\textbf{D}+k_nr\textbf{M}\right]V^n\
     =\
     \left[-\frac{1}{4}k_n\sigma^2\textbf{D}-\
     k_nr\textbf{M}+k_n\sigma^2\textbf{B}-\
     k_nr\textbf{A}+\textbf{M}\right]V^{n-1} -\
      k_n\left[\frac{1}{2}F^{n-1}+\frac{1}{2}F^n\right]


@f}



然后我们按上述方法解决这个方程。


examples/step-78/doc/results.dox



<h1>Results</h1>


下面是该程序的输出。

@code
===========================================
Number of active cells: 1
Number of degrees of freedom: 2


Time step 0 at t=0.0002
[...]


Cycle 7:
Number of active cells: 128
Number of degrees of freedom: 129


Time step 0 at t=0.0002
Time step 1000 at t=0.2002
Time step 2000 at t=0.4002
Time step 3000 at t=0.6002
Time step 4000 at t=0.8002


cells dofs    L2        H1      Linfty
    1    2 1.667e-01 5.774e-01 2.222e-01
    2    3 3.906e-02 2.889e-01 5.380e-02
    4    5 9.679e-03 1.444e-01 1.357e-02
    8    9 2.405e-03 7.218e-02 3.419e-03
   16   17 5.967e-04 3.609e-02 8.597e-04
   32   33 1.457e-04 1.804e-02 2.155e-04
   64   65 3.307e-05 9.022e-03 5.388e-05
  128  129 5.016e-06 4.511e-03 1.342e-05


n cells         H1                  L2
      1 5.774e-01    -    - 1.667e-01    -    -
      2 2.889e-01 2.00 1.00 3.906e-02 4.27 2.09
      4 1.444e-01 2.00 1.00 9.679e-03 4.04 2.01
      8 7.218e-02 2.00 1.00 2.405e-03 4.02 2.01
     16 3.609e-02 2.00 1.00 5.967e-04 4.03 2.01
     32 1.804e-02 2.00 1.00 1.457e-04 4.10 2.03
     64 9.022e-03 2.00 1.00 3.307e-05 4.41 2.14
    128 4.511e-03 2.00 1.00 5.016e-06 6.59 2.72
@endcode



更有趣的是收敛表的输出。它们被输出到控制台，以及一个LaTeX文件中。收敛表如上所示。在这里，你可以看到，相对于 $H^1$ -norm，解决方案的收敛率为 $\mathcal{O}(h)$ ，相对于 $L^2$ -norm，解决方案的收敛率为 $\mathcal{O}(h^2)$ 。


下面是解决方案的可视化。

<div style="text-align:center;"> <img src="https://www.dealii.org/images/steps/developer/step-78.mms-solution.png" alt="MMS问题的解决方案。"> </div>


examples/step-79/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

弹性介质的拓扑优化是一种用于优化承受某种载荷的结构的技术。理想情况下，我们希望通过选择一个放置材料的区域 $E$ ，使置于结构上的最大应力最小化。换句话说。

@f[
  \text{minimize}\| \boldsymbol{\sigma} (\mathbf{u}) \|_\infty


@f]



@f[
  \text{subject to } |E|\leq V_{\max},


@f]



@f[
  \text{and } \nabla \cdot \boldsymbol{\sigma} + \mathbf{F} = \mathbf{0}.


@f]



这里， $\boldsymbol{\sigma} = \mathbf{C} : \boldsymbol{\varepsilon}(\mathbf{u})$ 是由外力 $\mathbf F$ 引起的体内应力，为了简单起见，我们假设材料是线性弹性的，因此 $\mathbf{C}$ 是应力-应变张量， $\boldsymbol{\varepsilon}(\mathbf{u})=\frac{1}{2} (\nabla \mathbf{u} + (\nabla\mathbf{u})^T)$ 是作为位移 $\mathbf{u}$ 函数的小变形应变--关于线性弹性的详情，见步骤8 和步骤17。在上面的表述中， $V_\text{max}$ 是我们愿意为构建物体提供的最大材料量。最后一个约束条件是与应力 $\boldsymbol{\sigma}$ 和力 $\mathbf F$ 有关的偏微分方程，它只是稳态力平衡。

也就是说，上面的无穷大准则产生了一个问题：作为材料位置的函数，这个目标函数必然是不可微分的，使优化的前景相当暗淡。因此，取而代之的是，拓扑优化的一个常见方法是通过优化一个相关的问题来找到一个近似的解决方案：我们希望最小化应变能量。这是对物体因变形而储存的势能的衡量，同时也是对结构总变形的衡量。

@f[
  \text{minimize  } \int_E \frac{1}{2}\boldsymbol{\sigma} : \boldsymbol{\varepsilon} dV


@f]



@f[
  \text{subject to } \|E\| \leq V_{\max}


@f]



@f[
  \text{and } \nabla \cdot \boldsymbol{\sigma} + \mathbf{F} = \mathbf{0}


@f]



目标函数的值是用有限元方法计算的，其中的解决方案是位移。这被放置在一个非线性求解器的循环中，求解一个表示材料放置的向量。

<h3>Solid Isotropic Material with Penalization</h3>

在实际操作中，我们只能建造材料在任何给定的点上要么存在，要么不存在的物体--也就是说，我们会有一个描述材料填充区域的指标函数 $\rho_E(\mathbf{x})\in \{0,1\}$ ，并且我们想通过优化问题找到这个指标。在这种情况下，优化问题变成了组合性的，而且解决起来非常昂贵。取而代之的是，我们使用一种叫做各向同性的固体材料与惩罚的方法，或SIMP。   @cite Bendse2004 

SIMP方法是基于一个想法，即允许材料存在于密度 $\rho$ 在0和1之间的位置。密度为0表明材料不存在，它不是结构的一部分，而密度为1表明材料存在。0和1之间的值并不反映我们在现实世界中可以创造的设计，但允许我们将组合问题变成一个连续问题。然后我们看一下密度值  $\rho$  ，约束条件是  $0 < \rho_{\min} \leq \rho \leq 1$  。最小值 $\rho_{\min}$ ，通常选择在 $10^{-3}$ 左右，避免了出现无限应变能量的可能性，但小到足以提供准确的结果。

这种 "密度 "对介质弹性的影响的直接应用是简单地将介质的刚度张量 $\mathbf{C}_0$ 乘以给定的密度，即 $\mathbf{C} = \rho \mathbf{C}_0$  。然而，这种方法经常给出密度值离0和1都很远的最佳解决方案。由于人们希望找到一个现实世界的解决方案，即材料要么存在，要么不存在，因此对这些介于两者之间的值进行惩罚。一个简单有效的方法是将刚度张量乘以密度，并将其提高到某个整数功率的惩罚参数  $p$  ，因此  $\mathbf{C} = \rho^p \mathbf{C}_0$  。这使得远离0或1的密度值变得不那么有效。已经证明，使用 $p=3$ 足够高，可以产生'黑白'的解决方案：也就是说，可以得到最佳的解决方案，其中材料在所有点上要么存在，要么不存在。

更多的材料应该总是提供一个具有较低应变能量的结构，因此不等式约束可以被看作是一个等式，其中使用的总体积是最大体积。

使用这种密度思想也使我们能够重新构建优化问题的体积约束。使用SIMP后，优化问题就变成了以下内容。

@f[
  \text{minimize  } \int_\Omega \frac{1}{2}\boldsymbol{\sigma}(\rho) : \boldsymbol{\varepsilon}(\rho) d\Omega


@f]



@f[
  \text{subject to } \int_\Omega \rho(x) d\Omega= V_{\max},


@f]



@f[
  0<\rho_{\min}\leq \rho(x) \leq 1,


@f]



@f[


  \nabla \cdot \boldsymbol{\sigma}(\rho) + \mathbf{F} = 0 \quad \text{on } \Omega


@f]

最后一个约束，即线性动量的平衡（我们将称之为弹性方程），给出了一种在给定密度 $\boldsymbol{\sigma}$ 和 $\boldsymbol{\varepsilon}$ 的情况下寻找 $\rho$  的方法。

<h3>Elasticity Equation</h3> 在与时间无关的极限中，弹性方程为

@f[
  \nabla \cdot \boldsymbol{\sigma} + \mathbf{F} = \mathbf{0} .


@f]

在我们将关注的情况下，我们将假设介质具有线性材料响应，在这种情况下，我们有

@f[
  \boldsymbol{\sigma} = \mathbf{C} : \boldsymbol{\varepsilon} = \rho^p \mathbf{C}_0 : \boldsymbol{\varepsilon}(\mathbf{u})
   = \rho^p \mathbf{C}_0 : \left[\frac{1}{2} (\nabla \mathbf{u} + (\nabla \mathbf{u})^T) \right] .


@f]

在我们下面要做的一切中，我们将始终把位移场 $\mathbf{u}$ 视为唯一的解变量，而不是把 $\mathbf{u}$ 和 $\boldsymbol{\sigma}$ 视为解变量（像在混合公式中那样）。

此外，我们将假设材料是线性各向同性的，在这种情况下，应力-应变张量可以用Lam&eacute;参数 $\lambda,\mu$ 来表示，例如

@f{align}
  \boldsymbol{\sigma} &= \rho^p (\lambda \text{tr}(\boldsymbol{\varepsilon}) \mathbf{I} + 2 \mu \boldsymbol{\varepsilon}) , \\
  \sigma_{i,j} &= \rho^p (\lambda \varepsilon_{k,k} \delta_{i,j} + 2 \mu \varepsilon_{i,j}) .


@f}

参见步骤8，了解这种转变的原理。

对目标函数进行分项积分，得到

@f[
  \int_\Omega \boldsymbol{\sigma}(\rho) : (\nabla \mathbf{u} + (\nabla \mathbf{u}))^T  d\Omega+
  \int_\Omega (\nabla \cdot \boldsymbol{\sigma}(\rho)) \cdot \mathbf{u}  d\Omega=
  \int_{\partial \Omega} \mathbf{t} \cdot \mathbf{u} d\partial\Omega ,


@f]

然后将线性弹性方程代入其中，可以得到

@f[
  \int_\Omega \boldsymbol{\sigma}(\rho) : (\nabla \mathbf{u} + (\nabla \mathbf{u})^T) d\Omega =
  \int_\Omega \mathbf{F}\cdot \mathbf{u} d\Omega+
  \int_{\partial \Omega} \mathbf{t} \cdot \mathbf{u} d\partial\Omega .


@f]

因为我们假设没有身体的力量，这进一步简化为

@f[
  \int_\Omega \boldsymbol{\sigma}(\rho) : (\nabla \mathbf{u} + (\nabla \mathbf{u})^T) d\Omega
  = \int_{\partial \Omega} \mathbf{t} \cdot \mathbf{u} d\partial\Omega,


@f]

这就是我们从现在开始要考虑的治理方程的最终形式。

<h3>Making the solution mesh-independent</h3>

通常情况下，拓扑优化问题的解决方案是依赖于网格的，因此问题是不成立的。这是因为随着网格的进一步细化，往往会形成分形结构。随着网格分辨率的提高，最优解通常会获得越来越小的结构。对于这个问题，有一些相互竞争的解决方法，但对于一阶优化来说，最流行的是灵敏度滤波器，而二阶优化方法则倾向于使用密度滤波器。

由于滤波器会影响应变能量的梯度和Hessian（即目标函数），所以滤波器的选择会对问题的解决产生影响。作为二阶方法的一部分，密度滤波器的工作原理是引入一个未经过滤的密度，我们称之为 $\varrho$  ，然后要求密度是未经过滤的密度的卷积。

@f[
  \rho = H(\varrho).


@f]

这里， $H$ 是一个运算符，因此 $\rho(\mathbf{x})$ 是 $\varrho$ 在 $\mathbf{x}$ 周围区域的某种平均值 -- 即，它是 $\varrho$ 的平滑版本。

这可以防止棋盘效应；滤波器的半径允许用户为我们寻求的最佳结构定义一个有效的最小光束宽度。

<div style="text-align:center;"> <img src="https://www.dealii.org/images/steps/developer/step-79.checkerboard.png" alt="Checkerboarding occurring in an MBB Beam"> </div>

<h3>Complete Problem Formulation</h3>

现在的最小化问题是

@f[
  \min_{\rho,\varrho,\mathbf{u}} \int_{\partial\Omega} \mathbf{u} \cdot \mathbf{t} d\partial\Omega


@f]



@f[
  \text{subject to   } \rho = H(\varrho)


@f]



@f[
  \int_\Omega \rho^p \left(\frac{\mu}{2}\left(\boldsymbol{\varepsilon}(\mathbf{v}):
  \boldsymbol{\varepsilon}(\mathbf{u})) \right) + \lambda \left( \nabla \cdot \mathbf{u} \nabla
  \cdot \mathbf{v} \right)  \right) d\Omega = \int_{\partial \Omega} \mathbf{v} \cdot
  \mathbf{t} d\partial\Omega


@f]



@f[
  \int_\Omega \rho d\Omega= V


@f]



@f[
  0\leq \varrho \leq 1


@f]



处理不等式约束的方法是，首先引入松弛变量，其次使用对数障碍来确保我们得到一个内点方法。惩罚参数将是 $\alpha$  ，下面的松弛变量是<ol>  <li>   $s_1$  -对应于下限的松弛变量  </li>   <li>   $s_2$  -对应于上限的松弛变量。 </li>   </ol>  现在得出以下问题。

@f[
  \min_{\rho,\varrho,\mathbf{u}, s_1, s_2} \int_{\partial\Omega} \mathbf{u} \cdot
  \mathbf{t} d\partial\Omega- \alpha \int_\Omega \left(\log(s_1) + \log(s_2)\right) d\Omega


@f]



@f[
  \text{subject to   } \rho = H(\varrho)


@f]



@f[
  \int_\Omega \rho^p \left(\frac{\mu}{2}\left(\boldsymbol{\varepsilon}(\mathbf{v}):
  \boldsymbol{\varepsilon}(\mathbf{u})) \right) + \lambda \left( \nabla \cdot \mathbf{u} \nabla
  \cdot \mathbf{v} \right)  \right) d\Omega = \int_{\partial \Omega} \mathbf{v} \cdot
  \mathbf{t} d\partial\Omega


@f]



@f[
  \int_\Omega \rho d\Omega = V


@f]



@f[
  \varrho = s_1


@f]



@f[
  1-\varrho = s_2


@f]



有了这些变量，我们就可以按照通常的方法来解决限制性优化问题。我们引入一个拉格朗日，通过将约束条件乘以拉格朗日乘数，将目标函数和约束条件结合起来。具体来说，我们将使用以下符号表示各种约束条件的拉格朗日乘数。<ol>  <li>   $\mathbf{y}_1 $  ：对应于弹性约束的拉格朗日乘数，  </li>   <li>   $y_2$  ：对应于卷积过滤器约束的拉格朗日乘数，  </li>   <li>   $z_1$  ：对应于下层松弛变量的拉格朗日乘数，以及  </li>   <li>   $z_2$  ：对应于上限松弛变量的拉格朗日乘数。   </li>   </ol>  有了这些变量，拉格朗日函数的内容如下。

@f{align}{
  \mathcal{L} =& \int_{\partial\Omega} \mathbf{u} \cdot \mathbf{t} d\partial\Omega


   - \alpha \int_\Omega \left(\log(s_1) + \log(s_2)\right) d\Omega-  \int_\Omega
   \rho^p \left(\frac{\mu}{2}\left(\boldsymbol{\varepsilon}(\mathbf{y}_1):\boldsymbol{\varepsilon}(\mathbf{u}))
   \right) + \lambda \left( \nabla \cdot \mathbf{u} \nabla \cdot \mathbf{y}_1
   \right)\right) d\Omega - \int_{\partial \Omega} \mathbf{y}_1 \cdot \mathbf{t} d\partial\Omega  \\
   & -\int_\Omega y_2 (\rho - H(\varrho)) d\Omega - \int_\Omega z_1 (\varrho-s_1) d\Omega


   - \int_\Omega z_2 (1 - s_2 -\varrho) d\Omega


@f}



然后优化问题的解决方案需要满足所谓的[Karush-Kuhn-Tucker（KKT）条件]（https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions）。拉格朗日相对于其所有参数的导数需要等于零，而且由于我们有不等式约束，我们也有 "互补性 "条件。由于我们这里有一个无穷大的问题，这些条件都涉及到拉格朗日相对于某些测试函数的方向性导数--换句话说，所有这些条件都必须以弱形式表述，因为这通常是有限元方法的基础。

障碍法允许我们最初削弱典型的KKT条件所要求的 "补充松弛"。通常情况下，我们会要求 $s_i z_i = 0$  ，但屏障公式给出的KKT条件是 $s_i z_i = \alpha$  ，其中 $\alpha$  是我们的屏障参数。作为障碍法的一部分，这个参数必须被驱动到接近0，以便对原始问题有一个良好的近似。

在下文中，让我们陈述所有这些条件，其中 $d_{\{\bullet\}}$ 是一个测试函数，它与拉格朗日相对于 $\{\bullet\}$ 函数的变异导数自然成对。为了简单起见，我们引入 $\Gamma$ 来表示边界上受力的部分，并使用诺伊曼边界条件。

<ol>  <li>  静止性。

@f[
  \int_\Omega  - d_\rho y_2 + p\rho^{p-1}d_\rho \left[\lambda
  (\nabla \cdot \mathbf{y}_1) (\nabla \cdot \mathbf{u}) +
  \mu \boldsymbol{\varepsilon}(\mathbf{u}):\boldsymbol{\varepsilon}(\mathbf{y}_1)\right] d\Omega=0\;\;
  \forall d_\rho


@f]



@f[
  \int_\Gamma \mathbf d_\mathbf{u} \cdot \mathbf{t} d\partial\Omega+ \int_\Omega p\rho^{p}
  \left[\lambda (\nabla \cdot \mathbf d_\mathbf{u})( \nabla \cdot \mathbf{y}_1)
  + \mu \boldsymbol{\varepsilon}(\mathbf d_\mathbf{u}):\boldsymbol{\varepsilon}(\mathbf{y}_1)\right] d\Omega=0\;\;
  \forall \mathbf{d}_\mathbf{u}


@f]



@f[
  \int_\Omega -d_\varrho z_1 + d_\varrho z_2 + H(d_\varrho)y_2 d\Omega= 0\;\;\forall
  d_\varrho


@f]

 </li>   <li>  原始的可行性。

@f[
  \int_\Omega \rho^{p}\lambda (\nabla \cdot \mathbf d_{\mathbf{y}_1})
  (\nabla \cdot \mathbf{u}) +  \rho^{p}\mu  \boldsymbol{\varepsilon}(\mathbf
  d_{\mathbf{y}_1}) : \boldsymbol{\varepsilon}(\mathbf{u}) d\Omega - \int_\Gamma \mathbf
  d_{\mathbf{y}_1} \cdot \mathbf{t} d\partial\Omega =0 \;\;\forall \mathbf{d}_{\mathbf{y}_1}


@f]



@f[
  \int_\Omega d_{z_1}(\varrho - s_1) d\Omega = 0\;\;\forall d_{z_1}


@f]



@f[
  \int_\Omega d_{z_z}(1-\varrho-s_2) d\Omega = 0\;\;\forall d_{z_2}


@f]



@f[
  \int_\Omega d_{y_2}(\rho - H(\varrho)) d\Omega = 0\;\;\forall d_{y_2}


@f]

 </li>   <li>  互补性松弛。

@f[
  \int_\Omega d_{s_1}(s_1z_1 - \alpha) d\Omega = 0 \;\;\forall d_{s_1} ,\;\;\;
  \alpha \to 0


@f]



@f[
  \int_\Omega d_{s_2}(s_2z_2 - \alpha) d\Omega = 0  \;\;\forall d_{s_2} ,\;\;\;
  \alpha \to 0


@f]

 </li>   <li>  双重可行性。

@f[
  s_{1,i},s_{2,i},z_{1,i},z_{2,i} \geq 0 \;\;\;\; \forall i


@f]

 </li>  </ol>  。

<h3>Solution procedure</h3>

上面的优化条件除了复杂之外，还属于不容易解决的类型。它们通常是非线性的，而且有些关系也是不等式的。我们将使用牛顿方法计算搜索方向来解决非线性问题，并在下面讨论步长程序时再来讨论如何处理不等式问题。

牛顿方法应用于上述方程的结果是下面列出的方程组。其中，关于 $\{\bullet\}$ 变量的变异导数在 $c_{\{\bullet\}}$ 方向取值。

<ol>  <li>  静止性。这些方程确保我们在受约束时处于目标函数的临界点。

方程式1

@f{align}{
  &\int_\Omega-d_\rho c_{y_2} + p(p-1) \rho^{p-2} d_\rho c_\rho [\lambda \nabla
  \cdot \mathbf{y}_1 \nabla \cdot \mathbf{u} +  \mu  \boldsymbol{\varepsilon}(\mathbf{u})
  \boldsymbol{\varepsilon}(\mathbf{y}_1)]
  + p \rho^{p-1} d_\rho[\lambda \nabla \cdot
  \mathbf{c}_{\mathbf{y}_1} \nabla \cdot \mathbf{u} +   \mu  \boldsymbol{\varepsilon}
  (\mathbf{u}) \boldsymbol{\varepsilon}(\mathbf{c}_{\mathbf{y}_1})]  +  p \rho^{p-1} d_\rho
  [\lambda \nabla \cdot {\mathbf{y}_1} \nabla \cdot \mathbf{c}_\mathbf{u} +
  \mu  \boldsymbol{\varepsilon}(\mathbf{c}_\mathbf{u}) \boldsymbol{\varepsilon}(\mathbf{y}_1)] d\Omega \\
  &= -\int_\Omega -d_\rho z_1 + d_\rho z_2 - d_\rho y_2 + p\rho^{p-1}d_\rho
[\lambda \nabla \cdot \mathbf{y}_1 \nabla \cdot \mathbf{u} + \mu \boldsymbol{\varepsilon}
(\mathbf{u})\boldsymbol{\varepsilon}(\mathbf{y}_1)] d\Omega


@f}



方程式2

@f{align}{
  &\int_\Omega p \rho^{p-1} c_\rho [\lambda \nabla \cdot {\mathbf{y}_1} \nabla
  \cdot \mathbf{d}_\mathbf{u} +  \mu  \boldsymbol{\varepsilon}(\mathbf{d}_\mathbf{u})
  \boldsymbol{\varepsilon}(\mathbf{y})] + \rho^{p} [\lambda \nabla \cdot
  \mathbf{c}_{\mathbf{y}_1} \nabla \cdot \mathbf{d}_\mathbf{u} +  \mu
  \boldsymbol{\varepsilon}(\mathbf{d}_\mathbf{u})\boldsymbol{\varepsilon}(\mathbf{c}_{\mathbf{y}_1})] d\Omega \\
  &= -\int_\Gamma \mathbf{d}_\mathbf{u} \cdot \mathbf{t} -\int_\Omega \rho^{p}
  [\lambda \nabla \cdot \mathbf{y} \nabla \cdot \mathbf{d}_\mathbf{u} + \mu
  \boldsymbol{\varepsilon}(d_\mathbf{u})\boldsymbol{\varepsilon}(\mathbf{y}_1)] d\Omega


@f}



方程3

@f[
  \int_\Omega  - d_\varrho c_{z_1} +d_\varrho c_{z_2}  + H(d_\varrho)c_{y_2}  d\Omega =


  -\int_\Omega -d_\varrho z_1 + d_\varrho z_2 + H(d_\varrho)y_2 d\Omega


@f]

 </li> 

 <li>  原始可行性。这些方程保证了平等约束的满足。

方程4

@f{align}{
  &\int_\Omega p \rho^{p-1} c_p[\lambda \nabla \cdot
  \mathbf{d}_{\mathbf{y}_1} \nabla \cdot \mathbf{u} +  \mu
  \boldsymbol{\varepsilon}(\mathbf{u}) \boldsymbol{\varepsilon}(\mathbf{d}_{\mathbf{y}_1})] +
  \rho^{p}[\lambda \nabla \cdot \mathbf{d}_{\mathbf{y}_1} \nabla \cdot
  \mathbf{c}_\mathbf{u} +  \mu  \boldsymbol{\varepsilon}(\mathbf{c}_\mathbf{u})
  \boldsymbol{\varepsilon}(\mathbf{d}_{\mathbf{y}_1})] d\Omega \\
  &= -\int_\Omega \rho^{p}[\lambda \nabla \cdot \mathbf{d}_{\mathbf{y}_1} \nabla
  \cdot \mathbf{u} + \mu  \boldsymbol{\varepsilon}(\mathbf{u}) \boldsymbol{\varepsilon}
  (\mathbf{d}_{\mathbf{y}_1})]  + \int_\Gamma  \mathbf{d}_{\mathbf{y}_1}
  \cdot \mathbf{t} d\partial\Omega


@f}



方程5

@f[


  -\int_\Omega d_{z_1}(c_\varrho - c_{s_1}) d\Omega=\int_\Omega d_{z_1} (\varrho - s_1) d\Omega


@f]



方程6

@f[


  -\int_\Omega d_{z_2}(-c_\varrho-c_{s_2}) d\Omega= \int_\Omega d_{z_2} (1-\varrho-s_2) d\Omega


@f]



方程7

@f[


  -\int_\Omega   d_{y_2}(c_\rho - H(c_\varrho)) d\Omega=\int_\Omega d_{y_2}
  (\rho - H(\varrho)) d\Omega


@f]

 </li> 

 <li>  互补松弛性。这些方程基本上确保了障碍的满足--在最终的解决方案中，我们需要  $s^T z = 0$  。

方程8

@f[
  \int_\Omega d_{s_1}(c_{s_1}z_1/s_1 +  c_{z_1} ) d\Omega=-\int_\Omega d_{s_1}
  (z_1 - \alpha/s_1) d\Omega ,\;\;\; \alpha \to 0


@f]



方程9

@f[
  \int_\Omega d_{s_2} (c_{s_2}z_2/s_2 + c_{z_2} ) d\Omega=-\int_\Omega d_{s_2}
  (z_2 - \alpha/s_2)  d\Omega,\;\;\; \alpha \to 0


@f]

 </li> 

 <li>  双重可行性。松弛和松弛变量的拉格朗日乘数必须保持大于0。（这是唯一没有在 `SANDTopOpt::assemble_system()` 函数中实现的部分）。

@f[
  s,z \geq 0


@f]

 </li>   </ol> 




<h3>Discretization</h3>我们使用带有 $Q_1$ 元素的四边形网格来离散位移和位移Lagrange乘数。分片常数 $DGQ_0$ 元素被用来离散密度、未过滤密度、密度松弛变量以及松弛变量和过滤约束的乘数。

<h3>Nonlinear Algorithm</h3>

虽然上面的大部分讨论都是按照传统的和众所周知的方法来解决非线性优化问题，但事实证明，这个问题在实践中其实是相当难解决的。特别是，它是相当非线性的，一个重要的问题不仅仅是像上面讨论的基于牛顿方法的搜索方向 $c_{\{\bullet\}}$ ，而是人们需要花相当多的注意力在这个方向上要走多远。这通常被称为 "线搜索"，归结为如何选择步长 $\alpha_k \in (0,1]$ 的问题，以便我们以尽可能有效的方式从当前迭代 $\mathbf{x}_k$ 移动到下一个迭代 $\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k \mathbf{x}_k$ 。众所周知，我们最终需要选择 $\alpha_k=1$ 来实现牛顿方法的二次收敛；然而，在早期迭代中，采取如此长的步长实际上可能会使事情变得更糟，要么导致一个目标函数更差的点，要么在这个点上的约束条件的满足程度不如在 $\mathbf{x}_k$ 时。

已经提出了非常复杂的算法来处理这个问题  @cite Nocedal2009   @cite Waechter2005  。在这里，我们实现了一个看门狗搜索算法  @cite Nocedal2006  。在讨论这个算法时，我们将使用向量 $\mathbf{x}$ 来表示所有的原始变量--过滤和未过滤的密度、松弛变量和位移，并使用向量 $\mathbf{y}$ 来表示所有的对偶向量。上述非线性方程组的（增量）解决方案现在将被称为 $\Delta \mathbf{x}$ 和 $\Delta
\mathbf{y}$ ，而不是 $c_{\{\bullet\}}$  。一个优点函数（后面有详细解释）在这里被称为 $\phi(\mathbf{x,\mathbf{y}})$  。

应用于具有给定障碍参数的子问题的看门狗算法以如下方式工作。首先，当前迭代被保存为 "看门狗 "状态，并记录看门狗状态的优点。然后采取一个最大的可行的牛顿步骤。如果功绩比第一步充分减少，则接受这个新步骤。如果不是，则采取另一个最大可行的牛顿步骤，并再次将功绩与看门狗的功绩进行比较。如果经过一定数量（通常在5到8之间）的牛顿步骤后，功绩没有充分减少，算法从看门狗状态或最后一次迭代中选择一个缩放的牛顿步骤，以保证功绩充分减少，该步骤被接受。一旦一个步骤被接受，就会测量KKT误差的规范，如果它足够小，就会减少障碍值。如果不够小，则将最后接受的步骤作为新的看门狗步骤，并重复这一过程。


以上，"最大可行步长 "是对牛顿步长在原始变量和对偶变量中的一个缩放，其公式为

@f[
  \beta^\mathbf{y} = \min\{1,\max \beta \text{ such that }\left(\mathbf{z}_{k+i}
   + \beta^\mathbf{z}_{k+i} \Delta \mathbf{z}_{k+i}\right)_j \geq \zeta
   \mathbf{z}_{k+i,j} \forall j\}


@f]



@f[
  \beta^\mathbf{x} = \min\{1,\max \beta \text{ such that }\left(\mathbf{s}_{k+i}
   + \beta^\mathbf{s}_{k+i} \Delta \mathbf{s}_{k+i}\right)_j \geq \zeta
   \mathbf{s}_{k+i,j} \forall j\}


@f]



以上， $\zeta$ 是任何步骤上允许的 "到边界的分数"。由于导数在边界附近变得条件不良，这种技术代表了[信任区域](https://en.wikipedia.org/wiki/Trust_region)，对于确保未来的良好近似是必要的。   $\zeta$ 被认为是 $\max\{0.8, 1-\alpha\}$ ，这允许随着障碍物变小而向边界靠近。未来，在实施减少障碍物的LOQO算法时，必须将其保持在0.8，因为障碍物参数可能变化很大。

另外，我们需要处理我们用来强制执行松弛变量的正性约束的对数障碍 $s_1,s_2$ ：在我们解决的最终优化问题的声明中，我们添加了术语

@f[


  -\alpha \int_\Omega (\log(s_1) + \log(s_2)) d\Omega.


@f]

问题是我们应该如何选择惩罚因子  $\alpha$  。与所有的惩罚方法一样，我们实际上只对极限 $\alpha\to 0$ 感兴趣，因为这才是我们真正想要解决的问题，受松弛变量的正性约束。另一方面，我们需要选择足够大的 $\alpha$ 来使问题在实践中可以解决。因此，实际的实现从较大的 $\alpha$ 值开始，并随着外迭代的进行而逐渐减小它。

在这里实现的单调方法中，每当在当前的障碍参数下达到某种程度的收敛时，就会更新障碍参数。我们使用KKT条件的 $l_\infty$ 准则来检查每个障碍大小的收敛情况。要求是 $\|KKT\|_{l_\infty} < c \cdot \alpha$ ，其中 $c$ 是任何障碍大小的常数， $\alpha$ 是障碍参数。这迫使在以后的迭代中更好地收敛，这与[IPOPT](https://coin-or.github.io/Ipopt/)（一个用于大规模非线性优化的开源软件包）中的要求相同。

在这里，障碍值在较大的数值下是线性减少的，在较小的数值下是超线性的。在较大的数值下，它被乘以一个常数（大约0.6），而在较低的数值下，障碍值被提高到某个指数（大约1.2）的障碍值所取代。事实证明，这种方法能够有效地保持大障碍值下子问题的可解性，同时在较小的障碍值下仍然允许超线性收敛。在实践中，这看起来像以下情况。

@f[
  \alpha_{k+1} = \min\{\alpha_k^{1.2},0.6\alpha_k\}


@f]



虽然在达到收敛时大步减少障碍物的大小被广泛使用，但最近的研究表明，通常使用每次迭代自适应更新障碍物的算法会更快，也就是说，我们在每次迭代结束时使用具体的标准来决定下一次迭代中的惩罚参数应该是什么，而不是使用独立于当前解决方案的减少因素。也就是说，这样的方法也比较复杂，我们在此不做介绍。

<h3>Merit %Function</h3>

上面概述的算法利用了 "优点函数"。功绩函数用于确定从 $x_k$ 到建议点 $x_{k+1}$ 的一步是否有利。在无约束的优化问题中，人们可以简单地用我们试图最小化的目标函数来检查，通常使用[沃尔夫和戈尔茨坦条件]（https://en.wikipedia.org/wiki/Wolfe_conditions）等条件。

在有约束的优化问题中，问题是如何平衡目标函数的减少和可能增加的对约束的违反。一个建议的步骤可能会使目标函数变小，但离满足约束条件的点集更远，或者相反。这种权衡通常通过使用结合这两个标准的优点函数来解决。

在这里，我们使用一个精确的 $l_1$ 功绩函数来测试步骤。

@f{align}{
  \phi(\mathbf{x},\mathbf{y}) =& \int_{\partial \Omega} \mathbf{u}\cdot
  \mathbf{t} d\partial\Omega- \alpha \int_\Omega (\log(s_1) + \log(s_2)) + p \sum_i\left|
  \int_\Omega y_{2,i}(H(\varrho) - \rho) d\Omega \right| \\
  & + p \sum_i\left| \int_{\partial \Omega} \mathbf{y}_{1,i}\cdot \mathbf{t}  d\partial\Omega


  - \int_\Omega \rho^p[\lambda \nabla \cdot \mathbf{u} \nabla \cdot \mathbf{y}_{1,i}
  + \mu \boldsymbol{\varepsilon}{\mathbf{u}}\boldsymbol{\varepsilon}{\mathbf{y}_{1,i}}] d\Omega \right|
  + p \sum_i\left| \int_\Omega z_{1,i}(s_1 - \varrho) d\Omega\right|
  + p \sum_i\left| \int_\Omega z_{2,i}(1-\varrho - s_2) d\Omega\right|


@f}



这里， $p$ 是一个惩罚参数。这个优点函数是精确的，意味着存在一些 $p_0$ ，以便对于任何 $p > p_0$ ，优点函数的最小值与原始问题的位置相同。这个惩罚参数被更新（根据Nocedal和Wright @cite Benson2002 的建议），如下。

@f[
  p > \frac{\frac{1}{2} \mathbf{x}^T \cdot \mathbf{H} \cdot \mathbf{x} - \mathbf{x}^T \cdot \nabla f}{\|c_i\|_{l_\infty}}
  \quad , i \in \mathcal{E},


@f]

其中 $\mathbf{H}$ 是目标函数的Hessian， $\mathbf{x}$ 是我们的决策（原始）变量的矢量， $f$ 是目标函数， $c_i$ 是当前平等约束的误差。

我们使用这种方法的部分原因是在寻找右手边时已经计算了大部分必要的部分，而且使用精确的优点函数可以确保它在与整个问题相同的位置被最小化。最近的研究表明，人们可以用所谓的 "滤波方法 "代替优点函数，人们应该考虑使用这些方法，因为它们被证明是更有效的。


examples/step-79/doc/results.dox



<h1>Results</h1>

<h3>Test Problem</h3>上面使用的算法是针对一个传统的拓扑优化问题进行测试的，这个问题叫做Messerschmitt-Bolkow-Blohm Beam（MBB Beam）。

这个问题考虑的是在一个6个单位宽、1个单位高的矩形上可以建立的最佳二维结构。底部的角在 $y$ 方向用零Dirichlet边界条件固定住，通过强制执行Neumann边界条件在梁的顶部中心施加一个向下的力。边界的其余部分被允许移动，并且没有施加任何外力，这采取了零诺伊曼边界条件的形式。从本质上讲，我们提出了以下问题。我们应该如何设计一座桥，使桥的左下角和右下角的点在滚轮上，允许这些点在水平方向上移动，但不允许在垂直方向上移动，从而使响应于中心的垂直力的位移最小。

虽然领域的总体积是6个单位，但结构允许有3个单位的材料。由于问题的对称性，可以在一个宽为3、高为1的矩形上提出，方法是将原域切成两半，并沿切边在 $x$ 方向使用零迪里希特边界条件。也就是说，解决方案的对称性是一个很好的指标，表明程序正在按预期工作，所以我们在整个领域上解决问题，如下图所示。   @cite Bendse2004 

<div style="text-align:center;"> <img src="https://www.dealii.org/images/steps/developer/step-79.mbbgeometry.png" alt="MBB问题域和边界条件"> </div>


使用上面讨论的程序，我们找到了MBB梁的最小体积，解决方案的各个组成部分看起来如下。

<div class="onecolumn" style="width: 80%; text-align: center;"> <div> <img src="https://www.dealii.org/images/steps/developer/step-79.filtereddensity.png" alt="过滤的密度溶液"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-79.unfiltereddensity.png" alt="未过滤的密度溶液"> </div> </div>


这些图片表明，我们在这里发现的情况与人们通常在关于该主题的其他出版物中看到的情况相一致  @cite Bendse2004  。也许更有趣的是，结果看起来像一座桁架桥（除了我们在桁架的顶部施加负载，而不是像真正的桁架桥那样在底部施加负载，类似于 "桥面桁架 "桥），这表明几个世纪以来一直用于桥梁建设的设计确实是基于我们现在可以证明在某种意义上是最佳的想法。




<h4>Possibilities for extensions</h4>

上面显示的结果花了大约75次迭代才找到，考虑到在每次迭代中解决大型线性系统的费用，这相当令人担忧。看一下演化过程，收敛确实有快速发生和缓慢发生的时候。我们认为这是由于在何时和如何减少边界值方面缺乏精确性，以及我们对优点函数的选择不够理想。在未来，用LOQO障碍更新代替单调还原，以及用马尔科夫滤波器代替优点函数，将大大减少必要的迭代次数。

障碍物的减少在收敛的中间阶段最为敏感，这是有问题的，因为我们似乎需要它快速减少，然后缓慢减少，然后又快速减少。

其次，这里使用的线性求解器只是基于SparseDirectUMFPACK类的稀疏直接求解器。这在小问题上效果还不错，但是上面详述的优化问题的表述有相当多的变量，因此线性问题不仅大，而且在许多行中有很多非零项，即使在总体上仍然比较粗糙的网格上。因此，解算器的时间在计算中占主导地位，需要采用更复杂的方法来解决线性系统。


examples/step-8/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>


在现实生活中，大多数偏微分方程实际上是方程组。相应地，解通常是矢量值的。deal.II库支持这样的问题（见 @ref vector_valued 模块中的大量文档），我们将表明这大多是相当简单的。唯一比较复杂的问题是在组装矩阵和右手边，但这些也很容易理解。

 @dealiiVideoLecture{19} 

在这个教程程序中，我们将想解决<a href="https://en.wikipedia.org/wiki/Linear_elasticity">elastic equations</a>。它们是对拉普拉斯方程的扩展，有一个矢量值的解，描述了受力的刚体在每个空间方向的位移。当然，力也是矢量值的，意味着在每一个点上它都有一个方向和一个绝对值。

人们可以用多种方式来写弹性方程。以最明显的方式显示与拉普拉斯方程的对称性的是将其写成

@f[


  -
  \text{div}\,
  ({\mathbf C} \nabla \mathbf{u})
  =
  \mathbf f,


@f]

其中 $\mathbf u$ 是每一点的矢量值位移， $\mathbf f$ 是力， ${\mathbf C}$ 是一个等级4的张量（即它有四个指数），编码应力-应变关系--本质上，它代表胡克斯定律中的<a href="https://en.wikipedia.org/wiki/Hooke%27s_law">"spring constant"</a>，将位移与力联系起来。  在许多情况下，如果我们想要模拟的物体的变形是由不同的材料组成的，那么 ${\mathbf C}$ 将取决于 $\mathbf x$ 。

虽然上述方程的形式是正确的，但这并不是它们通常的推导方式。事实上，位移的梯度 $\nabla\mathbf u$ （一个矩阵）没有物理意义，而其对称版本。

@f[
\varepsilon(\mathbf u)_{kl} =\frac{1}{2}(\partial_k u_l + \partial_l u_k),


@f]

做，通常被称为 "应变"。(在这里和下文中， $\partial_k=\frac{\partial}{\partial x_k}$  。我们还将使用<a href="https://en.wikipedia.org/wiki/Einstein_notation">Einstein summation
convention</a>，即只要同一指数在方程式中出现两次，就意味着对该指数进行求和；但是，我们将不区分上下指数）。)有了这个应变的定义，弹性方程就读作

@f[


  -
  \text{div}\,
  ({\mathbf C} \varepsilon(\mathbf u))
  =
  \mathbf f,


@f]

你可以把它看作是拉普拉斯方程对矢量值问题的更自然的概括。(首先显示的形式等同于这种形式，因为张量 ${\mathbf C}$ 具有某些对称性，即 $C_{ijkl}=C_{ijlk}$  ，因此 ${\mathbf C} \varepsilon(\mathbf u)_{kl}
= {\mathbf C} \nabla\mathbf u$  。)

当然，我们也可以把这些方程写成组件形式。

@f[


  -
  \partial_j (c_{ijkl} \varepsilon_{kl})
  =
  f_i,
  \qquad
  i=1\ldots d.


@f]



在许多情况下，我们知道所考虑的材料是各向同性的，在这种情况下，通过引入两个系数 $\lambda$ 和 $\mu$ ，系数张量减少为

@f[
  c_{ijkl}
  =
  \lambda \delta_{ij} \delta_{kl} +
  \mu (\delta_{ik} \delta_{jl} + \delta_{il} \delta_{jk}).


@f]



然后，弹性方程可以用更简单的形式重写。

@f[


   -
   \nabla \lambda (\nabla\cdot {\mathbf u})


   -
   (\nabla \cdot \mu \nabla) {\mathbf u}


   -
   \nabla\cdot \mu (\nabla {\mathbf u})^T
   =
   {\mathbf f},


@f]

而各自的双线性形式则是

@f[
  a({\mathbf u}, {\mathbf v}) =
  \left(
    \lambda \nabla\cdot {\mathbf u}, \nabla\cdot {\mathbf v}
  \right)_\Omega
  +
  \sum_{k,l}
  \left(
    \mu \partial_k u_l, \partial_k v_l
  \right)_\Omega
  +
  \sum_{k,l}
  \left(
    \mu \partial_k u_l, \partial_l v_k
  \right)_\Omega,


@f]

或将第一项写成成分之和。

@f[
  a({\mathbf u}, {\mathbf v}) =
  \sum_{k,l}
  \left(
    \lambda \partial_l u_l, \partial_k v_k
  \right)_\Omega
  +
  \sum_{k,l}
  \left(
    \mu \partial_k u_l, \partial_k v_l
  \right)_\Omega
  +
  \sum_{k,l}
  \left(
    \mu \partial_k u_l, \partial_l v_k
  \right)_\Omega.


@f]



 @note 按照写法，如果位移很小，我们可以假设<a
href="http://en.wikipedia.org/wiki/Hookes_law">Hooke's law</a>是有效的，上面的方程一般被认为是对三维物体位移的正确描述。在这种情况下，上面的指数 $i,j,k,l$ 都是在集合 $\{1,2,3\}$ 上运行的（或者，在C++源中，在 $\{0,1,2\}$ 上运行）。然而，按照目前的情况，程序是在2d中运行的，虽然上面的方程在这种情况下也有数学意义，但它们只能描述一个真正的二维实体。特别是，它们不是对 $x-y$ 方向上无限大的体的横截面的适当描述；这与其他许多二维方程相反，这些方程可以通过假设体在 $z$ -方向上具有无限大的范围和解函数不依赖于 $z$ 坐标来获得。另一方面，也有二维弹性模型的方程；例如，见维基百科上的<a
href="http://en.wikipedia.org/wiki/Infinitesimal_strain_theory#Special_cases">plane
strain</a>、<a
href="http://en.wikipedia.org/wiki/Antiplane_shear">antiplane shear</a>和<a
href="http://en.wikipedia.org/wiki/Plane_stress#Plane_stress">plan stress</a>文章。

但让我们回到最初的问题上。我们如何为这样一个方程组装矩阵？在 @ref vector_valued 模块的文档中给出了一个很长的答案，其中有许多不同的选择。从历史上看，下面所示的解决方案是该库早期唯一可用的解决方案。事实证明，它也是最快的。另一方面，如果百分之几的计算时间并不重要，还有比下面讨论的更简单、更直观的方法来组装线性系统，但这些方法直到本教程首次编写后的几年才可用；如果你对它们感兴趣，可以看看  @ref vector_valued  模块。

让我们回到如何组装线性系统的问题上来。首先我们需要一些关于形状函数在矢量值有限元情况下如何工作的知识。基本上，这归结为以下几点：让 $n$ 为我们建立矢量元素的标量有限元素的形状函数的数量（例如，我们将对矢量值有限元素的每个分量使用双线性函数，所以标量有限元素是我们在以前的例子中已经使用过的 <code>FE_Q(1)</code> 元素，以及两个空间维度的 $n=4$ ）。此外，让 $N$ 为矢量元素的形状函数数量；在两个空间维度中，我们需要为矢量的每个分量提供 $n$ 个形状函数，因此 $N=2n$  。那么，矢量元素的 $i$ 个形状函数的形式为

@f[
  \Phi_i({\mathbf x}) = \varphi_{\text{base}(i)}({\mathbf x})\ {\mathbf e}_{\text{comp}(i)},


@f]

其中 $e_l$ 是第 $l$ 个单位向量， $\text{comp}(i)$ 是告诉我们 $\Phi_i$ 的哪个分量是不为零的函数（对于每个向量形状函数，只有一个分量是不为零的，其他都是零）。   $\varphi_{\text{base}(i)}(x)$ 描述了形状函数的空间依赖性，它被认为是标量元素的第 $\text{base}(i)$ 个形状函数。当然，虽然 $i$ 的范围是 $0,\ldots,N-1$ ，但函数 $\text{comp}(i)$ 和 $\text{base}(i)$ 的范围分别为 $0,1$ （在二维）和 $0,\ldots,n-1$ 。

例如（尽管这种形状函数的顺序不被保证，你也不应该依赖它），下面的布局可以被库使用。

@f{eqnarray*}
  \Phi_0({\mathbf x}) &=&
  \left(\begin{array}{c}
    \varphi_0({\mathbf x}) \\ 0
  \end{array}\right),
  \\
  \Phi_1({\mathbf x}) &=&
  \left(\begin{array}{c}
    0 \\ \varphi_0({\mathbf x})
  \end{array}\right),
  \\
  \Phi_2({\mathbf x}) &=&
  \left(\begin{array}{c}
    \varphi_1({\mathbf x}) \\ 0
  \end{array}\right),
  \\
  \Phi_3({\mathbf x}) &=&
  \left(\begin{array}{c}
    0 \\ \varphi_1({\mathbf x})
  \end{array}\right),
  \ldots


@f}

在这里

@f[
  \text{comp}(0)=0, \quad  \text{comp}(1)=1, \quad  \text{comp}(2)=0, \quad  \text{comp}(3)=1, \quad  \ldots


@f]



@f[
  \text{base}(0)=0, \quad  \text{base}(1)=0, \quad  \text{base}(2)=1, \quad  \text{base}(3)=1, \quad  \ldots


@f]



除了非常罕见的情况，你不需要知道标量元素的哪个形状函数 $\varphi_{\text{base}(i)}$ 属于矢量元素的一个形状函数 $\Phi_i$ 。因此，让我们定义

@f[
  \phi_i = \varphi_{\text{base}(i)}


@f]

据此，我们可以将矢量形状函数写为

@f[
  \Phi_i({\mathbf x}) = \phi_{i}({\mathbf x})\ {\mathbf e}_{\text{comp}(i)}.


@f]

现在你可以安全地忘记函数 $\text{base}(i)$ 了，至少在这个例子程序的其余部分。

现在使用这个矢量形状函数，我们可以将离散的有限元解写为

@f[
  {\mathbf u}_h({\mathbf x}) =
  \sum_i \Phi_i({\mathbf x})\ U_i


@f]

具有标量系数  $U_i$  。如果我们定义一个模拟函数 ${\mathbf v}_h$ 作为测试函数，我们可以将离散问题写成如下。找出系数 $U_i$ ，使得

@f[
  a({\mathbf u}_h, {\mathbf v}_h) = ({\mathbf f}, {\mathbf v}_h)
  \qquad
  \forall {\mathbf v}_h.


@f]



如果我们把双线性形式的定义和 ${\mathbf u}_h$ 和 ${\mathbf v}_h$ 的表示插入这个公式。

@f{eqnarray*}
  \sum_{i,j}
    U_i V_j
  \sum_{k,l}
  \left\{
  \left(
    \lambda \partial_l (\Phi_i)_l, \partial_k (\Phi_j)_k
  \right)_\Omega
  +
  \left(
    \mu \partial_l (\Phi_i)_k, \partial_l (\Phi_j)_k
  \right)_\Omega
  +
  \left(
    \mu \partial_l (\Phi_i)_k, \partial_k (\Phi_j)_l
  \right)_\Omega
  \right\}
\\
=
  \sum_j V_j
  \sum_l
  \left(
    f_l,
    (\Phi_j)_l
  \right)_\Omega.


@f}

我们注意到，在这里和下文中，指数 $k,l$ 在空间方向上运行，即 $0\le k,l < d$  ，而指数 $i,j$ 在自由度上运行。

因此，单元 $K$ 上的局部刚度矩阵有以下条目。

@f[
  A^K_{ij}
  =
  \sum_{k,l}
  \left\{
  \left(
    \lambda \partial_l (\Phi_i)_l, \partial_k (\Phi_j)_k
  \right)_K
  +
  \left(
    \mu \partial_l (\Phi_i)_k, \partial_l (\Phi_j)_k
  \right)_K
  +
  \left(
    \mu \partial_l (\Phi_i)_k, \partial_k (\Phi_j)_l
  \right)_K
  \right\},


@f]

其中 $i,j$ 现在是局部自由度，因此 $0\le i,j < N$  。在这些公式中，我们总是取矢量形状函数 $\Phi_i$ 的一些分量，当然，这些分量是如下给出的（见其定义）。

@f[
  (\Phi_i)_l = \phi_i \delta_{l,\text{comp}(i)},


@f]

与克朗克符号  $\delta_{nm}$  。由于这一点，我们可以删除一些对  $k$  和  $l$  的和。

@f{eqnarray*}
  A^K_{ij}
  &=&
  \sum_{k,l}
  \Bigl\{
  \left(
    \lambda \partial_l \phi_i\ \delta_{l,\text{comp}(i)},
            \partial_k \phi_j\ \delta_{k,\text{comp}(j)}
  \right)_K
\\
  &\qquad\qquad& +
  \left(
    \mu \partial_l \phi_i\ \delta_{k,\text{comp}(i)},
        \partial_l \phi_j\ \delta_{k,\text{comp}(j)}
  \right)_K
  +
  \left(
    \mu \partial_l \phi_i\ \delta_{k,\text{comp}(i)},
        \partial_k \phi_j\ \delta_{l,\text{comp}(j)}
  \right)_K
  \Bigr\}
\\
  &=&
  \left(
    \lambda \partial_{\text{comp}(i)} \phi_i,
            \partial_{\text{comp}(j)} \phi_j
  \right)_K
  +
  \sum_l
  \left(
    \mu \partial_l \phi_i,
        \partial_l \phi_j
  \right)_K
  \ \delta_{\text{comp}(i),\text{comp}(j)}
  +
  \left(
    \mu \partial_{\text{comp}(j)} \phi_i,
        \partial_{\text{comp}(i)} \phi_j
  \right)_K
\\
  &=&
  \left(
    \lambda \partial_{\text{comp}(i)} \phi_i,
            \partial_{\text{comp}(j)} \phi_j
  \right)_K
  +
  \left(
    \mu \nabla \phi_i,
        \nabla \phi_j
  \right)_K
  \ \delta_{\text{comp}(i),\text{comp}(j)}
  +
  \left(
    \mu \partial_{\text{comp}(j)} \phi_i,
        \partial_{\text{comp}(i)} \phi_j
  \right)_K.


@f}



同样地，单元格 $K$ 对右侧向量的贡献是

@f{eqnarray*}
  f^K_j
  &=&
  \sum_l
  \left(
    f_l,
    (\Phi_j)_l
  \right)_K
\\
  &=&
  \sum_l
  \left(
    f_l,
    \phi_j \delta_{l,\text{comp}(j)}
  \right)_K
\\
  &=&
  \left(
    f_{\text{comp}(j)},
    \phi_j
  \right)_K.


@f}



这就是我们要实现局部刚度矩阵和右手边向量的形式。

作为最后的说明：在第17步的例子程序中，我们将重新审视这里提出的弹性问题，并将展示如何在一个计算机集群上以%并行的方式解决这个问题。因此，所产生的程序将能够以更高的精度解决这个问题，而且如果需要的话，效率更高。此外，在第20步， @ref step_21 "第21步"，以及其他一些后来的教程程序中，我们将重新审视一些矢量值问题，并展示一些技术，这些技术可能使实际通过上面显示的所有东西更简单，与 FiniteElement::system_to_component_index 等。


examples/step-8/doc/results.dox



<h1>Results</h1>


关于这个程序的结果，除了它们看起来很好之外，没有什么可说的。所有图片都是用VisIt从程序写入磁盘的输出文件中制作的。前两张图片显示了 $x$ -和 $y$ -位移的标量分量。

 <table width="100%">
<tr>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-8.x.png" alt="">
</td>
<td>
<img src="https://www.dealii.org/images/steps/developer/step-8.y.png" alt="">
</td>
</tr>
</table> 


你可以清楚地看到 $x$ 周围的位移 $x=0.5$ 和 $x=-0.5$ 的来源，以及 $y$ 在原点的位移。

人们经常想做的是将位移显示为一个矢量场，也就是说，每一个点的矢量都说明了位移的方向和大小。不幸的是，这就有点麻烦了。为了理解为什么会这样，请记住，我们刚刚将我们的有限元定义为两个分量的集合（在 <code>dim=2</code> 维度）。我们没有说过这不仅仅是一个压力和一个浓度（两个标量），而是说这两个分量实际上是一个矢量值量的一部分，即位移。如果没有这方面的知识，DataOut类就会假定我们打印的所有单个变量都是独立的标量，然后VisIt和Paraview就会忠实地假定这确实是这样的。换句话说，一旦我们把数据写成标量，这些程序中就没有任何东西可以让我们把这两个标量字段粘贴到一起作为一个矢量字段。我们必须从根本上解决这个问题，即在  <code>ElasticProblem::output_results()</code>  。我们不会在这里这样做，而是让读者参考step-22程序，在那里我们展示了如何在一个更普遍的情况下这样做。话虽如此，我们还是忍不住要生成数据，以显示如果按照步骤22中讨论的方式实施，这将是什么样子。矢量场看起来是这样的（VisIt和Paraview随机选择几百个顶点来绘制矢量；从每个顶点绘制矢量会使图片无法阅读）。

 <img src="https://www.dealii.org/images/steps/developer/step-8.vectors.png" alt=""> 


我们注意到，由于 $x$ -和 $y$ -力相对于这些轴是对称的，人们可能直观地期望解是关于 $x$ -和 $y$ -轴的对称。然而，作为矢量的力是不对称的，因此解决方案也不对称。


examples/step-9/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>


在这个例子中，我们的目的如下。<ol>  <li>  解决平流方程  $\beta \cdot \nabla u = f$  ；  <li>  显示如果我们有一台多处理器机器，我们如何使用多线程来快速获得结果；  <li>  开发一个简单的细化准则。   </ol> 虽然第二个目的在不参考代码的情况下很难进行一般性描述，但我们将在下文中讨论其他两个目的。然后将在程序中的相关地方详细介绍多线程的使用。然而，我们将遵循 @ref threads "多处理器访问共享内存的并行计算 "文件模块中详述的关于WorkStream方法的一般讨论。




<h3>Discretizing the advection equation</h3>

在本例程序中，我们要对平流方程的解进行数值近似计算

@f[
  \beta \cdot \nabla u = f,


@f]

其中 $\beta$ 是描述平流方向和速度的矢量场（如果 $\beta=\beta(\mathbf x)$ ，它可能取决于空间变量）， $f$ 是一个源函数， $u$ 是解。该方程描述的物理过程是一个给定的流场 $\beta$ ，另一种物质随其流动，其密度或浓度由 $u$ 给出。该方程不包含这第二种物质在其载体物质内的扩散，但有源项。

很明显，在流入地，上述方程需要用边界条件来增加。

@f[
  u = g \qquad\qquad \mathrm{on}\ \partial\Omega_-,


@f]

其中 $\partial\Omega_-$ 描述了边界的流入部分，正式定义为

@f[
  \partial\Omega_-
  =
  \{{\mathbf x}\in \partial\Omega: \beta\cdot{\mathbf n}({\mathbf x}) < 0\},


@f]

和 ${\mathbf n}({\mathbf x})$ 是点 ${\mathbf x}\in\partial\Omega$ 处的域的向外法线。这个定义非常直观，因为由于 ${\mathbf n}$ 指向外侧，如果传输方向 $\beta$ 指向内侧，即在流入边界，那么与 $\beta$ 的标量乘积只能是负数。数学理论规定，我们不能在边界的流出部分提出任何边界条件。

不幸的是，上述方程不能以稳定的方式用标准的有限元方法进行求解。问题是，这个方程的解在垂直于传输方向上具有不充分的规则性：虽然它们沿 "风场" $\beta$ 定义的流线是平滑的，但它们在垂直于这个方向上可能是不连续的。这很容易理解：方程 $\beta \cdot
\nabla u = f$ 的意思实质上就是<i>rate of change of $u$ in
direction $\beta$ equals $f$</i>。但该方程对垂直方向的导数没有影响，因此，如果 $u$ 在流入边界的某一点上不连续，那么这个不连续将简单地沿着从这个边界点开始的风场流线传输。这些不连续会导致数值不稳定，使标准的连续有限元离散化不可能获得稳定的解。

解决这一困难的标准方法是  <em>  "流线-上风Petrov-Galerkin"  </em>  (SUPG)方法，有时也称为流线扩散法。对该方法的良好解释可以在  @cite elman2005  中找到。从形式上看，这种方法取代了我们从强形式推导出微分方程的弱形式的步骤。我们不是用测试函数 $v$ 乘以方程并在域上积分，而是乘以 $v + \delta \beta\cdot\nabla v$  ，其中 $\delta$ 是在（局部）网格宽度范围内选择的参数 $h$ ；通过设置 $\delta=0.1h$ 通常可以获得良好的结果。 为什么这被称为 "流线扩散 "将在下面解释；目前，让我们简单地认为这是我们如何推导出稳定的离散公式。这里 $\delta$ 的值小到足以使我们不引入过度的扩散，但大到足以使所产生的问题得到良好的解决。

使用上面定义的测试函数，问题的初始弱形式将要求找到一个函数 $u_h$ ，以便对于所有测试函数 $v_h$ ，我们有

@f[
  (\beta \cdot \nabla u_h, v_h + \delta \beta\cdot\nabla v_h)_\Omega
  =
  (f, v_h + \delta \beta\cdot\nabla v_h)_\Omega.


@f]

然而，我们希望将流入的边界条件 $u=g$ 弱化到这个问题中，这可以通过要求除了上述方程之外，我们还有

@f[
  (u_h, w_h)_{\partial\Omega_-}
  =
  (g, w_h)_{\partial\Omega_-}


@f]

为所有住在边界上的测试函数 $w_h$ ，它们来自一个合适的测试空间。事实证明，一个合适的检验函数空间恰好是 $\beta\cdot {\mathbf n}$ 乘以我们已经用于域内微分方程的检验空间中的函数 $v_h$ 的踪迹。因此，我们要求对于所有测试函数 $v_h$ ，我们有

@f[
  (u_h, \beta\cdot {\mathbf n} v_h)_{\partial\Omega_-}
  =
  (g, \beta\cdot {\mathbf n} v_h)_{\partial\Omega_-}.


@f]

在不试图进行论证的情况下（请再次参阅关于一般的有限元方法，特别是流线扩散方法的文献），我们可以将微分方程和边界值的方程结合在我们的稳定化问题的以下弱表述中：找到一个离散函数 $u_h$ ，使得对于所有离散测试函数 $v_h$ ，存在着

@f[
  (\beta \cdot \nabla u_h, v_h + \delta \beta\cdot\nabla v_h)_\Omega


  -
  (u_h, \beta\cdot {\mathbf n} v_h)_{\partial\Omega_-}
  =
  (f, v_h + \delta \beta\cdot\nabla v_h)_\Omega


  -
  (g, \beta\cdot {\mathbf n} v_h)_{\partial\Omega_-}.


@f]




人们会认为，这将导致一个系统矩阵被倒置，其形式为

@f[
  a_{ij} =
  (\beta \cdot \nabla \varphi_i,
   \varphi_j + \delta \beta\cdot\nabla \varphi_j)_\Omega


  -
  (\varphi_i, \beta\cdot {\mathbf n} \varphi_j)_{\partial\Omega_-},


@f]

与基函数  $\varphi_i,\varphi_j$  。  然而，这是每一个数值分析师至少会遇到一次的陷阱（包括作者）：我们在这里扩大了解决方案  $u_h = \sum_i U_i \varphi_i$  ，但如果我们这样做，我们将不得不解决这个问题

@f[
  U^T A = F^T,


@f]

其中 $U$ 是膨胀系数的向量，也就是说，我们必须解决我们可能天真的预期的转置问题。

这是我们在步骤3的介绍中提出的一个观点。在那里，我们认为为了避免这种问题，应该养成总是与检验函数<i>from the left</i>相乘的习惯，而不是从右边得到正确的矩阵。为了得到我们所需要的线性系统的形式，最好将弱式改写为

@f[
  (v_h + \delta \beta\cdot\nabla v_h, \beta \cdot \nabla u_h)_\Omega


  -
  (\beta\cdot {\mathbf n} v_h, u_h)_{\partial\Omega_-}
  =
  (v_h + \delta \beta\cdot\nabla v_h, f)_\Omega


  -
  (\beta\cdot {\mathbf n} v_h, g)_{\partial\Omega_-}


@f]

然后得到

@f[
  a_{ij} =
  (\varphi_i + \delta \beta \cdot \nabla \varphi_i,
   \beta\cdot\nabla \varphi_j)_\Omega


  -
  (\beta\cdot {\mathbf n} \varphi_i, \varphi_j)_{\partial\Omega_-},


@f]

作为系统矩阵。我们将在程序中组装这个矩阵。




<h3>Why is this method called "streamline diffusion"?</h3>

看一下上面提到的双线性形式，我们看到离散解必须满足一个方程，其中弱形式的左手边有一个域项，即

@f[
  (v_h + \delta \beta\cdot\nabla v_h, \beta \cdot \nabla u_h)_\Omega,


@f]

或如果我们将其拆分，则形式为

@f[
  (v_h, \beta \cdot \nabla u_h)_\Omega
  +
  (\delta \beta\cdot\nabla v_h, \beta \cdot \nabla u_h)_\Omega.


@f]

如果我们想看看这将对应于什么强的方程形式，我们需要对第二项进行积分。这就产生了下面的公式，为了简单起见，我们暂时不考虑边界项。

@f[
  (v_h, \beta \cdot \nabla u_h)_\Omega


  -
  \left(v_h, \delta \nabla \cdot \left[\beta \left(\beta \cdot \nabla
  u_h\right)\right]\right)_\Omega
  +
  \text{boundary terms}.


@f]

让我们暂时假设风场 $\beta$ 是无发散的，即 $\nabla \cdot \beta = 0$  。然后将乘积法则应用于右边方括号内项的导数，并利用发散-绿色，我们将得到以下结果。

@f[
  (v_h, \beta \cdot \nabla u_h)_\Omega


  -
  \left(v_h, \delta \left[\beta \cdot \nabla\right] \left[\beta \cdot \nabla
  \right]u_h\right)_\Omega
  +
  \text{boundary terms}.


@f]

这意味着，方程的强势形式将是这样的

@f[
  \beta \cdot \nabla u_h


  -
  \delta
  \left[\beta \cdot \nabla\right] \left[\beta \cdot \nabla
  \right] u_h.


@f]

现在要认识到的是， $\beta\cdot\nabla$ 是 <em> 方向的导数 $\beta$   </em>  。因此，如果我们用 $\beta\cdot\nabla=\frac{\partial}{\partial \beta}$ 来表示（就像我们经常用 $\mathbf n\cdot\nabla=\frac{\partial}{\partial n}$ 来表示边界处法线方向的导数一样），那么方程的强形式是

@f[
  \beta \cdot \nabla u_h


  -
  \delta
  \frac{\partial^2}{\partial\beta^2} u_h.


@f]

换句话说，测试函数的不寻常选择相当于在强形式中增加了一个项，它对应于风场方向的二阶（即扩散）微分算子 $\beta$ ，即 "流线方向"。更全面的说明还必须探讨测试函数对边界值的影响，以及为什么有必要对右手边也使用相同的测试函数，但上面的讨论可能会使人明白该方法的 "流线扩散 "名称的由来。




<h3>Why is this method also called "Petrov-Galerkin"?</h3>

"Galerkin方法 "是指通过将方程乘以测试函数 $v$ （然后在 $\Omega$ 上进行积分）来获得弱表述，其中函数 $v$ 与解 $u$ 来自同一空间（尽管可能具有不同的边界值）。但这并不是严格意义上的必要条件。我们也可以想象从不同的函数集中选择测试函数，只要这个不同的函数集具有与原始函数集 "同样多的维度"，这样我们最终就会有与自由度同样多的独立方程（在无限维的情况下，所有这些都需要适当地定义）。利用这种可能性的方法（即以不同的方式选择测试函数集和解决方案集）被称为 "Petrov-Galerkin "方法。在目前的情况下，测试函数的形式都是 $v+\beta\cdot\nabla v$ ，其中 $v$ 是来自解集。




<h3>Why is this method also called "streamline-upwind"?</h3>

[上风方法](https://en.wikipedia.org/wiki/Upwind_scheme)在推导平流方程的稳定方案方面有很长的历史。一般来说，这个想法是，我们不是在 "这里 "看一个函数，而是在 "上游 "或 "上风 "的一小段距离看它，也就是说，"这里 "的信息最初来自哪里。这可能意味着不考虑 $u(\mathbf x)$ ，而是像 $u(\mathbf x - \delta \beta)$ 这样的。或者，等于是在整合后，我们可以评估 $u(\mathbf x)$ ，而考虑 $v$ 的下游部分。   $v(\mathbf x+\delta \beta)$  .由于各种原因，这将是很麻烦的。首先，如果 $\mathbf x + \delta \beta$ 恰好在 $\Omega$ 之外，我们将不得不定义 $v$ 应该是什么；其次，数值计算积分将更加困难，因为我们不再在同一正交点评估 $u$ 和 $v$ 。但由于我们假设 $\delta$ 很小，我们可以做一个泰勒扩展。

@f[
  v(\mathbf x + \delta \beta)
  \approx
  v(\mathbf x) + \delta \beta \cdot \nabla v(\mathbf x).


@f]

这个测试函数的形式现在看起来应该很熟悉。




<h3>Solving the linear system that corresponds to the advection equation</h3>

由于产生的矩阵不再是对称正定的，我们不能使用通常的共轭梯度方法（在SolverCG类中实现）来解决这个系统。相反，我们使用GMRES（Generalized Minimum RESidual）方法（在SolverGMRES中实现），它适用于我们这里的那种问题。




<h3>The test case</h3>

对于我们将在本教程程序中解决的问题，我们使用以下领域和函数（在 $d=2$ 空间维度）。

@f{eqnarray*}
  \Omega &=& [-1,1]^d \\
  \beta({\mathbf x})
  &=&
  \left(
    \begin{array}{c}2 \\ 1+\frac 45 \sin(8\pi x)\end{array}
  \right),
  \\
  s
  &=&
  0.1,
  \\
  f({\mathbf x})
  &=&
  \left\{
    \begin{array}{ll}
        \frac 1{10 s^d} &
        \mathrm{for}\ |{\mathbf x}-{\mathbf x}_0|<s, \\
        0 & \mathrm{else},
    \end{array}
  \right.
  \qquad\qquad
  {\mathbf x}_0
  =
  \left(
    \begin{array}{c} -\frac 34 \\ -\frac 34\end{array}
  \right),
  \\
  g
  &=&
  e^{5 (1 - |\mathbf x|^2)} \sin(16\pi|\mathbf x|^2).


@f}

对于 $d>2$ ，我们扩展了 $\beta$ 和 ${\mathbf x}_0$ ，只是将上面显示的最后一个组件再重复一次。

说了这么多，下面的评论是有必要的。<ol>  <li>  平流场 $\beta$ 大致以对角线方向从左下角向右上角传输解决方案，但叠加了一个摆动结构。   <li>  右手边在流入边界条件产生的场中加入了左下角的一个圆球，然后沿着这个圆球传输。   <li>  流入边界条件施加了一个加权的正弦结构，该结构与流场一起被传输。由于 $|{\mathbf x}|\ge 1$ 在边界上，加权项从未变得非常大。   </ol> 




<h3>A simple refinement criterion</h3>

在以前所有的自适应细化的例子中，我们都使用了Kelly等人首先开发的误差估计器，它为每个单元 $K$ 分配了以下指标。

@f[
  \eta_K =
  \left(
    \frac {h_K}{24}
    \int_{\partial K}
      [\partial_n u_h]^2 \; d\sigma
  \right)^{1/2},


@f]

其中 $[\partial n u_h]$ 表示跨越单元格 $K$ 的一个面的法向导数的跳变。可以证明，这个误差指标使用的是二阶导数的离散类似物，由单元大小的一个幂加权，这个幂是根据这里假定使用的线性元素调整的。

@f[
  \eta_K \approx
  C h \| \nabla^2 u \|_K,


@f]

其本身与能量准则中的误差大小有关。

在目前的情况下，这个误差指标的问题是，它假定精确的解拥有二阶导数。在某些情况下，这对于拉普拉斯问题的解来说已经是个问题了，尽管那里大多数问题允许在 $H^2$ 中求解。如果解只在 $H^1$ 中，那么二阶导数在域的某些部分（低维）是奇异的，在网格细化的情况下，误差指标不会减少。因此，该算法将不断细化这些部分周围的单元，即细化为点或线（在2d中）。

然而，对于目前的情况，解通常不在 $H^1$ 中（而且这种缺失的规律性并不是像拉普拉斯方程那样的特殊情况），所以上述的误差指标并不真正适用。因此，我们将开发一个基于梯度的离散近似的指标。尽管梯度经常不存在，但这是我们唯一可用的标准，至少在我们使用连续元素时是如此。首先，我们注意到，给定两个单元 $K$ ， $K'$ ，其中心由矢量 ${\mathbf y}_{KK'}$ 连接，我们可以对一个函数 $u$ 的方向导数进行近似，如下所示。

@f[
  \frac{{\mathbf y}_{KK'}^T}{|{\mathbf y}_{KK'}|} \nabla u
  \approx
  \frac{u(K') - u(K)}{|{\mathbf y}_{KK'}|},


@f]

其中 $u(K)$ 和 $u(K')$ 表示 $u$ 在各自单元格中心的评价。现在我们将上述近似值乘以 ${\mathbf y}_{KK'}/|{\mathbf y}_{KK'}|$ ，并对 $K$ 的所有邻居 $K'$ 求和。

@f[
  \underbrace{
    \left(\sum_{K'} \frac{{\mathbf y}_{KK'} {\mathbf y}_{KK'}^T}
                         {|{\mathbf y}_{KK'}|^2}\right)}_{=:Y}
  \nabla u
  \approx
  \sum_{K'}
  \frac{{\mathbf y}_{KK'}}{|{\mathbf y}_{KK'}|}
  \frac{u(K') - u(K)}{|{\mathbf y}_{KK'}|}.


@f]

如果连接 ${\mathbf y}_{KK'}$ 与邻居的向量 $K$ 横跨整个空间（即大致为： $K$ 在所有方向都有邻居），那么左侧表达式中括号内的项形成一个正则矩阵，我们可以将其反转，得到 $u$ 对 $K$ 的梯度的近似。

@f[
  \nabla u
  \approx
  Y^{-1}
  \left(
    \sum_{K'}
    \frac{{\mathbf y}_{KK'}}{|{\mathbf y}_{KK'}|}
    \frac{u(K') - u(K)}{|{\mathbf y}_{KK'}|}
  \right).


@f]

我们将用 $\nabla_h u(K)$ 表示右手边的近似值，我们将使用以下数量作为细化标准。

@f[
  \eta_K = h^{1+d/2} |\nabla_h u_h(K)|,


@f]

这是受以下（不严谨的）论证的启发。

@f{eqnarray*}
  \|u-u_h\|^2_{L_2}
  &\le&
  C h^2 \|\nabla u\|^2_{L_2}
\\
  &\approx&
  C
  \sum_K
  h_K^2 \|\nabla u\|^2_{L_2(K)}
\\
  &\le&
  C
  \sum_K
  h_K^2 h_K^d \|\nabla u\|^2_{L_\infty(K)}
\\
  &\approx&
  C
  \sum_K
  h_K^{2+d} |\nabla_h u_h(K)|^2


@f}




examples/step-9/doc/results.dox



<h1>Results</h1>


这个程序的结果并不特别引人注目。它们由控制台输出、一些网格文件和每个网格的解决方案组成。首先是控制台的输出。

@code
Cycle 0:
   Number of active cells:              64
   Number of degrees of freedom:        1681
   Iterations required for convergence: 298
   Max norm of residual:                3.60316e-12
Cycle 1:
   Number of active cells:              124
   Number of degrees of freedom:        3537
   Iterations required for convergence: 415
   Max norm of residual:                3.70682e-12
Cycle 2:
   Number of active cells:              247
   Number of degrees of freedom:        6734
   Iterations required for convergence: 543
   Max norm of residual:                7.19716e-13
Cycle 3:
   Number of active cells:              502
   Number of degrees of freedom:        14105
   Iterations required for convergence: 666
   Max norm of residual:                3.45628e-13
Cycle 4:
   Number of active cells:              1003
   Number of degrees of freedom:        27462
   Iterations required for convergence: 1064
   Max norm of residual:                1.86495e-13
Cycle 5:
   Number of active cells:              1993
   Number of degrees of freedom:        55044
   Iterations required for convergence: 1251
   Max norm of residual:                1.28765e-13
Cycle 6:
   Number of active cells:              3985
   Number of degrees of freedom:        108492
   Iterations required for convergence: 2035
   Max norm of residual:                6.78085e-14
Cycle 7:
   Number of active cells:              7747
   Number of degrees of freedom:        210612
   Iterations required for convergence: 2187
   Max norm of residual:                2.61457e-14
Cycle 8:
   Number of active cells:              15067
   Number of degrees of freedom:        406907
   Iterations required for convergence: 3079
   Max norm of residual:                2.9932e-14
Cycle 9:
   Number of active cells:              29341
   Number of degrees of freedom:        780591
   Iterations required for convergence: 3913
   Max norm of residual:                8.15689e-15
@endcode



相当多的单元格被用在最精细的层面上，以解决解决方案的特征。下面是第四和第十个网格。<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-9-grid-3.png" alt="细化周期中的第四个网格，显示对特征的一些适应性。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-9-grid-9.png" alt="细化周期中的第十个网格，显示完全捕捉到波。" width="400" height="400"> </div> <div> 以及第四和第十的解决方案。<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-9-solution-3.png" alt="第四个解决方案，显示我们解决了大多数特征，但有些仍然没有解决，显得很模糊。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-9-solution-9.png" alt="第十个解决方案，显示完全解决的流动。" width="400" height="400"> </div> </div> 以及网格和解决方案都被放大。<div class="twocolumn" style="width: 80%"> <div> <img src="https://www.dealii.org/images/steps/developer/step-9-solution-3-zoom.png" alt="第四个解决方案的细节，显示我们解决了大多数特征，但有些仍然没有解决，显得模糊不清。特别是，较大的单元格需要细化。" width="400" height="400"> </div> <div> <img src="https://www.dealii.org/images/steps/developer/step-9-solution-9-zoom.png" alt="第十个解决方案的细节，显示我们需要比第四个解决方案中存在的更多单元格。" width="400" height="400"> </div> </div>

解决方案是由那部分沿摆动的平流场从左、下边界传送到右上方的部分，以及由左下角的源所产生的部分，其结果也是沿传送的。上面显示的网格很好地适应了解决这些特征。图中的比较表明，即使我们使用的是高阶近似，我们仍然需要自适应的网格细化来完全解决摆动。


